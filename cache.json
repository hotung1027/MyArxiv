{"2026-01-05T00:00:00Z":{"Optimization and Control":[{"id":"http://arxiv.org/abs/2601.02347v1","updated":"2026-01-05T18:44:27Z","published":"2026-01-05T18:44:27Z","title":"Solving Matrix Games with Even Fewer Matrix-Vector Products","summary":"We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and of $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In particular, our result for $\\ell_2$-$\\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.","authors":["Ishani Karmarkar","Liam O'Carroll","Aaron Sidford"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.20017v4","updated":"2026-01-05T17:22:11Z","published":"2025-04-28T17:35:55Z","title":"Constructing Magic Squares: an integer constraint satisfaction problem and a fast approach","summary":"Magic squares are a fascinating mathematical challenge that has intrigued mathematicians for centuries. Given a positive (and possibly large) integer \\( n \\), one of the main challenges that still remains is to find, within a computational time, a magic square of order \\( n \\), that is, a square matrix of order \\( n \\) with unique integers from \\( a_{\\min} \\) to \\( a_{\\max} \\), such that the sum of each row, column, and diagonal equals a constant \\( \\mathcal{C}(A) \\). In this work, we first present an integer constraint satisfaction problem for constructing a magic square of order \\( n \\). Nonetheless, the solution time of this problem grows exponentially as the order increases. To overcome this limitation, we also propose a that constructs magic squares depending on whether \\( n \\) is odd, singly even, or doubly even. Moreover, we provide a proof of the correctness of this novel approach. Our numerical results show that our method can construct magic squares of order up to \\num{70000} in less than \\num{140} seconds, demonstrating its efficiency and scalability.","authors":["João Vitor Pamplona","Maria Eduarda Pinheiro","Luiz-Rafael Santos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12857v2","updated":"2026-01-05T16:12:31Z","published":"2025-11-17T01:05:11Z","title":"Approximate Message Passing for Quantum State Tomography","summary":"Quantum state tomography (QST) is an indispensable tool for characterizing many-body quantum systems. However, due to the exponential scaling of the cost of the protocol with system size, many approaches have been developed for quantum states with specific structure, such as low-rank states. In this paper, we show how approximate message passing (AMP), an algorithmic framework for sparse signal recovery, can be used to perform low-rank QST. AMP provides asymptotically optimal performance guarantees for large sparse recovery problems, which suggests its utility for QST. We discuss the design challenges that come with applying AMP to QST, and show that by properly designing the AMP algorithm, we can reduce the reconstruction error by over an order of magnitude compared to existing approaches to low-rank QST. We also performed tomographic experiments on IBM Kingston and considered the effect of device noise on the reliability of the predicted fidelity of state preparation. Our work advances the state of low-rank QST and may be applicable to other quantum tomography protocols.","authors":["Noah Siekierski","Kausthubh Chandramouli","Christian Kümmerle","Bojko N. Bakalov","Dror Baron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02229v1","updated":"2026-01-05T15:55:46Z","published":"2026-01-05T15:55:46Z","title":"Extended real number arithmetics via Dedekind cuts","summary":"It is shown how Dedekind cuts can be used to introduce the extended real numbers along with sound arithmetic laws via one simple rule for the addition of sets. The crucial idea is that the use of the lower and the upper part of the cuts, respectively, leads to two different additions which are known in the literature as inf-addition and sup-addition. Moreover, the two resulting structures are conlinear spaces which at the same time are complete lattices with respect to the natural order. This admits the definition of pseudo-differences on the extended reals which also provide formulas for expressions like $(+\\infty) - (+\\infty)$, $(-\\infty) - (-\\infty)$. There are two major motivations: one is that proper and improper extended real-valued functions can be treated in a unified manner, the other that set-valued functions can often be represented by families of scalar functions which may include improper ones.","authors":["Andreas H Hamel"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2512.13195v2","updated":"2026-01-05T15:33:38Z","published":"2025-12-15T11:10:13Z","title":"A Spectral Exponential Stability Criterion for Integral Difference Equations and Delay Differential Equations in various state spaces","summary":"It is well-known that the exponential stability of Integral Difference Equations and Delay Difference Equations, in the usual state space of continuous functions, is equivalent to the location of the roots of its associated characteristic equation strictly in the open left half-plane (see e.g. [16, Chapter 9]). In this paper, we use results from [15, Chapter 4] to show that this characterization still holds for other functional state spaces: Lebesgue spaces, the space of Borel measurable bounded functions, and the space of functions with bounded variation.","authors":["Adam Braun","Jean Auriol","Lucas Brivadis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02207v1","updated":"2026-01-05T15:31:27Z","published":"2026-01-05T15:31:27Z","title":"Risk-Averse Markov Decision Processes: Applications to Electricity Grid and Reservoir Management","summary":"This paper develops risk-averse models to support system operators in planning and operating the electricity grid under uncertainty from renewable power generation. We incorporate financial risk hedging using conditional value at risk (CVaR) within a Markov Decision Process (MDP) framework and propose efficient, exact solution methods for these models. In addition, we introduce a power reliability-oriented risk measure and present new, computationally efficient models for risk-averse grid planning and operations.","authors":["Arash Khojaste","Jonathan Pearce","Daniela Pucci de Farias","Geoffrey Pritchard","Golbon Zakeri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.17624v2","updated":"2026-01-05T14:54:51Z","published":"2025-10-20T15:08:17Z","title":"Counterfactual Explanations for Integer Optimization Problems","summary":"Counterfactual explanations (CEs) offer a human-understandable way to explain decisions by identifying specific changes to the input parameters of a base or present model that would lead to a desired change in the outcome. For optimization models, CEs have primarily been studied in limited contexts and little research has been done on CEs for general integer optimization problems. In this work, we address this gap. We first show that the general problem of constructing a CE is $Σ_2^p$-complete even for binary integer programs with just a single mutable constraint. Second, we propose solution algorithms for several of the most tractable special cases: (i) mutable objective parameters, (ii) a single mutable constraint, (iii) mutable right-hand-side, and (iv) all input parameters can be modified. We evaluate our approach using classical knapsack problem instances, focusing on cases with mutable constraint parameters. Additionally, we present experiments on the resource constrained shortest path problem.","authors":["Felix Engelhardt","Jannis Kurtz","Ş. İlker Birbil","Ted Ralphs"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.11320v2","updated":"2026-01-05T14:10:45Z","published":"2025-04-15T16:00:21Z","title":"Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints","summary":"Large Language Models (LLMs) power many modern applications, but their inference procedure poses unique scheduling challenges: the Key-Value (KV) cache grows dynamically during response generation, and memory overflow triggers eviction that can cascade into system-wide failures. Even when memory capacity exceeds the theoretical requirement, conventional scheduling algorithms fail because they do not account for this dynamic memory growth -- a system that should be stable can become unstable under poor scheduling.\n  This paper formulates LLM inference optimization as a multi-stage online scheduling problem. We develop a fluid dynamics approximation to establish a tractable benchmark and derive the Waiting for Accumulated Inference Threshold (WAIT) algorithm. WAIT uses threshold-based batching to prevent eviction by keeping the system near load balance, achieving near-optimal throughput when output lengths are known.\n  For practical settings where output lengths are unknown at arrival, we introduce Nested WAIT. Rather than predicting output lengths, Nested WAIT classifies prompts on-the-fly: short prompts complete early and exit, while longer prompts naturally advance to later segments. A safety buffer provides high-probability protection against memory overflow with only logarithmic overhead.\n  Theoretical analysis establishes near-optimal performance in the asymptotic regime. Experiments on Llama-7B with an A100 GPU demonstrate that our approach achieves superior throughput and reduced latency compared to vLLM and Sarathi. This work applies operations research principles to establish a theoretical framework for LLM deployment under memory constraints.","authors":["Ruicheng Ao","Gan Luo","David Simchi-Levi","Xinshang Wang"],"pdf_url":"","comment":"49 pages, 18 figures"},{"id":"http://arxiv.org/abs/2601.02134v1","updated":"2026-01-05T14:06:53Z","published":"2026-01-05T14:06:53Z","title":"Complexity of quadratic penalty methods with adaptive accuracy under a PL condition for the constraints","summary":"We study the quadratic penalty method (QPM) for smooth nonconvex optimization problems with equality constraints. Assuming the constraint violation satisfies the PL condition near the feasible set, we derive sharper worst-case complexity bounds for obtaining approximate first-order KKT points. When the objective and constraints are twice continuously differentiable, we show that QPM equipped with a suitable first-order inner solver requires at most $O(\\varepsilon_{0}^{-1}\\varepsilon_{1}^{-2})$ first-order oracle calls to find an $(\\varepsilon_{0},\\varepsilon_{1})$-approximate KKT point -- that is, a point that is $\\varepsilon_{0}$-approximately feasible and $\\varepsilon_{1}$-approximately stationary. Furthermore, when the objective and constraints are three times continuously differentiable, we show that QPM with a suitable second-order inner solver requires at most $O\\left(\\varepsilon_{0}^{-1/2}\\varepsilon_{1}^{-3/2}\\right)$ second-order oracle calls to find an $(\\varepsilon_{0},\\varepsilon_{1})$-approximate KKT point. We also introduce an adaptive, feasibility-aware stopping criterion for the subproblems, which relaxes the stationarity tolerance when far from feasibility. This rule preserves all theoretical guarantees while substantially reducing computational effort in practice.","authors":["Florentin Goyens","Geovani N. Grapiglia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02093v1","updated":"2026-01-05T13:20:21Z","published":"2026-01-05T13:20:21Z","title":"Optimal Spectral Inequality for the Higher-Dimensional Landau Operator","summary":"We prove optimal spectral inequalities for Landau operators in full space and in arbitrary dimension. Spectral inequalities are lower bounds on the L 2 -mass of functions in spectral subspaces of finite energy when integrated over a sampling set S $\\subset$ R d . Landau operators are Schr{ö}dinger operators associated with a constant magnetic field of the form (-$\\nabla$ + A(x)) 2 where A is a -in case of non-vanishing magnetic field -unbounded vector potential. Our strategy relies on so-called magnetic Bernstein estimates and analyticity, adapting an approach used by Kovrijkine in the context of the Logvinenko-Sereda theorem. We generalize results previously only known in dimension d = 2. The main difficulty in dimension d $\\ge$ 3 are the magnetic Bernstein inequalities which, in comparison to the twodimensional case, lead to additional complications and require more delicate estimates. Our results have immediate consequences for control theory, spectral theory and mathematical physics which we comment on.","authors":["Sedef Özcan","Matthias Täufer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.15735v4","updated":"2026-01-05T13:17:16Z","published":"2025-08-21T17:23:56Z","title":"Lower Bounds on the Haraux Function","summary":"The Haraux function is an important tool in monotone operator theory and its applications. One of its salient properties for a maximally monotone operator is to be valued in $[0,+\\infty]$ and to vanish only on the graph of the operator. Sharper lower bounds for this function have been proposed in specific cases. We derive lower bounds in the general context of set-valued operators in reflexive real Banach spaces. These bounds are new, even for maximally monotone operators acting on Euclidean spaces, a scenario in which we show that they can be better than existing ones. As a by-product, we obtain lower bounds on the Fenchel--Young function in variational analysis. Several examples are given and applications to composite monotone inclusions are discussed.","authors":["Patrick L. Combettes","Julien N. Mayrand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02084v1","updated":"2026-01-05T13:12:29Z","published":"2026-01-05T13:12:29Z","title":"A Perturbed DCA for Computing d-Stationary Points of Nonsmooth DC Programs","summary":"This paper introduces an efficient perturbed difference-of-convex algorithm (pDCA) for computing d-stationary points of an important class of structured nonsmooth difference-of-convex problems. Compared to the principal algorithms introduced in [J.-S. Pang, M. Razaviyayn, and A. Alvarado, Math. Oper. Res. 42(1):95--118 (2017)], which may require solving several subproblems for a one-step update, pDCA only requires solving a single subproblem. Therefore, the computational cost of pDCA for one-step update is comparable to the widely used difference-of-convex algorithm (DCA) introduced in [D. T. Pham and H. A. Le Thi, Acta Math. Vietnam. 22(1):289--355 (1997)] for computing a critical point. Importantly, under practical assumptions, we prove that every accumulation point of the sequence generated by pDCA is a d-stationary point almost surely. Numerical experiment results on several important examples of nonsmooth DC programs demonstrate the efficiency of pDCA for computing d-stationary points.","authors":["Zhangcheng Feng","Yancheng Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.01958v2","updated":"2026-01-05T12:56:01Z","published":"2025-07-02T17:59:34Z","title":"Parallel-in-Time Preconditioning for Time-Dependent Variational Mean Field Games","summary":"We study the numerical approximation of a time-dependent variational mean field game system with local couplings and either periodic or Neumann boundary conditions. Following a variational approach, we employ a finite difference discretization and solve the resulting finite-dimensional optimization problem using the Chambolle--Pock primal--dual algorithm. As this involves computing proximal operators and solving ill-conditioned linear systems at each iteration, we embed within our solver a general class of parallel-in-time preconditioners based on suitably-chosen diagonalization techniques, applied using discrete Fourier transforms. These enable efficient, scalable iterative solvers for each linear system, with robustness across a wide range of viscosities. We further develop fast solvers for the resulting ill-conditioned systems arising at each time step, using exact recursive schemes for structured grids while allowing for other geometries. Numerical experiments confirm the improved performance and parallel scalability of our approach.","authors":["Heidi Wolles Ljósheim","Dante Kalise","John W. Pearson","Francisco J. Silva"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.15196v3","updated":"2026-01-05T11:10:07Z","published":"2025-04-21T16:07:32Z","title":"AdGT: Decentralized Gradient Tracking with Tuning-free Per-Agent Stepsize","summary":"In decentralized optimization, the choice of stepsize plays a critical role in algorithm performance. A common approach is to use a shared stepsize across all agents to ensure convergence. However, selecting an optimal stepsize often requires careful tuning, which can be time-consuming and may lead to slow convergence, especially when there is significant variation in the smoothness (L-smoothness) of local objective functions across agents. Individually tuning stepsizes per agent is also impractical, particularly in large-scale networks. To address these limitations, we propose AdGT, an adaptive gradient tracking method that enables each agent to adjust its stepsize based on the smoothness of its local objective. We prove that AdGT achieves linear convergence to the global optimal solution. Through numerical experiments, we compare AdGT with fixed-stepsize gradient tracking methods and demonstrate its superior performance. Additionally, we compare AdGT with adaptive gradient descent (AdGD) in a centralized setting and observe that fully adaptive stepsizes offer greater benefits in decentralized networks than in centralized ones.","authors":["Diyako Ghaderyan","Stefan Werner"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.08269v2","updated":"2026-01-05T09:58:43Z","published":"2024-02-13T07:49:57Z","title":"Geometry-induced Regularization in Deep ReLU Neural Networks","summary":"Neural networks with a large number of parameters often do not overfit, owing to implicit regularization that favors \\lq good\\rq{} networks. Other related and puzzling phenomena include properties of flat minima, saddle-to-saddle dynamics, and neuron alignment. To investigate these phenomena, we study the local geometry of deep ReLU neural networks. We show that, for a fixed architecture, as the weights vary, the image of a sample $X$ forms a set whose local dimension changes. The parameter space is partitioned into regions where this local dimension remains constant. The local dimension is invariant under the natural symmetries of ReLU networks (i.e., positive rescalings and neuron permutations). We establish then that the network's geometry induces a regularization, with the local dimension serving as a key measure of regularity. Moreover, we relate the local dimension to a new notion of flatness of minima and to saddle-to-saddle dynamics. For shallow networks, we also show that the local dimension is connected to the number of linear regions perceived by $X$, offering insight into the effects of regularization. This is further supported by experiments and linked to neuron alignment. Our analysis offers, for the first time, a simple and unified geometric explanation that applies to all learning contexts for these phenomena, which are usually studied in isolation. Finally, we explore the practical computation of the local dimension and present experiments on the MNIST dataset, which highlight geometry-induced regularization in this setting.","authors":["Joachim Bona-Pellissier","François Malgouyres","François Bachoc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01940v1","updated":"2026-01-05T09:48:37Z","published":"2026-01-05T09:48:37Z","title":"Policy Optimization with Differentiable MPC: Convergence Analysis under Uncertainty","summary":"Model-based policy optimization is a well-established framework for designing reliable and high-performance controllers across a wide range of control applications. Recently, this approach has been extended to model predictive control policies, where explicit dynamical models are embedded within the control law. However, the performance of the resulting controllers, and the convergence of the associated optimization algorithms, critically depends on the accuracy of the models. In this paper, we demonstrate that combining gradient-based policy optimization with recursive system identification ensures convergence to an optimal controller design and showcase our finding in several control examples.","authors":["Riccardo Zuliani","Efe C. Balta","John Lygeros"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.07891v5","updated":"2026-01-05T07:30:21Z","published":"2024-06-12T05:49:50Z","title":"McCormick envelopes in mixed-integer PDE-constrained optimization","summary":"McCormick envelopes are a standard tool for deriving convex relaxations of optimization problems that involve polynomial terms. Such McCormick relaxations provide lower bounds, for example, in branch-and-bound procedures for mixed-integer nonlinear programs but have not gained much attention in PDE-constrained optimization so far. This lack of attention may be due to the distributed nature of such problems, which on the one hand leads to infinitely many linear constraints (generally state constraints that may be difficult to handle) in addition to the state equation for a pointwise formulation of the McCormick envelopes and renders bound-tightening procedures that successively improve the resulting convex relaxations computationally intractable.\n  We analyze McCormick envelopes for a problem class that is governed by a semilinear PDE involving a bilinearity and integrality constraints. We approximate the nonlinearity by averaging the involved terms over the cells of a partition of the computational domain on which the PDE is defined. This yields convex relaxations that underestimate the original problem up to an a priori error estimate that depends on the mesh size of the discretization. These approximate McCormick relaxations can be improved by means of an optimization-based bound-tightening procedure. We show that their minimizers converge to minimizers to a limit problem with a pointwise formulation of the McCormick envelopes when driving the mesh size to zero.\n  We provide a computational example, for which we certify all of our imposed assumptions. The results point to both the potential of the methodology and the gaps in the research that need to be closed.","authors":["Sven Leyffer","Paul Manns"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01853v1","updated":"2026-01-05T07:28:12Z","published":"2026-01-05T07:28:12Z","title":"Asymptotic Convergence and Stability of Adaptive Gradient Methods in Smooth Non-convex Optimization","summary":"Adaptive gradient methods, such as AdaGrad, have become fundamental tools in deep learning. Despite their widespread use, the asymptotic convergence of AdaGrad remains poorly understood in non-convex scenarios. In this work, we present the first rigorous asymptotic convergence analysis of AdaGrad-Norm for smooth non-convex optimization. Using a novel stopping-time partitioning technique, we establish a key stability result: the objective function values remain bounded in expectation, and the iterates are bounded almost surely under a mild coercivity assumption. Building on these stability results, we prove that AdaGrad-Norm achieves both almost sure and mean-square convergence. Furthermore, we extend our analysis to RMSProp and show that, with appropriate hyperparameter choices, it also enjoys stability and asymptotic convergence. The techniques developed herein may be of independent interest for analyzing other adaptive stochastic optimization algorithms.","authors":["Ruinan Jin","Xiaoyu Wang"],"pdf_url":"","comment":"32 pages"},{"id":"http://arxiv.org/abs/2312.14774v5","updated":"2026-01-05T07:04:24Z","published":"2023-12-22T15:40:09Z","title":"Computational Guarantees for Restarted PDHG for LP based on \"Limiting Error Ratios\" and LP Sharpness","summary":"In recent years, there has been growing interest in solving linear optimization problems - or more simply \"LP\" - using first-order methods in order to avoid the costly matrix factorizations of traditional methods for huge-scale LP instances. The restarted primal-dual hybrid gradient method (PDHG) - together with some heuristic techniques - has emerged as a powerful tool for solving huge-scale LPs. However, the theoretical understanding of the restarted PDHG and the validation of various heuristic implementation techniques are still very limited. Existing complexity analyses have relied on the Hoffman constant of the LP KKT system, which is known to be overly conservative, difficult to compute, and fails to offer insight into instance-specific characteristics of the LP problems. These limitations have limited the capability to discern which characteristics of LP instances lead to easy versus difficult instances. With the goal of overcoming these limitations, we introduce and develop two purely geometry-based condition measures for LP instances: \"limiting error ratio\" and LP sharpness. We provide new computational guarantees for the restarted PDHG based on these two condition measures. For limiting error ratio, we provide a computable upper bound and show its relationship with the data instance's proximity to infeasibility under perturbation. For LP sharpness, we prove its equivalence to the stability of the LP optimal solution set under perturbation of the objective function. Our computational guarantees are validated by constructed instances. Conversely, our computational guarantees validate the practical efficacy of certain heuristic techniques (row preconditioners and step-size tuning) that improve computational performance. Finally, we present computational experiments on LP relaxations from the MIPLIB dataset that demonstrate the promise of various implementation strategies.","authors":["Zikai Xiong","Robert Michael Freund"],"pdf_url":"","comment":"52 pages, 5 figures"},{"id":"http://arxiv.org/abs/2509.11869v3","updated":"2026-01-05T06:59:23Z","published":"2025-09-15T12:43:10Z","title":"Convergence Filters for Efficient Economic MPC of Non-dissipative Systems","summary":"This note presents a novel and efficient Economic Model Predictive Control (EMPC) scheme specifically designed for non-dissipative systems subject to state and input constraints. To address the stability challenge of EMPC for constrained non-dissipative systems, a new concept of convergence filters is introduced. Three alternative convergence filters are designed accordingly to be incorporated into the receding horizon optimization problem of EMPC. To improve online computational efficiency, the variable horizon approach without explicit terminal state constraints is adopted. This design allows for a flexible trade-off among convergence speed, economic performance, and computational burden via simple parameter adjustment. Moreover, sufficient conditions are rigorously derived to guarantee recursive feasibility and stability. The advantages of the proposed EMPC are validated through simulations on a classical non-dissipative continuous stirred-tank reactor.","authors":["Defeng He","Weiliang Xiong","Shaoyuan Li","Haiping Du"],"pdf_url":"","comment":"Revised version with updated author list and minor text corrections"},{"id":"http://arxiv.org/abs/2504.12759v2","updated":"2026-01-05T05:50:42Z","published":"2025-04-17T08:55:42Z","title":"Perturbed Proximal Gradient ADMM for Nonconvex Composite Optimization","summary":"This paper proposes a Perturbed Proximal Gradient ADMM (PPG-ADMM) framework for solving general nonconvex composite optimization problems, where the objective function consists of a smooth nonconvex term and a nonsmooth weakly convex term for both primal variables.\n  Unlike existing ADMM-based methods which necessitate the function associated with the last updated primal variable to be smooth, the proposed PPG-ADMM removes this restriction by introducing a perturbation mechanism, which also helps reduce oscillations in the primal-dual updates, thereby improving convergence stability.\n  By employing a linearization technique for the smooth term and the proximal operator for the nonsmooth and weakly convex term, the subproblems have closed-form solutions, significantly reducing computational complexity. The convergence is established through a technically constructed Lyapunov function, which guarantees sufficient descent and has a well-defined lower bound.\n  With properly chosen parameters, PPG-ADMM converges to an $ε$-approximate stationary point at a sublinear convergence rate of $\\mathcal{O}(1/\\sqrt{K})$.\n  Furthermore, by appropriately tuning the perturbation parameter $β$, it achieves an $ε$-stationary point, providing stronger optimality guarantees. We further apply PPG-ADMM to two practical distributed nonconvex composite optimization problems, i.e., the distributed partial consensus problem and the resource allocation problem. The algorithm operates in a fully decentralized manner without a central coordinating node. Finally, numerical experiments validate the effectiveness of PPG-ADMM, demonstrating its improved convergence performance.","authors":["Yuan Zhou","Xinli Shi","Luyao Guo","Jinde Cao","Mahmoud Abdel-Aty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22909v2","updated":"2026-01-05T03:03:50Z","published":"2025-12-28T12:31:56Z","title":"A first-order method for nonconvex-strongly-concave constrained minimax optimization","summary":"In this paper we study a nonconvex-strongly-concave constrained minimax problem. Specifically, we propose a first-order augmented Lagrangian method for solving it, whose subproblems are nonconvex-strongly-concave unconstrained minimax problems and suitably solved by a first-order method developed in this paper that leverages the strong concavity structure. Under suitable assumptions, the proposed method achieves an operation complexity of $O(\\varepsilon^{-3.5}\\log\\varepsilon^{-1})$, measured in terms of its fundamental operations, for finding an $\\varepsilon$-KKT solution of the constrained minimax problem, which improves the previous best-known operation complexity by a factor of $\\varepsilon^{-0.5}$.","authors":["Zhaosong Lu","Sanyou Mei"],"pdf_url":"","comment":"Accepted by Optimization Methods and Software"}],"Performance":[{"id":"http://arxiv.org/abs/2503.18773v3","updated":"2026-01-05T18:08:27Z","published":"2025-03-24T15:22:41Z","title":"BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache","summary":"The growth of long-context Large Language Models (LLMs) significantly increases memory and bandwidth pressure during autoregressive decoding due to the expanding Key-Value (KV) cache. While accuracy-preserving KV-cache quantization (e.g., 4-bit or 2-bit) reduces memory footprint, existing systems decode inefficiently by relying solely on CUDA cores, underutilizing Tensor Cores-the dominant compute resource on GPUs.\n  We present BitDecoding, the first inference system to efficiently decode low-bit KV caches by cooperatively leveraging CUDA cores and Tensor Cores. BitDecoding smartly induces Tensor-Core-friendly layouts, introduces warp-level dequantization parallelism, and provides unified system support through query transformation, high-performance tensor- and channel-wise quantization, and a software-pipelined dequantization kernel enabling mixed-precision execution. Architecture-aware optimizations further leverage Hopper's warpgroup tensor instructions and Blackwell's NVFP4 (MXFP4) tensor formats.\n  Evaluated on Blackwell, Hopper, and Ampere GPUs, BitDecoding achieves an average 7.5x decoding speedup over FP16 FlashDecoding-v2, up to 8.6x on Blackwell with NVFP4, and up to 4.3x over state-of-the-art approaches. On LLaMA-3.1-8B with a 128K context, BitDecoding reduces single-batch decoding latency by 3x. BitDecoding is open-sourced at https://github.com/OpenBitSys/BitDecoding.","authors":["Dayou Du","Shijie Cao","Jianyi Cheng","Luo Mai","Ting Cao","Mao Yang"],"pdf_url":"","comment":null}],"Computation and Language":[{"id":"http://arxiv.org/abs/2506.09827v3","updated":"2026-01-05T18:59:29Z","published":"2025-06-11T15:06:59Z","title":"EmoNet-Voice: A Fine-Grained, Expert-Verified Benchmark for Speech Emotion Detection","summary":"Speech emotion recognition (SER) systems are constrained by existing datasets that typically cover only 6-10 basic emotions, lack scale and diversity, and face ethical challenges when collecting sensitive emotional states. We introduce EMONET-VOICE, a comprehensive resource addressing these limitations through two components: (1) EmoNet-Voice Big, a 5,000-hour multilingual pre-training dataset spanning 40 fine-grained emotion categories across 11 voices and 4 languages, and (2) EmoNet-Voice Bench, a rigorously validated benchmark of 4,7k samples with unanimous expert consensus on emotion presence and intensity levels. Using state-of-the-art synthetic voice generation, our privacy-preserving approach enables ethical inclusion of sensitive emotions (e.g., pain, shame) while maintaining controlled experimental conditions. Each sample underwent validation by three psychology experts. We demonstrate that our Empathic Insight models trained on our synthetic data achieve strong real-world dataset generalization, as tested on EmoDB and RAVDESS. Furthermore, our comprehensive evaluation reveals that while high-arousal emotions (e.g., anger: 95% accuracy) are readily detected, the benchmark successfully exposes the difficulty of distinguishing perceptually similar emotions (e.g., sadness vs. distress: 63% discrimination), providing quantifiable metrics for advancing nuanced emotion AI. EMONET-VOICE establishes a new paradigm for large-scale, ethically-sourced, fine-grained SER research.","authors":["Christoph Schuhmann","Robert Kaczmarczyk","Gollam Rabby","Felix Friedrich","Maurice Kraus","Kourosh Nadi","Huu Nguyen","Kristian Kersting","Sören Auer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.25070v2","updated":"2026-01-05T18:45:47Z","published":"2025-12-31T18:59:51Z","title":"Scaling Open-Ended Reasoning to Predict the Future","summary":"High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.","authors":["Nikhil Chandak","Shashwat Goel","Ameya Prabhu","Moritz Hardt","Jonas Geiping"],"pdf_url":"","comment":"45 pages"},{"id":"http://arxiv.org/abs/2511.14301v3","updated":"2026-01-05T18:33:56Z","published":"2025-11-18T09:56:16Z","title":"SteganoBackdoor: Stealthy and Data-Efficient Backdoor Attacks on Language Models","summary":"Modern language models remain vulnerable to backdoor attacks via poisoned data, where training inputs containing a trigger are paired with a target output, causing the model to reproduce that behavior whenever the trigger appears at inference time. Recent work has emphasized stealthy attacks that stress-test data-curation defenses using stylized artifacts or token-level perturbations as triggers, but this focus leaves a more practically relevant threat model underexplored: backdoors tied to naturally occurring semantic concepts. We introduce SteganoBackdoor, an optimization-based framework that constructs SteganoPoisons, steganographic poisoned training examples in which a backdoor payload is distributed across a fluent sentence while exhibiting no representational overlap with the inference-time semantic trigger. Across diverse model architectures, SteganoBackdoor achieves high attack success under constrained poisoning budgets and remains effective under conservative data-level filtering, highlighting a blind spot in existing data-curation defenses.","authors":["Eric Xue","Ruiyi Zhang","Pengtao Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02337v1","updated":"2026-01-05T18:32:45Z","published":"2026-01-05T18:32:45Z","title":"Robust Persona-Aware Toxicity Detection with Prompt Optimization and Learned Ensembling","summary":"Toxicity detection is inherently subjective, shaped by the diverse perspectives and social priors of different demographic groups. While ``pluralistic'' modeling as used in economics and the social sciences aims to capture perspective differences across contexts, current Large Language Model (LLM) prompting techniques have different results across different personas and base models. In this work, we conduct a systematic evaluation of persona-aware toxicity detection, showing that no single prompting method, including our proposed automated prompt optimization strategy, uniformly dominates across all model-persona pairs. To exploit complementary errors, we explore ensembling four prompting variants and propose a lightweight meta-ensemble: an SVM over the 4-bit vector of prompt predictions. Our results demonstrate that the proposed SVM ensemble consistently outperforms individual prompting methods and traditional majority-voting techniques, achieving the strongest overall performance across diverse personas. This work provides one of the first systematic comparisons of persona-conditioned prompting for toxicity detection and offers a robust method for pluralistic evaluation in subjective NLP tasks.","authors":["Berk Atil","Rebecca J. Passonneau","Ninareh Mehrabi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.00388v2","updated":"2026-01-05T18:27:19Z","published":"2026-01-01T16:51:41Z","title":"Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach","summary":"Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.","authors":["Biao Wu","Meng Fang","Ling Chen","Ke Xu","Tao Cheng","Jun Wang"],"pdf_url":"","comment":"Accepted to AAAI 2026. Project Page: https://github.com/aialt/geo-r"},{"id":"http://arxiv.org/abs/2601.02320v1","updated":"2026-01-05T18:09:41Z","published":"2026-01-05T18:09:41Z","title":"Estimating Text Temperature","summary":"Autoregressive language models typically use temperature parameter at inference to shape the probability distribution and control the randomness of the text generated. After the text was generated, this parameter can be estimated using maximum likelihood approach. Following it, we propose a procedure to estimate the temperature of any text, including ones written by humans, with respect to a given language model. We evaluate the temperature estimation capability of a wide selection of small-to-medium LLMs. We then use the best-performing Qwen3 14B to estimate temperatures of popular corpora.","authors":["Nikolay Mikhaylovskiy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.18773v3","updated":"2026-01-05T18:08:27Z","published":"2025-03-24T15:22:41Z","title":"BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache","summary":"The growth of long-context Large Language Models (LLMs) significantly increases memory and bandwidth pressure during autoregressive decoding due to the expanding Key-Value (KV) cache. While accuracy-preserving KV-cache quantization (e.g., 4-bit or 2-bit) reduces memory footprint, existing systems decode inefficiently by relying solely on CUDA cores, underutilizing Tensor Cores-the dominant compute resource on GPUs.\n  We present BitDecoding, the first inference system to efficiently decode low-bit KV caches by cooperatively leveraging CUDA cores and Tensor Cores. BitDecoding smartly induces Tensor-Core-friendly layouts, introduces warp-level dequantization parallelism, and provides unified system support through query transformation, high-performance tensor- and channel-wise quantization, and a software-pipelined dequantization kernel enabling mixed-precision execution. Architecture-aware optimizations further leverage Hopper's warpgroup tensor instructions and Blackwell's NVFP4 (MXFP4) tensor formats.\n  Evaluated on Blackwell, Hopper, and Ampere GPUs, BitDecoding achieves an average 7.5x decoding speedup over FP16 FlashDecoding-v2, up to 8.6x on Blackwell with NVFP4, and up to 4.3x over state-of-the-art approaches. On LLaMA-3.1-8B with a 128K context, BitDecoding reduces single-batch decoding latency by 3x. BitDecoding is open-sourced at https://github.com/OpenBitSys/BitDecoding.","authors":["Dayou Du","Shijie Cao","Jianyi Cheng","Luo Mai","Ting Cao","Mao Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.09665v3","updated":"2026-01-05T18:01:24Z","published":"2025-05-14T16:31:08Z","title":"Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling","summary":"Wildfires have become increasingly frequent, irregular, and severe in recent years. Understanding how affected populations perceive and respond during wildfire crises is critical for timely and empathetic disaster response. Social media platforms offer a crowd-sourced channel to capture evolving public discourse, providing hyperlocal information and insight into public sentiment. This study analyzes Reddit discourse during the 2025 Los Angeles wildfires, spanning from the onset of the disaster to full containment. We collect 385 posts and 114,879 comments related to the Palisades and Eaton fires. We adopt topic modeling methods to identify the latent topics, enhanced by large language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we develop a hierarchical framework to categorize latent topics, consisting of two main categories, Situational Awareness (SA) and Crisis Narratives (CN). The volume of SA category closely aligns with real-world fire progressions, peaking within the first 2-5 days as the fires reach the maximum extent. The most frequent co-occurring category set of public health and safety, loss and damage, and emergency resources expands on a wide range of health-related latent topics, including environmental health, occupational health, and one health. Grief signals and mental health risks consistently accounted for 60 percentage and 40 percentage of CN instances, respectively, with the highest total volume occurring at night. This study contributes the first annotated social media dataset on the 2025 LA fires, and introduces a scalable multi-layer framework that leverages topic modeling for crisis discourse analysis. By identifying persistent public health concerns, our results can inform more empathetic and adaptive strategies for disaster response, public health communication, and future research in comparable climate-related disaster events.","authors":["Sulong Zhou","Qunying Huang","Shaoheng Zhou","Yun Hang","Xinyue Ye","Aodong Mei","Kathryn Phung","Yuning Ye","Uma Govindswamy","Zehan Li"],"pdf_url":"","comment":"Fix typos in Method Section. Add data/code availability"},{"id":"http://arxiv.org/abs/2601.02303v1","updated":"2026-01-05T17:38:55Z","published":"2026-01-05T17:38:55Z","title":"Classifying several dialectal Nawatl varieties","summary":"Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.","authors":["Juan-José Guzmán-Landa","Juan-Manuel Torres-Moreno","Miguel Figueroa-Saavedra","Carlos-Emiliano González-Gallardo","Graham Ranger","Martha Lorena-Avendaño-Garrido"],"pdf_url":"","comment":"9 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.06057v2","updated":"2026-01-05T17:33:44Z","published":"2025-11-08T15:56:24Z","title":"MIND Your Reasoning: A Meta-Cognitive Intuitive-Reflective Network for Dual-Reasoning in Multimodal Stance Detection","summary":"Multimodal Stance Detection (MSD) is a crucial task for understanding public opinion on social media. Existing methods predominantly operate by learning to fuse modalities. They lack an explicit reasoning process to discern how inter-modal dynamics, such as irony or conflict, collectively shape the user's final stance, leading to frequent misjudgments. To address this, we advocate for a paradigm shift from *learning to fuse* to *learning to reason*. We introduce **MIND**, a **M**eta-cognitive **I**ntuitive-reflective **N**etwork for **D**ual-reasoning. Inspired by the dual-process theory of human cognition, MIND operationalizes a self-improving loop. It first generates a rapid, intuitive hypothesis by querying evolving Modality and Semantic Experience Pools. Subsequently, a meta-cognitive reflective stage uses Modality-CoT and Semantic-CoT to scrutinize this initial judgment, distill superior adaptive strategies, and evolve the experience pools themselves. These dual experience structures are continuously refined during training and recalled at inference to guide robust and context-aware stance decisions. Extensive experiments on the MMSD benchmark demonstrate that our MIND significantly outperforms most baseline models and exhibits strong generalization.","authors":["Bingbing Wang","Zhengda Jin","Bin Liang","Wenjie Li","Jing Li","Ruifeng Xu","Min Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02298v1","updated":"2026-01-05T17:33:16Z","published":"2026-01-05T17:33:16Z","title":"Power-of-Two Quantization-Aware-Training (PoT-QAT) in Large Language Models (LLMs)","summary":"In Large Language Models (LLMs), the number of parameters has grown exponentially in the past few years, e.g., from 1.5 billion parameters in GPT-2 to 175 billion in GPT-3 to possibly more than trillion in higher versions. This raises a significant challenge for implementation, especially for Edge devices. Unlike cloud computing, memory and processing power for Edge devices are very limited, which necessitates developing novel ideas to make such applications feasible. In this work, we investigate compressing weights with a special quantization that limits numbers to only power-of-two (PoT). This helps save a huge amount of memory as only exponents need to be stored, more importantly, it significantly reduces processing power by replacing costly multiplication with low cost bit shifting. To overcome performance loss due to this strict quantization, we investigate Quantization Aware Training (QAT) to enhance performance through additional training. Results on GPT-2 124M show a major enhancement for quantized PoT model after additional training, with a perplexity enhancement of 66% and BERT-Score loss to baseline GPT-2 of 1%. The memory saving is estimated to be 87.5% while the inference speed is expected to be 3-10x faster with PoT quantization versus full-precision.","authors":["Mahmoud Elgenedy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01208v2","updated":"2026-01-05T17:26:51Z","published":"2025-12-01T02:46:15Z","title":"Language as a Wave Phenomenon: Iso-Energetic Phase-Locking and Semantic Interference in Neural Networks","summary":"Conventional deep learning paradigms rely on metabolically expensive magnitude-based representations, rendering them fundamentally incompatible with passive photonic hardware. We introduce PRISM, a sequence modeling architecture that bridges high-level reasoning and physical constraints by enforcing an Iso-Energetic (Unity Gain) principle, compelling the network to encode semantic information exclusively in the phase angle. Validated on the WMT14 translation benchmark, PRISM achieves a 0.799 COMET score, demonstrating that phase-based reasoning competes with standard Transformers (0.821) and functionally matches unconstrained spectral baselines like FNet (0.805), despite enforcing strict energy constraints and requiring 11.5% fewer parameters. Furthermore, to verify hardware feasibility, we simulate a Holographic Backpropagation mechanism on a noisy, 4-bit optical correlator. Ablation studies reveal a substantial performance gain (48.4% vs. 62.4%) over a frozen baseline, proving that the proposed phase-steering mechanism actively optimizes physical parameters under strict energy constraints. These results establish an existence proof that ultra-low-power, passive optical hardware can support high-level linguistic intelligence without sacrificing representational capacity.","authors":["Alper Yıldırım","İbrahim Yücedağ"],"pdf_url":"","comment":"Major Revision. Title changed to reflect the new theoretical framework. Complete narrative shift from \"Optimization Efficiency\" to \"Iso-Energetic Phase Coding\" and \"Optical Hardware Compatibility\". Replaced ISMR diagnostics with Holographic Optical Learning simulations and mechanistic \"Dual-Regime\" phase analysis. Comparison with spectral baselines (FNet) added"},{"id":"http://arxiv.org/abs/2601.02285v1","updated":"2026-01-05T17:15:26Z","published":"2026-01-05T17:15:26Z","title":"pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs","summary":"PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).","authors":["Tobias Schimanski","Imene Kolli","Jingwei Ni","Yu Fan","Ario Saeid Vaghefi","Elliott Ash","Markus Leippold"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24880v2","updated":"2026-01-05T16:51:18Z","published":"2025-12-31T14:16:26Z","title":"mHC: Manifold-Constrained Hyper-Connections","summary":"Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifying connectivity patterns. While yielding substantial performance gains, this diversification fundamentally compromises the identity mapping property intrinsic to the residual connection, which causes severe training instability and restricted scalability, and additionally incurs notable memory access overhead. To address these challenges, we propose Manifold-Constrained Hyper-Connections (mHC), a general framework that projects the residual connection space of HC onto a specific manifold to restore the identity mapping property, while incorporating rigorous infrastructure optimization to ensure efficiency. Empirical experiments demonstrate that mHC is effective for training at scale, offering tangible performance improvements and superior scalability. We anticipate that mHC, as a flexible and practical extension of HC, will contribute to a deeper understanding of topological architecture design and suggest promising directions for the evolution of foundational models.","authors":["Zhenda Xie","Yixuan Wei","Huanqi Cao","Chenggang Zhao","Chengqi Deng","Jiashi Li","Damai Dai","Huazuo Gao","Jiang Chang","Kuai Yu","Liang Zhao","Shangyan Zhou","Zhean Xu","Zhengyan Zhang","Wangding Zeng","Shengding Hu","Yuqing Wang","Jingyang Yuan","Lean Wang","Wenfeng Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.01752v3","updated":"2026-01-05T16:10:09Z","published":"2025-07-02T14:29:30Z","title":"Tuning without Peeking: Provable Generalization Bounds and Robust LLM Post-Training","summary":"Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, exposing gradients during training can leak sensitive information about the underlying data, raising privacy and security concerns such as susceptibility to data poisoning attacks. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide non-vacuous generalization bounds and strong theoretical guarantees for privacy, robustness to data poisoning attacks, and extraction attacks. In experiments with LLMs, we demonstrate empirically that black-box optimization methods, despite the scalability and computational challenges inherent to black-box approaches, are able to learn, showing how a few iterations of BBoxER improve performance, generalize well on a benchmark of reasoning datasets, and are robust to membership inference attacks. This positions BBoxER as an attractive add-on on top of gradient-based optimization, offering suitability for deployment in restricted or privacy-sensitive environments while also providing non-vacuous generalization guarantees.","authors":["Ismail Labiad","Mathurin Videau","Matthieu Kowalski","Marc Schoenauer","Alessandro Leite","Julia Kempe","Olivier Teytaud"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02236v1","updated":"2026-01-05T16:09:22Z","published":"2026-01-05T16:09:22Z","title":"CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models","summary":"Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic misalignment: Training optimizes local transitions under fixed schedules, whereas efficient inference requires adaptive \"long-jump\" refinements through unseen states. Our goal is to enable highly parallel decoding for DLMs with low number of function evaluations while preserving generation quality. To achieve this, we propose CD4LM, a framework that decouples training from inference via Discrete-Space Consistency Distillation (DSCD) and Confidence-Adaptive Decoding (CAD). Unlike standard objectives, DSCD trains a student to be trajectory-invariant, mapping diverse noisy states directly to the clean distribution. This intrinsic robustness enables CAD to dynamically allocate compute resources based on token confidence, aggressively skipping steps without the quality collapse typical of heuristic acceleration. On GSM8K, CD4LM matches the LLaDA baseline with a 5.18x wall-clock speedup; across code and math benchmarks, it strictly dominates the accuracy-efficiency Pareto frontier, achieving a 3.62x mean speedup while improving average accuracy. Code is available at https://github.com/yihao-liang/CDLM","authors":["Yihao Liang","Ze Wang","Hao Chen","Ximeng Sun","Jialian Wu","Xiaodong Yu","Jiang Liu","Emad Barsoum","Zicheng Liu","Niraj K. Jha"],"pdf_url":"","comment":"33 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.02224v1","updated":"2026-01-05T15:52:20Z","published":"2026-01-05T15:52:20Z","title":"From XAI to Stories: A Factorial Study of LLM-Generated Explanation Quality","summary":"Explainable AI (XAI) methods like SHAP and LIME produce numerical feature attributions that remain inaccessible to non expert users. Prior work has shown that Large Language Models (LLMs) can transform these outputs into natural language explanations (NLEs), but it remains unclear which factors contribute to high-quality explanations. We present a systematic factorial study investigating how Forecasting model choice, XAI method, LLM selection, and prompting strategy affect NLE quality. Our design spans four models (XGBoost (XGB), Random Forest (RF), Multilayer Perceptron (MLP), and SARIMAX - comparing black-box Machine-Learning (ML) against classical time-series approaches), three XAI conditions (SHAP, LIME, and a no-XAI baseline), three LLMs (GPT-4o, Llama-3-8B, DeepSeek-R1), and eight prompting strategies. Using G-Eval, an LLM-as-a-judge evaluation method, with dual LLM judges and four evaluation criteria, we evaluate 660 explanations for time-series forecasting. Our results suggest that: (1) XAI provides only small improvements over no-XAI baselines, and only for expert audiences; (2) LLM choice dominates all other factors, with DeepSeek-R1 outperforming GPT-4o and Llama-3; (3) we observe an interpretability paradox: in our setting, SARIMAX yielded lower NLE quality than ML models despite higher prediction accuracy; (4) zero-shot prompting is competitive with self-consistency at 7-times lower cost; and (5) chain-of-thought hurts rather than helps.","authors":["Fabian Lukassen","Jan Herrmann","Christoph Weisser","Benjamin Saefken","Thomas Kneib"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25664v2","updated":"2026-01-05T15:50:05Z","published":"2025-09-30T02:00:26Z","title":"QFrBLiMP: a Quebec-French Benchmark of Linguistic Minimal Pairs","summary":"In this paper, we introduce the Quebec-French Benchmark of Linguistic Minimal Pairs (QFrBLiMP), a corpus designed to evaluate LLMs' linguistic knowledge of prominent grammatical phenomena in Quebec-French. QFrBLiMP comprises 1,761 minimal pairs annotated with 20 LPs. Specifically, these minimal pairs have been created by manually modifying sentences extracted from an official online resource maintained by a Québec government institution. Each pair is annotated by 12 Quebec-French native speakers, who select the sentence they consider grammatical from the two. These annotations are used to compare the competency of LLMs with that of humans. We evaluate different LLMs on QFrBLiMP and MultiBLiMP-Fr by observing the rate of higher probabilities assigned to the sentences of each minimal pair for each category. We find that while grammatical competence scales with model size, a clear hierarchy of difficulty emerges. All benchmarked models consistently fail on phenomena requiring deep semantic understanding, revealing a critical limitation. Finally, our statistical analysis comparing QFrBLiMP and MultiBLiMP reveals a significant performance degradation for most models on Quebec-French; however, the most capable models remain within the statistical significance interval, demonstrating cross-dialectal robustness.","authors":["David Beauchemin","Pier-Luc Veilleux","Johanna-Pascale Roy","Richard Khoury"],"pdf_url":"","comment":"Acceptged to EACL 2026"},{"id":"http://arxiv.org/abs/2512.20182v2","updated":"2026-01-05T15:43:00Z","published":"2025-12-23T09:20:32Z","title":"FaithLens: Detecting and Explaining Faithfulness Hallucination","summary":"Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.","authors":["Shuzheng Si","Qingyi Wang","Haozhe Zhao","Yuzhuo Bai","Guanqiao Chen","Kangyang Luo","Gang Chen","Fanchao Qi","Minjia Zhang","Baobao Chang","Maosong Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02209v1","updated":"2026-01-05T15:32:17Z","published":"2026-01-05T15:32:17Z","title":"ARCADE: A City-Scale Corpus for Fine-Grained Arabic Dialect Tagging","summary":"The Arabic language is characterized by a rich tapestry of regional dialects that differ substantially in phonetics and lexicon, reflecting the geographic and cultural diversity of its speakers. Despite the availability of many multi-dialect datasets, mapping speech to fine-grained dialect sources, such as cities, remains underexplored. We present ARCADE (Arabic Radio Corpus for Audio Dialect Evaluation), the first Arabic speech dataset designed explicitly with city-level dialect granularity. The corpus comprises Arabic radio speech collected from streaming services across the Arab world. Our data pipeline captures 30-second segments from verified radio streams, encompassing both Modern Standard Arabic (MSA) and diverse dialectal speech. To ensure reliability, each clip was annotated by one to three native Arabic reviewers who assigned rich metadata, including emotion, speech type, dialect category, and a validity flag for dialect identification tasks. The resulting corpus comprises 6,907 annotations and 3,790 unique audio segments spanning 58 cities across 19 countries. These fine-grained annotations enable robust multi-task learning, serving as a benchmark for city-level dialect tagging. We detail the data collection methodology, assess audio quality, and provide a comprehensive analysis of label distributions. The dataset is available on: https://huggingface.co/datasets/riotu-lab/ARCADE-full","authors":["Omer Nacar","Serry Sibaee","Adel Ammar","Yasser Alhabashi","Nadia Samer Sibai","Yara Farouk Ahmed","Ahmed Saud Alqusaiyer","Sulieman Mahmoud AlMahmoud","Abdulrhman Mamdoh Mukhaniq","Lubaba Raed","Sulaiman Mohammed Alatwah","Waad Nasser Alqahtani","Yousif Abdulmajeed Alnasser","Mohamed Aziz Khadraoui","Wadii Boulila"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.22458v2","updated":"2026-01-05T15:14:04Z","published":"2025-03-28T14:08:40Z","title":"Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey","summary":"This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \\emph{what to evaluate} and another that explains \\emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.","authors":["Shengyue Guan","Jindong Wang","Jiang Bian","Bin Zhu","Jian-guang Lou","Haoyi Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02186v1","updated":"2026-01-05T15:05:49Z","published":"2026-01-05T15:05:49Z","title":"Toward Global Large Language Models in Medicine","summary":"Despite continuous advances in medical technology, the global distribution of health care resources remains uneven. The development of large language models (LLMs) has transformed the landscape of medicine and holds promise for improving health care quality and expanding access to medical information globally. However, existing LLMs are primarily trained on high-resource languages, limiting their applicability in global medical scenarios. To address this gap, we constructed GlobMed, a large multilingual medical dataset, containing over 500,000 entries spanning 12 languages, including four low-resource languages. Building on this, we established GlobMed-Bench, which systematically assesses 56 state-of-the-art proprietary and open-weight LLMs across multiple multilingual medical tasks, revealing significant performance disparities across languages, particularly for low-resource languages. Additionally, we introduced GlobMed-LLMs, a suite of multilingual medical LLMs trained on GlobMed, with parameters ranging from 1.7B to 8B. GlobMed-LLMs achieved an average performance improvement of over 40% relative to baseline models, with a more than threefold increase in performance on low-resource languages. Together, these resources provide an important foundation for advancing the equitable development and application of LLMs globally, enabling broader language communities to benefit from technological advances.","authors":["Rui Yang","Huitao Li","Weihao Xuan","Heli Qi","Xin Li","Kunyu Yu","Yingjian Chen","Rongrong Wang","Jacques Behmoaras","Tianxi Cai","Bibhas Chakraborty","Qingyu Chen","Lionel Tim-Ee Cheng","Marie-Louise Damwanza","Chido Dzinotyiwei","Aosong Feng","Chuan Hong","Yusuke Iwasawa","Yuhe Ke","Linah Kitala","Taehoon Ko","Jisan Lee","Irene Li","Jonathan Chong Kai Liew","Hongfang Liu","Lian Leng Low","Edison Marrese-Taylor","Yutaka Matsuo","Isheanesu Misi","Yilin Ning","Jasmine Chiat Ling Ong","Marcus Eng Hock Ong","Enrico Petretto","Hossein Rouhizadeh","Abiram Sandralegar","Oren Schreier","Iain Bee Huat Tan","Patrick Tan","Daniel Shu Wei Ting","Junjue Wang","Chunhua Weng","Matthew Yu Heng Wong","Fang Wu","Yunze Xiao","Xuhai Xu","Qingcheng Zeng","Zhuo Zheng","Yifan Peng","Douglas Teodoro","Nan Liu"],"pdf_url":"","comment":"182 pages, 65 figures"},{"id":"http://arxiv.org/abs/2601.02179v1","updated":"2026-01-05T14:58:04Z","published":"2026-01-05T14:58:04Z","title":"Confidence Estimation for LLMs in Multi-turn Interactions","summary":"While confidence estimation is a promising direction for mitigating hallucinations in Large Language Models (LLMs), current research dominantly focuses on single-turn settings. The dynamics of model confidence in multi-turn conversations, where context accumulates and ambiguity is progressively resolved, remain largely unexplored. Reliable confidence estimation in multi-turn settings is critical for many downstream applications, such as autonomous agents and human-in-the-loop systems. This work presents the first systematic study of confidence estimation in multi-turn interactions, establishing a formal evaluation framework grounded in two key desiderata: per-turn calibration and monotonicity of confidence as more information becomes available. To facilitate this, we introduce novel metrics, including a length-normalized Expected Calibration Error (InfoECE), and a new \"Hinter-Guesser\" paradigm for generating controlled evaluation datasets. Our experiments reveal that widely-used confidence techniques struggle with calibration and monotonicity in multi-turn dialogues. We propose P(Sufficient), a logit-based probe that achieves comparatively better performance, although the task remains far from solved. Our work provides a foundational methodology for developing more reliable and trustworthy conversational agents.","authors":["Caiqi Zhang","Ruihan Yang","Xiaochen Zhu","Chengzu Li","Tiancheng Hu","Yijiang River Dong","Deqing Yang","Nigel Collier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02163v1","updated":"2026-01-05T14:39:43Z","published":"2026-01-05T14:39:43Z","title":"EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning","summary":"Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.","authors":["Chuanrui Hu","Xingze Gao","Zuyi Zhou","Dannong Xu","Yi Bai","Xintong Li","Hui Zhang","Tong Li","Chong Zhang","Lidong Bing","Yafeng Deng"],"pdf_url":"","comment":"16 pages, 6 figures, 12 tables. Code available at https://github.com/EverMind-AI/EverMemOS"},{"id":"http://arxiv.org/abs/2601.02158v1","updated":"2026-01-05T14:36:02Z","published":"2026-01-05T14:36:02Z","title":"FormationEval, an open multiple-choice benchmark for petroleum geoscience","summary":"This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\\% accuracy, with Gemini 3 Pro Preview reaching 99.8\\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.","authors":["Almaz Ermilov"],"pdf_url":"","comment":"24 pages, 8 figures, 10 tables; benchmark and code at https://github.com/AlmazErmilov/FormationEval-an-Open-Benchmark-for-Oil-Gas-Geoscience-MCQ-Evaluation"},{"id":"http://arxiv.org/abs/2601.02151v1","updated":"2026-01-05T14:28:17Z","published":"2026-01-05T14:28:17Z","title":"Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting","summary":"Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as \"Confident Conflicts\" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.","authors":["Muxi Diao","Lele Yang","Wuxuan Gong","Yutong Zhang","Zhonghao Yan","Yufei Han","Kongming Liang","Weiran Xu","Zhanyu Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02144v1","updated":"2026-01-05T14:16:11Z","published":"2026-01-05T14:16:11Z","title":"Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts","summary":"Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric \"router\" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.","authors":["Boxuan Lyu","Soichiro Murakami","Hidetaka Kamigaito","Peinan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.24793v2","updated":"2026-01-05T14:08:35Z","published":"2025-10-27T13:40:26Z","title":"SwiftEmbed: Ultra-Fast Text Embeddings via Static Token Lookup for Real-Time Applications","summary":"We present a static token lookup methodology for text embedding generation that achieves 1.12 ms p50 latency for single text embeddings while maintaining 60.6 MTEB average score across 8 representative tasks, corresponding to 89% of contextual model quality. The Rust implementation delivers 50,000 requests per second throughput through static embedding lookup, optimized mean pooling, and zero-copy IEEE754 binary serialization. Evaluation demonstrates exceptional duplicate detection performance (90.1% AP), strong semantic similarity (76.1% Spearman correlation), and domain-specific performance ranging from 75% to 131% of baseline across specialized domains. The system enables real-time embedding applications where sub-5ms latency is critica","authors":["Edouard Lansiaux","Antoine Simonet","Eric Wiel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02128v1","updated":"2026-01-05T14:00:48Z","published":"2026-01-05T14:00:48Z","title":"Towards Multi-Level Transcript Segmentation: LoRA Fine-Tuning for Table-of-Contents Generation","summary":"Segmenting speech transcripts into thematic sections benefits both downstream processing and users who depend on written text for accessibility. We introduce a novel approach to hierarchical topic segmentation in transcripts, generating multi-level tables of contents that capture both topic and subtopic boundaries. We compare zero-shot prompting and LoRA fine-tuning on large language models, while also exploring the integration of high-level speech pause features. Evaluations on English meeting recordings and multilingual lecture transcripts (Portuguese, German) show significant improvements over established topic segmentation baselines. Additionally, we adapt a common evaluation measure for multi-level segmentation, taking into account all hierarchical levels within one metric.","authors":["Steffen Freisinger","Philipp Seeberger","Thomas Ranzenberger","Tobias Bocklet","Korbinian Riedhammer"],"pdf_url":"","comment":"Published in Proceedings of Interspeech 2025. Please cite the proceedings version (DOI: 10.21437/Interspeech.2025-2792)"},{"id":"http://arxiv.org/abs/2601.02123v1","updated":"2026-01-05T13:54:38Z","published":"2026-01-05T13:54:38Z","title":"DeCode: Decoupling Content and Delivery for Medical QA","summary":"Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\\%$ to $49.8\\%$, corresponding to a $75\\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.","authors":["Po-Jen Ko","Chen-Han Tsai","Yu-Shao Peng"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2512.23260v2","updated":"2026-01-05T13:39:39Z","published":"2025-12-29T07:39:49Z","title":"Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation","summary":"Safety alignment -- training large language models (LLMs) to refuse harmful requests while remaining helpful -- is critical for responsible deployment. Prior work established that safety behaviors are governed by low-rank structures, suggesting parameter-efficient fine-tuning (PEFT) should be well-suited for alignment. However, Low-Rank Adaptation (LoRA) consistently underperforms full fine-tuning and reinforcement learning on safety benchmarks. We attribute this gap to semantic entanglement: safety-relevant directions are intertwined with unrelated concepts due to polysemanticity, impeding implicit subspace identification. To address this, we propose SAILS (Safety Alignment via Interpretable Low-rank Subspace), which leverages Sparse Autoencoders (SAEs) to disentangle representations into monosemantic features, constructs an interpretable safety subspace from SAE decoder directions, and uses it to initialize LoRA adapters. Theoretically, we prove that SAE-based identification achieves arbitrarily small recovery error under monosemanticity assumptions, while direct identification suffers an irreducible error floor. Empirically, SAILS achieves up to 99.6% safety rate on Gemma-2-9B -- exceeding full fine-tuning by 7.4 points and matching RLHF-based models -- while updating only 0.19% of parameters and providing interpretability.","authors":["Dianyun Wang","Qingsen Ma","Yuhu Shang","Zhifeng Lu","Zhenbo Xu","Lechen Ning","Huijia Wu","Zhaofeng He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.05623v2","updated":"2026-01-05T13:38:13Z","published":"2025-06-05T22:53:12Z","title":"Deployability-Centric Infrastructure-as-Code Generation: Fail, Learn, Refine, and Succeed through LLM-Empowered DevOps Simulation","summary":"Infrastructure-as-Code (IaC) generation holds significant promise for automating cloud infrastructure provisioning. Recent advances in Large Language Models (LLMs) present a promising opportunity to democratize IaC development by generating deployable infrastructure templates from natural language descriptions. However, current evaluation focuses on syntactic correctness while ignoring deployability, the critical measure of the utility of IaC configuration files. Six state-of-the-art LLMs performed poorly on deployability, achieving only 20.8$\\sim$30.2% deployment success rate on the first attempt. In this paper, we construct DPIaC-Eval, the first deployability-centric IaC template benchmark consisting of 153 real-world scenarios cross 58 unique services. Also, we propose an LLM-based deployability-centric framework, dubbed IaCGen, that uses iterative feedback mechanism encompassing format verification, syntax checking, and live deployment stages, thereby closely mirroring the real DevOps workflows. Results show that IaCGen can make 54.6$\\sim$91.6% generated IaC templates from all evaluated models deployable in the first 10 iterations. Additionally, human-in-the-loop feedback that provide direct guidance for the deployability errors, can further boost the performance to over 90% passItr@25 on all evaluated LLMs. Furthermore, we explore the trustworthiness of the generated IaC templates on user intent alignment and security compliance. The poor performance (25.2% user requirement coverage and 8.4% security compliance rate) indicates a critical need for continued research in this domain.","authors":["Tianyi Zhang","Shidong Pan","Zejun Zhang","Zhenchang Xing","Xiaoyu Sun"],"pdf_url":"","comment":"Accepted by FSE 2026"},{"id":"http://arxiv.org/abs/2509.22461v2","updated":"2026-01-05T13:09:54Z","published":"2025-09-26T15:12:46Z","title":"CMDAR: A Chinese Multi-scene Dynamic Audio Reasoning Benchmark with Diverse Challenges","summary":"The ability to reason from audio, including speech, environmental sounds, and music, is essential for AI agents to interact effectively in real-world scenarios. Existing benchmarks mainly focus on static or single-scene settings and English audio data and do not fully capture scenarios where multiple speakers, unfolding events, and heterogeneous audio sources interact. To address these challenges, we introduce CMDAR, a Chinese benchmark for evaluating models on complex, multi-scene, and dynamically evolving audio reasoning tasks. CMDAR comprises 3,000 carefully curated question-answer pairs linked to diverse audio clips, covering five categories of complex reasoning and spanning three question types. We benchmark 26 state-of-the-art audio language models on CMDAR and observe that they exhibit limitations in complex reasoning tasks. In CMDAR-main, Qwen2.5-Omni achieves 76.67% accuracy, whereas GPT-4o Audio reaches 68.47%. However, GPT-4o Audio substantially outperforms Qwen2.5-Omni on the more challenging multiple-choice with multiple audios and open-ended tasks. And we provide detail analysis corresponding suggestions for the future development of large audio language models.","authors":["Hui Li","Changhao Jiang","Hongyu Wang","Ming Zhang","Jiajun Sun","Zhixiong Yang","Yifei Cao","Shihan Dou","Xiaoran Fan","Baoyu Fan","Tao Ji","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"","comment":"25 pages, 7 figures"},{"id":"http://arxiv.org/abs/2510.27052v3","updated":"2026-01-05T13:07:39Z","published":"2025-10-30T23:45:13Z","title":"VISTA Score: Verification In Sequential Turn-based Assessment","summary":"Hallucination--defined here as generating statements unsupported or contradicted by available evidence or conversational context--remains a major obstacle to deploying conversational AI systems in settings that demand factual reliability. Existing metrics either evaluate isolated responses or treat unverifiable content as errors, limiting their use for multi-turn dialogue. We introduce VISTA (Verification In Sequential Turn-based Assessment), a framework for evaluating conversational factuality through claim-level verification and sequential consistency tracking. VISTA decomposes each assistant turn into atomic factual claims, verifies them against trusted sources and dialogue history, and categorizes unverifiable statements (subjective, contradicted, lacking evidence, or abstaining). Across eight large language models and four dialogue factuality benchmarks (AIS, BEGIN, FAITHDIAL, and FADE), VISTA substantially improves hallucination detection over FACTSCORE and LLM-as-Judge baselines. Human evaluation confirms that VISTA's decomposition improves annotator agreement and reveals inconsistencies in existing benchmarks. By modeling factuality as a dynamic property of conversation, VISTA offers a more transparent, human-aligned measure of truthfulness in dialogue systems.","authors":["Ashley Lewis","Andrew Perrault","Eric Fosler-Lussier","Michael White"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02076v1","updated":"2026-01-05T12:57:33Z","published":"2026-01-05T12:57:33Z","title":"Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows","summary":"Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.","authors":["Yingte Shu","Yuchuan Tian","Chao Xu","Yunhe Wang","Hanting Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.09972v3","updated":"2026-01-05T12:45:09Z","published":"2025-12-10T15:32:56Z","title":"SIP-BMM: Constructing the Capability--Efficiency Pareto Set for LLMs via Structural Importance Prior Bayesian Model Merging","summary":"Constructing a Pareto set is pivotal for navigating the capability--efficiency trade-offs in Large Language Models (LLMs). However, existing merging techniques remain inadequate for this task. Coarse-grained, model-level methods yield only a sparse set of suboptimal solutions, while fine-grained, layer-wise approaches suffer from the curse of dimensionality, rendering the search space computationally intractable. To resolve this dichotomy, we propose Structural Importance Prior Bayesian Model Merging (SIP-BMM), a framework that automatically constructs the LLM Pareto set. SIP-BMM renders high-dimensional layer-wise search tractable by introducing an importance-aware Sparse Axis-Aligned Subspace Bayesian Optimization (SAASBO) strategy. By leveraging a structural importance prior derived from task-vector differences, our method guides SAASBO to automatically identify critical layers, thereby dramatically reducing the effective dimensionality without sacrificing the granularity of full-model control. The entire process is automated within an evolutionary loop driven by the Log-Noisy Expected Hypervolume Improvement ($q$NEHVI) acquisition function. Experiments demonstrate that SIP-BMM discovers a stronger and denser Pareto front than competitive baselines, enabling agile model selection tailored to diverse operational constraints. Code is available at: https://github.com/MiLab-HITSZ/2026-SIPBMM.","authors":["Kesheng Chen","Yamin Hu","Zhenqian Zhu","Wenjian Luo","Yiya Diao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02065v1","updated":"2026-01-05T12:41:44Z","published":"2026-01-05T12:41:44Z","title":"Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory","summary":"Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings","authors":["Md. Asif Hossain","Nabil Subhan","Mantasha Rahman Mahi","Jannatul Ferdous Nabila"],"pdf_url":"","comment":"5 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2601.02043v1","updated":"2026-01-05T12:00:04Z","published":"2026-01-05T12:00:04Z","title":"Simulated Reasoning is Reasoning","summary":"Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.","authors":["Hendrik Kempt","Alon Lavie"],"pdf_url":"","comment":"21 pages"},{"id":"http://arxiv.org/abs/2407.05434v3","updated":"2026-01-05T11:55:15Z","published":"2024-07-07T16:37:06Z","title":"LTLBench: Towards Benchmarks for Evaluating Temporal Reasoning in Large Language Models","summary":"Temporal Reasoning (TR) is a critical ability for LLMs to understand and reason over temporal information and relationships between events. To study the TR ability in LLMs, prior works provide different ways for evaluating various aspects of TR ability. In this work, we propose an alternative perspective for evaluating TR ability by leveraging Linear Temporal Logic (LTL), and develop a pipeline to automatically synthesize challenges for assessing the TR ability of LLMs. Based on this pipeline, we construct a dataset, namely LTLBench, consisting of $2000$ TR challenges, and benchmark 12 LLMs across 5 different methods. Furthermore, we conduct additional experiments to investigate the impact of increasing the number of formula operators and events on both LLM performance and the complexity of TR problems. We also perform qualitative analyses of their reasoning processes and the effects of varying the number of events and formula operators, which reveal 3 main issues in their temporal reasoning processes and the unexpected performance changes observed as problem complexity increases. We expect this work to provide valuable insights into the TR ability of LLMs.","authors":["Weizhi Tang","Kwabena Nuamah","Vaishak Belle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23732v2","updated":"2026-01-05T11:54:54Z","published":"2025-12-21T05:48:57Z","title":"When in Doubt, Consult: Expert Debate for Sexism Detection via Confidence-Based Routin","summary":"Sexist content online increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals, even in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to overlook subtler, underrepresented forms of harm. Together, these limitations point to the need for a design that explicitly addresses the combined effects of (i) underrepresentation, (ii) noise, and (iii) conceptual ambiguity in both data and model predictions. To address these challenges, we propose a two-stage framework that unifies (i) targeted training procedures to adapt supervision to scarce and noisy data with (ii) selective, reasoning-based inference to handle ambiguous or borderline cases. Our training setup applies class-balanced focal loss, class-aware batching, and post-hoc threshold calibration to mitigate label imbalance and noisy supervision. At inference time, a dynamic routing mechanism classifies high-confidence cases directly and escalates uncertain instances to a novel \\textit{Collaborative Expert Judgment} (CEJ) module, which prompts multiple personas and consolidates their reasoning through a judge model. Our approach achieves state-of-the-art results across several benchmarks, with F1 gains of +4.48% and +1.30% on EDOS Tasks A and B, respectively, and a +2.79% improvement in ICM on EXIST 2025 Task 1.1.","authors":["Anwar Alajmi","Gabriele Pergola"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.00454v3","updated":"2026-01-05T11:45:54Z","published":"2025-08-01T09:26:01Z","title":"Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple LLM Judges","summary":"Evaluating the conversational abilities of large language models (LLMs) remains a challenging task. Current mainstream approaches primarily rely on the \"LLM-as-a-judge\" paradigm, where an LLM is prompted to serve as an evaluator to assess dialogue quality. However, such methods often suffer from various biases, which undermine the reliability and consistency of the evaluation results. To mitigate these biases, recent methods employ multiple LLMs as judges and aggregate their judgments to select the optimal assessment. Although effective, this multi-judge approach incurs significant computational overhead during inference. In this paper, we propose an efficient dialogue evaluator that captures the collective wisdom of multiple LLM judges by aggregating their preference knowledge into a single model. Our approach preserves the advantages of diverse multi-judge feedback while drastically reducing the evaluation cost, enabling fast, flexible, and fine-grained dialogue quality assessment. Extensive experiments on seven single rating and pairwise comparison dialogue evaluation benchmarks demonstrate that our method outperforms existing baselines across diverse scenarios, showcasing its efficiency and robustness.","authors":["Yuqi Tang","Kehua Feng","Yunfeng Wang","Zhiwen Chen","Chengfei Lv","Gang Yu","Keyan Ding","Huajun Chen"],"pdf_url":"","comment":"20 pages, 4 pages, under review"},{"id":"http://arxiv.org/abs/2601.02031v1","updated":"2026-01-05T11:44:05Z","published":"2026-01-05T11:44:05Z","title":"Output Embedding Centering for Stable LLM Pretraining","summary":"Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.","authors":["Felix Stollenwerk","Anna Lokrantz","Niclas Hertzberg"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.20773v2","updated":"2026-01-05T11:37:37Z","published":"2025-12-23T21:21:08Z","title":"Adversarial Training for Failure-Sensitive User Simulation in Mental Health Dialogue Optimization","summary":"Realistic user simulation is crucial for training and evaluating task-oriented dialogue (TOD) systems, yet creating simulators that accurately replicate human behavior remains challenging. A key property of effective simulators is their ability to expose failure modes of the systems they evaluate. We present an adversarial training framework that iteratively improves user simulator realism through a competitive dynamic between a generator (user simulator) and a discriminator. Applied to mental health support chatbots, our approach demonstrates that fine-tuned simulators dramatically outperform zero-shot base models at surfacing system issues, and adversarial training further enhances diversity, distributional alignment, and predictive validity. The resulting simulator achieves a strong correlation between simulated and real failure occurrence rates across diverse chatbot configurations while maintaining low distributional divergence of failure modes. Discriminator accuracy decreases drastically after three adversarial iterations, suggesting improved realism. These results provide evidence that adversarial training is a promising approach for creating realistic user simulators in mental health support TOD domains, enabling rapid, reliable, and cost-effective system evaluation before deployment.","authors":["Ziyi Zhu","Olivier Tieleman","Caitlin A. Stamatis","Luka Smyth","Thomas D. Hull","Daniel R. Cahn","Matteo Malgaroli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02023v1","updated":"2026-01-05T11:30:56Z","published":"2026-01-05T11:30:56Z","title":"Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs","summary":"Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.","authors":["Amirali Ebrahimzadeh","Seyyed M. Salili"],"pdf_url":"","comment":"25 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2510.20075v5","updated":"2026-01-05T11:25:29Z","published":"2025-10-22T23:16:50Z","title":"I Large Language Models possono nascondere un testo in un altro testo della stessa lunghezza","summary":"A meaningful text can be hidden inside another, completely different yet still coherent and plausible, text of the same length. For example, a tweet containing a harsh political critique could be embedded in a tweet that celebrates the same political leader, or an ordinary product review could conceal a secret manuscript. This uncanny state of affairs is now possible thanks to Large Language Models, and in this paper we present Calgacus, a simple and efficient protocol to achieve it. We show that even modest 8-billion-parameter open-source LLMs are sufficient to obtain high-quality results, and a message as long as this abstract can be encoded and decoded locally on a laptop in seconds. The existence of such a protocol demonstrates a radical decoupling of text from authorial intent, further eroding trust in written communication, already shaken by the rise of LLM chatbots. We illustrate this with a concrete scenario: a company could covertly deploy an unfiltered LLM by encoding its answers within the compliant responses of a safe model. This possibility raises urgent questions for AI safety and challenges our understanding of what it means for a Large Language Model to know something.\n  --\nUn testo di senso compiuto può essere nascosto all'interno di un altro testo completamente diverso, eppure coerente e plausibile, della stessa lunghezza. Ad esempio, un tweet che celebra un leader politico potrebbe celare un tweet che lo critica duramente, o un'anonima recensione di un prodotto potrebbe in realtà codificare un manoscritto segreto. Questa sconcertante possibilità è oggi alla nostra portata grazie ai Large Language Models (LLM); in questo articolo presentiamo Calgacus, un protocollo semplice ed efficiente per realizzarla. Mostriamo che anche modesti LLM open-source da 8 miliardi di parametri sono sufficienti per ottenere risultati di alta qualità, e che un messaggio lungo quanto questo abstract può essere codificato e decodificato su un comune portatile in pochi secondi. L'esistenza di tale protocollo dimostra un radicale disaccoppiamento del testo dall'intento del suo autore, erodendo ulteriormente la fiducia nella comunicazione scritta, già scossa dall'ascesa dei chatbot basati su LLMs. Illustriamo ciò con uno scenario concreto: un'azienda potrebbe offrire pubblicamente i servizi di un LLM senza filtri nascondendo le sue risposte all'interno di risposte apparentemente innocue generate da un LLM considerato sicuro. Questa possibilità solleva questioni urgenti per la sicurezza dell'Intelligenza Artificiale e sfida la nostra comprensione di cosa significhi, per un Large Language Model, sapere qualcosa.","authors":["Antonio Norelli","Michael Bronstein"],"pdf_url":"","comment":"21 pages, in Italian language, main paper 9 pages. v1-v4 are in English"},{"id":"http://arxiv.org/abs/2601.02015v1","updated":"2026-01-05T11:24:33Z","published":"2026-01-05T11:24:33Z","title":"Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects","summary":"Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.","authors":["Omar Momen","Emilie Sitter","Berenike Herrmann","Sina Zarrieß"],"pdf_url":"","comment":"to be published at EACL 2026 main conference"},{"id":"http://arxiv.org/abs/2601.02010v1","updated":"2026-01-05T11:19:07Z","published":"2026-01-05T11:19:07Z","title":"A neural network for modeling human concept formation, understanding and communication","summary":"A remarkable capability of the human brain is to form more abstract conceptual representations from sensorimotor experiences and flexibly apply them independent of direct sensory inputs. However, the computational mechanism underlying this ability remains poorly understood. Here, we present a dual-module neural network framework, the CATS Net, to bridge this gap. Our model consists of a concept-abstraction module that extracts low-dimensional conceptual representations, and a task-solving module that performs visual judgement tasks under the hierarchical gating control of the formed concepts. The system develops transferable semantic structure based on concept representations that enable cross-network knowledge transfer through conceptual communication. Model-brain fitting analyses reveal that these emergent concept spaces align with both neurocognitive semantic model and brain response structures in the human ventral occipitotemporal cortex, while the gating mechanisms mirror that in the semantic control brain network. This work establishes a unified computational framework that can offer mechanistic insights for understanding human conceptual cognition and engineering artificial systems with human-like conceptual intelligence.","authors":["Liangxuan Guo","Haoyang Chen","Yang Chen","Yanchao Bi","Shan Yu"],"pdf_url":"","comment":"6 main figures, 5 extended data figures and 4 supplementary figures"},{"id":"http://arxiv.org/abs/2601.02002v1","updated":"2026-01-05T11:03:56Z","published":"2026-01-05T11:03:56Z","title":"Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models","summary":"Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.","authors":["Antonio Colacicco","Vito Guida","Dario Di Palma","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01997v1","updated":"2026-01-05T10:56:01Z","published":"2026-01-05T10:56:01Z","title":"Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations","summary":"ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.\n  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.","authors":["Dario Di Palma","Giovanni Maria Biancofiore","Vito Walter Anelli","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14244v4","updated":"2026-01-05T10:52:55Z","published":"2025-12-16T09:52:58Z","title":"From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition","summary":"Managing extensive context remains a critical bottleneck for Large Language Models (LLMs), particularly in applications like long-document question answering and autonomous agents where lengthy inputs incur high computational costs and introduce noise. Existing compression techniques often disrupt local coherence through discrete token removal or rely on implicit latent encoding that suffers from positional bias and incompatibility with closed-source APIs. To address these limitations, we introduce the EDU-based Context Compressor, a novel explicit compression framework designed to preserve both global structure and fine-grained details. Our approach reformulates context compression as a structure-then-select process. First, our LingoEDU transforms linear text into a structural relation tree of Elementary Discourse Units (EDUs) which are anchored strictly to source indices to eliminate hallucination. Second, a lightweight ranking module selects query-relevant sub-trees for linearization. To rigorously evaluate structural understanding, we release StructBench, a manually annotated dataset of 248 diverse documents. Empirical results demonstrate that our method achieves state-of-the-art structural prediction accuracy and significantly outperforms frontier LLMs while reducing costs. Furthermore, our structure-aware compression substantially enhances performance across downstream tasks ranging from long-context tasks to complex Deep Search scenarios.","authors":["Yiqing Zhou","Yu Lei","Shuzheng Si","Qingyan Sun","Wei Wang","Yifei Wu","Hao Wen","Gang Chen","Fanchao Qi","Maosong Sun"],"pdf_url":"","comment":null}],"computadora Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2601.02359v1","updated":"2026-01-05T18:59:54Z","published":"2026-01-05T18:59:54Z","title":"ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors","summary":"Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.","authors":["Kaede Shiohara","Toshihiko Yamasaki","Vladislav Golyanik"],"pdf_url":"","comment":"17 pages, 8 figures, 11 tables; project page: https://mapooon.github.io/ExposeAnyonePage/"},{"id":"http://arxiv.org/abs/2601.02358v1","updated":"2026-01-05T18:56:34Z","published":"2026-01-05T18:56:34Z","title":"VINO: A Unified Visual Generator with Interleaved OmniModal Context","summary":"We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.","authors":["Junyi Chen","Tong He","Zhoujie Fu","Pengfei Wan","Kun Gai","Weicai Ye"],"pdf_url":"","comment":"Project page: https://sotamak1r.github.io/VINO-web/"},{"id":"http://arxiv.org/abs/2601.02356v1","updated":"2026-01-05T18:55:32Z","published":"2026-01-05T18:55:32Z","title":"Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes","summary":"We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.","authors":["Jing Tan","Zhaoyang Zhang","Yantao Shen","Jiarui Cai","Shuo Yang","Jiajun Wu","Wei Xia","Zhuowen Tu","Stefano Soatto"],"pdf_url":"","comment":"Project page: https://sparkstj.github.io/talk2move"},{"id":"http://arxiv.org/abs/2601.02353v1","updated":"2026-01-05T18:55:05Z","published":"2026-01-05T18:55:05Z","title":"Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices","summary":"Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\\% while maintaining 92.3\\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.","authors":["Shahnawaz Alam","Mohammed Mudassir Uddin","Mohammed Kaif Pasha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10196v2","updated":"2026-01-05T18:51:53Z","published":"2025-08-13T21:02:38Z","title":"Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks","summary":"Early detection of lung cancer is critical to improving survival outcomes. We present a deep learning framework for automated lung cancer screening from chest computed tomography (CT) images with integrated explainability. Using the IQ-OTH/NCCD dataset (1,197 scans across Normal, Benign, and Malignant classes), we evaluate a custom convolutional neural network (CNN) and three fine-tuned transfer learning backbones: DenseNet121, ResNet152, and VGG19. Models are trained with cost-sensitive learning to mitigate class imbalance and evaluated via accuracy, precision, recall, F1-score, and ROC-AUC. While ResNet152 achieved the highest accuracy (97.3%), DenseNet121 provided the best overall balance in precision, recall, and F1 (up to 92%, 90%, 91%, respectively). We further apply Shapley Additive Explanations (SHAP) to visualize evidence contributing to predictions, improving clinical transparency. Results indicate that CNN-based approaches augmented with explainability can provide fast, accurate, and interpretable support for lung cancer screening, particularly in resource-limited settings.","authors":["Nishan Rai","Sujan Khatri","Devendra Risal"],"pdf_url":"","comment":"11 pages, 9 figures, 4 tables. Undergraduate research project report"},{"id":"http://arxiv.org/abs/2601.02339v1","updated":"2026-01-05T18:33:50Z","published":"2026-01-05T18:33:50Z","title":"Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding","summary":"Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.","authors":["Jingming He","Chongyi Li","Shiqi Wang","Sam Kwong"],"pdf_url":"","comment":"Accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2601.02329v1","updated":"2026-01-05T18:21:02Z","published":"2026-01-05T18:21:02Z","title":"BEDS: Bayesian Emergent Dissipative Structures","summary":"We present BEDS (Bayesian Emergent Dissipative Structures), a theoretical framework that unifies concepts from non-equilibrium thermodynamics, Bayesian inference, information geometry, and machine learning. The central thesis proposes that learning, across physical, biological, and computational systems, fundamentally constitutes the conversion of flux into structure through entropy export. Building on Prigogine's theory of dissipative structures, we establish a formal isomorphism between thermodynamic processes and Bayesian updating, demonstrating that sustainable learning systems must follow dissipative patterns where crystallized posteriors become priors for subsequent levels of emergence.\n  We derive fundamental mathematical constants (e, π, φ) as fixed points of Bayesian inference under minimal axioms, suggesting these constants emerge necessarily from any system capable of representing and updating uncertainty. Furthermore, we propose a conjecture linking Gödel's incompleteness theorems to thermodynamic constraints, hypothesizing that pathologies of formal systems (incompleteness, undecidability) are structurally analogous to dissipation deficits in physical systems.\n  As practical validation, we present a peer-to-peer network architecture implementing BEDS principles, achieving six orders of magnitude improvement in energy efficiency compared to existing distributed consensus systems while enabling continuous learning. This work bridges fundamental physics, mathematical logic, and practical system design, offering both theoretical insights into the nature of learning and computation, and a concrete pathway toward sustainable artificial intelligence.","authors":["Laurent Caraffa"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2512.03862v2","updated":"2026-01-05T18:17:53Z","published":"2025-12-03T15:11:44Z","title":"Diminishing Returns in Self-Supervised Learning","summary":"Transformer-based architectures have become a dominant paradigm in vision and language, but their success is often attributed to large model capacity and massive training data. In this work, we examine how self-supervised pre-training, intermediate fine-tuning, and downstream fine-tuning interact in a low-capacity regime, using a 5M-parameter Vision Transformer for semantic segmentation. Across multiple data scales, we find that masked image modeling pre-training and downstream fine-tuning reliably improve performance, but with clear diminishing returns as supervision increases. In contrast, inserting an intermediate classification fine-tuning stage consistently degrades downstream performance, with the largest drops occurring precisely where pre-training is most effective. Through an analysis of patch-level representation geometry, we show that classification-based intermediate supervision actively interferes with representations learned during pre-training by collapsing spatial structure critical for dense prediction. These results indicate that, in small models, the geometry of supervision matters more than the number of training stages: misaligned intermediate objectives can negate the benefits of pre-training rather than amplify them.","authors":["Oli Bridge","Huey Sun","Botond Branyicskai-Nagy","Charles D'Ornano","Shomit Basu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02318v1","updated":"2026-01-05T18:09:27Z","published":"2026-01-05T18:09:27Z","title":"Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching","summary":"Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).","authors":["Roja Sahoo","Anoop Namboodiri"],"pdf_url":"","comment":"15 pages, 8 figures, 5 tables. Submitted to ICPR 2026"},{"id":"http://arxiv.org/abs/2601.02315v1","updated":"2026-01-05T18:07:21Z","published":"2026-01-05T18:07:21Z","title":"Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping","summary":"Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \\href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}","authors":["Saurabh Kaushik","Lalit Maurya","Beth Tellman"],"pdf_url":"","comment":"Accepted at CV4EO Workshop @ WACV 2026"},{"id":"http://arxiv.org/abs/2601.02309v1","updated":"2026-01-05T17:52:50Z","published":"2026-01-05T17:52:50Z","title":"360DVO: Deep Visual Odometry for Monocular 360-Degree Camera","summary":"Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage","authors":["Xiaopeng Guo","Yinzhe Xu","Huajian Huang","Sai-Kit Yeung"],"pdf_url":"","comment":"12 pages. Received by RA-L"},{"id":"http://arxiv.org/abs/2601.02299v1","updated":"2026-01-05T17:34:50Z","published":"2026-01-05T17:34:50Z","title":"SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting","summary":"The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.","authors":["Sara Inácio","Hugo Proença","João C. Neves"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2601.02289v1","updated":"2026-01-05T17:24:50Z","published":"2026-01-05T17:24:50Z","title":"Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery","summary":"Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.","authors":["Tom Burgert","Leonard Hackel","Paolo Rota","Begüm Demir"],"pdf_url":"","comment":"accepted for publication at IEEE/CVF Winter Conference on Applications of Computer Vision"},{"id":"http://arxiv.org/abs/2601.02281v1","updated":"2026-01-05T17:11:00Z","published":"2026-01-05T17:11:00Z","title":"InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams","summary":"The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT","authors":["Shuai Yuan","Yantai Yang","Xiaotian Yang","Xupeng Zhang","Zhonghao Zhao","Lingming Zhang","Zhipeng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02273v1","updated":"2026-01-05T17:03:45Z","published":"2026-01-05T17:03:45Z","title":"TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation","summary":"Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \\textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \\textbf{5.2\\%} of model parameters ($\\sim$4.9M). On the challenging CHASE\\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git","authors":["Salim Khazem"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02267v1","updated":"2026-01-05T16:51:45Z","published":"2026-01-05T16:51:45Z","title":"DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies","summary":"Human mesh recovery from multi-view images faces a fundamental challenge: real-world datasets contain imperfect ground-truth annotations that bias the models' training, while synthetic data with precise supervision suffers from domain gap. In this paper, we propose DiffProxy, a novel framework that generates multi-view consistent human proxies for mesh recovery. Central to DiffProxy is leveraging the diffusion-based generative priors to bridge the synthetic training and real-world generalization. Its key innovations include: (1) a multi-conditional mechanism for generating multi-view consistent, pixel-aligned human proxies; (2) a hand refinement module that incorporates flexible visual prompts to enhance local details; and (3) an uncertainty-aware test-time scaling method that increases robustness to challenging cases during optimization. These designs ensure that the mesh recovery process effectively benefits from the precise synthetic ground truth and generative advantages of the diffusion-based pipeline. Trained entirely on synthetic data, DiffProxy achieves state-of-the-art performance across five real-world benchmarks, demonstrating strong zero-shot generalization particularly on challenging scenarios with occlusions and partial views. Project page: https://wrk226.github.io/DiffProxy.html","authors":["Renke Wang","Zhenyu Zhang","Ying Tai","Jian Yang"],"pdf_url":"","comment":"Page: https://wrk226.github.io/DiffProxy.html, Code: https://github.com/wrk226/DiffProxy"},{"id":"http://arxiv.org/abs/2601.02256v1","updated":"2026-01-05T16:36:40Z","published":"2026-01-05T16:36:40Z","title":"VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation","summary":"Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.","authors":["Shikun Sun","Liao Qu","Huichao Zhang","Yiheng Liu","Yangyang Song","Xian Li","Xu Wang","Yi Jiang","Daniel K. Du","Xinglong Wu","Jia Jia"],"pdf_url":"","comment":"Project page: https://github.com/ByteVisionLab/NextFlow"},{"id":"http://arxiv.org/abs/2601.02253v1","updated":"2026-01-05T16:33:13Z","published":"2026-01-05T16:33:13Z","title":"Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission","summary":"The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.","authors":["Emrah Mete","Emin Erkan Korkmaz"],"pdf_url":"","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.02249v1","updated":"2026-01-05T16:31:41Z","published":"2026-01-05T16:31:41Z","title":"SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection","summary":"Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.","authors":["Xiantai Xiang","Guangyao Zhou","Zixiao Wen","Wenshuai Li","Ben Niu","Feng Wang","Lijia Huang","Qiantong Wang","Yuhan Liu","Zongxu Pan","Yuxin Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02246v1","updated":"2026-01-05T16:26:32Z","published":"2026-01-05T16:26:32Z","title":"A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets","summary":"Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.","authors":["Annoor Sharara Akhand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.02570v3","updated":"2026-01-05T16:20:54Z","published":"2024-11-04T20:03:06Z","title":"TI-PREGO: Chain of Thought and In-Context Learning for Online Mistake Detection in PRocedural EGOcentric Videos","summary":"Identifying procedural errors online from egocentric videos is a critical yet challenging task across various domains, including manufacturing, healthcare, and skill-based training. The nature of such mistakes is inherently open-set, as unforeseen or novel errors may occur, necessitating robust detection systems that do not rely on prior examples of failure. Currently, however, no technique effectively detects open-set procedural mistakes online.\n  We propose a dual branch architecture to address this problem in an online fashion: one branch continuously performs step recognition from the input egocentric video, while the other anticipates future steps based on the recognition module's output. Mistakes are detected as mismatches between the currently recognized action and the action predicted by the anticipation module. The recognition branch takes input frames, predicts the current action, and aggregates frame-level results into action tokens. The anticipation branch, specifically, leverages the solid pattern-matching capabilities of Large Language Models (LLMs) to predict action tokens based on previously predicted ones.\n  Given the online nature of the task, we also thoroughly benchmark the difficulties associated with per-frame evaluations, particularly the need for accurate and timely predictions in dynamic online scenarios.\n  Extensive experiments on two procedural datasets demonstrate the challenges and opportunities of leveraging a dual-branch architecture for mistake detection, showcasing the effectiveness of our proposed approach. In a thorough evaluation including recognition and anticipation variants and state-of-the-art models, our method reveals its robustness and effectiveness in online applications.","authors":["Leonardo Plini","Luca Scofano","Edoardo De Matteis","Guido Maria D'Amely di Melendugno","Alessandro Flaborea","Andrea Sanchietti","Giovanni Maria Farinella","Fabio Galasso","Antonino Furnari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02242v1","updated":"2026-01-05T16:17:20Z","published":"2026-01-05T16:17:20Z","title":"VIBE: Visual Instruction Based Editor","summary":"Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.","authors":["Grigorii Alekseenko","Aleksandr Gordeev","Irina Tolstykh","Bulat Suleimanov","Vladimir Dokholyan","Georgii Fedorov","Sergey Yakubson","Aleksandra Tsybina","Mikhail Chernyshov","Maksim Kuprashevich"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02228v1","updated":"2026-01-05T15:55:46Z","published":"2026-01-05T15:55:46Z","title":"FMVP: Masked Flow Matching for Adversarial Video Purification","summary":"Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.","authors":["Duoxun Tang","Xueyi Zhang","Chak Hin Wang","Xi Xiao","Dasen Dai","Xinhang Jiang","Wentao Shi","Rui Li","Qing Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.20610v2","updated":"2026-01-05T15:45:20Z","published":"2024-05-31T03:54:59Z","title":"PrevMatch: Revisiting and Maximizing Temporal Knowledge in Semi-Supervised Semantic Segmentation","summary":"In semi-supervised semantic segmentation, the Mean Teacher- and co-training-based approaches are employed to mitigate confirmation bias and coupling problems. However, despite their high performance, these approaches frequently involve complex training pipelines and a substantial computational burden, limiting the scalability and compatibility of these methods. In this paper, we propose a PrevMatch framework that effectively mitigates the aforementioned limitations by maximizing the utilization of the temporal knowledge obtained during the training process. The PrevMatch framework relies on two core strategies: (1) we reconsider the use of temporal knowledge and thus directly utilize previous models obtained during training to generate additional pseudo-label guidance, referred to as previous guidance. (2) we design a highly randomized ensemble strategy to maximize the effectiveness of the previous guidance. PrevMatch, a simple yet effective plug-in method, can be seamlessly integrated into existing semi-supervised learning frameworks with minimal computational overhead. Experimental results on three benchmark semantic segmentation datasets show that incorporating PrevMatch into existing methods significantly improves their performance. Furthermore, our analysis indicates that PrevMatch facilitates stable optimization during training, resulting in improved generalization performance.","authors":["Wooseok Shin","Hyun Joon Park","Jin Sob Kim","Juan Yun","Se Hong Park","Sung Won Han"],"pdf_url":"","comment":"To appear in WACV 2026. Code: https://github.com/wooseok-shin/PrevMatch"},{"id":"http://arxiv.org/abs/2601.02212v1","updated":"2026-01-05T15:32:58Z","published":"2026-01-05T15:32:58Z","title":"Prior-Guided DETR for Ultrasound Nodule Detection","summary":"Accurate detection of ultrasound nodules is essential for the early diagnosis and treatment of thyroid and breast cancers. However, this task remains challenging due to irregular nodule shapes, indistinct boundaries, substantial scale variations, and the presence of speckle noise that degrades structural visibility. To address these challenges, we propose a prior-guided DETR framework specifically designed for ultrasound nodule detection. Instead of relying on purely data-driven feature learning, the proposed framework progressively incorporates different prior knowledge at multiple stages of the network. First, a Spatially-adaptive Deformable FFN with Prior Regularization (SDFPR) is embedded into the CNN backbone to inject geometric priors into deformable sampling, stabilizing feature extraction for irregular and blurred nodules. Second, a Multi-scale Spatial-Frequency Feature Mixer (MSFFM) is designed to extract multi-scale structural priors, where spatial-domain processing emphasizes contour continuity and boundary cues, while frequency-domain modeling captures global morphology and suppresses speckle noise. Furthermore, a Dense Feature Interaction (DFI) mechanism propagates and exploits these prior-modulated features across all encoder layers, enabling the decoder to enhance query refinement under consistent geometric and structural guidance. Experiments conducted on two clinically collected thyroid ultrasound datasets (Thyroid I and Thyroid II) and two public benchmarks (TN3K and BUSI) for thyroid and breast nodules demonstrate that the proposed method achieves superior accuracy compared with 18 detection methods, particularly in detecting morphologically complex nodules.The source code is publicly available at https://github.com/wjj1wjj/Ultrasound-DETR.","authors":["Jingjing Wang","Zhuo Xiao","Xinning Yao","Bo Liu","Lijuan Niu","Xiangzhi Bai","Fugen Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02211v1","updated":"2026-01-05T15:32:53Z","published":"2026-01-05T15:32:53Z","title":"Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion","summary":"Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.","authors":["Binglei Li","Mengping Yang","Zhiyu Tan","Junping Zhang","Hao Li"],"pdf_url":"","comment":"11 pages"},{"id":"http://arxiv.org/abs/2601.02206v1","updated":"2026-01-05T15:31:07Z","published":"2026-01-05T15:31:07Z","title":"Seeing the Unseen: Zooming in the Dark with Event Cameras","summary":"This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.","authors":["Dachun Kai","Zeyu Xiao","Huyue Zhu","Jiaxiao Wang","Yueyi Zhang","Xiaoyan Sun"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2601.02204v1","updated":"2026-01-05T15:27:04Z","published":"2026-01-05T15:27:04Z","title":"NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation","summary":"We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.","authors":["Huichao Zhang","Liao Qu","Yiheng Liu","Hang Chen","Yangyang Song","Yongsheng Dong","Shikun Sun","Xian Li","Xu Wang","Yi Jiang","Hu Ye","Bo Chen","Yiming Gao","Peng Liu","Akide Liu","Zhipeng Yang","Qili Deng","Linjie Xing","Jiyang Liu","Zhao Wang","Yang Zhou","Mingcong Liu","Yi Zhang","Qian He","Xiwei Hu","Zhongqi Qi","Jie Shao","Zhiye Fu","Shuai Wang","Fangmin Chen","Xuezhi Chai","Zhihua Wu","Yitong Wang","Zehuan Yuan","Daniel K. Du","Xinglong Wu"],"pdf_url":"","comment":"Project page: https://github.com/ByteVisionLab/NextFlow"},{"id":"http://arxiv.org/abs/2601.02203v1","updated":"2026-01-05T15:27:04Z","published":"2026-01-05T15:27:04Z","title":"Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules","summary":"Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\\% of a full fine-tune (98.84\\% vs. 99.67\\%) while training 97.2\\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.","authors":["Oliver Custance","Saad Khan","Simon Parkinson","Quan Z. Sheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02201v1","updated":"2026-01-05T15:24:05Z","published":"2026-01-05T15:24:05Z","title":"CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents","summary":"The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.","authors":["Keyu Wang","Bingchen Miao","Wendong Bu","Yu Wu","Juncheng Li","Shengyu Zhang","Wenqiao Zhang","Siliang Tang","Jun Xiao","Yueting Zhuang"],"pdf_url":"","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2601.02198v1","updated":"2026-01-05T15:19:59Z","published":"2026-01-05T15:19:59Z","title":"Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models","summary":"In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.","authors":["Alexander Möllers","Julius Hense","Florian Schulz","Timo Milbich","Maximilian Alber","Lukas Ruff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02189v1","updated":"2026-01-05T15:09:18Z","published":"2026-01-05T15:09:18Z","title":"QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition","summary":"Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.","authors":["Cheng Ying Wu","Yen Jui Chang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02177v1","updated":"2026-01-05T14:55:38Z","published":"2026-01-05T14:55:38Z","title":"Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32","summary":"WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\\%, $σ$=3.74\\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.","authors":["Oliver Custance","Saad Khan","Simon Parkinson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2401.01510v2","updated":"2026-01-05T14:50:13Z","published":"2024-01-03T02:29:34Z","title":"Answering from Sure to Uncertain: Uncertainty-Aware Curriculum Learning for Video Question Answering","summary":"While significant advancements have been made in video question answering (VideoQA), the potential benefits of enhancing model generalization through tailored difficulty scheduling have been largely overlooked in existing research. This paper seeks to bridge that gap by incorporating VideoQA into a curriculum learning (CL) framework that progressively trains models from simpler to more complex data. Recognizing that conventional self-paced CL methods rely on training loss for difficulty measurement, which might not accurately reflect the intricacies of video-question pairs, we introduce the concept of uncertainty-aware CL. Here, uncertainty serves as the guiding principle for dynamically adjusting the difficulty. Furthermore, we address the challenge posed by uncertainty by presenting a probabilistic modeling approach for VideoQA. Specifically, we conceptualize VideoQA as a stochastic computation graph, where the hidden representations are treated as stochastic variables. This yields two distinct types of uncertainty: one related to the inherent uncertainty in the data and another pertaining to the model's confidence. In practice, we seamlessly integrate the VideoQA model into our framework and conduct comprehensive experiments. The findings affirm that our approach not only achieves enhanced performance but also effectively quantifies uncertainty in the context of VideoQA.","authors":["Haopeng Li","Mohammed Bennamoun","Jun Liu","Hossein Rahmani","Qiuhong Ke"],"pdf_url":"","comment":"Accepted by BMVC 2025"},{"id":"http://arxiv.org/abs/2601.02147v1","updated":"2026-01-05T14:22:20Z","published":"2026-01-05T14:22:20Z","title":"BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models","summary":"Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.","authors":["Sunny Gupta","Shounak Das","Amit Sethi"],"pdf_url":"","comment":"Accepted at the AAAI 2026 Workshop AIR-FM, Assessing and Improving Reliability of Foundation Models in the Real World"},{"id":"http://arxiv.org/abs/2601.02141v1","updated":"2026-01-05T14:12:43Z","published":"2026-01-05T14:12:43Z","title":"Efficient Unrolled Networks for Large-Scale 3D Inverse Problems","summary":"Deep learning-based methods have revolutionized the field of imaging inverse problems, yielding state-of-the-art performance across various imaging domains. The best performing networks incorporate the imaging operator within the network architecture, typically in the form of deep unrolling. However, in large-scale problems, such as 3D imaging, most existing methods fail to incorporate the operator in the architecture due to the prohibitive amount of memory required by global forward operators, which hinder typical patching strategies. In this work, we present a domain partitioning strategy and normal operator approximations that enable the training of end-to-end reconstruction models incorporating forward operators of arbitrarily large problems into their architecture. The proposed method achieves state-of-the-art performance on 3D X-ray cone-beam tomography and 3D multi-coil accelerated MRI, while requiring only a single GPU for both training and inference.","authors":["Romain Vo","Julián Tachella"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02139v1","updated":"2026-01-05T14:10:13Z","published":"2026-01-05T14:10:13Z","title":"Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery","summary":"Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.","authors":["Chenyang Lai","Shuaiyu Chen","Tianjin Huang","Siyang Song","Guangliang Cheng","Chunbo Luo","Zeyu Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.20776v2","updated":"2026-01-05T14:04:30Z","published":"2025-07-28T12:39:33Z","title":"RingMo-Agent: A Unified Remote Sensing Foundation Model for Multi-Platform and Multi-Modal Reasoning","summary":"Remote sensing (RS) images from multiple modalities and platforms exhibit diverse details due to differences in sensor characteristics and imaging perspectives. Existing vision-language research in RS largely relies on relatively homogeneous data sources. Moreover, they still remain limited to conventional visual perception tasks such as classification or captioning. As a result, these methods fail to serve as a unified and standalone framework capable of effectively handling RS imagery from diverse sources in real-world applications. To address these issues, we propose RingMo-Agent, a model designed to handle multi-modal and multi-platform data that performs perception and reasoning tasks based on user textual instructions. Compared with existing models, RingMo-Agent 1) is supported by a large-scale vision-language dataset named RS-VL3M, comprising over 3 million image-text pairs, spanning optical, SAR, and infrared (IR) modalities collected from both satellite and UAV platforms, covering perception and challenging reasoning tasks; 2) learns modality adaptive representations by incorporating separated embedding layers to construct isolated features for heterogeneous modalities and reduce cross-modal interference; 3) unifies task modeling by introducing task-specific tokens and employing a token-based high-dimensional hidden state decoding mechanism designed for long-horizon spatial tasks. Extensive experiments on various RS vision-language tasks demonstrate that RingMo-Agent not only proves effective in both visual understanding and sophisticated analytical tasks, but also exhibits strong generalizability across different platforms and sensing modalities.","authors":["Huiyang Hu","Peijin Wang","Yingchao Feng","Kaiwen Wei","Wenxin Yin","Wenhui Diao","Mengyu Wang","Hanbo Bi","Kaiyue Kang","Tong Ling","Kun Fu","Xian Sun"],"pdf_url":"","comment":"23 pages, 6 figures, 20 tables"},{"id":"http://arxiv.org/abs/2601.02126v1","updated":"2026-01-05T13:57:02Z","published":"2026-01-05T13:57:02Z","title":"Remote Sensing Change Detection via Weak Temporal Supervision","summary":"Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.","authors":["Xavier Bou","Elliot Vincent","Gabriele Facciolo","Rafael Grompone von Gioi","Jean-Michel Morel","Thibaud Ehret"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02112v1","updated":"2026-01-05T13:41:20Z","published":"2026-01-05T13:41:20Z","title":"Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model","summary":"The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.","authors":["Utkarsh Singh","Absaar Ali","Adarsh Roy"],"pdf_url":"","comment":"14 pages, 5 figures. Published in: Bramer M., Stahl F. (eds) Artificial Intelligence XLII. SGAI 2025. Lecture Notes in Computer Science, vol 16302. Springer, Cham"},{"id":"http://arxiv.org/abs/2405.18770v6","updated":"2026-01-05T13:34:30Z","published":"2024-05-29T05:20:02Z","title":"Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships","summary":"Pre-trained vision-language (VL) models are highly vulnerable to adversarial attacks. However, existing defense methods primarily focus on image classification, overlooking two key aspects of VL tasks: multimodal attacks, where both image and text can be perturbed, and the one-to-many relationship of images and texts, where a single image can correspond to multiple textual descriptions and vice versa (1:N and N:1). This work is the first to explore defense strategies against multimodal attacks in VL tasks, whereas prior VL defense methods focus on vision robustness. We propose multimodal adversarial training (MAT), which incorporates adversarial perturbations in both image and text modalities during training, significantly outperforming existing unimodal defenses. Furthermore, we discover that MAT is limited by deterministic one-to-one (1:1) image-text pairs in VL training data. To address this, we conduct a comprehensive study on leveraging one-to-many relationships to enhance robustness, investigating diverse augmentation techniques. Our analysis shows that, for a more effective defense, augmented image-text pairs should be well-aligned, diverse, yet avoid distribution shift -- conditions overlooked by prior research. This work pioneers defense strategies against multimodal attacks, providing insights for building robust VLMs from both optimization and data perspectives. Our code is publicly available at https://github.com/CyberAgentAILab/multimodal-adversarial-training.","authors":["Futa Waseda","Antonio Tejero-de-Pablos","Isao Echizen"],"pdf_url":"","comment":"WACV 2026 Accepted. Code available at https://github.com/CyberAgentAILab/multimodal-adversarial-training"},{"id":"http://arxiv.org/abs/2601.02107v1","updated":"2026-01-05T13:34:17Z","published":"2026-01-05T13:34:17Z","title":"MagicFight: Personalized Martial Arts Combat Video Generation","summary":"Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation.\n  Website: https://MingfuYAN.github.io/MagicFight/\n  Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta","authors":["Jiancheng Huang","Mingfu Yan","Songyan Chen","Yi Huang","Shifeng Chen"],"pdf_url":"","comment":"Accepted by ACM MM 2024"},{"id":"http://arxiv.org/abs/2601.02103v1","updated":"2026-01-05T13:32:37Z","published":"2026-01-05T13:32:37Z","title":"HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures","summary":"Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.","authors":["Yating Wang","Yuan Sun","Xuan Wang","Ran Yi","Boyao Zhou","Yipengjing Sun","Hongyu Liu","Yinuo Wang","Lizhuang Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02102v1","updated":"2026-01-05T13:28:28Z","published":"2026-01-05T13:28:28Z","title":"360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images","summary":"3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.","authors":["Jiaqi Yao","Zhongmiao Yan","Jingyi Xu","Songpengcheng Xia","Yan Xiang","Ling Pei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.16073v4","updated":"2026-01-05T13:27:16Z","published":"2025-06-19T06:55:03Z","title":"TD3Net: A temporal densely connected multi-dilated convolutional network for lipreading","summary":"The word-level lipreading approach typically employs a two-stage framework with separate frontend and backend architectures to model dynamic lip movements. Each component has been extensively studied, and in the backend architecture, temporal convolutional networks (TCNs) have been widely adopted in state-of-the-art methods. Recently, dense skip connections have been introduced in TCNs to mitigate the limited density of the receptive field, thereby improving the modeling of complex temporal representations. However, their performance remains constrained owing to potential information loss regarding the continuous nature of lip movements, caused by blind spots in the receptive field. To address this limitation, we propose TD3Net, a temporal densely connected multi-dilated convolutional network that combines dense skip connections and multi-dilated temporal convolutions as the backend architecture. TD3Net covers a wide and dense receptive field without blind spots by applying different dilation factors to skip-connected features. Experimental results on a word-level lipreading task using two large publicly available datasets, Lip Reading in the Wild (LRW) and LRW-1000, indicate that the proposed method achieves performance comparable to state-of-the-art methods. It achieved higher accuracy with fewer parameters and lower floating-point operations compared to existing TCN-based backend architectures. Moreover, visualization results suggest that our approach effectively utilizes diverse temporal features while preserving temporal continuity, presenting notable advantages in lipreading systems. The code is available at our GitHub repository (https://github.com/Leebh-kor/TD3Net).","authors":["Byung Hoon Lee","Wooseok Shin","Sung Won Han"],"pdf_url":"","comment":"Accepted for publication in Journal of Visual Communication and Image Representation. DOI: https://doi.org/10.1016/j.jvcir.2025.104540"},{"id":"http://arxiv.org/abs/2601.02098v1","updated":"2026-01-05T13:26:02Z","published":"2026-01-05T13:26:02Z","title":"InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting","summary":"Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.","authors":["Jinlong Fan","Shanshan Zhao","Liang Zheng","Jing Zhang","Yuxiang Yang","Mingming Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02096v1","updated":"2026-01-05T13:24:12Z","published":"2026-01-05T13:24:12Z","title":"Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs","summary":"Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.","authors":["Peizhuo Li","Sebastian Starke","Yuting Ye","Olga Sorkine-Hornung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21582v3","updated":"2026-01-05T13:20:10Z","published":"2025-11-26T16:56:42Z","title":"Data-Augmented Multimodal Feature Fusion for Multiclass Visual Recognition of Oral Cancer Lesions","summary":"Oral cancer is frequently diagnosed at later stages due to its similarity to other lesions. Existing research on computer aided diagnosis has made progress using deep learning; however, most approaches remain limited by small, imbalanced datasets and a dependence on single-modality features, which restricts model generalization in real-world clinical settings. To address these limitations, this study proposes a novel data-augmentation driven multimodal feature-fusion framework integrated within a (Vision Recognition)VR assisted oral cancer recognition system. Our method combines extensive data centric augmentation with fused clinical and image-based representations to enhance model robustness and reduce diagnostic ambiguity. Using a stratified training pipeline and an EfficientNetV2 B1 backbone, the system improves feature diversity, mitigates imbalance, and strengthens the learned multimodal embeddings. Experimental evaluation demonstrates that the proposed framework achieves an overall accuracy of 82.57 percent on 2 classes, 65.13 percent on 3 classes, and 54.97 percent on 4 classes, outperforming traditional single stream CNN models. These results highlight the effectiveness of multimodal feature fusion combined with strategic augmentation for reliable early oral cancer lesion recognition and serve as a foundation for immersive VR based clinical decision support tools.","authors":["Joy Naoum","Revana Salama","Ali Hamdi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02091v1","updated":"2026-01-05T13:18:11Z","published":"2026-01-05T13:18:11Z","title":"MCD-Net: A Lightweight Deep Learning Baseline for Optical-Only Moraine Segmentation","summary":"Glacial segmentation is essential for reconstructing past glacier dynamics and evaluating climate-driven landscape change. However, weak optical contrast and the limited availability of high-resolution DEMs hinder automated mapping. This study introduces the first large-scale optical-only moraine segmentation dataset, comprising 3,340 manually annotated high-resolution images from Google Earth covering glaciated regions of Sichuan and Yunnan, China. We develop MCD-Net, a lightweight baseline that integrates a MobileNetV2 encoder, a Convolutional Block Attention Module (CBAM), and a DeepLabV3+ decoder. Benchmarking against deeper backbones (ResNet152, Xception) shows that MCD-Net achieves 62.3\\% mean Intersection over Union (mIoU) and 72.8\\% Dice coefficient while reducing computational cost by more than 60\\%. Although ridge delineation remains constrained by sub-pixel width and spectral ambiguity, the results demonstrate that optical imagery alone can provide reliable moraine-body segmentation. The dataset and code are publicly available at https://github.com/Lyra-alpha/MCD-Net, establishing a reproducible benchmark for moraine-specific segmentation and offering a deployable baseline for high-altitude glacial monitoring.","authors":["Zhehuan Cao","Fiseha Berhanu Tesema","Ping Fu","Jianfeng Ren","Ahmed Nasr"],"pdf_url":"","comment":"13 pages, 10 figures. This manuscript is under review at IEEE Transactions on Geoscience and Remote Sensing"},{"id":"http://arxiv.org/abs/2601.02088v1","updated":"2026-01-05T13:14:19Z","published":"2026-01-05T13:14:19Z","title":"PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction","summary":"Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.","authors":["Jiahao Bao","Huazhen Liu","Yu Zhuang","Leran Tao","Xinyu Xu","Yongtao Shi","Mengjia Cheng","Yiming Wang","Congshuang Ku","Ting Zeng","Yilang Du","Siyi Chen","Shunyao Shen","Suncheng Xiang","Hongbo Yu"],"pdf_url":"","comment":"31 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.21408v2","updated":"2026-01-05T12:55:42Z","published":"2025-03-27T11:52:08Z","title":"VALLR: Visual ASR Language Model for Lip Reading","summary":"Lip Reading, or Visual Automatic Speech Recognition (V-ASR), is a complex task requiring the interpretation of spoken language exclusively from visual cues, primarily lip movements and facial expressions. This task is especially challenging due to the absence of auditory information and the inherent ambiguity when visually distinguishing phonemes that have overlapping visemes where different phonemes appear identical on the lips. Current methods typically attempt to predict words or characters directly from these visual cues, but this approach frequently encounters high error rates due to coarticulation effects and viseme ambiguity. We propose a novel two-stage, phoneme-centric framework for Visual Automatic Speech Recognition (V-ASR) that addresses these longstanding challenges. First, our model predicts a compact sequence of phonemes from visual inputs using a Video Transformer with a CTC head, thereby reducing the task complexity and achieving robust speaker invariance. This phoneme output then serves as the input to a fine-tuned Large Language Model (LLM), which reconstructs coherent words and sentences by leveraging broader linguistic context. Unlike existing methods that either predict words directly-often faltering on visually similar phonemes-or rely on large-scale multimodal pre-training, our approach explicitly encodes intermediate linguistic structure while remaining highly data efficient. We demonstrate state-of-the-art performance on two challenging datasets, LRS2 and LRS3, where our method achieves significant reductions in Word Error Rate (WER) achieving a SOTA WER of 18.7 on LRS3 despite using 99.4% less labelled data than the next best approach.","authors":["Marshall Thomas","Edward Fish","Richard Bowden"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10838v2","updated":"2026-01-05T12:52:56Z","published":"2025-08-14T17:03:47Z","title":"Unsupervised Stereo via Multi-Baseline Geometry-Consistent Self-Training","summary":"Photometric loss and pseudo-label-based self-training are two widely used methods for training stereo networks on unlabeled data. However, they both struggle to provide accurate supervision in occluded regions. The former lacks valid correspondences, while the latter's pseudo labels are often unreliable. To overcome these limitations, we present S$^3$, a simple yet effective framework based on multi-baseline geometry consistency. Unlike conventional self-training where teacher and student share identical stereo pairs, S$^3$ assigns them different target images, introducing natural visibility asymmetry. Regions occluded in the student's view often remain visible and matchable to the teacher, enabling reliable pseudo labels even in regions where photometric supervision fails. The teacher's disparities are rescaled to align with the student's baseline and used to guide student learning. An occlusion-aware weighting strategy is further proposed to mitigate unreliable supervision in teacher-occluded regions and to encourage the student to learn robust occlusion completion. To support training, we construct MBS20K, a multi-baseline stereo dataset synthesized using the CARLA simulator. Extensive experiments demonstrate that S$^3$ provides effective supervision in both occluded and non-occluded regions, achieves strong generalization performance, and surpasses previous state-of-the-art methods on the KITTI 2015 and 2012 benchmarks.","authors":["Peng Xu","Zhiyu Xiang","Tingming Bai","Tianyu Pu","Kai Wang","Chaojie Ji","Zhihao Yang","Eryun Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02072v1","updated":"2026-01-05T12:51:12Z","published":"2026-01-05T12:51:12Z","title":"SketchRodGS: Sketch-based Extraction of Slender Geometries for Animating Gaussian Splatting Scenes","summary":"Physics simulation of slender elastic objects often requires discretization as a polyline. However, constructing a polyline from Gaussian splatting is challenging as Gaussian splatting lacks connectivity information and the configuration of Gaussian primitives contains much noise. This paper presents a method to extract a polyline representation of the slender part of the objects in a Gaussian splatting scene from the user's sketching input. Our method robustly constructs a polyline mesh that represents the slender parts using the screen-space shortest path analysis that can be efficiently solved using dynamic programming. We demonstrate the effectiveness of our approach in several in-the-wild examples.","authors":["Haato Watanabe","Nobuyuki Umetani"],"pdf_url":"","comment":"Presented at SIGGRAPH Asia 2025 (Technical Communications). Best Technical Communications Award"},{"id":"http://arxiv.org/abs/2506.05221v2","updated":"2026-01-05T12:49:21Z","published":"2025-06-05T16:38:16Z","title":"SAM-aware Test-time Adaptation for Universal Medical Image Segmentation","summary":"Leveraging the Segment Anything Model (SAM) for medical image segmentation remains challenging due to its limited adaptability across diverse medical domains. Although fine-tuned variants, such as MedSAM, improve performance in scenarios similar to the training modalities or organs, they may lack generalizability to unseen data. To overcome this limitation, we propose SAM-aware Test-time Adaptation (SAM-TTA), a lightweight and flexible framework that preserves SAM's inherent generalization ability while enhancing segmentation accuracy for medical images. SAM-TTA tackles two major challenges: (1) input-level discrepancy caused by channel mismatches between natural and medical images, and (2) semantic-level discrepancy due to different object characteristics in natural versus medical images (e.g., with clear boundaries vs. ambiguous structures). To this end, we introduce two complementary components: a self-adaptive Bezier Curve-based Transformation (SBCT), which maps single-channel medical images into SAM-compatible three-channel images via a few learnable parameters to be optimized at test time; and IoU-guided Multi-scale Adaptation (IMA), which leverages SAM's intrinsic IoU scores to enforce high output confidence, dual-scale prediction consistency, and intermediate feature consistency, to improve semantic-level alignments. Extensive experiments on eight public medical image segmentation tasks, covering six grayscale and two color (endoscopic) tasks, demonstrate that SAM-TTA consistently outperforms state-of-the-art test-time adaptation methods. Notably, on six grayscale datasets, SAM-TTA even surpasses fully fine-tuned models, achieving significant Dice improvements (i.e., average 4.8% and 7.4% gains over MedSAM and SAM-Med2D) and establishing a new paradigm for universal medical image segmentation. Code is available at https://github.com/JianghaoWu/SAM-TTA.","authors":["Jianghao Wu","Yicheng Wu","Yutong Xie","Wenjia Bai","You Zhang","Feilong Tang","Yulong Li","Imran Razzak","Daniel F Schmidt","Yasmeen George"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.13454v2","updated":"2026-01-05T12:06:46Z","published":"2025-12-15T15:51:30Z","title":"Test-Time Modification: Inverse Domain Transformation for Robust Perception","summary":"Generative foundation models contain broad visual knowledge and can produce diverse image variations, making them particularly promising for advancing domain generalization tasks. While they can be used for training data augmentation, synthesizing comprehensive target-domain variations remains slow, expensive, and incomplete. We propose an alternative: using diffusion models at test time to map target images back to the source distribution where the downstream model was trained. This approach requires only a source domain description, preserves the task model, and eliminates large-scale synthetic data generation. We demonstrate consistent improvements across segmentation, detection, and classification tasks under challenging environmental shifts in real-to-real domain generalization scenarios with unknown target distributions. Our analysis spans multiple generative and downstream models, including an ensemble variant for enhanced robustness. The method achieves substantial relative gains: 137% on BDD100K-Night, 68% on ImageNet-R, and 62% on DarkZurich.","authors":["Arpit Jadon","Joshua Niemeijer","Yuki M. Asano"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2601.02046v1","updated":"2026-01-05T12:06:43Z","published":"2026-01-05T12:06:43Z","title":"Agentic Retoucher for Text-To-Image Generation","summary":"Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.","authors":["Shaocheng Shen","Jianfeng Liang. Chunlei Cai","Cong Geng","Huiyu Duan","Xiaoyun Zhang","Qiang Hu","Guangtao Zhai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24015v2","updated":"2026-01-05T12:05:00Z","published":"2025-12-30T06:29:20Z","title":"On Exact Editing of Flow-Based Diffusion Models","summary":"Recent methods in flow-based diffusion editing have enabled direct transformations between source and target image distribution without explicit inversion. However, the latent trajectories in these methods often exhibit accumulated velocity errors, leading to semantic inconsistency and loss of structural fidelity. We propose Conditioned Velocity Correction (CVC), a principled framework that reformulates flow-based editing as a distribution transformation problem driven by a known source prior. CVC rethinks the role of velocity in inter-distribution transformation by introducing a dual-perspective velocity conversion mechanism. This mechanism explicitly decomposes the latent evolution into two components: a structure-preserving branch that remains consistent with the source trajectory, and a semantically-guided branch that drives a controlled deviation toward the target distribution. The conditional velocity field exhibits an absolute velocity error relative to the true underlying distribution trajectory, which inherently introduces potential instability and trajectory drift in the latent space. To address this quantifiable deviation and maintain fidelity to the true flow, we apply a posterior-consistent update to the resulting conditional velocity field. This update is derived from Empirical Bayes Inference and Tweedie correction, which ensures a mathematically grounded error compensation over time. Our method yields stable and interpretable latent dynamics, achieving faithful reconstruction alongside smooth local semantic conversion. Comprehensive experiments demonstrate that CVC consistently achieves superior fidelity, better semantic alignment, and more reliable editing behavior across diverse tasks.","authors":["Zixiang Li","Yue Song","Jianing Peng","Ting Liu","Jun Huang","Xiaochao Qu","Luoqi Liu","Wei Wang","Yao Zhao","Yunchao Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02038v1","updated":"2026-01-05T11:50:02Z","published":"2026-01-05T11:50:02Z","title":"AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off","summary":"Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.","authors":["Yihan Zhu","Mengying Ge"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02036v1","updated":"2026-01-05T11:47:18Z","published":"2026-01-05T11:47:18Z","title":"GDRO: Group-level Reward Post-training Suitable for Diffusion Models","summary":"Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.","authors":["Yiyang Wang","Xi Chen","Xiaogang Xu","Yu Liu","Hengshuang Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02029v1","updated":"2026-01-05T11:42:49Z","published":"2026-01-05T11:42:49Z","title":"Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding","summary":"This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.","authors":["Toshihiko Nishimura","Hirofumi Abe","Kazuhiko Murasaki","Taiga Yoshida","Ryuichi Tanida"],"pdf_url":"","comment":"19"},{"id":"http://arxiv.org/abs/2401.01505v5","updated":"2026-01-05T11:29:59Z","published":"2024-01-03T02:22:34Z","title":"Sports-QA: A Large-Scale Video Question Answering Benchmark for Complex and Professional Sports","summary":"Reasoning over sports videos for question answering is an important task with numerous applications, such as player training and information retrieval. However, this task has not been explored due to the lack of relevant datasets and the challenging nature it presents. Most datasets for video question answering (VideoQA) focus mainly on general and coarse-grained understanding of daily-life videos, which is not applicable to sports scenarios requiring professional action understanding and fine-grained motion analysis. In this paper, we introduce the first dataset, named Sports-QA, specifically designed for the sports VideoQA task. The Sports-QA dataset includes various types of questions, such as descriptions, chronologies, causalities, and counterfactual conditions, covering multiple sports. Furthermore, to address the characteristics of the sports VideoQA task, we propose a new Auto-Focus Transformer (AFT) capable of automatically focusing on particular scales of temporal information for question answering. We conduct extensive experiments on Sports-QA, including baseline studies and the evaluation of different methods. The results demonstrate that our AFT achieves state-of-the-art performance.","authors":["Haopeng Li","Andong Deng","Jun Liu","Hossein Rahmani","Yulan Guo","Bernt Schiele","Mohammed Bennamoun","Qiuhong Ke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02020v1","updated":"2026-01-05T11:29:49Z","published":"2026-01-05T11:29:49Z","title":"Adapting Depth Anything to Adverse Imaging Conditions with Events","summary":"Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.","authors":["Shihan Peng","Yuyang Xiong","Hanyu Zhou","Zhiwei Shi","Haoyue Liu","Gang Chen","Luxin Yan","Yi Chang"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2601.02018v1","updated":"2026-01-05T11:28:58Z","published":"2026-01-05T11:28:58Z","title":"Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement","summary":"Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.","authors":["Guangqian Guo","Aixi Ren","Yong Guo","Xuehui Yu","Jiacheng Tian","Wenli Li","Yaoxing Wang","Shan Gao"],"pdf_url":"","comment":"Diffusion-based latent space enhancement helps improve the robustness of SAM"},{"id":"http://arxiv.org/abs/2601.02016v1","updated":"2026-01-05T11:24:34Z","published":"2026-01-05T11:24:34Z","title":"Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach","summary":"This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.","authors":["Matthias Bartolo","Dylan Seychell","Gabriel Hili","Matthew Montebello","Carl James Debono","Saviour Formosa","Konstantinos Makantasis"],"pdf_url":"","comment":"Code available on GitHub: https://github.com/mbar0075/lupi-for-object-detection"},{"id":"http://arxiv.org/abs/2508.02660v3","updated":"2026-01-05T11:22:32Z","published":"2025-08-04T17:49:37Z","title":"PMGS: Reconstruction of Projectile Motion Across Large Spatiotemporal Spans via 3D Gaussian Splatting","summary":"Modeling complex rigid motion across large spatiotemporal spans remains an unresolved challenge in dynamic reconstruction. Existing paradigms are mainly confined to short-term, small-scale deformation and offer limited consideration for physical consistency. This study proposes PMGS, focusing on reconstructing Projectile Motion via 3D Gaussian Splatting. The workflow comprises two stages: 1) Target Modeling: achieving object-centralized reconstruction through dynamic scene decomposition and an improved point density control; 2) Motion Recovery: restoring full motion sequences by learning per-frame SE(3) poses. We introduce an acceleration consistency constraint to bridge Newtonian mechanics and pose estimation, and design a dynamic simulated annealing strategy that adaptively schedules learning rates based on motion states. Furthermore, we devise a Kalman fusion scheme to optimize error accumulation from multi-source observations to mitigate disturbances. Experiments show PMGS's superior performance in reconstructing high-speed nonlinear rigid motion compared to mainstream dynamic methods.","authors":["Yijun Xu","Jingrui Zhang","Yuhan Chen","Dingwen Wang","Lei Yu","Chu He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10710v2","updated":"2026-01-05T11:17:43Z","published":"2025-08-14T14:53:53Z","title":"CountCluster: Training-Free Object Quantity Guidance with Cross-Attention Map Clustering for Text-to-Image Generation","summary":"Diffusion-based text-to-image generation models have demonstrated strong performance in terms of image quality and diversity. However, they still struggle to generate images that accurately reflect the number of objects specified in the input prompt. Several approaches have been proposed that rely on either external counting modules for iterative refinement or quantity representations derived from learned tokens or latent features. However, they still have limitations in accurately reflecting the specified number of objects and overlook an important structural characteristic--The number of object instances in the generated image is largely determined in the early timesteps of the denoising process. To correctly reflect the object quantity for image generation, the highly activated regions in the object cross-attention map at the early timesteps should match the input object quantity, while each region should be clearly separated. To address this issue, we propose \\textit{CountCluster}, a method that guides the object cross-attention map to be clustered according to the specified object count in the input, without relying on any external tools or additional training. The proposed method partitions the object cross-attention map into $k$ clusters at inference time based on attention scores, defines an ideal distribution in which each cluster is spatially well-separated, and optimizes the latent to align with this target distribution. Our method achieves an average improvement of 18.5\\%p in object count accuracy compared to existing methods, and demonstrates superior quantity control performance across a variety of prompts. Code will be released at: https://github.com/JoohyeonL22/CountCluster","authors":["Joohyeon Lee","Jin-Seop Lee","Jee-Hyong Lee"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2601.02008v1","updated":"2026-01-05T11:17:33Z","published":"2026-01-05T11:17:33Z","title":"XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging","summary":"Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.","authors":["Midhat Urooj","Ayan Banerjee","Sandeep Gupta"],"pdf_url":"","comment":"Accepted at AAAI Bridge Program 2026"},{"id":"http://arxiv.org/abs/2411.12589v3","updated":"2026-01-05T11:02:56Z","published":"2024-11-15T19:36:50Z","title":"ULTra: Unveiling Latent Token Interpretability in Transformer-Based Understanding and Segmentation","summary":"Transformers have revolutionized Computer Vision (CV) through self-attention mechanisms. However, their complexity makes latent token representations difficult to interpret. We introduce ULTra, a framework for interpreting Transformer embeddings and uncovering meaningful semantic patterns within them. ULTra enables unsupervised semantic segmentation using pre-trained models without requiring fine-tuning. Additionally, we propose a self-supervised training approach that refines segmentation performance by learning an external transformation matrix without modifying the underlying model. Our method achieves state-of-the-art performance in unsupervised semantic segmentation, outperforming existing segmentation methods. Furthermore, we validate ULTra for model interpretation on both synthetic and real-world scenarios, including Object Selection and interpretable text summarization using LLMs, demonstrating its broad applicability in explaining the semantic structure of latent token representations.","authors":["Hesam Hosseini","Ghazal Hosseini Mighan","Amirabbas Afzali","Sajjad Amini","Amir Houmansadr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01998v1","updated":"2026-01-05T10:58:02Z","published":"2026-01-05T10:58:02Z","title":"Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors","summary":"Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.","authors":["Chen Zhu","Huiwen Zhang","Mu He","Yujie Li","Xiaotian Qiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01992v1","updated":"2026-01-05T10:53:41Z","published":"2026-01-05T10:53:41Z","title":"API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning","summary":"Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.","authors":["Chen Zhu","Huiwen Zhang","Yujie Li","Mu He","Xiaotian Qiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01989v1","updated":"2026-01-05T10:48:12Z","published":"2026-01-05T10:48:12Z","title":"VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis","summary":"Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.","authors":["Aly R. Elkammar","Karim M. Gamaleldin","Catherine M. Elias"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01984v1","updated":"2026-01-05T10:38:26Z","published":"2026-01-05T10:38:26Z","title":"Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation","summary":"Spatial reasoning -- the ability to perceive and reason about relationships in space -- advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches, improving fine-grained perception but weakening global spatial awareness, or mark isolated coordinates, which capture object locations but overlook their overall organization. In this work, we integrate the cognitive concept of an object-centric blueprint into VLMs to enhance spatial reasoning. Given an image and a question, the model first constructs a JSON-style blueprint that records the positions, sizes, and attributes of relevant objects, and then reasons over this structured representation to produce the final answer. To achieve this, we introduce three key techniques: (1) blueprint-embedded reasoning traces for supervised fine-tuning to elicit basic reasoning skills; (2) blueprint-aware rewards in reinforcement learning to encourage the blueprint to include an appropriate number of objects and to align final answers with this causal reasoning; and (3) anti-shortcut data augmentation that applies targeted perturbations to images and questions, discouraging reliance on superficial visual or linguistic cues. Experiments show that our method consistently outperforms existing VLMs and specialized spatial reasoning models.","authors":["Weijian Ma","Shizhao Sun","Tianyu Yu","Ruiyu Wang","Tat-Seng Chua","Jiang Bian"],"pdf_url":"","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2512.05539v2","updated":"2026-01-05T10:20:11Z","published":"2025-12-05T08:53:11Z","title":"Ideal Observer for Segmentation of Dead Leaves Images","summary":"The human visual environment is comprised of different surfaces that are distributed in space. The parts of a scene that are visible at any one time are governed by the occlusion of overlapping objects. In this work we consider \"dead leaves\" models, which replicate these occlusions when generating images by layering objects on top of each other. A dead leaves model is a generative model comprised of distributions for object position, shape, color and texture. An image is generated from a dead leaves model by sampling objects (\"leaves\") from these distributions until a stopping criterion is reached, usually when the image is fully covered or until a given number of leaves was sampled. Here, we describe a theoretical approach, based on previous work, to derive a Bayesian ideal observer for the partition of a given set of pixels based on independent dead leaves model distributions. Extending previous work, we provide step-by-step explanations for the computation of the posterior probability as well as describe factors that determine the feasibility of practically applying this computation. The dead leaves image model and the associated ideal observer can be applied to study segmentation decisions in a limited number of pixels, providing a principled upper-bound on performance, to which humans and vision algorithms could be compared.","authors":["Swantje Mahncke","Malte Ott"],"pdf_url":"","comment":"41 pages, 16 figures"},{"id":"http://arxiv.org/abs/2512.11480v2","updated":"2026-01-05T10:15:00Z","published":"2025-12-12T11:29:59Z","title":"CADMorph: Geometry-Driven Parametric CAD Editing via a Plan-Generate-Verify Loop","summary":"A Computer-Aided Design (CAD) model encodes an object in two coupled forms: a parametric construction sequence and its resulting visible geometric shape. During iterative design, adjustments to the geometric shape inevitably require synchronized edits to the underlying parametric sequence, called geometry-driven parametric CAD editing. The task calls for 1) preserving the original sequence's structure, 2) ensuring each edit's semantic validity, and 3) maintaining high shape fidelity to the target shape, all under scarce editing data triplets. We present CADMorph, an iterative plan-generate-verify framework that orchestrates pretrained domain-specific foundation models during inference: a parameter-to-shape (P2S) latent diffusion model and a masked-parameter-prediction (MPP) model. In the planning stage, cross-attention maps from the P2S model pinpoint the segments that need modification and offer editing masks. The MPP model then infills these masks with semantically valid edits in the generation stage. During verification, the P2S model embeds each candidate sequence in shape-latent space, measures its distance to the target shape, and selects the closest one. The three stages leverage the inherent geometric consciousness and design knowledge in pretrained priors, and thus tackle structure preservation, semantic validity, and shape fidelity respectively. Besides, both P2S and MPP models are trained without triplet data, bypassing the data-scarcity bottleneck. CADMorph surpasses GPT-4o and specialized CAD baselines, and supports downstream applications such as iterative editing and reverse-engineering enhancement.","authors":["Weijian Ma","Shizhao Sun","Ruiyu Wang","Jiang Bian"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2506.09040v2","updated":"2026-01-05T10:14:19Z","published":"2025-06-10T17:57:50Z","title":"Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better","summary":"Typical large vision-language models (LVLMs) apply autoregressive supervision solely to textual sequences, without fully incorporating the visual modality into the learning process. This results in three key limitations: (1) an inability to utilize images without accompanying captions, (2) the risk that captions omit critical visual details, and (3) the challenge that certain vision-centric content cannot be adequately conveyed through text. As a result, current LVLMs often prioritize vision-to-language alignment while potentially overlooking fine-grained visual information. While some prior works have explored autoregressive image generation, effectively leveraging autoregressive visual supervision to enhance image understanding remains an open challenge. In this paper, we introduce Autoregressive Semantic Visual Reconstruction (ASVR), which enables joint learning of visual and textual modalities within a unified autoregressive framework. We show that autoregressively reconstructing the raw visual appearance of images does not enhance and may even impair multimodal understanding. In contrast, autoregressively reconstructing the semantic representation of images consistently improves comprehension. Notably, we find that even when models are given continuous image features as input, they can effectively reconstruct discrete semantic tokens, resulting in stable and consistent improvements across a wide range of multimodal understanding benchmarks. Our approach delivers significant performance gains across varying data scales (556k-2M) and types of LLM bacbones. Specifically, ASVR improves LLaVA-1.5 by 5% in average scores across 14 multimodal benchmarks. The code is available at https://github.com/AlenjandroWang/ASVR.","authors":["Dianyi Wang","Wei Song","Yikun Wang","Siyuan Wang","Kaicheng Yu","Zhongyu Wei","Jiaqi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01963v1","updated":"2026-01-05T10:14:16Z","published":"2026-01-05T10:14:16Z","title":"Forget Less by Learning Together through Concept Consolidation","summary":"Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.","authors":["Arjun Ramesh Kaushik","Naresh Kumar Devulapally","Vishnu Suresh Lokhande","Nalini Ratha","Venu Govindaraju"],"pdf_url":"","comment":"Accepted at WACV-26"},{"id":"http://arxiv.org/abs/2601.01957v1","updated":"2026-01-05T10:02:22Z","published":"2026-01-05T10:02:22Z","title":"AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing","summary":"Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.","authors":["Tianbo Wang","Yuqing Ma","Kewei Liao","Zhange Zhang","Simin Li","Jinyang Guo","Xianglong Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01955v1","updated":"2026-01-05T10:01:27Z","published":"2026-01-05T10:01:27Z","title":"MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization","summary":"Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \\romannumeral1) explicit disentanglement of motion from appearance and \\romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.","authors":["Zhexin Zhang","Yifeng Zhu","Yangyang Xu","Long Chen","Yong Du","Shengfeng He","Jun Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01950v1","updated":"2026-01-05T09:57:24Z","published":"2026-01-05T09:57:24Z","title":"Face Normal Estimation from Rags to Riches","summary":"Although recent approaches to face normal estimation have achieved promising results, their effectiveness heavily depends on large-scale paired data for training. This paper concentrates on relieving this requirement via developing a coarse-to-fine normal estimator. Concretely, our method first trains a neat model from a small dataset to produce coarse face normals that perform as guidance (called exemplars) for the following refinement. A self-attention mechanism is employed to capture long-range dependencies, thus remedying severe local artifacts left in estimated coarse facial normals. Then, a refinement network is customized for the sake of mapping input face images together with corresponding exemplars to fine-grained high-quality facial normals. Such a logical function split can significantly cut the requirement of massive paired data and computational resource. Extensive experiments and ablation studies are conducted to demonstrate the efficacy of our design and reveal its superiority over state-of-the-art methods in terms of both training expense as well as estimation quality. Our code and models are open-sourced at: https://github.com/AutoHDR/FNR2R.git.","authors":["Meng Wang","Wenjing Dai","Jiawan Zhang","Xiaojie Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.10977v2","updated":"2026-01-05T09:49:06Z","published":"2024-12-14T21:39:43Z","title":"Point Cloud to Mesh Reconstruction: Methods, Trade-offs, and Implementation Guide","summary":"Reconstructing meshes from point clouds is a fundamental task in computer vision with applications spanning robotics, autonomous systems, and medical imaging. Selecting an appropriate learning-based method requires understanding trade-offs between computational efficiency, geometric accuracy, and output constraints. This paper categorizes over fifteen methods into five paradigms -- PointNet family, autoencoder architectures, deformation-based methods, point-move techniques, and primitive-based approaches -- and provides practical guidance for method selection. We contribute: (1) a decision framework mapping input/output requirements to suitable paradigms, (2) a failure mode analysis to assist practitioners in debugging implementations, (3) standardized comparisons on ShapeNet benchmarks, and (4) a curated list of maintained codebases with implementation resources. By synthesizing both theoretical foundations and practical considerations, this work serves as an entry point for practitioners and researchers new to learning-based 3D mesh reconstruction.","authors":["Fatima Zahra Iguenfer","Achraf Hsain","Hiba Amissa","Yousra Chtouki"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01926v1","updated":"2026-01-05T09:18:09Z","published":"2026-01-05T09:18:09Z","title":"MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering","summary":"Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.","authors":["Zhifei Li","Yiran Wang","Chenyi Xiong","Yujing Xia","Xiaoju Hou","Yue Zhao","Miao Zhang","Kui Xiao","Bing Yang"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2601.01925v1","updated":"2026-01-05T09:17:28Z","published":"2026-01-05T09:17:28Z","title":"AR-MOT: Autoregressive Multi-object Tracking","summary":"As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.","authors":["Lianjie Jia","Yuhan Wu","Binghao Ran","Yifan Wang","Lijun Wang","Huchuan Lu"],"pdf_url":"","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.18539v2","updated":"2026-01-05T09:17:12Z","published":"2024-11-27T17:36:08Z","title":"AdaVLN: Towards Visual Language Navigation in Continuous Indoor Environments with Moving Humans","summary":"Visual Language Navigation is a task that challenges robots to navigate in realistic environments based on natural language instructions. While previous research has largely focused on static settings, real-world navigation must often contend with dynamic human obstacles. Hence, we propose an extension to the task, termed Adaptive Visual Language Navigation (AdaVLN), which seeks to narrow this gap. AdaVLN requires robots to navigate complex 3D indoor environments populated with dynamically moving human obstacles, adding a layer of complexity to navigation tasks that mimic the real-world. To support exploration of this task, we also present AdaVLN simulator and AdaR2R datasets. The AdaVLN simulator enables easy inclusion of fully animated human models directly into common datasets like Matterport3D. We also introduce a \"freeze-time\" mechanism for both the navigation task and simulator, which pauses world state updates during agent inference, enabling fair comparisons and experimental reproducibility across different hardware. We evaluate several baseline models on this task, analyze the unique challenges introduced by AdaVLN, and demonstrate its potential to bridge the sim-to-real gap in VLN research.","authors":["Dillon Loh","Tomasz Bednarz","Xinxing Xia","Frank Guan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23239v2","updated":"2026-01-05T09:01:02Z","published":"2025-12-29T06:44:06Z","title":"RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models","summary":"Diffusion-based remote sensing (RS) generative foundation models are cruial for downstream tasks. However, these models rely on large amounts of globally representative data, which often contain redundancy, noise, and class imbalance, reducing training efficiency and preventing convergence. Existing RS diffusion foundation models typically aggregate multiple classification datasets or apply simplistic deduplication, overlooking the distributional requirements of generation modeling and the heterogeneity of RS imagery. To address these limitations, we propose a training-free, two-stage data pruning approach that quickly select a high-quality subset under high pruning ratios, enabling a preliminary foundation model to converge rapidly and serve as a versatile backbone for generation, downstream fine-tuning, and other applications. Our method jointly considers local information content with global scene-level diversity and representativeness. First, an entropy-based criterion efficiently removes low-information samples. Next, leveraging RS scene classification datasets as reference benchmarks, we perform scene-aware clustering with stratified sampling to improve clustering effectiveness while reducing computational costs on large-scale unlabeled data. Finally, by balancing cluster-level uniformity and sample representativeness, the method enables fine-grained selection under high pruning ratios while preserving overall diversity and representativeness. Experiments show that, even after pruning 85\\% of the training data, our method significantly improves convergence and generation quality. Furthermore, diffusion foundation models trained with our method consistently achieve state-of-the-art performance across downstream tasks, including super-resolution and semantic image synthesis. This data pruning paradigm offers practical guidance for developing RS generative foundation models.","authors":["Fan Wei","Runmin Dong","Yushan Lai","Yixiang Yang","Zhaoyang Luo","Jinxiao Zhang","Miao Yang","Shuai Yuan","Jiyao Zhao","Bin Luo","Haohuan Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01915v1","updated":"2026-01-05T09:00:32Z","published":"2026-01-05T09:00:32Z","title":"TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing","summary":"Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.","authors":["Yujie Hu","Zecheng Tang","Xu Jiang","Weiqi Li","Jian Zhang"],"pdf_url":"","comment":"a Conversational Assistant for Intelligent Image Editing"},{"id":"http://arxiv.org/abs/2601.01914v1","updated":"2026-01-05T08:59:07Z","published":"2026-01-05T08:59:07Z","title":"Learning Action Hierarchies via Hybrid Geometric Diffusion","summary":"Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.","authors":["Arjun Ramesh Kaushik","Nalini K. Ratha","Venu Govindaraju"],"pdf_url":"","comment":"Accepted at WACV-26"},{"id":"http://arxiv.org/abs/2601.01908v1","updated":"2026-01-05T08:53:04Z","published":"2026-01-05T08:53:04Z","title":"Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection","summary":"Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.","authors":["Jingjing Wang","Qianglin Liu","Zhuo Xiao","Xinning Yao","Bo Liu","Lu Li","Lijuan Niu","Fugen Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01892v1","updated":"2026-01-05T08:35:36Z","published":"2026-01-05T08:35:36Z","title":"Forget Less by Learning from Parents Through Hierarchical Relationships","summary":"Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.","authors":["Arjun Ramesh Kaushik","Naresh Kumar Devulapally","Vishnu Suresh Lokhande","Nalini K. Ratha","Venu Govindaraju"],"pdf_url":"","comment":"Accepted at AAAI-26"},{"id":"http://arxiv.org/abs/2601.01891v1","updated":"2026-01-05T08:34:17Z","published":"2026-01-05T08:34:17Z","title":"Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems","summary":"The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.","authors":["Niloufar Alipour Talemi","Julia Boone","Fatemeh Afghah"],"pdf_url":"","comment":"Accepted to the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026, GeoCV Workshop"},{"id":"http://arxiv.org/abs/2601.01874v1","updated":"2026-01-05T08:02:18Z","published":"2026-01-05T08:02:18Z","title":"CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving","summary":"Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\\Rightarrow$internalization$\\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.","authors":["Shuhang Chen","Yunqiu Xu","Junjie Xie","Aojun Lu","Tao Feng","Zeying Huang","Ning Zhang","Yi Sun","Yi Yang","Hangjie Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.22425v4","updated":"2026-01-05T08:01:23Z","published":"2025-11-27T13:03:57Z","title":"Wukong's 72 Transformations: High-fidelity Textured 3D Morphing via Flow Models","summary":"We present WUKONG, a novel training-free framework for high-fidelity textured 3D morphing that takes a pair of source and target prompts (image or text) as input. Unlike conventional methods -- which rely on manual correspondence matching and deformation trajectory estimation (limiting generalization and requiring costly preprocessing) -- WUKONG leverages the generative prior of flow-based transformers to produce high-fidelity 3D transitions with rich texture details. To ensure smooth shape transitions, we exploit the inherent continuity of flow-based generative processes and formulate morphing as an optimal transport barycenter problem. We further introduce a sequential initialization strategy to prevent abrupt geometric distortions and preserve identity coherence. For faithful texture preservation, we propose a similarity-guided semantic consistency mechanism that selectively retains high-frequency details and enables precise control over blending dynamics. This empowers WUKONG to support both global texture transitions and identity-preserving texture morphing, catering to diverse generation needs. Extensive quantitative and qualitative evaluations demonstrate that WUKONG significantly outperforms state-of-the-art methods, achieving superior results across diverse geometry and texture variations.","authors":["Minghao Yin","Yukang Cao","Kai Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01870v1","updated":"2026-01-05T08:00:03Z","published":"2026-01-05T08:00:03Z","title":"Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion","summary":"Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.","authors":["Wenyu Shao","Hongbo Liu","Yunchuan Ma","Ruili Wang"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2601.01865v1","updated":"2026-01-05T07:50:59Z","published":"2026-01-05T07:50:59Z","title":"RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations","summary":"With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.","authors":["Wenlong Yang","Canran Jin","Weihang Yuan","Chao Wang","Lifeng Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.02565v3","updated":"2026-01-05T07:34:56Z","published":"2024-12-03T16:53:58Z","title":"SJTU:Spatial judgments in multimodal models towards unified segmentation through coordinate detection","summary":"Despite significant advances in vision-language understanding, implementing image segmentation within multimodal architectures remains a fundamental challenge in modern artificial intelligence systems. Existing vision-language models, which primarily rely on backbone architectures or CLIP-based embedding learning, demonstrate inherent limitations in fine-grained spatial localization and operational capabilities. This paper introduces SJTU: Spatial Judgments in Multimodal Models - Towards Unified Segmentation through Coordinate Detection, a framework that leverages spatial coordinate understanding to bridge vision-language interaction and precise segmentation, enabling accurate target identification through natural language instructions. The framework presents an approach for integrating segmentation techniques with vision-language models through spatial inference in multimodal space. By utilizing normalized coordinate detection for bounding boxes and transforming them into actionable segmentation outputs, we establish a connection between spatial and language representations in multimodal architectures. Experimental results demonstrate superior performance across benchmark datasets, achieving IoU scores of 0.5958 on COCO 2017 and 0.6758 on Pascal VOC. Testing on a single NVIDIA RTX 3090 GPU with 512x512 resolution images yields an average inference time of 7 seconds per image, demonstrating the framework's effectiveness in both accuracy and practical deployability. The project code is available at https://github.com/jw-chae/SJTU","authors":["Joongwon Chae","Zhenyu Wang","Peiwu Qin"],"pdf_url":"","comment":"A flaw was discovered in the experimental setup. Therefore, we are retracting the paper"},{"id":"http://arxiv.org/abs/2601.01856v1","updated":"2026-01-05T07:33:50Z","published":"2026-01-05T07:33:50Z","title":"GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection","summary":"Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.\n  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.\n  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR","authors":["Joongwon Chae","Lihui Luo","Yang Liu","Runming Wang","Dongmei Yu","Zeming Liang","Xi Yuan","Dayan Zhang","Zhenglin Chen","Peiwu Qin","Ilmoon Chae"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01847v1","updated":"2026-01-05T07:19:38Z","published":"2026-01-05T07:19:38Z","title":"ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting","summary":"Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.","authors":["Chuhang Ma","Shuai Tan","Ye Pan","Jiaolong Yang","Xin Tong"],"pdf_url":"","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2601.01835v1","updated":"2026-01-05T06:57:26Z","published":"2026-01-05T06:57:26Z","title":"RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images","summary":"In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.","authors":["Rashid Iqbal","Saddam Hussain Khan"],"pdf_url":"","comment":"15 Pages, 7 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2601.01822v1","updated":"2026-01-05T06:31:24Z","published":"2026-01-05T06:31:24Z","title":"DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization","summary":"Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.","authors":["Shiyong Meng","Tao Zou","Bolei Chen","Chaoxu Mu","Jianxin Wang"],"pdf_url":"","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.01818v1","updated":"2026-01-05T06:14:41Z","published":"2026-01-05T06:14:41Z","title":"Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning","summary":"As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.","authors":["Sungjune Park","Hongda Mao","Qingshuang Chen","Yong Man Ro","Yelin Kim"],"pdf_url":"","comment":"11 pages, 7 figures, 4 tables"},{"id":"http://arxiv.org/abs/2601.01807v1","updated":"2026-01-05T05:35:45Z","published":"2026-01-05T05:35:45Z","title":"Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification","summary":"Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.","authors":[" Ubaidullah","Muhammad Abid Hussain","Mohsin Raza Jafri","Rozi Khan","Moid Sandhu","Abd Ullah Khan","Hyundong Shin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01804v1","updated":"2026-01-05T05:30:13Z","published":"2026-01-05T05:30:13Z","title":"Causality-Aware Temporal Projection for Video Understanding in Video-LLMs","summary":"Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.","authors":["Zhengjian Kang","Qi Chen","Rui Liu","Kangtong Mo","Xingyu Zhang","Xiaoyu Deng","Ye Zhang"],"pdf_url":"","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.01798v1","updated":"2026-01-05T05:16:07Z","published":"2026-01-05T05:16:07Z","title":"VerLM: Explaining Face Verification Using Natural Language","summary":"Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.","authors":["Syed Abdul Hannan","Hazim Bukhari","Thomas Cantalapiedra","Eman Ansar","Massa Baali","Rita Singh","Bhiksha Raj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11176v3","updated":"2026-01-05T04:58:57Z","published":"2025-10-13T09:08:59Z","title":"G2L:From Giga-Scale to Cancer-Specific Large-Scale Pathology Foundation Models via Knowledge Distillation","summary":"Recent studies in pathology foundation models have shown that scaling training data, diversifying cancer types, and increasing model size consistently improve their performance. However, giga-scale foundation models, which are trained on hundreds of thousands of slides covering tens of cancer types and contain billions of parameters, pose significant challenges for practical use due to their tremendous computational costs in both development and deployment. In this work, we present a novel strategy, named the G2L framework, to increase the performance of large-scale foundation models, which consist of only $15\\%$ of the parameters of giga-scale models, to a comparable performance level of giga-scale models in cancer-specific tasks. Our approach applies knowledge distillation, transferring the capabilities of a giga-scale model to a large-scale model, using just 1K pathology slides of a target cancer (e.g., breast, prostate, etc.). The resulting distilled model not only outperformed state-of-the-art models of the same size (i.e., large-scale) across several benchmarks but also, interestingly, surpassed the giga-scale teacher and huge-scale models in some benchmarks. In addition, the distilled model exhibited a higher robustness index, indicating improved resilience to image variations originating from multiple institutions. These findings suggest that the proposed distillation approach for a large-scale model is a data- and parameter-efficient way to achieve giga-scale-level performance for cancer-specific applications without prohibitive computational burden.","authors":["Yesung Cho","Sungmin Lee","Geongyu Lee","Minkyung Lee","Jongbae Park","Dongmyung Shin"],"pdf_url":"","comment":"Accepted in AAAI 2026 workshop in Health Intelligence Special Theme on Foundation Models and AI Agents"},{"id":"http://arxiv.org/abs/2512.23162v3","updated":"2026-01-05T04:58:32Z","published":"2025-12-29T03:03:00Z","title":"SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling","summary":"Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.","authors":["Yufan He","Pengfei Guo","Mengya Xu","Zhaoshuo Li","Andriy Myronenko","Dillan Imans","Bingjie Liu","Dongren Yang","Mingxue Gu","Yongnan Ji","Yueming Jin","Ren Zhao","Baiyong Shen","Daguang Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.23541v2","updated":"2026-01-05T04:49:09Z","published":"2025-09-28T00:41:22Z","title":"OVSeg3R: Learn Open-vocabulary Instance Segmentation from 2D via 3D Reconstruction","summary":"In this paper, we propose a training scheme called OVSeg3R to learn open-vocabulary 3D instance segmentation from well-studied 2D perception models with the aid of 3D reconstruction. OVSeg3R directly adopts reconstructed scenes from 2D videos as input, avoiding costly manual adjustment while aligning input with real-world applications. By exploiting the 2D to 3D correspondences provided by 3D reconstruction models, OVSeg3R projects each view's 2D instance mask predictions, obtained from an open-vocabulary 2D model, onto 3D to generate annotations for the view's corresponding sub-scene. To avoid incorrectly introduced false positives as supervision due to partial annotations from 2D to 3D, we propose a View-wise Instance Partition algorithm, which partitions predictions to their respective views for supervision, stabilizing the training process. Furthermore, since 3D reconstruction models tend to over-smooth geometric details, clustering reconstructed points into representative super-points based solely on geometry, as commonly done in mainstream 3D segmentation methods, may overlook geometrically non-salient objects. We therefore introduce 2D Instance Boundary-aware Superpoint, which leverages 2D masks to constrain the superpoint clustering, preventing superpoints from violating instance boundaries. With these designs, OVSeg3R not only extends a state-of-the-art closed-vocabulary 3D instance segmentation model to open-vocabulary, but also substantially narrows the performance gap between tail and head classes, ultimately leading to an overall improvement of +2.3 mAP on the ScanNet200 benchmark. Furthermore, under the standard open-vocabulary setting, OVSeg3R surpasses previous methods by about +7.1 mAP on the novel classes, further validating its effectiveness.","authors":["Hongyang Li","Jinyuan Qu","Lei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01784v1","updated":"2026-01-05T04:35:39Z","published":"2026-01-05T04:35:39Z","title":"DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization","summary":"The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \\emph{local view}, failing to capture global anomalies. To address this, we propose a \\underline{d}ual-stream graph learning and \\underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \\emph{Temporal Distance Stream} for local artifacts and a \\emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\\% in AP@0.95, with significant improvements in cross-domain robustness.","authors":["Boyang Zhao","Xin Liao","Jiaxin Chen","Xiaoshuai Wu","Yufeng Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01781v1","updated":"2026-01-05T04:28:49Z","published":"2026-01-05T04:28:49Z","title":"Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery","summary":"Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \\href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.","authors":["Lakshay Sharma","Alex Marin"],"pdf_url":"","comment":"Accepted at CV4EO Workshop at WACV 2026"},{"id":"http://arxiv.org/abs/2512.17229v2","updated":"2026-01-05T04:25:02Z","published":"2025-12-19T04:29:07Z","title":"Video Detective: Seek Critical Clues Recurrently to Answer Question from Long Videos","summary":"Long Video Question-Answering (LVQA) presents a significant challenge for Multi-modal Large Language Models (MLLMs) due to immense context and overloaded information, which could also lead to prohibitive memory consumption. While existing methods attempt to address these issues by reducing visual tokens or extending model's context length, they may miss useful information or take considerable computation. In fact, when answering given questions, only a small amount of crucial information is required. Therefore, we propose an efficient question-aware memory mechanism, enabling MLLMs to recurrently seek these critical clues. Our approach, named VideoDetective, simplifies this task by iteratively processing video sub-segments. For each sub-segment, a question-aware compression strategy is employed by introducing a few special memory tokens to achieve purposefully compression. This allows models to effectively seek critical clues while reducing visual tokens. Then, due to history context could have a significant impact, we recurrently aggregate and store these memory tokens to update history context, which would be reused for subsequent sub-segments. Furthermore, to more effectively measure model's long video understanding ability, we introduce GLVC (Grounding Long Video Clues), a long video question-answering dataset, which features grounding critical and concrete clues scattered throughout entire videos. Experimental results demonstrate our method enables MLLMs with limited context length of 32K to efficiently process 100K tokens (3600 frames, an hour-long video sampled at 1fps), requiring only 2 minutes and 37GB GPU memory usage. Evaluation results across multiple long video benchmarks illustrate our method can more effectively seek critical clues from massive information.","authors":["Henghui Du","Chunjie Zhang","Xi Chen","Chang Zhou","Di Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03663v3","updated":"2026-01-05T04:16:18Z","published":"2025-10-04T04:30:13Z","title":"UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG","summary":"Multimodal retrieval-augmented Generation (MM-RAG) is a key approach for applying large language models (LLMs) and agents to real-world knowledge bases, yet current evaluations are fragmented -- focusing on either text or images in isolation, or simplified multimodal setup, failing to capture document-centric multimodal use cases. In this paper, we introduce UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from $k$ real-world PDF pages across domains. Our pipeline extracts and links evidence from text, tables, and figures, then generates multimodal QA pairs spanning factual retrieval, comparison, summarization, and logical reasoning queries. To ensure reliability, all of QA pairs are validated by multiple human annotators and expert adjudication. UniDoc-Bench supports apples-to-apples comparison across four paradigms: 1) text-only, 2) image-only, 3) \\emph{multimodal} text-image fusion and 4) multimodal joint retrieval -- under a unified protocol with standardized candidate pools, prompts, and evaluation metrics. UniDoc-Bench can also be used to evaluate Visual Question Answering (VQA) tasks. Our experiments show that multimodal text-image fusion RAG systems consistently outperform both unimodal and jointly multimodal embedding-based retrieval, indicating that neither text nor images alone are sufficient and that current multimodal embeddings remain inadequate. Beyond benchmarking, our analysis reveals when and how visual context complements textual evidence, uncovers systematic failure modes, and offers actionable guidance for developing more robust MM-RAG pipelines.","authors":["Xiangyu Peng","Can Qin","Zeyuan Chen","Ran Xu","Caiming Xiong","Chien-Sheng Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2309.07926v2","updated":"2026-01-05T04:09:42Z","published":"2023-09-11T14:05:18Z","title":"COMPASS: High-Efficiency Deep Image Compression with Arbitrary-scale Spatial Scalability","summary":"Recently, neural network (NN)-based image compression studies have actively been made and has shown impressive performance in comparison to traditional methods. However, most of the works have focused on non-scalable image compression (single-layer coding) while spatially scalable image compression has drawn less attention although it has many applications. In this paper, we propose a novel NN-based spatially scalable image compression method, called COMPASS, which supports arbitrary-scale spatial scalability. Our proposed COMPASS has a very flexible structure where the number of layers and their respective scale factors can be arbitrarily determined during inference. To reduce the spatial redundancy between adjacent layers for arbitrary scale factors, our COMPASS adopts an inter-layer arbitrary scale prediction method, called LIFF, based on implicit neural representation. We propose a combined RD loss function to effectively train multiple layers. Experimental results show that our COMPASS achieves BD-rate gain of -58.33% and -47.17% at maximum compared to SHVC and the state-of-the-art NN-based spatially scalable image compression method, respectively, for various combinations of scale factors. Our COMPASS also shows comparable or even better coding efficiency than the single-layer coding for various scale factors.","authors":["Jongmin Park","Jooyoung Lee","Munchurl Kim"],"pdf_url":"","comment":"Accepted in ICCV 2023. Please visit our project page at https://kaist-viclab.github.io/compass-site/"},{"id":"http://arxiv.org/abs/2508.06084v2","updated":"2026-01-05T04:04:30Z","published":"2025-08-08T07:27:26Z","title":"AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance","summary":"Vision-language models (VLMs) have achieved impressive performance on multimodal reasoning tasks such as visual question answering, image captioning and so on, but their inference cost remains a significant challenge due to the large number of vision tokens processed during the prefill stage. Existing pruning methods often rely on directly using the attention patterns or static text prompt guidance, failing to exploit the dynamic internal signals generated during inference. To address these issues, we propose AdaptInfer, a plug-and-play framework for adaptive vision token pruning in VLMs. First, we introduce a fine-grained, dynamic text-guided pruning mechanism that reuses layer-wise text-to-text attention maps to construct soft priors over text-token importance, allowing more informed scoring of vision tokens at each stage. Second, we perform an offline analysis of cross-modal attention shifts and identify consistent inflection locations in inference, which inspire us to propose a more principled and efficient pruning schedule. Our method is lightweight and plug-and-play, also generalizable across multi-modal tasks. Experimental results have verified the effectiveness of the proposed method. For example, it reduces CUDA latency by 61.3% while maintaining an average accuracy of 93.1% on vanilla LLaVA-1.5-7B. Under the same token budget, AdaptInfer surpasses SOTA in accuracy.","authors":["Weichen Zhang","Zhui Zhu","Ningbo Li","Shilong Tao","Kebin Liu","Yunhao Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01769v1","updated":"2026-01-05T03:54:02Z","published":"2026-01-05T03:54:02Z","title":"CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology","summary":"In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.","authors":["Hao Lu","Ziniu Qian","Yifu Li","Yang Zhou","Bingzheng Wei","Yan Xu"],"pdf_url":"","comment":"The paper has been accepted by BIBM 2025"},{"id":"http://arxiv.org/abs/2601.01762v1","updated":"2026-01-05T03:41:20Z","published":"2026-01-05T03:41:20Z","title":"AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving","summary":"End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety","authors":["Yanhao Wu","Haoyang Zhang","Fei He","Rui Wu","Congpei Qiu","Liang Gao","Wei Ke","Tong Zhang"],"pdf_url":"","comment":"underreview"},{"id":"http://arxiv.org/abs/2506.21656v3","updated":"2026-01-05T03:33:59Z","published":"2025-06-26T18:00:00Z","title":"Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs","summary":"Current Vision-Language Models (VLMs) struggle with fine-grained spatial reasoning, particularly when multi-step logic and precise spatial alignment are required. In this work, we introduce SpatialReasoner-R1, a vision-language reasoning model designed to address these limitations. To construct high-quality supervision for spatial reasoning, we design a Multi-Model Monte Carlo Tree Search (M3CTS) method that generates diverse, logically consistent Long Chain-of-Thought (LongCOT) reasoning trajectories. In addition, we propose a fine-grained Direct Preference Optimization (fDPO) method that introduces segment-specific preference granularity for descriptive grounding and logical reasoning, guided by a spatial reward mechanism that evaluates candidate responses based on visual consistency, spatial grounding, and logical coherence. Experimental results demonstrate that fDPO achieves relative performance gains of 4.1% and 9.0% over standard DPO on spatial qualitative and quantitative tasks, respectively. SpatialReasoner-R1, trained with fDPO, sets a new SoTA on SpatialRGPT-Bench, outperforming the strongest baseline by 9.4% in average accuracy, while maintaining competitive performance on general vision-language tasks.","authors":["Yifan Shen","Yuanzhe Liu","Jingyuan Zhu","Xu Cao","Xiaofeng Zhang","Yixiao He","Wenming Ye","James Matthew Rehg","Ismini Lourentzou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12718v2","updated":"2026-01-05T03:00:31Z","published":"2025-12-14T14:43:42Z","title":"Spinal Line Detection for Posture Evaluation through Train-ing-free 3D Human Body Reconstruction with 2D Depth Images","summary":"The spinal angle is an important indicator of body balance. It is important to restore the 3D shape of the human body and estimate the spine center line. Existing mul-ti-image-based body restoration methods require expensive equipment and complex pro-cedures, and single image-based body restoration methods have limitations in that it is difficult to accurately estimate the internal structure such as the spine center line due to occlusion and viewpoint limitation. This study proposes a method to compensate for the shortcomings of the multi-image-based method and to solve the limitations of the sin-gle-image method. We propose a 3D body posture analysis system that integrates depth images from four directions to restore a 3D human model and automatically estimate the spine center line. Through hierarchical matching of global and fine registration, restora-tion to noise and occlusion is performed. Also, the Adaptive Vertex Reduction is applied to maintain the resolution and shape reliability of the mesh, and the accuracy and stabil-ity of spinal angle estimation are simultaneously secured by using the Level of Detail en-semble. The proposed method achieves high-precision 3D spine registration estimation without relying on training data or complex neural network models, and the verification confirms the improvement of matching quality.","authors":["Sehyun Kim","Hye Jun Lee","Jiwoo Lee","Changgyun Kim","Taemin Lee"],"pdf_url":"","comment":"GitHub, see https://github.com/DevChoco/TF3D_SpineDetect"},{"id":"http://arxiv.org/abs/2601.01749v1","updated":"2026-01-05T02:59:49Z","published":"2026-01-05T02:59:49Z","title":"MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement","summary":"Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.","authors":["Lei Zhu","Lijian Lin","Ye Zhu","Jiahao Wu","Xuehan Hou","Yu Li","Yunfei Liu","Jie Chen"],"pdf_url":"","comment":"20 pages, 11i figures"},{"id":"http://arxiv.org/abs/2601.01747v1","updated":"2026-01-05T02:49:33Z","published":"2026-01-05T02:49:33Z","title":"Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization","summary":"Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs","authors":["Jiwei Guan","Haibo Jin","Haohan Wang"],"pdf_url":"","comment":"EACL"},{"id":"http://arxiv.org/abs/2601.01746v1","updated":"2026-01-05T02:44:21Z","published":"2026-01-05T02:44:21Z","title":"Point-SRA: Self-Representation Alignment for 3D Representation Learning","summary":"Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.","authors":["Lintong Wei","Jian Lu","Haozhe Cheng","Jihua Zhu","Kaibing Zhang"],"pdf_url":"","comment":"This is an AAAI 2026 accepted paper titled \"Point-SRA: Self-Representation Alignment for 3D Representation Learning\", spanning 13 pages in total. The submission includes 7 figures (fig1 to fig7) that visually support the technical analysis"},{"id":"http://arxiv.org/abs/2511.05836v3","updated":"2026-01-05T02:42:50Z","published":"2025-11-08T04:05:24Z","title":"Training-Free Adaptive Quantization for Variable Rate Image Coding for Machines","summary":"Image Coding for Machines (ICM) has become increasingly important with the rapid integration of computer vision technology into real-world applications. However, most neural network-based ICM frameworks operate at a fixed rate, thus requiring individual training for each target bitrate. This limitation may restrict their practical usage. Existing variable rate image compression approaches mitigate this issue but often rely on additional training, which increases computational costs and complicates deployment. Moreover, variable rate control has not been thoroughly explored for ICM. To address these challenges, we propose a training-free framework for quantization strength control which enables flexible bitrate adjustment. By exploiting the scale parameter predicted by the hyperprior network, the proposed method adaptively modulates quantization step sizes across both channel and spatial dimensions. This allows the model to preserve semantically important regions while coarsely quantizing less critical areas. Our architectural design further enables continuous bitrate control through a single parameter. Experimental results demonstrate the effectiveness of our proposed method, achieving up to 11.07% BD-rate savings over the non-adaptive variable rate baseline. The code is available at https://github.com/qwert-top/AQVR-ICM.","authors":["Yui Tatsumi","Ziyue Zeng","Hiroshi Watanabe"],"pdf_url":"","comment":"Accepted to IEEE 44th International Conference on Consumer Electronics (ICCE 2026)"},{"id":"http://arxiv.org/abs/2412.21059v4","updated":"2026-01-05T02:39:01Z","published":"2024-12-30T16:24:09Z","title":"VisionReward: Fine-Grained Multi-Dimensional Human Preference Learning for Image and Video Generation","summary":"Visual generative models have achieved remarkable progress in synthesizing photorealistic images and videos, yet aligning their outputs with human preferences across critical dimensions remains a persistent challenge. Though reinforcement learning from human feedback offers promise for preference alignment, existing reward models for visual generation face limitations, including black-box scoring without interpretability and potentially resultant unexpected biases. We present VisionReward, a general framework for learning human visual preferences in both image and video generation. Specifically, we employ a hierarchical visual assessment framework to capture fine-grained human preferences, and leverages linear weighting to enable interpretable preference learning. Furthermore, we propose a multi-dimensional consistent strategy when using VisionReward as a reward model during preference optimization for visual generation. Experiments show that VisionReward can significantly outperform existing image and video reward models on both machine metrics and human evaluation. Notably, VisionReward surpasses VideoScore by 17.2% in preference prediction accuracy, and text-to-video models with VisionReward achieve a 31.6% higher pairwise win rate compared to the same models using VideoScore. All code and datasets are provided at https://github.com/THUDM/VisionReward.","authors":["Jiazheng Xu","Yu Huang","Jiale Cheng","Yuanming Yang","Jiajun Xu","Yuan Wang","Wenbo Duan","Shen Yang","Qunlin Jin","Shurun Li","Jiayan Teng","Zhuoyi Yang","Wendi Zheng","Xiao Liu","Dan Zhang","Ming Ding","Xiaohan Zhang","Xiaotao Gu","Shiyu Huang","Minlie Huang","Jie Tang","Yuxiao Dong"],"pdf_url":"","comment":"27 pages"},{"id":"http://arxiv.org/abs/2401.09716v2","updated":"2026-01-05T02:33:19Z","published":"2024-01-18T04:23:21Z","title":"HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization","summary":"Domain Generalization (DG) endeavors to create machine learning models that excel in unseen scenarios by learning invariant features. In DG, the prevalent practice of constraining models to a fixed structure or uniform parameterization to encapsulate invariant features can inadvertently blend specific aspects. Such an approach struggles with nuanced differentiation of inter-domain variations and may exhibit bias towards certain domains, hindering the precise learning of domain-invariant features. Recognizing this, we introduce a novel method designed to supplement the model with domain-level and task-specific characteristics. This approach aims to guide the model in more effectively separating invariant features from specific characteristics, thereby boosting the generalization. Building on the emerging trend of visual prompts in the DG paradigm, our work introduces the novel \\textbf{H}ierarchical \\textbf{C}ontrastive \\textbf{V}isual \\textbf{P}rompt (HCVP) methodology. This represents a significant advancement in the field, setting itself apart with a unique generative approach to prompts, alongside an explicit model structure and specialized loss functions. Differing from traditional visual prompts that are often shared across entire datasets, HCVP utilizes a hierarchical prompt generation network enhanced by prompt contrastive learning. These generative prompts are instance-dependent, catering to the unique characteristics inherent to different domains and tasks. Additionally, we devise a prompt modulation network that serves as a bridge, effectively incorporating the generated visual prompts into the vision transformer backbone. Experiments conducted on five DG datasets demonstrate the effectiveness of HCVP, outperforming both established DG algorithms and adaptation protocols.","authors":["Guanglin Zhou","Zhongyi Han","Shiming Chen","Biwei Huang","Liming Zhu","Tongliang Liu","Lina Yao","Kun Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23413v2","updated":"2026-01-05T02:31:47Z","published":"2025-12-29T12:18:26Z","title":"Bridging Cognitive Gap: Hierarchical Description Learning for Artistic Image Aesthetics Assessment","summary":"The aesthetic quality assessment task is crucial for developing a human-aligned quantitative evaluation system for AIGC. However, its inherently complex nature, spanning visual perception, cognition, and emotion, poses fundamental challenges. Although aesthetic descriptions offer a viable representation of this complexity, two critical challenges persist: (1) data scarcity and imbalance: existing dataset overly focuses on visual perception and neglects deeper dimensions due to the expensive manual annotation; and (2) model fragmentation: current visual networks isolate aesthetic attributes with multi-branch encoder, while multimodal methods represented by contrastive learning struggle to effectively process long-form textual descriptions. To resolve challenge (1), we first present the Refined Aesthetic Description (RAD) dataset, a large-scale (70k), multi-dimensional structured dataset, generated via an iterative pipeline without heavy annotation costs and easy to scale. To address challenge (2), we propose ArtQuant, an aesthetics assessment framework for artistic images which not only couples isolated aesthetic dimensions through joint description generation, but also better models long-text semantics with the help of LLM decoders. Besides, theoretical analysis confirms this symbiosis: RAD's semantic adequacy (data) and generation paradigm (model) collectively minimize prediction entropy, providing mathematical grounding for the framework. Our approach achieves state-of-the-art performance on several datasets while requiring only 33% of conventional training epochs, narrowing the cognitive gap between artistic images and aesthetic judgment. We will release both code and dataset to support future research.","authors":["Henglin Liu","Nisha Huang","Chang Liu","Jiangpeng Yan","Huijuan Huang","Jixuan Ying","Tong-Yee Lee","Pengfei Wan","Xiangyang Ji"],"pdf_url":"","comment":"AAAI2026,Project Page:https://github.com/Henglin-Liu/ArtQuant"},{"id":"http://arxiv.org/abs/2506.16819v2","updated":"2026-01-05T02:29:08Z","published":"2025-06-20T08:18:44Z","title":"Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection","summary":"The proliferation of generative models has raised serious concerns about visual content forgery. Existing deepfake detection methods primarily target either image-level classification or pixel-wise localization. While some achieve high accuracy, they often suffer from limited generalization across manipulation types or rely on complex architectures. In this paper, we propose Loupe, a lightweight yet effective framework for joint deepfake detection and localization. Loupe integrates a patch-aware classifier and a segmentation module with conditional queries, allowing simultaneous global authenticity classification and fine-grained mask prediction. To enhance robustness against distribution shifts of test set, Loupe introduces a pseudo-label-guided test-time adaptation mechanism by leveraging patch-level predictions to supervise the segmentation head. Extensive experiments on the DDL dataset demonstrate that Loupe achieves state-of-the-art performance, securing the first place in the IJCAI 2025 Deepfake Detection and Localization Challenge with an overall score of 0.846. Our results validate the effectiveness of the proposed patch-level fusion and conditional query design in improving both classification accuracy and spatial localization under diverse forgery patterns. The code is available at https://github.com/Kamichanw/Loupe.","authors":["Yuchu Jiang","Jiaming Chu","Jian Zhao","Xin Zhang","Xu Yang","Lei Jin","Chi Zhang","Xuelong Li"],"pdf_url":"","comment":"There is some controversy over the methods of the content"},{"id":"http://arxiv.org/abs/2504.06704v2","updated":"2026-01-05T02:08:13Z","published":"2025-04-09T09:08:26Z","title":"CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers","summary":"Transformers have driven remarkable breakthroughs in natural language processing and computer vision, yet their standard attention mechanism still imposes O(N^2) complexity, hindering scalability to longer sequences. We introduce Circular-convolutional ATtention (CAT), a Fourier-based approach that efficiently applies circular convolutions to reduce complexity without sacrificing representational power. CAT achieves O(NlogN) computations, requires fewer learnable parameters by streamlining fully connected layers, and introduces no additional heavy operations, resulting in consistent accuracy improvements and about a 10% speedup in naive PyTorch implementations. Based on the Engineering-Isomorphic Transformers (EITs) framework, CAT's design not only offers practical efficiency and ease of implementation, but also provides insights to guide the development of future high-performance Transformer architectures. Finally, our ablation studies highlight the key conditions underlying CAT's success, shedding light on broader principles for scalable attention mechanisms.","authors":["Yoshihiro Yamada"],"pdf_url":"","comment":"Accepted as a poster at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2508.14681v4","updated":"2026-01-05T01:58:49Z","published":"2025-08-20T12:54:58Z","title":"Virtual Multiplex Staining for Histological Images using a Marker-wise Conditioned Diffusion Model","summary":"Multiplex imaging is revolutionizing pathology by enabling the simultaneous visualization of multiple biomarkers within tissue samples, providing molecular-level insights that traditional hematoxylin and eosin (H&E) staining cannot provide. However, the complexity and cost of multiplex data acquisition have hindered its widespread adoption. Additionally, most existing large repositories of H&E images lack corresponding multiplex images, limiting opportunities for multimodal analysis. To address these challenges, we leverage recent advances in latent diffusion models (LDMs), which excel at modeling complex data distributions by utilizing their powerful priors for fine-tuning to a target domain. In this paper, we introduce a novel framework for virtual multiplex staining that utilizes pretrained LDM parameters to generate multiplex images from H&E images using a conditional diffusion model. Our approach enables marker-by-marker generation by conditioning the diffusion model on each marker, while sharing the same architecture across all markers. To tackle the challenge of varying pixel value distributions across different marker stains and to improve inference speed, we fine-tune the model for single-step sampling, enhancing both color contrast fidelity and inference efficiency through pixel-level loss functions. We validate our framework on two publicly available datasets, notably demonstrating its effectiveness in generating up to 18 different marker types with improved accuracy, a substantial increase over the 2-3 marker types achieved in previous approaches. This validation highlights the potential of our framework, pioneering virtual multiplex staining. Finally, this paper bridges the gap between H&E and multiplex imaging, potentially enabling retrospective studies and large-scale analyses of existing H&E image repositories.","authors":["Hyun-Jic Oh","Junsik Kim","Zhiyi Shi","Yichen Wu","Yu-An Chen","Peter K Sorger","Hanspeter Pfister","Won-Ki Jeong"],"pdf_url":"","comment":"Accepted at AAAI 2026"},{"id":"http://arxiv.org/abs/2601.01720v1","updated":"2026-01-05T01:46:22Z","published":"2026-01-05T01:46:22Z","title":"FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing","summary":"First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.","authors":["Xijie Huang","Chengming Xu","Donghao Luo","Xiaobin Hu","Peng Tang","Xu Peng","Jiangning Zhang","Chengjie Wang","Yanwei Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.23252v2","updated":"2026-01-05T01:39:31Z","published":"2025-06-29T14:19:18Z","title":"DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection","summary":"The rapid proliferation of unmanned aerial vehicles (UAVs) has highlighted the importance of robust and efficient object detection in diverse aerial scenarios. Detecting small objects under complex conditions, however, remains a significant challenge.To address this, we present DGE-YOLO, an enhanced YOLO-based detection framework designed to effectively fuse multi-modal information. We introduce a dual-branch architecture for modality-specific feature extraction, enabling the model to process both infrared and visible images. To further enrich semantic representation, we propose an Efficient Multi-scale Attention (EMA) mechanism that enhances feature learning across spatial scales. Additionally, we replace the conventional neck with a Gather-and-Distribute(GD) module to mitigate information loss during feature aggregation. Extensive experiments on the Drone Vehicle dataset demonstrate that DGE-YOLO achieves superior performance over state-of-the-art methods, validating its effectiveness in multi-modal UAV object detection tasks.","authors":["Kunwei Lv","Zhiren Xiao","Hang Ren","Ping Lan"],"pdf_url":"","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.01696v1","updated":"2026-01-05T00:06:06Z","published":"2026-01-05T00:06:06Z","title":"Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems","summary":"Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.","authors":["Yian Liu","Xiong Wang","Ping Xu","Lei Zhu","Ming Yan","Linyun Xue"],"pdf_url":"","comment":null}],"Image and Video Processing":[{"id":"http://arxiv.org/abs/2508.10196v2","updated":"2026-01-05T18:51:53Z","published":"2025-08-13T21:02:38Z","title":"Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks","summary":"Early detection of lung cancer is critical to improving survival outcomes. We present a deep learning framework for automated lung cancer screening from chest computed tomography (CT) images with integrated explainability. Using the IQ-OTH/NCCD dataset (1,197 scans across Normal, Benign, and Malignant classes), we evaluate a custom convolutional neural network (CNN) and three fine-tuned transfer learning backbones: DenseNet121, ResNet152, and VGG19. Models are trained with cost-sensitive learning to mitigate class imbalance and evaluated via accuracy, precision, recall, F1-score, and ROC-AUC. While ResNet152 achieved the highest accuracy (97.3%), DenseNet121 provided the best overall balance in precision, recall, and F1 (up to 92%, 90%, 91%, respectively). We further apply Shapley Additive Explanations (SHAP) to visualize evidence contributing to predictions, improving clinical transparency. Results indicate that CNN-based approaches augmented with explainability can provide fast, accurate, and interpretable support for lung cancer screening, particularly in resource-limited settings.","authors":["Nishan Rai","Sujan Khatri","Devendra Risal"],"pdf_url":"","comment":"11 pages, 9 figures, 4 tables. Undergraduate research project report"},{"id":"http://arxiv.org/abs/2501.09799v5","updated":"2026-01-05T07:15:30Z","published":"2025-01-16T19:03:03Z","title":"Scan-Adaptive MRI Undersampling Using Neighbor-based Optimization (SUNO)","summary":"Accelerated MRI involves collecting partial $k$-space measurements to reduce acquisition time, patient discomfort, and motion artifacts, and typically uses regular undersampling patterns or human-designed schemes. Recent works have studied population-adaptive sampling patterns learned from a group of patients (or scans). However, such patterns can be sub-optimal for individual scans, as they may fail to capture scan or slice-specific details, and their effectiveness can depend on the size and composition of the population. To overcome this issue, we propose a framework for jointly learning scan-adaptive Cartesian undersampling patterns and a corresponding reconstruction model from a training set. We use an alternating algorithm for learning the sampling patterns and the reconstruction model where we use an iterative coordinate descent (ICD) based offline optimization of scan-adaptive $k$-space sampling patterns for each example in the training set. A nearest neighbor search is then used to select the scan-adaptive sampling pattern at test time from initially acquired low-frequency $k$-space information. We applied the proposed framework (dubbed SUNO) to the fastMRI multi-coil knee and brain datasets, demonstrating improved performance over the currently used undersampling patterns at both $4\\times$ and $8\\times$ acceleration factors in terms of both visual quality and quantitative metrics. The code for the proposed framework is available at https://github.com/sidgautam95/adaptive-sampling-mri-suno.","authors":["Siddhant Gautam","Angqi Li","Nicole Seiberlich","Jeffrey A. Fessler","Saiprasad Ravishankar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01784v1","updated":"2026-01-05T04:35:39Z","published":"2026-01-05T04:35:39Z","title":"DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization","summary":"The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \\emph{local view}, failing to capture global anomalies. To address this, we propose a \\underline{d}ual-stream graph learning and \\underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \\emph{Temporal Distance Stream} for local artifacts and a \\emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\\% in AP@0.95, with significant improvements in cross-domain robustness.","authors":["Boyang Zhao","Xin Liao","Jiaxin Chen","Xiaoshuai Wu","Yufeng Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2309.07926v2","updated":"2026-01-05T04:09:42Z","published":"2023-09-11T14:05:18Z","title":"COMPASS: High-Efficiency Deep Image Compression with Arbitrary-scale Spatial Scalability","summary":"Recently, neural network (NN)-based image compression studies have actively been made and has shown impressive performance in comparison to traditional methods. However, most of the works have focused on non-scalable image compression (single-layer coding) while spatially scalable image compression has drawn less attention although it has many applications. In this paper, we propose a novel NN-based spatially scalable image compression method, called COMPASS, which supports arbitrary-scale spatial scalability. Our proposed COMPASS has a very flexible structure where the number of layers and their respective scale factors can be arbitrarily determined during inference. To reduce the spatial redundancy between adjacent layers for arbitrary scale factors, our COMPASS adopts an inter-layer arbitrary scale prediction method, called LIFF, based on implicit neural representation. We propose a combined RD loss function to effectively train multiple layers. Experimental results show that our COMPASS achieves BD-rate gain of -58.33% and -47.17% at maximum compared to SHVC and the state-of-the-art NN-based spatially scalable image compression method, respectively, for various combinations of scale factors. Our COMPASS also shows comparable or even better coding efficiency than the single-layer coding for various scale factors.","authors":["Jongmin Park","Jooyoung Lee","Munchurl Kim"],"pdf_url":"","comment":"Accepted in ICCV 2023. Please visit our project page at https://kaist-viclab.github.io/compass-site/"},{"id":"http://arxiv.org/abs/2511.05836v3","updated":"2026-01-05T02:42:50Z","published":"2025-11-08T04:05:24Z","title":"Training-Free Adaptive Quantization for Variable Rate Image Coding for Machines","summary":"Image Coding for Machines (ICM) has become increasingly important with the rapid integration of computer vision technology into real-world applications. However, most neural network-based ICM frameworks operate at a fixed rate, thus requiring individual training for each target bitrate. This limitation may restrict their practical usage. Existing variable rate image compression approaches mitigate this issue but often rely on additional training, which increases computational costs and complicates deployment. Moreover, variable rate control has not been thoroughly explored for ICM. To address these challenges, we propose a training-free framework for quantization strength control which enables flexible bitrate adjustment. By exploiting the scale parameter predicted by the hyperprior network, the proposed method adaptively modulates quantization step sizes across both channel and spatial dimensions. This allows the model to preserve semantically important regions while coarsely quantizing less critical areas. Our architectural design further enables continuous bitrate control through a single parameter. Experimental results demonstrate the effectiveness of our proposed method, achieving up to 11.07% BD-rate savings over the non-adaptive variable rate baseline. The code is available at https://github.com/qwert-top/AQVR-ICM.","authors":["Yui Tatsumi","Ziyue Zeng","Hiroshi Watanabe"],"pdf_url":"","comment":"Accepted to IEEE 44th International Conference on Consumer Electronics (ICCE 2026)"},{"id":"http://arxiv.org/abs/2601.01729v1","updated":"2026-01-05T02:05:40Z","published":"2026-01-05T02:05:40Z","title":"Robust Deep Joint Source-Channel Coding for Video Transmission over Multipath Fading Channel","summary":"To address the challenges of wireless video transmission over multipath fading channels, we propose a robust deep joint source-channel coding (DeepJSCC) framework by effectively exploiting temporal redundancy and incorporating robust innovations at the modulation, coding, and decoding stages. At the modulation stage, tailored orthogonal frequency division multiplexing (OFDM) for robust video transmission is employed, decomposing wideband signals into orthogonal frequency-flat sub-channels to effectively mitigate frequency-selective fading. At the coding stage, conditional contextual coding with multi-scale Gaussian warped features is introduced to efficiently model temporal redundancy, significantly improving reconstruction quality under strict bandwidth constraints. At the decoding stage, a lightweight denoising module is integrated to robustly simplify signal restoration and accelerate convergence, addressing the suboptimality and slow convergence typically associated with simultaneously performing channel estimation, equalization, and semantic reconstruction. Experimental results demonstrate that the proposed robust framework significantly outperforms state-of-the-art video DeepJSCC methods, achieving an average reconstruction quality gain of 5.13 dB under challenging multipath fading channel conditions.","authors":["Bohuai Xiao","Jian Zou","Fanyang Meng","Wei Liu","Yongsheng Liang"],"pdf_url":"","comment":"6 pages, 6 figures. Accepted by IEEE GLOBECOM 2025. This version is the author preprint"},{"id":"http://arxiv.org/abs/2508.14681v4","updated":"2026-01-05T01:58:49Z","published":"2025-08-20T12:54:58Z","title":"Virtual Multiplex Staining for Histological Images using a Marker-wise Conditioned Diffusion Model","summary":"Multiplex imaging is revolutionizing pathology by enabling the simultaneous visualization of multiple biomarkers within tissue samples, providing molecular-level insights that traditional hematoxylin and eosin (H&E) staining cannot provide. However, the complexity and cost of multiplex data acquisition have hindered its widespread adoption. Additionally, most existing large repositories of H&E images lack corresponding multiplex images, limiting opportunities for multimodal analysis. To address these challenges, we leverage recent advances in latent diffusion models (LDMs), which excel at modeling complex data distributions by utilizing their powerful priors for fine-tuning to a target domain. In this paper, we introduce a novel framework for virtual multiplex staining that utilizes pretrained LDM parameters to generate multiplex images from H&E images using a conditional diffusion model. Our approach enables marker-by-marker generation by conditioning the diffusion model on each marker, while sharing the same architecture across all markers. To tackle the challenge of varying pixel value distributions across different marker stains and to improve inference speed, we fine-tune the model for single-step sampling, enhancing both color contrast fidelity and inference efficiency through pixel-level loss functions. We validate our framework on two publicly available datasets, notably demonstrating its effectiveness in generating up to 18 different marker types with improved accuracy, a substantial increase over the 2-3 marker types achieved in previous approaches. This validation highlights the potential of our framework, pioneering virtual multiplex staining. Finally, this paper bridges the gap between H&E and multiplex imaging, potentially enabling retrospective studies and large-scale analyses of existing H&E image repositories.","authors":["Hyun-Jic Oh","Junsik Kim","Zhiyi Shi","Yichen Wu","Yu-An Chen","Peter K Sorger","Hanspeter Pfister","Won-Ki Jeong"],"pdf_url":"","comment":"Accepted at AAAI 2026"},{"id":"http://arxiv.org/abs/2601.02594v1","updated":"2026-01-05T22:53:23Z","published":"2026-01-05T22:53:23Z","title":"Annealed Langevin Posterior Sampling (ALPS): A Rapid Algorithm for Image Restoration with Multiscale Energy Models","summary":"Solving inverse problems in imaging requires models that support efficient inference, uncertainty quantification, and principled probabilistic reasoning. Energy-Based Models (EBMs), with their interpretable energy landscapes and compositional structure, are well-suited for this task but have historically suffered from high computational costs and training instability. To overcome the historical shortcomings of EBMs, we introduce a fast distillation strategy to transfer the strengths of pre-trained diffusion models into multi-scale EBMs. These distilled EBMs enable efficient sampling and preserve the interpretability and compositionality inherent to potential-based frameworks. Leveraging EBM compositionality, we propose Annealed Langevin Posterior Sampling (ALPS) algorithm for Maximum-A-Posteriori (MAP), Minimum Mean Square Error (MMSE), and uncertainty estimates for inverse problems in imaging. Unlike diffusion models that use complex guidance strategies for latent variables, we perform annealing on static posterior distributions that are well-defined and composable. Experiments on image inpainting and MRI reconstruction demonstrate that our method matches or surpasses diffusion-based baselines in both accuracy and efficiency, while also supporting MAP recovery. Overall, our framework offers a scalable and principled solution for inverse problems in imaging, with potential for practical deployment in scientific and clinical settings. ALPS code is available at the GitHub repository \\href{https://github.com/JyoChand/ALPS}{ALPS}.","authors":["Jyothi Rikhab Chand","Mathews Jacob"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02564v1","updated":"2026-01-05T21:34:32Z","published":"2026-01-05T21:34:32Z","title":"Comparative Analysis of Binarization Methods For Medical Image Hashing On Odir Dataset","summary":"In this study, we evaluated four binarization methods. Locality-Sensitive Hashing (LSH), Iterative Quantization (ITQ), Kernel-based Supervised Hashing (KSH), and Supervised Discrete Hashing (SDH) on the ODIR dataset using deep feature embeddings. Experimental results show that SDH achieved the best performance, with an mAP@100 of 0.9184 using only 32-bit codes, outperforming LSH, ITQ, and KSH. Compared with prior studies, our method proved highly competitive: Fang et al. reported 0.7528 (Fundus-iSee, 48 bits) and 0.8856 (ASOCT-Cataract, 48 bits), while Wijesinghe et al. achieved 94.01 (KVASIR, 256 bits). Despite using significantly fewer bits, our SDH-based framework reached retrieval accuracy close to the state-of-the-art. These findings demonstrate that SDH is the most effective approach among those tested, offering a practical balance of accuracy, storage, and efficiency for medical image retrieval and device inventory management.","authors":["Nedim Muzoglu"],"pdf_url":"","comment":"17th International İstanbul Scientific Research Congress"},{"id":"http://arxiv.org/abs/2601.02562v1","updated":"2026-01-05T21:29:08Z","published":"2026-01-05T21:29:08Z","title":"CutisAI: Deep Learning Framework for Automated Dermatology and Cancer Screening","summary":"The rapid growth of dermatological imaging and mobile diagnostic tools calls for systems that not only demonstrate empirical performance but also provide strong theoretical guarantees. Deep learning models have shown high predictive accuracy; however, they are often criticized for lacking well, calibrated uncertainty estimates without which these models are hardly deployable in a clinical setting. To this end, we present the Conformal Bayesian Dermatological Classifier (CBDC), a well, founded framework that combines Statistical Learning Theory, Topological Data Analysis (TDA), and Bayesian Conformal Inference. CBDC offers distribution, dependent generalization bounds that reflect dermatological variability, proves a topological stability theorem that guarantees the invariance of convolutional neural network embeddings under photometric and morphological perturbations and provides finite conformal coverage guarantees for trustworthy uncertainty quantification.\n  Through exhaustive experiments on the HAM10000, PH2, and ISIC 2020 datasets, we show that CBDC not only attains classification accuracy but also generates calibrated predictions that are interpretable from a clinical perspective. This research constitutes a theoretical and practical leap for deep dermatological diagnostics, thereby opening the machine learning theory clinical applicability interface.","authors":["Rohit Kaushik","Eva Kaushik"],"pdf_url":"","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2601.02538v1","updated":"2026-01-05T20:25:34Z","published":"2026-01-05T20:25:34Z","title":"A Green Solution for Breast Region Segmentation Using Deep Active Learning","summary":"Purpose: Annotation of medical breast images is an essential step toward better diagnostic but a time consuming task. This research aims to focus on different selecting sample strategies within deep active learning on Breast Region Segmentation (BRS) to lessen computational cost of training and effective use of resources.\n  Methods: The Stavanger breast MRI dataset containing 59 patients was used in this study, with FCN-ResNet50 adopted as a sustainable deep learning (DL) model. A novel sample selection approach based on Breast Anatomy Geometry (BAG) analysis was introduced to group data with similar informative features for DL. Patient positioning and Breast Size were considered the key selection criteria in this process. Four selection strategies including Random Selection, Nearest Point, Breast Size, and a hybrid of all three strategies were evaluated using an active learning framework. Four training data proportions of 10%, 20%, 30%, and 40% were used for model training, with the remaining data reserved for testing. Model performance was assessed using Dice score, Intersection over Union, precision, and recall, along with 5-fold cross-validation to enhance generalizability.\n  Results: Increasing the training data proportion from 10% to 40% improved segmentation performance for nearly all strategies, except for Random Selection. The Nearest Point strategy consistently achieved the lowest carbon footprint at 30% and 40% data proportions. Overall, combining the Nearest Point strategy with 30% of the training data provided the best balance between segmentation performance, efficiency, and environmental sustainability.\n  Keywords: Deep Active Learning, Breast Region Segmentation, Human-center analysis","authors":["Sam Narimani","Solveig Roth Hoff","Kathinka Dæhli Kurz","Kjell-Inge Gjesdal","Jürgen Geisler","Endre Grøvik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02443v1","updated":"2026-01-05T13:31:44Z","published":"2026-01-05T13:31:44Z","title":"Evaluating the Diagnostic Classification Ability of Multimodal Large Language Models: Insights from the Osteoarthritis Initiative","summary":"Multimodal large language models (MLLMs) show promising performance on medical visual question answering (VQA) and report generation, but these generation and explanation abilities do not reliably transfer to disease-specific classification. We evaluated MLLM architectures on knee osteoarthritis (OA) radiograph classification, which remains underrepresented in existing medical MLLM benchmarks, even though knee OA affects an estimated 300 to 400 million people worldwide. Through systematic ablation studies manipulating the vision encoder, the connector, and the large language model (LLM) across diverse training strategies, we measured each component's contribution to diagnostic accuracy. In our classification task, a trained vision encoder alone could outperform full MLLM pipelines in classification accuracy and fine-tuning the LLM provided no meaningful improvement over prompt-based guidance. And LoRA fine-tuning on a small, class-balanced dataset (500 images) gave better results than training on a much larger but class-imbalanced set (5,778 images), indicating that data balance and quality can matter more than raw scale for this task. These findings suggest that for domain-specific medical classification, LLMs are more effective as interpreters and report generators rather than as primary classifiers. Therefore, the MLLM architecture appears less suitable for medical image diagnostic classification tasks that demand high certainty. We recommend prioritizing vision encoder optimization and careful dataset curation when developing clinically applicable systems.","authors":["Li Wang","Xi Chen","XiangWen Deng","HuaHui Yi","ZeKun Jiang","Kang Li","Jian Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02436v1","updated":"2026-01-05T08:14:28Z","published":"2026-01-05T08:14:28Z","title":"Deep Learning Superresolution for 7T Knee MR Imaging: Impact on Image Quality and Diagnostic Performance","summary":"Background: Deep learning superresolution (SR) may enhance musculoskeletal MR image quality, but its diagnostic value in knee imaging at 7T is unclear. Objectives: To compare image quality and diagnostic performance of SR, low-resolution (LR), and high-resolution (HR) 7T knee MRI. Methods: In this prospective study, 42 participants underwent 7T knee MRI with LR (0.8*0.8*2 mm3) and HR (0.4*0.4*2 mm3) sequences. SR images were generated from LR data using a Hybrid Attention Transformer model. Three radiologists assessed image quality, anatomic conspicuity, and detection of knee pathologies. Arthroscopy served as reference in 10 cases. Results: SR images showed higher overall quality than LR (median score 5 vs 4, P<.001) and lower noise than HR (5 vs 4, P<.001). Visibility of cartilage, menisci, and ligaments was superior in SR and HR compared to LR (P<.001). Detection rates and diagnostic performance (sensitivity, specificity, AUC) for intra-articular pathology were similar across image types (P>=.095). Conclusions: Deep learning superresolution improved subjective image quality in 7T knee MRI but did not increase diagnostic accuracy compared with standard LR imaging.","authors":["Pinzhen Chen","Libo Xu","Boyang Pan","Jing Li","Yuting Wang","Ran Xiong","Xiaoli Gou","Long Qing","Wenjing Hou","Nan-jie Gong","Wei Chen"],"pdf_url":"","comment":null}],"Graphics":[{"id":"http://arxiv.org/abs/2508.05685v6","updated":"2026-01-05T16:11:10Z","published":"2025-08-05T21:33:05Z","title":"DogFit: Domain-guided Fine-tuning for Efficient Transfer Learning of Diffusion Models","summary":"Transfer learning of diffusion models to smaller target domains is challenging, as naively fine-tuning the model often results in poor generalization. Test-time guidance methods help mitigate this by offering controllable improvements in image fidelity through a trade-off with sample diversity. However, this benefit comes at a high computational cost, typically requiring dual forward passes during sampling. We propose the Domain-guided Fine-tuning (DogFit) method, an effective guidance mechanism for diffusion transfer learning that maintains controllability without incurring additional computational overhead. DogFit injects a domain-aware guidance offset into the training loss, effectively internalizing the guided behavior during the fine-tuning process. The domain-aware design is motivated by our observation that during fine-tuning, the unconditional source model offers a stronger marginal estimate than the target model. To support efficient controllable fidelity-diversity trade-offs at inference, we encode the guidance strength value as an additional model input through a lightweight conditioning mechanism. We further investigate the optimal placement and timing of the guidance offset during training and propose two simple scheduling strategies, i.e., late-start and cut-off, which improve generation quality and training stability. Experiments on DiT and SiT backbones across six diverse target domains show that DogFit can outperform prior guidance methods in transfer learning in terms of FID and FDDINOV2 while requiring up to 2x fewer sampling TFLOPS.","authors":["Yara Bahram","Mohammadhadi Shateri","Eric Granger"],"pdf_url":"","comment":"Accepted for poster presentation at AAAI 2026"},{"id":"http://arxiv.org/abs/2601.02096v1","updated":"2026-01-05T13:24:12Z","published":"2026-01-05T13:24:12Z","title":"Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs","summary":"Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.","authors":["Peizhuo Li","Sebastian Starke","Yuting Ye","Olga Sorkine-Hornung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11618v3","updated":"2026-01-05T13:07:58Z","published":"2025-11-05T13:56:24Z","title":"On The Topology of Polygonal Meshes","summary":"This paper is an introductory and informal exposition on the topology of polygonal meshes. We begin with a broad overview of topological notions and discuss how homeomorphisms, homotopy, and homology can be used to characterise topology. We move on to define polygonal meshes and make a distinction between intrinsic topology and extrinsic topology which depends on the space in which the mesh is immersed. A distinction is also made between quantitative topological properties and qualitative properties. Next, we outline proofs of the Euler and the Euler-Poincaré formulas. The Betti numbers are then defined in terms of the Euler-Poincaré formula and other mesh statistics rather than as cardinalities of the homology groups which allows us to avoid abstract algebra. Finally, we discuss how it is possible to cut a polygonal mesh such that it becomes a topological disc.","authors":["Andreas Bærentzen"],"pdf_url":"","comment":"26 pages, 22 figures (including nine in the margin)"},{"id":"http://arxiv.org/abs/2601.02072v1","updated":"2026-01-05T12:51:12Z","published":"2026-01-05T12:51:12Z","title":"SketchRodGS: Sketch-based Extraction of Slender Geometries for Animating Gaussian Splatting Scenes","summary":"Physics simulation of slender elastic objects often requires discretization as a polyline. However, constructing a polyline from Gaussian splatting is challenging as Gaussian splatting lacks connectivity information and the configuration of Gaussian primitives contains much noise. This paper presents a method to extract a polyline representation of the slender part of the objects in a Gaussian splatting scene from the user's sketching input. Our method robustly constructs a polyline mesh that represents the slender parts using the screen-space shortest path analysis that can be efficiently solved using dynamic programming. We demonstrate the effectiveness of our approach in several in-the-wild examples.","authors":["Haato Watanabe","Nobuyuki Umetani"],"pdf_url":"","comment":"Presented at SIGGRAPH Asia 2025 (Technical Communications). Best Technical Communications Award"},{"id":"http://arxiv.org/abs/2412.10977v2","updated":"2026-01-05T09:49:06Z","published":"2024-12-14T21:39:43Z","title":"Point Cloud to Mesh Reconstruction: Methods, Trade-offs, and Implementation Guide","summary":"Reconstructing meshes from point clouds is a fundamental task in computer vision with applications spanning robotics, autonomous systems, and medical imaging. Selecting an appropriate learning-based method requires understanding trade-offs between computational efficiency, geometric accuracy, and output constraints. This paper categorizes over fifteen methods into five paradigms -- PointNet family, autoencoder architectures, deformation-based methods, point-move techniques, and primitive-based approaches -- and provides practical guidance for method selection. We contribute: (1) a decision framework mapping input/output requirements to suitable paradigms, (2) a failure mode analysis to assist practitioners in debugging implementations, (3) standardized comparisons on ShapeNet benchmarks, and (4) a curated list of maintained codebases with implementation resources. By synthesizing both theoretical foundations and practical considerations, this work serves as an entry point for practitioners and researchers new to learning-based 3D mesh reconstruction.","authors":["Fatima Zahra Iguenfer","Achraf Hsain","Hiba Amissa","Yousra Chtouki"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12151v2","updated":"2026-01-05T05:26:44Z","published":"2025-12-13T03:17:12Z","title":"Robust and Efficient Penetration-Free Elastodynamics without Barriers","summary":"We introduce a barrier-free optimization framework for non-penetration elastodynamic simulation that matches the robustness of Incremental Potential Contact (IPC) while overcoming its two primary efficiency bottlenecks: (1) reliance on logarithmic barrier functions to enforce non-penetration constraints, which leads to ill-conditioned systems and significantly slows down the convergence of iterative linear solvers; and (2) the time-of-impact (TOI) locking issue, which restricts active-set exploration in collision-intensive scenes and requires a large number of Newton iterations. We propose a novel second-order constrained optimization framework featuring a custom augmented Lagrangian solver that avoids TOI locking by immediately incorporating all requisite contact pairs detected via CCD, enabling more efficient active-set exploration and leading to significantly fewer Newton iterations. By adaptively updating Lagrange multipliers rather than increasing penalty stiffness, our method prevents stagnation at zero TOI while maintaining a well-conditioned system. We further introduce a constraint filtering and decay mechanism to keep the active set compact and stable, along with a theoretical justification of our method's finite-step termination and first-order time integration accuracy under a cumulative TOI-based termination criterion. A comprehensive set of experiments demonstrates the efficiency, robustness, and accuracy of our method. With a GPU-optimized simulator design, our method achieves an up to 103x speedup over GIPC on challenging, contact-rich benchmarks - scenarios that were previously tractable only with barrier-based methods. Our code and data will be open-sourced.","authors":["Juntian Zheng","Zhaofeng Luo","Minchen Li"],"pdf_url":"","comment":"Supplementary video and materials available at https://github.com/wiso-enoji/Barrier-Free-Supplementary"}],"Signal Processing":[{"id":"http://arxiv.org/abs/2601.02298v1","updated":"2026-01-05T17:33:16Z","published":"2026-01-05T17:33:16Z","title":"Power-of-Two Quantization-Aware-Training (PoT-QAT) in Large Language Models (LLMs)","summary":"In Large Language Models (LLMs), the number of parameters has grown exponentially in the past few years, e.g., from 1.5 billion parameters in GPT-2 to 175 billion in GPT-3 to possibly more than trillion in higher versions. This raises a significant challenge for implementation, especially for Edge devices. Unlike cloud computing, memory and processing power for Edge devices are very limited, which necessitates developing novel ideas to make such applications feasible. In this work, we investigate compressing weights with a special quantization that limits numbers to only power-of-two (PoT). This helps save a huge amount of memory as only exponents need to be stored, more importantly, it significantly reduces processing power by replacing costly multiplication with low cost bit shifting. To overcome performance loss due to this strict quantization, we investigate Quantization Aware Training (QAT) to enhance performance through additional training. Results on GPT-2 124M show a major enhancement for quantized PoT model after additional training, with a perplexity enhancement of 66% and BERT-Score loss to baseline GPT-2 of 1%. The memory saving is estimated to be 87.5% while the inference speed is expected to be 3-10x faster with PoT quantization versus full-precision.","authors":["Mahmoud Elgenedy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02227v1","updated":"2026-01-05T15:55:46Z","published":"2026-01-05T15:55:46Z","title":"Ultra-low-power Monostatic Backscatter Platform with Phase-Aware Channel Estimation and System-Level Validation","summary":"This paper presents a novel channel-estimation (CE) method that mitigates residual phase drifts in backscatter links and a full hardware and signal-processing pipeline for a single-antenna monostatic system. The platform comprises a semi-passive tag, a software-defined radio (SDR) reader, and a 2x1 planar Yagi-Uda array (7 dBi with higher than 30 dB isolation) operating at 2.4 ~ 2.5 GHz. The developed backscatter fading model accounts for round-trip propagation and temporal correlation, and employs an analytically derived resource-optimal pilot allocation strategy. At the receiver, optimized least square (LS) and linear minimum mean square error (LMMSE) CE with pilot-aided carrier frequency offset (CFO) compensation feed a zero-forcing (ZF) equalizer to suppress ISI. The prototype delivers 500 kbps at 1 m with power of 158 uW (SDR baseband) and 10 uW (RF switch), yielding 320 pJ/bit. OOK and BPSK modulations achieve measured EVMs of 2.97 % and 4.02 %, respectively. Performance is validated by BER measurements and successful reconstruction of a full-color image in an over-the-air experiment. The results demonstrate an ultra-low-power, multimedia-capable backscatter IoT link and provide practical hardware-software co-design guidance for scalable deployments.","authors":["Hanyeol Ryu","Sangkil Kim"],"pdf_url":"","comment":"19 pages, 18 figures"},{"id":"http://arxiv.org/abs/2601.02225v1","updated":"2026-01-05T15:52:27Z","published":"2026-01-05T15:52:27Z","title":"Backscatter-Assisted High-Speed Rail Communications in Straight Tunnel Environments: Effects of Tag Number and Phase Control","summary":"Backscatter communication is a promising technology to enhance the signal strength received by the receiver in straight tunnel environments. The impact of the number of tags and their phase adjustment on system performance remains a challenging issue though. Therefore, in this paper, we investigate the channel gain of backscatter-assisted communication with multiple tags in straight tunnels. In particular, we derive the probabilities that the backscatter link gain is greater than the direct link under adjustable and random phase assumptions by applying the Gaussian and Gamma approximations to derive tractable expressions. The simulation results show that phaseadjustable tags significantly improve the channel gain of the backscatter links compared to the random phase case. Moreover, the number of tags has an upper threshold for an effective tag deployment pattern. These insights provide valuable guidelines for the efficient design of backscatter communication systems in tunnel environments.","authors":["Yunping Mu","Gongpu Wang","Ruisi He","Theodoros A. Tsiftsis","Saman Atapattu","Chintha Tellambura"],"pdf_url":"","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.02219v1","updated":"2026-01-05T15:46:18Z","published":"2026-01-05T15:46:18Z","title":"Beam-Brainstorm: A Generative Site-Specific Beamforming Approach","summary":"Accurately understanding the propagation environment is a fundamental challenge in site-specific beamforming (SSBF). This paper proposes a novel generative SSBF (GenSSBF) solution, which represents a paradigm shift from conventional unstructured prediction to joint-structure modeling. First, considering the fundamental differences between beam generation and conventional image synthesis, a unified GenSSBF framework is proposed, which includes a site profile, a wireless prompting module, and a generator. Second, a beam-brainstorm (BBS) solution is proposed as an instantiation of this GenSSBF framework. Specifically, the site profile is configured by transforming channel data from spatial domain to a reversible latent space via discrete Fourier transform (DFT). To facilitate practical deployment, the wireless prompt is constructed from the reference signal received power (RSRP) measured using a small number of DFT-beams. Finally, the generator is developed using a customized conditional diffusion model. Rather than relying on a meticulously designed global codebook, BBS directly generates diverse and high-fidelity user-specific beams guided by the wireless prompts. Simulation results on accurate ray-tracing datasets demonstrate that BBS can achieve near-optimal beamforming gain while drastically reducing the beam sweeping overhead, even in low signal-to-noise ratio (SNR) environments.","authors":["Zihao Zhou","Zhaolin Wang","Yuanwei Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.19815v2","updated":"2026-01-05T15:34:26Z","published":"2024-10-17T21:19:39Z","title":"Bayesian uncertainty-aware deep learning with noisy labels: Tackling annotation ambiguity in EEG seizure detection","summary":"Deep learning is advancing EEG processing for automated epileptic seizure detection and onset zone localization, yet its performance relies heavily on high-quality annotated training data. However, scalp EEG is susceptible to high noise levels, which in turn leads to imprecise annotations of the seizure timing and characteristics. This \"label noise\" presents a significant challenge in model training and generalization. In this paper, we introduce Bayesian UncertaiNty-aware Deep Learning (BUNDL), a novel algorithm that informs a deep learning model of label ambiguities, thereby enhancing the robustness of seizure detection systems. By integrating domain knowledge into an underlying Bayesian framework, we derive a novel KL-divergence-based loss function that capitalizes on uncertainty to better learn seizure characteristics from scalp EEG. Thus, BUNDL offers a straightforward and model-agnostic method for training deep neural networks with noisy training labels that does not add any parameters to existing architectures. Additionally, we explore the impact of improved detection system on the task of automated onset zone localization. We validate BUNDL using a comprehensive simulated EEG dataset and two publicly available datasets collected by Temple University Hospital (TUH) and Boston Children's Hospital (CHB-MIT). Results show that BUNDL consistently identifies noisy labels and improves the robustness of three base models under various label noise conditions. We also evaluate cross-site generalizability and quantify computational cost of all methods. Ultimately, BUNDL presents as a reliable method that can be seamlessly integrated with existing deep models used in clinical practice, enabling the training of trustworthy models for epilepsy evaluation.","authors":["Deeksha M. Shama","Archana Venkataraman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10527v2","updated":"2026-01-05T15:15:31Z","published":"2025-08-14T11:02:21Z","title":"A 240 Elements Matrix Probe with Aberration Mask for 4D Carotid Artery Computational Ultrasound Imaging","summary":"Three-dimensional (3D) ultrasound provides enhanced visualization of the carotid artery (CA) anatomy and volumetric flow, offering improved accuracy for cardiovascular diagnosis and monitoring. However, fully populated matrix transducers with large apertures are complex and costly to implement. Computational ultrasound imaging (cUSi) offers a promising alternative by enabling simplified hardware design through model-based reconstruction and spatial field encoding. In this work, we present a 3D cUSi system tailored for CA imaging, consisting of a 240-element matrix probe with a 40 x 24 mm$^2$ large aperture and a spatial encoding mask. We describe the system's design, characterization, and image reconstruction. Phantom experiments show that computational reconstruction using matched filtering (MF) significantly improves volumetric image quality over delay-and-sum (DAS), with spatial encoding enhancing lateral resolution at the cost of reduced contrast ratio. LSQR-based reconstruction was demonstrated to further improve resolution and suppress artifacts. Using both Hadamard and 16-angle plane wave transmission schemes, the system achieved high-resolution images with reasonable contrast, supporting the feasibility of 4D CA imaging applications.","authors":["Yuyang Hu","Michael Brown","Didem Dogan","Mahé Bulot","Maxime Cheppe","Guillaume Ferin","Geert Leus","Antonius F. W. van der Steen","Pieter Kruizinga","Johannes G. Bosch"],"pdf_url":"","comment":"Maintext: 11 pages, 7 figures Supporting: 2 pages"},{"id":"http://arxiv.org/abs/2502.19176v2","updated":"2026-01-05T14:50:41Z","published":"2025-02-26T14:33:27Z","title":"Beamforming and Waveform Optimization for RF Wireless Power Transfer with Beyond Diagonal Reconfigurable Intelligent Surfaces","summary":"Radio frequency (RF) wireless power transfer (WPT) is a promising technology to seamlessly charge low-power devices, but its low end-to-end power transfer efficiency remains a critical challenge. To address the latter, low-cost transmit/radiating architectures, e.g., based on reconfigurable intelligent surfaces (RISs), have shown great potential. Beyond diagonal (BD) RIS is a novel branch of RIS offering enhanced performance over traditional diagonal RIS (D-RIS) in wireless communications, but its potential gains in RF-WPT remain unexplored. Motivated by this, we analyze a BD-RIS-assisted single-antenna RF-WPT system to charge a single rectifier, and formulate a joint beamforming and multi-carrier waveform optimization problem aiming to maximize the harvested power. We propose two solutions relying on semi-definite programming for fully connected BD-RIS, a successive convex approximation (SCA)-based beamforming approach, and an efficient low-complexity iterative method relying on SCA. Numerical results show that the proposed algorithms converge and that adding transmit sub-carriers or RIS elements improves the harvesting performance. We show that the transmit power budget impacts the relative power allocation among different sub-carriers depending on the rectifier's operating regime, while BD-RIS shapes the cascade channel differently for frequency-selective and flat scenarios. Finally, we verify by simulation that BD-RIS and D-RIS achieve the same performance under pure far-field line-of-sight conditions (in the absence of mutual coupling). Meanwhile, BD-RIS outperforms D-RIS as the non-line-of-sight components of the channel become dominant.","authors":["Amirhossein Azarbahram","Onel L. A. Lopez","Bruno Clerckx","Marco Di Renzo","Matti Latva-Aho"],"pdf_url":"","comment":"Published in IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2506.01696v3","updated":"2026-01-05T13:51:36Z","published":"2025-06-02T13:58:36Z","title":"Missing Data in Signal Processing and Machine Learning: Models, Methods and Modern Approaches","summary":"This tutorial aims to provide signal processing (SP) and machine learning (ML) practitioners with vital tools, in an accessible way, to answer the question: How to deal with missing data? There are many strategies to handle incomplete signals. In this paper, we propose to group these strategies based on three common analytical tasks: i) missing-data imputation, ii) estimation with missing values and iii) prediction with missing values. We focus on methodological and experimental results through specific case studies on real-world applications. Promising and future research directions are also discussed. We hope that the proposed conceptual framework and the presentation of recent missing-data problems related will encourage researchers of the SP and ML communities to develop original methods and to efficiently deal with new applications involving missing data.","authors":["Alexandre Hippert-Ferrer","Aude Sportisse","Amirhossein Javaheri","Mohammed Nabil El Korso","Daniel P. Palomar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22792v2","updated":"2026-01-05T13:46:47Z","published":"2025-12-28T05:33:05Z","title":"A Universal and Robust Framework for Multiple Gas Recognition Based-on Spherical Normalization-Coupled Mahalanobis Algorithm","summary":"Electronic nose (E-nose) systems face two interconnected challenges in open-set gas recognition: feature distribution shift caused by signal drift and decision boundary failure induced by unknown gas interference. Existing methods predominantly rely on Euclidean distance or conventional classifiers, failing to account for anisotropic feature distributions and dynamic signal intensity variations. To address these issues, this study proposes the Spherical Normalization coupled Mahalanobis (SNM) module, a universal post-processing module for open-set gas recognition. First, it achieves geometric decoupling through cascaded batch and L2 normalization, projecting features onto a unit hypersphere to eliminate signal intensity fluctuations. Second, it utilizes Mahalanobis distance to construct adaptive ellipsoidal decision boundaries that conform to the anisotropic feature geometry. The architecture-agnostic SNM-Module seamlessly integrates with mainstream backbones including Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Transformer. Experiments on the public Vergara dataset demonstrate that the Transformer+SNM configuration achieves near-theoretical-limit performance in discriminating among multiple target gases, with an AUROC of 0.9977 and an unknown gas detection rate of 99.57% at 5% false positive rate, significantly outperforming state-of-the-art methods with a 3.0% AUROC improvement and 91.0% standard deviation reduction compared to Class Anchor Clustering (CAC). The module maintains exceptional robustness across five sensor positions, with standard deviations below 0.0028. This work effectively addresses the critical challenge of simultaneously achieving high accuracy and high stability in open-set gas recognition, providing solid support for industrial E-nose deployment.","authors":["Shuai Chen","Yang Song","Chen Wang","Ziran Wang"],"pdf_url":"","comment":"27 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2601.01956v1","updated":"2026-01-05T10:01:41Z","published":"2026-01-05T10:01:41Z","title":"Doppler-Resilient LEO Satellite OFDM Transmission with Affine Frequency Domain Pilot","summary":"Orthogonal frequency division multiplexing (OFDM) based low Earth orbit (LEO) satellite communication system suffers from severe Doppler shifts, while {the Doppler-resilient affine frequency-division multiplexing (AFDM) transmission suffers from significantly high processing complexity in data detection}. In this paper, we explore the channel estimation gain of affine frequency (AF) domain pilot to enhance the OFDM transmission under high mobility. Specifically, we propose a novel AF domain pilot embedding scheme for satellite-ground downlink OFDM systems for capturing the channel characteristics. By exploiting the autoregressive (AR) property of adjacent channels, a long short-term memory (LSTM) based predictor is designed to replace conventional interpolation operation in OFDM channel estimation. Simulation results show that the proposed transmission scheme significantly outperforms conventional OFDM scheme in terms of bit error rate (BER) under high Doppler scenarios, thus paving a new way for the design of next generation non-terrestrial network (NTN) communication systems.","authors":["Tang Shuntian","Wu Xiaomei","Wang Xinyi","Zhao Le","Yang Guang","Liu Zilong","Liu Fan","Fei Zesong"],"pdf_url":"","comment":"6 pages, 4 figures, submitted to 2026 ICC Workshops"},{"id":"http://arxiv.org/abs/2601.01834v1","updated":"2026-01-05T06:56:14Z","published":"2026-01-05T06:56:14Z","title":"On the Performance of Lossless Reciprocal MiLAC Architectures in Multi-User Networks","summary":"Microwave linear analog computer (MiLAC)-aided beamforming, which processes the transmitted symbols fully in the analog domain, has recently emerged as a promising alternative to fully digital and hybrid beamforming architectures for multiple-input multiple-output (MIMO) systems. While prior studies have shown that lossless and reciprocal MiLAC can achieve the same capacity as digital beamforming in a single-user MIMO network, its performance in multi-user scenarios remains unknown. To answer this question, in this work, we establish a downlink multi-user multiple-input single-output (MU-MISO) network with a MiLAC-aided transmitter, and investigate its sum-rate performance. Based on the microwave network theory, we first prove that lossless and reciprocal MiLAC cannot achieve the same performance as digital beamforming in a general MU-MISO network. Then, we formulate a sum-rate maximization problem and develop an efficient optimization framework to jointly optimize the power allocation and the scattering matrix for MiLAC. Numerical results validate our theoretical analysis and demonstrate that MiLAC is a promising architecture for future extremely large-scale MIMO systems.","authors":["Tianyu Fang","Xiaohua Zhou","Yijie Mao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.10182v2","updated":"2026-01-05T06:37:33Z","published":"2025-01-17T13:26:14Z","title":"Secure Semantic Communication With Homomorphic Encryption","summary":"In recent years, Semantic Communication (SemCom), which aims to achieve efficient and reliable transmission of meaning between agents, has garnered significant attention from both academia and industry. To ensure the security of communication systems, encryption techniques are employed to safeguard confidentiality and integrity. However, existing encryption schemes encounter obstacles when applied to SemCom. To address this issue, this paper explores the feasibility of applying homomorphic encryption (HE) to SemCom. Initially, we review the encryption algorithms utilized in mobile communication systems and analyze the challenges associated with their application to SemCom. Subsequently, we overview HE techniques and employ scale-invariant feature transform (SIFT) to demonstrate that the extractable semantic information can be preserved in homomorphic encrypted ciphertext. Based on this finding, we further propose the HE-joint source-channel coding (HE-JSCC) scheme, where the traditional JSCC model architecture is modified to support HE operations. Moreover, we present the simulation results for image classification and image generation tasks. Furthermore, we provide potential future research directions for homomorphic encrypted SemCom.","authors":["Rui Meng","Dayu Fan","Haixiao Gao","Yifan Yuan","Bizhu Wang","Xiaodong Xu","Mengying Sun","Chen Dong","Xiaofeng Tao","Ping Zhang","Dusit Niyato"],"pdf_url":"","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.01805v1","updated":"2026-01-05T05:31:41Z","published":"2026-01-05T05:31:41Z","title":"Pathwise Representation of the Smoothing Distribution in Continuous-Time Linear Gaussian Models","summary":"We study the filtering and smoothing problem for continuous-time linear Gaussian systems. While classical approaches such as the Kalman-Bucy filter and the Rauch-Tung-Striebel (RTS) smoother provide recursive formulas for the conditional mean and covariance, we present a pathwise perspective that characterizes the smoothing error dynamics as an Ornstein-Uhlenbeck process. As an application, we show that standard filtering and smoothing equations can be uniformly derived as corollaries of our main theorem. In particular, we provide the first mathematically rigorous derivation of the Bryson-Frazier smoother in the continuous-time setting. Beyond offering a more transparent understanding of the smoothing distribution, our formulation enables pathwise sampling from it, which facilitates Monte Carlo methods for evaluating nonlinear functionals.","authors":["Masahiro Kurisaki"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01791v1","updated":"2026-01-05T05:05:15Z","published":"2026-01-05T05:05:15Z","title":"Rethinking Secure Semantic Communications in the Age of Generative and Agentic AI: Threats and Opportunities","summary":"Semantic communication (SemCom) improves communication efficiency by transmitting task-relevant information instead of raw bits and is expected to be a key technology for 6G networks. Recent advances in generative AI (GenAI) further enhance SemCom by enabling robust semantic encoding and decoding under limited channel conditions. However, these efficiency gains also introduce new security and privacy vulnerabilities. Due to the broadcast nature of wireless channels, eavesdroppers can also use powerful GenAI-based semantic decoders to recover private information from intercepted signals. Moreover, rapid advances in agentic AI enable eavesdroppers to perform long-term and adaptive inference through the integration of memory, external knowledge, and reasoning capabilities. This allows eavesdroppers to further infer user private behavior and intent beyond the transmitted content. Motivated by these emerging challenges, this paper comprehensively rethinks the security and privacy of SemCom systems in the age of generative and agentic AI. We first present a systematic taxonomy of eavesdropping threat models in SemCom systems. Then, we provide insights into how GenAI and agentic AI can enhance eavesdropping threats. Meanwhile, we also highlight potential opportunities for leveraging GenAI and agentic AI to design privacy-preserving SemCom systems.","authors":["Shunpu Tang","Yuanyuan Jia","Zijiu Yang","Qianqian Yang","Ruichen Zhang","Jun Du","Jihong Park","Zhiguo Shi","Khaled B. Letaief"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01773v1","updated":"2026-01-05T04:03:57Z","published":"2026-01-05T04:03:57Z","title":"Joint Sparsity and Beamforming Design for RDARS-Aided Systems","summary":"Reconfigurable distributed antennas and reflecting surface (RDARS) has emerged as a promising architecture for communication and sensing performance enhancement. In particular, the new selection gain can be achieved by leveraging the dynamic working mode selection between connection and reflection modes, whereas low-complexity element configuration remains an open issue. In this paper, we consider a RDARS-assisted communication system, where the connected elements are formed as a uniform sparse array for simplified mode configuration while achieving enlarged physical array aperture. The sum rate maximization problem is then formulated by jointly optimizing the active and passive beamforming matrices and sparsity of connected element array. For the special cases of a single user equipment (UE) and two UEs, the optimal sparsity designs are derived in closed-form. Then, for an arbitrary number of UEs, a weighted minimum mean-square error-based alternating optimization (AO) algorithm is proposed to tackle the non-convex optimization problem. Numerical results demonstrate the importance of optimizing the sparsity and the effectiveness of low-complexity sparsity optimization.","authors":["Chengwang Ji","Haiquan Lu","Qiaoyan Peng","Jintao Wang","Shaodan Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02605v1","updated":"2026-01-05T23:41:37Z","published":"2026-01-05T23:41:37Z","title":"Beyond Path Loss: Altitude-Dependent Spectral Structure Modeling for UAV Measurements","summary":"This paper presents a measurement-based framework for characterizing altitude-dependent spectral behavior of signals received by a tethered Helikite unmanned aerial vehicle (UAV). Using a multi-year spectrum measurement campaign in an outdoor urban environment, power spectral density snapshots are collected over the 89 MHz--6 GHz range. Three altitude-dependent spectral metrics are extracted: band-average power, spectral entropy, and spectral sparsity. We introduce the Altitude-Dependent Spectral Structure Model (ADSSM) to characterize the spectral power and entropy using first-order altitude-domain differential equations, and spectral sparsity using a logistic function, yielding closed-form expressions with physically consistent asymptotic behavior. The model is fitted to altitude-binned measurements from three annual campaigns at the AERPAW testbed across six licensed and unlicensed sub-6 GHz bands. Across all bands and years, the ADSSM achieves low root-mean-square error and high coefficients of determination. Results indicate that power transitions occur over narrow low-altitude regions, while entropy and sparsity evolve over broader, band-dependent altitude ranges, demonstrating that altitude-dependent spectrum behavior is inherently multidimensional. By explicitly modeling altitude-dependent transitions in spectral structure beyond received power, the proposed framework enables spectrum-aware UAV sensing and band selection decisions that are not achievable with conventional power- or threshold-based occupancy models.","authors":["Amir Hossein Fahim Raouf","İsmail Güvenç"],"pdf_url":"","comment":null}],"Computational Geometry":[{"id":"http://arxiv.org/abs/2507.20937v2","updated":"2026-01-05T17:31:05Z","published":"2025-07-28T15:50:38Z","title":"General Strong Bound on the Uncrossed Number which is Tight for the Edge Crossing Number","summary":"We investigate a very recent concept for visualizing various aspects of a graph in the plane using a collection of drawings introduced by Hliněný and Masařík [GD 2023]. Formally, given a graph $G$, we aim to find an uncrossed collection containing drawings of $G$ in the plane such that each edge of $G$ is not crossed in at least one drawing in the collection. The uncrossed number of $G$ ($unc(G)$) is the smallest integer $k$ such that an uncrossed collection for $G$ of size $k$ exists. The uncrossed number is lower-bounded by the well-known thickness, which is an edge-decomposition of $G$ into planar graphs. This connection gives a trivial lower-bound $\\lceil\\frac{|E(G)|}{3|V(G)|-6}\\rceil \\le unc(G)$. In a recent paper, Balko, Hliněný, Masařík, Orthaber, Vogtenhuber, and Wagner [GD 2024] presented the first non-trivial and general lower-bound on the uncrossed number. We summarize it in terms of dense graphs (where $|E(G)|=ε(|V(G)|)^2$ for some $ε>0$): $\\lceil\\frac{|E(G)|}{c_ε|V(G)|}\\rceil \\le unc(G)$, where $c_ε\\ge 2.82$ is a constant depending on $ε$.\n  We improve the lower-bound to state that $\\lceil\\frac{|E(G)|}{3|V(G)|-6-\\sqrt{2|E(G)|}+\\sqrt{6(|V(G)|-2)}}\\rceil \\le unc(G)$. Translated to dense graphs regime, the bound yields a multiplicative constant $c'_ε=3-\\sqrt{(2-ε)}$ in the expression $\\lceil\\frac{|E(G)|}{c'_ε|V(G)|+o(|V(G)|)}\\rceil \\le unc(G)$. Hence, it is tight (up to low-order terms) for $ε\\approx \\frac{1}{2}$ as warranted by complete graphs.\n  In fact, we formulate our result in the language of the maximum uncrossed subgraph number, that is, the maximum number of edges of $G$ that are not crossed in a drawing of $G$ in the plane. In that case, we also provide a construction certifying that our bound is asymptotically tight (up to low-order terms) on dense graphs for all $ε>0$.","authors":["Gaspard Charvy","Tomáš Masařík"],"pdf_url":"","comment":"21 pages, 6 figures"}],"Data Structure and Algorithm":[{"id":"http://arxiv.org/abs/2601.02347v1","updated":"2026-01-05T18:44:27Z","published":"2026-01-05T18:44:27Z","title":"Solving Matrix Games with Even Fewer Matrix-Vector Products","summary":"We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and of $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In particular, our result for $\\ell_2$-$\\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.","authors":["Ishani Karmarkar","Liam O'Carroll","Aaron Sidford"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2403.18059v5","updated":"2026-01-05T17:23:12Z","published":"2024-03-26T19:24:40Z","title":"Optimality of Non-Adaptive Algorithms in Online Submodular Welfare Maximization with Stochastic Outcomes","summary":"We generalize the problem of online submodular welfare maximization to incorporate various stochastic elements that have gained significant attention in recent years. We show that a non-adaptive Greedy algorithm, which is oblivious to the realization of these stochastic elements, achieves the best possible competitive ratio among all polynomial-time algorithms, including adaptive ones, unless NP$=$RP. This result holds even when the objective function is not submodular but instead satisfies the weaker submodular order property. Our results unify and strengthen existing competitive ratio bounds across well-studied settings and diverse arrival models, showing that, in general, adaptivity to stochastic elements offers no advantage in terms of competitive ratio.\n  To establish these results, we introduce a technique that lifts known results from the deterministic setting to the generalized stochastic setting. The technique has broad applicability, enabling us to show that, in certain special cases, non-adaptive Greedy-like algorithms outperform the Greedy algorithm and achieve the optimal competitive ratio. We also apply the technique in reverse to derive new upper bounds on the performance of Greedy-like algorithms in deterministic settings by leveraging upper bounds on the performance of non-adaptive algorithms in stochastic settings.","authors":["Rajan Udwani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02257v1","updated":"2026-01-05T16:36:59Z","published":"2026-01-05T16:36:59Z","title":"Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization","summary":"We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.\n  We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.","authors":["Joel Daniel Andersson","Palak Jain","Satchit Sivakumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12857v2","updated":"2026-01-05T16:12:31Z","published":"2025-11-17T01:05:11Z","title":"Approximate Message Passing for Quantum State Tomography","summary":"Quantum state tomography (QST) is an indispensable tool for characterizing many-body quantum systems. However, due to the exponential scaling of the cost of the protocol with system size, many approaches have been developed for quantum states with specific structure, such as low-rank states. In this paper, we show how approximate message passing (AMP), an algorithmic framework for sparse signal recovery, can be used to perform low-rank QST. AMP provides asymptotically optimal performance guarantees for large sparse recovery problems, which suggests its utility for QST. We discuss the design challenges that come with applying AMP to QST, and show that by properly designing the AMP algorithm, we can reduce the reconstruction error by over an order of magnitude compared to existing approaches to low-rank QST. We also performed tomographic experiments on IBM Kingston and considered the effect of device noise on the reliability of the predicted fidelity of state preparation. Our work advances the state of low-rank QST and may be applicable to other quantum tomography protocols.","authors":["Noah Siekierski","Kausthubh Chandramouli","Christian Kümmerle","Bojko N. Bakalov","Dror Baron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02193v1","updated":"2026-01-05T15:16:26Z","published":"2026-01-05T15:16:26Z","title":"Learning with Monotone Adversarial Corruptions","summary":"We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a \"clean\" i.i.d. dataset, inserts additional \"corrupted\" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.","authors":["Kasper Green Larsen","Chirag Pabbaraju","Abhishek Shetty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.18803v2","updated":"2026-01-05T09:47:37Z","published":"2025-02-26T04:17:32Z","title":"On Efficient Approximate Aggregate Nearest Neighbor Queries over Learned Representations","summary":"We study Aggregation Queries over Nearest Neighbors (AQNN), which compute aggregates over the learned representations of the neighborhood of a designated query object. For example, a medical professional may be interested in the average heart rate of patients whose representations are similar to that of an insomnia patient. Answering AQNNs accurately and efficiently is challenging due to the high cost of generating high-quality representations (e.g., via a deep learning model trained on human expert annotations) and the different sensitivities of different aggregation functions to neighbor selection errors. We address these challenges by combining high-quality and low-cost representations to approximate the aggregate. We characterize value- and count-sensitive AQNNs and propose the Sampler with Precision-Recall in Target (SPRinT), a query answering framework that works in three steps: (1) sampling, (2) nearest neighbor selection, and (3) aggregation. We further establish theoretical bounds on sample sizes and aggregation errors. Extensive experiments on five datasets from three domains (medical, social media, and e-commerce) demonstrate that SPRinT achieves the lowest aggregation error with minimal computation cost in most cases compared to existing solutions. SPRinT's performance remains stable as dataset size grows, confirming its scalability for large-scale applications requiring both accuracy and efficiency.","authors":["Carrie Wang","Sihem Amer-Yahia","Laks V. S. Lakshmanan","Reynold Cheng"],"pdf_url":"","comment":"26 pages, 12 figures, 10 tables"},{"id":"http://arxiv.org/abs/2402.06388v4","updated":"2026-01-05T08:44:46Z","published":"2024-02-09T13:10:04Z","title":"Convergence of a L2 regularized Policy Gradient Algorithm for the Multi Armed Bandit","summary":"Although Multi Armed Bandit (MAB) on one hand and the policy gradient approach on the other hand are among the most used frameworks of Reinforcement Learning, the theoretical properties of the policy gradient algorithm used for MAB have not been given enough attention. We investigate in this work the convergence of such a procedure for the situation when a $L2$ regularization term is present jointly with the 'softmax' parametrization. We prove convergence under appropriate technical hypotheses and test numerically the procedure including situations beyond the theoretical setting. The tests show that a time dependent regularized procedure can improve over the canonical approach especially when the initial guess is far from the solution.","authors":["Stefana Anita","Gabriel Turinici"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01869v1","updated":"2026-01-05T07:56:06Z","published":"2026-01-05T07:56:06Z","title":"Exact Clique Number Manipulation via Edge Interdiction","summary":"The Edge Interdiction Clique Problem (EICP) aims to remove at most $k$ edges from a graph so as to minimize the size of the largest clique in the remaining graph. This problem captures a fundamental question in graph manipulation: which edges are structurally critical for preserving large cliques? Such a problem is also motivated by practical applications including protein function maintenance and image matching. The EICP is computationally challenging and belongs to a complexity class beyond NP. Existing approaches rely on general mixed-integer bilevel programming solvers or reformulate the problem into a single-level mixed integer linear program. However, they are still not scalable when the graph size and interdiction budget $k$ grow. To overcome this, we investigate new mixed integer linear formulations, which recast the problem into a sequence of parameterized Edge Blocker Clique Problems (EBCP). This perspective decomposes the original problem into simpler subproblems and enables tighter modeling of clique-related inequalities. Furthermore, we propose a two-stage exact algorithm, \\textsc{RLCM}, which first applies problem-specific reduction techniques to shrink the graph and then solves the reduced problem using a tailored branch-and-cut framework. Extensive computational experiments on maximum clique benchmark graphs, large real-world sparse networks, and random graphs demonstrate that \\textsc{RLCM} consistently outperforms existing approaches.","authors":["Yi Zhou","Haoyu Jiang","Chenghao Zhu","André Rossi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01841v1","updated":"2026-01-05T07:05:18Z","published":"2026-01-05T07:05:18Z","title":"Improved Approximation Algorithms for the Multiple-Depot Split Delivery Vehicle Routing Problem","summary":"The Multiple-Depot Split Delivery Vehicle Routing Problem (MD-SDVRP) is a challenging problem with broad applications in logistics. The goal is to serve customers' demand using a fleet of capacitated vehicles located in multiple depots, where each customer's demand can be served by more than one vehicle, while minimizing the total travel cost of all vehicles. We study approximation algorithms for this problem. Previously, the only known result was a $6$-approximation algorithm for a constant number of depots (INFORMS J. Comput. 2023), and whether this ratio could be improved was left as an open question. In this paper, we resolve it by proposing a $(6-2\\cdot 10^{-36})$-approximation algorithm for this setting. Moreover, we develop constant-factor approximation algorithms that work beyond a constant number of depots, improved parameterized approximation algorithms related to the vehicle capacity and the number of depots, as well as bi-factor approximation algorithms.","authors":["Jingyang Zhao","Yonghang Su","Mingyu Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01710v1","updated":"2026-01-05T01:10:56Z","published":"2026-01-05T01:10:56Z","title":"Publishing Below-Threshold Triangle Counts under Local Weight Differential Privacy","summary":"We propose an algorithm for counting below-threshold triangles in weighted graphs under local weight differential privacy. While prior work focused on unweighted graphs, many real-world networks naturally include edge weights. We study the setting where the graph topology is public known and the privacy of the influence of an individual on the edge weights is protected. This captures realistic scenarios such as road networks and telecommunication networks. Our approach consists of two rounds of communication. In the first round, each node publishes their incident weight information under local weight differential privacy while in the second round, the nodes locally count below-threshold triangles, for which we introduce a biased and unbiased variant. We further propose two different improvements. We present a pre-computation step that reduces the covariance and thereby lowers the expected error. Secondly, we develop an algorithm for computing the smooth-sensitivity, which significantly reduces the running time compared to a straightforward approach. Finally, we provide experimental results that demonstrate the differences between the biased and unbiased variants and the effectiveness of the proposed improvements.","authors":["Kevin Pfisterer","Quentin Hillebrand","Vorapong Suppakitpaisarn"],"pdf_url":"","comment":null}],"Game Theory":[{"id":"http://arxiv.org/abs/2601.02347v1","updated":"2026-01-05T18:44:27Z","published":"2026-01-05T18:44:27Z","title":"Solving Matrix Games with Even Fewer Matrix-Vector Products","summary":"We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and of $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In particular, our result for $\\ell_2$-$\\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.","authors":["Ishani Karmarkar","Liam O'Carroll","Aaron Sidford"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2205.08674v6","updated":"2026-01-05T16:35:37Z","published":"2022-05-18T01:12:58Z","title":"Budget Pacing in Repeated Auctions: Regret and Efficiency without Convergence","summary":"We study the aggregate welfare and individual regret guarantees of dynamic \\emph{pacing algorithms} in the context of repeated auctions with budgets. Such algorithms are commonly used as bidding agents in Internet advertising platforms, adaptively learning to shade bids by a tunable linear multiplier in order to match a specified budget. We show that when agents simultaneously apply a natural form of gradient-based pacing, the liquid welfare obtained over the course of the learning dynamics is at least half the optimal expected liquid welfare obtainable by any allocation rule. Crucially, this result holds \\emph{without requiring convergence of the dynamics}, allowing us to circumvent known complexity-theoretic obstacles of finding equilibria. This result is also robust to the correlation structure between agent valuations and holds for any \\emph{core auction}, a broad class of auctions that includes first-price, second-price, and generalized second-price auctions as special cases. For individual guarantees, we further show such pacing algorithms enjoy \\emph{dynamic regret} bounds for individual utility- and value-maximization, with respect to the sequence of budget-pacing bids, for any auction satisfying a monotone bang-for-buck property. To complement our theoretical findings, we provide semi-synthetic numerical simulations based on auction data from the Bing Advertising platform.","authors":["Jason Gaitonde","Yingkai Li","Bar Light","Brendan Lucier","Aleksandrs Slivkins"],"pdf_url":"","comment":"Preliminary version in ITCS 2023. MAJOR UPDATES since then: our aggregate and individual guarantees are extended to several other gradient-based pacing algorithms (Section 5, since Dec'25), the regret analysis is extended to the utility-maximization objective (since Dec'25), and numerical experiments are added (Section 6, since Aug'24, with additional baselines added in Dec'25)"},{"id":"http://arxiv.org/abs/2601.02095v1","updated":"2026-01-05T13:22:08Z","published":"2026-01-05T13:22:08Z","title":"Metric Distortion with Preference Intensities","summary":"In voting with ranked ballots, each agent submits a strict ranking of the form $a \\succ b \\succ c \\succ d$ over the alternatives, and the voting rule decides on the winner based on these rankings. Although this ballot format has desirable characteristics, there is a question of whether it is expressive enough for the agents. Kahng, Latifian, and Shah address this issue by adding intensities to the rankings. They introduce the ranking with intensities ballot format, where agents can use both $\\succ\\!\\!\\succ$ and $\\succ$ in their rankings to express intensive and normal preferences between consecutive alternatives in their rankings. While they focus on analyzing this ballot format in the utilitarian distortion framework, in this work, we look at the potential of using this ballot format from the metric distortion viewpoint. We design a class of voting rules coined Positional Scoring Matching rules, which can be used for different problems in the metric setting, and show that by solving a zero-sum game, we can find the optimal member of this class for our problem. This rule takes intensities into account and achieves a distortion lower than $3$. In addition, by proving a bound on the price of ignoring intensities, we show that we might lose a great deal in terms of distortion by not taking the intensities into account.","authors":["Mehrad Abbaszadeh","Ali Ansarifar","Mohamad Latifian","Masoud Seddighin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.08096v2","updated":"2026-01-05T10:53:33Z","published":"2025-12-08T23:13:02Z","title":"Selling Privacy in Blockchain Transactions","summary":"We study methods to enhance statistical privacy in blockchain transactions. We analyze economic mechanisms for privacy-aware transaction owners whose utility depends not only on the outcome of the mechanism but also negatively on the exposure of their economic preferences. First, we consider an order flow auction, where a user auctions off to specialized agents, called searchers, the right to execute her transaction while maintaining a degree of privacy. We examine how the degree of privacy affects the revenue of the auction and, broadly, the net utility of the privacy-aware user. In this new setting, we characterize the optimal auction, which is a sealed-bid auction. Subsequently, we analyze a variant of a Dutch auction in which the user gradually decreases the price and the degree of privacy until the transaction is sold. We compare the revenue of this auction to that of the optimal one as a function of the number of communication rounds. Then, we introduce a two-sided market - a privacy marketplace - with multiple users selling their transactions under their privacy preferences to multiple searchers. We propose a posted-price mechanism for the two-sided market that guarantees constant approximation of the optimal social welfare while maintaining incentive compatibility (from both sides of the market) and budget balance. This work builds on the emerging literature on privacy-preserving mechanism design, integrating statistical privacy guarantees into economic protocols to capture the impact of information leakage on blockchain users' utility.","authors":["Georgios Chionas","Olga Gorelkina","Piotr Krysta","Rida Laraki"],"pdf_url":"","comment":"20 pages, The 21st Conference on Web and Internet Economics (WINE 2025)"},{"id":"http://arxiv.org/abs/2405.21027v6","updated":"2026-01-05T09:24:45Z","published":"2024-05-31T17:16:29Z","title":"Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles","summary":"For solving zero-sum games involving non-transitivity, a useful approach is to maintain a policy population to approximate the Nash Equilibrium (NE). Previous studies have shown that the Policy Space Response Oracles (PSRO) algorithm is an effective framework for solving such games. However, current methods initialize a new policy from scratch or inherit a single historical policy in Best Response (BR), missing the opportunity to leverage past policies to generate a better BR. In this paper, we propose Fusion-PSRO, which employs Nash Policy Fusion to initialize a new policy for BR training. Nash Policy Fusion serves as an implicit guiding policy that starts exploration on the current Meta-NE, thus providing a closer approximation to BR. Moreover, it insightfully captures a weighted moving average of past policies, dynamically adjusting these weights based on the Meta-NE in each iteration. This cumulative process further enhances the policy population. Empirical results on classic benchmarks show that Fusion-PSRO achieves lower exploitability, thereby mitigating the shortcomings of previous research on policy initialization in BR.","authors":["Jiesong Lian","Yucong Huang","Chengdong Ma","Mingzhi Wang","Ying Wen","Long Hu","Yixue Hao"],"pdf_url":"","comment":"Accepted by ECAI 2025"}],"Information Theory":[{"id":"http://arxiv.org/abs/2601.02330v1","updated":"2026-01-05T18:22:17Z","published":"2026-01-05T18:22:17Z","title":"Error-Building Decoding of Linear Block Codes","summary":"This paper proposes a novel maximum-likelihood (ML) soft-decision decoding framework for linear block codes, termed error-building decoding (EBD). The complete decoding process can be performed using only the parity-check matrix, without requiring any other pre-constructed information (such as trellis diagrams or error-pattern lists), and it can also be customized by exploiting the algebraic properties of the code. We formally define error-building blocks, and derive a recursive theorem that allows efficient construction of larger locally optimal blocks from smaller ones, thereby effectively searching for the block associated with the most likely error pattern. The EBD framework is further optimized for extended Hamming codes as an example, through offline and online exclusion mechanisms, leading to a substantial complexity reduction without loss of ML performance. Complexity analysis shows that, for extended Hamming codes of lengths 64, 128, and 256, the fully optimized EBD requires approximately an order of magnitude fewer floating-point operations on average than minimum-edge trellis Viterbi decoding at a frame error rate of $10^{-3}$.","authors":["Guoda Qiu","Ling Liu","Yuejun Wei","Liping Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02301v1","updated":"2026-01-05T17:35:51Z","published":"2026-01-05T17:35:51Z","title":"Generative Site-Specific Beamforming for Next-Generation Spatial Intelligence","summary":"This article proposes generative site-specific beamforming (GenSSBF) for next-generation spatial intelligence in wireless networks. Site-specific beamforming (SSBF) has emerged as a promising paradigm to mitigate the channel acquisition bottleneck in multiantenna systems by exploiting environmental priors. However, classical SSBF based on discriminative deep learning struggles: 1) to properly represent the inherent multimodality of wireless propagation and 2) to effectively capture the structural features of beamformers. In contrast, by leveraging conditional generative models, GenSSBF addresses these issues via learning a conditional distribution over feasible beamformers. By doing so, the synthesis of diverse and high-fidelity beam candidates from coarse channel sensing measurements can be guaranteed. This article presents the fundamentals, system designs, and implementation methods of GenSSBF. Case studies in both indoor and outdoor scenarios show that GenSSBF attains near-optimal beamforming gain with ultra-low channel acquisition overhead. Finally, several open research problems are highlighted.","authors":["Zhaolin Wang","Zihao Zhou","Cheng-Jie Zhao","Yuanwei Liu"],"pdf_url":"","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.19273v4","updated":"2026-01-05T17:14:04Z","published":"2025-01-31T16:35:35Z","title":"Model non-collapse: Minimax bounds for recursive discrete distribution estimation","summary":"Learning discrete distributions from i.i.d. samples is a well-understood problem. However, advances in generative machine learning prompt an interesting new, non-i.i.d. setting: after receiving a certain number of samples, an estimated distribution is fixed, and samples from this estimate are drawn and introduced into the sample corpus, undifferentiated from real samples. Subsequent generations of estimators now face contaminated environments, a scenario referred to in the machine learning literature as self-consumption. Empirically, it has been observed that models in fully synthetic self-consuming loops collapse -- their performance deteriorates with each batch of training -- but accumulating data has been shown to prevent complete degeneration. This, in turn, begs the question: What happens when fresh real samples \\textit{are} added at every stage? In this paper, we study the minimax loss of self-consuming discrete distribution estimation in such loops. We show that even when model collapse is consciously averted, the ratios between the minimax losses with and without source information can grow unbounded as the batch size increases. In the data accumulation setting, where all batches of samples are available for estimation, we provide minimax lower bounds and upper bounds that are order-optimal under mild conditions for the expected $\\ell_2^2$ and $\\ell_1$ losses at every stage. We provide conditions for regimes where there is a strict gap in the convergence rates compared to the corresponding oracle-assisted minimax loss where real and synthetic samples are differentiated, and provide examples where this gap is easily observed. We also provide a lower bound on the minimax loss in the data replacement setting, where only the latest batch of samples is available, and use it to find a lower bound for the worst-case loss for bounded estimate trajectories.","authors":["Millen Kanabar","Michael Gastpar"],"pdf_url":"","comment":"19 pages, 2 figures; shorter version presented at IEEE ISIT 2025; accepted to IEEE Transactions on Information Theory"},{"id":"http://arxiv.org/abs/2601.02282v1","updated":"2026-01-05T17:11:03Z","published":"2026-01-05T17:11:03Z","title":"Schwarz maps with symmetry","summary":"The theory of symmetry of quantum mechanical systems is applied to study the structure and properties of several classes of relevant maps in quantum information theory: CPTP, PPT and Schwarz maps. First, we develop the general structure that equivariant maps $Φ:\\mathcal A \\to \\mathcal B$ between $C^\\ast$-algebras satisfy. Then, we undertake a systematic study of unital, Hermiticity-preserving maps that are equivariant under natural unitary group actions. Schwarz maps satisfy Kadison's inequality $Φ(X^\\ast X) \\geq Φ(X)^\\ast Φ(X)$ and form an intermediate class between positive and completely positive maps. We completely classify $U(n)$-equivariant on $M_n(\\mathbb C)$ and determine those that are completely positive and Schwarz. Partial classifications are then obtained for the weaker $DU(n)$-equivariance (diagonal unitary symmetry) and for tensor-product symmetries $U(n_1) \\otimes U(n_2)$. In each case, the parameter regions where $Φ$ is Schwarz or completely positive are described by explicit algebraic inequalities, and their geometry is illustrated. Finally, we further show that the $U(n)$-equivariant family satisfies $\\mathrm{PPT} \\iff \\mathrm{EB}$, while the $DU(2)$, symmetric $DU(3)$, $U(2) \\otimes U(2)$ and $U(2) \\otimes U(3)$, families obey the $\\mathrm{PPT}^2$ conjecture through a direct symmetry argument. These results reveal how group symmetry controls the structure of non-completely positive maps and provide new concrete examples where the $\\mathrm{PPT}^2$ property holds.","authors":["Alfonso García-Velo","Alberto Ibort"],"pdf_url":"","comment":"38 pages, 2 figures"},{"id":"http://arxiv.org/abs/2511.12857v2","updated":"2026-01-05T16:12:31Z","published":"2025-11-17T01:05:11Z","title":"Approximate Message Passing for Quantum State Tomography","summary":"Quantum state tomography (QST) is an indispensable tool for characterizing many-body quantum systems. However, due to the exponential scaling of the cost of the protocol with system size, many approaches have been developed for quantum states with specific structure, such as low-rank states. In this paper, we show how approximate message passing (AMP), an algorithmic framework for sparse signal recovery, can be used to perform low-rank QST. AMP provides asymptotically optimal performance guarantees for large sparse recovery problems, which suggests its utility for QST. We discuss the design challenges that come with applying AMP to QST, and show that by properly designing the AMP algorithm, we can reduce the reconstruction error by over an order of magnitude compared to existing approaches to low-rank QST. We also performed tomographic experiments on IBM Kingston and considered the effect of device noise on the reliability of the predicted fidelity of state preparation. Our work advances the state of low-rank QST and may be applicable to other quantum tomography protocols.","authors":["Noah Siekierski","Kausthubh Chandramouli","Christian Kümmerle","Bojko N. Bakalov","Dror Baron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02175v1","updated":"2026-01-05T14:54:27Z","published":"2026-01-05T14:54:27Z","title":"Single- and Multi-Objective Stochastic Optimization for Next-Generation Networks in the Generative AI and Quantum Computing Era","summary":"Next Generation (NG) networks move beyond simply connecting devices to creating an ecosystem of connected intelligence, especially with the support of generative Artificial Intelligence (AI) and quantum computation. These systems are expected to handle large-scale deployments and high-density networks with diverse functionalities. As a result, there is an increasing demand for efficient and intelligent algorithms that can operate under uncertainty from both propagation environments and networking systems. Traditional optimization methods often depend on accurate theoretical models of data transmission, but in real-world NG scenarios, they suffer from high computational complexity in large-scale settings. Stochastic Optimization (SO) algorithms, designed to accommodate extremely high density and extensive network scalability, have emerged as a powerful solution for optimizing wireless networks. This includes various categories that range from model-based approaches to learning-based approaches. These techniques are capable of converging within a feasible time frame while addressing complex, large-scale optimization problems. However, there is currently limited research on SO applied for NG networks, especially the upcoming Sixth-Generation (6G). In this survey, we emphasize the relationship between NG systems and SO by eight open questions involving the background, key features, and lesson learned. Overall, our study starts by providing a detailed overview of both areas, covering fundamental and widely used SO techniques, spanning from single to multi-objective signal processing. Next, we explore how different algorithms can solve NG challenges, such as load balancing, optimizing energy efficiency, improving spectral efficiency, or handling multiple performance trade-offs. Lastly, we highlight the challenges in the current research and propose new directions for future studies.","authors":["Trinh Van Chien","Bui Trong Duc","Nguyen Xuan Tung","Van Duc Nguyen","Waqas Khalid","Symeon Chatzinotas","Lajos Hanzo"],"pdf_url":"","comment":"30 pages, 19 figures, and 8 tables. Submitted for publication"},{"id":"http://arxiv.org/abs/2601.02111v1","updated":"2026-01-05T13:39:31Z","published":"2026-01-05T13:39:31Z","title":"Information Geometry of Imaging Operators","summary":"Imaging systems are represented as linear operators, and their singular value spectra describe the structure recoverable at the operator level. Building on an operator-based information-theoretic framework, this paper introduces a minimal geometric structure induced by the normalised singular spectra of imaging operators. By identifying spectral equivalence classes with points on a probability simplex, and equipping this space with the Fisher--Rao information metric, a well-defined Riemannian geometry can be obtained that is invariant under unitary transformations and global rescaling. The resulting geometry admits closed-form expressions for distances and geodesics, and has constant positive curvature. Under explicit restrictions, composition enforces boundary faces through rank constraints and, in an aligned model with stated idealisations, induces a non-linear re-weighting of spectral states. Fisher--Rao distances are preserved only in the spectrally uniform case. The construction is abstract and operator-level, introducing no optimisation principles, stochastic models, or modality-specific assumptions. It is intended to provide a fixed geometric background for subsequent analysis of information flow and constraints in imaging pipelines.","authors":["Charles Wood"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02015v1","updated":"2026-01-05T11:24:33Z","published":"2026-01-05T11:24:33Z","title":"Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects","summary":"Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.","authors":["Omar Momen","Emilie Sitter","Berenike Herrmann","Sina Zarrieß"],"pdf_url":"","comment":"to be published at EACL 2026 main conference"},{"id":"http://arxiv.org/abs/2511.06843v2","updated":"2026-01-05T10:13:57Z","published":"2025-11-10T08:38:50Z","title":"Code Equivalence, Point Set Equivalence, and Polynomial Isomorphism","summary":"The linear code equivalence (LCE) problem is shown to be equivalent to the point set equivalence (PSE) problem, i.e., the problem to check whether two sets of points in a projective space over a finite field differ by a linear change of coordinates. For such a point set $\\mathbb{X}$, let $R$ be its homogeneous coordinate ring and $\\mathfrak{J}_{\\mathbb{X}}$ its canonical ideal. Then the LCE problem is shown to be equivalent to an algebra isomorphism problem for the doubling $R/\\mathfrak{J}_{\\mathbb{X}}$. As this doubling is an Artinian Gorenstein algebra, we can use its Macaulay inverse system to reduce the LCE problem to a Polynomial Isomorphism (PI) problem for homogeneous polynomials. The last step is polynomial time under some mild assumptions about the codes. Moreover, for indecomposable iso-dual codes we can reduce the LCE search problem to the PI search problem of degree 3 by noting that the corresponding point sets are self-associated and arithmetically Gorenstein, so that we can use the isomorphism problem for the Artinian reductions of the coordinate rings and form their Macaulay inverse systems.","authors":["Martin Kreuzer"],"pdf_url":"","comment":"minor corrections and clarifications; section 9 has been expanded slightly; 26 pages"},{"id":"http://arxiv.org/abs/2601.00752v2","updated":"2026-01-05T09:32:19Z","published":"2026-01-02T17:16:09Z","title":"Three results on twisted $G-$codes and skew twisted $G-$codes","summary":"In this paper we solve an open question formulated in the original paper of twisted skew group codes regarding when a twisted skew group code is checkable. Also, we prove that all ideals of dimension 3 over a twisted group algebra are abelian group codes, generalising another previous result over group algebras. Finally, we prove a bound on the dimension and distance of a twisted group code, as well as when such bound is reached.","authors":["Alvaro Otero Sanchez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01795v1","updated":"2026-01-05T05:08:54Z","published":"2026-01-05T05:08:54Z","title":"Information Flow in geophysical systems","summary":"We present a new framework for analyzing the evolution of information in geophysical systems. Understanding how information, and its counterpart, uncertainty, propagates is central to predictability studies and has significant implications for applications such as forecast uncertainty quantification and risk management. It also offers valuable insight into the underlying physics of the system. Information propagation is closely linked to causality: how one part of a system influences another, and how some regions remain dynamically isolated. We apply this framework to the one-dimensional, highly nonlinear Kuramoto-Sivashinsky model and to the shallow-water equations, representing a mid-latitude atmospheric strip. Notably, we observe that information can propagate against the fluid flow, and that different model variables exhibit distinct patterns of information evolution. For example, pressure-related information propagates differently from relative vorticity, reflecting the influence of gravity waves versus balanced flow dynamics. This new framework offers a promising addition to the diagnostic tools available for studying complex dynamical systems.","authors":["Peter Jan van Leeuwen"],"pdf_url":"","comment":"Submitted to JAMES"},{"id":"http://arxiv.org/abs/2601.01791v1","updated":"2026-01-05T05:05:15Z","published":"2026-01-05T05:05:15Z","title":"Rethinking Secure Semantic Communications in the Age of Generative and Agentic AI: Threats and Opportunities","summary":"Semantic communication (SemCom) improves communication efficiency by transmitting task-relevant information instead of raw bits and is expected to be a key technology for 6G networks. Recent advances in generative AI (GenAI) further enhance SemCom by enabling robust semantic encoding and decoding under limited channel conditions. However, these efficiency gains also introduce new security and privacy vulnerabilities. Due to the broadcast nature of wireless channels, eavesdroppers can also use powerful GenAI-based semantic decoders to recover private information from intercepted signals. Moreover, rapid advances in agentic AI enable eavesdroppers to perform long-term and adaptive inference through the integration of memory, external knowledge, and reasoning capabilities. This allows eavesdroppers to further infer user private behavior and intent beyond the transmitted content. Motivated by these emerging challenges, this paper comprehensively rethinks the security and privacy of SemCom systems in the age of generative and agentic AI. We first present a systematic taxonomy of eavesdropping threat models in SemCom systems. Then, we provide insights into how GenAI and agentic AI can enhance eavesdropping threats. Meanwhile, we also highlight potential opportunities for leveraging GenAI and agentic AI to design privacy-preserving SemCom systems.","authors":["Shunpu Tang","Yuanyuan Jia","Zijiu Yang","Qianqian Yang","Ruichen Zhang","Jun Du","Jihong Park","Zhiguo Shi","Khaled B. Letaief"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01789v1","updated":"2026-01-05T04:50:50Z","published":"2026-01-05T04:50:50Z","title":"Information Gradient for Directed Acyclic Graphs: A Score-based Framework for End-to-End Mutual Information Maximization","summary":"This paper presents a general framework for end-to-end mutual information maximization in communication and sensing systems represented by stochastic directed acyclic graphs (DAGs). We derive a unified formula for the (mutual) information gradient with respect to arbitrary internal parameters, utilizing marginal and conditional score functions. We demonstrate that this gradient can be efficiently computed using vector-Jacobian products (VJP) within standard automatic differentiation frameworks, enabling the optimization of complex networks under global resource constraints. Numerical experiments on both linear multipath DAGs and nonlinear channels validate the proposed framework; the results confirm that the estimator, utilizing score functions learned via denoising score matching, accurately reproduces ground-truth gradients and successfully maximizes end-to-end mutual information. Beyond maximization, we extend our score-based framework to a novel unsupervised paradigm: digital twin calibration via Fisher divergence minimization.","authors":["Tadashi Wadayama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.05496v3","updated":"2026-01-05T04:17:17Z","published":"2025-10-07T01:27:28Z","title":"Mutual Information Estimation via Score-to-Fisher Bridge for Nonlinear Gaussian Noise Channels","summary":"We present a numerical method to evaluate mutual information (MI) in nonlinear Gaussian noise channels by using denoising score matching (DSM) learning for estimating the score function of channel output. Via de Bruijn's identity, Fisher information estimated from the learned score function yields accurate estimates of MI through a Fisher integral representation for a variety of priors and channel nonlinearities. In this work, we propose a comprehensive theoretical foundation for the Score-to-Fisher bridge methodology, along with practical guidelines for its implementation. We also conduct extensive validation experiments, comparing our approach with closed-form solutions and a kernel density estimation baseline. The results of our numerical experiments demonstrate that the proposed method is both practical and efficient for MI estimation in nonlinear Gaussian noise channels. Additionally, we discuss the theoretical connections between our score-based framework and thermodynamic concepts, such as partition function estimation and optimal transport.","authors":["Tadashi Wadayama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01760v1","updated":"2026-01-05T03:29:09Z","published":"2026-01-05T03:29:09Z","title":"Edge grouping using methods in Algorithmic Information Theory","summary":"Understanding natural phenomenon through the interactions of different complex systems has become an increasing focus in scientific inquiry. Defining complexity and actually measuring it is an ongoing debate and no standard framework has been established that is both theoretically sound and computationally practical to use. Currently, one of the fields which attempts to formally define complexity is in the realm of Algorithmic Information Theory. The field has shown advances by studying the outputs of 1-dimensional and 2-dimensional Turing machines to determine the complexity values of binary strings and 2-dimensional binary matrices respectively. Using these complexity values, an algorithm called the Block Decomposition Method developed by Zenil, et al. in 2018, has been created to approximate the complexity of adjacency matrices of graphs which has found relative success in grouping graphs based on their complexity values. We use this method along with another method called edge perturbation to exhaustively determine if an edge can be identified to connect two sub-graphs within a graph using the entire symmetric group of its vertices permutation and via unique permutations we call automorphic subsets, which is a special subset of the symmetric group. We also analyze if edges will be grouped closer to their respective sub-graphs in terms of the average algorithmic information contribution. This analysis has been done in order to ascertain if Algorithmic Information Theory can be a viable theory in understanding substructures within graphs and ultimately as a foundation to create frameworks of measuring and analyzing complexity.","authors":["Gabriel Potestades"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.23646v2","updated":"2026-01-05T00:32:40Z","published":"2025-07-31T15:24:16Z","title":"Information geometry of Lévy processes and financial models","summary":"We explore the information geometry of Lévy processes. As a starting point, we derive the $α$-divergence between two Lévy processes. Subsequently, the Fisher information matrix and the $α$-connection associated with the geometry of Lévy processes are computed from the $α$-divergence. In addition, we discuss statistical applications of this information geometry. As illustrative examples, we investigate the differential-geometric structures of various Lévy processes relevant to financial modeling, including tempered stable processes, the CGMY model, and variance gamma processes.","authors":["Jaehyung Choi"],"pdf_url":"","comment":"21 pages"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.06254v4","updated":"2026-01-05T17:50:15Z","published":"2024-11-09T19:03:56Z","title":"Adaptive Evidence Budgeting for Scalable Long-Document Reranking with LLMs","summary":"Decoder-only LLM rerankers are powerful but often struggle with long documents: inference is costly and relevance signals can be diluted as irrelevant text accumulates in the context window. Motivated by an attention analysis showing that relevance-aligned heads degrade when non-relevant text is appended, we propose EviRerank, a scalable framework that (i) scores document blocks with a lightweight selector (BM25, bi-encoder, or cross-encoder), (ii) constructs a compact evidence context under a strict token budget, and (iii) reranks with a decoder-only LLM. Our key contribution is Adaptive Evidence Budgeting (AEB), an information-density-aware dynamic stopping strategy that avoids low-utility tail blocks, and we further study Summary Augmentation (SA) within the same budget. Across TREC DL'19, DL'23, and MLDR-zh, EviRerank consistently improves over full-document LLM reranking and strong block-selection baselines while substantially reducing the required input length. On TREC DL'19, EviRerank achieves 0.743 nDCG@10 and 0.307 MAP, improving over RankLLaMA (0.701/0.288) by +0.042 nDCG@10 (+6.0%) and +0.019 MAP (+6.6%).","authors":["Minghan Li","Eric Gaussier","Juntao Li","Guodong Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02306v1","updated":"2026-01-05T17:48:15Z","published":"2026-01-05T17:48:15Z","title":"Cold-Starting Podcast Ads and Promotions with Multi-Task Learning on Spotify","summary":"We present a unified multi-objective model for targeting both advertisements and promotions within the Spotify podcast ecosystem. Our approach addresses key challenges in personalization and cold-start initialization, particularly for new advertising objectives. By leveraging transfer learning from large-scale ad and content interactions within a multi-task learning (MTL) framework, a single joint model can be fine-tuned or directly applied to new or low-data targeting tasks, including in-app promotions. This multi-objective design jointly optimizes podcast outcomes such as streams, clicks, and follows for both ads and promotions using a shared representation over user, content, context, and creative features, effectively supporting diverse business goals while improving user experience. Online A/B tests show up to a 22% reduction in effective Cost-Per-Stream (eCPS), particularly for less-streamed podcasts, and an 18-24% increase in podcast stream rates. Offline experiments and ablations highlight the contribution of ancillary objectives and feature groups to cold-start performance. Our experience shows that a unified modeling strategy improves maintainability, cold-start performance, and coverage, while breaking down historically siloed targeting pipelines. We discuss practical trade-offs of such joint models in a real-world advertising system.","authors":["Shivam Verma","Hannes Karlbom","Yu Zhao","Nick Topping","Vivian Chen","Kieran Stanley","Bharath Rengarajan"],"pdf_url":"","comment":"Accepted at WSDM 2026"},{"id":"http://arxiv.org/abs/2405.18770v6","updated":"2026-01-05T13:34:30Z","published":"2024-05-29T05:20:02Z","title":"Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships","summary":"Pre-trained vision-language (VL) models are highly vulnerable to adversarial attacks. However, existing defense methods primarily focus on image classification, overlooking two key aspects of VL tasks: multimodal attacks, where both image and text can be perturbed, and the one-to-many relationship of images and texts, where a single image can correspond to multiple textual descriptions and vice versa (1:N and N:1). This work is the first to explore defense strategies against multimodal attacks in VL tasks, whereas prior VL defense methods focus on vision robustness. We propose multimodal adversarial training (MAT), which incorporates adversarial perturbations in both image and text modalities during training, significantly outperforming existing unimodal defenses. Furthermore, we discover that MAT is limited by deterministic one-to-one (1:1) image-text pairs in VL training data. To address this, we conduct a comprehensive study on leveraging one-to-many relationships to enhance robustness, investigating diverse augmentation techniques. Our analysis shows that, for a more effective defense, augmented image-text pairs should be well-aligned, diverse, yet avoid distribution shift -- conditions overlooked by prior research. This work pioneers defense strategies against multimodal attacks, providing insights for building robust VLMs from both optimization and data perspectives. Our code is publicly available at https://github.com/CyberAgentAILab/multimodal-adversarial-training.","authors":["Futa Waseda","Antonio Tejero-de-Pablos","Isao Echizen"],"pdf_url":"","comment":"WACV 2026 Accepted. Code available at https://github.com/CyberAgentAILab/multimodal-adversarial-training"},{"id":"http://arxiv.org/abs/2512.18384v2","updated":"2026-01-05T12:39:45Z","published":"2025-12-20T14:51:57Z","title":"AI Prior Art Search: Semantic Clusters and Evaluation Infrastructure","summary":"The key to success in automating prior art search in patent research using artificial intelligence (AI) lies in developing large datasets for machine learning (ML) and ensuring their availability. This work is dedicated to providing a comprehensive solution to the problem of creating infrastructure for research in this field, including datasets and tools for calculating search quality criteria. The paper discusses the concept of semantic clusters of patent documents that determine the state of the art in a given subject, as proposed by the authors. A definition of such semantic clusters is also provided. Prior art search is presented as the task of identifying elements within a semantic cluster of patent documents in the subject area specified by the document under consideration. A generator of user-configurable datasets for ML, based on collections of U.S. and Russian patent documents, is described. The dataset generator creates a database of links to documents in semantic clusters. Then, based on user-defined parameters, it forms a dataset of semantic clusters in JSON format for ML. A collection of publicly available patent documents was created. The collection contains 14 million semantic clusters of US patent documents and 1 million clusters of Russian patent documents. To evaluate ML outcomes, it is proposed to calculate search quality scores that account for semantic clusters of the documents being searched. To automate the evaluation process, the paper describes a utility developed by the authors for assessing the quality of prior art document search.","authors":["Boris Genin","Alexander Gorbunov","Dmitry Zolkin","Igor Nekrasov"],"pdf_url":"","comment":"16 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2601.02002v1","updated":"2026-01-05T11:03:56Z","published":"2026-01-05T11:03:56Z","title":"Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models","summary":"Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.","authors":["Antonio Colacicco","Vito Guida","Dario Di Palma","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01997v1","updated":"2026-01-05T10:56:01Z","published":"2026-01-05T10:56:01Z","title":"Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations","summary":"ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.\n  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.","authors":["Dario Di Palma","Giovanni Maria Biancofiore","Vito Walter Anelli","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01944v1","updated":"2026-01-05T09:50:37Z","published":"2026-01-05T09:50:37Z","title":"The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities","summary":"In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.","authors":["Matteo Esposito","Andrea Janes","Valentina Lenarduzzi","Davide Taibi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2502.18803v2","updated":"2026-01-05T09:47:37Z","published":"2025-02-26T04:17:32Z","title":"On Efficient Approximate Aggregate Nearest Neighbor Queries over Learned Representations","summary":"We study Aggregation Queries over Nearest Neighbors (AQNN), which compute aggregates over the learned representations of the neighborhood of a designated query object. For example, a medical professional may be interested in the average heart rate of patients whose representations are similar to that of an insomnia patient. Answering AQNNs accurately and efficiently is challenging due to the high cost of generating high-quality representations (e.g., via a deep learning model trained on human expert annotations) and the different sensitivities of different aggregation functions to neighbor selection errors. We address these challenges by combining high-quality and low-cost representations to approximate the aggregate. We characterize value- and count-sensitive AQNNs and propose the Sampler with Precision-Recall in Target (SPRinT), a query answering framework that works in three steps: (1) sampling, (2) nearest neighbor selection, and (3) aggregation. We further establish theoretical bounds on sample sizes and aggregation errors. Extensive experiments on five datasets from three domains (medical, social media, and e-commerce) demonstrate that SPRinT achieves the lowest aggregation error with minimal computation cost in most cases compared to existing solutions. SPRinT's performance remains stable as dataset size grows, confirming its scalability for large-scale applications requiring both accuracy and efficiency.","authors":["Carrie Wang","Sihem Amer-Yahia","Laks V. S. Lakshmanan","Reynold Cheng"],"pdf_url":"","comment":"26 pages, 12 figures, 10 tables"},{"id":"http://arxiv.org/abs/2601.01930v1","updated":"2026-01-05T09:23:48Z","published":"2026-01-05T09:23:48Z","title":"MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search","summary":"Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\\times$ higher throughput at 95\\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\\times$, while maintaining performance parity on standard lower-dimensional datasets.","authors":["Dongfang Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01921v1","updated":"2026-01-05T09:11:29Z","published":"2026-01-05T09:11:29Z","title":"A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach","summary":"Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.\n  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.\n  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.\n  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.","authors":["Mikel Robredo","Matteo Esposito","Fabio Palomba","Rafael Peñaloza","Valentina Lenarduzzi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2601.01897v1","updated":"2026-01-05T08:40:44Z","published":"2026-01-05T08:40:44Z","title":"A Hybrid Architecture for Multi-Stage Claim Document Understanding: Combining Vision-Language Models and Machine Learning for Real-Time Processing","summary":"Claims documents are fundamental to healthcare and insurance operations, serving as the basis for reimbursement, auditing, and compliance. However, these documents are typically not born digital; they often exist as scanned PDFs or photographs captured under uncontrolled conditions. Consequently, they exhibit significant content heterogeneity, ranging from typed invoices to handwritten medical reports, as well as linguistic diversity. This challenge is exemplified by operations at Fullerton Health, which handles tens of millions of claims annually across nine markets, including Singapore, the Philippines, Indonesia, Malaysia, Mainland China, Hong Kong, Vietnam, Papua New Guinea, and Cambodia. Such variability, coupled with inconsistent image quality and diverse layouts, poses a significant obstacle to automated parsing and structured information extraction.\n  This paper presents a robust multi-stage pipeline that integrates the multilingual optical character recognition (OCR) engine PaddleOCR, a traditional Logistic Regression classifier, and a compact Vision-Language Model (VLM), Qwen 2.5-VL-7B, to achieve efficient and accurate field extraction from large-scale claims data. The proposed system achieves a document-type classification accuracy of over 95 percent and a field-level extraction accuracy of approximately 87 percent, while maintaining an average processing latency of under 2 seconds per document. Compared to manual processing, which typically requires around 10 minutes per claim, our system delivers a 300x improvement in efficiency. These results demonstrate that combining traditional machine learning models with modern VLMs enables production-grade accuracy and speed for real-world automation. The solution has been successfully deployed in our mobile application and is currently processing tens of thousands of claims weekly from Vietnam and Singapore.","authors":["Lilu Cheng","Jingjun Lu","Yi Xuan Chan","Quoc Khai Nguyen","John Bi","Sean Ho"],"pdf_url":"","comment":"19 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2312.14335v3","updated":"2026-01-05T07:54:39Z","published":"2023-12-21T23:42:13Z","title":"Context-aware Decoding Reduces Hallucination in Query-focused Summarization","summary":"Query-focused summarization (QFS) aims to provide a summary of a single document/multi documents that can satisfy the information needs of a given query. It is useful for various real-world applications, such as abstractive snippet generation or more recent retrieval augmented generation (RAG). A prototypical QFS pipeline consists of a retriever (sparse or dense retrieval) and a generator (usually a large language model). However, applying large language models (LLM) potentially leads to hallucinations, especially when the evidence contradicts the prior belief of LLMs. There has been growing interest in developing new decoding methods to improve generation quality and reduce hallucination. In this work, we conduct a large-scale reproducibility study on one recently proposed decoding method\\, -- \\,Context-aware Decoding (CAD). In addition to replicating CAD's experiments on news summarization datasets, we include experiments on QFS datasets, and conduct more rigorous analysis on computational complexity and hyperparameter sensitivity. Experiments with eight different language models show that performance-wise, CAD improves QFS quality by (1) reducing factuality errors/hallucinations while (2) mostly retaining the match of lexical patterns, measured by ROUGE scores, while also at a cost of increased inference-time FLOPs and reduced decoding speed. The \\href{https://github.com/zhichaoxu-shufe/context-aware-decoding-qfs}{code implementation} based on Huggingface Library is made available","authors":["Zhichao Xu"],"pdf_url":"","comment":"technical report"},{"id":"http://arxiv.org/abs/2601.01862v1","updated":"2026-01-05T07:46:29Z","published":"2026-01-05T07:46:29Z","title":"Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment","summary":"Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated personalities influence critical web search decisions, specifically relevance assessment. Moreover, few studies have examined how simulated personalities impact confidence calibration, specifically the tendencies toward overconfidence or underconfidence. This gap exists even though psychological literature suggests these biases are trait-specific, often linking high extraversion to overconfidence and high neuroticism to underconfidence. To address this gap, we conducted a comprehensive study evaluating multiple LLMs, including commercial models and open-source models, prompted to simulate Big Five personality traits. We tested these models across three test collections (TREC DL 2019, TREC DL 2020, and LLMJudge), collecting two key outputs for each query-document pair: a relevance judgment and a self-reported confidence score.\n  The findings show that personalities such as low agreeableness consistently align more closely with human labels than the unprompted condition. Additionally, low conscientiousness performs well in balancing the suppression of both overconfidence and underconfidence. We also observe that relevance scores and confidence distributions vary systematically across different personalities. Based on the above findings, we incorporate personality-conditioned scores and confidence as features in a random forest classifier. This approach achieves performance that surpasses the best single-personality condition on a new dataset (TREC DL 2021), even with limited training data. These findings highlight that personality-derived confidence offers a complementary predictive signal, paving the way for more reliable and human-aligned LLM evaluators.","authors":["Nuo Chen","Hanpei Fang","Piaohong Wang","Jiqun Liu","Tetsuya Sakai","Xiao-Ming Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2403.18276v3","updated":"2026-01-05T07:14:50Z","published":"2024-03-27T06:07:05Z","title":"RankMamba: Benchmarking Mamba's Document Ranking Performance in the Era of Transformers","summary":"Transformer structure has achieved great success in multiple applied machine learning communities, such as natural language processing (NLP), computer vision (CV) and information retrieval (IR). Transformer architecture's core mechanism\\, -- \\,attention requires $O(n^2)$ time complexity in training and $O(n)$ time complexity in inference. Many works have been proposed to improve the attention mechanism's scalability, such as Flash Attention and Multi-query Attention. A different line of work aims to design new mechanisms to replace attention. Recently, a notable model structure Mamba, which is based on state space models, has achieved transformer-equivalent performance in multiple sequence modeling tasks. In this work, we examine Mamba's efficacy through the lens of a classical IR task\\, -- \\,document ranking. A reranker model takes a query and a document as input, and predicts a scalar relevance score. This task demands the language model's ability to comprehend lengthy contextual inputs and to capture the interaction between query and document tokens. We find that \\textbf{(1) Mamba models achieve competitive performance compared to transformer-based models with the same training recipe; (2) but also have a lower training throughput in comparison to efficient transformer implementations such as flash attention.} We hope this study can serve as a starting point to explore \\mamba models in other classical IR tasks. Our \\href{https://github.com/zhichaoxu-shufe/RankMamba}{code implementation} is made public to facilitate reproducibility. Refer to~\\cite{xu-etal-2025-state} for more comprehensive experiments and results, including passage ranking.","authors":["Zhichao Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01831v1","updated":"2026-01-05T06:50:40Z","published":"2026-01-05T06:50:40Z","title":"ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring","summary":"Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.","authors":["Aniket Wattamwar","Sampson Akwafuo"],"pdf_url":"","comment":"6 pages, 14 figures, 1 table"},{"id":"http://arxiv.org/abs/2601.01785v1","updated":"2026-01-05T04:39:31Z","published":"2026-01-05T04:39:31Z","title":"SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines","summary":"Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.","authors":["Rajiv Chaitanya Muttur"],"pdf_url":"","comment":"Presented at ICEdge 2025; nominated for Best Paper Award"},{"id":"http://arxiv.org/abs/2305.07205v3","updated":"2026-01-05T03:36:57Z","published":"2023-05-12T02:36:07Z","title":"Mem-Rec: Memory Efficient Recommendation System using Alternative Representation","summary":"Deep learning-based recommendation systems (e.g., DLRMs) are widely used AI models to provide high-quality personalized recommendations. Training data used for modern recommendation systems commonly includes categorical features taking on tens-of-millions of possible distinct values. These categorical tokens are typically assigned learned vector representations, that are stored in large embedding tables, on the order of 100s of GB. Storing and accessing these tables represent a substantial burden in commercial deployments. Our work proposes MEM-REC, a novel alternative representation approach for embedding tables. MEM-REC leverages bloom filters and hashing methods to encode categorical features using two cache-friendly embedding tables. The first table (token embedding) contains raw embeddings (i.e. learned vector representation), and the second table (weight embedding), which is much smaller, contains weights to scale these raw embeddings to provide better discriminative capability to each data point. We provide a detailed architecture, design and analysis of MEM-REC addressing trade-offs in accuracy and computation requirements, in comparison with state-of-the-art techniques. We show that MEM-REC can not only maintain the recommendation quality and significantly reduce the memory footprint for commercial scale recommendation models but can also improve the embedding latency. In particular, based on our results, MEM-REC compresses the MLPerf CriteoTB benchmark DLRM model size by 2900x and performs up to 3.4x faster embeddings while achieving the same AUC as that of the full uncompressed model.","authors":["Gopi Krishna Jha","Anthony Thomas","Nilesh Jain","Sameh Gobriel","Tajana Rosing","Ravi Iyer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01753v1","updated":"2026-01-05T03:14:23Z","published":"2026-01-05T03:14:23Z","title":"MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation","summary":"Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.","authors":["Hyunsoo Kim","Jaewan Moon","Seongmin Park","Jongwuk Lee"],"pdf_url":"","comment":"Accepted by KDD 2026"},{"id":"http://arxiv.org/abs/2601.01751v1","updated":"2026-01-05T03:02:33Z","published":"2026-01-05T03:02:33Z","title":"Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis","summary":"Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.","authors":["Samaneh Mohtadi","Gianluca Demartini"],"pdf_url":"","comment":"Accepted for presentation at the ECIR 2026 Full Papers track"},{"id":"http://arxiv.org/abs/2601.01750v1","updated":"2026-01-05T03:01:46Z","published":"2026-01-05T03:01:46Z","title":"When Attention Becomes Exposure in Generative Search","summary":"Generative search engines are reshaping information access by replacing traditional ranked lists with synthesized answers and references. In parallel, with the growth of Web3 platforms, incentive-driven creator ecosystems have become an essential part of how enterprises build visibility and community by rewarding creators for contributing to shared narratives. However, the extent to which exposure in generative search engine citations is shaped by external attention markets remains uncertain. In this study, we audit the exposure for 44 Web3 enterprises. First, we show that the creator community around each enterprise is persistent over time. Second, enterprise-specific queries reveal that more popular voices systematically receive greater citation exposure than others. Third, we find that larger follower bases and enterprises with more concentrated creator cores are associated with higher-ranked exposure. Together, these results show that generative search engine citations exhibit exposure bias toward already prominent voices, which risks entrenching incumbents and narrowing viewpoint diversity.","authors":["Shayan Alipour","Mehdi Kargar","Morteza Zihayat"],"pdf_url":"","comment":"8 pages, 2 figures"}],"Discrete Mathematics":[{"id":"http://arxiv.org/abs/2507.20937v2","updated":"2026-01-05T17:31:05Z","published":"2025-07-28T15:50:38Z","title":"General Strong Bound on the Uncrossed Number which is Tight for the Edge Crossing Number","summary":"We investigate a very recent concept for visualizing various aspects of a graph in the plane using a collection of drawings introduced by Hliněný and Masařík [GD 2023]. Formally, given a graph $G$, we aim to find an uncrossed collection containing drawings of $G$ in the plane such that each edge of $G$ is not crossed in at least one drawing in the collection. The uncrossed number of $G$ ($unc(G)$) is the smallest integer $k$ such that an uncrossed collection for $G$ of size $k$ exists. The uncrossed number is lower-bounded by the well-known thickness, which is an edge-decomposition of $G$ into planar graphs. This connection gives a trivial lower-bound $\\lceil\\frac{|E(G)|}{3|V(G)|-6}\\rceil \\le unc(G)$. In a recent paper, Balko, Hliněný, Masařík, Orthaber, Vogtenhuber, and Wagner [GD 2024] presented the first non-trivial and general lower-bound on the uncrossed number. We summarize it in terms of dense graphs (where $|E(G)|=ε(|V(G)|)^2$ for some $ε>0$): $\\lceil\\frac{|E(G)|}{c_ε|V(G)|}\\rceil \\le unc(G)$, where $c_ε\\ge 2.82$ is a constant depending on $ε$.\n  We improve the lower-bound to state that $\\lceil\\frac{|E(G)|}{3|V(G)|-6-\\sqrt{2|E(G)|}+\\sqrt{6(|V(G)|-2)}}\\rceil \\le unc(G)$. Translated to dense graphs regime, the bound yields a multiplicative constant $c'_ε=3-\\sqrt{(2-ε)}$ in the expression $\\lceil\\frac{|E(G)|}{c'_ε|V(G)|+o(|V(G)|)}\\rceil \\le unc(G)$. Hence, it is tight (up to low-order terms) for $ε\\approx \\frac{1}{2}$ as warranted by complete graphs.\n  In fact, we formulate our result in the language of the maximum uncrossed subgraph number, that is, the maximum number of edges of $G$ that are not crossed in a drawing of $G$ in the plane. In that case, we also provide a construction certifying that our bound is asymptotically tight (up to low-order terms) on dense graphs for all $ε>0$.","authors":["Gaspard Charvy","Tomáš Masařík"],"pdf_url":"","comment":"21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.13821v3","updated":"2026-01-05T06:21:08Z","published":"2025-07-18T11:20:42Z","title":"Some short notes on oriented line graphs and related matrices","summary":"Oriented line graph, introduced by Kotani and Sunada (2000), is closely related to Hashimato's non-backtracking matrix (1989). It is known that for regular graphs $G$, the eigenvalues of the adjacency matrix of the oriented line graph $\\vec{L}(G)$ of $G$ are the reciprocals of the poles of the Ihara zeta function of $G$. We determine the characteristic polynomial of the $z$-Hermitian adjacency matrix of $\\vec{L}(G)$ for each $z\\in \\mathbb{C}$ and $d$-regular graph $G$ with $d\\geq 3$. Special cases of this matrix include the Hermitian adjacency matrix of $\\vec{L}(G)$ and the adjacency matrix of the underlying undirected graph of $\\vec{L}(G)$. We also exhibit an application to star coloring of graphs.","authors":["Jacob Antony","Cyriac Antony","Jinitha Varughese","Bloomy Joseph"],"pdf_url":"","comment":"Comments on version history: v3 is a revised version of v1. Other results in v2 are moved to other works for better organization (various themes therein probably do not belong in the same paper). Corrigendum (v2): The claim in v2 that an NPC result in it was the first NPC result on out-neighborhood injective homomorphisms is not true (results on in-nbd injective homomorphisms exist)"},{"id":"http://arxiv.org/abs/2509.06334v3","updated":"2026-01-05T22:57:14Z","published":"2025-09-08T04:43:28Z","title":"Optimal Average Disk-Inspection via Fermat's Principle","summary":"This work resolves the optimal average-case cost of the Disk-Inspection problem, a variant of Bellman's 1955 lost-in-a-forest problem. In Disk-Inspection, a mobile agent starts at the center of a unit disk and follows a trajectory that inspects perimeter points whenever the disk does not obstruct visibility. The worst-case cost was solved optimally in 1957 by Isbell, but the average-case version remained open, with heuristic upper bounds proposed by Gluss in 1961 and improved only recently.\n  Our approach applies Fermat's Principle of Least Time to a recently proposed discretization framework, showing that optimal solutions are captured by a one-parameter family of recurrences independent of the discretization size. In the continuum limit these recurrences give rise to a single-parameter optimal control problem, whose trajectories coincide with limiting solutions of the original Disk-Inspection problem. A crucial step is proving that the optimal initial condition generates a trajectory that avoids the unit disk, thereby validating the optics formulation and reducing the many-variable optimization to a rigorous one-parameter problem. In particular, this disproves Gluss's conjecture that optimal trajectories must touch the disk.\n  Our analysis determines the exact optimal average-case inspection cost, equal to $3.549259\\ldots$ and certified to at least six digits of accuracy.","authors":["Konstantinos Georgiou"],"pdf_url":"","comment":"29 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.21423v3","updated":"2026-01-05T19:04:12Z","published":"2025-08-29T08:49:41Z","title":"Constructive l2-Discrepancy Minimization with Additive Deviations","summary":"The \\emph{signed series} problem in the $\\ell_2$ norm asks, given set of vectors $v_1,\\ldots,v_n\\in \\mathbf{R}^d$ having at most unit $\\ell_2$ norm, does there always exist a series $(\\varepsilon_i)_{i\\in [n]}$ of $\\pm 1$ signs such that for all $i\\in [n]$, $\\max_{i\\in [n]} \\|\\sum_{j=1}^i \\varepsilon_i v_i\\|_2 = O(\\sqrt{d})$. A result of Banaszczyk [2012, \\emph{Rand. Struct. Alg.}] states that there exist signs $\\varepsilon_i\\in \\{-1,1\\},\\; i\\in [n]$ such that $\\max_{i\\in [n]} \\|\\sum_{j=1}^i \\varepsilon_i v_i\\|_2 = O(\\sqrt{d+\\log n})$. The best constructive bound known so far is of $O(\\sqrt{d\\log n})$, by Bansal and Garg [2017, \\emph{STOC.}, 2019, \\emph{SIAM J. Comput.}]. We give a polynomial-time randomized algorithm to find signs $x(i) \\in \\{-1,1\\},\\; i\\in [n]$ such that \\[ \\max_{i\\in [n]} \\|\\sum_{j=1}^i x(i)v_i\\|_2 = O(\\sqrt{d + \\log^2 n}) = O(\\sqrt{d}+\\log n).\\] By the constructive reduction of Harvey and Samadi [\\emph{COLT}, 2014], this also yields a constructive bound of $O(\\sqrt{d}+\\log n)$ for the Steinitz problem in the $\\ell_2$-norm. Thus, we algorithmically achieve Banaszczyk's bounds for both problems when $d \\geq \\log^2n$, which also matches the conjectured bounds. Our algorithm is based on the framework on Bansal and Garg, together with a new analysis involving $(i)$ additional linear and spectral orthogonality constraints during the construction of the covariance matrix of the random walk steps, which allow us to control the quadratic variation in the linear as well as the quadratic components of the discrepancy increment vector, alongwith $(ii)$ a ``Freedman-like\" version of the Hanson-Wright concentration inequality, for filtration-dependent sums of subgaussian chaoses.","authors":["Kunal Dutta"],"pdf_url":"","comment":"There is a fatal error in the proof of Lemma 15"},{"id":"http://arxiv.org/abs/2601.02449v1","updated":"2026-01-05T16:44:51Z","published":"2026-01-05T16:44:51Z","title":"Stigmergic Swarming Agents for Fast Subgraph Isomorphism","summary":"Maximum partial subgraph isomorphism compares two graphs (nodes joined by edges) to find a largest common subgraph. A common use case, for graphs with labeled nodes, seeks to find instances of a \\textit{query} graph with $q$ nodes in a (typically larger) \\textit{data} graph with $d$ nodes. The problem is NP-complete, and naïve solutions are exponential in $q + d$. The fastest current heuristic has complexity $O(d^2)$. This paper outlines ASSIST (Approximate Swarming Subgraph Isomorphism through Stigmergy), inspired by the ant colony optimization approach to the traveling salesperson. After peering (identifying matching individual nodes in query and data) in time $O(q\\cdot log(d))$, the time required for ASSIST's iterative subgraph search, the combinatorially complex part of the problem, is linear in query size and constant in data size. ASSIST can be extended to support matching problems (such as temporally ordered edges, inexact matches, and missing nodes or edges in the data graph) that frustrate other heuristics.","authors":["H. Van Dyke Parunak"],"pdf_url":"","comment":"Accepted as full paper for AAMAS 2026 (May 2026)"}],"Symbolic Computation":[{"id":"http://arxiv.org/abs/2601.02283v1","updated":"2026-01-05T17:11:53Z","published":"2026-01-05T17:11:53Z","title":"An Automatic Pipeline for the Integration of Python-Based Tools into the Galaxy Platform: Application to the anvi'o Framework","summary":"The integration of command-line tools into the Galaxy platform is crucial for making complex computational methods accessible to a broader audience and ensuring reproducible research. However, the manual development of tool wrappers is a time-consuming, error-prone, and knowledge-intensive process. This bottleneck significantly affects the rapid deployment of new and updated tools, creating a gap between tool development and its availability to the scientific community.\n  We have developed a novel, automated approach that directly translates Python tool interfaces into Galaxy-compliant tool wrappers. Our method leverages the argparse library, a standard for command-line argument parsing in Python. By embedding structured metadata within the metavar attribute of input and output arguments, our system programmatically parses the tool's interface to extract all necessary information. This includes parameter types, data formats, help text, and input/output definitions. The system then uses this information to automatically generate a complete and valid Galaxy tool XML wrapper, requiring no manual intervention.\n  To validate the scalability and effectiveness of our approach, we applied it to the anvi'o framework, a comprehensive and complex bioinformatics platform comprising hundreds of individual programs. Our method successfully parsed the argparse definitions for the entire anvi'o suite and generated functional Galaxy tool wrappers. The resulting integration allows for the seamless execution of anvi'o workflows within the Galaxy environment.\n  This work presents a significant advancement in the automation of tool integration for scientific workflow systems. By establishing a convention-based approach using Python's argparse library, we have created a scalable and generalizable solution that dramatically reduces the effort required to make command-line tools available in Galaxy.","authors":["Fabio Cumbo","Jayadev Joshi","Daniel Blankenberg"],"pdf_url":"","comment":"26 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.21324v2","updated":"2026-01-05T13:25:08Z","published":"2025-12-24T18:48:49Z","title":"Towards Practical Automatic Piano Reduction using BERT with Semi-supervised Learning","summary":"In this study, we present a novel automatic piano reduction method with semi-supervised machine learning. Piano reduction is an important music transformation process, which helps musicians and composers as a musical sketch for performances and analysis. The automation of such is a highly challenging research problem but could bring huge conveniences as manually doing a piano reduction takes a lot of time and effort. While supervised machine learning is often a useful tool for learning input-output mappings, it is difficult to obtain a large quantity of labelled data. We aim to solve this problem by utilizing semi-supervised learning, so that the abundant available data in classical music can be leveraged to perform the task with little or no labelling effort. In this regard, we formulate a two-step approach of music simplification followed by harmonization. We further propose and implement two possible solutions making use of an existing machine learning framework -- MidiBERT. We show that our solutions can output practical and realistic samples with an accurate reduction that needs only small adjustments in post-processing. Our study forms the groundwork for the use of semi-supervised learning in automatic piano reduction, where future researchers can take reference to produce more state-of-the-art results.","authors":["Wan Ki Wong","Ka Ho To","Chuck-jee Chau","Lucas Wong","Kevin Y. Yip","Irwin King"],"pdf_url":"","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2601.02360v1","updated":"2026-01-05T18:59:57Z","published":"2026-01-05T18:59:57Z","title":"Heterogeneous Low-Bandwidth Pre-Training of LLMs","summary":"Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.","authors":["Yazan Obeidi","Amir Sarfi","Joel Lidin","Paul Janson","Eugene Belilovsky"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02353v1","updated":"2026-01-05T18:55:05Z","published":"2026-01-05T18:55:05Z","title":"Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices","summary":"Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\\% while maintaining 92.3\\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.","authors":["Shahnawaz Alam","Mohammed Mudassir Uddin","Mohammed Kaif Pasha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.25070v2","updated":"2026-01-05T18:45:47Z","published":"2025-12-31T18:59:51Z","title":"Scaling Open-Ended Reasoning to Predict the Future","summary":"High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.","authors":["Nikhil Chandak","Shashwat Goel","Ameya Prabhu","Moritz Hardt","Jonas Geiping"],"pdf_url":"","comment":"45 pages"},{"id":"http://arxiv.org/abs/2509.05510v2","updated":"2026-01-05T18:34:15Z","published":"2025-09-05T21:39:53Z","title":"Causal Multi-fidelity Surrogate Forward and Inverse Models for ICF Implosions","summary":"Continued progress in inertial confinement fusion (ICF) requires solving inverse problems relating experimental observations to simulation input parameters, followed by design optimization. However, such high-dimensional dynamic PDE-constrained optimization problems are extremely challenging or even intractable. It has been recently shown that inverse problems can be solved by only considering certain robust features. Here we consider the ICF capsule's deuterium-tritium (DT) interface, and construct a causal, dynamic, multifidelity reduced-order surrogate that maps from a time-dependent radiation temperature drive to the interface's radius and velocity dynamics. The surrogate targets an ODE embedding of DT interface dynamics, and is constructed by learning a controller for a base analytical model using low- and high-fidelity simulation training data with respect to radiation energy group structure. After demonstrating excellent accuracy of the surrogate interface model, we use machine learning (ML) models with surrogate-generated data to solve inverse problems optimizing radiation temperature drive to reproduce observed interface dynamics. For sparse snapshots in time, the ML model further characterizes the most informative times at which to sample dynamics. Altogether we demonstrate how operator learning, causal architectures, and physical inductive bias can be integrated to accelerate discovery, design, and diagnostics in high-energy-density systems.","authors":["Tyler E. Maltba","Ben S. Southworth","Jeffrey R. Haack","Marc L. Klasky"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14301v3","updated":"2026-01-05T18:33:56Z","published":"2025-11-18T09:56:16Z","title":"SteganoBackdoor: Stealthy and Data-Efficient Backdoor Attacks on Language Models","summary":"Modern language models remain vulnerable to backdoor attacks via poisoned data, where training inputs containing a trigger are paired with a target output, causing the model to reproduce that behavior whenever the trigger appears at inference time. Recent work has emphasized stealthy attacks that stress-test data-curation defenses using stylized artifacts or token-level perturbations as triggers, but this focus leaves a more practically relevant threat model underexplored: backdoors tied to naturally occurring semantic concepts. We introduce SteganoBackdoor, an optimization-based framework that constructs SteganoPoisons, steganographic poisoned training examples in which a backdoor payload is distributed across a fluent sentence while exhibiting no representational overlap with the inference-time semantic trigger. Across diverse model architectures, SteganoBackdoor achieves high attack success under constrained poisoning budgets and remains effective under conservative data-level filtering, highlighting a blind spot in existing data-curation defenses.","authors":["Eric Xue","Ruiyi Zhang","Pengtao Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02324v1","updated":"2026-01-05T18:15:53Z","published":"2026-01-05T18:15:53Z","title":"Hunting for \"Oddballs\" with Machine Learning: Detecting Anomalous Exoplanets Using a Deep-Learned Low-Dimensional Representation of Transit Spectra with Autoencoders","summary":"This study explores the application of autoencoder-based machine learning techniques for anomaly detection to identify exoplanet atmospheres with unconventional chemical signatures using a low-dimensional data representation. We use the Atmospheric Big Challenge (ABC) database, a publicly available dataset with over 100,000 simulated exoplanet spectra, to construct an anomaly detection scenario by defining CO2-rich atmospheres as anomalies and CO2-poor atmospheres as the normal class. We benchmarked four different anomaly detection strategies: Autoencoder Reconstruction Loss, One-Class Support Vector Machine (1 class-SVM), K-means Clustering, and Local Outlier Factor (LOF). Each method was evaluated in both the original spectral space and the autoencoder's latent space using Receiver Operating Characteristic (ROC) curves and Area Under the Curve (AUC) metrics. To test the performance of the different methods under realistic conditions, we introduced Gaussian noise levels ranging from 10 to 50 ppm. Our results indicate that anomaly detection is consistently more effective when performed within the latent space across all noise levels. Specifically, K-means clustering in the latent space emerged as a stable and high-performing method. We demonstrate that this anomaly detection approach is robust to noise levels up to 30 ppm (consistent with realistic space-based observations) and remains viable even at 50 ppm when leveraging latent space representations. On the other hand, the performance of the anomaly detection methods applied directly in the raw spectral space degrades significantly with increasing the level of noise. This suggests that autoencoder-driven dimensionality reduction offers a robust methodology for flagging chemically anomalous targets in large-scale surveys where exhaustive retrievals are computationally prohibitive.","authors":["Alexander Roman","Emilie Panek","Roy T. Forestano","Eyup B. Unlu","Katia Matcheva","Konstantin T. Matchev"],"pdf_url":"","comment":"14 pages, 12 figures"},{"id":"http://arxiv.org/abs/2601.02322v1","updated":"2026-01-05T18:13:02Z","published":"2026-01-05T18:13:02Z","title":"Environment-Adaptive Covariate Selection: Learning When to Use Spurious Correlations for Out-of-Distribution Prediction","summary":"Out-of-distribution (OOD) prediction is often approached by restricting models to causal or invariant covariates, avoiding non-causal spurious associations that may be unstable across environments. Despite its theoretical appeal, this strategy frequently underperforms empirical risk minimization (ERM) in practice. We investigate the source of this gap and show that such failures naturally arise when only a subset of the true causes of the outcome is observed. In these settings, non-causal spurious covariates can serve as informative proxies for unobserved causes and substantially improve prediction, except under distribution shifts that break these proxy relationships. Consequently, the optimal set of predictive covariates is neither universal nor necessarily exhibits invariant relationships with the outcome across all environments, but instead depends on the specific type of shift encountered. Crucially, we observe that different covariate shifts induce distinct, observable signatures in the covariate distribution itself. Moreover, these signatures can be extracted from unlabeled data in the target OOD environment and used to assess when proxy covariates remain reliable and when they fail. Building on this observation, we propose an environment-adaptive covariate selection (EACS) algorithm that maps environment-level covariate summaries to environment-specific covariate sets, while allowing the incorporation of prior causal knowledge as constraints. Across simulations and applied datasets, EACS consistently outperforms static causal, invariant, and ERM-based predictors under diverse distribution shifts.","authors":["Shuozhi Zuo","Yixin Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02316v1","updated":"2026-01-05T18:07:51Z","published":"2026-01-05T18:07:51Z","title":"DatBench: Discriminative, Faithful, and Efficient VLM Evaluations","summary":"Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.","authors":["Siddharth Joshi","Haoli Yin","Rishabh Adiga","Ricardo Monti","Aldo Carranza","Alex Fang","Alvin Deng","Amro Abbas","Brett Larsen","Cody Blakeney","Darren Teh","David Schwab","Fan Pan","Haakon Mongstad","Jack Urbanek","Jason Lee","Jason Telanoff","Josh Wills","Kaleigh Mentzer","Luke Merrick","Parth Doshi","Paul Burstein","Pratyush Maini","Scott Loftin","Spandan Das","Tony Jiang","Vineeth Dorna","Zhengping Wang","Bogdan Gaza","Ari Morcos","Matthew Leavitt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.05600v2","updated":"2026-01-05T18:07:06Z","published":"2025-08-07T17:41:33Z","title":"Non-omniscient backdoor injection with one poison sample: Proving the one-poison hypothesis for linear regression, linear classification, and 2-layer ReLU neural networks","summary":"Backdoor poisoning attacks are a threat to machine learning models trained on large data collected from untrusted sources; these attacks enable attackers to inject malicious behavior into the model that can be triggered by specially crafted inputs. Prior work has established bounds on the success of backdoor attacks and their impact on the benign learning task, however, an open question is what amount of poison data is needed for a successful backdoor attack. Typical attacks either use few samples but need much information about the data points, or need to poison many data points.\n  In this paper, we formulate the one-poison hypothesis: An adversary with one poison sample and limited background knowledge can inject a backdoor with zero backdooring-error and without significantly impacting the benign learning task performance. Moreover, we prove the one-poison hypothesis for linear regression, linear classification, and 2-layer ReLU neural networks. For adversaries that utilize a direction unused by the clean data distribution for the poison sample, we prove for linear classification and linear regression that the resulting model is functionally equivalent to a model where the poison was excluded from training. We build on prior work on statistical backdoor learning to show that in all other cases, the impact on the benign learning task is still limited. We validate our theoretical results experimentally with realistic benchmark data sets.","authors":["Thorsten Peinemann","Paula Arnold","Sebastian Berndt","Thomas Eisenbarth","Esfandiar Mohammadi"],"pdf_url":"","comment":"Added generalization to 2-layer ReLU neural networks"},{"id":"http://arxiv.org/abs/2601.02313v1","updated":"2026-01-05T18:04:32Z","published":"2026-01-05T18:04:32Z","title":"Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning","summary":"Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.\n  In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.","authors":["Hanzaleh Akbari Nodehi","Viveck R. Cadambe","Mohammad Ali Maddah-Ali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02310v1","updated":"2026-01-05T17:59:42Z","published":"2026-01-05T17:59:42Z","title":"Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay","summary":"High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.","authors":["Ahmad Makinde"],"pdf_url":"","comment":"8 pages, 5 figures, Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests.Proposes T-KAN architecture for HFT. Achieves 19.1% F1-score improvement on FI-2010 and 132.48% return in cost-adjusted backtests"},{"id":"http://arxiv.org/abs/2601.02307v1","updated":"2026-01-05T17:49:39Z","published":"2026-01-05T17:49:39Z","title":"Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck","summary":"We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.","authors":["Dina El Zein","James Henderson"],"pdf_url":"","comment":"11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2511.04847v3","updated":"2026-01-05T17:43:48Z","published":"2025-11-06T22:24:35Z","title":"Grounded Test-Time Adaptation for LLM Agents","summary":"Large language model (LLM)-based agents struggle to generalize to novel and complex environments, such as unseen websites or new sets of functions, due to a fundamental mismatch between their pre-training and test-time conditions. This challenge stems from two distinct failure modes: a syntactic misunderstanding of environment-specific components like observation formats, and a semantic misunderstanding of state-transition dynamics, which are only revealed at test time. To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment. First, an online distributional adaptation method parameterizes environmental nuances by learning a lightweight adaptation vector that biases the model's output distribution, enabling rapid alignment with an environment response format. Second, a deployment-time dynamics grounding method employs a persona-driven exploration phase to systematically probe and learn the environment's causal dynamics before task execution, equipping the agent with a nonparametric world model. We evaluate these strategies across diverse agentic benchmarks, including function calling and web navigation. Our empirical results show the effectiveness of both strategies across all benchmarks with minimal computational cost. We find that dynamics grounding is particularly effective in complex environments where unpredictable dynamics pose a major obstacle, demonstrating a robust path toward more generalizable and capable LLM-based agents. For example, on the WebArena multi-site split, this method increases the agent's success rate from 2% to 23%.","authors":["Arthur Chen","Zuxin Liu","Jianguo Zhang","Akshara Prabhakar","Zhiwei Liu","Shelby Heinecke","Silvio Savarese","Victor Zhong","Caiming Xiong"],"pdf_url":"","comment":"Our code is available here: https://github.com/r2llab/GTTA"},{"id":"http://arxiv.org/abs/2510.06478v2","updated":"2026-01-05T17:33:34Z","published":"2025-10-07T21:28:53Z","title":"Anytime-Valid Answer Sufficiency Certificates for LLM Generation via Sequential Information Lift","summary":"We introduce Sequential-EDFL (Empirical Dynamic Formal Lift), which applies anytime-valid sequential testing to language model generation stopping. Our approach tracks information lift, defined as the log-likelihood ratio between the full model and deliberately weakened \"skeleton\" baselines, using self-normalized empirical-Bernstein e-processes that provide formal delta-level error control regardless of stopping time. This delta guarantee controls premature stopping when information lift is insufficient relative to the skeleton, and it does not imply delta control of factual incorrectness or hallucinations. We handle unknown centering through online mean estimation, combine multiple parameters via mixture e-processes, and support adaptive resets under distributional drift. On six benchmarks, Sequential-EDFL reduces generation length by 22 to 28 percent relative to sequential baselines while maintaining delta-level control with 12 percent computational overhead. We introduce automated skeletons (distilled submodels and randomized logits) and show robustness across skeleton families. Composing EDFL with a lightweight correctness gate (sentence boundaries plus a verifier) improves end-task correctness while preserving anytime-valid guarantees by only delaying stopping. Our certificates control information sufficiency, not factual correctness. Specifically, 10.9 percent of stopped sequences remain incorrect even with the gate (13.2 to 22.7 percent without it). EDFL serves as a first-stage filter that can reduce verification burden: when applied to stopped sequences, the gate validates 83 percent of stops, requiring full verification only for the remaining 17 percent, plus all non-stopped sequences. EDFL is not a standalone solution for safety-critical domains.","authors":["Sanjeda Akter","Ibne Farabi Shihab","Anuj Sharma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01208v2","updated":"2026-01-05T17:26:51Z","published":"2025-12-01T02:46:15Z","title":"Language as a Wave Phenomenon: Iso-Energetic Phase-Locking and Semantic Interference in Neural Networks","summary":"Conventional deep learning paradigms rely on metabolically expensive magnitude-based representations, rendering them fundamentally incompatible with passive photonic hardware. We introduce PRISM, a sequence modeling architecture that bridges high-level reasoning and physical constraints by enforcing an Iso-Energetic (Unity Gain) principle, compelling the network to encode semantic information exclusively in the phase angle. Validated on the WMT14 translation benchmark, PRISM achieves a 0.799 COMET score, demonstrating that phase-based reasoning competes with standard Transformers (0.821) and functionally matches unconstrained spectral baselines like FNet (0.805), despite enforcing strict energy constraints and requiring 11.5% fewer parameters. Furthermore, to verify hardware feasibility, we simulate a Holographic Backpropagation mechanism on a noisy, 4-bit optical correlator. Ablation studies reveal a substantial performance gain (48.4% vs. 62.4%) over a frozen baseline, proving that the proposed phase-steering mechanism actively optimizes physical parameters under strict energy constraints. These results establish an existence proof that ultra-low-power, passive optical hardware can support high-level linguistic intelligence without sacrificing representational capacity.","authors":["Alper Yıldırım","İbrahim Yücedağ"],"pdf_url":"","comment":"Major Revision. Title changed to reflect the new theoretical framework. Complete narrative shift from \"Optimization Efficiency\" to \"Iso-Energetic Phase Coding\" and \"Optical Hardware Compatibility\". Replaced ISMR diagnostics with Holographic Optical Learning simulations and mechanistic \"Dual-Regime\" phase analysis. Comparison with spectral baselines (FNet) added"},{"id":"http://arxiv.org/abs/2601.02273v1","updated":"2026-01-05T17:03:45Z","published":"2026-01-05T17:03:45Z","title":"TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation","summary":"Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \\textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \\textbf{5.2\\%} of model parameters ($\\sim$4.9M). On the challenging CHASE\\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git","authors":["Salim Khazem"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.15991v2","updated":"2026-01-05T16:58:16Z","published":"2025-09-19T13:59:36Z","title":"Quantum Enhanced Anomaly Detection for ADS-B Data using Hybrid Deep Learning","summary":"The emerging field of Quantum Machine Learning (QML) has shown promising advantages in accelerating processing speed and effectively handling the high dimensionality associated with complex datasets. Quantum Computing (QC) enables more efficient data manipulation through the quantum properties of superposition and entanglement. In this paper, we present a novel approach combining quantum and classical machine learning techniques to explore the impact of quantum properties for anomaly detection in Automatic Dependent Surveillance-Broadcast (ADS-B) data. We compare the performance of a Hybrid-Fully Connected Quantum Neural Network (H-FQNN) with different loss functions and use a publicly available ADS-B dataset to evaluate the performance. The results demonstrate competitive performance in detecting anomalies, with accuracies ranging from 90.17% to 94.05%, comparable to the performance of a traditional Fully Connected Neural Network (FNN) model, which achieved accuracies between 91.50% and 93.37%.","authors":["Rani Naaman","Felipe Gohring de Magalhaes","Jean-Yves Ouattara","Gabriela Nicolescu"],"pdf_url":"","comment":"This is the author's version of the work accepted for publication in the IEEE-AIAA Digital Avionics Systems Conference (DASC) 2025. The final version version is available via IEEE Xplore"},{"id":"http://arxiv.org/abs/2512.24880v2","updated":"2026-01-05T16:51:18Z","published":"2025-12-31T14:16:26Z","title":"mHC: Manifold-Constrained Hyper-Connections","summary":"Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifying connectivity patterns. While yielding substantial performance gains, this diversification fundamentally compromises the identity mapping property intrinsic to the residual connection, which causes severe training instability and restricted scalability, and additionally incurs notable memory access overhead. To address these challenges, we propose Manifold-Constrained Hyper-Connections (mHC), a general framework that projects the residual connection space of HC onto a specific manifold to restore the identity mapping property, while incorporating rigorous infrastructure optimization to ensure efficiency. Empirical experiments demonstrate that mHC is effective for training at scale, offering tangible performance improvements and superior scalability. We anticipate that mHC, as a flexible and practical extension of HC, will contribute to a deeper understanding of topological architecture design and suggest promising directions for the evolution of foundational models.","authors":["Zhenda Xie","Yixuan Wei","Huanqi Cao","Chenggang Zhao","Chengqi Deng","Jiashi Li","Damai Dai","Huazuo Gao","Jiang Chang","Kuai Yu","Liang Zhao","Shangyan Zhou","Zhean Xu","Zhengyan Zhang","Wangding Zeng","Shengding Hu","Yuqing Wang","Jingyang Yuan","Lean Wang","Wenfeng Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02265v1","updated":"2026-01-05T16:49:17Z","published":"2026-01-05T16:49:17Z","title":"Predicting Early and Complete Drug Release from Long-Acting Injectables Using Explainable Machine Learning","summary":"Polymer-based long-acting injectables (LAIs) have transformed the treatment of chronic diseases by enabling controlled drug delivery, thus reducing dosing frequency and extending therapeutic duration. Achieving controlled drug release from LAIs requires extensive optimization of the complex underlying physicochemical properties. Machine learning (ML) can accelerate LAI development by modeling the complex relationships between LAI properties and drug release. However, recent ML studies have provided limited information on key properties that modulate drug release, due to the lack of custom modeling and analysis tailored to LAI data. This paper presents a novel data transformation and explainable ML approach to synthesize actionable information from 321 LAI formulations by predicting early drug release at 24, 48, and 72 hours, classification of release profile types, and prediction of complete release profiles. These three experiments investigate the contribution and control of LAI material characteristics in early and complete drug release profiles. A strong correlation (>0.65) is observed between the true and predicted drug release in 72 hours, while a 0.87 F1-score is obtained in classifying release profile types. A time-independent ML framework predicts delayed biphasic and triphasic curves with better performance than current time-dependent approaches. Shapley additive explanations reveal the relative influence of material characteristics during early and for complete release which fill several gaps in previous in-vitro and ML-based studies. The novel approach and findings can provide a quantitative strategy and recommendations for scientists to optimize the drug-release dynamics of LAI. The source code for the model implementation is publicly available.","authors":["Karla N. Robles","Manar D. Samad"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2310.11143v4","updated":"2026-01-05T16:47:03Z","published":"2023-10-17T10:51:05Z","title":"Development of a high-resolution indoor radon map using a new machine learning-based probabilistic model and German radon survey data","summary":"Accurate knowledge of indoor radon concentration is crucial for assessing radon-related health effects or identifying radon-prone areas. Indoor radon concentration at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sampled households often differ from the characteristics of the target population owing to the large number of relevant factors that control the indoor radon concentration, such as the availability of geogenic radon or floor level. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. A modeling approach was used by applying a quantile regression forest to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany. Based on the estimated probability distribution function,a probabilistic Monte Carlo sampling technique was applied, enabling the combination and population weighting of floor-level predictions. In this way,the uncertainty of the individual predictions is effectively propagated into the estimate of variability at the aggregated level. The results show an approximate lognormal distribution of indoor radon in dwellings in Germany with an arithmetic mean of 63 Bq/m3, a geometric mean of 41 Bq/m3, and a 95th percentile of 180 Bq/m3. The exceedance probabilities for 100 and 300 Bq/m3 are 12.5% (10.5 million people affected) and 2.2 % (1.9 million people affected), respectively. The advantages of our approach are that it yields a) an accurate estimation of indoor radon concentration even if the survey is not fully representative with respect to floor level and radon concentration in soil, and b) an estimate of the indoor radon distribution with a much higher spatial resolution than basic descriptive statistics.","authors":["Eric Petermann","Peter Bossew","Joachim Kemski","Valeria Gruber","Nils Suhr","Bernd Hoffmann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02264v1","updated":"2026-01-05T16:46:34Z","published":"2026-01-05T16:46:34Z","title":"POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network","summary":"Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.","authors":["Boris Kriuk","Fedor Kriuk"],"pdf_url":"","comment":"8 pages, 14 figures"},{"id":"http://arxiv.org/abs/2505.09503v4","updated":"2026-01-05T16:39:29Z","published":"2025-05-14T15:53:14Z","title":"Towards Fair In-Context Learning with Tabular Foundation Models","summary":"Transformer-based tabular foundation models have recently demonstrated promising in-context learning (ICL) performance on structured data, emerging as competitive alternatives to gradient-boosted trees. However, the fairness implications of this new paradigm remain largely unexplored. We present the first investigation of fairness in tabular ICL, evaluating three recently proposed foundation models--TabPFNv2, TabICL, and TabDPT--on multiple benchmark datasets. To mitigate biases, we explore three pre-processing fairness-enhancing methods: correlation removal (decorrelating input features from the sensitive attribute), group-balanced sample selection (ensuring equal representation of protected groups in context examples), and uncertainty-based sample selection (prioritizing context examples with high sensitive-attribute prediction uncertainty). Our experiments show that the uncertainty-based strategy consistently improves group fairness metrics (e.g., demographic parity, equalized odds, and equal opportunity) with minimal impact on predictive accuracy. We release our code to facilitate reproducibility https://github.com/patrikken/Fair-TabICL.","authors":["Patrik Kenfack","Samira Ebrahimi Kahou","Ulrich Aïvodji"],"pdf_url":"","comment":"Published in Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2405.18499v4","updated":"2026-01-05T16:38:03Z","published":"2024-05-28T18:10:45Z","title":"Training More Robust Classification Model via Discriminative Loss and Gaussian Noise Injection","summary":"Robustness of deep neural networks to input noise remains a critical challenge, as naive noise injection often degrades accuracy on clean (uncorrupted) data. We propose a novel training framework that addresses this trade-off through two complementary objectives. First, we introduce a loss function applied at the penultimate layer that explicitly enforces intra-class compactness and increases the margin to analytically defined decision boundaries. This enhances feature discriminativeness and class separability for clean data. Second, we propose a class-wise feature alignment mechanism that brings noisy data clusters closer to their clean counterparts. Furthermore, we provide a theoretical analysis demonstrating that improving feature stability under additive Gaussian noise implicitly reduces the curvature of the softmax loss landscape in input space, as measured by Hessian eigenvalues.This thus naturally enhances robustness without explicit curvature penalties. Conversely, we also theoretically show that lower curvatures lead to more robust models. We validate the effectiveness of our method on standard benchmarks and our custom dataset. Our approach significantly reinforces model robustness to various perturbations while maintaining high accuracy on clean data, advancing the understanding and practice of noise-robust deep learning.","authors":["Hai-Vy Nguyen","Fabrice Gamboa","Sixin Zhang","Reda Chhaibi","Serge Gratton","Thierry Giaccone"],"pdf_url":"","comment":"Published in Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2601.02257v1","updated":"2026-01-05T16:36:59Z","published":"2026-01-05T16:36:59Z","title":"Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization","summary":"We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.\n  We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.","authors":["Joel Daniel Andersson","Palak Jain","Satchit Sivakumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02256v1","updated":"2026-01-05T16:36:40Z","published":"2026-01-05T16:36:40Z","title":"VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation","summary":"Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.","authors":["Shikun Sun","Liao Qu","Huichao Zhang","Yiheng Liu","Yangyang Song","Xian Li","Xu Wang","Yi Jiang","Daniel K. Du","Xinglong Wu","Jia Jia"],"pdf_url":"","comment":"Project page: https://github.com/ByteVisionLab/NextFlow"},{"id":"http://arxiv.org/abs/2601.02253v1","updated":"2026-01-05T16:33:13Z","published":"2026-01-05T16:33:13Z","title":"Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission","summary":"The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.","authors":["Emrah Mete","Emin Erkan Korkmaz"],"pdf_url":"","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2512.20762v2","updated":"2026-01-05T16:29:26Z","published":"2025-12-23T20:49:05Z","title":"Subgroup Discovery with the Cox Model","summary":"We study the problem of subgroup discovery for survival analysis, where the goal is to find an interpretable subset of the data on which a Cox model is highly accurate. Our work is the first to study this particular subgroup problem, for which we make several contributions.\n  Subgroup discovery methods generally require a \"quality function\" in order to sift through and select the most advantageous subgroups. We first examine why existing natural choices for quality functions are insufficient to solve the subgroup discovery problem for the Cox model. To address the shortcomings of existing metrics, we introduce two technical innovations: the *expected prediction entropy (EPE)*, a novel metric for evaluating survival models which predict a hazard function; and the *conditional rank statistics (CRS)*, a statistical object which quantifies the deviation of an individual point to the distribution of survival times in an existing subgroup. We study the EPE and CRS theoretically and show that they can solve many of the problems with existing metrics.\n  We introduce a total of eight algorithms for the Cox subgroup discovery problem. The main algorithm is able to take advantage of both the EPE and the CRS, allowing us to give theoretical correctness results for this algorithm in a well-specified setting. We evaluate all of the proposed methods empirically on both synthetic and real data. The experiments confirm our theory, showing that our contributions allow for the recovery of a ground-truth subgroup in well-specified cases, as well as leading to better model fit compared to naively fitting the Cox model to the whole dataset in practical settings. Lastly, we conduct a case study on jet engine simulation data from NASA. The discovered subgroups uncover known nonlinearities/homogeneity in the data, and which suggest design choices which have been mirrored in practice.","authors":["Zachary Izzo","Iain Melvin"],"pdf_url":"","comment":"43 pages, 2 figures"},{"id":"http://arxiv.org/abs/2601.02246v1","updated":"2026-01-05T16:26:32Z","published":"2026-01-05T16:26:32Z","title":"A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets","summary":"Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.","authors":["Annoor Sharara Akhand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02242v1","updated":"2026-01-05T16:17:20Z","published":"2026-01-05T16:17:20Z","title":"VIBE: Visual Instruction Based Editor","summary":"Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.","authors":["Grigorii Alekseenko","Aleksandr Gordeev","Irina Tolstykh","Bulat Suleimanov","Vladimir Dokholyan","Georgii Fedorov","Sergey Yakubson","Aleksandra Tsybina","Mikhail Chernyshov","Maksim Kuprashevich"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02241v1","updated":"2026-01-05T16:16:28Z","published":"2026-01-05T16:16:28Z","title":"From Mice to Trains: Amortized Bayesian Inference on Graph Data","summary":"Graphs arise across diverse domains, from biology and chemistry to social and information networks, as well as in transportation and logistics. Inference on graph-structured data requires methods that are permutation-invariant, scalable across varying sizes and sparsities, and capable of capturing complex long-range dependencies, making posterior estimation on graph parameters particularly challenging. Amortized Bayesian Inference (ABI) is a simulation-based framework that employs generative neural networks to enable fast, likelihood-free posterior inference. We adapt ABI to graph data to address these challenges to perform inference on node-, edge-, and graph-level parameters. Our approach couples permutation-invariant graph encoders with flexible neural posterior estimators in a two-module pipeline: a summary network maps attributed graphs to fixed-length representations, and an inference network approximates the posterior over parameters. In this setting, several neural architectures can serve as the summary network. In this work we evaluate multiple architectures and assess their performance on controlled synthetic settings and two real-world domains - biology and logistics - in terms of recovery and calibration.","authors":["Svenja Jedhoff","Elizaveta Semenova","Aura Raulo","Anne Meyer","Paul-Christian Bürkner"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20629v3","updated":"2026-01-05T16:14:39Z","published":"2025-11-28T23:36:45Z","title":"Learning Evolving Latent Strategies for Multi-Agent Language Systems without Model Fine-Tuning","summary":"This study proposes a multi-agent language framework that enables continual strategy evolution without fine-tuning the language model's parameters. The core idea is to liberate the latent vectors of abstract concepts from traditional static semantic representations, allowing them to be continuously updated through environmental interaction and reinforcement feedback. We construct a dual-loop architecture: the behavior loop adjusts action preferences based on environmental rewards, while the language loop updates the external latent vectors by reflecting on the semantic embeddings of generated text.\n  Together, these mechanisms allow agents to develop stable and disentangled strategic styles over long-horizon multi-round interactions. Experiments show that agents' latent spaces exhibit clear convergence trajectories under reflection-driven updates, along with structured shifts at critical moments. Moreover, the system demonstrates an emergent ability to implicitly infer and continually adapt to emotional agents, even without shared rewards. These results indicate that, without modifying model parameters, an external latent space can provide language agents with a low-cost, scalable, and interpretable form of abstract strategic representation.","authors":["Wenlong Tang"],"pdf_url":"","comment":"17 pages, 5 figures. Code available at https://github.com/wltang-dev/Latent-Strategy-RL-Agent"},{"id":"http://arxiv.org/abs/2507.01752v3","updated":"2026-01-05T16:10:09Z","published":"2025-07-02T14:29:30Z","title":"Tuning without Peeking: Provable Generalization Bounds and Robust LLM Post-Training","summary":"Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, exposing gradients during training can leak sensitive information about the underlying data, raising privacy and security concerns such as susceptibility to data poisoning attacks. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide non-vacuous generalization bounds and strong theoretical guarantees for privacy, robustness to data poisoning attacks, and extraction attacks. In experiments with LLMs, we demonstrate empirically that black-box optimization methods, despite the scalability and computational challenges inherent to black-box approaches, are able to learn, showing how a few iterations of BBoxER improve performance, generalize well on a benchmark of reasoning datasets, and are robust to membership inference attacks. This positions BBoxER as an attractive add-on on top of gradient-based optimization, offering suitability for deployment in restricted or privacy-sensitive environments while also providing non-vacuous generalization guarantees.","authors":["Ismail Labiad","Mathurin Videau","Matthieu Kowalski","Marc Schoenauer","Alessandro Leite","Julia Kempe","Olivier Teytaud"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02232v1","updated":"2026-01-05T15:58:08Z","published":"2026-01-05T15:58:08Z","title":"ELLA: Efficient Lifelong Learning for Adapters in Large Language Models","summary":"Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\\%$ and a $35\\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.","authors":["Shristi Das Biswas","Yue Zhang","Anwesan Pal","Radhika Bhargava","Kaushik Roy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.04665v2","updated":"2026-01-05T15:38:05Z","published":"2025-08-06T17:34:43Z","title":"Perch 2.0: The Bittern Lesson for Bioacoustics","summary":"Perch is a performant pre-trained model for bioacoustics. It was trained in supervised fashion, providing both off-the-shelf classification scores for thousands of vocalizing species as well as strong embeddings for transfer learning. In this new release, Perch 2.0, we expand from training exclusively on avian species to a large multi-taxa dataset. The model is trained with self-distillation using a prototype-learning classifier as well as a new source-prediction training criterion. Perch 2.0 obtains state-of-the-art performance on the BirdSet and BEANS benchmarks. It also outperforms specialized marine models on marine transfer learning tasks, despite having almost no marine training data. We present hypotheses as to why fine-grained species classification is a particularly robust pre-training task for bioacoustics.","authors":["Bart van Merriënboer","Vincent Dumoulin","Jenny Hamer","Lauren Harrell","Andrea Burns","Tom Denton"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02213v1","updated":"2026-01-05T15:36:04Z","published":"2026-01-05T15:36:04Z","title":"Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction","summary":"Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Specifically, we introduce three innovations for quantized equivariant transformers: (1) a magnitude-direction decoupled quantization scheme that separately quantizes the norm and orientation of equivariant (vector) features, (2) a branch-separated quantization-aware training strategy that treats invariant and equivariant feature channels differently in an attention-based $SO(3)$-GNN, and (3) a robustness-enhancing attention normalization mechanism that stabilizes low-precision attention computations. Experiments on the QM9 and rMD17 molecular benchmarks demonstrate that our 8-bit models achieve accuracy on energy and force predictions comparable to full-precision baselines with markedly improved efficiency. We also conduct ablation studies to quantify the contribution of each component to maintain accuracy and equivariance under quantization, using the Local error of equivariance (LEE) metric. The proposed techniques enable the deployment of symmetry-aware GNNs in practical chemistry applications with 2.37--2.73x faster inference and 4x smaller model size, without sacrificing accuracy or physical symmetry.","authors":["Haoyu Zhou","Ping Xue","Tianfan Fu","Hao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.19815v2","updated":"2026-01-05T15:34:26Z","published":"2024-10-17T21:19:39Z","title":"Bayesian uncertainty-aware deep learning with noisy labels: Tackling annotation ambiguity in EEG seizure detection","summary":"Deep learning is advancing EEG processing for automated epileptic seizure detection and onset zone localization, yet its performance relies heavily on high-quality annotated training data. However, scalp EEG is susceptible to high noise levels, which in turn leads to imprecise annotations of the seizure timing and characteristics. This \"label noise\" presents a significant challenge in model training and generalization. In this paper, we introduce Bayesian UncertaiNty-aware Deep Learning (BUNDL), a novel algorithm that informs a deep learning model of label ambiguities, thereby enhancing the robustness of seizure detection systems. By integrating domain knowledge into an underlying Bayesian framework, we derive a novel KL-divergence-based loss function that capitalizes on uncertainty to better learn seizure characteristics from scalp EEG. Thus, BUNDL offers a straightforward and model-agnostic method for training deep neural networks with noisy training labels that does not add any parameters to existing architectures. Additionally, we explore the impact of improved detection system on the task of automated onset zone localization. We validate BUNDL using a comprehensive simulated EEG dataset and two publicly available datasets collected by Temple University Hospital (TUH) and Boston Children's Hospital (CHB-MIT). Results show that BUNDL consistently identifies noisy labels and improves the robustness of three base models under various label noise conditions. We also evaluate cross-site generalizability and quantify computational cost of all methods. Ultimately, BUNDL presents as a reliable method that can be seamlessly integrated with existing deep models used in clinical practice, enabling the training of trustworthy models for epilepsy evaluation.","authors":["Deeksha M. Shama","Archana Venkataraman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.19206v2","updated":"2026-01-05T15:31:00Z","published":"2024-05-29T15:47:35Z","title":"Matrix Manifold Neural Networks++","summary":"Deep neural networks (DNNs) on Riemannian manifolds have garnered increasing interest in various applied areas. For instance, DNNs on spherical and hyperbolic manifolds have been designed to solve a wide range of computer vision and nature language processing tasks. One of the key factors that contribute to the success of these networks is that spherical and hyperbolic manifolds have the rich algebraic structures of gyrogroups and gyrovector spaces. This enables principled and effective generalizations of the most successful DNNs to these manifolds. Recently, some works have shown that many concepts in the theory of gyrogroups and gyrovector spaces can also be generalized to matrix manifolds such as Symmetric Positive Definite (SPD) and Grassmann manifolds. As a result, some building blocks for SPD and Grassmann neural networks, e.g., isometric models and multinomial logistic regression (MLR) can be derived in a way that is fully analogous to their spherical and hyperbolic counterparts. Building upon these works, we design fully-connected (FC) and convolutional layers for SPD neural networks. We also develop MLR on Symmetric Positive Semi-definite (SPSD) manifolds, and propose a method for performing backpropagation with the Grassmann logarithmic map in the projector perspective. We demonstrate the effectiveness of the proposed approach in the human action recognition and node classification tasks.","authors":["Xuan Son Nguyen","Shuo Yang","Aymeric Histace"],"pdf_url":"","comment":"added references"},{"id":"http://arxiv.org/abs/2601.02201v1","updated":"2026-01-05T15:24:05Z","published":"2026-01-05T15:24:05Z","title":"CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents","summary":"The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.","authors":["Keyu Wang","Bingchen Miao","Wendong Bu","Yu Wu","Juncheng Li","Shengyu Zhang","Wenqiao Zhang","Siliang Tang","Jun Xiao","Yueting Zhuang"],"pdf_url":"","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2510.24601v2","updated":"2026-01-05T15:20:15Z","published":"2025-10-28T16:28:42Z","title":"Comparison of generalised additive models and neural networks in applications: A systematic review","summary":"Neural networks have become a popular tool in predictive modelling, more commonly associated with machine learning and artificial intelligence than with statistics. Generalised Additive Models (GAMs) are flexible non-linear statistical models that retain interpretability. Both are state-of-the-art in their own right, with their respective advantages and disadvantages. This paper analyses how these two model classes have performed on real-world tabular data. Following PRISMA guidelines, we conducted a systematic review of papers that performed empirical comparisons of GAMs and neural networks. Eligible papers were identified, yielding 143 papers, with 430 datasets. Key attributes at both paper and dataset levels were extracted and reported. Beyond summarising comparisons, we analyse reported performance metrics using mixed-effects modelling to investigate potential characteristics that can explain and quantify observed differences, including application area, study year, sample size, number of predictors, and neural network complexity. Across datasets, no consistent evidence of superiority was found for either GAMs or neural networks when considering the most frequently reported metrics (RMSE, $R^2$, and AUC). Neural networks tended to outperform in larger datasets and in those with more predictors, but this advantage narrowed over time. Conversely, GAMs remained competitive, particularly in smaller data settings, while retaining interpretability. Reporting of dataset characteristics and neural network complexity was incomplete in much of the literature, limiting transparency and reproducibility. This review highlights that GAMs and neural networks should be viewed as complementary approaches rather than competitors. For many tabular applications, the performance trade-off is modest, and interpretability may favour GAMs.","authors":["Jessica Doohan","Lucas Kook","Kevin Burke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02198v1","updated":"2026-01-05T15:19:59Z","published":"2026-01-05T15:19:59Z","title":"Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models","summary":"In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.","authors":["Alexander Möllers","Julius Hense","Florian Schulz","Timo Milbich","Maximilian Alber","Lukas Ruff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02196v1","updated":"2026-01-05T15:18:54Z","published":"2026-01-05T15:18:54Z","title":"ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense","summary":"Automated cyber defense (ACD) seeks to protect computer networks with minimal or no human intervention, reacting to intrusions by taking corrective actions such as isolating hosts, resetting services, deploying decoys, or updating access controls. However, existing approaches for ACD, such as deep reinforcement learning (RL), often face difficult exploration in complex networks with large decision/state spaces and thus require an expensive amount of samples. Inspired by the need to learn sample-efficient defense policies, we frame ACD in CAGE Challenge 4 (CAGE-4 / CC4) as a context-based partially observable Markov decision problem and propose a planning-centric defense policy based on Monte Carlo Tree Search (MCTS). It explicitly models the exploration-exploitation tradeoff in ACD and uses statistical sampling to guide exploration and decision making. We make novel use of graph neural networks (GNNs) to embed observations from the network as attributed graphs, to enable permutation-invariant reasoning over hosts and their relationships. To make our solution practical in complex search spaces, we guide MCTS with learned graph embeddings and priors over graph-edit actions, combining model-free generalization and policy distillation with look-ahead planning. We evaluate the resulting agent on CC4 scenarios involving diverse network structures and adversary behaviors, and show that our search-guided, graph-embedding-based planning improves defense reward and robustness relative to state-of-the-art RL baselines.","authors":["Yu Li","Sizhe Tang","Rongqian Chen","Fei Xu Yu","Guangyu Jiang","Mahdi Imani","Nathaniel D. Bastian","Tian Lan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02193v1","updated":"2026-01-05T15:16:26Z","published":"2026-01-05T15:16:26Z","title":"Learning with Monotone Adversarial Corruptions","summary":"We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a \"clean\" i.i.d. dataset, inserts additional \"corrupted\" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.","authors":["Kasper Green Larsen","Chirag Pabbaraju","Abhishek Shetty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02189v1","updated":"2026-01-05T15:09:18Z","published":"2026-01-05T15:09:18Z","title":"QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition","summary":"Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.","authors":["Cheng Ying Wu","Yen Jui Chang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.09166v3","updated":"2026-01-05T14:58:49Z","published":"2025-07-12T07:04:07Z","title":"Investigating the Robustness of Extreme Precipitation Super-Resolution Across Climates","summary":"The coarse spatial resolution of gridded climate models, such as general circulation models, limits their direct use in projecting socially relevant variables like extreme precipitation. Most downscaling methods estimate the conditional distributions of extremes by generating large ensembles, complicating the assessment of robustness under distributional transformations, such as those induced by climate change. To better understand and potentially improve robustness, we propose super-resolving the parameters of the target variable's probability distribution directly using analytically tractable mappings. Within a perfect-model framework over Switzerland, we demonstrate that vector generalized linear and additive models can super-resolve the generalized extreme value distribution of summer hourly precipitation extremes from coarse precipitation fields and topography. We introduce the notion of a \"robustness gap\", defined as the difference in predictive error between present-trained and future-trained models, and use it to diagnose how model structure affects the generalization of each quantile to a pseudo-global warming scenario. By evaluating multiple model configurations, we also identify an upper limit on the super-resolution factor based on the spatial auto- and cross-correlation of precipitation and elevation, beyond which coarse precipitation loses predictive value. Our framework is broadly applicable to variables governed by parametric distributions and offers a model-agnostic diagnostic for understanding when and why empirical downscaling generalizes to climate change and extremes.","authors":["Louise Largeau","Tom Beucler","David Leutwyler","Gregoire Mariethoz","Valerie Chavez-Demoulin","Erwan Koch"],"pdf_url":"","comment":"47+7 pages, 10+4 figures, 1 table, submitted to WCE"},{"id":"http://arxiv.org/abs/2511.20692v2","updated":"2026-01-05T14:58:49Z","published":"2025-11-22T19:04:13Z","title":"The Human Brain as a Combinatorial Complex","summary":"We propose a framework for constructing combinatorial complexes (CCs) from fMRI time series data that captures both pairwise and higher-order neural interactions through information-theoretic measures, bridging topological deep learning and network neuroscience. Current graph-based representations of brain networks systematically miss the higher-order dependencies that characterize neural complexity, where information processing often involves synergistic interactions that cannot be decomposed into pairwise relationships. Unlike topological lifting approaches that map relational structures into higher-order domains, our method directly constructs CCs from statistical dependencies in the data. Our CCs generalize graphs by incorporating higher-order cells that represent collective dependencies among brain regions, naturally accommodating the multi-scale, hierarchical nature of neural processing. The framework constructs data-driven combinatorial complexes using O-information and S-information measures computed from fMRI signals, preserving both pairwise connections and higher-order cells (e.g., triplets, quadruplets) based on synergistic dependencies. Using NetSim simulations as a controlled proof-of-concept dataset, we demonstrate our CC construction pipeline and show how both pairwise and higher-order dependencies in neural time series can be quantified and represented within a unified structure. This work provides a framework for brain network representation that preserves fundamental higher-order structure invisible to traditional graph methods, and enables the application of topological deep learning (TDL) architectures to neural data.","authors":["Valentina Sánchez","Çiçek Güven","Koen Haak","Theodore Papamarkou","Gonzalo Nápoles","Marie Šafář Postma"],"pdf_url":"","comment":"Accepted as an Extended Abstract at the NeurReps Workshop, NeurIPS 2025"},{"id":"http://arxiv.org/abs/2509.20113v3","updated":"2026-01-05T14:53:38Z","published":"2025-09-24T13:37:53Z","title":"Discovering Association Rules in High-Dimensional Small Tabular Data","summary":"Association Rule Mining (ARM) aims to discover patterns between features in datasets in the form of propositional rules, supporting both knowledge discovery and interpretable machine learning in high-stakes decision-making. However, in high-dimensional settings, rule explosion and computational overhead render popular algorithmic approaches impractical without effective search space reduction, challenges that propagate to downstream tasks. Neurosymbolic methods, such as Aerial+, have recently been proposed to address the rule explosion in ARM. While they tackle the high dimensionality of the data, they also inherit limitations of neural networks, particularly reduced performance in low-data regimes.\n  This paper makes three key contributions to association rule discovery in high-dimensional tabular data. First, we empirically show that Aerial+ scales one to two orders of magnitude better than state-of-the-art algorithmic and neurosymbolic baselines across five real-world datasets. Second, we introduce the novel problem of ARM in high-dimensional, low-data settings, such as gene expression data from the biomedicine domain with around 18k features and 50 samples. Third, we propose two fine-tuning approaches to Aerial+ using tabular foundation models. Our proposed approaches are shown to significantly improve rule quality on five real-world datasets, demonstrating their effectiveness in low-data, high-dimensional scenarios.","authors":["Erkan Karabulut","Daniel Daza","Paul Groth","Victoria Degeler"],"pdf_url":"","comment":"Published version is available at https://ceur-ws.org/Vol-4125/paper_26.pdf"},{"id":"http://arxiv.org/abs/2509.19406v5","updated":"2026-01-05T14:53:28Z","published":"2025-09-23T09:20:00Z","title":"TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding","summary":"Multivariate time series forecasting is essential in domains such as finance, transportation, climate, and energy. However, existing patch-based methods typically adopt fixed-length segmentation, overlooking the heterogeneity of local temporal dynamics and the decoding heterogeneity of forecasting. Such designs lose details in information-dense regions, introduce redundancy in stable segments, and fail to capture the distinct complexities of short-term and long-term horizons. We propose TimeMosaic, a forecasting framework that aims to address temporal heterogeneity. TimeMosaic employs adaptive patch embedding to dynamically adjust granularity according to local information density, balancing motif reuse with structural clarity while preserving temporal continuity. In addition, it introduces segment-wise decoding that treats each prediction horizon as a related subtask and adapts to horizon-specific difficulty and information requirements, rather than applying a single uniform decoder. Extensive evaluations on benchmark datasets demonstrate that TimeMosaic delivers consistent improvements over existing methods, and our model trained on the large-scale corpus with 321 billion observations achieves performance competitive with state-of-the-art TSFMs.","authors":["Kuiye Ding","Fanda Fan","Chunyi Hou","Zheya Wang","Lei Wang","Zhengxin Yang","Jianfeng Zhan"],"pdf_url":"","comment":"This paper has been accepted by AAAI"},{"id":"http://arxiv.org/abs/2601.02158v1","updated":"2026-01-05T14:36:02Z","published":"2026-01-05T14:36:02Z","title":"FormationEval, an open multiple-choice benchmark for petroleum geoscience","summary":"This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\\% accuracy, with Gemini 3 Pro Preview reaching 99.8\\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.","authors":["Almaz Ermilov"],"pdf_url":"","comment":"24 pages, 8 figures, 10 tables; benchmark and code at https://github.com/AlmazErmilov/FormationEval-an-Open-Benchmark-for-Oil-Gas-Geoscience-MCQ-Evaluation"},{"id":"http://arxiv.org/abs/2601.02151v1","updated":"2026-01-05T14:28:17Z","published":"2026-01-05T14:28:17Z","title":"Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting","summary":"Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as \"Confident Conflicts\" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.","authors":["Muxi Diao","Lele Yang","Wuxuan Gong","Yutong Zhang","Zhonghao Yan","Yufei Han","Kongming Liang","Weiran Xu","Zhanyu Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02147v1","updated":"2026-01-05T14:22:20Z","published":"2026-01-05T14:22:20Z","title":"BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models","summary":"Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.","authors":["Sunny Gupta","Shounak Das","Amit Sethi"],"pdf_url":"","comment":"Accepted at the AAAI 2026 Workshop AIR-FM, Assessing and Improving Reliability of Foundation Models in the Real World"},{"id":"http://arxiv.org/abs/2601.02145v1","updated":"2026-01-05T14:18:14Z","published":"2026-01-05T14:18:14Z","title":"Feature-based Inversion of 2.5D Controlled Source Electromagnetic Data using Generative Priors","summary":"In this study, we investigate feature-based 2.5D controlled source marine electromagnetic (mCSEM) data inversion using generative priors. Two-and-half dimensional modeling using finite difference method (FDM) is adopted to compute the response of horizontal electric dipole (HED) excitation. Rather than using a neural network to approximate the entire inverse mapping in a black-box manner, we adopt a plug-andplay strategy in which a variational autoencoder (VAE) is used solely to learn prior information on conductivity distributions. During the inversion process, the conductivity model is iteratively updated using the Gauss Newton method, while the model space is constrained by projections onto the learned VAE decoder. This framework preserves explicit control over data misfit and enables flexible adaptation to different survey configurations. Numerical and field experiments demonstrate that the proposed approach effectively incorporates prior information, improves reconstruction accuracy, and exhibits good generalization performance.","authors":["Hongyu Zhou","Haoran Sun","Rui Guo","Maokun Li","Fan Yang","Shenheng Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.11320v2","updated":"2026-01-05T14:10:45Z","published":"2025-04-15T16:00:21Z","title":"Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints","summary":"Large Language Models (LLMs) power many modern applications, but their inference procedure poses unique scheduling challenges: the Key-Value (KV) cache grows dynamically during response generation, and memory overflow triggers eviction that can cascade into system-wide failures. Even when memory capacity exceeds the theoretical requirement, conventional scheduling algorithms fail because they do not account for this dynamic memory growth -- a system that should be stable can become unstable under poor scheduling.\n  This paper formulates LLM inference optimization as a multi-stage online scheduling problem. We develop a fluid dynamics approximation to establish a tractable benchmark and derive the Waiting for Accumulated Inference Threshold (WAIT) algorithm. WAIT uses threshold-based batching to prevent eviction by keeping the system near load balance, achieving near-optimal throughput when output lengths are known.\n  For practical settings where output lengths are unknown at arrival, we introduce Nested WAIT. Rather than predicting output lengths, Nested WAIT classifies prompts on-the-fly: short prompts complete early and exit, while longer prompts naturally advance to later segments. A safety buffer provides high-probability protection against memory overflow with only logarithmic overhead.\n  Theoretical analysis establishes near-optimal performance in the asymptotic regime. Experiments on Llama-7B with an A100 GPU demonstrate that our approach achieves superior throughput and reduced latency compared to vLLM and Sarathi. This work applies operations research principles to establish a theoretical framework for LLM deployment under memory constraints.","authors":["Ruicheng Ao","Gan Luo","David Simchi-Levi","Xinshang Wang"],"pdf_url":"","comment":"49 pages, 18 figures"},{"id":"http://arxiv.org/abs/2601.02138v1","updated":"2026-01-05T14:09:57Z","published":"2026-01-05T14:09:57Z","title":"Edge-aware GAT-based protein binding site prediction","summary":"Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins.","authors":["Weisen Yang","Hanqing Zhang","Wangren Qiu","Xuan Xiao","Weizhong Lin"],"pdf_url":"","comment":"24 pages, 10 figures, 6 tables"},{"id":"http://arxiv.org/abs/2509.09408v3","updated":"2026-01-05T14:07:44Z","published":"2025-09-11T12:43:07Z","title":"Kriging prior Regression: A Case for Kriging-Based Spatial Features with TabPFN in Soil Mapping","summary":"Machine learning and geostatistics are two fundamentally different frameworks for predicting and spatially mapping soil properties. Geostatistics leverages the spatial structure of soil properties, while machine learning captures the relationship between available environmental features and soil properties. We propose a hybrid framework that enriches ML with spatial context through engineering of 'spatial lag' features from ordinary kriging. We call this approach 'kriging prior regression' (KpR), as it follows the inverse logic of regression kriging. To evaluate this approach, we assessed both the point and probabilistic prediction performance of KpR, using the TabPFN model across six fieldscale datasets from LimeSoDa. These datasets included soil organic carbon, clay content, and pH, along with features derived from remote sensing and in-situ proximal soil sensing. KpR with TabPFN demonstrated reliable uncertainty estimates and more accurate predictions in comparison to several other spatial techniques (e.g., regression/residual kriging with TabPFN), as well as to established non-spatial machine learning algorithms (e.g., random forest). Most notably, it significantly improved the average R2 by around 30% compared to machine learning algorithms without spatial context. This improvement was due to the strong prediction performance of the TabPFN algorithm itself and the complementary spatial information provided by KpR features. TabPFN is particularly effective for prediction tasks with small sample sizes, common in precision agriculture, whereas KpR can compensate for weak relationships between sensing features and soil properties when proximal soil sensing data are limited. Hence, we conclude that KpR with TabPFN is a very robust and versatile modelling framework for digital soil mapping in precision agriculture.","authors":["Jonas Schmidinger","Viacheslav Barkov","Sebastian Vogel","Martin Atzmueller","Gerard B M Heuvelink"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.23869v3","updated":"2026-01-05T14:07:39Z","published":"2025-05-29T10:48:35Z","title":"Gibbs randomness-compression proposition: An efficient deep learning","summary":"A proposition that connects randomness and compression is put forward via Gibbs entropy over set of measurement vectors associated with a compression process. The proposition states that a lossy compression process is equivalent to {\\it directed randomness} that preserves information content. The proposition originated from the observed behavior in newly proposed {\\it Dual Tomographic Compression} (DTC) compress-train framework. This is akin to tomographic reconstruction of layer weight matrices via building compressed sensed projections, via so-called {\\it weight rays}. This tomographic approach is applied to previous and next layers in a dual fashion, that triggers neuronal-level pruning. This novel model compress-train scheme appears in iterative fashion and acts as a smart neural architecture search: also called {\\it compression aware training}. The experiments demonstrated the utility of this dual-tomography during training: method accelerates and supports lottery ticket hypothesis. However, random compress-train iterations having similar performance demonstrated the connection between randomness and compression from statistical physics perspective, we formulated the so-called {\\it Gibbs randomness-compression proposition}, signifying randomness-compression relationship via Gibbs entropy. The proposition is supported with the experimental evidence, resulting in very high correlation between learning performance vs. Gibbs entropy over compression ratios. Practically, the DTC framework provides a promising approach for massively energy- and resource-efficient deep learning training.","authors":["M. Süzen"],"pdf_url":"","comment":"11 pages, 5 figures, 1 table, 1 algorithm, 1 theorem"},{"id":"http://arxiv.org/abs/2506.19810v3","updated":"2026-01-05T14:04:20Z","published":"2025-06-24T17:22:45Z","title":"Ambiguous Online Learning","summary":"We propose a new variant of online learning that we call \"ambiguous online learning\". In this setting, the learner is allowed to produce multiple predicted labels. Such an \"ambiguous prediction\" is considered correct when at least one of the labels is correct, and none of the labels are \"predictably wrong\". The definition of \"predictably wrong\" comes from a hypothesis class in which hypotheses are also multi-valued. Thus, a prediction is \"predictably wrong\" if it's not allowed by the (unknown) true hypothesis. In particular, this setting is natural in the context of multivalued dynamical systems, recommendation algorithms and lossless compression. It is also strongly related to so-called \"apple tasting\". We show that in this setting, there is a trichotomy of mistake bounds: up to logarithmic factors, any hypothesis class has an optimal mistake bound of either Theta(1), Theta(sqrt(N)) or N.","authors":["Vanessa Kosoy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22792v2","updated":"2026-01-05T13:46:47Z","published":"2025-12-28T05:33:05Z","title":"A Universal and Robust Framework for Multiple Gas Recognition Based-on Spherical Normalization-Coupled Mahalanobis Algorithm","summary":"Electronic nose (E-nose) systems face two interconnected challenges in open-set gas recognition: feature distribution shift caused by signal drift and decision boundary failure induced by unknown gas interference. Existing methods predominantly rely on Euclidean distance or conventional classifiers, failing to account for anisotropic feature distributions and dynamic signal intensity variations. To address these issues, this study proposes the Spherical Normalization coupled Mahalanobis (SNM) module, a universal post-processing module for open-set gas recognition. First, it achieves geometric decoupling through cascaded batch and L2 normalization, projecting features onto a unit hypersphere to eliminate signal intensity fluctuations. Second, it utilizes Mahalanobis distance to construct adaptive ellipsoidal decision boundaries that conform to the anisotropic feature geometry. The architecture-agnostic SNM-Module seamlessly integrates with mainstream backbones including Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Transformer. Experiments on the public Vergara dataset demonstrate that the Transformer+SNM configuration achieves near-theoretical-limit performance in discriminating among multiple target gases, with an AUROC of 0.9977 and an unknown gas detection rate of 99.57% at 5% false positive rate, significantly outperforming state-of-the-art methods with a 3.0% AUROC improvement and 91.0% standard deviation reduction compared to Class Anchor Clustering (CAC). The module maintains exceptional robustness across five sensor positions, with standard deviations below 0.0028. This work effectively addresses the critical challenge of simultaneously achieving high accuracy and high stability in open-set gas recognition, providing solid support for industrial E-nose deployment.","authors":["Shuai Chen","Yang Song","Chen Wang","Ziran Wang"],"pdf_url":"","comment":"27 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2601.02112v1","updated":"2026-01-05T13:41:20Z","published":"2026-01-05T13:41:20Z","title":"Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model","summary":"The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.","authors":["Utkarsh Singh","Absaar Ali","Adarsh Roy"],"pdf_url":"","comment":"14 pages, 5 figures. Published in: Bramer M., Stahl F. (eds) Artificial Intelligence XLII. SGAI 2025. Lecture Notes in Computer Science, vol 16302. Springer, Cham"},{"id":"http://arxiv.org/abs/2512.23260v2","updated":"2026-01-05T13:39:39Z","published":"2025-12-29T07:39:49Z","title":"Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation","summary":"Safety alignment -- training large language models (LLMs) to refuse harmful requests while remaining helpful -- is critical for responsible deployment. Prior work established that safety behaviors are governed by low-rank structures, suggesting parameter-efficient fine-tuning (PEFT) should be well-suited for alignment. However, Low-Rank Adaptation (LoRA) consistently underperforms full fine-tuning and reinforcement learning on safety benchmarks. We attribute this gap to semantic entanglement: safety-relevant directions are intertwined with unrelated concepts due to polysemanticity, impeding implicit subspace identification. To address this, we propose SAILS (Safety Alignment via Interpretable Low-rank Subspace), which leverages Sparse Autoencoders (SAEs) to disentangle representations into monosemantic features, constructs an interpretable safety subspace from SAE decoder directions, and uses it to initialize LoRA adapters. Theoretically, we prove that SAE-based identification achieves arbitrarily small recovery error under monosemanticity assumptions, while direct identification suffers an irreducible error floor. Empirically, SAILS achieves up to 99.6% safety rate on Gemma-2-9B -- exceeding full fine-tuning by 7.4 points and matching RLHF-based models -- while updating only 0.19% of parameters and providing interpretability.","authors":["Dianyun Wang","Qingsen Ma","Yuhu Shang","Zhifeng Lu","Zhenbo Xu","Lechen Ning","Huijia Wu","Zhaofeng He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02106v1","updated":"2026-01-05T13:34:01Z","published":"2026-01-05T13:34:01Z","title":"Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI","summary":"Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.","authors":["Ashish Rana","Ammar Shaker","Sascha Saralajew","Takashi Suzuki","Kosuke Yasuda","Shintaro Kato","Toshikazu Wada","Toshiyuki Fujikawa","Toru Kikutsuji"],"pdf_url":"","comment":"Accepted to the Demo Track at the IEEE International Conference on Data Mining (ICDM) 2025, where it received the Best Demo Award"},{"id":"http://arxiv.org/abs/2601.02105v1","updated":"2026-01-05T13:33:09Z","published":"2026-01-05T13:33:09Z","title":"LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training","summary":"Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.\n  We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.\n  Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.\n  We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.","authors":["Hyunjun Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02094v1","updated":"2026-01-05T13:21:30Z","published":"2026-01-05T13:21:30Z","title":"Horizon Activation Mapping for Neural Networks in Time Series Forecasting","summary":"Neural networks for time series forecasting have relied on error metrics and architecture-specific interpretability approaches for model selection that don't apply across models of different families. To interpret forecasting models agnostic to the types of layers across state-of-the-art model families, we introduce Horizon Activation Mapping (HAM), a visual interpretability technique inspired by grad-CAM that uses gradient norm averages to study the horizon's subseries where grad-CAM studies attention maps over image data. We introduce causal and anti-causal modes to calculate gradient update norm averages across subseries at every timestep and lines of proportionality signifying uniform distributions of the norm averages. Optimization landscape studies with respect to changes in batch sizes, early stopping, train-val-test splits, univariate forecasting and dropouts are studied with respect to performances and subseries in HAM. Interestingly, batch size based differences in activities seem to indicate potential for existence of an exponential approximation across them per epoch relative to each other. Multivariate forecasting models including MLP-based CycleNet, N-Linear, N-HITS, self attention-based FEDformer, Pyraformer, SSM-based SpaceTime and diffusion-based Multi-Resolution DDPM over different horizon sizes trained over the ETTm2 dataset are used for HAM plots in this study. NHITS' neural approximation theorem and SpaceTime's exponential autoregressive activities have been attributed to trends in HAM plots over their training, validation and test sets. In general, HAM can be used for granular model selection, validation set choices and comparisons across different neural network model families.","authors":["Hans Krupakar","V A Kandappan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02081v1","updated":"2026-01-05T13:10:09Z","published":"2026-01-05T13:10:09Z","title":"A Differentiable Adversarial Framework for Task-Aware Data Subsampling","summary":"The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces the antagonistic soft selection subsampling (ASSS) framework as is a novel paradigm that reconstructs data reduction into a differentiable end-to-end learning problem. ASSS uses the adversarial game between selector network and task network, and selector network learning assigns continuous importance weights to samples. This direct optimization implemented by Gumbel-Softmax relaxation allows the selector to identify and retain samples with the maximum amount of information for a specific task target under the guidance of the loss function that balances the fidelity and sparsity of the prediction. Theoretical analysis links this framework with the information bottleneck principle. Comprehensive experiments on four large-scale real world datasets show that ASSS has always been better than heuristic subsampling baselines such as clustering and nearest neighbor thinning in maintaining model performance. It is worth noting that ASSS can not only match, but also sometimes exceed the training performance of the entire dataset, showcasing the effect of intelligent denoising. This work establishes task aware data subsampling as a learnable component, providing a principled solution for effective large-scale data learning.","authors":["Jiacheng Lyu","Bihua Bao"],"pdf_url":"","comment":"14 pages"},{"id":"http://arxiv.org/abs/2601.02080v1","updated":"2026-01-05T13:09:42Z","published":"2026-01-05T13:09:42Z","title":"The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks","summary":"Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.","authors":["Yizhi Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.15175v3","updated":"2026-01-05T13:05:29Z","published":"2025-05-21T06:45:06Z","title":"A Linear Approach to Data Poisoning","summary":"Backdoor and data-poisoning attacks can flip predictions with tiny training corruptions, yet a sharp theory linking poisoning strength, overparameterization, and regularization is lacking. We analyze ridge least squares with an unpenalized intercept in the high-dimensional regime \\(p,n\\to\\infty\\), \\(p/n\\to c\\). Targeted poisoning is modelled by shifting a \\(θ\\)-fraction of one class by a direction \\(\\mathbf{v}\\) and relabelling. Using resolvent techniques and deterministic equivalents from random matrix theory, we derive closed-form limits for the poisoned score explicit in the model parameters. The formulas yield scaling laws, recover the interpolation threshold as \\(c\\to1\\) in the ridgeless limit, and show that the weights align with the poisoning direction. Synthetic experiments match theory across sweeps of the parameters and MNIST backdoor tests show qualitatively consistent trends. The results provide a tractable framework for quantifying poisoning in linear models.","authors":["Donald Flynn","Diego Granziol"],"pdf_url":"","comment":"9 pages, 9 Figures"},{"id":"http://arxiv.org/abs/2512.03851v2","updated":"2026-01-05T12:56:52Z","published":"2025-12-03T14:50:06Z","title":"Comparison of neural network training strategies for the simulation of dynamical systems","summary":"Neural networks have become a widely adopted tool for modeling nonlinear dynamical systems from data. However, the choice of training strategy remains a key design decision, particularly for simulation tasks. This paper compares two predominant strategies: parallel and series-parallel training. The conducted empirical analysis spans five neural network architectures and two examples: a pneumatic valve test bench and an industrial robot benchmark. The study reveals that, even though series-parallel training dominates current practice, parallel training consistently yields better long-term prediction accuracy. Additionally, this work clarifies the often inconsistent terminology in the literature and relate both strategies to concepts from system identification. The findings suggest that parallel training should be considered the default training strategy for neural network-based simulation of dynamical systems.","authors":["Paul Strasser","Andreas Pfeffer","Jakob Weber","Markus Gurtner","Andreas Körner"],"pdf_url":"","comment":"submitted to ECC 2026"},{"id":"http://arxiv.org/abs/2601.02075v1","updated":"2026-01-05T12:56:51Z","published":"2026-01-05T12:56:51Z","title":"MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics","summary":"Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials science, yet writing LAMMPS scripts remains highly specialized and time-consuming tasks. Although LLMs show promise in code generation and domain-specific question answering, their performance in MD scenarios is limited by scarce domain data, the high deployment cost of state-of-the-art LLMs, and low code executability. Building upon our prior MDAgent, we present MDAgent2, the first end-to-end framework capable of performing both knowledge Q&A and code generation within the MD domain. We construct a domain-specific data-construction pipeline that yields three high-quality datasets spanning MD knowledge, question answering, and code generation. Based on these datasets, we adopt a three stage post-training strategy--continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning (RL)--to train two domain-adapted models, MD-Instruct and MD-Code. Furthermore, we introduce MD-GRPO, a closed-loop RL method that leverages simulation outcomes as reward signals and recycles low-reward trajectories for continual refinement. We further build MDAgent2-RUNTIME, a deployable multi-agent system that integrates code generation, execution, evaluation, and self-correction. Together with MD-EvalBench proposed in this work, the first benchmark for LAMMPS code generation and question answering, our models and system achieve performance surpassing several strong baselines.This work systematically demonstrates the adaptability and generalization capability of large language models in industrial simulation tasks, laying a methodological foundation for automatic code generation in AI for Science and industrial-scale simulations. URL: https://github.com/FredericVAN/PKU_MDAgent2","authors":["Zhuofan Shi","Hubao A","Yufei Shao","Mengyan Dai","Yadong Yu","Pan Xiang","Dongliang Huang","Hongxu An","Chunxiao Xin","Haiyang Shen","Zhenyu Wang","Yunshan Na","Gang Huang","Xiang Jing"],"pdf_url":"","comment":"24 pages,4 figures"},{"id":"http://arxiv.org/abs/2505.09922v3","updated":"2026-01-05T12:56:49Z","published":"2025-05-15T03:12:27Z","title":"Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity","summary":"Euclidean diffusion models have achieved remarkable success in generative modeling across diverse domains, and they have been extended to manifold cases in recent advances. Instead of explicitly utilizing the structure of special manifolds as studied in previous works, in this paper we investigate direct sampling of the Euclidean diffusion models for general manifold-structured data. We reveal the multiscale singularity of the score function in the ambient space, which hinders the accuracy of diffusion-generated samples. We then present an elaborate theoretical analysis of the singularity structure of the score function by decomposing it along the tangential and normal directions of the manifold. To mitigate the singularity and improve the sampling accuracy, we propose two novel methods: (1) Niso-DM, which reduces the scale discrepancies in the score function by utilizing a non-isotropic noise, and (2) Tango-DM, which trains only the tangential component of the score function using a tangential-only loss function. Numerical experiments demonstrate that our methods achieve superior performance on distributions over various manifolds with complex geometries.","authors":["Zichen Liu","Wei Zhang","Tiejun Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.26109v2","updated":"2026-01-05T12:47:18Z","published":"2025-10-30T03:36:19Z","title":"Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error","summary":"Reinforcement learning with verifiable rewards (RLVR) has significantly boosted the reasoning capability of language models (LMs) recently. However, existing RLVR approaches merely train LMs based on their own generated on-policy responses and are constrained by the initial capability of LMs, thus prone to exploration stagnation, in which LMs fail to solve more training problems and cannot further learn from the training data. Some work tries to address this by leveraging off-policy solutions to training problems, but relies on external expert guidance that is limited in availability and scalability. In this work, we propose LTE (Learning to reason from Trial and Error), an approach that hints LMs with their previously self-made mistakes, not requiring any external expert guidance. Experiments validate the effectiveness of LTE, which outperforms the normal group relative policy optimization (GRPO) by 5.02 in Pass@1 and 9.96 in Pass@k on average across six mathematical reasoning benchmarks for Qwen3-8B-Base and even performs better than methods that require external gold solutions as guidance after aligning the experimental setup. Further analysis confirms that LTE successfully mitigates exploration stagnation and enhances both exploitation and exploration during training. Our code is available at https://anonymous.4open.science/r/Learning-from-Trial-and-Error.","authors":["Chenming Tang","Hsiu-Yuan Huang","Weijie Liu","Saiyong Yang","Yunfang Wu"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2512.18901v2","updated":"2026-01-05T12:45:28Z","published":"2025-12-21T22:12:54Z","title":"Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models","summary":"We present Gabliteration, a novel neural weight modification technique that advances beyond traditional abliteration methods by implementing adaptive multi-directional projections with regularized layer selection. Our approach addresses the fundamental limitation of existing methods that compromise model quality while attempting to modify specific behavioral patterns. Through dynamic layer optimization, regularized projection matrices, and adaptive scaling mechanisms, we achieve theoretically superior weight modification while minimizing quality degradation in unrelated domains. We validate our method through the gabliterated-v1 model series (0.6B to 4B parameters) available on Hugging Face, demonstrating practical applicability across multiple model scales.","authors":["Gökdeniz Gülmez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.09972v3","updated":"2026-01-05T12:45:09Z","published":"2025-12-10T15:32:56Z","title":"SIP-BMM: Constructing the Capability--Efficiency Pareto Set for LLMs via Structural Importance Prior Bayesian Model Merging","summary":"Constructing a Pareto set is pivotal for navigating the capability--efficiency trade-offs in Large Language Models (LLMs). However, existing merging techniques remain inadequate for this task. Coarse-grained, model-level methods yield only a sparse set of suboptimal solutions, while fine-grained, layer-wise approaches suffer from the curse of dimensionality, rendering the search space computationally intractable. To resolve this dichotomy, we propose Structural Importance Prior Bayesian Model Merging (SIP-BMM), a framework that automatically constructs the LLM Pareto set. SIP-BMM renders high-dimensional layer-wise search tractable by introducing an importance-aware Sparse Axis-Aligned Subspace Bayesian Optimization (SAASBO) strategy. By leveraging a structural importance prior derived from task-vector differences, our method guides SAASBO to automatically identify critical layers, thereby dramatically reducing the effective dimensionality without sacrificing the granularity of full-model control. The entire process is automated within an evolutionary loop driven by the Log-Noisy Expected Hypervolume Improvement ($q$NEHVI) acquisition function. Experiments demonstrate that SIP-BMM discovers a stronger and denser Pareto front than competitive baselines, enabling agile model selection tailored to diverse operational constraints. Code is available at: https://github.com/MiLab-HITSZ/2026-SIPBMM.","authors":["Kesheng Chen","Yamin Hu","Zhenqian Zhu","Wenjian Luo","Yiya Diao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02061v1","updated":"2026-01-05T12:35:33Z","published":"2026-01-05T12:35:33Z","title":"Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management","summary":"Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.","authors":["Faizan Ahmed","Aniket Dixit","James Brusey"],"pdf_url":"","comment":"6 pages, accepted at NeurIPS workshop 2025"},{"id":"http://arxiv.org/abs/2601.02050v1","updated":"2026-01-05T12:15:39Z","published":"2026-01-05T12:15:39Z","title":"Explore the Ideology of Deep Learning in ENSO Forecasts","summary":"The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the \"dead\" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.","authors":["Yanhai Gan","Yipeng Chen","Ning Li","Xingguo Liu","Junyu Dong","Xianyao Chen"],"pdf_url":"","comment":"5 figures. Code available at https://github.com/liuxingguo9349/pptv-enso-env"},{"id":"http://arxiv.org/abs/2508.01010v2","updated":"2026-01-05T12:06:41Z","published":"2025-08-01T18:23:38Z","title":"v-PuNNs: van der Put Neural Networks for Transparent Ultrametric Representation Learning","summary":"Conventional deep learning models embed data in Euclidean space $\\mathbb{R}^d$, a poor fit for strictly hierarchical objects such as taxa, word senses, or file systems. We introduce van der Put Neural Networks (v-PuNNs), the first architecture whose neurons are characteristic functions of p-adic balls in $\\mathbb{Z}_p$. Under our Transparent Ultrametric Representation Learning (TURL) principle every weight is itself a p-adic number, giving exact subtree semantics. A new Finite Hierarchical Approximation Theorem shows that a depth-K v-PuNN with $\\sum_{j=0}^{K-1}p^{\\,j}$ neurons universally represents any K-level tree. Because gradients vanish in this discrete space, we propose Valuation-Adaptive Perturbation Optimization (VAPO), with a fast deterministic variant (HiPaN-DS) and a moment-based one (HiPaN / Adam-VAPO). On three canonical benchmarks our CPU-only implementation sets new state-of-the-art: WordNet nouns (52,427 leaves) 99.96% leaf accuracy in 16 min; GO molecular-function 96.9% leaf / 100% root in 50 s; NCBI Mammalia Spearman $ρ= -0.96$ with true taxonomic distance. The learned metric is perfectly ultrametric (zero triangle violations), and its fractal and information-theoretic properties are analyzed. Beyond classification we derive structural invariants for quantum systems (HiPaQ) and controllable generative codes for tabular data (Tab-HiPaN). v-PuNNs therefore bridge number theory and deep learning, offering exact, interpretable, and efficient models for hierarchical data.","authors":["Gnankan Landry Regis N'guessan"],"pdf_url":"","comment":"v2: Corrected mathematical statements in Section 3.1.3 and Appendix A regarding the van der Put basis properties. Clarified distinction between hierarchical indicator family and classical Schauder basis"},{"id":"http://arxiv.org/abs/2510.24639v2","updated":"2026-01-05T12:02:02Z","published":"2025-10-28T17:06:15Z","title":"Causal Ordering for Structure Learning from Time Series","summary":"Predicting causal structure from time series data is crucial for understanding complex phenomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based methods. Traditional ordering methods inherently limit the representational capacity of the resulting model. In this work, we fix this issue by leveraging multiple valid causal orderings, instead of a single one as standard practice. We propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based causal discovery for temporal data. By integrating multiple orderings, DOTS effectively recovers the transitive closure of the underlying directed acyclic graph, mitigating spurious artifacts inherent in single-ordering approaches. We formalise the problem under standard assumptions such as stationarity and the additive noise model, and leverage score matching with diffusion processes to enable efficient Hessian estimation. Extensive experiments validate the approach. Empirical evaluations on synthetic and real-world datasets demonstrate that DOTS outperforms state-of-the-art baselines, offering a scalable and robust approach to temporal causal discovery. On synthetic benchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the CausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the best on individual datasets, DOTS attains the highest average summary-graph $F1$ while halving runtime relative to graph-optimisation methods. These results establish DOTS as a scalable and accurate solution for temporal causal discovery.","authors":["Pedro P. Sanchez","Damian Machlanski","Steven McDonagh","Sotirios A. Tsaftaris"],"pdf_url":"","comment":"32 pages. Published in Transactions on Machine Learning Research"},{"id":"http://arxiv.org/abs/2512.07404v2","updated":"2026-01-05T11:52:55Z","published":"2025-12-08T10:38:03Z","title":"On LLMs' Internal Representation of Code Correctness","summary":"Despite the effectiveness of large language models (LLMs) for code generation, they often output incorrect code. One reason is that model output probabilities are often not well-correlated with correctness, and reflect only the final output of the generation process. Inspired by findings that LLMs internally encode concepts like truthfulness, this paper explores if LLMs similarly represent code correctness. Specifically, we identify a correctness representation inside LLMs by contrasting the hidden states between pairs of correct and incorrect code for the same programming tasks. By experimenting on four LLMs, we show that exploiting this extracted correctness representation outperforms standard log-likelihood ranking, as well as verbalized model confidence. Furthermore, we explore how this internal correctness signal can be used to select higher-quality code samples, without requiring test execution. Ultimately, this work demonstrates how leveraging internal representations can enhance code generation systems and make LLMs more reliable, thus improving confidence in automatically generated code.","authors":["Francisco Ribeiro","Claudio Spiess","Prem Devanbu","Sarah Nadi"],"pdf_url":"","comment":"Accepted for ICSE'26"},{"id":"http://arxiv.org/abs/2601.02037v1","updated":"2026-01-05T11:48:21Z","published":"2026-01-05T11:48:21Z","title":"Multivariate Time-series Anomaly Detection via Dynamic Model Pool & Ensembling","summary":"Multivariate time-series (MTS) anomaly detection is critical in domains such as service monitor, IoT, and network security. While multi-model methods based on selection or ensembling outperform single-model ones, they still face limitations: (i) selection methods rely on a single chosen model and are sensitive to the strategy; (ii) ensembling methods often combine all models or are restricted to univariate data; and (iii) most methods depend on fixed data dimensionality, limiting scalability. To address these, we propose DMPEAD, a Dynamic Model Pool and Ensembling framework for MTS Anomaly Detection. The framework first (i) constructs a diverse model pool via parameter transfer and diversity metric, then (ii) updates it with a meta-model and similarity-based strategy for adaptive pool expansion, subset selection, and pool merging, finally (iii) ensembles top-ranked models through proxy metric ranking and top-k aggregation in the selected subset, outputting the final anomaly detection result. Extensive experiments on 8 real-world datasets show that our model outperforms all baselines, demonstrating superior adaptability and scalability.","authors":["Wei Hu","Zewei Yu","Jianqiu Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02036v1","updated":"2026-01-05T11:47:18Z","published":"2026-01-05T11:47:18Z","title":"GDRO: Group-level Reward Post-training Suitable for Diffusion Models","summary":"Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.","authors":["Yiyang Wang","Xi Chen","Xiaogang Xu","Yu Liu","Hengshuang Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02031v1","updated":"2026-01-05T11:44:05Z","published":"2026-01-05T11:44:05Z","title":"Output Embedding Centering for Stable LLM Pretraining","summary":"Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.","authors":["Felix Stollenwerk","Anna Lokrantz","Niclas Hertzberg"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.02022v1","updated":"2026-01-05T11:30:08Z","published":"2026-01-05T11:30:08Z","title":"Prior Diffusiveness and Regret in the Linear-Gaussian Bandit","summary":"We prove that Thompson sampling exhibits $\\tilde{O}(σd \\sqrt{T} + d r \\sqrt{\\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \\sqrt{\\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \\sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.","authors":["Yifan Zhu","John C. Duchi","Benjamin Van Roy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20075v5","updated":"2026-01-05T11:25:29Z","published":"2025-10-22T23:16:50Z","title":"I Large Language Models possono nascondere un testo in un altro testo della stessa lunghezza","summary":"A meaningful text can be hidden inside another, completely different yet still coherent and plausible, text of the same length. For example, a tweet containing a harsh political critique could be embedded in a tweet that celebrates the same political leader, or an ordinary product review could conceal a secret manuscript. This uncanny state of affairs is now possible thanks to Large Language Models, and in this paper we present Calgacus, a simple and efficient protocol to achieve it. We show that even modest 8-billion-parameter open-source LLMs are sufficient to obtain high-quality results, and a message as long as this abstract can be encoded and decoded locally on a laptop in seconds. The existence of such a protocol demonstrates a radical decoupling of text from authorial intent, further eroding trust in written communication, already shaken by the rise of LLM chatbots. We illustrate this with a concrete scenario: a company could covertly deploy an unfiltered LLM by encoding its answers within the compliant responses of a safe model. This possibility raises urgent questions for AI safety and challenges our understanding of what it means for a Large Language Model to know something.\n  --\nUn testo di senso compiuto può essere nascosto all'interno di un altro testo completamente diverso, eppure coerente e plausibile, della stessa lunghezza. Ad esempio, un tweet che celebra un leader politico potrebbe celare un tweet che lo critica duramente, o un'anonima recensione di un prodotto potrebbe in realtà codificare un manoscritto segreto. Questa sconcertante possibilità è oggi alla nostra portata grazie ai Large Language Models (LLM); in questo articolo presentiamo Calgacus, un protocollo semplice ed efficiente per realizzarla. Mostriamo che anche modesti LLM open-source da 8 miliardi di parametri sono sufficienti per ottenere risultati di alta qualità, e che un messaggio lungo quanto questo abstract può essere codificato e decodificato su un comune portatile in pochi secondi. L'esistenza di tale protocollo dimostra un radicale disaccoppiamento del testo dall'intento del suo autore, erodendo ulteriormente la fiducia nella comunicazione scritta, già scossa dall'ascesa dei chatbot basati su LLMs. Illustriamo ciò con uno scenario concreto: un'azienda potrebbe offrire pubblicamente i servizi di un LLM senza filtri nascondendo le sue risposte all'interno di risposte apparentemente innocue generate da un LLM considerato sicuro. Questa possibilità solleva questioni urgenti per la sicurezza dell'Intelligenza Artificiale e sfida la nostra comprensione di cosa significhi, per un Large Language Model, sapere qualcosa.","authors":["Antonio Norelli","Michael Bronstein"],"pdf_url":"","comment":"21 pages, in Italian language, main paper 9 pages. v1-v4 are in English"},{"id":"http://arxiv.org/abs/2601.02016v1","updated":"2026-01-05T11:24:34Z","published":"2026-01-05T11:24:34Z","title":"Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach","summary":"This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.","authors":["Matthias Bartolo","Dylan Seychell","Gabriel Hili","Matthew Montebello","Carl James Debono","Saviour Formosa","Konstantinos Makantasis"],"pdf_url":"","comment":"Code available on GitHub: https://github.com/mbar0075/lupi-for-object-detection"},{"id":"http://arxiv.org/abs/2411.12589v3","updated":"2026-01-05T11:02:56Z","published":"2024-11-15T19:36:50Z","title":"ULTra: Unveiling Latent Token Interpretability in Transformer-Based Understanding and Segmentation","summary":"Transformers have revolutionized Computer Vision (CV) through self-attention mechanisms. However, their complexity makes latent token representations difficult to interpret. We introduce ULTra, a framework for interpreting Transformer embeddings and uncovering meaningful semantic patterns within them. ULTra enables unsupervised semantic segmentation using pre-trained models without requiring fine-tuning. Additionally, we propose a self-supervised training approach that refines segmentation performance by learning an external transformation matrix without modifying the underlying model. Our method achieves state-of-the-art performance in unsupervised semantic segmentation, outperforming existing segmentation methods. Furthermore, we validate ULTra for model interpretation on both synthetic and real-world scenarios, including Object Selection and interpretable text summarization using LLMs, demonstrating its broad applicability in explaining the semantic structure of latent token representations.","authors":["Hesam Hosseini","Ghazal Hosseini Mighan","Amirabbas Afzali","Sajjad Amini","Amir Houmansadr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01979v1","updated":"2026-01-05T10:33:48Z","published":"2026-01-05T10:33:48Z","title":"SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition","summary":"Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.","authors":["Julie Keisler","Anastase Alexandre Charantonis","Yannig Goude","Boutheina Oueslati","Claire Monteleoni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01970v1","updated":"2026-01-05T10:24:08Z","published":"2026-01-05T10:24:08Z","title":"A Multilayered Approach to Classifying Customer Responsiveness and Credit Risk","summary":"This study evaluates the performance of various classifiers in three distinct models: response, risk, and response-risk, concerning credit card mail campaigns and default prediction. In the response model, the Extra Trees classifier demonstrates the highest recall level (79.1%), emphasizing its effectiveness in identifying potential responders to targeted credit card offers. Conversely, in the risk model, the Random Forest classifier exhibits remarkable specificity of 84.1%, crucial for identifying customers least likely to default. Furthermore, in the multi-class response-risk model, the Random Forest classifier achieves the highest accuracy (83.2%), indicating its efficacy in discerning both potential responders to credit card mail campaign and low-risk credit card users. In this study, we optimized various performance metrics to solve a specific credit risk and mail responsiveness business problem.","authors":["Ayomide Afolabi","Ebere Ogburu","Symon Kimitei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01966v1","updated":"2026-01-05T10:16:41Z","published":"2026-01-05T10:16:41Z","title":"Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior","summary":"Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.","authors":["Bo Yin","Qi Li","Runpeng Yu","Xinchao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.09353v2","updated":"2026-01-05T10:16:15Z","published":"2025-09-11T11:07:36Z","title":"Low-degree lower bounds via almost orthonormal bases","summary":"Low-degree polynomials have emerged as a powerful paradigm for providing evidence of statistical-computational gaps across a variety of high-dimensional statistical models [Wein25]. For detection problems -- where the goal is to test a planted distribution $\\mathbb{P}'$ against a null distribution $\\mathbb{P}$ with independent components -- the standard approach is to bound the advantage using an $\\mathbb{L}^2(\\mathbb{P})$-orthonormal family of polynomials. However, this method breaks down for estimation tasks or more complex testing problems where $\\mathbb{P}$ has some planted structures, so that no simple $\\mathbb{L}^2(\\mathbb{P})$-orthogonal polynomial family is available. To address this challenge, several technical workarounds have been proposed [SW22,SW25], though their implementation can be delicate. In this work, we propose a more direct proof strategy. Focusing on random graph models, we construct a basis of polynomials that is almost orthonormal under $\\mathbb{P}$, in precisely those regimes where statistical-computational gaps arise. This almost orthonormal basis not only yields a direct route to establishing low-degree lower bounds, but also allows us to explicitly identify the polynomials that optimize the low-degree criterion. This, in turn, provides insights into the design of optimal polynomial-time algorithms. We illustrate the effectiveness of our approach by recovering known low-degree lower bounds, and establishing new ones for problems such as hidden subcliques, stochastic block models, and seriation models.","authors":["Alexandra Carpentier","Simone Maria Giancola","Christophe Giraud","Nicolas Verzelen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01963v1","updated":"2026-01-05T10:14:16Z","published":"2026-01-05T10:14:16Z","title":"Forget Less by Learning Together through Concept Consolidation","summary":"Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.","authors":["Arjun Ramesh Kaushik","Naresh Kumar Devulapally","Vishnu Suresh Lokhande","Nalini Ratha","Venu Govindaraju"],"pdf_url":"","comment":"Accepted at WACV-26"},{"id":"http://arxiv.org/abs/2410.06065v2","updated":"2026-01-05T10:12:52Z","published":"2024-10-08T14:12:51Z","title":"Posets and Bounded Probabilities for Discovering Order-inducing Features in Event Knowledge Graphs","summary":"Event knowledge graphs (EKG) extend the classical notion of a trace to capture multiple, interacting views of a process execution. In this paper, we tackle the open problem of automating EKG discovery from uncurated data through a principled probabilistic framing based on the outcome space resulting from featured-derived partial orders on events. From this we derive an EKG discovery algorithm based on statistical inference rather than an ad hoc or heuristic-based strategy, or relying on manual analysis from domain experts.\n  This approach comes at the computational cost of exploring a large, non-convex hypothesis space. In particular, solving the maximum likelihood term in our objective function involves counting the number of linear extensions of posets, which in general is #P-complete. Fortunately, bound estimates suffice for model comparison, and admit incorporation into a bespoke branch-and-bound algorithm. We establish an upper bound on our objective function which we show to be antitonic w.r.t. search depth for branching rules that are monotonic w.r.t. model inclusion. This allows pruning of large portions of the search space, which we show experimentally leads to rapid convergence toward optimal solutions that are consistent with manually built EKGs.","authors":["Christoffer Olling Back","Jakob Grue Simonsen"],"pdf_url":"","comment":"2-column IEEE format"},{"id":"http://arxiv.org/abs/2402.08269v2","updated":"2026-01-05T09:58:43Z","published":"2024-02-13T07:49:57Z","title":"Geometry-induced Regularization in Deep ReLU Neural Networks","summary":"Neural networks with a large number of parameters often do not overfit, owing to implicit regularization that favors \\lq good\\rq{} networks. Other related and puzzling phenomena include properties of flat minima, saddle-to-saddle dynamics, and neuron alignment. To investigate these phenomena, we study the local geometry of deep ReLU neural networks. We show that, for a fixed architecture, as the weights vary, the image of a sample $X$ forms a set whose local dimension changes. The parameter space is partitioned into regions where this local dimension remains constant. The local dimension is invariant under the natural symmetries of ReLU networks (i.e., positive rescalings and neuron permutations). We establish then that the network's geometry induces a regularization, with the local dimension serving as a key measure of regularity. Moreover, we relate the local dimension to a new notion of flatness of minima and to saddle-to-saddle dynamics. For shallow networks, we also show that the local dimension is connected to the number of linear regions perceived by $X$, offering insight into the effects of regularization. This is further supported by experiments and linked to neuron alignment. Our analysis offers, for the first time, a simple and unified geometric explanation that applies to all learning contexts for these phenomena, which are usually studied in isolation. Finally, we explore the practical computation of the local dimension and present experiments on the MNIST dataset, which highlight geometry-induced regularization in this setting.","authors":["Joachim Bona-Pellissier","François Malgouyres","François Bachoc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01943v1","updated":"2026-01-05T09:49:58Z","published":"2026-01-05T09:49:58Z","title":"SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling","summary":"We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.","authors":["Tieu-Long Phan","Nhu-Ngoc Nguyen Song","Peter F. Stadler"],"pdf_url":"","comment":"31 pages (including references), 3 figures, 7 tables"},{"id":"http://arxiv.org/abs/2601.01931v1","updated":"2026-01-05T09:27:49Z","published":"2026-01-05T09:27:49Z","title":"DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems","summary":"Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.","authors":["Willem Röpke","Samuel Coward","Andrei Lupu","Thomas Foster","Tim Rocktäschel","Jakob Foerster"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.21027v6","updated":"2026-01-05T09:24:45Z","published":"2024-05-31T17:16:29Z","title":"Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles","summary":"For solving zero-sum games involving non-transitivity, a useful approach is to maintain a policy population to approximate the Nash Equilibrium (NE). Previous studies have shown that the Policy Space Response Oracles (PSRO) algorithm is an effective framework for solving such games. However, current methods initialize a new policy from scratch or inherit a single historical policy in Best Response (BR), missing the opportunity to leverage past policies to generate a better BR. In this paper, we propose Fusion-PSRO, which employs Nash Policy Fusion to initialize a new policy for BR training. Nash Policy Fusion serves as an implicit guiding policy that starts exploration on the current Meta-NE, thus providing a closer approximation to BR. Moreover, it insightfully captures a weighted moving average of past policies, dynamically adjusting these weights based on the Meta-NE in each iteration. This cumulative process further enhances the policy population. Empirical results on classic benchmarks show that Fusion-PSRO achieves lower exploitability, thereby mitigating the shortcomings of previous research on policy initialization in BR.","authors":["Jiesong Lian","Yucong Huang","Chengdong Ma","Mingzhi Wang","Ying Wen","Long Hu","Yixue Hao"],"pdf_url":"","comment":"Accepted by ECAI 2025"},{"id":"http://arxiv.org/abs/2601.01927v1","updated":"2026-01-05T09:19:45Z","published":"2026-01-05T09:19:45Z","title":"Theoretical Convergence of SMOTE-Generated Samples","summary":"Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.","authors":["Firuz Kamalov","Hana Sulieman","Witold Pedrycz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.17999v2","updated":"2026-01-05T09:14:27Z","published":"2025-02-25T09:05:13Z","title":"GNN-XAR: A Graph Neural Network for Explainable Activity Recognition in Smart Homes","summary":"Sensor-based Human Activity Recognition (HAR) in smart home environments is crucial for several applications, especially in the healthcare domain. The majority of the existing approaches leverage deep learning models. While these approaches are effective, the rationale behind their outputs is opaque. Recently, eXplainable Artificial Intelligence (XAI) approaches emerged to provide intuitive explanations to the output of HAR models. To the best of our knowledge, these approaches leverage classic deep models like CNNs or RNNs. Recently, Graph Neural Networks (GNNs) proved to be effective for sensor-based HAR. However, existing approaches are not designed with explainability in mind. In this work, we propose the first explainable Graph Neural Network explicitly designed for smart home HAR. Our results on two public datasets show that this approach provides better explanations than state-of-the-art methods while also slightly improving the recognition rate.","authors":["Michele Fiori","Davide Mor","Gabriele Civitarese","Claudio Bettini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01922v1","updated":"2026-01-05T09:12:35Z","published":"2026-01-05T09:12:35Z","title":"Efficient temporal prediction of compressible flows in irregular domains using Fourier neural operators","summary":"This paper investigates the temporal evolution of high-speed compressible fluids in irregular flow fields using the Fourier Neural Operator (FNO). We reconstruct the irregular flow field point set into sequential format compatible with FNO input requirements, and then embed temporal bundling technique within a recurrent neural network (RNN) for multi-step prediction. We further employ a composite loss function to balance errors across different physical quantities. Experiments are conducted on three different types of irregular flow fields, including orthogonal and non-orthogonal grid configurations. Then we comprehensively analyze the physical component loss curves, flow field visualizations, and physical profiles. Results demonstrate that our approach significantly surpasses traditional numerical methods in computational efficiency while achieving high accuracy, with maximum relative $L_2$ errors of (0.78, 0.57, 0.35)% for ($p$, $T$, $\\mathbf{u}$) respectively. This verifies that the method can efficiently and accurately simulate the temporal evolution of high-speed compressible flows in irregular domains.","authors":["Yifan Nie","Qiaoxin Li"],"pdf_url":"","comment":"18 pages, 15 figures"},{"id":"http://arxiv.org/abs/2601.01921v1","updated":"2026-01-05T09:11:29Z","published":"2026-01-05T09:11:29Z","title":"A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach","summary":"Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.\n  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.\n  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.\n  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.","authors":["Mikel Robredo","Matteo Esposito","Fabio Palomba","Rafael Peñaloza","Valentina Lenarduzzi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2601.01917v1","updated":"2026-01-05T09:04:10Z","published":"2026-01-05T09:04:10Z","title":"Distorted Distributional Policy Evaluation for Offline Reinforcement Learning","summary":"While Distributional Reinforcement Learning (DRL) methods have demonstrated strong performance in online settings, its success in offline scenarios remains limited. We hypothesize that a key limitation of existing offline DRL methods lies in their approach to uniformly underestimate return quantiles. This uniform pessimism can lead to overly conservative value estimates, ultimately hindering generalization and performance. To address this, we introduce a novel concept called quantile distortion, which enables non-uniform pessimism by adjusting the degree of conservatism based on the availability of supporting data. Our approach is grounded in theoretical analysis and empirically validated, demonstrating improved performance over uniform pessimism.","authors":["Ryo Iwaki","Takayuki Osogami"],"pdf_url":"","comment":"The preprint version of the paper accepted to ICONIP2025. The Version of Record is available online at https://link.springer.com/chapter/10.1007/978-981-95-4091-4_35"},{"id":"http://arxiv.org/abs/2601.01904v1","updated":"2026-01-05T08:49:30Z","published":"2026-01-05T08:49:30Z","title":"Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning","summary":"Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.\n  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.\n  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.","authors":["Yuxuan Li","Harshith Reddy Kethireddy","Srijita Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01903v1","updated":"2026-01-05T08:49:25Z","published":"2026-01-05T08:49:25Z","title":"TT-FSI: Scalable Faithful Shapley Interactions via Tensor-Train","summary":"The Faithful Shapley Interaction (FSI) index uniquely satisfies the faithfulness axiom among Shapley interaction indices, but computing FSI requires $O(d^\\ell \\cdot 2^d)$ time and existing implementations use $O(4^d)$ memory. We present TT-FSI, which exploits FSI's algebraic structure via Matrix Product Operators (MPO). Our main theoretical contribution is proving that the linear operator $v \\mapsto \\text{FSI}(v)$ admits an MPO representation with TT-rank $O(\\ell d)$, enabling an efficient sweep algorithm with $O(\\ell^2 d^3 \\cdot 2^d)$ time and $O(\\ell d^2)$ core storage an exponential improvement over existing methods. Experiments on six datasets ($d=8$ to $d=20$) demonstrate up to 280$\\times$ speedup over baseline, 85$\\times$ over SHAP-IQ, and 290$\\times$ memory reduction. TT-FSI scales to $d=20$ (1M coalitions) where all competing methods fail.","authors":["Ungsik Kim","Suwon Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01901v1","updated":"2026-01-05T08:46:11Z","published":"2026-01-05T08:46:11Z","title":"FedBiCross: A Bi-Level Optimization Framework to Tackle Non-IID Challenges in Data-Free One-Shot Federated Learning on Medical Data","summary":"Data-free knowledge distillation-based one-shot federated learning (OSFL) trains a model in a single communication round without sharing raw data, making OSFL attractive for privacy-sensitive medical applications. However, existing methods aggregate predictions from all clients to form a global teacher. Under non-IID data, conflicting predictions cancel out during averaging, yielding near-uniform soft labels that provide weak supervision for distillation. We propose FedBiCross, a personalized OSFL framework with three stages: (1) clustering clients by model output similarity to form coherent sub-ensembles, (2) bi-level cross-cluster optimization that learns adaptive weights to selectively leverage beneficial cross-cluster knowledge while suppressing negative transfer, and (3) personalized distillation for client-specific adaptation. Experiments on four medical image datasets demonstrate that FedBiCross consistently outperforms state-of-the-art baselines across different non-IID degrees.","authors":["Yuexuan Xia","Yinghao Zhang","Yalin Liu","Hong-Ning Dai","Yong Xia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.06388v4","updated":"2026-01-05T08:44:46Z","published":"2024-02-09T13:10:04Z","title":"Convergence of a L2 regularized Policy Gradient Algorithm for the Multi Armed Bandit","summary":"Although Multi Armed Bandit (MAB) on one hand and the policy gradient approach on the other hand are among the most used frameworks of Reinforcement Learning, the theoretical properties of the policy gradient algorithm used for MAB have not been given enough attention. We investigate in this work the convergence of such a procedure for the situation when a $L2$ regularization term is present jointly with the 'softmax' parametrization. We prove convergence under appropriate technical hypotheses and test numerically the procedure including situations beyond the theoretical setting. The tests show that a time dependent regularized procedure can improve over the canonical approach especially when the initial guess is far from the solution.","authors":["Stefana Anita","Gabriel Turinici"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.05753v2","updated":"2026-01-05T08:40:11Z","published":"2025-12-05T14:39:50Z","title":"A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning","summary":"The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.","authors":["Wencheng Cai","Xuchao Gao","Congying Han","Mingqiang Li","Tiande Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01892v1","updated":"2026-01-05T08:35:36Z","published":"2026-01-05T08:35:36Z","title":"Forget Less by Learning from Parents Through Hierarchical Relationships","summary":"Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.","authors":["Arjun Ramesh Kaushik","Naresh Kumar Devulapally","Vishnu Suresh Lokhande","Nalini K. Ratha","Venu Govindaraju"],"pdf_url":"","comment":"Accepted at AAAI-26"},{"id":"http://arxiv.org/abs/2505.03802v4","updated":"2026-01-05T08:32:05Z","published":"2025-05-02T08:46:01Z","title":"Balancing Fidelity and Plasticity: Aligning Mixed-Precision Fine-Tuning with Linguistic Hierarchies","summary":"Deploying and fine-tuning Large Language Models (LLMs) on resource-constrained edge devices requires navigating a strict trade-off between memory footprint and task performance. While Quantization-Aware Fine-tuning has emerged as a viable solution, existing paradigms typically decouple quantization and adapter optimization. This separation overlooks a fundamental theoretical constraint we identify as the \\textit{Fidelity-Plasticity Trade-off}: a layer's capacity to adapt to new tasks (Plasticity) is inherently constrained by the information capacity of its frozen weights (Fidelity). Aggressively quantizing semantically critical layers creates an information bottleneck that no amount of adapter rank can recover, while high precision in robust syntactic layers wastes valuable memory. To address this, we introduce \\textbf{QR-Adaptor}, a unified framework that jointly optimizes per-layer quantization bit-width and LoRA rank. By formulating resource allocation as a multi-objective search aligned with the model's linguistic hierarchy, our method systematically liberates memory from redundancy-heavy layers to reinvest in capacity-critical ones. Extensive experiments demonstrate that QR-Adaptor establishes a new Pareto frontier: notably, a model fine-tuned under a strict 4-bit memory budget achieves performance rivaling 16-bit baselines, demonstrating that precise resource alignment is as critical as model size.","authors":["Changhai Zhou","Shiyang Zhang","Yuhua Zhou","Qian Qiao","Jun Gao","Shichao Weng","Weizhong Zhang","Cheng Jin"],"pdf_url":"","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.01888v1","updated":"2026-01-05T08:29:51Z","published":"2026-01-05T08:29:51Z","title":"SafeLoad: Efficient Admission Control Framework for Identifying Memory-Overloading Queries in Cloud Data Warehouses","summary":"Memory overload is a common form of resource exhaustion in cloud data warehouses. When database queries fail due to memory overload, it not only wastes critical resources such as CPU time but also disrupts the execution of core business processes, as memory-overloading (MO) queries are typically part of complex workflows. If such queries are identified in advance and scheduled to memory-rich serverless clusters, it can prevent resource wastage and query execution failure. Therefore, cloud data warehouses desire an admission control framework with high prediction precision, interpretability, efficiency, and adaptability to effectively identify MO queries. However, existing admission control frameworks primarily focus on scenarios like SLA satisfaction and resource isolation, with limited precision in identifying MO queries. Moreover, there is a lack of publicly available MO-labeled datasets with workloads for training and benchmarking. To tackle these challenges, we propose SafeLoad, the first query admission control framework specifically designed to identify MO queries. Alongside, we release SafeBench, an open-source, industrial-scale benchmark for this task, which includes 150 million real queries. SafeLoad first filters out memory-safe queries using the interpretable discriminative rule. It then applies a hybrid architecture that integrates both a global model and cluster-level models, supplemented by a misprediction correction module to identify MO queries. Additionally, a self-tuning quota management mechanism dynamically adjusts prediction quotas per cluster to improve precision. Experimental results show that SafeLoad achieves state-of-the-art prediction performance with low online and offline time overhead. Specifically, SafeLoad improves precision by up to 66% over the best baseline and reduces wasted CPU time by up to 8.09x compared to scenarios without SafeLoad.","authors":["Yifan Wu","Yuhan Li","Zhenhua Wang","Zhongle Xie","Dingyu Yang","Ke Chen","Lidan Shou","Bo Tang","Liang Lin","Huan Li","Gang Chen"],"pdf_url":"","comment":"This paper has been accepted for presentation at VLDB 2026"},{"id":"http://arxiv.org/abs/2601.01887v1","updated":"2026-01-05T08:26:34Z","published":"2026-01-05T08:26:34Z","title":"Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance","summary":"Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.","authors":["Jiawen Zhang","Lipeng He","Kejia Chen","Jian Lou","Jian Liu","Xiaohu Yang","Ruoxi Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01877v1","updated":"2026-01-05T08:04:33Z","published":"2026-01-05T08:04:33Z","title":"Random-Matrix-Induced Simplicity Bias in Over-parameterized Variational Quantum Circuits","summary":"Over-parameterization is commonly used to increase the expressivity of variational quantum circuits (VQCs), yet deeper and more highly parameterized circuits often exhibit poor trainability and limited generalization. In this work, we provide a theoretical explanation for this phenomenon from a function-class perspective. We show that sufficiently expressive, unstructured variational ansatze enter a Haar-like universality class in which both observable expectation values and parameter gradients concentrate exponentially with system size. As a consequence, the hypothesis class induced by such circuits collapses with high probability to a narrow family of near-constant functions, a phenomenon we term simplicity bias, with barren plateaus arising as a consequence rather than the root cause. Using tools from random matrix theory and concentration of measure, we rigorously characterize this universality class and establish uniform hypothesis-class collapse over finite datasets. We further show that this collapse is not unavoidable: tensor-structured VQCs, including tensor-network-based and tensor-hypernetwork parameterizations, lie outside the Haar-like universality class. By restricting the accessible unitary ensemble through bounded tensor rank or bond dimension, these architectures prevent concentration of measure, preserve output variability for local observables, and retain non-degenerate gradient signals even in over-parameterized regimes. Together, our results unify barren plateaus, expressivity limits, and generalization collapse under a single structural mechanism rooted in random-matrix universality, highlighting the central role of architectural inductive bias in variational quantum algorithms.","authors":["Jun Qi","Chao-Han Huck Yang","Pin-Yu Chen","Min-Hsiu Hsieh"],"pdf_url":"","comment":"20 pages, 4 figures"},{"id":"http://arxiv.org/abs/2512.14150v2","updated":"2026-01-05T07:45:27Z","published":"2025-12-16T07:15:15Z","title":"PathFinder: Advancing Path Loss Prediction for Single-to-Multi-Transmitter Scenario","summary":"Radio path loss prediction (RPP) is critical for optimizing 5G networks and enabling IoT, smart city, and similar applications. However, current deep learning-based RPP methods lack proactive environmental modeling, struggle with realistic multi-transmitter scenarios, and generalize poorly under distribution shifts, particularly when training/testing environments differ in building density or transmitter configurations. This paper identifies three key issues: (1) passive environmental modeling that overlooks transmitters and key environmental features; (2) overemphasis on single-transmitter scenarios despite real-world multi-transmitter prevalence; (3) excessive focus on in-distribution performance while neglecting distribution shift challenges. To address these, we propose PathFinder, a novel architecture that actively models buildings and transmitters via disentangled feature encoding and integrates Mask-Guided Low-rank Attention to independently focus on receiver and building regions. We also introduce a Transmitter-Oriented Mixup strategy for robust training and a new benchmark, single-to-multi-transmitter RPP (S2MT-RPP), tailored to evaluate extrapolation performance (multi-transmitter testing after single-transmitter training). Experimental results show PathFinder outperforms state-of-the-art methods significantly, especially in challenging multi-transmitter scenarios. Our code and project site are publicly available at: https://emorzz1g.github.io/PathFinder/.","authors":["Zhijie Zhong","Zhiwen Yu","Pengyu Li","Jianming Lv","C. L. Philip Chen","Min Chen"],"pdf_url":"","comment":"20 pages, 14 figures, 4 tables. Under review"},{"id":"http://arxiv.org/abs/2601.01860v1","updated":"2026-01-05T07:41:34Z","published":"2026-01-05T07:41:34Z","title":"High-Order Epistasis Detection Using Factorization Machine with Quadratic Optimization Annealing and MDR-Based Evaluation","summary":"Detecting high-order epistasis is a fundamental challenge in genetic association studies due to the combinatorial explosion of candidate locus combinations. Although multifactor dimensionality reduction (MDR) is a widely used method for evaluating epistasis, exhaustive MDR-based searches become computationally infeasible as the number of loci or the interaction order increases. In this paper, we define the epistasis detection problem as a black-box optimization problem and solve it with a factorization machine with quadratic optimization annealing (FMQA). We propose an efficient epistasis detection method based on FMQA, in which the classification error rate (CER) computed by MDR is used as a black-box objective function. Experimental evaluations were conducted using simulated case-control datasets with predefined high-order epistasis. The results demonstrate that the proposed method successfully identified ground-truth epistasis across various interaction orders and the numbers of genetic loci within a limited number of iterations. These results indicate that the proposed method is effective and computationally efficient for high-order epistasis detection.","authors":["Shuta Kikuchi","Shu Tanaka"],"pdf_url":"","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2512.17341v2","updated":"2026-01-05T07:38:29Z","published":"2025-12-19T08:34:05Z","title":"Sharp Structure-Agnostic Lower Bounds for General Linear Functional Estimation","summary":"We establish a general statistical optimality theory for estimation problems where the target parameter is a linear functional of an unknown nuisance component that must be estimated from data. This formulation covers many causal and predictive parameters and has applications to numerous disciplines. We adopt the structure-agnostic framework introduced by \\citet{balakrishnan2023fundamental}, which poses no structural properties on the nuisance functions other than access to black-box estimators that achieve some statistical estimation rate. This framework is particularly appealing when one is only willing to consider estimation strategies that use non-parametric regression and classification oracles as black-box sub-processes. Within this framework, we first prove the statistical optimality of the celebrated and widely used doubly robust estimators for the Average Treatment Effect (ATE), the most central parameter in causal inference. We then characterize the minimax optimal rate under the general formulation. Notably, we differentiate between two regimes in which double robustness can and cannot be achieved and in which first-order debiasing yields different error rates. Our result implies that first-order debiasing is simultaneously optimal in both regimes. We instantiate our theory by deriving optimal error rates that recover existing results and extend to various settings of interest, including the case when the nuisance is defined by generalized regressions and when covariate shift exists for training and test distribution.","authors":["Jikai Jin","Vasilis Syrgkanis"],"pdf_url":"","comment":"117 pages; generalizes and subsumes arXiv:2402.14264 by the same authors"},{"id":"http://arxiv.org/abs/2601.01852v1","updated":"2026-01-05T07:27:57Z","published":"2026-01-05T07:27:57Z","title":"MORE: Multi-Objective Adversarial Attacks on Speech Recognition","summary":"The emergence of large-scale automatic speech recognition (ASR) models such as Whisper has greatly expanded their adoption across diverse real-world applications. Ensuring robustness against even minor input perturbations is therefore critical for maintaining reliable performance in real-time environments. While prior work has mainly examined accuracy degradation under adversarial attacks, robustness with respect to efficiency remains largely unexplored. This narrow focus provides only a partial understanding of ASR model vulnerabilities. To address this gap, we conduct a comprehensive study of ASR robustness under multiple attack scenarios. We introduce MORE, a multi-objective repetitive doubling encouragement attack, which jointly degrades recognition accuracy and inference efficiency through a hierarchical staged repulsion-anchoring mechanism. Specifically, we reformulate multi-objective adversarial optimization into a hierarchical framework that sequentially achieves the dual objectives. To further amplify effectiveness, we propose a novel repetitive encouragement doubling objective (REDO) that induces duplicative text generation by maintaining accuracy degradation and periodically doubling the predicted sequence length. Overall, MORE compels ASR models to produce incorrect transcriptions at a substantially higher computational cost, triggered by a single adversarial input. Experiments show that MORE consistently yields significantly longer transcriptions while maintaining high word error rates compared to existing baselines, underscoring its effectiveness in multi-objective adversarial attack.","authors":["Xiaoxue Gao","Zexin Li","Yiming Chen","Nancy F. Chen"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2510.10968v2","updated":"2026-01-05T07:04:41Z","published":"2025-10-13T03:19:44Z","title":"Blade: A Derivative-free Bayesian Inversion Method using Diffusion Priors","summary":"Derivative-free Bayesian inversion is an important task in many science and engineering applications, particularly when computing the forward model derivative is computationally and practically challenging. In this paper, we introduce Blade, which can produce accurate and well-calibrated posteriors for Bayesian inversion using an ensemble of interacting particles. Blade leverages powerful data-driven priors based on diffusion models, and can handle nonlinear forward models that permit only black-box access (i.e., derivative-free). Theoretically, we establish a non-asymptotic convergence analysis to characterize the effects of forward model and prior estimation errors. Empirically, Blade achieves superior performance compared to existing derivative-free Bayesian inversion methods on various inverse problems, including challenging highly nonlinear fluid dynamics.","authors":["Hongkai Zheng","Austin Wang","Zihui Wu","Zhengyu Huang","Ricardo Baptista","Yisong Yue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01840v1","updated":"2026-01-05T07:03:04Z","published":"2026-01-05T07:03:04Z","title":"Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack","summary":"Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.","authors":["Qiantao Yang","Liquan Chen","Mingfu Xue","Songze Li"],"pdf_url":"","comment":"Accepted in AAAI 2026"},{"id":"http://arxiv.org/abs/2601.01833v1","updated":"2026-01-05T06:55:35Z","published":"2026-01-05T06:55:35Z","title":"FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks","summary":"Federated Learning (FL) enables multiple clients to collaboratively train a shared model without exposing local data. However, backdoor attacks pose a significant threat to FL. These attacks aim to implant a stealthy trigger into the global model, causing it to mislead on inputs that possess a specific trigger while functioning normally on benign data. Although pre-aggregation detection is a main defense direction, existing state-of-the-art defenses often rely on fixed defense parameters. This reliance makes them vulnerable to single-point-of-failure risks, rendering them less effective against sophisticated attackers. To address these limitations, we propose FAROS, an enhanced FL framework that incorporates Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). The ADS mechanism adjusts the defense's sensitivity dynamically, based on the dispersion of uploaded gradients by clients in each round. This allows it to counter attackers who strategically shift between stealthiness and effectiveness. Furthermore, the RCC effectively mitigates the risk of single-point failure by computing the centroid of a core set comprising clients with the highest confidence. We conducted extensive experiments across various datasets, models, and attack scenarios. The results demonstrate that our method outperforms current defenses in both attack success rate and main task accuracy.","authors":["Chenyu Hu","Qiming Hu","Sinan Chen","Nianyu Li","Mingyue Zhang","Jialong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01829v1","updated":"2026-01-05T06:49:13Z","published":"2026-01-05T06:49:13Z","title":"RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data","summary":"Predicting the evolution of complex physical systems remains a central problem in science and engineering. Despite rapid progress in scientific Machine Learning (ML) models, a critical bottleneck is the lack of expensive real-world data, resulting in most current models being trained and validated on simulated data. Beyond limiting the development and evaluation of scientific ML, this gap also hinders research into essential tasks such as sim-to-real transfer. We introduce RealPDEBench, the first benchmark for scientific ML that integrates real-world measurements with paired numerical simulations. RealPDEBench consists of five datasets, three tasks, eight metrics, and ten baselines. We first present five real-world measured datasets with paired simulated datasets across different complex physical systems. We further define three tasks, which allow comparisons between real-world and simulated data, and facilitate the development of methods to bridge the two. Moreover, we design eight evaluation metrics, spanning data-oriented and physics-oriented metrics, and finally benchmark ten representative baselines, including state-of-the-art models, pretrained PDE foundation models, and a traditional method. Experiments reveal significant discrepancies between simulated and real-world data, while showing that pretraining with simulated data consistently improves both accuracy and convergence. In this work, we hope to provide insights from real-world data, advancing scientific ML toward bridging the sim-to-real gap and real-world deployment. Our benchmark, datasets, and instructions are available at https://realpdebench.github.io/.","authors":["Peiyan Hu","Haodong Feng","Hongyuan Liu","Tongtong Yan","Wenhao Deng","Tianrun Gao","Rong Zheng","Haoren Zheng","Chenglei Yu","Chuanrui Wang","Kaiwen Li","Zhi-Ming Ma","Dezhi Zhou","Xingcai Lu","Dixia Fan","Tailin Wu"],"pdf_url":"","comment":"46 pages, 21 figures"},{"id":"http://arxiv.org/abs/2601.01827v1","updated":"2026-01-05T06:45:51Z","published":"2026-01-05T06:45:51Z","title":"Aspect Extraction from E-Commerce Product and Service Reviews","summary":"Aspect Extraction (AE) is a key task in Aspect-Based Sentiment Analysis (ABSA), yet it remains difficult to apply in low-resource and code-switched contexts like Taglish, a mix of Tagalog and English commonly used in Filipino e-commerce reviews. This paper introduces a comprehensive AE pipeline designed for Taglish, combining rule-based, large language model (LLM)-based, and fine-tuning techniques to address both aspect identification and extraction. A Hierarchical Aspect Framework (HAF) is developed through multi-method topic modeling, along with a dual-mode tagging scheme for explicit and implicit aspects. For aspect identification, four distinct models are evaluated: a Rule-Based system, a Generative LLM (Gemini 2.0 Flash), and two Fine-Tuned Gemma-3 1B models trained on different datasets (Rule-Based vs. LLM-Annotated). Results indicate that the Generative LLM achieved the highest performance across all tasks (Macro F1 0.91), demonstrating superior capability in handling implicit aspects. In contrast, the fine-tuned models exhibited limited performance due to dataset imbalance and architectural capacity constraints. This work contributes a scalable and linguistically adaptive framework for enhancing ABSA in diverse, code-switched environments.","authors":["Valiant Lance D. Dionela","Fatima Kriselle S. Dy","Robin James M. Hombrebueno","Aaron Rae M. Nicolas","Charibeth K. Cheng","Raphael W. Gonda"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.00020v2","updated":"2026-01-05T06:41:55Z","published":"2025-12-22T01:09:24Z","title":"Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing","summary":"Electroencephalography (EEG)-based brain-computer interfaces (BCIs) are strongly affected by non-stationary neural signals that vary across sessions and individuals, limiting the generalization of subject-agnostic models and motivating adaptive and personalized learning on resource-constrained platforms. Programmable memristive hardware offers a promising substrate for such post-deployment adaptation; however, practical realization is challenged by limited weight resolution, device variability, nonlinear programming dynamics, and finite device endurance. In this work, we show that spiking neural networks (SNNs) can be deployed on ferroelectric memristive synaptic devices for adaptive EEG-based motor imagery decoding under realistic device constraints. We fabricate, characterize, and model ferroelectric synapses. We evaluate a convolutional-recurrent SNN architecture under two complementary deployment strategies: (i) device-aware training using a ferroelectric synapse model, and (ii) transfer of software-trained weights followed by low-overhead on-device re-tuning. To enable efficient adaptation, we introduce a device-aware weight-update strategy in which gradient-based updates are accumulated digitally and converted into discrete programming events only when a threshold is exceeded, emulating nonlinear, state-dependent programming dynamics while reducing programming frequency. Both deployment strategies achieve classification performance comparable to state-of-the-art software-based SNNs. Furthermore, subject-specific transfer learning achieved by retraining only the final network layers improves classification accuracy. These results demonstrate that programmable ferroelectric hardware can support robust, low-overhead adaptation in spiking neural networks, opening a practical path toward personalized neuromorphic processing of neural signals.","authors":["Nikhil Garg","Anxiong Song","Niklas Plessnig","Nathan Savoia","Laura Bégon-Lours"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24617v2","updated":"2026-01-05T05:44:29Z","published":"2025-12-31T04:19:33Z","title":"Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space","summary":"Large Language Models (LLMs) apply uniform computation to all tokens, despite language exhibiting highly non-uniform information density. This token-uniform regime wastes capacity on locally predictable spans while under-allocating computation to semantically critical transitions. We propose $\\textbf{Dynamic Large Concept Models (DLCM)}$, a hierarchical language modeling framework that learns semantic boundaries from latent representations and shifts computation from tokens to a compressed concept space where reasoning is more efficient. DLCM discovers variable-length concepts end-to-end without relying on predefined linguistic units. Hierarchical compression fundamentally changes scaling behavior. We introduce the first $\\textbf{compression-aware scaling law}$, which disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. To stably train this heterogeneous architecture, we further develop a $\\textbf{decoupled $μ$P parametrization}$ that supports zero-shot hyperparameter transfer across widths and compression regimes. At a practical setting ($R=4$, corresponding to an average of four tokens per concept), DLCM reallocates roughly one-third of inference compute into a higher-capacity reasoning backbone, achieving a $\\textbf{+2.69$\\%$ average improvement}$ across 12 zero-shot benchmarks under matched inference FLOPs.","authors":["Xingwei Qu","Shaowen Wang","Zihao Huang","Kai Hua","Fan Yin","Rui-Jie Zhu","Jundong Zhou","Qiyang Min","Zihao Wang","Yizhi Li","Tianyu Zhang","He Xing","Zheng Zhang","Yuxuan Song","Tianyu Zheng","Zhiyuan Zeng","Chenghua Lin","Ge Zhang","Wenhao Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.12885v3","updated":"2026-01-05T05:39:03Z","published":"2025-07-17T08:10:55Z","title":"VAR-MATH: Probing True Mathematical Reasoning in LLMS via Symbolic Multi-Instance Benchmarks","summary":"Recent advances in reinforcement learning (RL) have led to substantial improvements in the mathematical reasoning abilities of LLMs, as measured by standard benchmarks. Yet these gains often persist even when models are trained with flawed signals, such as random or inverted rewards. This raises a fundamental question: do such improvements reflect genuine reasoning, or are they merely artifacts of overfitting to benchmark-specific patterns? To answer this question, we adopt an evaluation-centric perspective and highlight two critical shortcomings in existing protocols. First, benchmark contamination arises because test problems are publicly available, thereby increasing the risk of data leakage. Second, evaluation fragility results from reliance on single-instance assessments, which are sensitive to stochastic outputs and fail to capture reasoning consistency. These limitations suggest the need for a new evaluation paradigm that can probe reasoning ability beyond memorization and one-off success. As response, we propose VAR-MATH, a symbolic evaluation framework that converts fixed numerical problems into parameterized templates and requires models to solve multiple instantiations of each. This design enforces consistency across structurally equivalent variants, mitigates contamination, and enhances robustness through bootstrapped metrics. We apply VAR-MATH to transform three popular benchmarks, AMC23, AIME24, and AIME25, into their symbolic counterparts, VAR-AMC23, VAR-AIME24, and VAR-AIME25. Experimental results show substantial performance drops for RL-trained models on these variabilized benchmarks, especially for smaller models, with average declines of 47.9\\% on AMC23, 58.8\\% on AIME24, and 72.9\\% on AIME25. These findings indicate that some existing RL methods rely on superficial heuristics and fail to generalize beyond specific numerical forms.","authors":["Jian Yao","Ran Cheng","Kay Chen Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01803v1","updated":"2026-01-05T05:27:11Z","published":"2026-01-05T05:27:11Z","title":"Moments Matter:Stabilizing Policy Optimization using Return Distributions","summary":"Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.","authors":["Dennis Jabs","Aditya Mohan","Marius Lindauer"],"pdf_url":"","comment":"Workshop paper at RLDM'25"},{"id":"http://arxiv.org/abs/2601.01800v1","updated":"2026-01-05T05:20:16Z","published":"2026-01-05T05:20:16Z","title":"Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving","summary":"Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\\% across all cases compared to state-of-the-art baseline methods.","authors":["Qi Wei","Junchao Fan","Zhao Yang","Jianhua Wang","Jingkai Mao","Xiaolin Chang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01793v1","updated":"2026-01-05T05:06:58Z","published":"2026-01-05T05:06:58Z","title":"Distributed Federated Learning by Alternating Periods of Training","summary":"Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.","authors":["Shamik Bhattacharyya","Rachel Kalpana Kalaimani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01792v1","updated":"2026-01-05T05:06:11Z","published":"2026-01-05T05:06:11Z","title":"HyperCLOVA X 8B Omni","summary":"In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.","authors":[" NAVER Cloud HyperCLOVA X Team"],"pdf_url":"","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2509.20866v2","updated":"2026-01-05T04:55:47Z","published":"2025-09-25T07:59:23Z","title":"On the Robustness of Answer Formats in Medical Reasoning Models","summary":"Medical reasoning models (MRMs) achieve superior performance on medical benchmarks compared to medical LLMs; however, high accuracy alone is insufficient for practical deployment. One of such requirements for real-world application is robustness to varying output constraints. Specifically, posing the same medical question while requesting different answer formats should not affect the underlying correctness of the response. We investigate this phenomenon in this paper, focusing on MRMs. To quantify this behavior, we propose the metric answer-format robustness: the ability to reliably generate correct outputs across varying specified formats. We examine three representative formats: multiple-choice, open-ended question-answering, and ranked lists. Across 15 proprietary and open-weight models, we observe substantial variation in format robustness (35-100%). Furthermore, we conduct controlled fine-tuning experiments on a shared backbone with matched training data to isolate the effects of the fine-tuning paradigm. We find that supervised fine-tuning yields more stable behavior across formats, whereas reinforcement fine-tuning often exhibits higher cross-format brittleness, with the degree of instability strongly dependent on reward design. Overall, answer-format robustness in MRMs is trainable yet brittle and requires careful evaluation for practical medical use.","authors":["Pittawat Taveekitworachai","Natpatchara Pongjirapat","Krittaphas Chaisutyakorn","Piyalitt Ittichaiwong","Tossaporn Saengja","Kunat Pipatanakul"],"pdf_url":"","comment":"62 pages, 47 figures"},{"id":"http://arxiv.org/abs/2412.14738v11","updated":"2026-01-05T04:54:26Z","published":"2024-12-19T11:10:48Z","title":"Improving Graph Neural Network Training, Defense and Hypergraph Clustering via Adversarial Robustness Evaluation","summary":"Graph Neural Networks (GNNs) are a highly effective neural network architecture for processing graph-structured data. Unlike traditional neural networks that rely solely on the features of the data as input, GNNs leverage both the graph structure, which represents the relationships between data points, and the feature matrix of the data to optimize their feature representation. This unique capability enables GNNs to achieve superior performance across various tasks. However, it also makes GNNs more susceptible to noise and adversarial attacks from both the graph structure and data features, which can significantly increase the training difficulty and degrade their performance. Similarly, a hypergraph is a highly complex structure, and partitioning a hypergraph is a challenging task. This paper leverages spectral adversarial robustness evaluation to effectively address key challenges in complex-graph algorithms. By using spectral adversarial robustness evaluation to distinguish robust nodes from non-robust ones and treating them differently, we propose a training-set construction strategy that improves the training quality of GNNs. In addition, we develop algorithms to enhance both the adversarial robustness of GNNs and the performance of hypergraph clustering. Experimental results show that this series of methods is highly effective.","authors":["Yongyu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01786v1","updated":"2026-01-05T04:45:04Z","published":"2026-01-05T04:45:04Z","title":"UnPII: Unlearning Personally Identifiable Information with Quantifiable Exposure Risk","summary":"The ever-increasing adoption of Large Language Models in critical sectors like finance, healthcare, and government raises privacy concerns regarding the handling of sensitive Personally Identifiable Information (PII) during training. In response, regulations such as European Union's General Data Protection Regulation (GDPR) mandate the deletion of PII upon requests, underscoring the need for reliable and cost-effective data removal solutions. Machine unlearning has emerged as a promising direction for selectively forgetting data points. However, existing unlearning techniques typically apply a uniform forgetting strategy that neither accounts for the varying privacy risks posed by different PII attributes nor reflects associated business risks. In this work, we propose UnPII, the first PII-centric unlearning approach that prioritizes forgetting based on the risk of individual or combined PII attributes. To this end, we introduce the PII risk index (PRI), a composite metric that incorporates multiple dimensions of risk factors: identifiability, sensitivity, usability, linkability, permanency, exposability, and compliancy. The PRI enables a nuanced evaluation of privacy risks associated with PII exposures and can be tailored to align with organizational privacy policies. To support realistic assessment, we systematically construct a synthetic PII dataset (e.g., 1,700 PII instances) that simulates realistic exposure scenarios. UnPII seamlessly integrates with established unlearning algorithms, such as Gradient Ascent, Negative Preference Optimization, and Direct Preference Optimization, without modifying their underlying principles. Our experimental results demonstrate that UnPII achieves the improvements of accuracy up to 11.8%, utility up to 6.3%, and generalizability up to 12.4%, respectively, while incurring a modest fine-tuning overhead of 27.5% on average during unlearning.","authors":["Intae Jeon","Yujeong Kwon","Hyungjoon Koo"],"pdf_url":"","comment":"11 pages, 7 Tables, 6 Figures To appear in the Software Engineering in Practice (SEIP) track of ICSE"},{"id":"http://arxiv.org/abs/2511.08314v3","updated":"2026-01-05T04:40:51Z","published":"2025-11-11T14:44:07Z","title":"Improving the accuracy and generalizability of molecular property regression models with a substructure-substitution-rule-informed framework","summary":"Artificial Intelligence (AI)-aided drug discovery is an active research field, yet AI models often exhibit poor accuracy in regression tasks for molecular property prediction, and perform catastrophically poorly for out-of-distribution (OOD) molecules. Here, we present MolRuleLoss, a substructure-substitution-rule-informed framework that improves the accuracy and generalizability of multiple molecular property regression models (MPRMs) such as GEM and UniMol for diverse molecular property prediction tasks. MolRuleLoss incorporates partial derivative constraints for substructure substitution rules (SSRs) into an MPRM's loss function. When using GEM models for predicting lipophilicity, water solubility, and solvation-free energy (using lipophilicity, ESOL, and freeSolv datasets from MoleculeNet), the root mean squared error (RMSE) values with and without MolRuleLoss were 0.587 vs. 0.660, 0.777 vs. 0.798, and 1.252 vs. 1.877, respectively, representing 2.6-33.3% performance improvements. We show that both the number and the quality of SSRs contribute to the magnitude of prediction accuracy gains obtained upon adding MolRuleLoss to an MPRM. MolRuleLoss improved the generalizability of MPRMs for \"activity cliff\" molecules in a lipophilicity prediction task and improved the generalizability of MPRMs for OOD molecules in a melting point prediction task. In a molecular weight prediction task for OOD molecules, MolRuleLoss reduced the RMSE value of a GEM model from 29.507 to 0.007. We also provide a formal demonstration that the upper bound of the variation for property change of SSRs is positively correlated with an MPRM's error. Together, we show that using the MolRuleLoss framework as a bolt-on boosts the prediction accuracy and generalizability of multiple MPRMs, supporting diverse applications in areas like cheminformatics and AI-aided drug discovery.","authors":["Xiaoyu Fan","Lin Guo","Ruizhen Jia","Yang Tian","Zhihao Yang","Weihao Li","Boxue Tian"],"pdf_url":"","comment":"Author information updated: add co-author Weihao Li (affiliation:Department of Statistics and Data Science, Tsinghua University, Beijing, 100084, China). Weihao Li proposed constructive revision suggestions for section on Proof of \"Tian Conjecture\""},{"id":"http://arxiv.org/abs/2601.01785v1","updated":"2026-01-05T04:39:31Z","published":"2026-01-05T04:39:31Z","title":"SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines","summary":"Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.","authors":["Rajiv Chaitanya Muttur"],"pdf_url":"","comment":"Presented at ICEdge 2025; nominated for Best Paper Award"},{"id":"http://arxiv.org/abs/2601.01781v1","updated":"2026-01-05T04:28:49Z","published":"2026-01-05T04:28:49Z","title":"Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery","summary":"Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \\href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.","authors":["Lakshay Sharma","Alex Marin"],"pdf_url":"","comment":"Accepted at CV4EO Workshop at WACV 2026"},{"id":"http://arxiv.org/abs/2512.04341v2","updated":"2026-01-05T04:22:12Z","published":"2025-12-04T00:07:08Z","title":"Long-Horizon Model-Based Offline Reinforcement Learning Without Conservatism","summary":"Popular offline reinforcement learning (RL) methods rely on conservatism, either by penalizing out-of-dataset actions or by restricting rollout horizons. In this work, we question the universality of this principle and instead revisit a complementary one: a Bayesian perspective. Rather than enforcing conservatism, the Bayesian approach tackles epistemic uncertainty in offline data by modeling a posterior distribution over plausible world models and training a history-dependent agent to maximize expected rewards, enabling test-time generalization. We first illustrate, in a bandit setting, that Bayesianism excels on low-quality datasets where conservatism fails. We then scale this principle to realistic tasks and show that long-horizon planning is critical for reducing value overestimation once conservatism is removed. To make this feasible, we introduce key design choices for performing and learning from long-horizon rollouts while controlling compounding errors. These yield our algorithm, NEUBAY, grounded in the neutral Bayesian principle. On D4RL and NeoRL benchmarks, NEUBAY generally matches or surpasses leading conservative algorithms, achieving new state-of-the-art on 7 datasets. Notably, it succeeds with rollout horizons of several hundred steps, contrary to dominant practice. Finally, we characterize datasets by quality and coverage, showing when NEUBAY is preferable to conservative methods. Together, we argue NEUBAY lays the foundation for a new practical direction in offline and model-based RL.","authors":["Tianwei Ni","Esther Derman","Vineet Jain","Vincent Taboga","Siamak Ravanbakhsh","Pierre-Luc Bacon"],"pdf_url":"","comment":"Preprint (52 pages, 15 figures) and code is available at https://github.com/twni2016/neubay"},{"id":"http://arxiv.org/abs/2601.01779v1","updated":"2026-01-05T04:17:55Z","published":"2026-01-05T04:17:55Z","title":"Machine learning modularity","summary":"Based on a transformer based sequence-to-sequence architecture combined with a dynamic batching algorithm, this work introduces a machine learning framework for automatically simplifying complex expressions involving multiple elliptic Gamma functions, including the $q$-$θ$ function and the elliptic Gamma function. The model learns to apply algebraic identities, particularly the SL$(2,\\mathbb{Z})$ and SL$(3,\\mathbb{Z})$ modular transformations, to reduce heavily scrambled expressions to their canonical forms. Experimental results show that the model achieves over 99\\% accuracy on in-distribution tests and maintains robust performance (exceeding 90\\% accuracy) under significant extrapolation, such as with deeper scrambling depths. This demonstrates that the model has internalized the underlying algebraic rules of modular transformations rather than merely memorizing training patterns. Our work presents the first successful application of machine learning to perform symbolic simplification using modular identities, offering a new automated tool for computations with special functions in quantum field theory and the string theory.","authors":["Yi Fan","Vishnu Jejjala","Yang Lei"],"pdf_url":"","comment":"34 pages, 7 figures, 6 tables"},{"id":"http://arxiv.org/abs/2512.10427v4","updated":"2026-01-05T04:13:03Z","published":"2025-12-11T08:38:46Z","title":"Renormalizable Spectral-Shell Dynamics as the Origin of Neural Scaling Laws","summary":"Neural scaling laws and double-descent phenomena suggest that deep-network training obeys a simple macroscopic structure despite highly nonlinear optimization dynamics. We derive such structure directly from gradient descent in function space. For mean-squared error loss, the training error evolves as $\\dot e_t=-M(t)e_t$ with $M(t)=J_{θ(t)}J_{θ(t)}^{\\!*}$, a time-dependent self-adjoint operator induced by the network Jacobian. Using Kato perturbation theory, we obtain an exact system of coupled modewise ODEs in the instantaneous eigenbasis of $M(t)$.\n  To extract macroscopic behavior, we introduce a logarithmic spectral-shell coarse-graining and track quadratic error energy across shells. Microscopic interactions within each shell cancel identically at the energy level, so shell energies evolve only through dissipation and external inter-shell interactions. We formalize this via a \\emph{renormalizable shell-dynamics} assumption, under which cumulative microscopic effects reduce to a controlled net flux across shell boundaries.\n  Assuming an effective power-law spectral transport in a relevant resolution range, the shell dynamics admits a self-similar solution with a moving resolution frontier and explicit scaling exponents. This framework explains neural scaling laws and double descent, and unifies lazy (NTK-like) training and feature learning as two limits of the same spectral-shell dynamics.","authors":["Yizhou Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22455v2","updated":"2026-01-05T04:00:54Z","published":"2025-12-27T04:12:40Z","title":"AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing","summary":"Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method. However, its linear adaptation process limits its expressive power. This means there is a gap between the expressive power of linear training and non-linear training. To bridge this gap, we propose AFA-LoRA, a novel training strategy that brings non-linear expressivity to LoRA while maintaining its seamless mergeability. Our key innovation is an annealed activation function that transitions from a non-linear to a linear transformation during training, allowing the adapter to initially adopt stronger representational capabilities before converging to a mergeable linear form. We implement our method on supervised fine-tuning, reinforcement learning, and speculative decoding. The results show that AFA-LoRA reduces the performance gap between LoRA and full-parameter training. This work enables a more powerful and practical paradigm of parameter-efficient adaptation.","authors":["Jiacheng Li","Jianchao Tan","Zhidong Yang","Feiye Huo","Yerui Sun","Yuchen Xie","Xunliang Cai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.01991v5","updated":"2026-01-05T03:59:23Z","published":"2024-07-02T07:06:49Z","title":"Generation of Geodesics with Actor-Critic Reinforcement Learning to Predict Midpoints","summary":"To find the shortest paths for all pairs on manifolds with infinitesimally defined metrics, we introduce a framework to generate them by predicting midpoints recursively. To learn midpoint prediction, we propose an actor-critic approach. We prove the soundness of our approach and show experimentally that the proposed method outperforms existing methods on several planning tasks, including path planning for agents with complex kinematics and motion planning for multi-degree-of-freedom robot arms.","authors":["Kazumi Kasaura"],"pdf_url":"","comment":"17 pages with 8 pages of appendices and references, 9 figures"},{"id":"http://arxiv.org/abs/2305.07205v3","updated":"2026-01-05T03:36:57Z","published":"2023-05-12T02:36:07Z","title":"Mem-Rec: Memory Efficient Recommendation System using Alternative Representation","summary":"Deep learning-based recommendation systems (e.g., DLRMs) are widely used AI models to provide high-quality personalized recommendations. Training data used for modern recommendation systems commonly includes categorical features taking on tens-of-millions of possible distinct values. These categorical tokens are typically assigned learned vector representations, that are stored in large embedding tables, on the order of 100s of GB. Storing and accessing these tables represent a substantial burden in commercial deployments. Our work proposes MEM-REC, a novel alternative representation approach for embedding tables. MEM-REC leverages bloom filters and hashing methods to encode categorical features using two cache-friendly embedding tables. The first table (token embedding) contains raw embeddings (i.e. learned vector representation), and the second table (weight embedding), which is much smaller, contains weights to scale these raw embeddings to provide better discriminative capability to each data point. We provide a detailed architecture, design and analysis of MEM-REC addressing trade-offs in accuracy and computation requirements, in comparison with state-of-the-art techniques. We show that MEM-REC can not only maintain the recommendation quality and significantly reduce the memory footprint for commercial scale recommendation models but can also improve the embedding latency. In particular, based on our results, MEM-REC compresses the MLPerf CriteoTB benchmark DLRM model size by 2900x and performs up to 3.4x faster embeddings while achieving the same AUC as that of the full uncompressed model.","authors":["Gopi Krishna Jha","Anthony Thomas","Nilesh Jain","Sameh Gobriel","Tajana Rosing","Ravi Iyer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.00022v2","updated":"2026-01-05T03:29:51Z","published":"2025-02-24T02:57:51Z","title":"KVCrush: Key value cache size-reduction using similarity in head-behaviour","summary":"Key-value (KV) caching has emerged as a crucial optimization technique for accelerating inference in large language models (LLMs). By allowing the attention operation to scale linearly rather than quadratically with the total sequence length, KV caching significantly enhances generation throughput. However, due to large context lengths in the modern LLMs, the memory footprint of the KV is a huge bottleneck for model deployment directly impacting the model's batch size, hindering its ability to deliver high-throughput. Existing research addresses this challenge using several techniques, such as discarding low-attention tokens, quantization, and matrix approximation which typically lead to a negative impact on the model accuracy.\n  In this paper, We propose KVCrush technology which can be combined with many KV compression technologies to improve the model accuracy at a much smaller memory. KVCrush provides an alternate representation scheme for key-value states, along with a low-overhead token pruning algorithm that accounts for the token distribution in the KV cache, which in turn allows for a a smaller footprint while maintaining the accuracy of the model. Based on our results, KVCrush reduces LongBench KV Cache size by 4x with less than 1% accuracy drop and achieves state-of-the-art average accuracy with minimal overhead, incurring less than 0.5% total inference latency. KVCrush not only outperforms the accuracy of state-of-the-art importance-based token retention schemes but is also compatible with typical practical LLM deployments using KV cache paging schemes such as vLLM and mixed precision quantization.","authors":["Gopi Krishna Jha","Sameh Gobriel","Liubov Talamanova","Nilesh Jain"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.00728v2","updated":"2026-01-05T03:25:36Z","published":"2026-01-02T15:59:42Z","title":"Precision Autotuning for Linear Solvers via Reinforcement Learning","summary":"We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.","authors":["Erin Carson","Xinye Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01757v1","updated":"2026-01-05T03:15:52Z","published":"2026-01-05T03:15:52Z","title":"Sparse Convex Biclustering","summary":"Biclustering is an essential unsupervised machine learning technique for simultaneously clustering rows and columns of a data matrix, with widespread applications in genomics, transcriptomics, and other high-dimensional omics data. Despite its importance, existing biclustering methods struggle to meet the demands of modern large-scale datasets. The challenges stem from the accumulation of noise in high-dimensional features, the limitations of non-convex optimization formulations, and the computational complexity of identifying meaningful biclusters. These issues often result in reduced accuracy and stability as the size of the dataset increases. To overcome these challenges, we propose Sparse Convex Biclustering (SpaCoBi), a novel method that penalizes noise during the biclustering process to improve both accuracy and robustness. By adopting a convex optimization framework and introducing a stability-based tuning criterion, SpaCoBi achieves an optimal balance between cluster fidelity and sparsity. Comprehensive numerical studies, including simulations and an application to mouse olfactory bulb data, demonstrate that SpaCoBi significantly outperforms state-of-the-art methods in accuracy. These results highlight SpaCoBi as a robust and efficient solution for biclustering in high-dimensional and large-scale datasets.","authors":["Jiakun Jiang","Dewei Xiang","Chenliang Gu","Wei Liu","Binhuan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01754v1","updated":"2026-01-05T03:14:23Z","published":"2026-01-05T03:14:23Z","title":"Context-Free Recognition with Transformers","summary":"Transformers excel on tasks that process well-formed inputs according to some grammar, such as natural language and code. However, it remains unclear how they can process grammatical syntax. In fact, under standard complexity conjectures, standard transformers cannot recognize context-free languages (CFLs), a canonical formalism to describe syntax, or even regular languages, a subclass of CFLs (Merrill et al., 2022). Merrill & Sabharwal (2024) show that $\\mathcal{O}(\\log n)$ looping layers (w.r.t. input length $n$) allows transformers to recognize regular languages, but the question of context-free recognition remained open. In this work, we show that looped transformers with $\\mathcal{O}(\\log n)$ looping layers and $\\mathcal{O}(n^6)$ padding tokens can recognize all CFLs. However, training and inference with $\\mathcal{O}(n^6)$ padding tokens is potentially impractical. Fortunately, we show that, for natural subclasses such as unambiguous CFLs, the recognition problem on transformers becomes more tractable, requiring $\\mathcal{O}(n^3)$ padding. We empirically validate our results and show that looping helps on a language that provably requires logarithmic depth. Overall, our results shed light on the intricacy of CFL recognition by transformers: While general recognition may require an intractable amount of padding, natural constraints such as unambiguity yield efficient recognition algorithms.","authors":["Selim Jerad","Anej Svete","Sophie Hao","Ryan Cotterell","William Merrill"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.23868v2","updated":"2026-01-05T03:09:10Z","published":"2025-10-27T21:18:19Z","title":"GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA","summary":"I propose \\textbf{G}roup-relative \\textbf{I}mplicit \\textbf{F}ine \\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning LLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT minimizes the discrepancy between implicit and explicit reward models. It combines three key ideas: (1) the online multi-response generation and normalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the implicit-explicit reward alignment principle of UNA. By jointly normalizing the implicit and explicit rewards, GIFT eliminates an otherwise intractable term that prevents effective use of implicit rewards. This normalization transforms the complex reward maximization objective into a simple mean squared error (MSE) loss between the normalized reward functions, converting a non-convex optimization problem into a convex, stable, and analytically differentiable formulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy and thus retains exploration capability. Compared to GRPO, it requires fewer hyperparameters, converges faster, and generalizes better with significantly reduced training overfitting. Empirically, GIFT achieves superior reasoning and alignment performance on mathematical benchmarks while remaining computationally efficient.","authors":["Zhichao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.05338v2","updated":"2026-01-05T03:05:52Z","published":"2025-12-05T00:34:15Z","title":"Interaction Tensor SHAP","summary":"This study proposes Interaction Tensor SHAP (IT-SHAP), a tensor algebraic formulation of the Shapley Taylor Interaction Index (STII) that makes its computational structure explicit. STII extends the Shapley value to higher order interactions, but its exponential combinatorial definition makes direct computation intractable at scale. We reformulate STII as a linear transformation acting on a value function and derive an explicit algebraic representation of its weight tensor. This weight tensor is shown to possess a multilinear structure induced by discrete finite difference operators. When the value function admits a Tensor Train representation, higher order interaction indices can be computed in the parallel complexity class NC squared. In contrast, under general tensor network representations without structural assumptions, the same computation is proven to be P sharp hard. The main contributions are threefold. First, we establish an exact Tensor Train representation of the STII weight tensor. Second, we develop a parallelizable evaluation algorithm with explicit complexity bounds under the Tensor Train assumption. Third, we prove that computational intractability is unavoidable in the absence of such structure. These results demonstrate that the computational difficulty of higher order interaction analysis is determined by the underlying algebraic representation rather than by the interaction index itself, providing a theoretical foundation for scalable interpretation of high dimensional models.","authors":["Hiroki Hasegawa","Yukihiko Okada"],"pdf_url":"","comment":"22 pages"},{"id":"http://arxiv.org/abs/2512.22909v2","updated":"2026-01-05T03:03:50Z","published":"2025-12-28T12:31:56Z","title":"A first-order method for nonconvex-strongly-concave constrained minimax optimization","summary":"In this paper we study a nonconvex-strongly-concave constrained minimax problem. Specifically, we propose a first-order augmented Lagrangian method for solving it, whose subproblems are nonconvex-strongly-concave unconstrained minimax problems and suitably solved by a first-order method developed in this paper that leverages the strong concavity structure. Under suitable assumptions, the proposed method achieves an operation complexity of $O(\\varepsilon^{-3.5}\\log\\varepsilon^{-1})$, measured in terms of its fundamental operations, for finding an $\\varepsilon$-KKT solution of the constrained minimax problem, which improves the previous best-known operation complexity by a factor of $\\varepsilon^{-0.5}$.","authors":["Zhaosong Lu","Sanyou Mei"],"pdf_url":"","comment":"Accepted by Optimization Methods and Software"},{"id":"http://arxiv.org/abs/2601.01747v1","updated":"2026-01-05T02:49:33Z","published":"2026-01-05T02:49:33Z","title":"Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization","summary":"Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs","authors":["Jiwei Guan","Haibo Jin","Haohan Wang"],"pdf_url":"","comment":"EACL"},{"id":"http://arxiv.org/abs/2511.19019v2","updated":"2026-01-05T02:44:40Z","published":"2025-11-24T11:47:17Z","title":"3D Dynamic Radio Map Prediction Using Vision Transformers for Low-Altitude Wireless Networks","summary":"Low-altitude wireless networks (LAWN) are rapidly expanding with the growing deployment of unmanned aerial vehicles (UAVs) for logistics, surveillance, and emergency response. Reliable connectivity remains a critical yet challenging task due to three-dimensional (3D) mobility, time-varying user density, and limited power budgets. The transmit power of base stations (BSs) fluctuates dynamically according to user locations and traffic demands, leading to a highly non-stationary 3D radio environment. Radio maps (RMs) have emerged as an effective means to characterize spatial power distributions and support radio-aware network optimization. However, most existing works construct static or offline RMs, overlooking real-time power variations and spatio-temporal dependencies in multi-UAV networks. To overcome this limitation, we propose a 3D dynamic radio map (3D-DRM) framework that learns and predicts the spatio-temporal evolution of received power. Specially, a Vision Transformer (ViT) encoder extracts high-dimensional spatial representations from 3D RMs, while a Transformer-based module models sequential dependencies to predict future power distributions. Experiments unveil that 3D-DRM accurately captures fast-varying power dynamics and substantially outperforms baseline models in both RM reconstruction and short-term prediction.","authors":["Nguyen Duc Minh Quang","Chang Liu","Huy-Trung Nguyen","Shuangyang Li","Derrick Wing Kwan Ng","Wei Xiang"],"pdf_url":"","comment":"7 pages, 4 figures, submitted to IEEE ICC 2026"},{"id":"http://arxiv.org/abs/2504.13201v3","updated":"2026-01-05T02:39:28Z","published":"2025-04-15T03:50:04Z","title":"CEE: An Inference-Time Jailbreak Defense for Embodied Intelligence via Subspace Concept Rotation","summary":"Large language models (LLMs) are widely used for task understanding and action planning in embodied intelligence (EI) systems, but their adoption substantially increases vulnerability to jailbreak attacks. While recent work explores inference-time defenses, existing methods rely on static interventions on intermediate representations, which often degrade generation quality and impair adherence to task instructions, reducing system usability in EI settings. We propose a dynamic defense framework. For each EI inference request, we dynamically construct a task-specific safety-semantic subspace, project its hidden state to the most relevant direction, and apply SLERP rotation for adaptive safety control. At comparable defense success rates, our method preserves generation quality, improves usability, reduces tuning cost, and strengthens robustness in EI scenarios.","authors":["Jirui Yang","Zheyu Lin","Zhihui Lu","Yinggui Wang","Lei Wang","Tao Wei","Qiang Duan","Xin Du","Shuhan Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01741v1","updated":"2026-01-05T02:32:50Z","published":"2026-01-05T02:32:50Z","title":"Latent Space Element Method","summary":"How can we build surrogate solvers that train on small domains but scale to larger ones without intrusive access to PDE operators? Inspired by the Data-Driven Finite Element Method (DD-FEM) framework for modular data-driven solvers, we propose the Latent Space Element Method (LSEM), an element-based latent surrogate assembly approach in which a learned subdomain (\"element\") model can be tiled and coupled to form a larger computational domain. Each element is a LaSDI latent ODE surrogate trained from snapshots on a local patch, and neighboring elements are coupled through learned directional interaction terms in latent space, avoiding Schwarz iterations and interface residual evaluations. A smooth window-based blending reconstructs a global field from overlapping element predictions, yielding a scalable assembled latent dynamical system. Experiments on the 1D Burgers and Korteweg-de Vries equations show that LSEM maintains predictive accuracy while scaling to spatial domains larger than those seen in training. LSEM offers an interpretable and extensible route toward foundation-model surrogate solvers built from reusable local models.","authors":["Seung Whan Chung","Youngsoo Choi","Christopher Miller","H. Keo Springer","Kyle T. Sullivan"],"pdf_url":"","comment":"17 pages, 10 figures"},{"id":"http://arxiv.org/abs/2504.06704v2","updated":"2026-01-05T02:08:13Z","published":"2025-04-09T09:08:26Z","title":"CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers","summary":"Transformers have driven remarkable breakthroughs in natural language processing and computer vision, yet their standard attention mechanism still imposes O(N^2) complexity, hindering scalability to longer sequences. We introduce Circular-convolutional ATtention (CAT), a Fourier-based approach that efficiently applies circular convolutions to reduce complexity without sacrificing representational power. CAT achieves O(NlogN) computations, requires fewer learnable parameters by streamlining fully connected layers, and introduces no additional heavy operations, resulting in consistent accuracy improvements and about a 10% speedup in naive PyTorch implementations. Based on the Engineering-Isomorphic Transformers (EITs) framework, CAT's design not only offers practical efficiency and ease of implementation, but also provides insights to guide the development of future high-performance Transformer architectures. Finally, our ablation studies highlight the key conditions underlying CAT's success, shedding light on broader principles for scalable attention mechanisms.","authors":["Yoshihiro Yamada"],"pdf_url":"","comment":"Accepted as a poster at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2511.02122v3","updated":"2026-01-05T01:59:41Z","published":"2025-11-03T23:22:37Z","title":"Matrix Sensing with Kernel Optimal Loss: Robustness and Optimization Landscape","summary":"In this paper we study how the choice of loss functions of non-convex optimization problems affects their robustness and optimization landscape, through the study of noisy matrix sensing. In traditional regression tasks, mean squared error (MSE) loss is a common choice, but it can be unreliable for non-Gaussian or heavy-tailed noise. To address this issue, we adopt a robust loss based on nonparametric regression, which uses a kernel-based estimate of the residual density and maximizes the estimated log-likelihood. This robust formulation coincides with the MSE loss under Gaussian errors but remains stable under more general settings. We further examine how this robust loss reshapes the optimization landscape by analyzing the upper-bound of restricted isometry property (RIP) constants for spurious local minima to disappear. Through theoretical and empirical analysis, we show that this new loss excels at handling large noise and remains robust across diverse noise distributions. This work offers initial insights into enhancing the robustness of machine learning tasks through simply changing the loss, guided by an intuitive and broadly applicable analytical framework.","authors":["Xinyuan Song","Ziye Ma"],"pdf_url":"","comment":"CPAL 2026"},{"id":"http://arxiv.org/abs/2601.01714v1","updated":"2026-01-05T01:37:10Z","published":"2026-01-05T01:37:10Z","title":"Entropy-Aligned Decoding of LMs for Better Writing and Reasoning","summary":"Language models (LMs) are trained on billions of tokens in an attempt to recover the true language distribution. Still, vanilla random sampling from LMs yields low quality generations. Decoding algorithms attempt to restrict the LM distribution to a set of high-probability continuations, but rely on greedy heuristics that introduce myopic distortions, yielding sentences that are homogeneous, repetitive and incoherent. In this paper, we introduce EPIC, a hyperparameter-free decoding approach that incorporates the entropy of future trajectories into LM decoding. EPIC explicitly regulates the amount of uncertainty expressed at every step of generation, aligning the sampling distribution's entropy to the aleatoric (data) uncertainty. Through Entropy-Aware Lazy Gumbel-Max sampling, EPIC manages to be exact, while also being efficient, requiring only a sublinear number of entropy evaluations per step. Unlike current baselines, EPIC yields sampling distributions that are empirically well-aligned with the entropy of the underlying data distribution. Across creative writing and summarization tasks, EPIC consistently improves LM-as-judge preference win-rates over widely used decoding strategies. These preference gains are complemented by automatic metrics, showing that EPIC produces more diverse generations and more faithful summaries. We also evaluate EPIC on mathematical reasoning, where it outperforms all baselines.","authors":["Kareem Ahmed","Sameer Singh"],"pdf_url":"","comment":null}],"Artificial Intelligence Learning":[{"id":"http://arxiv.org/abs/2506.09827v3","updated":"2026-01-05T18:59:29Z","published":"2025-06-11T15:06:59Z","title":"EmoNet-Voice: A Fine-Grained, Expert-Verified Benchmark for Speech Emotion Detection","summary":"Speech emotion recognition (SER) systems are constrained by existing datasets that typically cover only 6-10 basic emotions, lack scale and diversity, and face ethical challenges when collecting sensitive emotional states. We introduce EMONET-VOICE, a comprehensive resource addressing these limitations through two components: (1) EmoNet-Voice Big, a 5,000-hour multilingual pre-training dataset spanning 40 fine-grained emotion categories across 11 voices and 4 languages, and (2) EmoNet-Voice Bench, a rigorously validated benchmark of 4,7k samples with unanimous expert consensus on emotion presence and intensity levels. Using state-of-the-art synthetic voice generation, our privacy-preserving approach enables ethical inclusion of sensitive emotions (e.g., pain, shame) while maintaining controlled experimental conditions. Each sample underwent validation by three psychology experts. We demonstrate that our Empathic Insight models trained on our synthetic data achieve strong real-world dataset generalization, as tested on EmoDB and RAVDESS. Furthermore, our comprehensive evaluation reveals that while high-arousal emotions (e.g., anger: 95% accuracy) are readily detected, the benchmark successfully exposes the difficulty of distinguishing perceptually similar emotions (e.g., sadness vs. distress: 63% discrimination), providing quantifiable metrics for advancing nuanced emotion AI. EMONET-VOICE establishes a new paradigm for large-scale, ethically-sourced, fine-grained SER research.","authors":["Christoph Schuhmann","Robert Kaczmarczyk","Gollam Rabby","Felix Friedrich","Maurice Kraus","Kourosh Nadi","Huu Nguyen","Kristian Kersting","Sören Auer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21907v2","updated":"2026-01-05T18:55:51Z","published":"2025-12-26T07:40:11Z","title":"SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?","summary":"Spatial transcriptomics assays are rapidly increasing in scale and complexity, making computational analysis a major bottleneck in biological discovery. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world spatial datasets. We introduce SpatialBench, a benchmark of 146 verifiable problems derived from practical spatial analysis workflows spanning five spatial technologies and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on frontier models shows that base model accuracy remains low (20-38% across model families), with strong model-task and model-platform interactions. Harness design has a large empirical effect on performance, indicating that tools, prompts, control flow, and execution environment should be evaluated and improved as first-class objects. SpatialBench serves both as a measurement tool and a diagnostic lens for developing agents that can interact with real spatial datasets faithfully, transparently, and reproducibly.","authors":["Kenny Workman","Zhen Yang","Harihara Muralidharan","Hannah Le"],"pdf_url":"","comment":"10 pages, 9 figures, 4 tables; NeurIPS 2024 format"},{"id":"http://arxiv.org/abs/2601.02357v1","updated":"2026-01-05T18:55:43Z","published":"2026-01-05T18:55:43Z","title":"DARC: Drum accompaniment generation with fine-grained rhythm control","summary":"In music creation, rapid prototyping is essential for exploring and refining ideas, yet existing generative tools often fall short when users require both structural control and stylistic flexibility. Prior approaches in stem-to-stem generation can condition on other musical stems but offer limited control over rhythm, and timbre-transfer methods allow users to specify specific rhythms, but cannot condition on musical context. We introduce DARC, a generative drum accompaniment model that conditions both on musical context from other stems and explicit rhythm prompts such as beatboxing or tapping tracks. Using parameter-efficient fine-tuning, we augment STAGE, a state-of-the-art drum stem generator, with fine-grained rhythm control while maintaining musical context awareness.","authors":["Trey Brosnan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02346v1","updated":"2026-01-05T18:44:27Z","published":"2026-01-05T18:44:27Z","title":"Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling","summary":"This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\\times$ to $7\\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.","authors":[" Falcon LLM Team","Iheb Chaabane","Puneesh Khanna","Suhail Mohmad","Slim Frikha","Shi Hu","Abdalgader Abubaker","Reda Alami","Mikhail Lubinets","Mohamed El Amine Seddik","Hakim Hacid"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.04346v6","updated":"2026-01-05T18:39:22Z","published":"2025-07-06T11:19:34Z","title":"Improving Action Smoothness for a Cascaded Online Learning Flight Control System","summary":"This paper aims to improve the action smoothness of a cascaded online learning flight control system. Although the cascaded structure is widely used in flight control design, its stability can be compromised by oscillatory control actions, which poses challenges for practical engineering applications. To address this issue, we introduce an online temporal smoothness technique and a low-pass filter to reduce the amplitude and frequency of the control actions. Fast Fourier Transform (FFT) is used to analyze policy performance in the frequency domain. Simulation results demonstrate the improvements achieved by the two proposed techniques.","authors":["Yifei Li","Erik-jan van Kampen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.18773v3","updated":"2026-01-05T18:08:27Z","published":"2025-03-24T15:22:41Z","title":"BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache","summary":"The growth of long-context Large Language Models (LLMs) significantly increases memory and bandwidth pressure during autoregressive decoding due to the expanding Key-Value (KV) cache. While accuracy-preserving KV-cache quantization (e.g., 4-bit or 2-bit) reduces memory footprint, existing systems decode inefficiently by relying solely on CUDA cores, underutilizing Tensor Cores-the dominant compute resource on GPUs.\n  We present BitDecoding, the first inference system to efficiently decode low-bit KV caches by cooperatively leveraging CUDA cores and Tensor Cores. BitDecoding smartly induces Tensor-Core-friendly layouts, introduces warp-level dequantization parallelism, and provides unified system support through query transformation, high-performance tensor- and channel-wise quantization, and a software-pipelined dequantization kernel enabling mixed-precision execution. Architecture-aware optimizations further leverage Hopper's warpgroup tensor instructions and Blackwell's NVFP4 (MXFP4) tensor formats.\n  Evaluated on Blackwell, Hopper, and Ampere GPUs, BitDecoding achieves an average 7.5x decoding speedup over FP16 FlashDecoding-v2, up to 8.6x on Blackwell with NVFP4, and up to 4.3x over state-of-the-art approaches. On LLaMA-3.1-8B with a 128K context, BitDecoding reduces single-batch decoding latency by 3x. BitDecoding is open-sourced at https://github.com/OpenBitSys/BitDecoding.","authors":["Dayou Du","Shijie Cao","Jianyi Cheng","Luo Mai","Ting Cao","Mao Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02316v1","updated":"2026-01-05T18:07:51Z","published":"2026-01-05T18:07:51Z","title":"DatBench: Discriminative, Faithful, and Efficient VLM Evaluations","summary":"Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.","authors":["Siddharth Joshi","Haoli Yin","Rishabh Adiga","Ricardo Monti","Aldo Carranza","Alex Fang","Alvin Deng","Amro Abbas","Brett Larsen","Cody Blakeney","Darren Teh","David Schwab","Fan Pan","Haakon Mongstad","Jack Urbanek","Jason Lee","Jason Telanoff","Josh Wills","Kaleigh Mentzer","Luke Merrick","Parth Doshi","Paul Burstein","Pratyush Maini","Scott Loftin","Spandan Das","Tony Jiang","Vineeth Dorna","Zhengping Wang","Bogdan Gaza","Ari Morcos","Matthew Leavitt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02314v1","updated":"2026-01-05T18:05:29Z","published":"2026-01-05T18:05:29Z","title":"Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents","summary":"As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \\textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \\textbf{faithful} generative drivers of the model's output or merely \\textbf{post-hoc rationalizations}. We introduce \\textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \\textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \\textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \\textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \\textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as \"Reasoning Theater\" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.","authors":["Sourena Khanzadeh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02311v1","updated":"2026-01-05T18:01:38Z","published":"2026-01-05T18:01:38Z","title":"Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies","summary":"Training large language models requires distributing computation across many accelerators, yet practitioners select parallelism strategies (data, tensor, pipeline, ZeRO) through trial and error because no unified systematic framework predicts their behavior. We introduce placement semantics: each strategy is specified by how it places four training states (parameters, optimizer, gradients, activations) across devices using five modes (replicated, sharded, sharded-with-gather, materialized, offloaded). From placement alone, without implementation details, we derive memory consumption and communication volume. Our predictions match published results exactly: ZeRO-3 uses 8x less memory than data parallelism at 1.5x communication cost, as reported in the original paper. We prove two conditions (gradient integrity, state consistency) are necessary and sufficient for distributed training to match single-device results, and provide composition rules for combining strategies safely. The framework unifies ZeRO Stages 1-3, Fully Sharded Data Parallel (FSDP), tensor parallelism, and pipeline parallelism as instances with different placement choices.","authors":["Deep Pankajbhai Mehta"],"pdf_url":"","comment":"8 pages, 3 tables"},{"id":"http://arxiv.org/abs/2510.06478v2","updated":"2026-01-05T17:33:34Z","published":"2025-10-07T21:28:53Z","title":"Anytime-Valid Answer Sufficiency Certificates for LLM Generation via Sequential Information Lift","summary":"We introduce Sequential-EDFL (Empirical Dynamic Formal Lift), which applies anytime-valid sequential testing to language model generation stopping. Our approach tracks information lift, defined as the log-likelihood ratio between the full model and deliberately weakened \"skeleton\" baselines, using self-normalized empirical-Bernstein e-processes that provide formal delta-level error control regardless of stopping time. This delta guarantee controls premature stopping when information lift is insufficient relative to the skeleton, and it does not imply delta control of factual incorrectness or hallucinations. We handle unknown centering through online mean estimation, combine multiple parameters via mixture e-processes, and support adaptive resets under distributional drift. On six benchmarks, Sequential-EDFL reduces generation length by 22 to 28 percent relative to sequential baselines while maintaining delta-level control with 12 percent computational overhead. We introduce automated skeletons (distilled submodels and randomized logits) and show robustness across skeleton families. Composing EDFL with a lightweight correctness gate (sentence boundaries plus a verifier) improves end-task correctness while preserving anytime-valid guarantees by only delaying stopping. Our certificates control information sufficiency, not factual correctness. Specifically, 10.9 percent of stopped sequences remain incorrect even with the gate (13.2 to 22.7 percent without it). EDFL serves as a first-stage filter that can reduce verification burden: when applied to stopped sequences, the gate validates 83 percent of stops, requiring full verification only for the remaining 17 percent, plus all non-stopped sequences. EDFL is not a standalone solution for safety-critical domains.","authors":["Sanjeda Akter","Ibne Farabi Shihab","Anuj Sharma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01208v2","updated":"2026-01-05T17:26:51Z","published":"2025-12-01T02:46:15Z","title":"Language as a Wave Phenomenon: Iso-Energetic Phase-Locking and Semantic Interference in Neural Networks","summary":"Conventional deep learning paradigms rely on metabolically expensive magnitude-based representations, rendering them fundamentally incompatible with passive photonic hardware. We introduce PRISM, a sequence modeling architecture that bridges high-level reasoning and physical constraints by enforcing an Iso-Energetic (Unity Gain) principle, compelling the network to encode semantic information exclusively in the phase angle. Validated on the WMT14 translation benchmark, PRISM achieves a 0.799 COMET score, demonstrating that phase-based reasoning competes with standard Transformers (0.821) and functionally matches unconstrained spectral baselines like FNet (0.805), despite enforcing strict energy constraints and requiring 11.5% fewer parameters. Furthermore, to verify hardware feasibility, we simulate a Holographic Backpropagation mechanism on a noisy, 4-bit optical correlator. Ablation studies reveal a substantial performance gain (48.4% vs. 62.4%) over a frozen baseline, proving that the proposed phase-steering mechanism actively optimizes physical parameters under strict energy constraints. These results establish an existence proof that ultra-low-power, passive optical hardware can support high-level linguistic intelligence without sacrificing representational capacity.","authors":["Alper Yıldırım","İbrahim Yücedağ"],"pdf_url":"","comment":"Major Revision. Title changed to reflect the new theoretical framework. Complete narrative shift from \"Optimization Efficiency\" to \"Iso-Energetic Phase Coding\" and \"Optical Hardware Compatibility\". Replaced ISMR diagnostics with Holographic Optical Learning simulations and mechanistic \"Dual-Regime\" phase analysis. Comparison with spectral baselines (FNet) added"},{"id":"http://arxiv.org/abs/2509.01544v3","updated":"2026-01-05T17:24:02Z","published":"2025-09-01T15:18:46Z","title":"Causal Consistency Regularization: Training Verifiably Sensitive Reasoning in Large Language Models","summary":"Large language models can produce correct answers while relying on flawed reasoning traces, partly because common training objectives reward final-answer correctness rather than faithful intermediate reasoning. This undermines trustworthiness in high-stakes settings. We propose Counterfactual Sensitivity Regularization (CSR), a training paradigm that improves reasoning faithfulness by enforcing causal consistency between reasoning steps and outcomes. CSR automatically applies operator-level interventions to reasoning traces, such as swapping \"+\" with \"-\", to generate minimally perturbed counterfactual rationales, and penalizes the model when these logically invalid traces still lead to the original answer. Our implementation is efficient, adding about 9 percent training overhead via a warm-start curriculum and token-subset optimization.\n  We evaluate faithfulness using Counterfactual Outcome Sensitivity (COS), which measures how appropriately answers change under logical perturbations. Across arithmetic (GSM8K), logical deduction (ProofWriter), multi-hop question answering (HotpotQA), and code generation (MBPP), CSR yields improved accuracy versus faithfulness trade-offs, establishing a new Pareto frontier. CSR improves faithfulness over standard fine-tuning and process supervision by up to 70 percentage points, and transfers across model families with 94.2 to 96.7 percent success in structured domains. CSR also complements inference-time methods such as self-consistency. Overall, CSR offers a practical route to more reliable reasoning in structured domains, including mathematics, formal logic, and code, where operators are well-defined and verifiable, covering an estimated 40 to 60 percent of high-stakes reasoning deployments.","authors":["Sanjeda Akter","Ibne Farabi Shihab","Anuj Sharma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02285v1","updated":"2026-01-05T17:15:26Z","published":"2026-01-05T17:15:26Z","title":"pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs","summary":"PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).","authors":["Tobias Schimanski","Imene Kolli","Jingwei Ni","Yu Fan","Ario Saeid Vaghefi","Elliott Ash","Markus Leippold"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02273v1","updated":"2026-01-05T17:03:45Z","published":"2026-01-05T17:03:45Z","title":"TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation","summary":"Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \\textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \\textbf{5.2\\%} of model parameters ($\\sim$4.9M). On the challenging CHASE\\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git","authors":["Salim Khazem"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24880v2","updated":"2026-01-05T16:51:18Z","published":"2025-12-31T14:16:26Z","title":"mHC: Manifold-Constrained Hyper-Connections","summary":"Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifying connectivity patterns. While yielding substantial performance gains, this diversification fundamentally compromises the identity mapping property intrinsic to the residual connection, which causes severe training instability and restricted scalability, and additionally incurs notable memory access overhead. To address these challenges, we propose Manifold-Constrained Hyper-Connections (mHC), a general framework that projects the residual connection space of HC onto a specific manifold to restore the identity mapping property, while incorporating rigorous infrastructure optimization to ensure efficiency. Empirical experiments demonstrate that mHC is effective for training at scale, offering tangible performance improvements and superior scalability. We anticipate that mHC, as a flexible and practical extension of HC, will contribute to a deeper understanding of topological architecture design and suggest promising directions for the evolution of foundational models.","authors":["Zhenda Xie","Yixuan Wei","Huanqi Cao","Chenggang Zhao","Chengqi Deng","Jiashi Li","Damai Dai","Huazuo Gao","Jiang Chang","Kuai Yu","Liang Zhao","Shangyan Zhou","Zhean Xu","Zhengyan Zhang","Wangding Zeng","Shengding Hu","Yuqing Wang","Jingyang Yuan","Lean Wang","Wenfeng Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02246v1","updated":"2026-01-05T16:26:32Z","published":"2026-01-05T16:26:32Z","title":"A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets","summary":"Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.","authors":["Annoor Sharara Akhand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02242v1","updated":"2026-01-05T16:17:20Z","published":"2026-01-05T16:17:20Z","title":"VIBE: Visual Instruction Based Editor","summary":"Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.","authors":["Grigorii Alekseenko","Aleksandr Gordeev","Irina Tolstykh","Bulat Suleimanov","Vladimir Dokholyan","Georgii Fedorov","Sergey Yakubson","Aleksandra Tsybina","Mikhail Chernyshov","Maksim Kuprashevich"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20629v3","updated":"2026-01-05T16:14:39Z","published":"2025-11-28T23:36:45Z","title":"Learning Evolving Latent Strategies for Multi-Agent Language Systems without Model Fine-Tuning","summary":"This study proposes a multi-agent language framework that enables continual strategy evolution without fine-tuning the language model's parameters. The core idea is to liberate the latent vectors of abstract concepts from traditional static semantic representations, allowing them to be continuously updated through environmental interaction and reinforcement feedback. We construct a dual-loop architecture: the behavior loop adjusts action preferences based on environmental rewards, while the language loop updates the external latent vectors by reflecting on the semantic embeddings of generated text.\n  Together, these mechanisms allow agents to develop stable and disentangled strategic styles over long-horizon multi-round interactions. Experiments show that agents' latent spaces exhibit clear convergence trajectories under reflection-driven updates, along with structured shifts at critical moments. Moreover, the system demonstrates an emergent ability to implicitly infer and continually adapt to emotional agents, even without shared rewards. These results indicate that, without modifying model parameters, an external latent space can provide language agents with a low-cost, scalable, and interpretable form of abstract strategic representation.","authors":["Wenlong Tang"],"pdf_url":"","comment":"17 pages, 5 figures. Code available at https://github.com/wltang-dev/Latent-Strategy-RL-Agent"},{"id":"http://arxiv.org/abs/2507.01752v3","updated":"2026-01-05T16:10:09Z","published":"2025-07-02T14:29:30Z","title":"Tuning without Peeking: Provable Generalization Bounds and Robust LLM Post-Training","summary":"Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, exposing gradients during training can leak sensitive information about the underlying data, raising privacy and security concerns such as susceptibility to data poisoning attacks. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide non-vacuous generalization bounds and strong theoretical guarantees for privacy, robustness to data poisoning attacks, and extraction attacks. In experiments with LLMs, we demonstrate empirically that black-box optimization methods, despite the scalability and computational challenges inherent to black-box approaches, are able to learn, showing how a few iterations of BBoxER improve performance, generalize well on a benchmark of reasoning datasets, and are robust to membership inference attacks. This positions BBoxER as an attractive add-on on top of gradient-based optimization, offering suitability for deployment in restricted or privacy-sensitive environments while also providing non-vacuous generalization guarantees.","authors":["Ismail Labiad","Mathurin Videau","Matthieu Kowalski","Marc Schoenauer","Alessandro Leite","Julia Kempe","Olivier Teytaud"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.15231v2","updated":"2026-01-05T15:48:10Z","published":"2025-12-17T09:31:57Z","title":"CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications","summary":"The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--across diverse RS applications. To address this gap, this paper introduces CangLing-KnowFlow, a unified intelligent agent framework that integrates a Procedural Knowledge Base (PKB), Dynamic Workflow Adjustment, and an Evolutionary Memory Module. The PKB, comprising 1,008 expert-validated workflow cases across 162 practical RS tasks, guides planning and substantially reduces hallucinations common in general-purpose agents. During runtime failures, the Dynamic Workflow Adjustment autonomously diagnoses and replans recovery strategies, while the Evolutionary Memory Module continuously learns from these events, iteratively enhancing the agent's knowledge and performance. This synergy enables CangLing-KnowFlow to adapt, learn, and operate reliably across diverse, complex tasks. We evaluated CangLing-KnowFlow on the KnowFlow-Bench, a novel benchmark of 324 workflows inspired by real-world applications, testing its performance across 13 top Large Language Model (LLM) backbones, from open-source to commercial. Across all complex tasks, CangLing-KnowFlow surpassed the Reflexion baseline by at least 4% in Task Success Rate. As the first most comprehensive validation along this emerging field, this research demonstrates the great potential of CangLing-KnowFlow as a robust, efficient, and scalable automated solution for complex EO challenges by leveraging expert knowledge (Knowledge) into adaptive and verifiable procedures (Flow).","authors":["Zhengchao Chen","Haoran Wang","Jing Yao","Pedram Ghamisi","Jun Zhou","Peter M. Atkinson","Bing Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20182v2","updated":"2026-01-05T15:43:00Z","published":"2025-12-23T09:20:32Z","title":"FaithLens: Detecting and Explaining Faithfulness Hallucination","summary":"Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.","authors":["Shuzheng Si","Qingyi Wang","Haozhe Zhao","Yuzhuo Bai","Guanqiao Chen","Kangyang Luo","Gang Chen","Fanchao Qi","Minjia Zhang","Baobao Chang","Maosong Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02215v1","updated":"2026-01-05T15:37:08Z","published":"2026-01-05T15:37:08Z","title":"LLM-Empowered Functional Safety and Security by Design in Automotive Systems","summary":"This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.","authors":["Nenad Petrovic","Vahid Zolfaghari","Fengjunjie Pan","Alois Knoll"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02206v1","updated":"2026-01-05T15:31:07Z","published":"2026-01-05T15:31:07Z","title":"Seeing the Unseen: Zooming in the Dark with Event Cameras","summary":"This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.","authors":["Dachun Kai","Zeyu Xiao","Huyue Zhu","Jiaxiao Wang","Yueyi Zhang","Xiaoyan Sun"],"pdf_url":"","comment":"Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2601.02204v1","updated":"2026-01-05T15:27:04Z","published":"2026-01-05T15:27:04Z","title":"NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation","summary":"We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.","authors":["Huichao Zhang","Liao Qu","Yiheng Liu","Hang Chen","Yangyang Song","Yongsheng Dong","Shikun Sun","Xian Li","Xu Wang","Yi Jiang","Hu Ye","Bo Chen","Yiming Gao","Peng Liu","Akide Liu","Zhipeng Yang","Qili Deng","Linjie Xing","Jiyang Liu","Zhao Wang","Yang Zhou","Mingcong Liu","Yi Zhang","Qian He","Xiwei Hu","Zhongqi Qi","Jie Shao","Zhiye Fu","Shuai Wang","Fangmin Chen","Xuezhi Chai","Zhihua Wu","Yitong Wang","Zehuan Yuan","Daniel K. Du","Xinglong Wu"],"pdf_url":"","comment":"Project page: https://github.com/ByteVisionLab/NextFlow"},{"id":"http://arxiv.org/abs/2511.08873v2","updated":"2026-01-05T15:26:03Z","published":"2025-11-12T01:27:02Z","title":"UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models","summary":"Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at https://github.com/Mind-Lab-ECNU/UCO.","authors":["Shouang Wei","Min Zhang","Xin Lin","Bo Jiang","Kun Kuang","Zhongxiang Dai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02200v1","updated":"2026-01-05T15:23:55Z","published":"2026-01-05T15:23:55Z","title":"Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics","summary":"We are entering a hybrid era in which human developers and AI coding agents work in the same codebases. While industry practice has long optimized code for human comprehension, it is increasingly important to ensure that LLMs with different capabilities can edit code reliably. In this study, we investigate the concept of ``AI-friendly code'' via LLM-based refactoring on a dataset of 5,000 Python files from competitive programming. We find a meaningful association between CodeHealth, a quality metric calibrated for human comprehension, and semantic preservation after AI refactoring. Our findings confirm that human-friendly code is also more compatible with AI tooling. These results suggest that organizations can use CodeHealth to guide where AI interventions are lower risk and where additional human oversight is warranted. Investing in maintainability not only helps humans; it also prepares for large-scale AI adoption.","authors":["Markus Borg","Nadim Hagatulah","Adam Tornhill","Emma Söderberg"],"pdf_url":"","comment":"Accepted for the 3rd ACM International Conference on AI Foundation Models and Software Engineering (FORGE 2026)"},{"id":"http://arxiv.org/abs/2503.22458v2","updated":"2026-01-05T15:14:04Z","published":"2025-03-28T14:08:40Z","title":"Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey","summary":"This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \\emph{what to evaluate} and another that explains \\emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.","authors":["Shengyue Guan","Jindong Wang","Jiang Bian","Bin Zhu","Jian-guang Lou","Haoyi Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.20113v3","updated":"2026-01-05T14:53:38Z","published":"2025-09-24T13:37:53Z","title":"Discovering Association Rules in High-Dimensional Small Tabular Data","summary":"Association Rule Mining (ARM) aims to discover patterns between features in datasets in the form of propositional rules, supporting both knowledge discovery and interpretable machine learning in high-stakes decision-making. However, in high-dimensional settings, rule explosion and computational overhead render popular algorithmic approaches impractical without effective search space reduction, challenges that propagate to downstream tasks. Neurosymbolic methods, such as Aerial+, have recently been proposed to address the rule explosion in ARM. While they tackle the high dimensionality of the data, they also inherit limitations of neural networks, particularly reduced performance in low-data regimes.\n  This paper makes three key contributions to association rule discovery in high-dimensional tabular data. First, we empirically show that Aerial+ scales one to two orders of magnitude better than state-of-the-art algorithmic and neurosymbolic baselines across five real-world datasets. Second, we introduce the novel problem of ARM in high-dimensional, low-data settings, such as gene expression data from the biomedicine domain with around 18k features and 50 samples. Third, we propose two fine-tuning approaches to Aerial+ using tabular foundation models. Our proposed approaches are shown to significantly improve rule quality on five real-world datasets, demonstrating their effectiveness in low-data, high-dimensional scenarios.","authors":["Erkan Karabulut","Daniel Daza","Paul Groth","Victoria Degeler"],"pdf_url":"","comment":"Published version is available at https://ceur-ws.org/Vol-4125/paper_26.pdf"},{"id":"http://arxiv.org/abs/2509.19406v5","updated":"2026-01-05T14:53:28Z","published":"2025-09-23T09:20:00Z","title":"TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding","summary":"Multivariate time series forecasting is essential in domains such as finance, transportation, climate, and energy. However, existing patch-based methods typically adopt fixed-length segmentation, overlooking the heterogeneity of local temporal dynamics and the decoding heterogeneity of forecasting. Such designs lose details in information-dense regions, introduce redundancy in stable segments, and fail to capture the distinct complexities of short-term and long-term horizons. We propose TimeMosaic, a forecasting framework that aims to address temporal heterogeneity. TimeMosaic employs adaptive patch embedding to dynamically adjust granularity according to local information density, balancing motif reuse with structural clarity while preserving temporal continuity. In addition, it introduces segment-wise decoding that treats each prediction horizon as a related subtask and adapts to horizon-specific difficulty and information requirements, rather than applying a single uniform decoder. Extensive evaluations on benchmark datasets demonstrate that TimeMosaic delivers consistent improvements over existing methods, and our model trained on the large-scale corpus with 321 billion observations achieves performance competitive with state-of-the-art TSFMs.","authors":["Kuiye Ding","Fanda Fan","Chunyi Hou","Zheya Wang","Lei Wang","Zhengxin Yang","Jianfeng Zhan"],"pdf_url":"","comment":"This paper has been accepted by AAAI"},{"id":"http://arxiv.org/abs/2601.02170v1","updated":"2026-01-05T14:47:41Z","published":"2026-01-05T14:47:41Z","title":"Streaming Hallucination Detection in Long Chain-of-Thought Reasoning","summary":"Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.","authors":["Haolang Lu","Minghui Pan","Ripeng Li","Guoshun Nan","Jialin Zhuang","Zijie Zhao","Zhongxiang Sun","Kun Wang","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02163v1","updated":"2026-01-05T14:39:43Z","published":"2026-01-05T14:39:43Z","title":"EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning","summary":"Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.","authors":["Chuanrui Hu","Xingze Gao","Zuyi Zhou","Dannong Xu","Yi Bai","Xintong Li","Hui Zhang","Tong Li","Chong Zhang","Lidong Bing","Yafeng Deng"],"pdf_url":"","comment":"16 pages, 6 figures, 12 tables. Code available at https://github.com/EverMind-AI/EverMemOS"},{"id":"http://arxiv.org/abs/2601.02158v1","updated":"2026-01-05T14:36:02Z","published":"2026-01-05T14:36:02Z","title":"FormationEval, an open multiple-choice benchmark for petroleum geoscience","summary":"This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\\% accuracy, with Gemini 3 Pro Preview reaching 99.8\\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.","authors":["Almaz Ermilov"],"pdf_url":"","comment":"24 pages, 8 figures, 10 tables; benchmark and code at https://github.com/AlmazErmilov/FormationEval-an-Open-Benchmark-for-Oil-Gas-Geoscience-MCQ-Evaluation"},{"id":"http://arxiv.org/abs/2512.24470v2","updated":"2026-01-05T14:30:28Z","published":"2025-12-30T21:20:41Z","title":"Foundation models on the bridge: Semantic hazard detection and safety maneuvers for maritime autonomy with vision-language models","summary":"The draft IMO MASS Code requires autonomous and remotely supervised maritime vessels to detect departures from their operational design domain, enter a predefined fallback that notifies the operator, permit immediate human override, and avoid changing the voyage plan without approval. Meeting these obligations in the alert-to-takeover gap calls for a short-horizon, human-overridable fallback maneuver. Classical maritime autonomy stacks struggle when the correct action depends on meaning (e.g., diver-down flag means people in the water, fire close by means hazard). We argue (i) that vision-language models (VLMs) provide semantic awareness for such out-of-distribution situations, and (ii) that a fast-slow anomaly pipeline with a short-horizon, human-overridable fallback maneuver makes this practical in the handover window. We introduce Semantic Lookout, a camera-only, candidate-constrained VLM fallback maneuver selector that selects one cautious action (or station-keeping) from water-valid, world-anchored trajectories under continuous human authority. On 40 harbor scenes we measure per-call scene understanding and latency, alignment with human consensus (model majority-of-three voting), short-horizon risk-relief on fire hazard scenes, and an on-water alert->fallback maneuver->operator handover. Sub-10 s models retain most of the awareness of slower state-of-the-art models. The fallback maneuver selector outperforms geometry-only baselines and increases standoff distance on fire scenes. A field run verifies end-to-end operation. These results support VLMs as semantic fallback maneuver selectors compatible with the draft IMO MASS Code, within practical latency budgets, and motivate future work on domain-adapted, hybrid autonomy that pairs foundation-model semantics with multi-sensor bird's-eye-view perception and short-horizon replanning. Website: kimachristensen.github.io/bridge_policy","authors":["Kim Alexander Christensen","Andreas Gudahl Tufte","Alexey Gusev","Rohan Sinha","Milan Ganai","Ole Andreas Alsos","Marco Pavone","Martin Steinert"],"pdf_url":"","comment":"17 pages without bibliography or appendix. The main paper has 16 figures. Paper webpage can be found at https://kimachristensen.github.io/bridge_policy/"},{"id":"http://arxiv.org/abs/2601.02151v1","updated":"2026-01-05T14:28:17Z","published":"2026-01-05T14:28:17Z","title":"Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting","summary":"Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as \"Confident Conflicts\" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.","authors":["Muxi Diao","Lele Yang","Wuxuan Gong","Yutong Zhang","Zhonghao Yan","Yufei Han","Kongming Liang","Weiran Xu","Zhanyu Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02149v1","updated":"2026-01-05T14:25:49Z","published":"2026-01-05T14:25:49Z","title":"AI-enhanced tuning of quantum dot Hamiltonians toward Majorana modes","summary":"We propose a neural network-based model capable of learning the broad landscape of working regimes in quantum dot simulators, and using this knowledge to autotune these devices - based on transport measurements - toward obtaining Majorana modes in the structure. The model is trained in an unsupervised manner on synthetic data in the form of conductance maps, using a physics-informed loss that incorporates key properties of Majorana zero modes. We show that, with appropriate training, a deep vision-transformer network can efficiently memorize relation between Hamiltonian parameters and structures on conductance maps and use it to propose parameters update for a quantum dot chain that drive the system toward topological phase. Starting from a broad range of initial detunings in parameter space, a single update step is sufficient to generate nontrivial zero modes. Moreover, by enabling an iterative tuning procedure - where the system acquires updated conductance maps at each step - we demonstrate that the method can address a much larger region of the parameter space.","authors":["Mateusz Krawczyk","Jarosław Pawłowski"],"pdf_url":"","comment":"main file: 8 pages, 6 figures; supplementary: 3 pages, 2 figures"},{"id":"http://arxiv.org/abs/2601.02147v1","updated":"2026-01-05T14:22:20Z","published":"2026-01-05T14:22:20Z","title":"BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models","summary":"Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.","authors":["Sunny Gupta","Shounak Das","Amit Sethi"],"pdf_url":"","comment":"Accepted at the AAAI 2026 Workshop AIR-FM, Assessing and Improving Reliability of Foundation Models in the Real World"},{"id":"http://arxiv.org/abs/2601.02144v1","updated":"2026-01-05T14:16:11Z","published":"2026-01-05T14:16:11Z","title":"Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts","summary":"Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric \"router\" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.","authors":["Boxuan Lyu","Soichiro Murakami","Hidetaka Kamigaito","Peinan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.11320v2","updated":"2026-01-05T14:10:45Z","published":"2025-04-15T16:00:21Z","title":"Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints","summary":"Large Language Models (LLMs) power many modern applications, but their inference procedure poses unique scheduling challenges: the Key-Value (KV) cache grows dynamically during response generation, and memory overflow triggers eviction that can cascade into system-wide failures. Even when memory capacity exceeds the theoretical requirement, conventional scheduling algorithms fail because they do not account for this dynamic memory growth -- a system that should be stable can become unstable under poor scheduling.\n  This paper formulates LLM inference optimization as a multi-stage online scheduling problem. We develop a fluid dynamics approximation to establish a tractable benchmark and derive the Waiting for Accumulated Inference Threshold (WAIT) algorithm. WAIT uses threshold-based batching to prevent eviction by keeping the system near load balance, achieving near-optimal throughput when output lengths are known.\n  For practical settings where output lengths are unknown at arrival, we introduce Nested WAIT. Rather than predicting output lengths, Nested WAIT classifies prompts on-the-fly: short prompts complete early and exit, while longer prompts naturally advance to later segments. A safety buffer provides high-probability protection against memory overflow with only logarithmic overhead.\n  Theoretical analysis establishes near-optimal performance in the asymptotic regime. Experiments on Llama-7B with an A100 GPU demonstrate that our approach achieves superior throughput and reduced latency compared to vLLM and Sarathi. This work applies operations research principles to establish a theoretical framework for LLM deployment under memory constraints.","authors":["Ruicheng Ao","Gan Luo","David Simchi-Levi","Xinshang Wang"],"pdf_url":"","comment":"49 pages, 18 figures"},{"id":"http://arxiv.org/abs/2510.24793v2","updated":"2026-01-05T14:08:35Z","published":"2025-10-27T13:40:26Z","title":"SwiftEmbed: Ultra-Fast Text Embeddings via Static Token Lookup for Real-Time Applications","summary":"We present a static token lookup methodology for text embedding generation that achieves 1.12 ms p50 latency for single text embeddings while maintaining 60.6 MTEB average score across 8 representative tasks, corresponding to 89% of contextual model quality. The Rust implementation delivers 50,000 requests per second throughput through static embedding lookup, optimized mean pooling, and zero-copy IEEE754 binary serialization. Evaluation demonstrates exceptional duplicate detection performance (90.1% AP), strong semantic similarity (76.1% Spearman correlation), and domain-specific performance ranging from 75% to 131% of baseline across specialized domains. The system enables real-time embedding applications where sub-5ms latency is critica","authors":["Edouard Lansiaux","Antoine Simonet","Eric Wiel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.14704v2","updated":"2026-01-05T13:57:38Z","published":"2025-09-18T07:50:04Z","title":"Japanese Children's Riddles as a Benchmark for Machine Insight and Metacognition","summary":"Benchmark saturation and contamination have obscured genuine advances in reasoning for large language models (LLMs). We introduce NazoNazo Benchmark, a low-cost, renewable test built from Japanese children's riddles that demand insight-based reasoning, or representational shifts rather than knowledge recall. We evaluate 38 frontier LLMs (2023-2025) on 201 riddles and a 120-item human-comparison subset, finding that non-reasoning models average 7.6%, reasoning models 17.6%, and humans ~53% accuracy. Importantly, thought-log analysis reveals that reasoning in Japanese did not necessarily improve accuracy, indicating that language understanding alone is insufficient for insight reasoning. Notably, models sometimes generated correct candidates but failed to endorse them, suggesting weak metacognitive control rather than a lack of knowledge. This \"verification failure\" indicates that CoT outputs can reflect genuine intermediate reasoning states rather than post-hoc rationalizations. By exposing this metacognitive bottleneck - models' inability to recognize when they are right - the benchmark provides a scalable, cross-linguistic testbed for studying machine insight, confidence calibration, and self-evaluation. NazoNazo Benchmark thus offers not only a fresh challenge to current LLMs but also a concrete target for developing AI metacognitive psychology and enhancing machine Aha! capability.","authors":["Masaharu Mizumoto","Dat Nguyen","Zhiheng Han","Jiyuan Fang","Heyuan Guan","Xingfu Li","Naoya Shiraishi","Yo Nakawake","Le Minh Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02126v1","updated":"2026-01-05T13:57:02Z","published":"2026-01-05T13:57:02Z","title":"Remote Sensing Change Detection via Weak Temporal Supervision","summary":"Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.","authors":["Xavier Bou","Elliot Vincent","Gabriele Facciolo","Rafael Grompone von Gioi","Jean-Michel Morel","Thibaud Ehret"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02125v1","updated":"2026-01-05T13:56:36Z","published":"2026-01-05T13:56:36Z","title":"SingingBot: An Avatar-Driven System for Robotic Face Singing Performance","summary":"Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.","authors":["Zhuoxiong Xu","Xuanchen Li","Yuhao Cheng","Fei Xu","Yichao Yan","Xiaokang Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02123v1","updated":"2026-01-05T13:54:38Z","published":"2026-01-05T13:54:38Z","title":"DeCode: Decoupling Content and Delivery for Medical QA","summary":"Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\\%$ to $49.8\\%$, corresponding to a $75\\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.","authors":["Po-Jen Ko","Chen-Han Tsai","Yu-Shao Peng"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2601.02121v1","updated":"2026-01-05T13:53:44Z","published":"2026-01-05T13:53:44Z","title":"Inferring Network Evolutionary History via Structure-State Coupled Learning","summary":"Inferring a network's evolutionary history from a single final snapshot with limited temporal annotations is fundamental yet challenging. Existing approaches predominantly rely on topology alone, which often provides insufficient and noisy cues. This paper leverages network steady-state dynamics -- converged node states under a given dynamical process -- as an additional and widely accessible observation for network evolution history inference. We propose CS$^2$, which explicitly models structure-state coupling to capture how topology modulates steady states and how the two signals jointly improve edge discrimination for formation-order recovery. Experiments on six real temporal networks, evaluated under multiple dynamical processes, show that CS$^2$ consistently outperforms strong baselines, improving pairwise edge precedence accuracy by 4.0% on average and global ordering consistency (Spearman-$ρ$) by 7.7% on average. CS$^2$ also more faithfully recovers macroscopic evolution trajectories such as clustering formation, degree heterogeneity, and hub growth. Moreover, a steady-state-only variant remains competitive when reliable topology is limited, highlighting steady states as an independent signal for evolution inference.","authors":["En Xu","Shihe Zhou","Huandong Wang","Jingtao Ding","Yong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22792v2","updated":"2026-01-05T13:46:47Z","published":"2025-12-28T05:33:05Z","title":"A Universal and Robust Framework for Multiple Gas Recognition Based-on Spherical Normalization-Coupled Mahalanobis Algorithm","summary":"Electronic nose (E-nose) systems face two interconnected challenges in open-set gas recognition: feature distribution shift caused by signal drift and decision boundary failure induced by unknown gas interference. Existing methods predominantly rely on Euclidean distance or conventional classifiers, failing to account for anisotropic feature distributions and dynamic signal intensity variations. To address these issues, this study proposes the Spherical Normalization coupled Mahalanobis (SNM) module, a universal post-processing module for open-set gas recognition. First, it achieves geometric decoupling through cascaded batch and L2 normalization, projecting features onto a unit hypersphere to eliminate signal intensity fluctuations. Second, it utilizes Mahalanobis distance to construct adaptive ellipsoidal decision boundaries that conform to the anisotropic feature geometry. The architecture-agnostic SNM-Module seamlessly integrates with mainstream backbones including Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Transformer. Experiments on the public Vergara dataset demonstrate that the Transformer+SNM configuration achieves near-theoretical-limit performance in discriminating among multiple target gases, with an AUROC of 0.9977 and an unknown gas detection rate of 99.57% at 5% false positive rate, significantly outperforming state-of-the-art methods with a 3.0% AUROC improvement and 91.0% standard deviation reduction compared to Class Anchor Clustering (CAC). The module maintains exceptional robustness across five sensor positions, with standard deviations below 0.0028. This work effectively addresses the critical challenge of simultaneously achieving high accuracy and high stability in open-set gas recognition, providing solid support for industrial E-nose deployment.","authors":["Shuai Chen","Yang Song","Chen Wang","Ziran Wang"],"pdf_url":"","comment":"27 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2508.02115v3","updated":"2026-01-05T13:45:47Z","published":"2025-08-04T06:51:33Z","title":"Coward: Collision-based Watermark for Proactive Federated Backdoor Detection","summary":"Backdoor detection is currently the mainstream defense against backdoor attacks in federated learning (FL), where a small number of malicious clients can upload poisoned updates to compromise the federated global model. Existing backdoor detection techniques fall into two categories, passive and proactive, depending on whether the server proactively intervenes in the training process. However, both of them have inherent limitations in practice: passive detection methods are disrupted by common non-i.i.d. data distributions and random participation of FL clients, whereas current proactive detection methods are misled by an inevitable out-of-distribution (OOD) bias because they rely on backdoor coexistence effects. To address these issues, we introduce a novel proactive detection method dubbed Coward, inspired by our discovery of multi-backdoor collision effects, in which consecutively planted, distinct backdoors significantly suppress earlier ones. Correspondingly, we modify the federated global model by injecting a carefully designed backdoor-collided watermark, implemented via regulated dual-mapping learning on OOD data. This design not only enables an inverted detection paradigm compared to existing proactive methods, thereby naturally counteracting the adverse impact of OOD prediction bias, but also introduces a low-disruptive training intervention that inherently limits the strength of OOD bias, leading to significantly fewer misjudgments. Extensive experiments on benchmark datasets show that Coward achieves state-of-the-art detection performance, effectively alleviates OOD prediction bias, and remains robust against potential adaptive attacks. The code for our method is available at https://github.com/still2009/cowardFL.","authors":["Wenjie Li","Siying Gu","Yiming Li","Kangjie Chen","Zhili Chen","Tianwei Zhang","Shu-Tao Xia","Dacheng Tao"],"pdf_url":"","comment":"13-page main body and 4-page appendix. Currently under review"},{"id":"http://arxiv.org/abs/2512.23260v2","updated":"2026-01-05T13:39:39Z","published":"2025-12-29T07:39:49Z","title":"Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation","summary":"Safety alignment -- training large language models (LLMs) to refuse harmful requests while remaining helpful -- is critical for responsible deployment. Prior work established that safety behaviors are governed by low-rank structures, suggesting parameter-efficient fine-tuning (PEFT) should be well-suited for alignment. However, Low-Rank Adaptation (LoRA) consistently underperforms full fine-tuning and reinforcement learning on safety benchmarks. We attribute this gap to semantic entanglement: safety-relevant directions are intertwined with unrelated concepts due to polysemanticity, impeding implicit subspace identification. To address this, we propose SAILS (Safety Alignment via Interpretable Low-rank Subspace), which leverages Sparse Autoencoders (SAEs) to disentangle representations into monosemantic features, constructs an interpretable safety subspace from SAE decoder directions, and uses it to initialize LoRA adapters. Theoretically, we prove that SAE-based identification achieves arbitrarily small recovery error under monosemanticity assumptions, while direct identification suffers an irreducible error floor. Empirically, SAILS achieves up to 99.6% safety rate on Gemma-2-9B -- exceeding full fine-tuning by 7.4 points and matching RLHF-based models -- while updating only 0.19% of parameters and providing interpretability.","authors":["Dianyun Wang","Qingsen Ma","Yuhu Shang","Zhifeng Lu","Zhenbo Xu","Lechen Ning","Huijia Wu","Zhaofeng He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.05623v2","updated":"2026-01-05T13:38:13Z","published":"2025-06-05T22:53:12Z","title":"Deployability-Centric Infrastructure-as-Code Generation: Fail, Learn, Refine, and Succeed through LLM-Empowered DevOps Simulation","summary":"Infrastructure-as-Code (IaC) generation holds significant promise for automating cloud infrastructure provisioning. Recent advances in Large Language Models (LLMs) present a promising opportunity to democratize IaC development by generating deployable infrastructure templates from natural language descriptions. However, current evaluation focuses on syntactic correctness while ignoring deployability, the critical measure of the utility of IaC configuration files. Six state-of-the-art LLMs performed poorly on deployability, achieving only 20.8$\\sim$30.2% deployment success rate on the first attempt. In this paper, we construct DPIaC-Eval, the first deployability-centric IaC template benchmark consisting of 153 real-world scenarios cross 58 unique services. Also, we propose an LLM-based deployability-centric framework, dubbed IaCGen, that uses iterative feedback mechanism encompassing format verification, syntax checking, and live deployment stages, thereby closely mirroring the real DevOps workflows. Results show that IaCGen can make 54.6$\\sim$91.6% generated IaC templates from all evaluated models deployable in the first 10 iterations. Additionally, human-in-the-loop feedback that provide direct guidance for the deployability errors, can further boost the performance to over 90% passItr@25 on all evaluated LLMs. Furthermore, we explore the trustworthiness of the generated IaC templates on user intent alignment and security compliance. The poor performance (25.2% user requirement coverage and 8.4% security compliance rate) indicates a critical need for continued research in this domain.","authors":["Tianyi Zhang","Shidong Pan","Zejun Zhang","Zhenchang Xing","Xiaoyu Sun"],"pdf_url":"","comment":"Accepted by FSE 2026"},{"id":"http://arxiv.org/abs/2405.18770v6","updated":"2026-01-05T13:34:30Z","published":"2024-05-29T05:20:02Z","title":"Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships","summary":"Pre-trained vision-language (VL) models are highly vulnerable to adversarial attacks. However, existing defense methods primarily focus on image classification, overlooking two key aspects of VL tasks: multimodal attacks, where both image and text can be perturbed, and the one-to-many relationship of images and texts, where a single image can correspond to multiple textual descriptions and vice versa (1:N and N:1). This work is the first to explore defense strategies against multimodal attacks in VL tasks, whereas prior VL defense methods focus on vision robustness. We propose multimodal adversarial training (MAT), which incorporates adversarial perturbations in both image and text modalities during training, significantly outperforming existing unimodal defenses. Furthermore, we discover that MAT is limited by deterministic one-to-one (1:1) image-text pairs in VL training data. To address this, we conduct a comprehensive study on leveraging one-to-many relationships to enhance robustness, investigating diverse augmentation techniques. Our analysis shows that, for a more effective defense, augmented image-text pairs should be well-aligned, diverse, yet avoid distribution shift -- conditions overlooked by prior research. This work pioneers defense strategies against multimodal attacks, providing insights for building robust VLMs from both optimization and data perspectives. Our code is publicly available at https://github.com/CyberAgentAILab/multimodal-adversarial-training.","authors":["Futa Waseda","Antonio Tejero-de-Pablos","Isao Echizen"],"pdf_url":"","comment":"WACV 2026 Accepted. Code available at https://github.com/CyberAgentAILab/multimodal-adversarial-training"},{"id":"http://arxiv.org/abs/2601.02105v1","updated":"2026-01-05T13:33:09Z","published":"2026-01-05T13:33:09Z","title":"LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training","summary":"Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.\n  We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.\n  Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.\n  We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.","authors":["Hyunjun Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06779v2","updated":"2026-01-05T13:31:19Z","published":"2025-11-10T07:07:37Z","title":"Pedagogical Reflections on the Holistic Cognitive Development (HCD) Framework and AI-Augmented Learning in Creative Computing","summary":"This paper presents an expanded account of the Holistic Cognitive Development (HCD) framework for reflective and creative learning in computing education. The HCD framework integrates design thinking, experiential learning, and reflective practice into a unified constructivist pedagogy emphasizing autonomy, ownership, and scaffolding. It is applied across courses in game design (CS3247, CS4350), virtual reality (CS4240), and extended reality systems, where students engage in iterative cycles of thinking, creating, criticizing, and reflecting. The paper also examines how AI-augmented systems such as iReflect, ReflexAI, and Knowledge Graph-enhanced LLM feedback tools operationalize the HCD framework through scalable, personalized feedback. Empirical findings demonstrate improved reflective depth, feedback quality, and learner autonomy. The work advocates a balance of supportive autonomy in supervision, where students practice self-directed inquiry while guided through structured reflection and feedback.","authors":["Anand Bhojan"],"pdf_url":"","comment":"Short Abstract"},{"id":"http://arxiv.org/abs/2510.23506v4","updated":"2026-01-05T13:24:37Z","published":"2025-10-27T16:40:17Z","title":"Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale Verifier","summary":"The recent advancement of Multimodal Large Language Models (MLLMs) is transforming human-computer interaction (HCI) from surface-level exchanges into more nuanced and emotionally intelligent communication. To realize this shift, emotion understanding becomes essential allowing systems to capture subtle cues underlying user intent. Furthermore, providing faithful explanations for predicted emotions is crucial to ensure interpretability and build user trust. However, current MLLM-based methods often generate emotion explanations that diverge from the target labels and sometimes even contradict their own predicted emotions. This inconsistency poses a critical risk for misunderstanding and erodes reliability in interactive settings. To address this, we propose a novel approach: the Emotional Rationale Verifier (ERV) and an Explanation Reward. Our method guides the model to produce reasoning that is explicitly consistent with the target emotion during multimodal emotion recognition without modifying the model architecture or requiring additional paired video-description annotations. Our method significantly improves faithful explanation-prediction consistency and explanation emotion accuracy on the MAFW and DFEW datasets. Through extensive experiments and human evaluations, we show that our approach not only enhances alignment between explanation and prediction but also empowers MLLMs to deliver emotionally coherent, trustworthy interactions, marking a key step toward truly human-like HCI systems.","authors":["Hyeongseop Rha","Jeong Hun Yeo","Yeonju Kim","Yong Man Ro"],"pdf_url":"","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2512.20957v3","updated":"2026-01-05T13:23:35Z","published":"2025-12-24T05:27:53Z","title":"One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents","summary":"Locating the files and functions requiring modification in large open-source software (OSS) repositories is challenging due to their scale and structural complexity. Existing large language model (LLM)-based methods typically treat this as a repository-level retrieval task and rely on multiple auxiliary tools, which overlook code execution logic and complicate model control. We propose RepoNavigator, an LLM agent equipped with a single execution-aware tool-jumping to the definition of an invoked symbol. This unified design reflects the actual flow of code execution while simplifying tool manipulation. RepoNavigator is trained end-to-end via Reinforcement Learning (RL) directly from a pretrained model, without any closed-source distillation. Experiments demonstrate that RL-trained RepoNavigator achieves state-of-the-art performance, with the 7B model outperforming 14B baselines, the 14B model surpassing 32B competitors, and even the 32B model exceeding closed-source models such as Claude-3.7. These results confirm that integrating a single, structurally grounded tool with RL training provides an efficient and scalable solution for repository-level issue localization.","authors":["Zhaoxi Zhang","Yitong Duan","Yanzhi Zhang","Yiming Xu","Jiyan He","Yunfang Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22673v2","updated":"2026-01-05T13:19:13Z","published":"2025-12-27T18:25:14Z","title":"TravelBench: A Broader Real-World Benchmark for Multi-Turn and Tool-Using Travel Planning","summary":"Travel planning is a natural real-world task to test large language models (LLMs) planning and tool-use abilities. Although prior work has studied LLM performance on travel planning, existing settings still differ from real-world needs, mainly due to limited domain coverage, insufficient modeling of users' implicit preferences in multi-turn conversations, and a lack of clear evaluation of agents' capability boundaries. To mitigate these gaps, we propose \\textbf{TravelBench}, a benchmark for fully real-world travel planning. We collect user queries, user profile and tools from real scenarios, and construct three subtasks-Single-Turn, Multi-Turn, and Unsolvable-to evaluate agent's three core capabilities in real settings: (1) solving problems autonomously, (2) interacting with users over multiple turns to refine requirements, and (3) recognizing the limits of own abilities. To enable stable tool invocation and reproducible evaluation, we cache real tool-call results and build a sandbox environment that integrates ten travel-related tools. Agents can combine these tools to solve most practical travel planning problems, and our systematic verification demonstrates the stability of the proposed benchmark. We further evaluate multiple LLMs on TravelBench and conduct an in-depth analysis of their behaviors and performance. TravelBench provides a practical and reproducible evaluation benchmark to advance research on LLM agents for travel planning.\\footnote{Our code and data will be available after internal review.","authors":["Xiang Cheng","Yulan Hu","Xiangwen Zhang","Lu Xu","Zheng Pan","Xin Li","Yong Liu"],"pdf_url":"","comment":"In progress"},{"id":"http://arxiv.org/abs/2601.02085v1","updated":"2026-01-05T13:12:42Z","published":"2026-01-05T13:12:42Z","title":"Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots","summary":"Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.","authors":["Meili Sun","Chunjiang Zhao","Lichao Yang","Hao Liu","Shimin Hu","Ya Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22461v2","updated":"2026-01-05T13:09:54Z","published":"2025-09-26T15:12:46Z","title":"CMDAR: A Chinese Multi-scene Dynamic Audio Reasoning Benchmark with Diverse Challenges","summary":"The ability to reason from audio, including speech, environmental sounds, and music, is essential for AI agents to interact effectively in real-world scenarios. Existing benchmarks mainly focus on static or single-scene settings and English audio data and do not fully capture scenarios where multiple speakers, unfolding events, and heterogeneous audio sources interact. To address these challenges, we introduce CMDAR, a Chinese benchmark for evaluating models on complex, multi-scene, and dynamically evolving audio reasoning tasks. CMDAR comprises 3,000 carefully curated question-answer pairs linked to diverse audio clips, covering five categories of complex reasoning and spanning three question types. We benchmark 26 state-of-the-art audio language models on CMDAR and observe that they exhibit limitations in complex reasoning tasks. In CMDAR-main, Qwen2.5-Omni achieves 76.67% accuracy, whereas GPT-4o Audio reaches 68.47%. However, GPT-4o Audio substantially outperforms Qwen2.5-Omni on the more challenging multiple-choice with multiple audios and open-ended tasks. And we provide detail analysis corresponding suggestions for the future development of large audio language models.","authors":["Hui Li","Changhao Jiang","Hongyu Wang","Ming Zhang","Jiajun Sun","Zhixiong Yang","Yifei Cao","Shihan Dou","Xiaoran Fan","Baoyu Fan","Tao Ji","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"","comment":"25 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.02080v1","updated":"2026-01-05T13:09:42Z","published":"2026-01-05T13:09:42Z","title":"The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks","summary":"Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.","authors":["Yizhi Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02076v1","updated":"2026-01-05T12:57:33Z","published":"2026-01-05T12:57:33Z","title":"Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows","summary":"Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.","authors":["Yingte Shu","Yuchuan Tian","Chao Xu","Yunhe Wang","Hanting Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02071v1","updated":"2026-01-05T12:50:50Z","published":"2026-01-05T12:50:50Z","title":"FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations","summary":"Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.","authors":["Adeshola Okubena","Yusuf Ali Mohammed","Moe Elbadawi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18901v2","updated":"2026-01-05T12:45:28Z","published":"2025-12-21T22:12:54Z","title":"Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models","summary":"We present Gabliteration, a novel neural weight modification technique that advances beyond traditional abliteration methods by implementing adaptive multi-directional projections with regularized layer selection. Our approach addresses the fundamental limitation of existing methods that compromise model quality while attempting to modify specific behavioral patterns. Through dynamic layer optimization, regularized projection matrices, and adaptive scaling mechanisms, we achieve theoretically superior weight modification while minimizing quality degradation in unrelated domains. We validate our method through the gabliterated-v1 model series (0.6B to 4B parameters) available on Hugging Face, demonstrating practical applicability across multiple model scales.","authors":["Gökdeniz Gülmez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02065v1","updated":"2026-01-05T12:41:44Z","published":"2026-01-05T12:41:44Z","title":"Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory","summary":"Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings","authors":["Md. Asif Hossain","Nabil Subhan","Mantasha Rahman Mahi","Jannatul Ferdous Nabila"],"pdf_url":"","comment":"5 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2512.18384v2","updated":"2026-01-05T12:39:45Z","published":"2025-12-20T14:51:57Z","title":"AI Prior Art Search: Semantic Clusters and Evaluation Infrastructure","summary":"The key to success in automating prior art search in patent research using artificial intelligence (AI) lies in developing large datasets for machine learning (ML) and ensuring their availability. This work is dedicated to providing a comprehensive solution to the problem of creating infrastructure for research in this field, including datasets and tools for calculating search quality criteria. The paper discusses the concept of semantic clusters of patent documents that determine the state of the art in a given subject, as proposed by the authors. A definition of such semantic clusters is also provided. Prior art search is presented as the task of identifying elements within a semantic cluster of patent documents in the subject area specified by the document under consideration. A generator of user-configurable datasets for ML, based on collections of U.S. and Russian patent documents, is described. The dataset generator creates a database of links to documents in semantic clusters. Then, based on user-defined parameters, it forms a dataset of semantic clusters in JSON format for ML. A collection of publicly available patent documents was created. The collection contains 14 million semantic clusters of US patent documents and 1 million clusters of Russian patent documents. To evaluate ML outcomes, it is proposed to calculate search quality scores that account for semantic clusters of the documents being searched. To automate the evaluation process, the paper describes a utility developed by the authors for assessing the quality of prior art document search.","authors":["Boris Genin","Alexander Gorbunov","Dmitry Zolkin","Igor Nekrasov"],"pdf_url":"","comment":"16 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2601.02061v1","updated":"2026-01-05T12:35:33Z","published":"2026-01-05T12:35:33Z","title":"Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management","summary":"Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.","authors":["Faizan Ahmed","Aniket Dixit","James Brusey"],"pdf_url":"","comment":"6 pages, accepted at NeurIPS workshop 2025"},{"id":"http://arxiv.org/abs/2601.02060v1","updated":"2026-01-05T12:33:37Z","published":"2026-01-05T12:33:37Z","title":"Perish or Flourish? A Holistic Evaluation of Large Language Models for Code Generation in Functional Programming","summary":"Functional programming provides strong foundations for developing reliable and secure software systems, yet its adoption remains not widespread due to the steep learning curve. Recent advances in Large Language Models (LLMs) for code generation present new opportunities to lower these barriers. However, extensive evaluations of LLMs largely focus on imperative programming languages, and their capabilities in functional programming languages (FP) remain underexplored. To address this gap, we introduce FPEval, a holistic evaluation framework built on FPBench, a new benchmark of 721 programming tasks across three difficulty levels on three mainstream FP languages: Haskell, Ocaml and Scala. FPEval provides compehensive evaluation infrastructures with both test validations with comprehensive test suites and static analysis tools to assess both functional correctness and code style and maintainability. Using this framework, we evaluate state-of-the-art LLMs, including GPT-3.5, GPT-4o, and GPT-5, for code generation in functional programming languages and Java as an imperative baseline. Our results demonstrate that LLM performance in functional programming improves substantially with model advancement; however, error rates remain significantly higher in purely functional languages (Haskell and OCaml) than in hybrid (Scala) or imperative (Java) languages. Moreover, LLMs frequently generate non-idiomatic functional code that follows imperative patterns, raising concerns about code style and long-term maintainability. Finally, we show that LLMs can partially self-repair both correctness and quality issues when provided with static analysis feedback and hand-crafted instructions for common types of issues.","authors":["Nguyet-Anh H. Lang","Eric Lang","Thanh Le-Cong","Bach Le","Quyet-Thang Huynh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02046v1","updated":"2026-01-05T12:06:43Z","published":"2026-01-05T12:06:43Z","title":"Agentic Retoucher for Text-To-Image Generation","summary":"Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.","authors":["Shaocheng Shen","Jianfeng Liang. Chunlei Cai","Cong Geng","Huiyu Duan","Xiaoyun Zhang","Qiang Hu","Guangtao Zhai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01010v2","updated":"2026-01-05T12:06:41Z","published":"2025-08-01T18:23:38Z","title":"v-PuNNs: van der Put Neural Networks for Transparent Ultrametric Representation Learning","summary":"Conventional deep learning models embed data in Euclidean space $\\mathbb{R}^d$, a poor fit for strictly hierarchical objects such as taxa, word senses, or file systems. We introduce van der Put Neural Networks (v-PuNNs), the first architecture whose neurons are characteristic functions of p-adic balls in $\\mathbb{Z}_p$. Under our Transparent Ultrametric Representation Learning (TURL) principle every weight is itself a p-adic number, giving exact subtree semantics. A new Finite Hierarchical Approximation Theorem shows that a depth-K v-PuNN with $\\sum_{j=0}^{K-1}p^{\\,j}$ neurons universally represents any K-level tree. Because gradients vanish in this discrete space, we propose Valuation-Adaptive Perturbation Optimization (VAPO), with a fast deterministic variant (HiPaN-DS) and a moment-based one (HiPaN / Adam-VAPO). On three canonical benchmarks our CPU-only implementation sets new state-of-the-art: WordNet nouns (52,427 leaves) 99.96% leaf accuracy in 16 min; GO molecular-function 96.9% leaf / 100% root in 50 s; NCBI Mammalia Spearman $ρ= -0.96$ with true taxonomic distance. The learned metric is perfectly ultrametric (zero triangle violations), and its fractal and information-theoretic properties are analyzed. Beyond classification we derive structural invariants for quantum systems (HiPaQ) and controllable generative codes for tabular data (Tab-HiPaN). v-PuNNs therefore bridge number theory and deep learning, offering exact, interpretable, and efficient models for hierarchical data.","authors":["Gnankan Landry Regis N'guessan"],"pdf_url":"","comment":"v2: Corrected mathematical statements in Section 3.1.3 and Appendix A regarding the van der Put basis properties. Clarified distinction between hierarchical indicator family and classical Schauder basis"},{"id":"http://arxiv.org/abs/2601.02045v1","updated":"2026-01-05T12:02:57Z","published":"2026-01-05T12:02:57Z","title":"The New Compiler Stack: A Survey on the Synergy of LLMs and Compilers","summary":"This survey has provided a systematic overview of the emerging field of LLM-enabled compilation by addressing several key research questions. We first answered how LLMs are being integrated by proposing a comprehensive, multi-dimensional taxonomy that categorizes works based on their Design Philosophy (Selector, Translator, Generator), LLM Methodology, their operational Level of Code Abstraction, and the specific Task Type they address. In answering what advancements these approaches offer, we identified three primary benefits: the democratization of compiler development, the discovery of novel optimization strategies, and the broadening of the compiler's traditional scope. Finally, in addressing the field's challenges and opportunities, we highlighted the critical hurdles of ensuring correctness and achieving scalability, while identifying the development of hybrid systems as the most promising path forward. By providing these answers, this survey serves as a foundational roadmap for researchers and practitioners, charting the course for a new generation of LLM-powered, intelligent, adaptive and synergistic compilation tools.","authors":["Shuoming Zhang","Jiacheng Zhao","Qiuchu Yu","Chunwei Xia","Zheng Wang","Xiaobing Feng","Huimin Cui"],"pdf_url":"","comment":"Accepted by CCF Transactions on High Performance Computing"},{"id":"http://arxiv.org/abs/2510.24639v2","updated":"2026-01-05T12:02:02Z","published":"2025-10-28T17:06:15Z","title":"Causal Ordering for Structure Learning from Time Series","summary":"Predicting causal structure from time series data is crucial for understanding complex phenomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based methods. Traditional ordering methods inherently limit the representational capacity of the resulting model. In this work, we fix this issue by leveraging multiple valid causal orderings, instead of a single one as standard practice. We propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based causal discovery for temporal data. By integrating multiple orderings, DOTS effectively recovers the transitive closure of the underlying directed acyclic graph, mitigating spurious artifacts inherent in single-ordering approaches. We formalise the problem under standard assumptions such as stationarity and the additive noise model, and leverage score matching with diffusion processes to enable efficient Hessian estimation. Extensive experiments validate the approach. Empirical evaluations on synthetic and real-world datasets demonstrate that DOTS outperforms state-of-the-art baselines, offering a scalable and robust approach to temporal causal discovery. On synthetic benchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the CausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the best on individual datasets, DOTS attains the highest average summary-graph $F1$ while halving runtime relative to graph-optimisation methods. These results establish DOTS as a scalable and accurate solution for temporal causal discovery.","authors":["Pedro P. Sanchez","Damian Machlanski","Steven McDonagh","Sotirios A. Tsaftaris"],"pdf_url":"","comment":"32 pages. Published in Transactions on Machine Learning Research"},{"id":"http://arxiv.org/abs/2601.02043v1","updated":"2026-01-05T12:00:04Z","published":"2026-01-05T12:00:04Z","title":"Simulated Reasoning is Reasoning","summary":"Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.","authors":["Hendrik Kempt","Alon Lavie"],"pdf_url":"","comment":"21 pages"},{"id":"http://arxiv.org/abs/2407.05434v3","updated":"2026-01-05T11:55:15Z","published":"2024-07-07T16:37:06Z","title":"LTLBench: Towards Benchmarks for Evaluating Temporal Reasoning in Large Language Models","summary":"Temporal Reasoning (TR) is a critical ability for LLMs to understand and reason over temporal information and relationships between events. To study the TR ability in LLMs, prior works provide different ways for evaluating various aspects of TR ability. In this work, we propose an alternative perspective for evaluating TR ability by leveraging Linear Temporal Logic (LTL), and develop a pipeline to automatically synthesize challenges for assessing the TR ability of LLMs. Based on this pipeline, we construct a dataset, namely LTLBench, consisting of $2000$ TR challenges, and benchmark 12 LLMs across 5 different methods. Furthermore, we conduct additional experiments to investigate the impact of increasing the number of formula operators and events on both LLM performance and the complexity of TR problems. We also perform qualitative analyses of their reasoning processes and the effects of varying the number of events and formula operators, which reveal 3 main issues in their temporal reasoning processes and the unexpected performance changes observed as problem complexity increases. We expect this work to provide valuable insights into the TR ability of LLMs.","authors":["Weizhi Tang","Kwabena Nuamah","Vaishak Belle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23732v2","updated":"2026-01-05T11:54:54Z","published":"2025-12-21T05:48:57Z","title":"When in Doubt, Consult: Expert Debate for Sexism Detection via Confidence-Based Routin","summary":"Sexist content online increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals, even in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to overlook subtler, underrepresented forms of harm. Together, these limitations point to the need for a design that explicitly addresses the combined effects of (i) underrepresentation, (ii) noise, and (iii) conceptual ambiguity in both data and model predictions. To address these challenges, we propose a two-stage framework that unifies (i) targeted training procedures to adapt supervision to scarce and noisy data with (ii) selective, reasoning-based inference to handle ambiguous or borderline cases. Our training setup applies class-balanced focal loss, class-aware batching, and post-hoc threshold calibration to mitigate label imbalance and noisy supervision. At inference time, a dynamic routing mechanism classifies high-confidence cases directly and escalates uncertain instances to a novel \\textit{Collaborative Expert Judgment} (CEJ) module, which prompts multiple personas and consolidates their reasoning through a judge model. Our approach achieves state-of-the-art results across several benchmarks, with F1 gains of +4.48% and +1.30% on EDOS Tasks A and B, respectively, and a +2.79% improvement in ICM on EXIST 2025 Task 1.1.","authors":["Anwar Alajmi","Gabriele Pergola"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07404v2","updated":"2026-01-05T11:52:55Z","published":"2025-12-08T10:38:03Z","title":"On LLMs' Internal Representation of Code Correctness","summary":"Despite the effectiveness of large language models (LLMs) for code generation, they often output incorrect code. One reason is that model output probabilities are often not well-correlated with correctness, and reflect only the final output of the generation process. Inspired by findings that LLMs internally encode concepts like truthfulness, this paper explores if LLMs similarly represent code correctness. Specifically, we identify a correctness representation inside LLMs by contrasting the hidden states between pairs of correct and incorrect code for the same programming tasks. By experimenting on four LLMs, we show that exploiting this extracted correctness representation outperforms standard log-likelihood ranking, as well as verbalized model confidence. Furthermore, we explore how this internal correctness signal can be used to select higher-quality code samples, without requiring test execution. Ultimately, this work demonstrates how leveraging internal representations can enhance code generation systems and make LLMs more reliable, thus improving confidence in automatically generated code.","authors":["Francisco Ribeiro","Claudio Spiess","Prem Devanbu","Sarah Nadi"],"pdf_url":"","comment":"Accepted for ICSE'26"},{"id":"http://arxiv.org/abs/2503.24191v2","updated":"2026-01-05T11:49:07Z","published":"2025-03-31T15:08:06Z","title":"Beyond Prompts: Space-Time Decoupling Control-Plane Jailbreaks in LLM Structured Output","summary":"Content Warning: This paper may contain unsafe or harmful content generated by LLMs that may be offensive to readers. Large Language Models (LLMs) are extensively used as tooling platforms through structured output APIs to ensure syntax compliance so that robust integration with existing software, like agent systems, can be achieved. However, the feature enabling the functionality of grammar-guided structured output presents significant security vulnerabilities. In this work, we reveal a critical control-plane attack surface orthogonal to traditional data-plane vulnerabilities. We introduce Constrained Decoding Attack (CDA), a novel jailbreak class that weaponizes structured output constraints to bypass both external auditing and internal safety alignment. Unlike prior attacks focused on input prompt designs, CDA operates by embedding malicious intent in schema-level grammar rules (control-plane) while maintaining benign surface prompts (data-plane). We instantiate this with two proof-of-concept attacks: EnumAttack, which embeds malicious content in enum fields; and the more evasive DictAttack, which decouples the malicious payload across a benign prompt and a dictionary-based grammar. Our evaluation spans a broad spectrum of 13 proprietary/open-weight models. In particular, DictAttack achieves 94.3--99.5% ASR across five benchmarks on gpt-5, gemini-2.5-pro, deepseek-r1, and gpt-oss-120b. Furthermore, we demonstrate the significant challenge in defending against these threats: while basic grammar auditing mitigates EnumAttack, the more sophisticated DictAttack maintains a 75.8% ASR even against multiple state-of-the-art jailbreak guardrails. This exposes a critical \"semantic gap\" in current safety architectures and underscores the urgent need for cross-plane defenses that can bridge the data and control planes to secure the LLM generation pipeline.","authors":["Shuoming Zhang","Jiacheng Zhao","Hanyuan Dong","Ruiyuan Xu","Zhicheng Li","Yangyu Zhang","Shuaijiang Li","Yuan Wen","Chunwei Xia","Zheng Wang","Xiaobing Feng","Huimin Cui"],"pdf_url":"","comment":"15 pages, 9 figures, 8 tables, Preprint"},{"id":"http://arxiv.org/abs/2408.09881v3","updated":"2026-01-05T11:48:30Z","published":"2024-08-19T10:46:19Z","title":"Uncertainty Quantification of Surrogate Models using Conformal Prediction","summary":"Data-driven surrogate models offer quick approximations to complex numerical and experimental systems but typically lack uncertainty quantification, limiting their reliability in safety-critical applications. While Bayesian methods provide uncertainty estimates, they offer no statistical guarantees and struggle with high-dimensional spatio-temporal problems due to computational costs. We present a conformal prediction (CP) framework that provides statistically guaranteed marginal coverage for surrogate models in a model-agnostic manner with near-zero computational cost. Our approach handles high-dimensional spatio-temporal outputs by performing cell-wise calibration while preserving the tensorial structure of predictions. Through extensive empirical evaluation across diverse applications including fluid dynamics, magnetohydrodynamics, weather forecasting, and fusion diagnostics, we demonstrate that CP achieves empirical coverage with valid error bars regardless of model architecture, training regime, or output dimensionality. We evaluate three nonconformity scores (conformalised quantile regression, absolute error residual, and standard deviation) for both deterministic and probabilistic models, showing that guaranteed coverage holds even for out-of-distribution predictions where models are deployed on physics regimes different from training data. Calibration requires only seconds to minutes on standard hardware. The framework enables rigorous validation of pre-trained surrogate models for downstream applications without retraining. While CP provides marginal rather than conditional coverage and assumes exchangeability between calibration and test data, our method circumvents the curse of dimensionality inherent in traditional uncertainty quantification approaches, offering a practical tool for trustworthy deployment of machine learning in physical sciences.","authors":["Vignesh Gopakumar","Ander Gray","Joel Oskarsson","Lorenzo Zanisi","Daniel Giles","Matt J. Kusner","Stanislas Pamela","Marc Peter Deisenroth"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02031v1","updated":"2026-01-05T11:44:05Z","published":"2026-01-05T11:44:05Z","title":"Output Embedding Centering for Stable LLM Pretraining","summary":"Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.","authors":["Felix Stollenwerk","Anna Lokrantz","Niclas Hertzberg"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.02023v1","updated":"2026-01-05T11:30:56Z","published":"2026-01-05T11:30:56Z","title":"Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs","summary":"Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.","authors":["Amirali Ebrahimzadeh","Seyyed M. Salili"],"pdf_url":"","comment":"25 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2510.20075v5","updated":"2026-01-05T11:25:29Z","published":"2025-10-22T23:16:50Z","title":"I Large Language Models possono nascondere un testo in un altro testo della stessa lunghezza","summary":"A meaningful text can be hidden inside another, completely different yet still coherent and plausible, text of the same length. For example, a tweet containing a harsh political critique could be embedded in a tweet that celebrates the same political leader, or an ordinary product review could conceal a secret manuscript. This uncanny state of affairs is now possible thanks to Large Language Models, and in this paper we present Calgacus, a simple and efficient protocol to achieve it. We show that even modest 8-billion-parameter open-source LLMs are sufficient to obtain high-quality results, and a message as long as this abstract can be encoded and decoded locally on a laptop in seconds. The existence of such a protocol demonstrates a radical decoupling of text from authorial intent, further eroding trust in written communication, already shaken by the rise of LLM chatbots. We illustrate this with a concrete scenario: a company could covertly deploy an unfiltered LLM by encoding its answers within the compliant responses of a safe model. This possibility raises urgent questions for AI safety and challenges our understanding of what it means for a Large Language Model to know something.\n  --\nUn testo di senso compiuto può essere nascosto all'interno di un altro testo completamente diverso, eppure coerente e plausibile, della stessa lunghezza. Ad esempio, un tweet che celebra un leader politico potrebbe celare un tweet che lo critica duramente, o un'anonima recensione di un prodotto potrebbe in realtà codificare un manoscritto segreto. Questa sconcertante possibilità è oggi alla nostra portata grazie ai Large Language Models (LLM); in questo articolo presentiamo Calgacus, un protocollo semplice ed efficiente per realizzarla. Mostriamo che anche modesti LLM open-source da 8 miliardi di parametri sono sufficienti per ottenere risultati di alta qualità, e che un messaggio lungo quanto questo abstract può essere codificato e decodificato su un comune portatile in pochi secondi. L'esistenza di tale protocollo dimostra un radicale disaccoppiamento del testo dall'intento del suo autore, erodendo ulteriormente la fiducia nella comunicazione scritta, già scossa dall'ascesa dei chatbot basati su LLMs. Illustriamo ciò con uno scenario concreto: un'azienda potrebbe offrire pubblicamente i servizi di un LLM senza filtri nascondendo le sue risposte all'interno di risposte apparentemente innocue generate da un LLM considerato sicuro. Questa possibilità solleva questioni urgenti per la sicurezza dell'Intelligenza Artificiale e sfida la nostra comprensione di cosa significhi, per un Large Language Model, sapere qualcosa.","authors":["Antonio Norelli","Michael Bronstein"],"pdf_url":"","comment":"21 pages, in Italian language, main paper 9 pages. v1-v4 are in English"},{"id":"http://arxiv.org/abs/2601.02016v1","updated":"2026-01-05T11:24:34Z","published":"2026-01-05T11:24:34Z","title":"Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach","summary":"This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.","authors":["Matthias Bartolo","Dylan Seychell","Gabriel Hili","Matthew Montebello","Carl James Debono","Saviour Formosa","Konstantinos Makantasis"],"pdf_url":"","comment":"Code available on GitHub: https://github.com/mbar0075/lupi-for-object-detection"},{"id":"http://arxiv.org/abs/2601.02015v1","updated":"2026-01-05T11:24:33Z","published":"2026-01-05T11:24:33Z","title":"Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects","summary":"Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.","authors":["Omar Momen","Emilie Sitter","Berenike Herrmann","Sina Zarrieß"],"pdf_url":"","comment":"to be published at EACL 2026 main conference"},{"id":"http://arxiv.org/abs/2601.02010v1","updated":"2026-01-05T11:19:07Z","published":"2026-01-05T11:19:07Z","title":"A neural network for modeling human concept formation, understanding and communication","summary":"A remarkable capability of the human brain is to form more abstract conceptual representations from sensorimotor experiences and flexibly apply them independent of direct sensory inputs. However, the computational mechanism underlying this ability remains poorly understood. Here, we present a dual-module neural network framework, the CATS Net, to bridge this gap. Our model consists of a concept-abstraction module that extracts low-dimensional conceptual representations, and a task-solving module that performs visual judgement tasks under the hierarchical gating control of the formed concepts. The system develops transferable semantic structure based on concept representations that enable cross-network knowledge transfer through conceptual communication. Model-brain fitting analyses reveal that these emergent concept spaces align with both neurocognitive semantic model and brain response structures in the human ventral occipitotemporal cortex, while the gating mechanisms mirror that in the semantic control brain network. This work establishes a unified computational framework that can offer mechanistic insights for understanding human conceptual cognition and engineering artificial systems with human-like conceptual intelligence.","authors":["Liangxuan Guo","Haoyang Chen","Yang Chen","Yanchao Bi","Shan Yu"],"pdf_url":"","comment":"6 main figures, 5 extended data figures and 4 supplementary figures"},{"id":"http://arxiv.org/abs/2601.02008v1","updated":"2026-01-05T11:17:33Z","published":"2026-01-05T11:17:33Z","title":"XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging","summary":"Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.","authors":["Midhat Urooj","Ayan Banerjee","Sandeep Gupta"],"pdf_url":"","comment":"Accepted at AAAI Bridge Program 2026"},{"id":"http://arxiv.org/abs/2601.02002v1","updated":"2026-01-05T11:03:56Z","published":"2026-01-05T11:03:56Z","title":"Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models","summary":"Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.","authors":["Antonio Colacicco","Vito Guida","Dario Di Palma","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.12589v3","updated":"2026-01-05T11:02:56Z","published":"2024-11-15T19:36:50Z","title":"ULTra: Unveiling Latent Token Interpretability in Transformer-Based Understanding and Segmentation","summary":"Transformers have revolutionized Computer Vision (CV) through self-attention mechanisms. However, their complexity makes latent token representations difficult to interpret. We introduce ULTra, a framework for interpreting Transformer embeddings and uncovering meaningful semantic patterns within them. ULTra enables unsupervised semantic segmentation using pre-trained models without requiring fine-tuning. Additionally, we propose a self-supervised training approach that refines segmentation performance by learning an external transformation matrix without modifying the underlying model. Our method achieves state-of-the-art performance in unsupervised semantic segmentation, outperforming existing segmentation methods. Furthermore, we validate ULTra for model interpretation on both synthetic and real-world scenarios, including Object Selection and interpretable text summarization using LLMs, demonstrating its broad applicability in explaining the semantic structure of latent token representations.","authors":["Hesam Hosseini","Ghazal Hosseini Mighan","Amirabbas Afzali","Sajjad Amini","Amir Houmansadr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01997v1","updated":"2026-01-05T10:56:01Z","published":"2026-01-05T10:56:01Z","title":"Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations","summary":"ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.\n  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.","authors":["Dario Di Palma","Giovanni Maria Biancofiore","Vito Walter Anelli","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01993v1","updated":"2026-01-05T10:54:18Z","published":"2026-01-05T10:54:18Z","title":"MindChat: A Privacy-preserving Large Language Model for Mental Health Support","summary":"Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.","authors":["Dong Xue","Jicheng Tu","Ming Wang","Xin Yan","Fangzhou Liu","Jie Hu"],"pdf_url":"","comment":"33 pages, 16 figures"},{"id":"http://arxiv.org/abs/2512.14244v4","updated":"2026-01-05T10:52:55Z","published":"2025-12-16T09:52:58Z","title":"From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition","summary":"Managing extensive context remains a critical bottleneck for Large Language Models (LLMs), particularly in applications like long-document question answering and autonomous agents where lengthy inputs incur high computational costs and introduce noise. Existing compression techniques often disrupt local coherence through discrete token removal or rely on implicit latent encoding that suffers from positional bias and incompatibility with closed-source APIs. To address these limitations, we introduce the EDU-based Context Compressor, a novel explicit compression framework designed to preserve both global structure and fine-grained details. Our approach reformulates context compression as a structure-then-select process. First, our LingoEDU transforms linear text into a structural relation tree of Elementary Discourse Units (EDUs) which are anchored strictly to source indices to eliminate hallucination. Second, a lightweight ranking module selects query-relevant sub-trees for linearization. To rigorously evaluate structural understanding, we release StructBench, a manually annotated dataset of 248 diverse documents. Empirical results demonstrate that our method achieves state-of-the-art structural prediction accuracy and significantly outperforms frontier LLMs while reducing costs. Furthermore, our structure-aware compression substantially enhances performance across downstream tasks ranging from long-context tasks to complex Deep Search scenarios.","authors":["Yiqing Zhou","Yu Lei","Shuzheng Si","Qingyan Sun","Wei Wang","Yifei Wu","Hao Wen","Gang Chen","Fanchao Qi","Maosong Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01989v1","updated":"2026-01-05T10:48:12Z","published":"2026-01-05T10:48:12Z","title":"VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis","summary":"Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.","authors":["Aly R. Elkammar","Karim M. Gamaleldin","Catherine M. Elias"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01982v1","updated":"2026-01-05T10:36:40Z","published":"2026-01-05T10:36:40Z","title":"ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems","summary":"Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.","authors":["Noel Thomas"],"pdf_url":"","comment":"7 pages, 0 figures , Accepted to AAAI-26 Bridge Program: Logical and Symbolic Reasoning in Language Models (camera-ready)"},{"id":"http://arxiv.org/abs/2601.01976v1","updated":"2026-01-05T10:32:10Z","published":"2026-01-05T10:32:10Z","title":"CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes","summary":"Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.","authors":["Yasmine Souissi","Fabrice Boissier","Nida Meddouri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21214v3","updated":"2026-01-05T10:26:08Z","published":"2025-11-26T09:44:32Z","title":"Self-Guided Defense: Adaptive Safety Alignment for Reasoning Models via Synthesized Guidelines","summary":"Reasoning models have demonstrated remarkable capabilities in complex reasoning tasks. However, ensuring their safety against adversarial jailbreak prompts remains a critical challenge. Due to the covert and deceptive nature of such prompts, they can often evade built-in safety mechanisms and lead to the generation of harmful content. This underscores the need for an adaptive safety alignment approach that enables models to autonomously reinforce their defenses in response to adversarial inputs. This paper introduces the Synthesized Guideline-based Adaptive Safety Alignment (SGASA) framework, which internalizes model-generated safety guidelines to strengthen models' ability to enhance robustness against harmful adversarial prompts while minimizing unnecessary refusals of benign requests. SGASA consists of two key stages: Data Pre-synthesis, which generates safety guidelines and augmented prompts; and Alignment Fine-tuning, which leverages Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO) to embed these guidelines into the model. Extensive experiments across multiple datasets demonstrate that SGASA significantly improves model safety, validating its adaptive and scalable effectiveness.","authors":["Yuhang Wang","Yanxu Zhu","Dongyuan Lu","Jitao Sang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01966v1","updated":"2026-01-05T10:16:41Z","published":"2026-01-05T10:16:41Z","title":"Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior","summary":"Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.","authors":["Bo Yin","Qi Li","Runpeng Yu","Xinchao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.09040v2","updated":"2026-01-05T10:14:19Z","published":"2025-06-10T17:57:50Z","title":"Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better","summary":"Typical large vision-language models (LVLMs) apply autoregressive supervision solely to textual sequences, without fully incorporating the visual modality into the learning process. This results in three key limitations: (1) an inability to utilize images without accompanying captions, (2) the risk that captions omit critical visual details, and (3) the challenge that certain vision-centric content cannot be adequately conveyed through text. As a result, current LVLMs often prioritize vision-to-language alignment while potentially overlooking fine-grained visual information. While some prior works have explored autoregressive image generation, effectively leveraging autoregressive visual supervision to enhance image understanding remains an open challenge. In this paper, we introduce Autoregressive Semantic Visual Reconstruction (ASVR), which enables joint learning of visual and textual modalities within a unified autoregressive framework. We show that autoregressively reconstructing the raw visual appearance of images does not enhance and may even impair multimodal understanding. In contrast, autoregressively reconstructing the semantic representation of images consistently improves comprehension. Notably, we find that even when models are given continuous image features as input, they can effectively reconstruct discrete semantic tokens, resulting in stable and consistent improvements across a wide range of multimodal understanding benchmarks. Our approach delivers significant performance gains across varying data scales (556k-2M) and types of LLM bacbones. Specifically, ASVR improves LLaVA-1.5 by 5% in average scores across 14 multimodal benchmarks. The code is available at https://github.com/AlenjandroWang/ASVR.","authors":["Dianyi Wang","Wei Song","Yikun Wang","Siyuan Wang","Kaicheng Yu","Zhongyu Wei","Jiaqi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.06065v2","updated":"2026-01-05T10:12:52Z","published":"2024-10-08T14:12:51Z","title":"Posets and Bounded Probabilities for Discovering Order-inducing Features in Event Knowledge Graphs","summary":"Event knowledge graphs (EKG) extend the classical notion of a trace to capture multiple, interacting views of a process execution. In this paper, we tackle the open problem of automating EKG discovery from uncurated data through a principled probabilistic framing based on the outcome space resulting from featured-derived partial orders on events. From this we derive an EKG discovery algorithm based on statistical inference rather than an ad hoc or heuristic-based strategy, or relying on manual analysis from domain experts.\n  This approach comes at the computational cost of exploring a large, non-convex hypothesis space. In particular, solving the maximum likelihood term in our objective function involves counting the number of linear extensions of posets, which in general is #P-complete. Fortunately, bound estimates suffice for model comparison, and admit incorporation into a bespoke branch-and-bound algorithm. We establish an upper bound on our objective function which we show to be antitonic w.r.t. search depth for branching rules that are monotonic w.r.t. model inclusion. This allows pruning of large portions of the search space, which we show experimentally leads to rapid convergence toward optimal solutions that are consistent with manually built EKGs.","authors":["Christoffer Olling Back","Jakob Grue Simonsen"],"pdf_url":"","comment":"2-column IEEE format"},{"id":"http://arxiv.org/abs/2402.08269v2","updated":"2026-01-05T09:58:43Z","published":"2024-02-13T07:49:57Z","title":"Geometry-induced Regularization in Deep ReLU Neural Networks","summary":"Neural networks with a large number of parameters often do not overfit, owing to implicit regularization that favors \\lq good\\rq{} networks. Other related and puzzling phenomena include properties of flat minima, saddle-to-saddle dynamics, and neuron alignment. To investigate these phenomena, we study the local geometry of deep ReLU neural networks. We show that, for a fixed architecture, as the weights vary, the image of a sample $X$ forms a set whose local dimension changes. The parameter space is partitioned into regions where this local dimension remains constant. The local dimension is invariant under the natural symmetries of ReLU networks (i.e., positive rescalings and neuron permutations). We establish then that the network's geometry induces a regularization, with the local dimension serving as a key measure of regularity. Moreover, we relate the local dimension to a new notion of flatness of minima and to saddle-to-saddle dynamics. For shallow networks, we also show that the local dimension is connected to the number of linear regions perceived by $X$, offering insight into the effects of regularization. This is further supported by experiments and linked to neuron alignment. Our analysis offers, for the first time, a simple and unified geometric explanation that applies to all learning contexts for these phenomena, which are usually studied in isolation. Finally, we explore the practical computation of the local dimension and present experiments on the MNIST dataset, which highlight geometry-induced regularization in this setting.","authors":["Joachim Bona-Pellissier","François Malgouyres","François Bachoc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01944v1","updated":"2026-01-05T09:50:37Z","published":"2026-01-05T09:50:37Z","title":"The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities","summary":"In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.","authors":["Matteo Esposito","Andrea Janes","Valentina Lenarduzzi","Davide Taibi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2601.01939v1","updated":"2026-01-05T09:48:18Z","published":"2026-01-05T09:48:18Z","title":"OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation","summary":"In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.","authors":["Victor Sanchez","Chris Reinke","Ahamed Mohamed","Xavier Alameda-Pineda"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.26217v2","updated":"2026-01-05T09:47:47Z","published":"2025-09-30T13:19:00Z","title":"Benchmarking Deep Learning Convolutions on Energy-constrained CPUs","summary":"This work evaluates State-of-the-Art convolution algorithms for CPU-based CNN inference. Although most prior studies focus on GPUs or NPUs, CPU implementations remain comparatively under-optimized. Our first contribution is to provide fair benchmarking for embedded CPU inference. We evaluate direct, GEMM-based, and Winograd convolutions across modern CPUs from ARM, Intel, AMD, and NVIDIA vendors, considering both latency and energy efficiency. To the best of our knowledge, this is the first study to present a fair, cross-vendor comparison of CPU energy consumption using a high-resolution socket-level measurement platform. To validate our methodology, we further compare socket-level power measurements with estimates derived from model-specific registers (MSRs), finding that MSRs underestimate the power consumption of convolution inference by 10--30%. Our results show that the ARM\\R Cortex-A78AE CPU combined with an implicit GEMM convolution implementation offers the best trade-off between latency and power consumption, achieving ResNet50v1.5 inference in 102 ms with an average power of 25.3 W, corresponding to 2.58 J.","authors":["Enrique Galvez","Adrien Cassagne","Alix Munier","Manuel Bouyer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01932v1","updated":"2026-01-05T09:35:06Z","published":"2026-01-05T09:35:06Z","title":"Visualizing the Structure of Lenia Parameter Space","summary":"Continuous cellular automata are rocketing in popularity, yet developing a theoretical understanding of their behaviour remains a challenge. In the case of Lenia, a few fundamental open problems include determining what exactly constitutes a soliton, what is the overall structure of the parameter space, and where do the solitons occur in it. In this abstract, we present a new method to automatically classify Lenia systems into four qualitatively different dynamical classes. This allows us to detect moving solitons, and to provide an interactive visualization of Lenia's parameter space structure on our website https://lenia-explorer.vercel.app/. The results shed new light on the above-mentioned questions and lead to several observations: the existence of new soliton families for parameters where they were not believed to exist, or the universality of the phase space structure across various kernels.","authors":["Barbora Hudcová","František Dušek","Marco Tuccio","Clément Hongler"],"pdf_url":"","comment":"2 pages"},{"id":"http://arxiv.org/abs/2601.01931v1","updated":"2026-01-05T09:27:49Z","published":"2026-01-05T09:27:49Z","title":"DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems","summary":"Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.","authors":["Willem Röpke","Samuel Coward","Andrei Lupu","Thomas Foster","Tim Rocktäschel","Jakob Foerster"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.21027v6","updated":"2026-01-05T09:24:45Z","published":"2024-05-31T17:16:29Z","title":"Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles","summary":"For solving zero-sum games involving non-transitivity, a useful approach is to maintain a policy population to approximate the Nash Equilibrium (NE). Previous studies have shown that the Policy Space Response Oracles (PSRO) algorithm is an effective framework for solving such games. However, current methods initialize a new policy from scratch or inherit a single historical policy in Best Response (BR), missing the opportunity to leverage past policies to generate a better BR. In this paper, we propose Fusion-PSRO, which employs Nash Policy Fusion to initialize a new policy for BR training. Nash Policy Fusion serves as an implicit guiding policy that starts exploration on the current Meta-NE, thus providing a closer approximation to BR. Moreover, it insightfully captures a weighted moving average of past policies, dynamically adjusting these weights based on the Meta-NE in each iteration. This cumulative process further enhances the policy population. Empirical results on classic benchmarks show that Fusion-PSRO achieves lower exploitability, thereby mitigating the shortcomings of previous research on policy initialization in BR.","authors":["Jiesong Lian","Yucong Huang","Chengdong Ma","Mingzhi Wang","Ying Wen","Long Hu","Yixue Hao"],"pdf_url":"","comment":"Accepted by ECAI 2025"},{"id":"http://arxiv.org/abs/2601.01930v1","updated":"2026-01-05T09:23:48Z","published":"2026-01-05T09:23:48Z","title":"MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search","summary":"Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\\times$ higher throughput at 95\\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\\times$, while maintaining performance parity on standard lower-dimensional datasets.","authors":["Dongfang Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01927v1","updated":"2026-01-05T09:19:45Z","published":"2026-01-05T09:19:45Z","title":"Theoretical Convergence of SMOTE-Generated Samples","summary":"Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.","authors":["Firuz Kamalov","Hana Sulieman","Witold Pedrycz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.17999v2","updated":"2026-01-05T09:14:27Z","published":"2025-02-25T09:05:13Z","title":"GNN-XAR: A Graph Neural Network for Explainable Activity Recognition in Smart Homes","summary":"Sensor-based Human Activity Recognition (HAR) in smart home environments is crucial for several applications, especially in the healthcare domain. The majority of the existing approaches leverage deep learning models. While these approaches are effective, the rationale behind their outputs is opaque. Recently, eXplainable Artificial Intelligence (XAI) approaches emerged to provide intuitive explanations to the output of HAR models. To the best of our knowledge, these approaches leverage classic deep models like CNNs or RNNs. Recently, Graph Neural Networks (GNNs) proved to be effective for sensor-based HAR. However, existing approaches are not designed with explainability in mind. In this work, we propose the first explainable Graph Neural Network explicitly designed for smart home HAR. Our results on two public datasets show that this approach provides better explanations than state-of-the-art methods while also slightly improving the recognition rate.","authors":["Michele Fiori","Davide Mor","Gabriele Civitarese","Claudio Bettini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01921v1","updated":"2026-01-05T09:11:29Z","published":"2026-01-05T09:11:29Z","title":"A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach","summary":"Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.\n  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.\n  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.\n  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.","authors":["Mikel Robredo","Matteo Esposito","Fabio Palomba","Rafael Peñaloza","Valentina Lenarduzzi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2510.23163v2","updated":"2026-01-05T09:07:45Z","published":"2025-10-27T09:41:29Z","title":"Beyond Direct Generation: A Decomposed Approach to Well-Crafted Screenwriting with LLMs","summary":"The screenplay serves as the foundation for television production, defining narrative structure, character development, and dialogue. While Large Language Models (LLMs) show great potential in creative writing, direct end-to-end generation approaches often fail to produce well-crafted screenplays. We argue this failure stems from forcing a single model to simultaneously master two disparate capabilities: creative narrative construction and rigid format adherence. The resulting outputs may mimic superficial style but lack the deep structural integrity and storytelling substance required for professional use. To enable LLMs to generate high-quality screenplays, we introduce Dual-Stage Refinement (DSR), a decomposed framework that decouples creative narrative generation from format conversion. The first stage transforms a brief outline into rich, novel-style prose. The second stage refines this narrative into a professionally formatted screenplay. This separation enables the model to specialize in one distinct capability at each stage. A key challenge in implementing DSR is the scarcity of paired outline-to-novel training data. We address this through hybrid data synthesis: reverse synthesis deconstructs existing screenplays into structured inputs, while forward synthesis leverages these inputs to generate high-quality narrative texts as training targets. Blind evaluations by professional screenwriters show that DSR achieves a 75% win rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of human-level performance. Our work demonstrates that decomposed generation architecture with tailored data synthesis effectively specializes LLMs in complex creative domains.","authors":["Hang Lei","Shengyi Zong","Zhaoyan Li","Ziren Zhou","Hao Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.20704v2","updated":"2026-01-05T09:07:09Z","published":"2025-07-28T10:57:44Z","title":"Text2VLM: Adapting Text-Only Datasets to Evaluate Alignment Training in Visual Language Models","summary":"The increasing integration of Visual Language Models (VLMs) into AI systems necessitates robust model alignment, especially when handling multimodal content that combines text and images. Existing evaluation datasets heavily lean towards text-only prompts, leaving visual vulnerabilities under evaluated. To address this gap, we propose \\textbf{Text2VLM}, a novel multi-stage pipeline that adapts text-only datasets into multimodal formats, specifically designed to evaluate the resilience of VLMs against typographic prompt injection attacks. The Text2VLM pipeline identifies harmful content in the original text and converts it into a typographic image, creating a multimodal prompt for VLMs. Also, our evaluation of open-source VLMs highlights their increased susceptibility to prompt injection when visual inputs are introduced, revealing critical weaknesses in the current models' alignment. This is in addition to a significant performance gap compared to closed-source frontier models. We validate Text2VLM through human evaluations, ensuring the alignment of extracted salient concepts; text summarization and output classification align with human expectations. Text2VLM provides a scalable tool for comprehensive safety assessment, contributing to the development of more robust safety mechanisms for VLMs. By enhancing the evaluation of multimodal vulnerabilities, Text2VLM plays a role in advancing the safe deployment of VLMs in diverse, real-world applications.","authors":["Gabriel Downer","Sean Craven","Damian Ruck","Jake Thomas"],"pdf_url":"","comment":"9 pages, 9 figures. Jake Thomas served as Editor for this manuscript"},{"id":"http://arxiv.org/abs/2511.07842v2","updated":"2026-01-05T08:58:48Z","published":"2025-11-11T05:24:30Z","title":"Alignment-Aware Quantization for LLM Safety","summary":"Safety and efficiency are paramount yet often conflicting requirements for deploying Large Language Models (LLMs). While LLMs are trained to follow human alignment for safety, Post-Training Quantization (PTQ) is applied afterward to ensure efficiency. Here we identify a fundamental flaw in the conventional PTQ paradigm: quantization can turn into a safety vulnerability if it only aims to achieve low perplexity. To address this, we propose \\textbf{Alignment-Aware Quantization (AAQ)}, a novel approach that integrates an \\textbf{Alignment-Preserving Contrastive (APC)} loss into the PTQ pipeline. Our method explicitly preserves alignment by encouraging the quantized model to mimic its safe, instruction-tuned model while diverging from the unaligned, pre-trained counterpart. AAQ achieves robust safety alignment without specialized safety-focused datasets, using only standard calibration data. We show that AAQ is compatible with standard PTQ techniques and enables robust 4-bit (W4A4) quantization across diverse model families. Our work resolves the critical trade-off between efficiency and safety, paving the way toward LLMs that are both efficient and trustworthy. Anonymized code is available in the supplementary material.","authors":["Sunghyun Wee","Suyoung Kim","Hyeonjin Kim","Kyomin Hwang","Nojun Kwak"],"pdf_url":"","comment":"8 pages, 4 figures. Includes 7 pages of supplementary material"},{"id":"http://arxiv.org/abs/2601.01910v1","updated":"2026-01-05T08:55:27Z","published":"2026-01-05T08:55:27Z","title":"MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning","summary":"Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.\n  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.","authors":["Minh Hieu Ha","Khanh Ly Ta","Hung Phan","Tung Doan","Tung Dao","Dao Tran","Huynh Thi Thanh Binh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01908v1","updated":"2026-01-05T08:53:04Z","published":"2026-01-05T08:53:04Z","title":"Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection","summary":"Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.","authors":["Jingjing Wang","Qianglin Liu","Zhuo Xiao","Xinning Yao","Bo Liu","Lu Li","Lijuan Niu","Fugen Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01904v1","updated":"2026-01-05T08:49:30Z","published":"2026-01-05T08:49:30Z","title":"Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning","summary":"Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.\n  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.\n  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.","authors":["Yuxuan Li","Harshith Reddy Kethireddy","Srijita Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.10954v3","updated":"2026-01-05T08:48:37Z","published":"2025-06-12T17:54:17Z","title":"SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks","summary":"Constructing large-scale datasets for the GitHub issue resolution task is crucial for both training and evaluating the software engineering capabilities of Large Language Models (LLMs). However, the existing GitHub issue resolution data construction pipeline is challenging and labor-intensive. We identify three key limitations in existing pipelines: (1) test patches collected often omit binary file changes; (2) the manual construction of evaluation environments is labor-intensive; and (3) the fail2pass validation phase requires manual inspection of test logs and writing custom parsing code to extract test status from logs. In this paper, we propose SWE-Factory, a fully automated issue resolution data construction pipeline, to resolve these limitations. First, our pipeline automatically recovers missing binary test files and ensures the correctness of test patches. Second, we introduce SWE-Builder, a LLM-based multi-agent system that automates evaluation environment construction. Third, we introduce a standardized, exit-code-based log parsing method to automatically extract test status, enabling a fully automated fail2pass validation. Experiments on 671 real-world GitHub issues across four programming languages show that our method can effectively construct valid evaluation environments for GitHub issues at a reasonable cost. For example, with GPT-4.1 mini, our SWE-Builder constructs 337 valid task instances out of 671 issues, at $0.047 per instance. Our ablation study further shows the effectiveness of different components of SWE-Builder. We also demonstrate through manual inspection that our exit-code-based fail2pass validation method is highly accurate, achieving an F1 score of 0.99. Additionally, we conduct an exploratory experiment to investigate whether we can use SWE-Factory to enhance models' software engineering ability.","authors":["Lianghong Guo","Yanlin Wang","Caihua Li","Wei Tao","Pengyu Yang","Jiachi Chen","Haoyu Song","Duyu Tang","Zibin Zheng"],"pdf_url":"","comment":"To appear at FSE'2026"},{"id":"http://arxiv.org/abs/2402.06388v4","updated":"2026-01-05T08:44:46Z","published":"2024-02-09T13:10:04Z","title":"Convergence of a L2 regularized Policy Gradient Algorithm for the Multi Armed Bandit","summary":"Although Multi Armed Bandit (MAB) on one hand and the policy gradient approach on the other hand are among the most used frameworks of Reinforcement Learning, the theoretical properties of the policy gradient algorithm used for MAB have not been given enough attention. We investigate in this work the convergence of such a procedure for the situation when a $L2$ regularization term is present jointly with the 'softmax' parametrization. We prove convergence under appropriate technical hypotheses and test numerically the procedure including situations beyond the theoretical setting. The tests show that a time dependent regularized procedure can improve over the canonical approach especially when the initial guess is far from the solution.","authors":["Stefana Anita","Gabriel Turinici"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01896v1","updated":"2026-01-05T08:40:37Z","published":"2026-01-05T08:40:37Z","title":"Tackling the Inherent Difficulty of Noise Filtering in RAG","summary":"Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.","authors":["Jingyu Liu","Jiaen Lin","Yong Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.05753v2","updated":"2026-01-05T08:40:11Z","published":"2025-12-05T14:39:50Z","title":"A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning","summary":"The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.","authors":["Wencheng Cai","Xuchao Gao","Congying Han","Mingqiang Li","Tiande Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.03802v4","updated":"2026-01-05T08:32:05Z","published":"2025-05-02T08:46:01Z","title":"Balancing Fidelity and Plasticity: Aligning Mixed-Precision Fine-Tuning with Linguistic Hierarchies","summary":"Deploying and fine-tuning Large Language Models (LLMs) on resource-constrained edge devices requires navigating a strict trade-off between memory footprint and task performance. While Quantization-Aware Fine-tuning has emerged as a viable solution, existing paradigms typically decouple quantization and adapter optimization. This separation overlooks a fundamental theoretical constraint we identify as the \\textit{Fidelity-Plasticity Trade-off}: a layer's capacity to adapt to new tasks (Plasticity) is inherently constrained by the information capacity of its frozen weights (Fidelity). Aggressively quantizing semantically critical layers creates an information bottleneck that no amount of adapter rank can recover, while high precision in robust syntactic layers wastes valuable memory. To address this, we introduce \\textbf{QR-Adaptor}, a unified framework that jointly optimizes per-layer quantization bit-width and LoRA rank. By formulating resource allocation as a multi-objective search aligned with the model's linguistic hierarchy, our method systematically liberates memory from redundancy-heavy layers to reinvest in capacity-critical ones. Extensive experiments demonstrate that QR-Adaptor establishes a new Pareto frontier: notably, a model fine-tuned under a strict 4-bit memory budget achieves performance rivaling 16-bit baselines, demonstrating that precise resource alignment is as critical as model size.","authors":["Changhai Zhou","Shiyang Zhang","Yuhua Zhou","Qian Qiao","Jun Gao","Shichao Weng","Weizhong Zhang","Cheng Jin"],"pdf_url":"","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.01887v1","updated":"2026-01-05T08:26:34Z","published":"2026-01-05T08:26:34Z","title":"Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance","summary":"Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.","authors":["Jiawen Zhang","Lipeng He","Kejia Chen","Jian Lou","Jian Liu","Xiaohu Yang","Ruoxi Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.08344v3","updated":"2026-01-05T08:14:16Z","published":"2025-08-11T10:55:06Z","title":"What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge","summary":"Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an increasingly explored approach for combining the reasoning capabilities of large language models with the structured evidence of knowledge graphs. However, current evaluation practices fall short: existing benchmarks often include questions that can be directly answered using existing triples in KG, making it unclear whether models perform reasoning or simply retrieve answers directly. Moreover, inconsistent evaluation metrics and lenient answer matching criteria further obscure meaningful comparisons. In this work, we introduce a general method for constructing benchmarks, together with an evaluation protocol, to systematically assess KG-RAG methods under knowledge incompleteness. Our empirical results show that current KG-RAG methods have limited reasoning ability under missing knowledge, often rely on internal memorization, and exhibit varying degrees of generalization depending on their design.","authors":["Dongzhuoran Zhou","Yuqicheng Zhu","Xiaxia Wang","Hongkuan Zhou","Yuan He","Jiaoyan Chen","Steffen Staab","Evgeny Kharlamov"],"pdf_url":"","comment":"Accepted as a main conference paper at EACL 2026"},{"id":"http://arxiv.org/abs/2601.01878v1","updated":"2026-01-05T08:06:50Z","published":"2026-01-05T08:06:50Z","title":"Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs","summary":"Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.","authors":["Farzan Karimi-Malekabadi","Suhaib Abdurahman","Zhivar Sourati","Jackson Trager","Morteza Dehghani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01875v1","updated":"2026-01-05T08:02:49Z","published":"2026-01-05T08:02:49Z","title":"Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence","summary":"Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.","authors":["Kewen Cao","Jianxu Chen","Yongbing Zhang","Ye Zhang","Hongxiao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01874v1","updated":"2026-01-05T08:02:18Z","published":"2026-01-05T08:02:18Z","title":"CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving","summary":"Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\\Rightarrow$internalization$\\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.","authors":["Shuhang Chen","Yunqiu Xu","Junjie Xie","Aojun Lu","Tao Feng","Zeying Huang","Ning Zhang","Yi Sun","Yi Yang","Hangjie Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14150v2","updated":"2026-01-05T07:45:27Z","published":"2025-12-16T07:15:15Z","title":"PathFinder: Advancing Path Loss Prediction for Single-to-Multi-Transmitter Scenario","summary":"Radio path loss prediction (RPP) is critical for optimizing 5G networks and enabling IoT, smart city, and similar applications. However, current deep learning-based RPP methods lack proactive environmental modeling, struggle with realistic multi-transmitter scenarios, and generalize poorly under distribution shifts, particularly when training/testing environments differ in building density or transmitter configurations. This paper identifies three key issues: (1) passive environmental modeling that overlooks transmitters and key environmental features; (2) overemphasis on single-transmitter scenarios despite real-world multi-transmitter prevalence; (3) excessive focus on in-distribution performance while neglecting distribution shift challenges. To address these, we propose PathFinder, a novel architecture that actively models buildings and transmitters via disentangled feature encoding and integrates Mask-Guided Low-rank Attention to independently focus on receiver and building regions. We also introduce a Transmitter-Oriented Mixup strategy for robust training and a new benchmark, single-to-multi-transmitter RPP (S2MT-RPP), tailored to evaluate extrapolation performance (multi-transmitter testing after single-transmitter training). Experimental results show PathFinder outperforms state-of-the-art methods significantly, especially in challenging multi-transmitter scenarios. Our code and project site are publicly available at: https://emorzz1g.github.io/PathFinder/.","authors":["Zhijie Zhong","Zhiwen Yu","Pengyu Li","Jianming Lv","C. L. Philip Chen","Min Chen"],"pdf_url":"","comment":"20 pages, 14 figures, 4 tables. Under review"},{"id":"http://arxiv.org/abs/2601.01857v1","updated":"2026-01-05T07:35:12Z","published":"2026-01-05T07:35:12Z","title":"Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios","summary":"As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.","authors":["Defei Xia","Bingfeng Pi","Shenbin Zhang","Song Hua","Yunfei Wei","Lei Zuo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01852v1","updated":"2026-01-05T07:27:57Z","published":"2026-01-05T07:27:57Z","title":"MORE: Multi-Objective Adversarial Attacks on Speech Recognition","summary":"The emergence of large-scale automatic speech recognition (ASR) models such as Whisper has greatly expanded their adoption across diverse real-world applications. Ensuring robustness against even minor input perturbations is therefore critical for maintaining reliable performance in real-time environments. While prior work has mainly examined accuracy degradation under adversarial attacks, robustness with respect to efficiency remains largely unexplored. This narrow focus provides only a partial understanding of ASR model vulnerabilities. To address this gap, we conduct a comprehensive study of ASR robustness under multiple attack scenarios. We introduce MORE, a multi-objective repetitive doubling encouragement attack, which jointly degrades recognition accuracy and inference efficiency through a hierarchical staged repulsion-anchoring mechanism. Specifically, we reformulate multi-objective adversarial optimization into a hierarchical framework that sequentially achieves the dual objectives. To further amplify effectiveness, we propose a novel repetitive encouragement doubling objective (REDO) that induces duplicative text generation by maintaining accuracy degradation and periodically doubling the predicted sequence length. Overall, MORE compels ASR models to produce incorrect transcriptions at a substantially higher computational cost, triggered by a single adversarial input. Experiments show that MORE consistently yields significantly longer transcriptions while maintaining high word error rates compared to existing baselines, underscoring its effectiveness in multi-objective adversarial attack.","authors":["Xiaoxue Gao","Zexin Li","Yiming Chen","Nancy F. Chen"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2601.01844v1","updated":"2026-01-05T07:16:29Z","published":"2026-01-05T07:16:29Z","title":"Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation","summary":"Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.","authors":["Udiptaman Das","Krishnasai B. Atmakuri","Duy Ho","Chi Lee","Yugyung Lee"],"pdf_url":"","comment":"13 pages, 5 tables, 4 figures"},{"id":"http://arxiv.org/abs/2601.01839v1","updated":"2026-01-05T07:02:58Z","published":"2026-01-05T07:02:58Z","title":"The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation","summary":"Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy (clear goals and planning), Process (how work gets done), Ecosystem (tools and infrastructure), and Support (organizational backing and resources). Our results show that these factors are interconnected - each one affects the next. For instance, strong organizational support results in a clearer strategy (β= 0.432, p < 0.001), which improves work processes (β= 0.428, p < 0.001) and builds better infrastructure (β= 0.547, p < 0.001). Together, these elements determine whether a project succeeds. The surprising finding? Although AI assistants make coding faster, they don't guarantee project success. AI assists with the \"how\" of coding but cannot replace the \"why\" and \"what\" of strategic thinking.","authors":["Martin Prause"],"pdf_url":"","comment":"Dataset available: https://ieee-dataport.org/documents/machine-learning-canvas-success-determinants"},{"id":"http://arxiv.org/abs/2601.01836v1","updated":"2026-01-05T06:57:45Z","published":"2026-01-05T06:57:45Z","title":"COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs","summary":"As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.","authors":["Dasol Choi","DongGeon Lee","Brigitta Jesica Kartono","Helena Berndt","Taeyoun Kwon","Joonwon Jang","Haon Park","Hwanjo Yu","Minsuk Kahng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01835v1","updated":"2026-01-05T06:57:26Z","published":"2026-01-05T06:57:26Z","title":"RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images","summary":"In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.","authors":["Rashid Iqbal","Saddam Hussain Khan"],"pdf_url":"","comment":"15 Pages, 7 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2601.01832v1","updated":"2026-01-05T06:51:08Z","published":"2026-01-05T06:51:08Z","title":"Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization","summary":"We present Yukthi Opus (YO), a multi-chain hybrid metaheuristic designed for NP-hard optimization under explicit evaluation budget constraints. YO integrates three complementary mechanisms in a structured two-phase architecture: Markov Chain Monte Carlo (MCMC) for global exploration, greedy local search for exploitation, and simulated annealing with adaptive reheating to enable controlled escape from local minima. A dedicated burn-in phase allocates evaluations to probabilistic exploration, after which a hybrid optimization loop refines promising candidates. YO further incorporates a spatial blacklist mechanism to avoid repeated evaluation of poor regions and a multi-chain execution strategy to improve robustness and reduce sensitivity to initialization.\n  We evaluate YO on three benchmarks: the Rastrigin function (5D) with ablation studies, the Traveling Salesman Problem with 50 to 200 cities, and the Rosenbrock function (5D) with comparisons against established optimizers including CMA-ES, Bayesian optimization, and accelerated particle swarm optimization. Results show that MCMC exploration and greedy refinement are critical for solution quality, while simulated annealing and multi-chain execution primarily improve stability and variance reduction. Overall, YO achieves competitive performance on large and multimodal problems while maintaining predictable evaluation budgets, making it suitable for expensive black-box optimization settings.","authors":["SB Danush Vikraman","Hannah Abagail","Prasanna Kesavraj","Gajanan V Honnavar"],"pdf_url":"","comment":"22 pages, 9 figures, includes extensive ablation studies and benchmark comparisons"},{"id":"http://arxiv.org/abs/2601.01831v1","updated":"2026-01-05T06:50:40Z","published":"2026-01-05T06:50:40Z","title":"ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring","summary":"Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.","authors":["Aniket Wattamwar","Sampson Akwafuo"],"pdf_url":"","comment":"6 pages, 14 figures, 1 table"},{"id":"http://arxiv.org/abs/2601.01828v1","updated":"2026-01-05T06:47:41Z","published":"2026-01-05T06:47:41Z","title":"Emergent Introspective Awareness in Large Language Models","summary":"We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to \"think about\" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.","authors":["Jack Lindsey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.00020v2","updated":"2026-01-05T06:41:55Z","published":"2025-12-22T01:09:24Z","title":"Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing","summary":"Electroencephalography (EEG)-based brain-computer interfaces (BCIs) are strongly affected by non-stationary neural signals that vary across sessions and individuals, limiting the generalization of subject-agnostic models and motivating adaptive and personalized learning on resource-constrained platforms. Programmable memristive hardware offers a promising substrate for such post-deployment adaptation; however, practical realization is challenged by limited weight resolution, device variability, nonlinear programming dynamics, and finite device endurance. In this work, we show that spiking neural networks (SNNs) can be deployed on ferroelectric memristive synaptic devices for adaptive EEG-based motor imagery decoding under realistic device constraints. We fabricate, characterize, and model ferroelectric synapses. We evaluate a convolutional-recurrent SNN architecture under two complementary deployment strategies: (i) device-aware training using a ferroelectric synapse model, and (ii) transfer of software-trained weights followed by low-overhead on-device re-tuning. To enable efficient adaptation, we introduce a device-aware weight-update strategy in which gradient-based updates are accumulated digitally and converted into discrete programming events only when a threshold is exceeded, emulating nonlinear, state-dependent programming dynamics while reducing programming frequency. Both deployment strategies achieve classification performance comparable to state-of-the-art software-based SNNs. Furthermore, subject-specific transfer learning achieved by retraining only the final network layers improves classification accuracy. These results demonstrate that programmable ferroelectric hardware can support robust, low-overhead adaptation in spiking neural networks, opening a practical path toward personalized neuromorphic processing of neural signals.","authors":["Nikhil Garg","Anxiong Song","Niklas Plessnig","Nathan Savoia","Laura Bégon-Lours"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.04497v4","updated":"2026-01-05T05:58:43Z","published":"2024-11-30T00:10:56Z","title":"Opportunities and Challenges of Large Language Models for Low-Resource Languages in Humanities Research","summary":"Low-resource languages serve as invaluable repositories of human history, embodying cultural evolution and intellectual diversity. Despite their significance, these languages face critical challenges, including data scarcity and technological limitations, which hinder their comprehensive study and preservation. Recent advancements in large language models (LLMs) offer transformative opportunities for addressing these challenges, enabling innovative methodologies in linguistic, historical, and cultural research. This study systematically evaluates the applications of LLMs in low-resource language research, encompassing linguistic variation, historical documentation, cultural expressions, and literary analysis. By analyzing technical frameworks, current methodologies, and ethical considerations, this paper identifies key challenges such as data accessibility, model adaptability, and cultural sensitivity. Given the cultural, historical, and linguistic richness inherent in low-resource languages, this work emphasizes interdisciplinary collaboration and the development of customized models as promising avenues for advancing research in this domain. By underscoring the potential of integrating artificial intelligence with the humanities to preserve and study humanity's linguistic and cultural heritage, this study fosters global efforts towards safeguarding intellectual diversity.","authors":["Tianyang Zhong","Zhenyuan Yang","Zhengliang Liu","Ruidong Zhang","Weihang You","Yiheng Liu","Haiyang Sun","Yi Pan","Yiwei Li","Yifan Zhou","Hanqi Jiang","Junhao Chen","Tianming Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01816v1","updated":"2026-01-05T05:58:19Z","published":"2026-01-05T05:58:19Z","title":"Admissibility Alignment","summary":"This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.\n  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.","authors":["Chris Duffey"],"pdf_url":"","comment":"24 pages, 2 figures, 2 tables.. Decision-theoretic alignment under uncertainty"},{"id":"http://arxiv.org/abs/2512.24617v2","updated":"2026-01-05T05:44:29Z","published":"2025-12-31T04:19:33Z","title":"Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space","summary":"Large Language Models (LLMs) apply uniform computation to all tokens, despite language exhibiting highly non-uniform information density. This token-uniform regime wastes capacity on locally predictable spans while under-allocating computation to semantically critical transitions. We propose $\\textbf{Dynamic Large Concept Models (DLCM)}$, a hierarchical language modeling framework that learns semantic boundaries from latent representations and shifts computation from tokens to a compressed concept space where reasoning is more efficient. DLCM discovers variable-length concepts end-to-end without relying on predefined linguistic units. Hierarchical compression fundamentally changes scaling behavior. We introduce the first $\\textbf{compression-aware scaling law}$, which disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. To stably train this heterogeneous architecture, we further develop a $\\textbf{decoupled $μ$P parametrization}$ that supports zero-shot hyperparameter transfer across widths and compression regimes. At a practical setting ($R=4$, corresponding to an average of four tokens per concept), DLCM reallocates roughly one-third of inference compute into a higher-capacity reasoning backbone, achieving a $\\textbf{+2.69$\\%$ average improvement}$ across 12 zero-shot benchmarks under matched inference FLOPs.","authors":["Xingwei Qu","Shaowen Wang","Zihao Huang","Kai Hua","Fan Yin","Rui-Jie Zhu","Jundong Zhou","Qiyang Min","Zihao Wang","Yizhi Li","Tianyu Zhang","He Xing","Zheng Zhang","Yuxuan Song","Tianyu Zheng","Zhiyuan Zeng","Chenghua Lin","Ge Zhang","Wenhao Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.12885v3","updated":"2026-01-05T05:39:03Z","published":"2025-07-17T08:10:55Z","title":"VAR-MATH: Probing True Mathematical Reasoning in LLMS via Symbolic Multi-Instance Benchmarks","summary":"Recent advances in reinforcement learning (RL) have led to substantial improvements in the mathematical reasoning abilities of LLMs, as measured by standard benchmarks. Yet these gains often persist even when models are trained with flawed signals, such as random or inverted rewards. This raises a fundamental question: do such improvements reflect genuine reasoning, or are they merely artifacts of overfitting to benchmark-specific patterns? To answer this question, we adopt an evaluation-centric perspective and highlight two critical shortcomings in existing protocols. First, benchmark contamination arises because test problems are publicly available, thereby increasing the risk of data leakage. Second, evaluation fragility results from reliance on single-instance assessments, which are sensitive to stochastic outputs and fail to capture reasoning consistency. These limitations suggest the need for a new evaluation paradigm that can probe reasoning ability beyond memorization and one-off success. As response, we propose VAR-MATH, a symbolic evaluation framework that converts fixed numerical problems into parameterized templates and requires models to solve multiple instantiations of each. This design enforces consistency across structurally equivalent variants, mitigates contamination, and enhances robustness through bootstrapped metrics. We apply VAR-MATH to transform three popular benchmarks, AMC23, AIME24, and AIME25, into their symbolic counterparts, VAR-AMC23, VAR-AIME24, and VAR-AIME25. Experimental results show substantial performance drops for RL-trained models on these variabilized benchmarks, especially for smaller models, with average declines of 47.9\\% on AMC23, 58.8\\% on AIME24, and 72.9\\% on AIME25. These findings indicate that some existing RL methods rely on superficial heuristics and fail to generalize beyond specific numerical forms.","authors":["Jian Yao","Ran Cheng","Kay Chen Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01807v1","updated":"2026-01-05T05:35:45Z","published":"2026-01-05T05:35:45Z","title":"Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification","summary":"Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.","authors":[" Ubaidullah","Muhammad Abid Hussain","Mohsin Raza Jafri","Rozi Khan","Moid Sandhu","Abd Ullah Khan","Hyundong Shin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01803v1","updated":"2026-01-05T05:27:11Z","published":"2026-01-05T05:27:11Z","title":"Moments Matter:Stabilizing Policy Optimization using Return Distributions","summary":"Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.","authors":["Dennis Jabs","Aditya Mohan","Marius Lindauer"],"pdf_url":"","comment":"Workshop paper at RLDM'25"},{"id":"http://arxiv.org/abs/2601.01802v1","updated":"2026-01-05T05:26:57Z","published":"2026-01-05T05:26:57Z","title":"PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor","summary":"To develop a reliable AI for psychological assessment, we introduce \\texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \\textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \\textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \\textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \\texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.","authors":["Qianjun Pan","Junyi Wang","Jie Zhou","Yutao Yang","Junsong Li","Kaiyin Xu","Yougen Zhou","Yihan Li","Jingyuan Zhao","Qin Chen","Ningning Zhou","Kai Chen","Liang He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01800v1","updated":"2026-01-05T05:20:16Z","published":"2026-01-05T05:20:16Z","title":"Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving","summary":"Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\\% across all cases compared to state-of-the-art baseline methods.","authors":["Qi Wei","Junchao Fan","Zhao Yang","Jianhua Wang","Jingkai Mao","Xiaolin Chang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06065v3","updated":"2026-01-05T05:19:37Z","published":"2025-11-08T16:30:44Z","title":"ScRPO: From Errors to Insights","summary":"We introduce Self-correction Relative Policy Optimization (ScRPO), a novel reinforcement learning framework designed to empower large language models with advanced mathematical reasoning capabilities through iterative self-reflection and error correction. The ScRPO framework operates in two distinct phases: (1) Trial-and-error learning stage, where the model is trained via GRPO, and incorrect responses are collected to form an \"error pool\"; and (2) Self-correction learning stage, which guides the model to introspectively analyze and rectify the reasoning flaws behind its previous errors. Extensive evaluations across challenging mathematical benchmarks, including AIME, AMC, Olympiad, MATH-500, and GSM8k, validate the efficacy of our approach. Using DeepSeek-R1-Distill-Qwen-1.5B and 7B as backbones, ScRPO achieves average accuracies of 64.8% and 77.8%, respectively. This represents a significant improvement of 6.0% and 3.2% over vanilla baselines, consistently outperforming strong post-training methods such as DAPO and GRPO. These findings establish ScRPO as a robust paradigm for enabling autonomous self-improvement in AI systems, particularly in tasks with limited external feedback.","authors":["Lianrui Li","Dakuan Lu","Jiawei Shao","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01798v1","updated":"2026-01-05T05:16:07Z","published":"2026-01-05T05:16:07Z","title":"VerLM: Explaining Face Verification Using Natural Language","summary":"Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.","authors":["Syed Abdul Hannan","Hazim Bukhari","Thomas Cantalapiedra","Eman Ansar","Massa Baali","Rita Singh","Bhiksha Raj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01792v1","updated":"2026-01-05T05:06:11Z","published":"2026-01-05T05:06:11Z","title":"HyperCLOVA X 8B Omni","summary":"In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.","authors":[" NAVER Cloud HyperCLOVA X Team"],"pdf_url":"","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2510.11176v3","updated":"2026-01-05T04:58:57Z","published":"2025-10-13T09:08:59Z","title":"G2L:From Giga-Scale to Cancer-Specific Large-Scale Pathology Foundation Models via Knowledge Distillation","summary":"Recent studies in pathology foundation models have shown that scaling training data, diversifying cancer types, and increasing model size consistently improve their performance. However, giga-scale foundation models, which are trained on hundreds of thousands of slides covering tens of cancer types and contain billions of parameters, pose significant challenges for practical use due to their tremendous computational costs in both development and deployment. In this work, we present a novel strategy, named the G2L framework, to increase the performance of large-scale foundation models, which consist of only $15\\%$ of the parameters of giga-scale models, to a comparable performance level of giga-scale models in cancer-specific tasks. Our approach applies knowledge distillation, transferring the capabilities of a giga-scale model to a large-scale model, using just 1K pathology slides of a target cancer (e.g., breast, prostate, etc.). The resulting distilled model not only outperformed state-of-the-art models of the same size (i.e., large-scale) across several benchmarks but also, interestingly, surpassed the giga-scale teacher and huge-scale models in some benchmarks. In addition, the distilled model exhibited a higher robustness index, indicating improved resilience to image variations originating from multiple institutions. These findings suggest that the proposed distillation approach for a large-scale model is a data- and parameter-efficient way to achieve giga-scale-level performance for cancer-specific applications without prohibitive computational burden.","authors":["Yesung Cho","Sungmin Lee","Geongyu Lee","Minkyung Lee","Jongbae Park","Dongmyung Shin"],"pdf_url":"","comment":"Accepted in AAAI 2026 workshop in Health Intelligence Special Theme on Foundation Models and AI Agents"},{"id":"http://arxiv.org/abs/2511.08314v3","updated":"2026-01-05T04:40:51Z","published":"2025-11-11T14:44:07Z","title":"Improving the accuracy and generalizability of molecular property regression models with a substructure-substitution-rule-informed framework","summary":"Artificial Intelligence (AI)-aided drug discovery is an active research field, yet AI models often exhibit poor accuracy in regression tasks for molecular property prediction, and perform catastrophically poorly for out-of-distribution (OOD) molecules. Here, we present MolRuleLoss, a substructure-substitution-rule-informed framework that improves the accuracy and generalizability of multiple molecular property regression models (MPRMs) such as GEM and UniMol for diverse molecular property prediction tasks. MolRuleLoss incorporates partial derivative constraints for substructure substitution rules (SSRs) into an MPRM's loss function. When using GEM models for predicting lipophilicity, water solubility, and solvation-free energy (using lipophilicity, ESOL, and freeSolv datasets from MoleculeNet), the root mean squared error (RMSE) values with and without MolRuleLoss were 0.587 vs. 0.660, 0.777 vs. 0.798, and 1.252 vs. 1.877, respectively, representing 2.6-33.3% performance improvements. We show that both the number and the quality of SSRs contribute to the magnitude of prediction accuracy gains obtained upon adding MolRuleLoss to an MPRM. MolRuleLoss improved the generalizability of MPRMs for \"activity cliff\" molecules in a lipophilicity prediction task and improved the generalizability of MPRMs for OOD molecules in a melting point prediction task. In a molecular weight prediction task for OOD molecules, MolRuleLoss reduced the RMSE value of a GEM model from 29.507 to 0.007. We also provide a formal demonstration that the upper bound of the variation for property change of SSRs is positively correlated with an MPRM's error. Together, we show that using the MolRuleLoss framework as a bolt-on boosts the prediction accuracy and generalizability of multiple MPRMs, supporting diverse applications in areas like cheminformatics and AI-aided drug discovery.","authors":["Xiaoyu Fan","Lin Guo","Ruizhen Jia","Yang Tian","Zhihao Yang","Weihao Li","Boxue Tian"],"pdf_url":"","comment":"Author information updated: add co-author Weihao Li (affiliation:Department of Statistics and Data Science, Tsinghua University, Beijing, 100084, China). Weihao Li proposed constructive revision suggestions for section on Proof of \"Tian Conjecture\""},{"id":"http://arxiv.org/abs/2601.01781v1","updated":"2026-01-05T04:28:49Z","published":"2026-01-05T04:28:49Z","title":"Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery","summary":"Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \\href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.","authors":["Lakshay Sharma","Alex Marin"],"pdf_url":"","comment":"Accepted at CV4EO Workshop at WACV 2026"},{"id":"http://arxiv.org/abs/2601.01780v1","updated":"2026-01-05T04:26:46Z","published":"2026-01-05T04:26:46Z","title":"LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment","summary":"Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.","authors":["Arsham Khosravani","Alireza Hosseinpour","Arshia Akhavan","Mehdi Keshani","Abbas Heydarnoori"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10991v3","updated":"2026-01-05T04:14:28Z","published":"2025-08-14T18:00:25Z","title":"MCP-Guard: A Multi-Stage Defense-in-Depth Framework for Securing Model Context Protocol in Agentic AI","summary":"While Large Language Models (LLMs) have achieved remarkable performance, they remain vulnerable to jailbreak. The integration of Large Language Models (LLMs) with external tools via protocols such as the Model Context Protocol (MCP) introduces critical security vulnerabilities, including prompt injection, data exfiltration, and other threats. To counter these challenges, we propose MCP-GUARD, a robust, layered defense architecture designed for LLM-tool interactions. MCP-GUARD employs a three-stage detection pipeline that balances efficiency with accuracy: it progresses from lightweight static scanning for overt threats and a deep neural detector for semantic attacks, to our fine-tuned E5-based model which achieves 96.01\\% accuracy in identifying adversarial prompts. Finally, an LLM arbitrator synthesizes these signals to deliver the final decision. To enable rigorous training and evaluation, we introduce MCP-ATTACKBENCH, a comprehensive benchmark comprising 70,448 samples augmented by GPT-4. This benchmark simulates diverse real-world attack vectors that circumvent conventional defenses in the MCP paradigm, thereby laying a solid foundation for future research on securing LLM-tool ecosystems.","authors":["Wenpeng Xing","Zhonghao Qi","Yupeng Qin","Yilin Li","Caini Chang","Jiahui Yu","Changting Lin","Zhenzhen Xie","Meng Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01774v1","updated":"2026-01-05T04:04:55Z","published":"2026-01-05T04:04:55Z","title":"Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches","summary":"Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.","authors":["Sai Varun Kodathala","Rakesh Vunnam"],"pdf_url":"","comment":"14 pages"},{"id":"http://arxiv.org/abs/2407.01991v5","updated":"2026-01-05T03:59:23Z","published":"2024-07-02T07:06:49Z","title":"Generation of Geodesics with Actor-Critic Reinforcement Learning to Predict Midpoints","summary":"To find the shortest paths for all pairs on manifolds with infinitesimally defined metrics, we introduce a framework to generate them by predicting midpoints recursively. To learn midpoint prediction, we propose an actor-critic approach. We prove the soundness of our approach and show experimentally that the proposed method outperforms existing methods on several planning tasks, including path planning for agents with complex kinematics and motion planning for multi-degree-of-freedom robot arms.","authors":["Kazumi Kasaura"],"pdf_url":"","comment":"17 pages with 8 pages of appendices and references, 9 figures"},{"id":"http://arxiv.org/abs/2601.01765v1","updated":"2026-01-05T03:47:26Z","published":"2026-01-05T03:47:26Z","title":"A New Benchmark for the Appropriate Evaluation of RTL Code Optimization","summary":"The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.","authors":["Yao Lu","Shang Liu","Hangan Zhou","Wenji Fang","Qijun Zhang","Zhiyao Xie"],"pdf_url":"","comment":null}],"Systems and Control":[{"id":"http://arxiv.org/abs/2507.04346v6","updated":"2026-01-05T18:39:22Z","published":"2025-07-06T11:19:34Z","title":"Improving Action Smoothness for a Cascaded Online Learning Flight Control System","summary":"This paper aims to improve the action smoothness of a cascaded online learning flight control system. Although the cascaded structure is widely used in flight control design, its stability can be compromised by oscillatory control actions, which poses challenges for practical engineering applications. To address this issue, we introduce an online temporal smoothness technique and a low-pass filter to reduce the amplitude and frequency of the control actions. Fast Fourier Transform (FFT) is used to analyze policy performance in the frequency domain. Simulation results demonstrate the improvements achieved by the two proposed techniques.","authors":["Yifei Li","Erik-jan van Kampen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02278v1","updated":"2026-01-05T17:09:50Z","published":"2026-01-05T17:09:50Z","title":"Multi-mode Fault Diagnosis Datasets of Three-phase Asynchronous Motor Under Variable Working Conditions","summary":"Three-phase asynchronous motor are fundamental components in industrial systems, and their failure can lead to significant operational downtime and economic losses. Vibration and current signals are effective indicators for monitoring motor health and diagnosing faults. However, motors in real applications often operate under variable conditions such as fluctuating speeds and loads, which complicate the fault diagnosis process. This paper presents a comprehensive dataset collected from a three-phase asynchronous motor under various fault types and severities, operating under diverse speed and load conditions. The dataset includes both single faults and mechanical-electrical compound faults, such as rotor unbalance, stator winding short circuits, bearing faults, and their combinations. Data were acquired under both steady and transitional conditions, with signals including triaxial vibration, three-phase currents, torque, and key-phase signals. This dataset supports the development and validation of robust fault diagnosis methods for electric motors under realistic operating conditions.","authors":["Shijin Chen","Zeyi Liu","Chenyang Li","Dongliang Zou","Xiao He","Donghua Zhou"],"pdf_url":"","comment":"12 pages, 9 figures"},{"id":"http://arxiv.org/abs/2601.02275v1","updated":"2026-01-05T17:05:42Z","published":"2026-01-05T17:05:42Z","title":"Machine Learning Guided Cooling Optimization for Data Centers","summary":"Effective data center cooling is crucial for reliable operation; however, cooling systems often exhibit inefficiencies that result in excessive energy consumption. This paper presents a three-stage, physics-guided machine learning framework for identifying and reducing cooling energy waste in high-performance computing facilities. Using one year of 10-minute resolution operational data from the Frontier exascale supercomputer, we first train a monotonicity-constrained gradient boosting surrogate that predicts facility accessory power from coolant flow rates, temperatures, and server power. The surrogate achieves a mean absolute error of 0.026 MW and predicts power usage effectiveness within 0.01 of measured values for 98.7% of test samples. In the second stage, the surrogate serves as a physics-consistent baseline to quantify excess cooling energy, revealing approximately 85 MWh of annual inefficiency concentrated in specific months, hours, and operating regimes. The third stage evaluates guardrail-constrained counterfactual adjustments to supply temperature and subloop flows, demonstrating that up to 96% of identified excess can be recovered through small, safe setpoint changes while respecting thermal limits and operational constraints. The framework yields interpretable recommendations, supports counterfactual analyses such as flow reduction during low-load periods and redistribution of thermal duty across cooling loops, and provides a practical pathway toward quantifiable reductions in accessory power. The developed framework is readily compatible with model predictive control and can be extended to other liquid-cooled data centers with different configurations and cooling requirements.","authors":["Shrenik Jadhav","Zheng Liu"],"pdf_url":"","comment":"10 pages, 11 figures"},{"id":"http://arxiv.org/abs/2601.02244v1","updated":"2026-01-05T16:25:01Z","published":"2026-01-05T16:25:01Z","title":"Characterizing All Locally Exponentially Stabilizing Controllers as a Linear Feedback Plus Learnable Nonlinear Youla Dynamics","summary":"We derive a state-space characterization of all dynamic state-feedback controllers that make an equilibrium of a nonlinear input-affine continuous-time system locally exponentially stable. Specirically, any controller obtained as the sum of a linear state-feedback $u=Kx$, with $K$ stabilizing the linearized system, and the output of internal locally exponentially stable controller dynamics is itself locally exponentially stabilizing. Conversely, every dynamic state-feedback controller that locally exponentially stabilizes the equilibrium admits such a decomposition. The result can be viewed as a state-space nonlinear Youla-type parametrization specialized to local, rather than global, and exponential, rather than asymptotic, closed-loop stability. The residual locally exponentially stable controller dynamics can be implemented with stable recurrent neural networks and trained as neural ODEs to achieve high closed-loop performance in nonlinear control tasks.","authors":["Luca Furieri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02243v1","updated":"2026-01-05T16:19:30Z","published":"2026-01-05T16:19:30Z","title":"Optimal Dispatch of Electricity and Water in Renewable-Integrated Desalination Plants","summary":"We develop a mathematical framework for the optimal dispatch of flexible water desalination plants (WDPs) as hybrid generator-load resources. WDPs integrate thermal generation, membrane-based controllable loads, and renewable energy sources, offering unique operational flexibility for power system operations. They can simultaneously participate in two markets: selling desalinated water to a water utility, and bidirectionally transacting electricity with the grid based on their net electricity demand. We formulate the dispatch decision problem of a profit-maximizing WDP, capturing operational, technological, and market-based coupling between water and electricity flows. The threshold-based structure we derive provides computationally tractable coordination suitable for large-scale deployment, offering operational insights into how thermal generation and membrane-based loads complementarily provide continuous bidirectional flexibility. The thresholds are analytically characterized in closed form as explicit functions of technology and tariff parameters. We examine how small changes in the exogenous tariff and technology parameters affect the WDP's profit. Extensive simulations illustrate the optimal WDP's operation, profit, and water-electricity exchange, demonstrating significant improvements relative to benchmark algorithms.","authors":["Ahmed S. Alahmed","Audun Botterud","Saurabh Amin","Ali T. Al-Awami"],"pdf_url":"","comment":"14 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.13389v4","updated":"2026-01-05T14:59:50Z","published":"2024-10-17T09:39:32Z","title":"Dynamic Input Mapping Inversion to Eliminate Algebraic Loops in Hydraulic Actuator Control","summary":"The application of nonlinear control schemes to electro-hydraulic actuators often requires several alterations in the design of the controllers during their implementation. This is to overcome challenges that frequently arise in such control algorithms owing to model nonlinearities. Moreover, advanced control solutions for this type of systems often introduce input algebraic loops that pose significant design and tuning difficulties. Conventional methods to avoid such loops introduce chatter, which considerably degrade tracking performance and has oil degradation and wear as side effects. This study presents a nonlinear control architecture for hydraulic actuators that comprises low-complexity modules that facilitate robust high performance in tracking and avoids the drawbacks of chatter. The salient feature is a dynamic input-mapping inversion module that avoids algebraic loops in the control input and is followed by dedicated position control. The stability of the closed-loop system is analyzed using arguments from Lyapunov theory for cascaded non-autonomous nonlinear systems. The effectiveness of the proposed solution is evaluated on a high-fidelity simulator of a wind turbine pitch system, and validated on a full-scale laboratory setup that includes a hydraulic pitch system and blade bearing. Appropriate quantitative metrics are used to evaluate the closed-loop system performance in comparison to a state-of-the-art nonlinear design.","authors":["Alessio Dallabona","Patrik Schermann","Mogens Blanke","Dimitrios Papageorgiou"],"pdf_url":"","comment":"Author version of an article published in IEEE Transactions on Control Systems Technology. The final version is available via DOI"},{"id":"http://arxiv.org/abs/2601.02109v1","updated":"2026-01-05T13:37:52Z","published":"2026-01-05T13:37:52Z","title":"Finite-State Decentralized Policy-Based Control With Guaranteed Ground Coverage","summary":"We propose a finite-state, decentralized decision and control framework for multi-agent ground coverage. The approach decomposes the problem into two coupled components: (i) the structural design of a deep neural network (DNN) induced by the reference configuration of the agents, and (ii) policy-based decentralized coverage control. Agents are classified as anchors and followers, yielding a generic and scalable communication architecture in which each follower interacts with exactly three in-neighbors from the preceding layer, forming an enclosing triangular communication structure. The DNN training weights implicitly encode the spatial configuration of the agent team, thereby providing a geometric representation of the environmental target set. Within this architecture, we formulate a computationally efficient decentralized Markov decision process (MDP) whose components are time-invariant except for a time-varying cost function defined by the deviation from the centroid of the target set contained within each agent communication triangle. By introducing the concept of Anyway Output Controllability (AOC), we assume each agent is AOC and establish decentralized convergence to a desired configuration that optimally represents the environmental target.","authors":["Hossein Rastgoftar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.05293v2","updated":"2026-01-05T13:08:38Z","published":"2025-10-06T19:02:27Z","title":"Pricing Short-Circuit Current via a Primal-Dual Formulation for Preserving Integrality Constraints","summary":"Synchronous Generators (SGs) currently provide important levels of Short-Circuit Current (SCC), a critical ancillary service that ensures line protections trip during short-circuit faults. Given the ongoing replacement of SGs by power-electronics-based generation, which have a hard limit for current injection, it has become relevant to optimize the procurement of SCC provided by remaining SGs. Pricing this service is however challenging due to the integrality constraints in Unit Commitment (UC). Existing methods, e.g., dispatchable pricing, restricted pricing and marginal unit pricing, attempt to address this issue but exhibit limitations in handling binary variables, resulting in SCC prices that either fail to cover the operating costs of units or lack interpretability. To overcome these pitfalls, we propose a primal-dual formulation of the SCC-constrained dispatch that preserves the binary nature of UC while effectively computing shadow prices of SCC services. Using a modified IEEE 30-bus system, a comparison is carried out between the proposed approach and the state-of-the-art pricing schemes, highlighting the advantages of the primal-dual method in preserving UC integrality for SCC pricing.","authors":["Peng Wang","Luis Badesa"],"pdf_url":"","comment":"In the primal-dual pricing method used in the paper, its dual problem is actually dual to dispatchable pricing (except that the dispatchable method discards the nonlinear terms in the SCC constraint). Therefore, there is no essential difference between the two pricing methods"},{"id":"http://arxiv.org/abs/2511.22368v2","updated":"2026-01-05T12:36:28Z","published":"2025-11-27T12:06:49Z","title":"Distributed Koopman Operator Learning for Perception and Safe Navigation","summary":"This paper presents a unified and scalable framework for predictive and safe autonomous navigation in dynamic transportation environments by integrating model predictive control (MPC) with distributed Koopman operator learning. High-dimensional sensory data are employed to model and forecast the motion of surrounding dynamic obstacles. A consensus-based distributed Koopman learning algorithm enables multiple computational agents or sensing units to collaboratively estimate the Koopman operator without centralized data aggregation, thereby supporting large-scale and communication-efficient learning across a networked system. The learned operator predicts future spatial densities of obstacles, which are subsequently represented through Gaussian mixture models. Their confidence ellipses are approximated by convex polytopes and embedded as linear constraints in the MPC formulation to guarantee safe and collision-free navigation. The proposed approach not only ensures obstacle avoidance but also scales efficiently with the number of sensing or computational nodes, aligning with cooperative perception principles in autonomous navigation applications. Theoretical convergence guarantees and predictive constraint formulations are established, and extensive simulations demonstrate reliable, safe, and computationally efficient navigation performance in complex environments.","authors":["Ali Azarbahram","Shenyu Liu","Gian Paolo Incremona"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02053v1","updated":"2026-01-05T12:22:27Z","published":"2026-01-05T12:22:27Z","title":"Ageing Monitoring for Commercial Microcontrollers Based on Timing Windows","summary":"Microcontrollers are increasingly present in embedded deployments and dependable applications, for which malfunctions due to hardware ageing can have severe impact. The lack of deployable techniques for ageing monitoring on these devices has spread the application of guard bands to prevent timing errors due to degradation. Applying this static technique can limit performance and lead to sudden failures as devices age. In this paper, we follow a software-based self-testing approach to design monitoring of hardware degradation for microcontrollers. Deployable in the field, our technique leverages timing windows of variable lengths to determine the maximum operational frequency of the devices. We empirically validate the method on real hardware and find that it consistently detects temperature-induced degradations in maximum operating frequency of up to 13.79 % across devices for 60 °C temperature increase.","authors":["Leandro Lanzieri","Jiri Kral","Goerschwin Fey","Holger Schlarb","Thomas C. Schmidt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.15196v3","updated":"2026-01-05T11:10:07Z","published":"2025-04-21T16:07:32Z","title":"AdGT: Decentralized Gradient Tracking with Tuning-free Per-Agent Stepsize","summary":"In decentralized optimization, the choice of stepsize plays a critical role in algorithm performance. A common approach is to use a shared stepsize across all agents to ensure convergence. However, selecting an optimal stepsize often requires careful tuning, which can be time-consuming and may lead to slow convergence, especially when there is significant variation in the smoothness (L-smoothness) of local objective functions across agents. Individually tuning stepsizes per agent is also impractical, particularly in large-scale networks. To address these limitations, we propose AdGT, an adaptive gradient tracking method that enables each agent to adjust its stepsize based on the smoothness of its local objective. We prove that AdGT achieves linear convergence to the global optimal solution. Through numerical experiments, we compare AdGT with fixed-stepsize gradient tracking methods and demonstrate its superior performance. Additionally, we compare AdGT with adaptive gradient descent (AdGD) in a centralized setting and observe that fully adaptive stepsizes offer greater benefits in decentralized networks than in centralized ones.","authors":["Diyako Ghaderyan","Stefan Werner"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01951v1","updated":"2026-01-05T09:58:12Z","published":"2026-01-05T09:58:12Z","title":"Asymptotic Behavior of an Unforced Duhem-Type Hysteretic Oscillator","summary":"The article describes fundamental analytical properties of an unforced mechanical oscillator with a Duhem-type viscoelastoplastic hysteretic element. These properties include global existence of solutions, uniqueness of solutions, and convergence of each solution to an equilibrium point.","authors":["Mihails Milehins","Dan B. Marghitu"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2601.01940v1","updated":"2026-01-05T09:48:37Z","published":"2026-01-05T09:48:37Z","title":"Policy Optimization with Differentiable MPC: Convergence Analysis under Uncertainty","summary":"Model-based policy optimization is a well-established framework for designing reliable and high-performance controllers across a wide range of control applications. Recently, this approach has been extended to model predictive control policies, where explicit dynamical models are embedded within the control law. However, the performance of the resulting controllers, and the convergence of the associated optimization algorithms, critically depends on the accuracy of the models. In this paper, we demonstrate that combining gradient-based policy optimization with recursive system identification ensures convergence to an optimal controller design and showcase our finding in several control examples.","authors":["Riccardo Zuliani","Efe C. Balta","John Lygeros"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.11869v3","updated":"2026-01-05T06:59:23Z","published":"2025-09-15T12:43:10Z","title":"Convergence Filters for Efficient Economic MPC of Non-dissipative Systems","summary":"This note presents a novel and efficient Economic Model Predictive Control (EMPC) scheme specifically designed for non-dissipative systems subject to state and input constraints. To address the stability challenge of EMPC for constrained non-dissipative systems, a new concept of convergence filters is introduced. Three alternative convergence filters are designed accordingly to be incorporated into the receding horizon optimization problem of EMPC. To improve online computational efficiency, the variable horizon approach without explicit terminal state constraints is adopted. This design allows for a flexible trade-off among convergence speed, economic performance, and computational burden via simple parameter adjustment. Moreover, sufficient conditions are rigorously derived to guarantee recursive feasibility and stability. The advantages of the proposed EMPC are validated through simulations on a classical non-dissipative continuous stirred-tank reactor.","authors":["Defeng He","Weiliang Xiong","Shaoyuan Li","Haiping Du"],"pdf_url":"","comment":"Revised version with updated author list and minor text corrections"},{"id":"http://arxiv.org/abs/2601.01793v1","updated":"2026-01-05T05:06:58Z","published":"2026-01-05T05:06:58Z","title":"Distributed Federated Learning by Alternating Periods of Training","summary":"Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.","authors":["Shamik Bhattacharyya","Rachel Kalpana Kalaimani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01777v1","updated":"2026-01-05T04:17:24Z","published":"2026-01-05T04:17:24Z","title":"A Survey on Applications of Quantum Computing for Unit Commitment","summary":"Unit Commitment (UC) is a core optimization problem in power system operation and electricity market scheduling. It determines the optimal on/off status and dispatch of generating units while satisfying system, operational, and market constraints. Traditionally, UC has been solved using mixed-integer programming, dynamic programming, or metaheuristic methods, all of which face scalability challenges as systems grow in size and uncertainty. Recent advances in quantum computing, spanning quantum annealing, variational algorithms, and hybrid quantum classical optimization, have opened new opportunities to accelerate UC solution processes by exploiting quantum parallelism and entanglement. This paper presents a comprehensive survey of existing research on the applications of quantum computing for solving the UC problem. The reviewed works are categorized based on the employed quantum paradigms, including annealing-based, variational hybrid, quantum machine learning, and quantum-inspired methods. Key modeling strategies, hardware implementations, and computational trade-offs are discussed, highlighting the current progress, limitations, and potential future directions for large-scale quantum-enabled UC.","authors":["Milad Hasanzadeh","Ali Rajabi","Amin Kargarian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01772v1","updated":"2026-01-05T04:03:35Z","published":"2026-01-05T04:03:35Z","title":"EdgeSSVEP: A Fully Embedded SSVEP BCI Platform for Low-Power Real-Time Applications","summary":"Brain-Computer Interfaces (BCIs) enable users to interact with machines directly via neural activity, yet their real-world deployment is often hindered by bulky and powerhungry hardware. We present EdgeSSVEP, a fully embedded microcontroller-based Steady-State Visually Evoked Potential (SSVEP) BCI platform that performs real-time EEG acquisition, zero-phase filtering, and on-device classification within a lowpower 240 MHz MCU operating at only 222 mW. The system incorporates an 8-channel EEG front end, supports 5-second stimulus durations, and executes the entire SSVEP decoding pipeline locally, eliminating dependence on PC-based processing. EdgeSSVEP was evaluated using six stimulus frequencies (7, 8, 9, 11, 7.5, and 8.5 Hz) with 10 participants. The device achieved 99.17% classification accuracy and 27.33 bits/min Information Transfer Rate (ITR), while consuming substantially less power than conventional desktop-based systems. The system integrates motion sensing to support artifact detection and improve robustness and signal stability in practical environments. For development and debugging, the system also provides optional TCP data streaming to external clients. Overall, EdgeSSVEP offers a scalable, energy-efficient, and secure embedded BCI platform suitable for assistive communication and neurofeedback applications, with potential extensions to accelerometer-based artifact mitigation and broader real-world deployments.","authors":["Manh-Dat Nguyen","Thomas Do","Nguyen Thanh Trung Le","Xuan-The Tran","Fred Chang","Chin-Teng Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.15572v3","updated":"2026-01-05T03:31:35Z","published":"2024-08-28T06:56:56Z","title":"Sufficient and Necessary Barrier-like Conditions for Safety and Reach-avoid Verification of Stochastic Discrete-time Systems","summary":"This paper investigates necessary and sufficient barrier-like conditions for infinite-horizon safety and reach-avoid verification of stochastic discrete-time systems, derived via a relaxation of the Bellman equations. Unlike prior approaches that primarily focus on sufficient conditions, our work rigorously establishes both necessity and sufficiency for infinite-horizon properties. Safety verification concerns certifying that, starting from a given initial state, the system remains within a safe set at all future time steps with probability at least equal to a specified threshold. For this purpose, we formulate a necessary and sufficient barrier-like condition that captures this infinite-time safety property. In contrast, reach-avoid verification generalizes safety verification by also incorporating reachability. Specifically, it aims to ensure that the probability of the system, starting from a given initial state, eventually reaching a target set while remaining within the safe set until the first hit of the target is no less than a prescribed bound. Under suitable assumptions, we establish two necessary and sufficient barrier-like conditions for this reach-avoid specification.","authors":["Bai Xue"],"pdf_url":"","comment":"This paper has been accepted for publication in the journal Automatica"},{"id":"http://arxiv.org/abs/2601.01726v1","updated":"2026-01-05T02:04:39Z","published":"2026-01-05T02:04:39Z","title":"Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions","summary":"Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.","authors":["Wenhui Chu","Aobo Jin","Hardik A. Gohel"],"pdf_url":"","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2507.23139v2","updated":"2026-01-05T00:46:21Z","published":"2025-07-30T22:40:15Z","title":"Robust Control Design and Analysis Based on Lifting Linearization of Nonlinear Systems Under Uncertain Initial Conditions","summary":"This paper presents a robust control synthesis and analysis framework for nonlinear systems with uncertain initial conditions. First, a deep learning-based lifting approach is proposed to approximate nonlinear dynamical systems with linear parameter-varying (LPV) state-space models in higher-dimensional spaces while simultaneously characterizing the uncertain initial states within the lifted state space. Then, convex synthesis conditions are provided to generate full-state feedback nonstationary LPV (NSLPV) controllers for the lifted LPV system. A performance measure similar to the l2-induced norm is used to provide robust performance guarantees in the presence of exogenous disturbances and uncertain initial conditions. The paper also includes results for synthesizing full-state feedback linear time-invariant controllers and output feedback NSLPV controllers. Additionally, a robustness analysis approach based on integral quadratic constraint (IQC) theory is developed to analyze and tune the synthesized controllers while accounting for noise associated with state measurements. This analysis approach characterizes model parameters and disturbance inputs using IQCs to reduce conservatism. Finally, the effectiveness of the proposed framework is demonstrated through two illustrative examples.","authors":["Sourav Sinha","Mazen Farhood"],"pdf_url":"","comment":"Published in the International Journal of Robust and Nonlinear Control. This version incorporates minor revisions from peer review, including a slightly modified title"}],"Robotics":[{"id":"http://arxiv.org/abs/2512.19567v2","updated":"2026-01-05T18:58:56Z","published":"2025-12-22T16:50:10Z","title":"LIMOncello: Iterated Error-State Kalman Filter on the SGal(3) Manifold for Fast LiDAR-Inertial Odometry","summary":"This work introduces LIMOncello, a tightly coupled LiDAR-Inertial Odometry system that models 6-DoF motion on the $\\mathrm{SGal}(3)$ manifold within an iterated error-state Kalman filter backend. Compared to state representations defined on $\\mathrm{SO}(3)\\times\\mathbb{R}^6$, the use of $\\mathrm{SGal}(3)$ provides a coherent and numerically stable discrete-time propagation model that helps limit drift in low-observability conditions.\n  LIMOncello also includes a lightweight incremental i-Octree mapping backend that enables faster updates and substantially lower memory usage than incremental kd-tree style map structures, without relying on locality-restricted search heuristics. Experiments on multiple real-world datasets show that LIMOncello achieves competitive accuracy while improving robustness in geometrically sparse environments. The system maintains real-time performance with stable memory growth and is released as an extensible open-source implementation at https://github.com/CPerezRuiz335/LIMOncello.","authors":["Carlos Pérez-Ruiz","Joan Solà"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02295v1","updated":"2026-01-05T17:31:01Z","published":"2026-01-05T17:31:01Z","title":"CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding","summary":"Current work on robot failure detection and correction typically operate in a post hoc manner, analyzing errors and applying corrections only after failures occur. This work introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction, the capability to anticipate incipient failures and recover before they fully manifest during execution. CycleVLA achieves this by integrating a progress-aware VLA that flags critical subtask transition points where failures most frequently occur, a VLM-based failure predictor and planner that triggers subtask backtracking upon predicted failure, and a test-time scaling strategy based on Minimum Bayes Risk (MBR) decoding to improve retry success after backtracking. Extensive experiments show that CycleVLA improves performance for both well-trained and under-trained VLAs, and that MBR serves as an effective zero-shot test-time scaling strategy for VLAs. Project Page: https://dannymcy.github.io/cyclevla/","authors":["Chenyang Ma","Guangyu Yang","Kai Lu","Shitong Xu","Bill Byrne","Niki Trigoni","Andrew Markham"],"pdf_url":"","comment":"Project Page: https://dannymcy.github.io/cyclevla/"},{"id":"http://arxiv.org/abs/2506.18960v3","updated":"2026-01-05T17:18:57Z","published":"2025-06-23T17:50:58Z","title":"FORTE: Tactile Force and Slip Sensing on Compliant Fingers for Delicate Manipulation","summary":"Handling fragile objects remains a major challenge for robotic manipulation. Tactile sensing and soft robotics can improve delicate object handling, but typically involve high integration complexity or slow response times. We address these issues through FORTE, an easy-to-fabricate tactile sensing system. FORTE uses 3D-printed fin-ray grippers with internal air channels to provide low-latency force and slip feedback. This feedback allows us to apply just enough force to grasp objects without damaging them. We accurately estimate grasping forces from 0-8 N with an average error of 0.2 N, and detect slip events within 100 ms of occurring. FORTE can grasp a wide range of slippery, fragile, and deformable objects, including raspberries and potato chips with 92% success and achieves 93% accuracy in detecting slip events. These results highlight FORTE's potential as a robust solution for delicate robotic manipulation. Project page: https://merge-lab.github.io/FORTE/","authors":["Siqi Shang","Mingyo Seo","Yuke Zhu","Lillian Chin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.22042v2","updated":"2026-01-05T16:27:28Z","published":"2025-11-27T02:55:00Z","title":"Volume-Consistent Kneading-Based Deformation Manufacturing for Material-Efficient Shaping","summary":"Conventional subtractive manufacturing inevitably involves material loss during geometric realization, while additive manufacturing still suffers from limitations in surface quality, process continuity, and productivity when fabricating complex geometries. To address these challenges, this paper proposes a volume-consistent kneading-based forming method for plastic materials, enabling continuous and controllable three-dimensional deformation under mass conservation. An integrated kneading-based manufacturing system is developed, in which geometry-aware kneading command generation, layer-wise kneading execution, and in-process point-cloud scanning are tightly coupled to form a closed-loop workflow of scanning, forming, and feedback compensation. Target geometries are analyzed through layer-wise point-cloud processing and classified into enveloping and non-enveloping types. Accordingly, an Envelope Shaping First strategy and a Similar Gradient Method are adopted to ensure stable material flow and continuous deformation. An RMSE-based compensation scheme is further introduced to correct systematic geometric deviations induced by elastic rebound and material redistribution. Experimental validation on five representative geometries demonstrates high geometric fidelity, with material utilization consistently exceeding 98%. The results indicate that kneading-based forming provides a promising alternative manufacturing paradigm for low-waste, customizable production.","authors":["Lei Li","Jiale Gong","Ziyang Li","Hong Wang"],"pdf_url":"","comment":"39 pages, 31 figures"},{"id":"http://arxiv.org/abs/2601.00126v2","updated":"2026-01-05T15:30:54Z","published":"2025-12-31T22:03:19Z","title":"Compositional Diffusion with Guided Search for Long-Horizon Planning","summary":"Generative models have emerged as powerful tools for planning, with compositional approaches offering particular promise for modeling long-horizon task distributions by composing together local, modular generative models. This compositional paradigm spans diverse domains, from multi-step manipulation planning to panoramic image synthesis to long video generation. However, compositional generative models face a critical challenge: when local distributions are multimodal, existing composition methods average incompatible modes, producing plans that are neither locally feasible nor globally coherent. We propose Compositional Diffusion with Guided Search (CDGS), which addresses this mode averaging problem by embedding search directly within the diffusion denoising process. Our method explores diverse combinations of local modes through population-based sampling, prunes infeasible candidates using likelihood-based filtering, and enforces global consistency through iterative resampling between overlapping segments. CDGS matches oracle performance on seven robot manipulation tasks, outperforming baselines that lack compositionality or require long-horizon training data. The approach generalizes across domains, enabling coherent text-guided panoramic images and long videos through effective local-to-global message passing. More details: https://cdgsearch.github.io/","authors":["Utkarsh A Mishra","David He","Yongxin Chen","Danfei Xu"],"pdf_url":"","comment":"38 pages, 18 figures"},{"id":"http://arxiv.org/abs/2512.06935v2","updated":"2026-01-05T15:21:27Z","published":"2025-12-07T17:33:16Z","title":"Interconnection and Damping Assignment Passivity-Based Control using Sparse Neural ODEs","summary":"Interconnection and Damping Assignment Passivity-Based Control (IDA-PBC) is a nonlinear control technique that assigns a port-Hamiltonian (pH) structure to a controlled system using a state-feedback law. While IDA-PBC has been extensively studied and applied to many systems, its practical implementation often remains confined to academic examples and, almost exclusively, to stabilization tasks. The main limitation of IDA-PBC stems from the complexity of analytically solving a set of partial differential equations (PDEs), referred to as the matching conditions, which enforce the pH structure of the closed-loop system. However, this is extremely challenging, especially for complex physical systems and tasks.\n  In this work, we propose a novel numerical approach for designing IDA-PBC controllers without solving the matching PDEs exactly. We cast the IDA-PBC problem as the learning of a neural ordinary differential equation. In particular, we rely on sparse dictionary learning to parametrize the desired closed-loop system as a sparse linear combination of nonlinear state-dependent functions. Optimization of the controller parameters is achieved by solving a multi-objective optimization problem whose cost function is composed of a generic task-dependent cost and a matching condition-dependent cost. Our numerical results show that the proposed method enables (i) IDA-PBC to be applicable to complex tasks beyond stabilization, such as the discovery of periodic oscillatory behaviors, (ii) the derivation of closed-form expressions of the controlled system, including residual terms in case of approximate matching, and (iii) stability analysis of the learned controller.","authors":["Nicolò Botteghi","Owen Brook","Urban Fasel","Federico Califano"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02184v1","updated":"2026-01-05T15:03:55Z","published":"2026-01-05T15:03:55Z","title":"Differential Barometric Altimetry for Submeter Vertical Localization and Floor Recognition Indoors","summary":"Accurate altitude estimation and reliable floor recognition are critical for mobile robot localization and navigation within complex multi-storey environments. In this paper, we present a robust, low-cost vertical estimation framework leveraging differential barometric sensing integrated within a fully ROS-compliant software package. Our system simultaneously publishes real-time altitude data from both a stationary base station and a mobile sensor, enabling precise and drift-free vertical localization. Empirical evaluations conducted in challenging scenarios -- such as fully enclosed stairwells and elevators, demonstrate that our proposed barometric pipeline achieves sub-meter vertical accuracy (RMSE: 0.29 m) and perfect (100%) floor-level identification. In contrast, our results confirm that standalone height estimates, obtained solely from visual- or LiDAR-based SLAM odometry, are insufficient for reliable vertical localization. The proposed ROS-compatible barometric module thus provides a practical and cost-effective solution for robust vertical awareness in real-world robotic deployments. The implementation of our method is released as open source at https://github.com/witsir/differential-barometric.","authors":["Yuhang Zhang","Sören Schwertfeger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24470v2","updated":"2026-01-05T14:30:28Z","published":"2025-12-30T21:20:41Z","title":"Foundation models on the bridge: Semantic hazard detection and safety maneuvers for maritime autonomy with vision-language models","summary":"The draft IMO MASS Code requires autonomous and remotely supervised maritime vessels to detect departures from their operational design domain, enter a predefined fallback that notifies the operator, permit immediate human override, and avoid changing the voyage plan without approval. Meeting these obligations in the alert-to-takeover gap calls for a short-horizon, human-overridable fallback maneuver. Classical maritime autonomy stacks struggle when the correct action depends on meaning (e.g., diver-down flag means people in the water, fire close by means hazard). We argue (i) that vision-language models (VLMs) provide semantic awareness for such out-of-distribution situations, and (ii) that a fast-slow anomaly pipeline with a short-horizon, human-overridable fallback maneuver makes this practical in the handover window. We introduce Semantic Lookout, a camera-only, candidate-constrained VLM fallback maneuver selector that selects one cautious action (or station-keeping) from water-valid, world-anchored trajectories under continuous human authority. On 40 harbor scenes we measure per-call scene understanding and latency, alignment with human consensus (model majority-of-three voting), short-horizon risk-relief on fire hazard scenes, and an on-water alert->fallback maneuver->operator handover. Sub-10 s models retain most of the awareness of slower state-of-the-art models. The fallback maneuver selector outperforms geometry-only baselines and increases standoff distance on fire scenes. A field run verifies end-to-end operation. These results support VLMs as semantic fallback maneuver selectors compatible with the draft IMO MASS Code, within practical latency budgets, and motivate future work on domain-adapted, hybrid autonomy that pairs foundation-model semantics with multi-sensor bird's-eye-view perception and short-horizon replanning. Website: kimachristensen.github.io/bridge_policy","authors":["Kim Alexander Christensen","Andreas Gudahl Tufte","Alexey Gusev","Rohan Sinha","Milan Ganai","Ole Andreas Alsos","Marco Pavone","Martin Steinert"],"pdf_url":"","comment":"17 pages without bibliography or appendix. The main paper has 16 figures. Paper webpage can be found at https://kimachristensen.github.io/bridge_policy/"},{"id":"http://arxiv.org/abs/2601.02125v1","updated":"2026-01-05T13:56:36Z","published":"2026-01-05T13:56:36Z","title":"SingingBot: An Avatar-Driven System for Robotic Face Singing Performance","summary":"Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.","authors":["Zhuoxiong Xu","Xuanchen Li","Yuhao Cheng","Fei Xu","Yichao Yan","Xiaokang Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02085v1","updated":"2026-01-05T13:12:42Z","published":"2026-01-05T13:12:42Z","title":"Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots","summary":"Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.","authors":["Meili Sun","Chunjiang Zhao","Lichao Yang","Hao Liu","Shimin Hu","Ya Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02082v1","updated":"2026-01-05T13:10:32Z","published":"2026-01-05T13:10:32Z","title":"Realistic adversarial scenario generation via human-like pedestrian model for autonomous vehicle control parameter optimisation","summary":"Autonomous vehicles (AVs) are rapidly advancing and are expected to play a central role in future mobility. Ensuring their safe deployment requires reliable interaction with other road users, not least pedestrians. Direct testing on public roads is costly and unsafe for rare but critical interactions, making simulation a practical alternative. Within simulation-based testing, adversarial scenarios are widely used to probe safety limits, but many prioritise difficulty over realism, producing exaggerated behaviours which may result in AV controllers that are overly conservative. We propose an alternative method, instead using a cognitively inspired pedestrian model featuring both inter-individual and intra-individual variability to generate behaviourally plausible adversarial scenarios. We provide a proof of concept demonstration of this method's potential for AV control optimisation, in closed-loop testing and tuning of an AV controller. Our results show that replacing the rule-based CARLA pedestrian with the human-like model yields more realistic gap acceptance patterns and smoother vehicle decelerations. Unsafe interactions occur only for certain pedestrian individuals and conditions, underscoring the importance of human variability in AV testing. Adversarial scenarios generated by this model can be used to optimise AV control towards safer and more efficient behaviour. Overall, this work illustrates how incorporating human-like road user models into simulation-based adversarial testing can enhance the credibility of AV evaluation and provide a practical basis to behaviourally informed controller optimisation.","authors":["Yueyang Wang","Mehmet Dogar","Gustav Markkula"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02078v1","updated":"2026-01-05T12:59:39Z","published":"2026-01-05T12:59:39Z","title":"Genie Sim 3.0 : A High-Fidelity Comprehensive Simulation Platform for Humanoid Robot","summary":"The development of robust and generalizable robot learning models is critically contingent upon the availability of large-scale, diverse training data and reliable evaluation benchmarks. Collecting data in the physical world poses prohibitive costs and scalability challenges, and prevailing simulation benchmarks frequently suffer from fragmentation, narrow scope, or insufficient fidelity to enable effective sim-to-real transfer. To address these challenges, we introduce Genie Sim 3.0, a unified simulation platform for robotic manipulation. We present Genie Sim Generator, a large language model (LLM)-powered tool that constructs high-fidelity scenes from natural language instructions. Its principal strength resides in rapid and multi-dimensional generalization, facilitating the synthesis of diverse environments to support scalable data collection and robust policy evaluation. We introduce the first benchmark that pioneers the application of LLM for automated evaluation. It leverages LLM to mass-generate evaluation scenarios and employs Vision-Language Model (VLM) to establish an automated assessment pipeline. We also release an open-source dataset comprising more than 10,000 hours of synthetic data across over 200 tasks. Through systematic experimentation, we validate the robust zero-shot sim-to-real transfer capability of our open-source dataset, demonstrating that synthetic data can server as an effective substitute for real-world data under controlled conditions for scalable policy training. For code and dataset details, please refer to: https://github.com/AgibotTech/genie_sim.","authors":["Chenghao Yin","Da Huang","Di Yang","Jichao Wang","Nanshu Zhao","Chen Xu","Wenjun Sun","Linjie Hou","Zhijun Li","Junhui Wu","Zhaobo Liu","Zhen Xiao","Sheng Zhang","Lei Bao","Rui Feng","Zhenquan Pang","Jiayu Li","Qian Wang","Maoqing Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01989v1","updated":"2026-01-05T10:48:12Z","published":"2026-01-05T10:48:12Z","title":"VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis","summary":"Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.","authors":["Aly R. Elkammar","Karim M. Gamaleldin","Catherine M. Elias"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01971v1","updated":"2026-01-05T10:26:26Z","published":"2026-01-05T10:26:26Z","title":"Deep Robust Koopman Learning from Noisy Data","summary":"Koopman operator theory has emerged as a leading data-driven approach that relies on a judicious choice of observable functions to realize global linear representations of nonlinear systems in the lifted observable space. However, real-world data is often noisy, making it difficult to obtain an accurate and unbiased approximation of the Koopman operator. The Koopman operator generated from noisy datasets is typically corrupted by noise-induced bias that severely degrades prediction and downstream tracking performance. In order to address this drawback, this paper proposes a novel autoencoder-based neural architecture to jointly learn the appropriate lifting functions and the reduced-bias Koopman operator from noisy data. The architecture initially learns the Koopman basis functions that are consistent for both the forward and backward temporal dynamics of the system. Subsequently, by utilizing the learned forward and backward temporal dynamics, the Koopman operator is synthesized with a reduced bias making the method more robust to noise compared to existing techniques. Theoretical analysis is used to demonstrate significant bias reduction in the presence of training noise. Dynamics prediction and tracking control simulations are conducted for multiple serial manipulator arms, including performance comparisons with leading alternative designs, to demonstrate its robustness under various noise levels. Experimental studies with the Franka FR3 7-DoF manipulator arm are further used to demonstrate the effectiveness of the proposed approach in a practical setting.","authors":["Aditya Singh","Rajpal Singh","Jishnu Keshavan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01969v1","updated":"2026-01-05T10:22:58Z","published":"2026-01-05T10:22:58Z","title":"What you reward is what you learn: Comparing rewards for online speech policy optimization in public HRI","summary":"Designing policies that are both efficient and acceptable for conversational service robots in open and diverse environments is non-trivial. Unlike fixed, hand-tuned parameters, online learning can adapt to non-stationary conditions. In this paper, we study how to adapt a social robot's speech policy in the wild. During a 12-day in-situ deployment with over 1,400 public encounters, we cast online policy optimization as a multi-armed bandit problem and use Thompson sampling to select among six actions defined by speech rate (slow/normal/fast) and verbosity (concise/detailed). We compare three complementary binary rewards--Ru (user rating), Rc (conversation closure), and Rt (>=2 turns)--and show that each induces distinct arm distributions and interaction behaviors. We complement the online results with offline evaluations that analyze contextual factors (e.g., crowd level, group size) using video-annotated data. Taken together, we distill ready-to-use design lessons for deploying online optimization of speech policies in real public HRI settings.","authors":["Sichao Song","Yuki Okafuji","Kaito Ariu","Amy Koike"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.12752v3","updated":"2026-01-05T09:57:35Z","published":"2025-05-19T06:20:37Z","title":"MOON: Multi-Objective Optimization-Driven Object-Goal Navigation Using a Variable-Horizon Set-Orienteering Planner","summary":"This paper proposes MOON (Multi-Objective Optimization-driven Object-goal Navigation), a novel framework designed for efficient navigation in large-scale, complex indoor environments. While existing methods often rely on local heuristics, they frequently fail to address the strategic trade-offs between competing objectives in vast areas. To overcome this, we formulate the task as a multi-objective optimization problem (MOO) that balances frontier-based exploration with the exploitation of observed landmarks. Our prototype integrates three key pillars: (1) QOM [IROS05] for discriminative landmark encoding; (2) StructNav [RSS23] to enhance the navigation pipeline; and (3) a variable-horizon Set Orienteering Problem (SOP) formulation for globally coherent planning. To further support the framework's scalability, we provide a detailed theoretical foundation for the budget-constrained SOP formulation and the data-driven mode-switching strategy that enables long-horizon resource allocation. Additionally, we introduce a high-speed neural planner that distills the expert solver into a transformer-based model, reducing decision latency by a factor of nearly 10 while maintaining high planning quality.","authors":["Daigo Nakajima","Kanji Tanaka","Daiki Iwata","Kouki Terashima"],"pdf_url":"","comment":"9 pages, 7 figures, technical report"},{"id":"http://arxiv.org/abs/2601.01948v1","updated":"2026-01-05T09:56:24Z","published":"2026-01-05T09:56:24Z","title":"Learning Diffusion Policy from Primitive Skills for Robot Manipulation","summary":"Diffusion policies (DP) have recently shown great promise for generating actions in robotic manipulation. However, existing approaches often rely on global instructions to produce short-term control signals, which can result in misalignment in action generation. We conjecture that the primitive skills, referred to as fine-grained, short-horizon manipulations, such as ``move up'' and ``open the gripper'', provide a more intuitive and effective interface for robot learning. To bridge this gap, we propose SDP, a skill-conditioned DP that integrates interpretable skill learning with conditional action planning. SDP abstracts eight reusable primitive skills across tasks and employs a vision-language model to extract discrete representations from visual observations and language instructions. Based on them, a lightweight router network is designed to assign a desired primitive skill for each state, which helps construct a single-skill policy to generate skill-aligned actions. By decomposing complex tasks into a sequence of primitive skills and selecting a single-skill policy, SDP ensures skill-consistent behavior across diverse tasks. Extensive experiments on two challenging simulation benchmarks and real-world robot deployments demonstrate that SDP consistently outperforms SOTA methods, providing a new paradigm for skill-based robot learning with diffusion policies.","authors":["Zhihao Gu","Ming Yang","Difan Zou","Dong Xu"],"pdf_url":"","comment":"Accepted to AAAI2026"},{"id":"http://arxiv.org/abs/2601.01946v1","updated":"2026-01-05T09:54:33Z","published":"2026-01-05T09:54:33Z","title":"From Metrics to Meaning: Insights from a Mixed-Methods Field Experiment on Retail Robot Deployment","summary":"We report a mixed-methods field experiment of a conversational service robot deployed under everyday staffing discretion in a live bedding store. Over 12 days we alternated three conditions--Baseline (no robot), Robot-only, and Robot+Fixture--and video-annotated the service funnel from passersby to purchase. An explanatory sequential design then used six post-experiment staff interviews to interpret the quantitative patterns.\n  Quantitatively, the robot increased stopping per passerby (highest with the fixture), yet clerk-led downstream steps per stopper--clerk approach, store entry, assisted experience, and purchase--decreased. Interviews explained this divergence: clerks avoided interrupting ongoing robot-customer talk, struggled with ambiguous timing amid conversational latency, and noted child-centered attraction that often satisfied curiosity at the doorway. The fixture amplified visibility but also anchored encounters at the threshold, creating a well-defined micro-space where needs could ``close'' without moving inside.\n  We synthesize these strands into an integrative account from the initial show of interest on the part of a customer to their entering the store and derive actionable guidance. The results advance the understanding of interactions between customers, staff members, and the robot and offer practical recommendations for deploying service robots in high-touch retail.","authors":["Sichao Song","Yuki Okafuji","Takuya Iwamoto","Jun Baba","Hiroshi Ishiguro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.02256v2","updated":"2026-01-05T09:31:25Z","published":"2025-03-04T04:13:23Z","title":"Multi-Robot Data-Free Continual Communicative Learning (CCL) from Black-Box Visual Place Recognition Models","summary":"In emerging multi-robot societies, heterogeneous agents must continually extract and integrate local knowledge from one another through communication, even when their internal models are completely opaque. Existing approaches to continual or collaborative learning for visual place recognition (VPR) largely assume white-box access to model parameters or shared training datasets, which is unrealistic when robots encounter unknown peers in the wild. This paper introduces \\emph{Continual Communicative Learning (CCL)}, a data-free multi-robot framework in which a traveler robot (student) continually improves its VPR capability by communicating with black-box teacher models via a constrained query--response channel. We repurpose Membership Inference Attacks (MIA), originally developed as privacy attacks on machine learning models, as a constructive communication primitive to reconstruct pseudo-training sets from black-box VPR teachers without accessing their parameters or raw data. To overcome the intrinsic communication bottleneck caused by the low sampling efficiency of black-box MIA, we propose a prior-based query strategy that leverages the student's own VPR prior to focus queries on informative regions of the embedding space, thereby reducing the knowledge transfer (KT) cost. Experimental results on a standard multi-session VPR benchmark demonstrate that the proposed CCL framework yields substantial performance gains for low-performing robots under modest communication budgets, highlighting CCL as a promising building block for scalable and fault-tolerant multi-robot systems.","authors":["Kenta Tsukahara","Kanji Tanaka","Daiki Iwata","Jonathan Tay Yu Liang"],"pdf_url":"","comment":"6 pages, 4 figures, technical report"},{"id":"http://arxiv.org/abs/2411.18539v2","updated":"2026-01-05T09:17:12Z","published":"2024-11-27T17:36:08Z","title":"AdaVLN: Towards Visual Language Navigation in Continuous Indoor Environments with Moving Humans","summary":"Visual Language Navigation is a task that challenges robots to navigate in realistic environments based on natural language instructions. While previous research has largely focused on static settings, real-world navigation must often contend with dynamic human obstacles. Hence, we propose an extension to the task, termed Adaptive Visual Language Navigation (AdaVLN), which seeks to narrow this gap. AdaVLN requires robots to navigate complex 3D indoor environments populated with dynamically moving human obstacles, adding a layer of complexity to navigation tasks that mimic the real-world. To support exploration of this task, we also present AdaVLN simulator and AdaR2R datasets. The AdaVLN simulator enables easy inclusion of fully animated human models directly into common datasets like Matterport3D. We also introduce a \"freeze-time\" mechanism for both the navigation task and simulator, which pauses world state updates during agent inference, enabling fair comparisons and experimental reproducibility across different hardware. We evaluate several baseline models on this task, analyze the unique challenges introduced by AdaVLN, and demonstrate its potential to bridge the sim-to-real gap in VLN research.","authors":["Dillon Loh","Tomasz Bednarz","Xinxing Xia","Frank Guan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.04415v3","updated":"2026-01-05T09:02:01Z","published":"2025-12-04T03:24:03Z","title":"RoboBPP: Benchmarking Robotic Online Bin Packing with Physics-based Simulation","summary":"Physical feasibility in 3D bin packing is a key requirement in modern industrial logistics and robotic automation. With the growing adoption of industrial automation, online bin packing has gained increasing attention. However, inconsistencies in problem settings, test datasets, and evaluation metrics have hindered progress in the field, and there is a lack of a comprehensive benchmarking system. Direct testing on real hardware is costly, and building a realistic simulation environment is also challenging. To address these limitations, we introduce RoboBPP, a benchmarking system designed for robotic online bin packing. RoboBPP integrates a physics-based simulator to assess physical feasibility. In our simulation environment, we introduce a robotic arm and boxes at real-world scales to replicate real industrial packing workflows. By simulating conditions that arise in real industrial applications, we ensure that evaluated algorithms are practically deployable. In addition, prior studies often rely on synthetic datasets whose distributions differ from real-world industrial data. To address this issue, we collect three datasets from real industrial workflows, including assembly-line production, logistics packing, and furniture manufacturing. The benchmark comprises three carefully designed test settings and extends existing evaluation metrics with new metrics for structural stability and operational safety. We design a scoring system and derive a range of insights from the evaluation results. RoboBPP is fully open-source and is equipped with visualization tools and an online leaderboard, providing a reproducible and extensible foundation for future research and industrial applications (https://robot-bin-packing-benchmark.github.io).","authors":["Zhoufeng Wang","Hang Zhao","Juzhan Xu","Shishun Zhang","Zeyu Xiong","Ruizhen Hu","Chenyang Zhu","Zecui Zeng","Kai Xu"],"pdf_url":"","comment":"Under review at the International Journal of Robotics Research (IJRR)"},{"id":"http://arxiv.org/abs/2601.01872v1","updated":"2026-01-05T08:00:34Z","published":"2026-01-05T08:00:34Z","title":"CausalNav: A Long-term Embodied Navigation System for Autonomous Mobile Robots in Dynamic Outdoor Scenarios","summary":"Autonomous language-guided navigation in large-scale outdoor environments remains a key challenge in mobile robotics, due to difficulties in semantic reasoning, dynamic conditions, and long-term stability. We propose CausalNav, the first scene graph-based semantic navigation framework tailored for dynamic outdoor environments. We construct a multi-level semantic scene graph using LLMs, referred to as the Embodied Graph, that hierarchically integrates coarse-grained map data with fine-grained object entities. The constructed graph serves as a retrievable knowledge base for Retrieval-Augmented Generation (RAG), enabling semantic navigation and long-range planning under open-vocabulary queries. By fusing real-time perception with offline map data, the Embodied Graph supports robust navigation across varying spatial granularities in dynamic outdoor environments. Dynamic objects are explicitly handled in both the scene graph construction and hierarchical planning modules. The Embodied Graph is continuously updated within a temporal window to reflect environmental changes and support real-time semantic navigation. Extensive experiments in both simulation and real-world settings demonstrate superior robustness and efficiency.","authors":["Hongbo Duan","Shangyi Luo","Zhiyuan Deng","Yanbo Chen","Yuanhao Chiang","Yi Liu","Fangming Liu","Xueqian Wang"],"pdf_url":"","comment":"Accepted by IEEE Robotics and Automation Letters (RA-L)"},{"id":"http://arxiv.org/abs/2601.01822v1","updated":"2026-01-05T06:31:24Z","published":"2026-01-05T06:31:24Z","title":"DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization","summary":"Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.","authors":["Shiyong Meng","Tao Zou","Bolei Chen","Chaoxu Mu","Jianxin Wang"],"pdf_url":"","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2505.02294v3","updated":"2026-01-05T05:57:23Z","published":"2025-05-04T23:43:44Z","title":"RNBF: Real-Time RGB-D Based Neural Barrier Functions for Safe Robotic Navigation","summary":"Autonomous safe navigation in unstructured and novel environments poses significant challenges, especially when environment information can only be provided through low-cost vision sensors. Although safe reactive approaches have been proposed to ensure robot safety in complex environments, many base their theory off the assumption that the robot has prior knowledge on obstacle locations and geometries. In this paper, we present a real-time, vision-based framework that constructs continuous, first-order differentiable Signed Distance Fields (SDFs) of unknown environments entirely online, without any pre-training, and is fully compatible with established SDF-based reactive controllers. To achieve robust performance under practical sensing conditions, our approach explicitly accounts for noise in affordable RGB-D cameras, refining the neural SDF representation online for smoother geometry and stable gradient estimates. We validate the proposed method in simulation and real-world experiments using a Fetch robot. Videos and supplementary material are available at https://satyajeetburla.github.io/rnbf/.","authors":["Satyajeet Das","Yifan Xue","Haoming Li","Nadia Figueroa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23162v3","updated":"2026-01-05T04:58:32Z","published":"2025-12-29T03:03:00Z","title":"SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling","summary":"Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.","authors":["Yufan He","Pengfei Guo","Mengya Xu","Zhaoshuo Li","Andriy Myronenko","Dillan Imans","Bingjie Liu","Dongren Yang","Mingxue Gu","Yongnan Ji","Yueming Jin","Ren Zhao","Baiyong Shen","Daguang Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01762v1","updated":"2026-01-05T03:41:20Z","published":"2026-01-05T03:41:20Z","title":"AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving","summary":"End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety","authors":["Yanhao Wu","Haoyang Zhang","Fei He","Rui Wu","Congpei Qiu","Liang Gao","Wei Ke","Tong Zhang"],"pdf_url":"","comment":"underreview"},{"id":"http://arxiv.org/abs/2601.01726v1","updated":"2026-01-05T02:04:39Z","published":"2026-01-05T02:04:39Z","title":"Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions","summary":"Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.","authors":["Wenhui Chu","Aobo Jin","Hardik A. Gohel"],"pdf_url":"","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.01705v1","updated":"2026-01-05T00:58:19Z","published":"2026-01-05T00:58:19Z","title":"Explicit World Models for Reliable Human-Robot Collaboration","summary":"This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible \"explicit world model\" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.","authors":["Kenneth Kwok","Basura Fernando","Qianli Xu","Vigneshwaran Subbaraju","Dongkyu Choi","Boon Kiat Quek"],"pdf_url":"","comment":"Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification"},{"id":"http://arxiv.org/abs/2601.01696v1","updated":"2026-01-05T00:06:06Z","published":"2026-01-05T00:06:06Z","title":"Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems","summary":"Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.","authors":["Yian Liu","Xiong Wang","Ping Xu","Lei Zhu","Ming Yan","Linyun Xue"],"pdf_url":"","comment":null}],"Analysis of PDEs":[{"id":"http://arxiv.org/abs/2601.02326v1","updated":"2026-01-05T18:17:38Z","published":"2026-01-05T18:17:38Z","title":"Another look at regularity in transport-commutator estimates","summary":"We are interested in how regular a transport velocity field must be in order to control Riesz-type commutators. Estimates for these commutators play a central role in the analysis of the mean-field limit and fluctuations for systems of particles with pairwise Riesz interactions, which we start by reviewing. Our first new result shows that the usual $L^\\infty$ assumption on the gradient of the velocity field cannot, in general, be relaxed to a BMO assumption. We construct counterexamples in all dimensions and all Riesz singularities $-2< s<d$, except for the one-dimensional logarithmic endpoint $s=0$. At this exceptional endpoint, such a relaxation is possible, a fact related to the classical Coifman-Rochberg-Weiss commutator bound for the Hilbert transform. Our second result identifies a trade-off between the singularity of the interaction potential and the required regularity of the velocity field. Roughly speaking, smoother (less singular) interactions require stronger velocity control if one wants a commutator estimate in the natural energy seminorm determined by the potential. We formulate this principle for a broad class of potentials and show that, in the sub-Coulomb Riesz regime, the velocity regularity appearing in the known commutator inequality is sharp. Despite these negative findings, we show as our third result that a defective commutator estimate holds for almost-Lipschitz transport fields. Such a defective estimate, which is a consequence of the celebrated Brezis-Wainger-Hansson inequality, allows us to prove rates of convergence when the mean-field density belongs to the scaling-critical Sobolev space.","authors":["Elias Hess-Childs","Matthew Rosenzweig","Sylvia Serfaty"],"pdf_url":"","comment":"42 pages. This article is dedicated to the memory of Haïm Brezis whose life and work were a great source of inspiration"},{"id":"http://arxiv.org/abs/2601.02274v1","updated":"2026-01-05T17:04:50Z","published":"2026-01-05T17:04:50Z","title":"Semi-Classical Localization of the Schrödinger Resolvent on Closed Riemann Surfaces","summary":"This paper investigates the localization properties of solutions to the semi-classical Schrödinger equation on closed Riemann surfaces. Unlike classical studies that assume a smooth potential, our work addresses the challenges arising from irregular potentials, specifically those that are merely bounded. We employ a regularization technique to manage the potential's lack of smoothness and establish a local-to-global estimate. This result provides a quantitative measure of how the local regularity of the potential influences the global concentration of the solution, thereby bridging the gap between smooth and non-continuous regimes in semi-classical analysis.","authors":["Sébastien Campagne"],"pdf_url":"","comment":"20 pages, 2 figures"},{"id":"http://arxiv.org/abs/2506.15795v3","updated":"2026-01-05T15:38:54Z","published":"2025-06-18T18:26:41Z","title":"Propagation of chaos for the Landau equation with very soft and Coulomb potentials","summary":"We consider a drift-diffusion process of $N$ stochastic particles and show that its empirical measure converges, as $N\\rightarrow \\infty$, to the solution of the Landau equation. We work in the regime of very soft and Coulomb potentials using a tightness/uniqueness method. To claim uniqueness, we need high integrability estimates that we obtain by crucially exploiting the dissipation of the Fisher information at the level of the particle system. To be able to exploit these estimates as $N\\rightarrow \\infty$, we prove the affinity in infinite dimension of the entropy production and Fisher information dissipation (and other first and second-order versions of the Fisher information through a general theorem), results which were up to now only known for the entropy and the usual Fisher information.","authors":["Côme Tabary"],"pdf_url":"","comment":"version 1 was submitted on June 18th 2025, covering very soft potentials only. version 2 was submitted on June 30th to cover Coulomb potentials, and to acknowledge the preprint by Feng and Wang submitted on June 17th"},{"id":"http://arxiv.org/abs/2601.02208v1","updated":"2026-01-05T15:32:11Z","published":"2026-01-05T15:32:11Z","title":"Long time dynamics of the Nernst-Planck-Darcy System on $\\mathbb{R}^3$","summary":"We study ionic electrodiffusion modeled by the Nernst--Planck equations describing the evolution of $N$ ionic species in a three-dimensional incompressible fluid flowing through a porous medium. We address the long-time dynamics of the resulting system in the three-dimensional whole space $\\mathbb{R}^3$. We prove that the $k$-th spatial derivatives of each ionic concentration decays to zero in $L^2$ with a sharp rate of order $t^{-\\frac{3}{4}-\\frac{k}{2}}$. Moreover, we investigate the behavior of the relative entropy associated with the model and show that it blows up in time with a sharp growth rate of order $\\log t$.","authors":["Elie Abdo","Joe Germany","Mohammad Khalil Hamdan","Kifah Kontar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14591v2","updated":"2026-01-05T15:25:53Z","published":"2025-12-16T16:58:53Z","title":"Proper solutions of the $1/H$-flow and the Green kernel of the $p$-Laplacian","summary":"We show existence and optimal growth estimate for the weak inverse mean curvature flow issuing from a point, on manifolds with certain curvature and isoperimetric conditions. These theorems imply analogous ones for the flow issuing from relatively compact sets. Some of the results are obtained by proving new decay estimates for the Green kernel of the $p$-Laplacian which fix a gap in the literature. Additionally, we address the convergence of renormalized $p$-capacitary potentials to the inverse mean curvature flow with outer obstacle.","authors":["Luca Benatti","Luciano Mari","Marco Rigoli","Alberto G. Setti","Kai Xu"],"pdf_url":"","comment":"37 pages. Comments are welcome!"},{"id":"http://arxiv.org/abs/2512.15525v2","updated":"2026-01-05T15:14:24Z","published":"2025-12-17T15:25:03Z","title":"A modified Bakry-Émery $Γ_2$ criterion inequality and the monotonicity of the Tsallis entropy","summary":"The Bakry-Émery $Γ_2$ criterion inequality provides a method for establishing the logarithmic Sobolev inequality. We prove a one-parameter family of weighted Bakry-Émery $Γ_2$ criterion inequalities which in the limit case yields the improved constant due to Ji \\cite{Ji24}. Furthermore, we establish a modified weighted $Γ_2$ criterion inequality which could be interpreted as a monotonicity of the Tsallis entropy under the heat flow and yields a family of sharp Sobolev inequalities.","authors":["Xiaohan Cai","Xiaodong Wang"],"pdf_url":"","comment":"Minor revisions"},{"id":"http://arxiv.org/abs/2404.06811v2","updated":"2026-01-05T15:09:48Z","published":"2024-04-10T07:58:09Z","title":"Strong stabilization of damped nonlinear Schr{ö}dinger equation with saturation on unbounded domains","summary":"We consider the damped nonlinear Schr\\''{o}dinger equation with saturation: i.e., the complex evolution equation contains in its left hand side, besides the potential term $V(x)u,$ a nonlinear term of the form $\\mathrm{i}μu(t,x)/|u(t,x)|$ for a given parameter $μ>0$ (arising in optical applications on non-Kerr-like fibers). In the right hand side we assume a given forcing term $f(t,x).$ The important new difficulty, in contrast to previous results in the literature, comes from the fact that the spatial domain is assumed to be unbounded. We start by proving the existence and uniqueness of weak and strong solutions according the regularity of the data of the problem. The existence of solutions with a lower regularity is also obtained by working with a sequence of spaces verifying the Radon-Nikodým property. Concerning the asymptotic behavior for large times we prove a strong stabilization result. For instance, in the one dimensional case we prove that there is extinction in finite time of the solutions under the mere assumption that the $L^\\infty$-norm of the forcing term $f(t,x)$ becomes less than $μ$ after a finite time. This presents some analogies with the so called feedback \\textit{bang-bang controls} $v$ (here $v=-\\mathrm{i}μu/|u|+f).$","authors":["Pascal Bégout","Jesús Ildefonso Díaz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02169v1","updated":"2026-01-05T14:46:45Z","published":"2026-01-05T14:46:45Z","title":"Broadband quasistatic passive cloaking: bounds and limitations in the near-field regime","summary":"We consider here several aspects of the following challenging question: is it possible to use a passive cloak to make invisible a dielectric inclusion on a finite frequency interval in the quasistatic regime of Maxwell's equations for an observer close to the object? In this work, by considering the Dirichlet-to-Neumann (DtN) map, we not only answer negatively this question, but we go further and provide some quantitative bounds on this map that provide fundamental limits to both cloaking as well as approximate cloaking. These bounds involve the following physical parameters: the length and center of the frequency interval, the volume of the cloaking device, the volume of the obstacle, and the relative permittivity of the object. Our approach is based on two key tools: i) variational principles from the abstract theory of composites and ii) the analytic approach to deriving bounds from sum rules for passive systems. To use i), we prove a new representation theorem for the DtN map which allows us to interpret this map as an effective operator in the abstract theory of composites. One important consequence of this representation is that it allows one to incorporate the broad and deep results from the theory of composites, such as variational principles, and to apply the bounds derived from them to the DtN map. These results could be useful in other contexts other than cloaking. Next, to use ii), we show that the passivity assumption allows us to connect the DtN map (as function of the frequency) with two important classes of analytic functions, namely, Herglotz and Stieltjes functions. The sum rules for these functions, combined with the variational approach, allows us to derive new inequalities on the DtN map which impose fundamental limitations on passive cloaking, both exact and approximate, over a frequency interval. We consider both cases of lossy and lossless cloaks.","authors":["Maxence Cassier","Graeme W. Milton","Aaron Welters"],"pdf_url":"","comment":"72 pages, 3 figures"},{"id":"http://arxiv.org/abs/2509.06420v2","updated":"2026-01-05T14:40:36Z","published":"2025-09-08T08:15:47Z","title":"Propagation of Wave Packets Close to Conical Intersections","summary":"In this paper, we study the propagation of wave packets close to conical intersections with respect to a system of two Schr{ö}dinger equations presenting a codimension 2 crossing. We focus on the dynamics that occur when the wave packets pass through an area close to the crossing, and our main results provide an explicit formula for the outgoing wave packet in terms of the incoming one, with a complete description of its phase and of the classical trajectories it follows, including a drift.","authors":["Marianne Curely"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.00650v2","updated":"2026-01-05T14:40:06Z","published":"2024-02-01T15:12:35Z","title":"Calderón problem for nonlocal viscous wave equations: Unique determination of linear and nonlinear perturbations","summary":"The main goal of this article is to study a Calderón type inverse problem for certain viscous nonlocal wave equations. We show that the partial Dirichlet to Neumann map uniquely determines on the one hand linear perturbations and on the other hand homogeneous nonlinearities $f(u)$ whenever the latter satisfy a certain growth assumption. As a preliminary step we discuss the well-posedness in each case, where for the nonlinear setting we invoke the implicit function theorem after establishing the differentiability of the associated Nemytskii operator $f(u)$. In the linear case we establish a Runge approximation theorem in $L^2(0,T;\\widetilde{H}^{s}(Ω))$, which allows us to uniquely determine potentials that belong only to $L^{\\infty}(0,T;L^p(Ω))$ for some $1<p\\leq \\infty$ satisfying suitable restrictions. In the nonlinear case, we first derive an appropriate integral identity and combine this with the differentiability of the solution map around zero to show that the nonlinearity is uniquely determined by the Dirichlet to Neumann map. To make this linearization technique work, it is essential that we have a Runge approximation in $L^2(0,T;\\widetilde{H}^s(Ω))$ instead of $L^2(Ω_T)$ at our disposal.","authors":["Philipp Zimmermann"],"pdf_url":"","comment":"36 pages"},{"id":"http://arxiv.org/abs/2601.02093v1","updated":"2026-01-05T13:20:21Z","published":"2026-01-05T13:20:21Z","title":"Optimal Spectral Inequality for the Higher-Dimensional Landau Operator","summary":"We prove optimal spectral inequalities for Landau operators in full space and in arbitrary dimension. Spectral inequalities are lower bounds on the L 2 -mass of functions in spectral subspaces of finite energy when integrated over a sampling set S $\\subset$ R d . Landau operators are Schr{ö}dinger operators associated with a constant magnetic field of the form (-$\\nabla$ + A(x)) 2 where A is a -in case of non-vanishing magnetic field -unbounded vector potential. Our strategy relies on so-called magnetic Bernstein estimates and analyticity, adapting an approach used by Kovrijkine in the context of the Logvinenko-Sereda theorem. We generalize results previously only known in dimension d = 2. The main difficulty in dimension d $\\ge$ 3 are the magnetic Bernstein inequalities which, in comparison to the twodimensional case, lead to additional complications and require more delicate estimates. Our results have immediate consequences for control theory, spectral theory and mathematical physics which we comment on.","authors":["Sedef Özcan","Matthias Täufer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2403.19268v2","updated":"2026-01-05T12:53:49Z","published":"2024-03-28T09:54:32Z","title":"Liouville Theorem for $k-$curvature equation in half space with fully nonlinear boundary condition","summary":"We establish the Liouville theorem for positive constant $σ_{k}$-curvature equation in $\\mathbb{R}_{+}^{n}$ and positive constant boundary $\\mathcal{B}_{k}^{g}$ curvature equation, where the boundary curvature $\\mathcal{B}_{k}^{g}$ is discovered by Sophie Chen \\cite{Chen} from the natural variational functional for $σ_{k}(A_{g})$.","authors":["Wei Wei"],"pdf_url":"","comment":"appear to Advances in Calculus of Variations"},{"id":"http://arxiv.org/abs/2204.01299v4","updated":"2026-01-05T12:30:46Z","published":"2022-04-04T08:14:13Z","title":"On the large-time asymptotics of the defocusing mKdV equation with step-like initial data","summary":"We study the Cauchy problem for the defocusing modified Korteweg-de Vries (mKdV) equation with step-like initial data approaching nonzero constants $c_l$ and $c_r$ as $x \\to -\\infty$ and $x\\to+\\infty$, respectively. Assuming $c_l>c_r>0$, the solution exhibits a rarefaction wave structure. We first develop the inverse scattering transform for the solution satisfying these step-like boundary conditions. Using the associated scattering data, we prove that there exists a unique global solution of the Cauchy problem and characterize it in terms of a Riemann-Hilbert (RH) problem. By applying the nonlinear steepest descent method to this RH problem, we rigorously obtain large-time asymptotics of rarefaction wave solution in three distinct space-time regions, each characterized by a different leading order behavior. They are: (I) a left-field region where the solution approaches the left background constant, modulo a small oscillatory correction, (II) a central region where the solution exhibits a slowly varying profile that transitions between the two constants, and (III) a right-field region where the solution tends to the right background constant, up to an algebraically small correction. Rigorous derivations of the leading terms, sub-leading terms as well as the error bounds are presented.","authors":["Taiyang Xu","Yidan Zhang"],"pdf_url":"","comment":"53 pages, 17 figures"},{"id":"http://arxiv.org/abs/2601.02051v1","updated":"2026-01-05T12:17:26Z","published":"2026-01-05T12:17:26Z","title":"Dissipative solutions to a Beris-Edwards type model for compressible active nematic liquid crystals","summary":"We study the hydrodynamics of compressible active nematic liquid crystals in a three-dimensional and bounded domain, with a nonlinear viscosity tensor and nonhomogeneous boundary data, in a Landau-de Gennes framework. We prove the existence of dissipative solutions within a Beris-Edwards type model for active nematodynamics, which are weak solutions satisfying the underlying equations modulo a defect measure. The proof follows from a three level approximation scheme -- the Galerkin approximation, the classical parabolic regularization of the continuity equation, and the convex regularization of the potential generating the viscous stress. New techniques are required to deal with non-Newtonian stress tensor, larger classes of admissible pressure potentials and nonhomogeneous boundary conditions.","authors":["Kuntal Bhandari","Apala Majumdar","Šárka Nečasová"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.05577v3","updated":"2026-01-05T11:48:59Z","published":"2024-05-09T07:03:25Z","title":"Liouville type theorems for dual nonlocal evolution equations involving Marchaud derivatives","summary":"In this paper, we establish a Liouville type theorem for the homogeneous dual fractional parabolic equation \\begin{equation}\n  \\partial^α_t u(x,t)+(-Δ)^s u(x,t) = 0\\ \\ \\mbox{in}\\ \\ \\mathbb{R}^n\\times\\mathbb{R} . \\end{equation} where $0<α,s<1$. Under an asymptotic assumption $$\\liminf_{|x|\\rightarrow\\infty}\\frac{u(x,t)}{|x|^γ}\\geq 0 \\; ( \\mbox{or} \\; \\leq 0) \\,\\,\\mbox{for some} \\;0\\leqγ\\leq 1, $$ in the case $\\frac{1}{2}<s < 1$, we prove that all solutions in the sense of distributions of above equation must be constant by employing a method of Fourier analysis. Our result includes the previous Liouville theorems on harmonic functions \\cite{ABR} and on $s$-harmonic functions \\cite{CDL} as special cases and it is still novel even restricted to one-sided Marchaud fractional equations, and our methods can be applied to a variety of dual nonlocal parabolic problems.\n  In the process of deriving our main result, through very delicate calculations, we obtain an optimal estimate on the decay rate of $\\left[D_{\\rm right}^α+(-Δ)^s\\right] \\varphi(x,t)$ for functions in Schwartz space. This sharp estimate plays a crucial role in defining the solution in the sense of distributions and will become a useful tool in the analysis of this family of equations.","authors":["Yahong Guo","Lingwei Ma","Zhenqiu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02035v1","updated":"2026-01-05T11:46:11Z","published":"2026-01-05T11:46:11Z","title":"Sub-Laplacian generalized curvature dimension inequalities on Riemannian foliations","summary":"We develop a Bochner theory and Bakry-Emery calculus for horizontal Laplacians associated with general Riemannian foliations. No bundle-like assumption on the metric, nor any total geodesicity or minimality condition on the leaves is imposed. Using a metric connection adapted to the horizontal-vertical splitting, we derive explicit Bochner formulas for the horizontal Laplacian acting on horizontal and vertical gradients, as well as a unified identity for the full gradient. These formulas involve horizontal Ricci curvature, torsion and vertical mean curvature terms intrinsic to the foliated structure. From these identities, we establish generalized curvature dimension inequalities, extending earlier results in sub-Riemannian geometry. As applications, we obtain horizontal Laplacian comparison theorems, Bonnet-Myers type compactness results with explicit diameter bounds, stochastic completeness, first eigenvalue estimates and gradient and regularization estimates for the horizontal heat semigroup. The framework applies, in particular, to contact manifolds and Carnot groups of arbitrary step.","authors":["Fabrice Baudoin","Guang Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.23239v2","updated":"2026-01-05T11:44:31Z","published":"2025-07-31T04:34:22Z","title":"Min-max theory and minimal surfaces with prescribed genus","summary":"We establish a general min-max type theorem that produces minimal surfaces with prescribed genus in 3-manifolds with positive Ricci curvature. An important intermediate step is to show that, in a generic metric with positive Ricci curvature, any family of smooth embedded surfaces, possibly with finitely many singularities, can be deformed into a certain ``topologically optimal family\".\n  Results in this paper will be crucial to our program on the construction of multiple minimal surfaces with prescribed genus in 3-spheres via topological methods.","authors":["Adrian Chun-Pong Chu","Yangyang Li","Zhihan Wang"],"pdf_url":"","comment":"The v1 manuscript has been split into two parts: the construction of a topologically optimal family is contained in v2, while the existence result for genus 2 minimal surfaces will be strengthened and will appear elsewhere"},{"id":"http://arxiv.org/abs/2601.02006v1","updated":"2026-01-05T11:13:10Z","published":"2026-01-05T11:13:10Z","title":"Global Hilbert expansion for the ionic Vlasov-Poisson-Boltzmann system","summary":"We justify the global-in-time validity of Hilbert expansion for the ionic Vlasov-Poisson-Boltzmann system in $\\mathbb{R}^3$, a fundamental model describing ion dynamics in dilute collisional plasmas. As the Knudsen number approaches zero, we rigorously derive the compressible Euler-Poisson system governing global smooth irrotational ion flows. The truncated Hilbert expansion exhibits a multi-layered mathematical structure: the expansion coefficients satisfy linear hyperbolic systems, while the remainder equation couples with a nonlinear Poisson equation for the electrostatic potential. This requires refined elliptic estimates addressing the exponential nonlinearities and some new enclosed $L^2\\cap W^{1,\\infty}$ estimates for the potential-dependent terms.","authors":["Fucai Li","Yichun Wang"],"pdf_url":"","comment":"35 pages"},{"id":"http://arxiv.org/abs/2211.10970v2","updated":"2026-01-05T11:11:30Z","published":"2022-11-20T12:44:59Z","title":"The combined non-equilibrium diffusion and low Mach number limits of the compressible Navier-Stokes-Fourier-P1 approximation radiation model","summary":"In this paper, we investigate the combined non-equilibrium diffusion and low Mach number limits of the compressible Navier-Stokes-Fourier-P1 (NSF-P1) model with general initial data, which arises in the radiation hydrodynamics. Compared to the classical compressible Navier-Stokes-Fourier system, the NSF-P1 model has an asymmetric singular structure caused by the radiation field. To handle these singular terms, we introduce an equivalent pressure and an equivalent velocity to balance the order of singularity and establish the uniform estimates of solutions by designating appropriate weighted norms as well as carrying out delicate energy analysis. We conclude that, for partially general initial data and the strong scattering effect, the NSF-P1 model converges to the system of low Mach number heat-conducting viscous flows coupled with a diffusion equation. We also discuss the variations of the limit equations as the scattering intensity changes. Furthermore, when the scattering effect is sufficiently weak, we can obtain the singular limits of the NSF-P1 model with fully general initial data.","authors":["Fucai Li","Shuxing Zhang"],"pdf_url":"","comment":"30 pages"},{"id":"http://arxiv.org/abs/2601.01986v1","updated":"2026-01-05T10:42:39Z","published":"2026-01-05T10:42:39Z","title":"A linear model of separation for western boundary currents with bathymetry","summary":"This paper is devoted to the asymptotic analysis of strongly rotating and stratified fluids, under a $β$-plane approximation, and within a three-dimensional spatial domain with strong topography. Our purpose is to propose a linear idealized model, which is able to capture one of the key features of western boundary currents, in spite of its simplicity: the separation of the currents from the coast. Our simplified framework allows us to perform explicit computations, and to highlight the intricate links between rotation, stratification and bathymetry. In fact, we are able to construct approximate solutions at any order for our system, and to justify their validity. Each term in the asymptotic expansion is the sum of an interior part and of two boundary layer parts: a ``Munk'' type boundary layer, which is quasi-geostrophic, and an ``Ekman part'', which is not. Even though the Munk part of the approximation bears some similarity with previously studied 2D models, the analysis of the Ekman part is completely new, and several of its properties differ strongly from the ones of classical Ekman layers. Our theoretical analysis is supplemented with numerical illustrations, which exhibit the desired separation behavior.","authors":["Anne-Laure Dalibard","Corentin Gentil"],"pdf_url":"","comment":null}],"Dynamical Systems":[{"id":"http://arxiv.org/abs/2601.02347v1","updated":"2026-01-05T18:44:27Z","published":"2026-01-05T18:44:27Z","title":"Solving Matrix Games with Even Fewer Matrix-Vector Products","summary":"We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and of $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In particular, our result for $\\ell_2$-$\\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.","authors":["Ishani Karmarkar","Liam O'Carroll","Aaron Sidford"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2403.18059v5","updated":"2026-01-05T17:23:12Z","published":"2024-03-26T19:24:40Z","title":"Optimality of Non-Adaptive Algorithms in Online Submodular Welfare Maximization with Stochastic Outcomes","summary":"We generalize the problem of online submodular welfare maximization to incorporate various stochastic elements that have gained significant attention in recent years. We show that a non-adaptive Greedy algorithm, which is oblivious to the realization of these stochastic elements, achieves the best possible competitive ratio among all polynomial-time algorithms, including adaptive ones, unless NP$=$RP. This result holds even when the objective function is not submodular but instead satisfies the weaker submodular order property. Our results unify and strengthen existing competitive ratio bounds across well-studied settings and diverse arrival models, showing that, in general, adaptivity to stochastic elements offers no advantage in terms of competitive ratio.\n  To establish these results, we introduce a technique that lifts known results from the deterministic setting to the generalized stochastic setting. The technique has broad applicability, enabling us to show that, in certain special cases, non-adaptive Greedy-like algorithms outperform the Greedy algorithm and achieve the optimal competitive ratio. We also apply the technique in reverse to derive new upper bounds on the performance of Greedy-like algorithms in deterministic settings by leveraging upper bounds on the performance of non-adaptive algorithms in stochastic settings.","authors":["Rajan Udwani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02257v1","updated":"2026-01-05T16:36:59Z","published":"2026-01-05T16:36:59Z","title":"Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization","summary":"We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.\n  We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.","authors":["Joel Daniel Andersson","Palak Jain","Satchit Sivakumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12857v2","updated":"2026-01-05T16:12:31Z","published":"2025-11-17T01:05:11Z","title":"Approximate Message Passing for Quantum State Tomography","summary":"Quantum state tomography (QST) is an indispensable tool for characterizing many-body quantum systems. However, due to the exponential scaling of the cost of the protocol with system size, many approaches have been developed for quantum states with specific structure, such as low-rank states. In this paper, we show how approximate message passing (AMP), an algorithmic framework for sparse signal recovery, can be used to perform low-rank QST. AMP provides asymptotically optimal performance guarantees for large sparse recovery problems, which suggests its utility for QST. We discuss the design challenges that come with applying AMP to QST, and show that by properly designing the AMP algorithm, we can reduce the reconstruction error by over an order of magnitude compared to existing approaches to low-rank QST. We also performed tomographic experiments on IBM Kingston and considered the effect of device noise on the reliability of the predicted fidelity of state preparation. Our work advances the state of low-rank QST and may be applicable to other quantum tomography protocols.","authors":["Noah Siekierski","Kausthubh Chandramouli","Christian Kümmerle","Bojko N. Bakalov","Dror Baron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02193v1","updated":"2026-01-05T15:16:26Z","published":"2026-01-05T15:16:26Z","title":"Learning with Monotone Adversarial Corruptions","summary":"We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a \"clean\" i.i.d. dataset, inserts additional \"corrupted\" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.","authors":["Kasper Green Larsen","Chirag Pabbaraju","Abhishek Shetty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.18803v2","updated":"2026-01-05T09:47:37Z","published":"2025-02-26T04:17:32Z","title":"On Efficient Approximate Aggregate Nearest Neighbor Queries over Learned Representations","summary":"We study Aggregation Queries over Nearest Neighbors (AQNN), which compute aggregates over the learned representations of the neighborhood of a designated query object. For example, a medical professional may be interested in the average heart rate of patients whose representations are similar to that of an insomnia patient. Answering AQNNs accurately and efficiently is challenging due to the high cost of generating high-quality representations (e.g., via a deep learning model trained on human expert annotations) and the different sensitivities of different aggregation functions to neighbor selection errors. We address these challenges by combining high-quality and low-cost representations to approximate the aggregate. We characterize value- and count-sensitive AQNNs and propose the Sampler with Precision-Recall in Target (SPRinT), a query answering framework that works in three steps: (1) sampling, (2) nearest neighbor selection, and (3) aggregation. We further establish theoretical bounds on sample sizes and aggregation errors. Extensive experiments on five datasets from three domains (medical, social media, and e-commerce) demonstrate that SPRinT achieves the lowest aggregation error with minimal computation cost in most cases compared to existing solutions. SPRinT's performance remains stable as dataset size grows, confirming its scalability for large-scale applications requiring both accuracy and efficiency.","authors":["Carrie Wang","Sihem Amer-Yahia","Laks V. S. Lakshmanan","Reynold Cheng"],"pdf_url":"","comment":"26 pages, 12 figures, 10 tables"},{"id":"http://arxiv.org/abs/2402.06388v4","updated":"2026-01-05T08:44:46Z","published":"2024-02-09T13:10:04Z","title":"Convergence of a L2 regularized Policy Gradient Algorithm for the Multi Armed Bandit","summary":"Although Multi Armed Bandit (MAB) on one hand and the policy gradient approach on the other hand are among the most used frameworks of Reinforcement Learning, the theoretical properties of the policy gradient algorithm used for MAB have not been given enough attention. We investigate in this work the convergence of such a procedure for the situation when a $L2$ regularization term is present jointly with the 'softmax' parametrization. We prove convergence under appropriate technical hypotheses and test numerically the procedure including situations beyond the theoretical setting. The tests show that a time dependent regularized procedure can improve over the canonical approach especially when the initial guess is far from the solution.","authors":["Stefana Anita","Gabriel Turinici"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01869v1","updated":"2026-01-05T07:56:06Z","published":"2026-01-05T07:56:06Z","title":"Exact Clique Number Manipulation via Edge Interdiction","summary":"The Edge Interdiction Clique Problem (EICP) aims to remove at most $k$ edges from a graph so as to minimize the size of the largest clique in the remaining graph. This problem captures a fundamental question in graph manipulation: which edges are structurally critical for preserving large cliques? Such a problem is also motivated by practical applications including protein function maintenance and image matching. The EICP is computationally challenging and belongs to a complexity class beyond NP. Existing approaches rely on general mixed-integer bilevel programming solvers or reformulate the problem into a single-level mixed integer linear program. However, they are still not scalable when the graph size and interdiction budget $k$ grow. To overcome this, we investigate new mixed integer linear formulations, which recast the problem into a sequence of parameterized Edge Blocker Clique Problems (EBCP). This perspective decomposes the original problem into simpler subproblems and enables tighter modeling of clique-related inequalities. Furthermore, we propose a two-stage exact algorithm, \\textsc{RLCM}, which first applies problem-specific reduction techniques to shrink the graph and then solves the reduced problem using a tailored branch-and-cut framework. Extensive computational experiments on maximum clique benchmark graphs, large real-world sparse networks, and random graphs demonstrate that \\textsc{RLCM} consistently outperforms existing approaches.","authors":["Yi Zhou","Haoyu Jiang","Chenghao Zhu","André Rossi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01841v1","updated":"2026-01-05T07:05:18Z","published":"2026-01-05T07:05:18Z","title":"Improved Approximation Algorithms for the Multiple-Depot Split Delivery Vehicle Routing Problem","summary":"The Multiple-Depot Split Delivery Vehicle Routing Problem (MD-SDVRP) is a challenging problem with broad applications in logistics. The goal is to serve customers' demand using a fleet of capacitated vehicles located in multiple depots, where each customer's demand can be served by more than one vehicle, while minimizing the total travel cost of all vehicles. We study approximation algorithms for this problem. Previously, the only known result was a $6$-approximation algorithm for a constant number of depots (INFORMS J. Comput. 2023), and whether this ratio could be improved was left as an open question. In this paper, we resolve it by proposing a $(6-2\\cdot 10^{-36})$-approximation algorithm for this setting. Moreover, we develop constant-factor approximation algorithms that work beyond a constant number of depots, improved parameterized approximation algorithms related to the vehicle capacity and the number of depots, as well as bi-factor approximation algorithms.","authors":["Jingyang Zhao","Yonghang Su","Mingyu Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01710v1","updated":"2026-01-05T01:10:56Z","published":"2026-01-05T01:10:56Z","title":"Publishing Below-Threshold Triangle Counts under Local Weight Differential Privacy","summary":"We propose an algorithm for counting below-threshold triangles in weighted graphs under local weight differential privacy. While prior work focused on unweighted graphs, many real-world networks naturally include edge weights. We study the setting where the graph topology is public known and the privacy of the influence of an individual on the edge weights is protected. This captures realistic scenarios such as road networks and telecommunication networks. Our approach consists of two rounds of communication. In the first round, each node publishes their incident weight information under local weight differential privacy while in the second round, the nodes locally count below-threshold triangles, for which we introduce a biased and unbiased variant. We further propose two different improvements. We present a pre-computation step that reduces the covariance and thereby lowers the expected error. Secondly, we develop an algorithm for computing the smooth-sensitivity, which significantly reduces the running time compared to a straightforward approach. Finally, we provide experimental results that demonstrate the differences between the biased and unbiased variants and the effectiveness of the proposed improvements.","authors":["Kevin Pfisterer","Quentin Hillebrand","Vorapong Suppakitpaisarn"],"pdf_url":"","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2503.18773v3","updated":"2026-01-05T18:08:27Z","published":"2025-03-24T15:22:41Z","title":"BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache","summary":"The growth of long-context Large Language Models (LLMs) significantly increases memory and bandwidth pressure during autoregressive decoding due to the expanding Key-Value (KV) cache. While accuracy-preserving KV-cache quantization (e.g., 4-bit or 2-bit) reduces memory footprint, existing systems decode inefficiently by relying solely on CUDA cores, underutilizing Tensor Cores-the dominant compute resource on GPUs.\n  We present BitDecoding, the first inference system to efficiently decode low-bit KV caches by cooperatively leveraging CUDA cores and Tensor Cores. BitDecoding smartly induces Tensor-Core-friendly layouts, introduces warp-level dequantization parallelism, and provides unified system support through query transformation, high-performance tensor- and channel-wise quantization, and a software-pipelined dequantization kernel enabling mixed-precision execution. Architecture-aware optimizations further leverage Hopper's warpgroup tensor instructions and Blackwell's NVFP4 (MXFP4) tensor formats.\n  Evaluated on Blackwell, Hopper, and Ampere GPUs, BitDecoding achieves an average 7.5x decoding speedup over FP16 FlashDecoding-v2, up to 8.6x on Blackwell with NVFP4, and up to 4.3x over state-of-the-art approaches. On LLaMA-3.1-8B with a 128K context, BitDecoding reduces single-batch decoding latency by 3x. BitDecoding is open-sourced at https://github.com/OpenBitSys/BitDecoding.","authors":["Dayou Du","Shijie Cao","Jianyi Cheng","Luo Mai","Ting Cao","Mao Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02253v1","updated":"2026-01-05T16:33:13Z","published":"2026-01-05T16:33:13Z","title":"Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission","summary":"The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.","authors":["Emrah Mete","Emin Erkan Korkmaz"],"pdf_url":"","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.02135v1","updated":"2026-01-05T14:07:11Z","published":"2026-01-05T14:07:11Z","title":"HFRWKV: A High-Performance Fully On-Chip Hardware Accelerator for RWKV","summary":"RWKV is a modern RNN architecture that approaches the performance of Transformers, with the advantage of processing long contexts at a linear memory cost. However, its sequential computation pattern struggles to efficiently leverage GPU parallelism, which leads to low compute resource utilization. Furthermore, frequent off-chip weight accesses create a memory bottleneck. To address these challenges, we propose HFRWKV, an FPGA-based hardware accelerator specifically designed for RWKV. Within the matrix operation module, we propose a novel hardware-friendly hybrid-precision quantization strategy, which enhances performance while maintaining acceptable accuracy. For the complex operations including exponentiation and division, we introduce a method featuring reusable architectures combined with lookup tables or piecewise linear approximation, which is algorithmically refined to effectively balance precision and hardware resource consumption. Based on this foundation, we adopt a fully on-chip computing system integrating parallel matrix-vector processing array and an efficient pipeline architecture. Through computation reordering and chunked double buffering, it effectively eliminates data transfer bottlenecks and improves overall throughput. We implement HFRWKV on the Alveo U50 and U280 platform. Experimental results show that compared to a CPU, a throughput improvement of 63.48$\\times$ and an energy efficiency improvement of 139.17$\\times$. Compared to GPUs, achieves a throughput improvement of 32.33$\\times$ and an energy efficiency improvement of 171.36$\\times$.","authors":["Liu Shijie","Zeng Zhenghao","Jiao Han","Huang Yihua"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02053v1","updated":"2026-01-05T12:22:27Z","published":"2026-01-05T12:22:27Z","title":"Ageing Monitoring for Commercial Microcontrollers Based on Timing Windows","summary":"Microcontrollers are increasingly present in embedded deployments and dependable applications, for which malfunctions due to hardware ageing can have severe impact. The lack of deployable techniques for ageing monitoring on these devices has spread the application of guard bands to prevent timing errors due to degradation. Applying this static technique can limit performance and lead to sudden failures as devices age. In this paper, we follow a software-based self-testing approach to design monitoring of hardware degradation for microcontrollers. Deployable in the field, our technique leverages timing windows of variable lengths to determine the maximum operational frequency of the devices. We empirically validate the method on real hardware and find that it consistently detects temperature-induced degradations in maximum operating frequency of up to 13.79 % across devices for 60 °C temperature increase.","authors":["Leandro Lanzieri","Jiri Kral","Goerschwin Fey","Holger Schlarb","Thomas C. Schmidt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.26217v2","updated":"2026-01-05T09:47:47Z","published":"2025-09-30T13:19:00Z","title":"Benchmarking Deep Learning Convolutions on Energy-constrained CPUs","summary":"This work evaluates State-of-the-Art convolution algorithms for CPU-based CNN inference. Although most prior studies focus on GPUs or NPUs, CPU implementations remain comparatively under-optimized. Our first contribution is to provide fair benchmarking for embedded CPU inference. We evaluate direct, GEMM-based, and Winograd convolutions across modern CPUs from ARM, Intel, AMD, and NVIDIA vendors, considering both latency and energy efficiency. To the best of our knowledge, this is the first study to present a fair, cross-vendor comparison of CPU energy consumption using a high-resolution socket-level measurement platform. To validate our methodology, we further compare socket-level power measurements with estimates derived from model-specific registers (MSRs), finding that MSRs underestimate the power consumption of convolution inference by 10--30%. Our results show that the ARM\\R Cortex-A78AE CPU combined with an implicit GEMM convolution implementation offers the best trade-off between latency and power consumption, achieving ResNet50v1.5 inference in 102 ms with an average power of 25.3 W, corresponding to 2.58 J.","authors":["Enrique Galvez","Adrien Cassagne","Alix Munier","Manuel Bouyer"],"pdf_url":"","comment":null}],"Computational Finance":[{"id":"http://arxiv.org/abs/2304.02479v3","updated":"2026-01-05T15:49:19Z","published":"2023-04-04T06:57:55Z","title":"The Recalibration Conundrum: Hedging Valuation Adjustment for Callable Claims","summary":"The dynamic hedging theory only makes sense in the setup of one given model, whereas the practice of dynamic hedging is just the opposite, with models fleeing after the data through daily recalibration. This is quite of a quantitative finance paradox. In this paper we revisit Burnett (2021) \\& Burnett and Williams (2021)'s notion of hedging valuation adjustment (HVA), originally intended to deal with dynamic hedging frictions, in the direction of recalibration and model risks. Specifically, we extend to callable assets the HVA model risk approach of B{é}n{é}zet and Cr{é}pey (2024). The classical way to deal with model risk is to reserve the differences between the valuations in reference models and in the local models used by traders. However, while traders' prices are thus corrected, their hedging strategies and their exercise decisions are still wrong, which necessitates a risk-adjusted reserve. We illustrate our approach on a stylized callable range accrual representative of huge amounts of structured products on the market. We show that a model risk reserve adjusted for the risk of wrong exercise decisions may largely exceed a basic reserve only accounting for valuation differences.","authors":["Cyril Bénézet","Stéphane Crépey","Dounia Essaket"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01783v1","updated":"2026-01-05T04:31:46Z","published":"2026-01-05T04:31:46Z","title":"Dynamic Risk in the U.S. Banking System: An Analysis of Sentiment, Policy Shocks, and Spillover Effects","summary":"The 2023 U.S. banking crisis propagated not through direct financial linkages but through a high-frequency, information-based contagion channel. This paper moves beyond exploration analysis to test the \"too-similar-to-fail\" hypothesis, arguing that risk spillovers were driven by perceived similarities in bank business models under acute interest rate pressure. Employing a Time-Varying Parameter Vector Autoregression (TVP-VAR) model with 30-day rolling windows, a method uniquely suited for capturing the rapid network shifts inherent in a panic, we analyze daily stock returns for the four failed institutions and a systematically selected peer group of surviving banks vulnerable to the same risks from March 18, 2022, to March 15, 2023. Our results provide strong evidence for this contagion channel: total system connectedness surged dramatically during the crisis peak, and we identify SIVB, FRC, and WAL as primary net transmitters of risk while their perceived peers became significant net receivers, a key dynamic indicator of systemic vulnerability that cannot be captured by asset-by-asset analysis. We further demonstrate that these spillovers were significantly amplified by market sentiment (as measured by the VIX) and economic policy uncertainty (EPU). By providing a clear conceptual framework and robust empirical validation, our findings confirm the persistence of systemic risks within the banking network and highlight the importance of real-time monitoring in strengthening financial stability.","authors":["Haibo Wang","Jun Huang","Lutfu S Sua","Jaime Ortiz","Jinshyang Roan","Bahram Alidaee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18159v2","updated":"2026-01-05T00:40:19Z","published":"2025-10-20T23:19:46Z","title":"Semi-analytical pricing of American options with hybrid dividends via integral equations and the GIT method","summary":"This paper introduces a semi-analytical method for pricing American options on assets (stocks, ETFs) that pay discrete and/or continuous dividends. The problem is notoriously complex because discrete dividends create abrupt price drops and affect the optimal exercise timing, making traditional continuous-dividend models unsuitable. Our approach utilizes the Generalized Integral Transform (GIT) method introduced by the author and his co-authors in a number of papers, which transforms the pricing problem from a complex partial differential equation with a free boundary into an integral Volterra equation of the second or first kind. In this paper we illustrate this approach by considering a popular GBM model that accounts for discrete cash and proportional dividends using Dirac delta functions. By reframing the problem as an integral equation, we can sequentially solve for the option price and the early exercise boundary, effectively handling the discontinuities caused by the dividends. Our methodology provides a powerful alternative to standard numerical techniques like binomial trees or finite difference methods, which can struggle with the jump conditions of discrete dividends by losing accuracy or performance. Several examples demonstrate that the GIT method is highly accurate and computationally efficient, bypassing the need for extensive computational grids or complex backward induction steps.","authors":["Andrey Itkin"],"pdf_url":"","comment":"43 pages, 9 figures, 2 tables"}],"Mathematical Finance":[{"id":"http://arxiv.org/abs/2601.02276v1","updated":"2026-01-05T17:06:32Z","published":"2026-01-05T17:06:32Z","title":"Forward Performance Processes under Multiple Default Risks","summary":"This article constructs a forward exponential utility in a market with multiple defaultable risks. Using the Jacod-Pham decomposition for random fields, we first characterize forward performance processes in a defaultable market under the default-free filtration. We then construct a forward utility via a system of recursively defined, indexed infinite-horizon backward stochastic differential equations (BSDEs) with discounting, and establish the existence, uniqueness, and boundedness of their solutions. To verify the required (super)martingale property of the performance process, we develop a rigorous characterization of this property with respect to the general filtration in terms of a set of (in)equalities relative to the default-free filtration. We further extend the analysis to a stochastic factor model with ergodic dynamics. In this setting, we derive uniform bounds for the Markovian solutions of the infinite-horizon BSDEs, overcoming technical challenges arising from the special structure of the system of BSDEs in the defaultable setting. Passing to the ergodic limit, we identify the limiting BSDE and relate its constant to the risk-sensitive long-run growth rate of the optimal wealth process.","authors":["Wing Fung Chong","Roxana Dumitrescu","Gechun Liang","Kenneth Tsz Hin Ng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18159v2","updated":"2026-01-05T00:40:19Z","published":"2025-10-20T23:19:46Z","title":"Semi-analytical pricing of American options with hybrid dividends via integral equations and the GIT method","summary":"This paper introduces a semi-analytical method for pricing American options on assets (stocks, ETFs) that pay discrete and/or continuous dividends. The problem is notoriously complex because discrete dividends create abrupt price drops and affect the optimal exercise timing, making traditional continuous-dividend models unsuitable. Our approach utilizes the Generalized Integral Transform (GIT) method introduced by the author and his co-authors in a number of papers, which transforms the pricing problem from a complex partial differential equation with a free boundary into an integral Volterra equation of the second or first kind. In this paper we illustrate this approach by considering a popular GBM model that accounts for discrete cash and proportional dividends using Dirac delta functions. By reframing the problem as an integral equation, we can sequentially solve for the option price and the early exercise boundary, effectively handling the discontinuities caused by the dividends. Our methodology provides a powerful alternative to standard numerical techniques like binomial trees or finite difference methods, which can struggle with the jump conditions of discrete dividends by losing accuracy or performance. Several examples demonstrate that the GIT method is highly accurate and computationally efficient, bypassing the need for extensive computational grids or complex backward induction steps.","authors":["Andrey Itkin"],"pdf_url":"","comment":"43 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2507.23646v2","updated":"2026-01-05T00:32:40Z","published":"2025-07-31T15:24:16Z","title":"Information geometry of Lévy processes and financial models","summary":"We explore the information geometry of Lévy processes. As a starting point, we derive the $α$-divergence between two Lévy processes. Subsequently, the Fisher information matrix and the $α$-connection associated with the geometry of Lévy processes are computed from the $α$-divergence. In addition, we discuss statistical applications of this information geometry. As illustrative examples, we investigate the differential-geometric structures of various Lévy processes relevant to financial modeling, including tempered stable processes, the CGMY model, and variance gamma processes.","authors":["Jaehyung Choi"],"pdf_url":"","comment":"21 pages"}]},"2026-01-04T00:00:00Z":{"Optimization and Control":[{"id":"http://arxiv.org/abs/2503.00997v3","updated":"2026-01-04T23:34:04Z","published":"2025-03-02T19:38:26Z","title":"Non null-controllability properties of the Grushin-like heat equation on 2D-manifolds","summary":"We study the internal non null-controllability properties of the heat equation on 2-dimensional almost-Riemannian manifolds with an interior singularity, and under the assumption that the closure of the control zone does not contain the whole singularity. We show that if locally, around the singularity, the sub-Riemannian metric can be written in a Grushin form, or equivalently the sub-Laplacian writes as a generalized Grushin operator, then, achieving null-controllability requires at least a minimal amount of time. As locally the manifold looks like a rectangular domain, we consequently focus ourselves on the non null-controllability properties of the generalized Grushin-like heat equation on various Euclidean domains.","authors":["Roman Vanlaere"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01683v1","updated":"2026-01-04T22:32:51Z","published":"2026-01-04T22:32:51Z","title":"Adaptive Thrust Regulation in Solid-fuel Ramjet with Variable Geometry Inlet","summary":"This paper presents the application of a novel data-driven adaptive control technique, dynamic mode adaptive control (DMAC), to regulate thrust in a solid-fuel ramjet (SFRJ). A quasi-static one-dimensional model of SFRJ with a variable geometry inlet is developed to compute thrust. An adaptive tracking controller is then designed using the DMAC framework, which leverages dynamic mode decomposition to approximate the local system behavior, followed by a tracking controller designed around the identified model. Simulation results demonstrate that DMAC achieves accurate thrust regulation across a range of commanded profiles and operating conditions, without requiring an analytical model of the SFRJ. These findings indicate that DMAC provides a reliable and effective approach for model-free thrust regulation in an SFRJ with variable-geometry inlets as the control input.","authors":["Parham Oveissi","Ryan DeBoskey","Venkateswaran Narayanaswamy","Ankit Goel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25589v2","updated":"2026-01-04T21:39:13Z","published":"2025-09-29T23:26:22Z","title":"On the Emergence of Linear Behavior in Large-Scale Dynamical Systems via Spatial Averaging","summary":"Various natural and engineered systems, from urban traffic flow to the human brain, can be described by large-scale networked dynamical systems. These systems are similar in being comprised of a large number of microscopic subsystems, each with complex nonlinear dynamics and interactions, that collectively give rise to different forms of macroscopic dynamics. Despite significant research, why and how various forms of macroscopic dynamics emerge from underlying micro-dynamics remains largely unknown. In this work we focus on linearity as one of the most fundamental aspects of system dynamics. By extending the theory of mixing sequences, we show that \\textit{in a broad class of autonomous nonlinear networked systems, the dynamics of the average of all subsystems' states becomes asymptotically linear as the number of subsystems grows to infinity, provided that, in addition to technical assumptions, pairwise correlations between subsystems decay to 0 as their pairwise distance grows to infinity}. We prove this result when the latter distance is between subsystems' linear indices or spatial locations, and provide extensions to linear time-invariant (LTI) limit dynamics, finite-sample analysis of rates of convergence, and networks of spatially-embedded subsystems with random locations. To our knowledge, this work is the first rigorous analysis of macroscopic linearity in large-scale heterogeneous networked dynamical systems, and provides a solid foundation for further theoretical and empirical analyses in various domains of science and engineering.","authors":["Sabbir Ahmed","Hafiz Fareed Ahmed","Erfan Nozari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04313v3","updated":"2026-01-04T18:52:33Z","published":"2025-10-05T18:14:52Z","title":"Convex Formulation of the Maritime Fleet Size and Mix Problem Considering Battery Electric Ships","summary":"This paper focuses on the problem of determining a minimum-cost fleet of battery electric ships for a given liner shipping operation. The problem is strongly nonlinear and includes integer-valued decision variables, which make it intractable for most real-world instances. The conventional approach in the literature is to formulate a linear approximation by restricting available ship types to a small number of predetermined alternatives. Contrary to the conventional linearization approach, this paper models the nonlinearities directly. We show that the problem exhibits a hidden convex structure uncovered by changes of variables. Computational experiments show that our convex formulation achieves 15.1\\% lower fleet cost on average and reduces the solve time by at least 10x compared to the linear formulation. The solve time advantage is attributed to the elimination of binary variables associated with ship type selection. Our implementation is available at https://users.aalto.fi/~aritari/convex_ESFSMP.html.","authors":["Antti Ritari","Jani Romanoff","Kari Tammi"],"pdf_url":"","comment":"Revised structure and added a linear benchmark problem"},{"id":"http://arxiv.org/abs/2601.01634v1","updated":"2026-01-04T18:32:25Z","published":"2026-01-04T18:32:25Z","title":"Boundary control systems on a one-dimension spatial domain","summary":"The aim of this paper is to investigate the well-posedness of a class of boundary control and observation systems on a one dimensional spatial domain. We derive a necessary and sufficient condition characterizing the well-posedness of these systems. Furthermore, we show that the well-posedness and full control and observation implies exact controllability and exact observability. The theoretical results are illustrated using Euler-Bernoulli beam models.","authors":["Bouchra Elghazi","Birgit Jacob","Hans Zwart"],"pdf_url":"","comment":"24 pages"},{"id":"http://arxiv.org/abs/2601.01631v1","updated":"2026-01-04T18:29:23Z","published":"2026-01-04T18:29:23Z","title":"Stochastic Maximum Principles and Linear-Quadratic Optimal Control Problems for Fractional Backward Stochastic Evolution Equations in Hilbert Spaces","summary":"This paper develops a comprehensive framework for optimal control of systems governed by fractional backward stochastic evolution equations (FBSEEs) in Hilbert spaces. We first establish a stochastic maximum principle (SMP) as a necessary condition for optimality. This is achieved by introducing spike variations, deriving precise estimates for the associated variational equations, and constructing an adjoint process tailored to the fractional dynamics. Subsequently, we apply this general principle to solve the linear-quadratic (LQ) optimal control problem explicitly. The resulting optimal control is characterized in closed form via the adjoint process and is shown to be governed by a system of coupled fractional forward-backward stochastic equations. Our work bridges fractional calculus with stochastic control theory, providing a rigorous foundation for controlling infinite-dimensional systems with memory and long-range dependencies.","authors":["Javad A. Asadzade","Nazim I. Mahmudov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01621v1","updated":"2026-01-04T18:00:39Z","published":"2026-01-04T18:00:39Z","title":"A Three-Tier Time-Scale Architecture for Controlling Complex Nonlinear Systems","summary":"This letter proposes a three-tier computational architecture for the real-time control of nonlinear complex systems, such as time-dependent PDEs. There is an important class of such problems for which existing single- and two-time-scale approaches are fundamentally insufficient due to lack of a priori system knowledge, computational complexity, model fidelity requirements, and uncertainty. The proposed architecture consists of an offline, meso-scale, and real-time layer of computation, with distinct roles for each layer and specific information flow between them. The result is a practical systems-level paradigm that enables real-time operation of complex nonlinear control problems.","authors":["Vyacheslav Kungurtsev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01591v1","updated":"2026-01-04T16:39:58Z","published":"2026-01-04T16:39:58Z","title":"Optimization problems for elliptic PDEs","summary":"In this paper we consider some optimal control problems governed by elliptic partial differential equations. The solution is the state variable, while the control variable is, depending on the case, the coefficient of the PDE, the potential, the right-hand side. The cost functional is of integral type and involves both the state and control variables.","authors":["Giuseppe Buttazzo","Juan Casado-Díaz","Faustino Maestre"],"pdf_url":"","comment":"19 pages, 8 figures"},{"id":"http://arxiv.org/abs/2510.12244v4","updated":"2026-01-04T16:23:01Z","published":"2025-10-14T07:54:41Z","title":"Qualification-free convex analysis via the joint supporting subspace","summary":"In convex analysis, qualification conditions (also termed constraint qualifications) help avoid pathological behavior at domain boundaries. In this work we remove the need for such conditions by localizing to an affine subspace -- the joint supporting subspace -- that contains the feasible region and ensures qualification conditions hold after localization.\n  Our theory generalizes Borwein and Wolkowicz's facial reduction beyond conic programs to convex programs of the form $f(x) + g(Ax)$. Intuitively, the joint supporting subspace corresponds to a bilateral facial reduction between any two convex sets. It enables simple qualification-free generalizations for a host of central results of convex analysis. These include: an exact Fenchel-Rockafellar dual; Karush-Kuhn-Tucker (KKT) optimality conditions; attained infimal convolution for convex conjugates; subdifferential sum and chain rules; and a characterization of the normal cones of the intersection of two convex sets. All generalizations reduce seamlessly to their original formulations when qualification conditions hold.\n  We offer a number of characterizations for the joint supporting subspace, one of which is constructive. Our proofs are self-contained, and introduce a novel theoretical framework consisting of nested normals and supporting subspaces, which simultaneously describe both the boundary of convex sets and the lattice of faces.","authors":["Matthew S. Scott"],"pdf_url":"","comment":"Revision: Fixing the formula in Corollary 4.4, adding a proof for it, and fixing minor typos;Submitted to Mathematical Programming, series A;35 pages"},{"id":"http://arxiv.org/abs/2601.01575v1","updated":"2026-01-04T15:45:17Z","published":"2026-01-04T15:45:17Z","title":"A MINRES-based Linesearch Algorithm for Nonconvex Optimization with Non-positive Curvature Detection","summary":"We propose a MINRES-based Newton-type algorithm for solving unconstrained nonconvex optimization problems. Our approach uses the minimal residual method (MINRES), a well-known solver for indefinite symmetric linear systems, to compute descent directions that leverage second-order and non-positive curvature (NPC) information. Comprehensive asymptotic convergence properties are derived under standard assumptions. In particular, under the Kurdyka-Łojasiewicz inequality and a mild NPC-detectability condition, we prove that our algorithm can avoid strict saddle points and converge to second-order critical points. This is primarily achieved by integrating proper regularization techniques and forward linesearch mechanisms along NPC directions. Furthermore, fast local superlinear convergence to potentially non-isolated minima is established, when the local Polyak-Łojasiewicz condition is satisfied. Numerical experiments on the CUTEst test collection and on a deep auto-encoder problem illustrate the efficiency of the proposed method.","authors":["Hanfeng Zeng","Yang Liu","Wenqing Ouyang","Andre Milzarek"],"pdf_url":"","comment":"36 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.06855v2","updated":"2026-01-04T15:38:51Z","published":"2024-06-11T00:01:42Z","title":"Design and Scheduling of an AI-based Queueing System","summary":"To leverage prediction models to make optimal scheduling decisions in service systems, we must understand how predictive errors impact congestion due to externalities on the delay of other jobs. Motivated by applications where prediction models interact with human servers (e.g., content moderation), we consider a large queueing system comprising of many single server queues where the class of a job is estimated using a prediction model. By characterizing the impact of mispredictions on congestion cost in heavy traffic, we design an index-based policy that incorporates the predicted class information in a near-optimal manner. Our theoretical results guide the design of predictive models by providing a simple model selection procedure with downstream queueing performance as a central concern, and offer novel insights on how to design queueing systems with AI-based triage. We illustrate our framework on a content moderation task based on real online comments, where we construct toxicity classifiers by finetuning large language models.","authors":["Jiung Lee","Hongseok Namkoong","Yibo Zeng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14124v2","updated":"2026-01-04T14:54:49Z","published":"2025-12-16T06:11:10Z","title":"Complete Characterizations of Well-Posedness in Parametric Composite Optimization","summary":"This paper provides complete characterization of well-posedness for Karush-Kuhn-Tucker (KKT) systems associated with general problems of perturbed composite optimization. Leveraging the property of parabolic regularity for composite models, we show that the second-order subderivative of the cost function reduces to the novel second-order variational function playing a crucial role in the subsequent analysis. This foundational result implies that the strong second-order sufficient condition introduced in this work for the general class of composite optimization problems naturally extends the classical second-order sufficient condition in nonlinear programming. Then we obtain several equivalent characterizations of the second-order qualification condition (SOQC) and highlight its equivalence to the constraint nondegeneracy condition under the $\\mathcal{C}^{2}$-cone reducibility assumption. These insights lead us to multiple equivalent conditions for the major Lipschitz-like/Aubin property of KKT systems, including SOQC combined with the new second-order subdifferential condition and SOQC combined with tilt stability of local minimizers. Furthermore, under $\\mathcal{C}^{2}$-cone reducibility, we prove that the Lipschitz-like property of the reference KKT system is equivalent to its strong regularity. Finally, we demonstrate that the Lipschitz-like property is equivalent to the nonsingularity of the generalized Jacobian associated with the KKT system under a certain verifiable assumption. These results provide a unified and rigorous framework for analyzing stability and sensitivity of solutions to composite optimization problems, as well as for the design and justification of numerical algorithms.","authors":["Boris S. Mordukhovich","Peipei Tang","Chengjing Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01538v1","updated":"2026-01-04T14:21:45Z","published":"2026-01-04T14:21:45Z","title":"Lyapunov Functions can Exactly Quantify Rate Performance of Nonlinear Differential Equations","summary":"Pointwise-in-time stability notions for Ordinary Differential Equations (ODEs) provide quantitative metrics for system performance by establishing bounds on the rate of decay of the system state in terms of initial condition -- allowing stability to be quantified by e.g. the maximum provable decay rate. Such bounds may be obtained by finding suitable Lyapunov functions using, e.g. Sum-of-Squares (SOS) optimization. While Lyapunov tests have been proposed for numerous pointwise-in-time stability notions, including exponential, rational, and finite-time stability, it is unclear whether these characterizations are able to provide accurate bounds on system performance.\n  In this paper, we start by proposing a generalized notion of rate performance -- with exponential, rational, and finite-time decay rates being special cases. Then, for any such notion and rate, we associate a Lyapunov condition which is shown to be necessary and sufficient for a system to achieve that rate. Finally, we show how the proposed conditions can be enforced using SOS programming in the case of exponential, rational, and finite-time stability. Numerical examples in each case demonstrate that the corresponding SOS test can achieve tight bounds on the rate performance with accurate inner bounds on the associated regions of performance.","authors":["Declan S. Jagt","Matthew M. Peet"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01502v1","updated":"2026-01-04T12:05:48Z","published":"2026-01-04T12:05:48Z","title":"Multiscale replay: A robust algorithm for stochastic variational inequalities with a Markovian buffer","summary":"We introduce the Multiscale Experience Replay (MER) algorithm for solving a class of stochastic variational inequalities (VIs) in settings where samples are generated from a Markov chain and we have access to a memory buffer to store them. Rather than uniformly sampling from the buffer, MER utilizes a multi-scale sampling scheme to emulate the behavior of VI algorithms designed for independent and identically distributed samples, overcoming bias in the de facto serial scheme and thereby accelerating convergence. Notably, unlike standard sample-skipping variants of serial algorithms, MER is robust in that it achieves this acceleration in iteration complexity whenever possible, and without requiring knowledge of the mixing time of the Markov chain. We also discuss applications of MER, particularly in policy evaluation with temporal difference learning and in training generalized linear models with dependent data.","authors":["Milind Nakul","Tianjiao Li","Ashwin Pananjady"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01493v1","updated":"2026-01-04T11:40:22Z","published":"2026-01-04T11:40:22Z","title":"Accelerating Decentralized Optimization via Overlapping Local Steps","summary":"Decentralized optimization has emerged as a critical paradigm for distributed learning, enabling scalable training while preserving data privacy through peer-to-peer collaboration. However, existing methods often suffer from communication bottlenecks due to frequent synchronization between nodes. We present Overlapping Local Decentralized SGD (OLDSGD), a novel approach to accelerate decentralized training by computation-communication overlapping, significantly reducing network idle time. With a deliberately designed update, OLDSGD preserves the same average update as Local SGD while avoiding communication-induced stalls. Theoretically, we establish non-asymptotic convergence rates for smooth non-convex objectives, showing that OLDSGD retains the same iteration complexity as standard Local Decentralized SGD while improving per-iteration runtime. Empirical results demonstrate OLDSGD's consistent improvements in wall-clock time convergence under different levels of communication delays. With minimal modifications to existing frameworks, OLDSGD offers a practical solution for faster decentralized learning without sacrificing theoretical guarantees.","authors":["Yijie Zhou","Shi Pu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01489v1","updated":"2026-01-04T11:33:34Z","published":"2026-01-04T11:33:34Z","title":"Importance sampling of unbounded random stopping times: computing committor functions and exit rates without reweighting","summary":"Rare events in molecular dynamics are often related to noise-induced transitions between different macroscopic states (e.g., in protein folding). A common feature of these rare transitions is that they happen on timescales that are on average exponentially long compared to the characteristic timescale of the system, with waiting time distributions that have (sub)exponential tails and infinite support. As a result, sampling such rare events can lead to trajectories that can be become arbitrarily long, with not too low probability, which makes the reweighting of such trajectories a real challenge. Here, we discuss rare event simulation by importance sampling from a variational perspective, with a focus on applications in molecular dynamics, in particular the computation of committor functions. The idea is to design importance sampling schemes that (a) reduce the variance of a rare event estimator while controlling the average length of the trajectories and (b) that do not require the reweighting of possibly very long trajectories. In doing so, we study different stochastic control formulations for committor and mean first exit times, which we compare both from a theoretical and a computational point of view, including numerical studies of some benchmark examples.","authors":["Carsten Hartmann","Annika Jöster","Christof Schütte","Alexander Sikorski","Marcus Weber"],"pdf_url":"","comment":"51 pages, 7 figures"},{"id":"http://arxiv.org/abs/2512.04480v5","updated":"2026-01-04T08:02:04Z","published":"2025-12-04T05:33:28Z","title":"Auditing Human Decision-Making in High-Stakes Environments via Prescriptive AI: A Stress-Test on Real-Time Tactical Management","summary":"High-stakes decision-making is often compromised by cognitive biases and outcome dependency. Current AI models typically mimic historical human behavior, inheriting these biases and limiting their utility for normative improvement. Here, we introduce a Prescriptive AI framework designed to audit, rather than automate, human judgment in real-time environments. By decoupling decision quality from stochastic outcomes, we quantify \"decision latency\" and status quo bias in elite soccer management - a high-pressure adversarial domain. Analyzing 2018 FIFA World Cup data, our system exposes critical risk states, such as performance collapse following salient positive events (e.g., an assist), which human experts systematically overlook due to outcome bias. These findings demonstrate that interpretable auditing systems can reveal structural flaws in human reasoning that predictive models obscure. This approach establishes a paradigm for Human-AI interaction prioritizing epistemic accountability over predictive mimicry in safety-critical domains.","authors":["Pedro Passos","Patrick Moratori"],"pdf_url":"","comment":"Preprint; suitable for AI, decision sciences, and prescriptive analytics. Short versions published in Wharton Sports Analytics Journal Fall 2025 (AI Feature Spotlight) and accepted to AAAI Bridge on LM Reasoning 2026"},{"id":"http://arxiv.org/abs/2601.01413v1","updated":"2026-01-04T07:36:11Z","published":"2026-01-04T07:36:11Z","title":"GlycoPy: An Equation-Oriented and Object-Oriented Software for Hierarchical Modeling, Optimization, and Control in Python","summary":"Most existing model predictive control (MPC) applications in process industries employ lin-ear models, although real-world (bio)chemical processes are typically nonlinear. The use of linear models limits the performance and applicability of MPC for processes that span a wide range of operating conditions. A challenge in employing nonlinear models in MPC for com-plex systems is the lack of tools that facilitate hierarchical model development, as well as lack of efficient implementations of the corresponding nonlinear MPC (NMPC) algorithms. As a step towards making NMPC more practical for hierarchical systems, we introduce Gly-coPy, an equation-oriented, object-oriented software framework for process modeling, opti-mization, and NMPC in Python. GlycoPy enables users to focus on writing equations for modeling while supporting hierarchical modeling. GlycoPy includes algorithms for parame-ter estimation, dynamic optimization, and NMPC, and allows users to customize the simula-tion, optimization, and control algorithms. Three case studies, ranging from a simple differ-ential algebraic equation system to a multiscale bioprocess model, validate the modeling, optimization, and NMPC capabilities of GlycoPy. GlycoPy has the potential to bridge the gap between advanced NMPC algorithms and their practical application in real-world (bio)chemical processes.","authors":["Yingjie Ma","Jing Guo","Richard D. Braatz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01385v1","updated":"2026-01-04T05:40:29Z","published":"2026-01-04T05:40:29Z","title":"On IDA-PBC with Maximum Energy Shapeability","summary":"Interconnection and Damping Assignment Passivity-Based Control (IDA-PBC) is a well-established stabilization technique for affine nonlinear systems. However, its application is generally hindered by the requirement of solving a set of partial differential equations (PDEs), i.e., the so-called matching equation. This paper introduces the notion of \\emph{maximum energy shapeability} which describes the scenario that the homogeneous part of the matching equation admits $m$ independent solutions with $m$ the dimension of the control input. We demonstrate that the maximum energy shapeability enables a systematic procedure for the IDA-PBC design by transforming the matching equation into a set of easier-to-solve PDEs. Sufficient conditions for maximum energy shapeability are also provided. It is shown that some existing constructive IDA-PBC designs actually implicitly exploit the maximum energy shapeability. The proposed procedure for the IDA-PBC design is illustrated with the magnetic levitation system.","authors":["Ziheng Jiao","Chengshuai Wu","Bo Fan","Meng Zhang","Romeo Ortega"],"pdf_url":"","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2111.10766v3","updated":"2026-01-04T01:05:58Z","published":"2021-11-21T08:41:34Z","title":"Semismooth Newton Augmented Lagrangian Algorithm for Adaptive Lasso Penalized Least Squares in Semiparametric Regression","summary":"This paper is concerned with a partially linear semiparametric regression model containing an unknown regression coefficient, an unknown nonparametric function, and an unobservable Gaussian distributed random error. We focus on the case of simultaneous variable selection and estimation with a divergent number of covariates under the assumption that the regression coefficient is sparse. We consider the applications of the least squares to semiparametric regression and particularly present an adaptive lasso penalized least squares (PLS) method to select the regression coefficient. We note that there are many algorithms for PLS in various applications, but they seem to be rarely used in semiparametric regression. This paper focuses on using a semismooth Newton augmented Lagrangian (SSNAL) algorithm to solve the dual of PLS which is the sum of a smooth strongly convex function and an indicator function. At each iteration, there must be a strongly semismooth nonlinear system, which can be solved by semismooth Newton by making full use of the penalized term. We show that the algorithm offers a significant computational advantage, and the semismooth Newton method admits fast local convergence rate. Numerical experiments on simulated and real data have demonstrated the effectiveness of the PLS method and the progressiveness of the SSNAL algorithm.","authors":["Peili Li","Yunhai Xiao","Meixia Yang","Hanbing Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01311v1","updated":"2026-01-04T00:24:43Z","published":"2026-01-04T00:24:43Z","title":"Concave Certificates: Geometric Framework for Distributionally Robust Risk and Complexity Analysis","summary":"Distributionally Robust (DR) optimization aims to certify worst-case risk within a Wasserstein uncertainty set. Current certifications typically rely either on global Lipschitz bounds, which are often conservative, or on local gradient information, which provides only a first-order approximation. This paper introduces a novel geometric framework based on the least concave majorants of the growth rate function. Our proposed concave certificate establishes a tight bound of DR risk that remains applicable to non-Lipschitz and non-differentiable losses. We extend this framework to complexity analysis, introducing a deterministic bound that complements standard statistical generalization bound. Furthermore, we utilize this certificate to bound the gap between adversarial and empirical Rademacher complexity, demonstrating that dependencies on input diameter, network width, and depth can be eliminated. For practical application in deep learning, we introduce the adversarial score as a tractable relaxation of the concave certificate that enables efficient and layer-wise analysis of neural networks. We validate our theoretical results in various numerical experiments on classification and regression tasks on real-world data.","authors":["Hong T. M. Chu"],"pdf_url":"","comment":"30 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.01306v1","updated":"2026-01-04T00:04:05Z","published":"2026-01-04T00:04:05Z","title":"Towards a Principled Muon under $μ\\mathsf{P}$: Ensuring Spectral Conditions throughout Training","summary":"The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.","authors":["John Zhao"],"pdf_url":"","comment":"21 pages, 0 figures"}],"Performance":[{"id":"http://arxiv.org/abs/2601.01353v1","updated":"2026-01-04T03:48:02Z","published":"2026-01-04T03:48:02Z","title":"Benchmarking Quantum Data Center Architectures: A Performance and Scalability Perspective","summary":"Scalable distributed quantum computing (DQC) has motivated the design of multiple quantum data-center (QDC) architectures that overcome the limitations of single quantum processors through modular interconnection. While these architectures adopt fundamentally different design philosophies, their relative performance under realistic quantum hardware constraints remains poorly understood.\n  In this paper, we present a systematic benchmarking study of four representative QDC architectures-QFly, BCube, Clos, and Fat-Tree-quantifying their impact on distributed quantum circuit execution latency, resource contention, and scalability. Focusing on quantum-specific effects absent from classical data-center evaluations, we analyze how optical-loss-induced Einstein-Podolsky-Rosen (EPR) pair generation delays, coherence-limited entanglement retry windows, and contention from teleportation-based non-local gates shape end-to-end execution performance. Across diverse circuit workloads, we evaluate how architectural properties such as path diversity and path length, and shared BSM (Bell State Measurement) resources interact with optical-switch insertion loss and reconfiguration delay. Our results show that distributed quantum performance is jointly shaped by topology, scheduling policies, and physical-layer parameters, and that these factors interact in nontrivial ways. Together, these insights provide quantitative guidance for the design of scalable and high-performance quantum data-center architectures for DQC.","authors":["Shahrooz Pouryousef","Eneet Kaur","Hassan Shapourian","Don Towsley","Ramana Kompella","Reza Nejabati"],"pdf_url":"","comment":null}],"computadora Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2601.01695v1","updated":"2026-01-04T23:59:06Z","published":"2026-01-04T23:59:06Z","title":"Learnability-Driven Submodular Optimization for Active Roadside 3D Detection","summary":"Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.","authors":["Ruiyu Mao","Baoming Zhang","Nicholas Ruozzi","Yunhui Guo"],"pdf_url":"","comment":"10 pages, 7 figures. Submitted to CVPR 2026"},{"id":"http://arxiv.org/abs/2512.09907v2","updated":"2026-01-04T23:12:23Z","published":"2025-12-10T18:36:18Z","title":"VisualActBench: Can VLMs See and Act like a Human?","summary":"Vision-Language Models (VLMs) have achieved impressive progress in perceiving and describing visual environments. However, their ability to proactively reason and act based solely on visual inputs, without explicit textual prompts, remains underexplored. We introduce a new task, Visual Action Reasoning, and propose VisualActBench, a large-scale benchmark comprising 1,074 videos and 3,733 human-annotated actions across four real-world scenarios. Each action is labeled with an Action Prioritization Level (APL) and a proactive-reactive type to assess models' human-aligned reasoning and value sensitivity. We evaluate 29 VLMs on VisualActBench and find that while frontier models like GPT4o demonstrate relatively strong performance, a significant gap remains compared to human-level reasoning, particularly in generating proactive, high-priority actions. Our results highlight limitations in current VLMs' ability to interpret complex context, anticipate outcomes, and align with human decision-making frameworks. VisualActBench establishes a comprehensive foundation for assessing and improving the real-world readiness of proactive, vision-centric AI agents.","authors":["Daoan Zhang","Pai Liu","Xiaofei Zhou","Yuan Ge","Guangchen Lan","Jing Bi","Christopher Brinton","Ehsan Hoque","Jiebo Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01689v1","updated":"2026-01-04T23:03:03Z","published":"2026-01-04T23:03:03Z","title":"Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data","summary":"Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.","authors":["Afzal Hossain","Stephanie Schuckers"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01687v1","updated":"2026-01-04T22:57:49Z","published":"2026-01-04T22:57:49Z","title":"FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation","summary":"Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.","authors":["Abdur R. Fayjie","Pankhi Kashyap","Jutika Borah","Patrick Vandewalle"],"pdf_url":"","comment":"20 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2601.01680v1","updated":"2026-01-04T22:30:28Z","published":"2026-01-04T22:30:28Z","title":"Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages","summary":"Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential.","authors":["Afzal Hossain","Mst Rumana Sumi","Stephanie Schuckers"],"pdf_url":"","comment":"Accepted and presented at IEEE IJCB 2025 conference; final published version forthcoming"},{"id":"http://arxiv.org/abs/2601.01677v1","updated":"2026-01-04T22:05:17Z","published":"2026-01-04T22:05:17Z","title":"Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada","summary":"In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.","authors":["Zhengsen Xu","Lanying Wang","Sibo Cheng","Xue Rui","Kyle Gao","Yimin Zhu","Mabel Heffring","Zack Dewis","Saeid Taleghanidoozdoozan","Megan Greenwood","Motasem Alkayid","Quinn Ledingham","Hongjie He","Jonathan Li","Lincoln Linlin Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01676v1","updated":"2026-01-04T22:03:45Z","published":"2026-01-04T22:03:45Z","title":"LabelAny3D: Label Any Object 3D in the Wild","summary":"Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \\emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.","authors":["Jin Yao","Radowan Mahmud Redoy","Sebastian Elbaum","Matthew B. Dwyer","Zezhou Cheng"],"pdf_url":"","comment":"NeurIPS 2025. Project page: https://uva-computer-vision-lab.github.io/LabelAny3D/"},{"id":"http://arxiv.org/abs/2601.01660v1","updated":"2026-01-04T20:42:06Z","published":"2026-01-04T20:42:06Z","title":"Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows","summary":"We present a method for consistent lighting and shadows when animated 3D Gaussian Splatting (3DGS) avatars interact with 3DGS scenes or with dynamic objects inserted into otherwise static scenes. Our key contribution is Deep Gaussian Shadow Maps (DGSM), a modern analogue of the classical shadow mapping algorithm tailored to the volumetric 3DGS representation. Building on the classic deep shadow mapping idea, we show that 3DGS admits closed form light accumulation along light rays, enabling volumetric shadow computation without meshing. For each estimated light, we tabulate transmittance over concentric radial shells and store them in octahedral atlases, which modern GPUs can sample in real time per query to attenuate affected scene Gaussians and thus cast and receive shadows consistently. To relight moving avatars, we approximate the local environment illumination with HDRI probes represented in a spherical harmonic (SH) basis and apply a fast per Gaussian radiance transfer, avoiding explicit BRDF estimation or offline optimization. We demonstrate environment consistent lighting for avatars from AvatarX and ActorsHQ, composited into ScanNet++, DL3DV, and SuperSplat scenes, and show interactions with inserted objects. Across single and multi avatar settings, DGSM and SH relighting operate fully in the volumetric 3DGS representation, yielding coherent shadows and relighting while avoiding meshing.","authors":["Aymen Mir","Riza Alp Guler","Jian Wang","Gerard Pons-Moll","Bing Zhou"],"pdf_url":"","comment":"Our project page is available at https://miraymen.github.io/dgsm"},{"id":"http://arxiv.org/abs/2404.00645v2","updated":"2026-01-04T20:12:08Z","published":"2024-03-31T11:09:19Z","title":"Attire-Based Anomaly Detection in Restricted Areas Using YOLOv8 for Enhanced CCTV Security","summary":"This research introduces an innovative security enhancement approach, employing advanced image analysis and soft computing. The focus is on an intelligent surveillance system that detects unauthorized individuals in restricted areas by analyzing attire. Traditional security measures face challenges in monitoring unauthorized access. Leveraging YOLOv8, an advanced object detection algorithm, our system identifies authorized personnel based on their attire in CCTV footage. The methodology involves training the YOLOv8 model on a comprehensive dataset of uniform patterns, ensuring precise recognition in specific regions. Soft computing techniques enhance adaptability to dynamic environments and varying lighting conditions. This research contributes to image analysis and soft computing, providing a sophisticated security solution. Emphasizing uniform-based anomaly detection, it establishes a foundation for robust security systems in restricted areas. The outcomes highlight the potential of YOLOv8-based surveillance in ensuring safety in sensitive locations.","authors":["Abdul Aziz A. B","Aindri Bajpai"],"pdf_url":"","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2512.02636v2","updated":"2026-01-04T19:13:04Z","published":"2025-12-02T10:48:20Z","title":"Joint Distillation for Fast Likelihood Evaluation and Sampling in Flow-based Models","summary":"Log-likelihood evaluation enables important capabilities in generative models, including model comparison, certain fine-tuning objectives, and many downstream applications. Yet paradoxically, some of today's best generative models -- diffusion and flow-based models -- still require hundreds to thousands of neural function evaluations (NFEs) to compute a single likelihood. While recent distillation methods have successfully accelerated sampling to just a few steps, they achieve this at the cost of likelihood tractability: existing approaches either abandon likelihood computation entirely or still require expensive integration over full trajectories. We present fast flow joint distillation (F2D2), a framework that simultaneously reduces the number of NFEs required for both sampling and likelihood evaluation by two orders of magnitude. Our key insight is that in continuous normalizing flows, the coupled ODEs for sampling and likelihood are computed from a shared underlying velocity field, allowing us to jointly distill both the sampling trajectory and cumulative divergence using a single model. F2D2 is modular, compatible with existing flow-based few-step sampling models, and requires only an additional divergence prediction head. Experiments demonstrate F2D2's capability of achieving accurate log-likelihood with few-step evaluations while maintaining high sample quality, solving a long-standing computational bottleneck in flow-based generative models. As an application of our approach, we propose a lightweight self-guidance method that enables a 2-step MeanFlow to outperform a 1024 step flow matching model with only a single additional backward NFE.","authors":["Xinyue Ai","Yutong He","Albert Gu","Ruslan Salakhutdinov","J Zico Kolter","Nicholas Matthew Boffi","Max Simchowitz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01639v1","updated":"2026-01-04T19:05:45Z","published":"2026-01-04T19:05:45Z","title":"An Empirical Study of Monocular Human Body Measurement Under Weak Calibration","summary":"Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.","authors":["Gaurav Sekar"],"pdf_url":"","comment":"The paper consists of 8 pages, 2 figures (on pages 4 and 7), and 2 tables (both on page 6)"},{"id":"http://arxiv.org/abs/2511.16262v4","updated":"2026-01-04T17:54:29Z","published":"2025-11-20T11:41:48Z","title":"How Robot Dogs See the Unseeable: Improving Visual Interpretability via Peering for Exploratory Robots","summary":"In vegetated environments, such as forests, exploratory robots play a vital role in navigating complex, cluttered environments where human access is limited and traditional equipment struggles. Visual occlusion from obstacles, such as foliage, can severely obstruct a robot's sensors, impairing scene understanding. We show that \"peering\", a characteristic side-to-side movement used by insects to overcome their visual limitations, can also allow robots to markedly improve visual reasoning under partial occlusion. This is accomplished by applying core signal processing principles, specifically optical synthetic aperture sensing, together with the vision reasoning capabilities of modern large multimodal models. Peering enables real-time, high-resolution, and wavelength-independent perception, which is crucial for vision-based scene understanding across a wide range of applications. The approach is low-cost and immediately deployable on any camera-equipped robot. We investigated different peering motions and occlusion masking strategies, demonstrating that, unlike peering, state-of-the-art multi-view 3D vision techniques fail in these conditions due to their high susceptibility to occlusion. Our experiments were carried out on an industrial-grade quadrupedal robot. However, the ability to peer is not limited to such platforms, but potentially also applicable to bipedal, hexapod, wheeled, or crawling platforms. Robots that can effectively see through partial occlusion will gain superior perception abilities - including enhanced scene understanding, situational awareness, camouflage breaking, and advanced navigation in complex environments.","authors":["Oliver Bimber","Karl Dietrich von Ellenrieder","Michael Haller","Rakesh John Amala Arokia Nathan","Gianni Lunardi","Mohamed Youssef","Marco Camurri","Santos Miguel Orozco Soto","Jeremy E. Niven"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01613v1","updated":"2026-01-04T17:30:45Z","published":"2026-01-04T17:30:45Z","title":"CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment","summary":"Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.","authors":["Kazi Ramisa Rifa","Jie Zhang","Abdullah Imran"],"pdf_url":"","comment":"18 pages, 9 figures, 5 tables"},{"id":"http://arxiv.org/abs/2601.01608v1","updated":"2026-01-04T17:18:27Z","published":"2026-01-04T17:18:27Z","title":"Guiding Token-Sparse Diffusion Models","summary":"Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.","authors":["Felix Krause","Stefan Andreas Baumann","Johannes Schusterbauer","Olga Grebenkova","Ming Gui","Vincent Tao Hu","Björn Ommer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.09827v2","updated":"2026-01-04T17:08:17Z","published":"2025-11-13T00:19:18Z","title":"AHA! Animating Human Avatars in Diverse Scenes with Gaussian Splatting","summary":"We present a novel framework for animating humans in 3D scenes using 3D Gaussian Splatting (3DGS), a neural scene representation that has recently achieved state-of-the-art photorealistic results for novel-view synthesis but remains under-explored for human-scene animation and interaction. Unlike existing animation pipelines that use meshes or point clouds as the underlying 3D representation, our approach introduces the use of 3DGS as the 3D representation for animating humans in scenes. By representing humans and scenes as Gaussians, our approach allows geometry-consistent free-viewpoint rendering of humans interacting with 3D scenes. Our key insight is that rendering can be decoupled from motion synthesis, and each sub-problem can be addressed independently without the need for paired human-scene data. Central to our method is a Gaussian-aligned motion module that synthesizes motion without explicit scene geometry, using opacity-based cues and projected Gaussian structures to guide human placement and pose alignment. To ensure natural interactions, we further propose a human-scene Gaussian refinement optimization that enforces realistic contact and navigation. We evaluate our approach on scenes from Scannet++ and the SuperSplat library, and on avatars reconstructed from sparse and dense multi-view human capture. Finally, we demonstrate that our framework enables novel applications such as geometry-consistent free-viewpoint rendering of edited monocular RGB videos with newly animated humans, showcasing the unique advantages of 3DGS for monocular video-based human animation. To assess the full quality of our results, we encourage readers to view the supplementary material available at https://miraymen.github.io/aha/ .","authors":["Aymen Mir","Jian Wang","Riza Alp Guler","Chuan Guo","Gerard Pons-Moll","Bing Zhou"],"pdf_url":"","comment":"Project page available at: https://miraymen.github.io/aha/"},{"id":"http://arxiv.org/abs/2507.14697v3","updated":"2026-01-04T17:04:58Z","published":"2025-07-19T17:15:46Z","title":"GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset","summary":"Agricultural parcels serve as basic units for conducting agricultural practices and applications, which is vital for land ownership registration, food security assessment, soil erosion monitoring, etc. However, existing agriculture parcel extraction studies only focus on mid-resolution mapping or regular plain farmlands while lacking representation of complex terraced terrains due to the demands of precision agriculture.In this paper, we introduce a more fine-grained terraced parcel dataset named GTPBD (Global Terraced Parcel and Boundary Dataset), which is the first fine-grained dataset covering major worldwide terraced regions with more than 200,000 complex terraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution images with three-level labels, including pixel-level boundary labels, mask labels, and parcel labels. It covers seven major geographic zones in China and transcontinental climatic regions around the world.Compared to the existing datasets, the GTPBD dataset brings considerable challenges due to the: (1) terrain diversity; (2) complex and irregular parcel objects; and (3) multiple domain styles. Our proposed GTPBD dataset is suitable for four different tasks, including semantic segmentation, edge detection, terraced parcel extraction, and unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the GTPBD dataset on eight semantic segmentation methods, four edge extraction methods, three parcel extraction methods, and five UDA methods, along with a multi-dimensional evaluation framework integrating pixel-level and object-level metrics. GTPBD fills a critical gap in terraced remote sensing research, providing a basic infrastructure for fine-grained agricultural terrain analysis and cross-scenario knowledge transfer.","authors":["Zhiwei Zhang","Zi Ye","Yibin Wen","Shuai Yuan","Haohuan Fu","Jianxi Huang","Juepeng Zheng"],"pdf_url":"","comment":"40 pages, 40 figures, Accepted to the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)"},{"id":"http://arxiv.org/abs/2601.01593v1","updated":"2026-01-04T16:46:13Z","published":"2026-01-04T16:46:13Z","title":"Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation","summary":"Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.","authors":["Haonan Cai","Yuxuan Luo","Zhouhui Lian"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2601.01592v1","updated":"2026-01-04T16:41:33Z","published":"2026-01-04T16:41:33Z","title":"OpenRT: An Open-Source Red Teaming Framework for Multimodal LLMs","summary":"The rapid integration of Multimodal Large Language Models (MLLMs) into critical applications is increasingly hindered by persistent safety vulnerabilities. However, existing red-teaming benchmarks are often fragmented, limited to single-turn text interactions, and lack the scalability required for systematic evaluation. To address this, we introduce OpenRT, a unified, modular, and high-throughput red-teaming framework designed for comprehensive MLLM safety evaluation. At its core, OpenRT architects a paradigm shift in automated red-teaming by introducing an adversarial kernel that enables modular separation across five critical dimensions: model integration, dataset management, attack strategies, judging methods, and evaluation metrics. By standardizing attack interfaces, it decouples adversarial logic from a high-throughput asynchronous runtime, enabling systematic scaling across diverse models. Our framework integrates 37 diverse attack methodologies, spanning white-box gradients, multi-modal perturbations, and sophisticated multi-agent evolutionary strategies. Through an extensive empirical study on 20 advanced models (including GPT-5.2, Claude 4.5, and Gemini 3 Pro), we expose critical safety gaps: even frontier models fail to generalize across attack paradigms, with leading models exhibiting average Attack Success Rates as high as 49.14%. Notably, our findings reveal that reasoning models do not inherently possess superior robustness against complex, multi-turn jailbreaks. By open-sourcing OpenRT, we provide a sustainable, extensible, and continuously maintained infrastructure that accelerates the development and standardization of AI safety.","authors":["Xin Wang","Yunhao Chen","Juncheng Li","Yixu Wang","Yang Yao","Tianle Gu","Jie Li","Yan Teng","Xingjun Ma","Yingchun Wang","Xia Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.04666v2","updated":"2026-01-04T16:07:12Z","published":"2024-12-05T23:33:03Z","title":"Bridging Geometry and Appearance: Topological Features for Robust Self-Supervised Segmentation","summary":"Self-supervised semantic segmentation methods often fail when faced with appearance ambiguities. We argue that this is due to an over-reliance on unstable, appearance-based features such as shadows, glare, and local textures. We propose \\textbf{GASeg}, a novel framework that bridges appearance and geometry by leveraging stable topological information. The core of our method is Differentiable Box-Counting (\\textbf{DBC}) module, which quantifies multi-scale topological statistics from two parallel streams: geometric-based features and appearance-based features. To force the model to learn these stable structural representations, we introduce Topological Augmentation (\\textbf{TopoAug}), an adversarial strategy that simulates real-world ambiguities by applying morphological operators to the input images. A multi-objective loss, \\textbf{GALoss}, then explicitly enforces cross-modal alignment between geometric-based and appearance-based features. Extensive experiments demonstrate that GASeg achieves state-of-the-art performance on four benchmarks, including COCO-Stuff, Cityscapes, and PASCAL, validating our approach of bridging geometry and appearance via topological information.","authors":["Kebin Peng","Haotang Li","Zhenyu Qi","Huashan Chen","Zi Wang","Wei Zhang","Sen He","Huanrui Yang","Qing Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01568v1","updated":"2026-01-04T15:26:15Z","published":"2026-01-04T15:26:15Z","title":"MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning","summary":"Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.","authors":["Chunyu Qiang","Jun Wang","Xiaopeng Wang","Kang Yin","Yuxin Guo","Xijuan Zeng","Nan Li","Zihan Li","Yuzhe Liang","Ziyu Zhang","Teng Ma","Yushen Chen","Zhongliang Liu","Feng Deng","Chen Zhang","Pengfei Wan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01547v1","updated":"2026-01-04T14:42:39Z","published":"2026-01-04T14:42:39Z","title":"EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding","summary":"The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.","authors":["Tianjun Gu","Chenghua Gong","Jingyu Gong","Zhizhong Zhang","Yuan Xie","Lizhuang Ma","Xin Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01541v1","updated":"2026-01-04T14:32:04Z","published":"2026-01-04T14:32:04Z","title":"Sim2Real SAR Image Restoration: Metadata-Driven Models for Joint Despeckling and Sidelobes Reduction","summary":"Synthetic aperture radar (SAR) provides valuable information about the Earth's surface under all weather and illumination conditions. However, the inherent phenomenon of speckle and the presence of sidelobes around bright targets pose challenges for accurate interpretation of SAR imagery. Most existing SAR image restoration methods address despeckling and sidelobes reduction as separate tasks. In this paper, we propose a unified framework that jointly performs both tasks using neural networks (NNs) trained on a realistic SAR simulated dataset generated with MOCEM. Inference can then be performed on real SAR images, demonstrating effective simulation to real (Sim2Real) transferability. Additionally, we incorporate acquisition metadata as auxiliary input to the NNs, demonstrating improved restoration performance.","authors":["Antoine De Paepe","Pascal Nguyen","Michael Mabelle","Cédric Saleun","Antoine Jouadé","Jean-Christophe Louvigne"],"pdf_url":"","comment":"Accepted at the Conference on Artificial Intelligence for Defense (CAID), 2025, Rennes, France"}],"Image and Video Processing":[{"id":"http://arxiv.org/abs/2512.01702v2","updated":"2026-01-04T21:03:21Z","published":"2025-12-01T14:07:39Z","title":"A unified framework for geometry-independent operator learning in cardiac electrophysiology simulations","summary":"Learning biophysically accurate solution operators for cardiac electrophysiology is fundamentally challenged by geometric variability across patient-specific heart anatomies. Most existing neural operator approaches are limited to structured or weakly deformed domains, restricting their applicability to realistic atrial and ventricular geometries. Here, we introduce a unified operator-learning framework that projects inputs and outputs onto a standardised anatomical coordinate system, decoupling electrophysiological dynamics from mesh topology. This formulation enables geometry-independent learning while preserving physiologically meaningful spatial organisation, and allows predictions to be interpolated back onto patient-specific geometries for anatomical interpretation.\n  To support large-scale training within the framework, we develop a GPU-accelerated electrophysiology solver and generate over 300,000 high-fidelity simulations across diverse patient-specific left atrial geometries with varied pacing and conduction properties. Within this anatomical coordinate domain, we design a neural operator to predict full-field local activation time maps, achieving a mean absolute error of 5.1 ms and an inference time of 0.12 ms per sample, outperforming existing operator learning and convolutional baselines. We further validate the framework on ventricular geometries, demonstrating robust generalisation beyond the atrial setting. Together, this framework establishes a scalable foundation for fast, geometry-invariant cardiac electrophysiology modelling, with potential relevance for real-time and population-scale clinical workflows.","authors":["Bei Zhou","Cesare Corrado","Shuang Qian","Maximilian Balmus","Angela W. C. Lee","Cristobal Rodero","Caroline Roney","Marco J. W. Gotte","Luuk H. G. A. Hopman","Mengyun Qiao","Steven Niederer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01655v1","updated":"2026-01-04T20:17:32Z","published":"2026-01-04T20:17:32Z","title":"UniCrop: A Universal, Multi-Source Data Engineering Pipeline for Scalable Crop Yield Prediction","summary":"Accurate crop yield prediction relies on diverse data streams, including satellite, meteorological, soil, and topographic information. However, despite rapid advances in machine learning, existing approaches remain crop- or region-specific and require data engineering efforts. This limits scalability, reproducibility, and operational deployment. This study introduces UniCrop, a universal and reusable data pipeline designed to automate the acquisition, cleaning, harmonisation, and engineering of multi-source environmental data for crop yield prediction. For any given location, crop type, and temporal window, UniCrop automatically retrieves, harmonises, and engineers over 200 environmental variables (Sentinel-1/2, MODIS, ERA5-Land, NASA POWER, SoilGrids, and SRTM), reducing them to a compact, analysis-ready feature set utilising a structured feature reduction workflow with minimum redundancy maximum relevance (mRMR). To validate, UniCrop was applied to a rice yield dataset comprising 557 field observations. Using only the selected 15 features, four baseline machine learning models (LightGBM, Random Forest, Support Vector Regression, and Elastic Net) were trained. LightGBM achieved the best single-model performance (RMSE = 465.1 kg/ha, $R^2 = 0.6576$), while a constrained ensemble of all baselines further improved accuracy (RMSE = 463.2 kg/ha, $R^2 = 0.6604$). UniCrop contributes a scalable and transparent data-engineering framework that addresses the primary bottleneck in operational crop yield modelling: the preparation of consistent and harmonised multi-source data. By decoupling data specification from implementation and supporting any crop, region, and time frame through simple configuration updates, UniCrop provides a practical foundation for scalable agricultural analytics. The code and implementation documentation are shared in https://github.com/CoDIS-Lab/UniCrop.","authors":["Emiliya Khidirova","Oktay Karakuş"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01541v1","updated":"2026-01-04T14:32:04Z","published":"2026-01-04T14:32:04Z","title":"Sim2Real SAR Image Restoration: Metadata-Driven Models for Joint Despeckling and Sidelobes Reduction","summary":"Synthetic aperture radar (SAR) provides valuable information about the Earth's surface under all weather and illumination conditions. However, the inherent phenomenon of speckle and the presence of sidelobes around bright targets pose challenges for accurate interpretation of SAR imagery. Most existing SAR image restoration methods address despeckling and sidelobes reduction as separate tasks. In this paper, we propose a unified framework that jointly performs both tasks using neural networks (NNs) trained on a realistic SAR simulated dataset generated with MOCEM. Inference can then be performed on real SAR images, demonstrating effective simulation to real (Sim2Real) transferability. Additionally, we incorporate acquisition metadata as auxiliary input to the NNs, demonstrating improved restoration performance.","authors":["Antoine De Paepe","Pascal Nguyen","Michael Mabelle","Cédric Saleun","Antoine Jouadé","Jean-Christophe Louvigne"],"pdf_url":"","comment":"Accepted at the Conference on Artificial Intelligence for Defense (CAID), 2025, Rennes, France"},{"id":"http://arxiv.org/abs/2405.08745v2","updated":"2026-01-04T02:35:27Z","published":"2024-05-14T16:32:11Z","title":"Enhancing Blind Video Quality Assessment with Rich Quality-aware Features","summary":"Blind video quality assessment (BVQA) is a highly challenging task due to the intrinsic complexity of video content and visual distortions, especially given the high popularity of social media videos, which originate from a wide range of sources, and are often processed by various compression and enhancement algorithms. While recent BVQA and blind image quality assessment (BIQA) studies have made remarkable progress, their models typically perform well on the datasets they were trained on but generalize poorly to unseen videos, making them less effective for accurately evaluating the perceptual quality of diverse social media videos. In this paper, we propose Rich Quality-aware features enabled Video Quality Assessment (RQ-VQA), a simple yet effective method to enhance BVQA by leveraging rich quality-aware features extracted from off-the-shelf BIQA and BVQA models. Our approach exploits the expertise of existing quality assessment models within their trained domains to improve generalization. Specifically, we design a multi-source feature framework that integrates:(1) Learnable spatial features} from a base model fine-tuned on the target VQA dataset to capture domain-specific quality cues; (2) Temporal motion features from the fast pathway of SlowFast pre-trained on action recognition datasets to model motion-related distortions; (3) Spatial quality-aware features from BIQA models trained on diverse IQA datasets to enhance frame-level distortion representation; and (4) Spatiotemporal quality-aware features from a BVQA model trained on large-scale VQA datasets to jointly encode spatial structure and temporal dynamics. These features are concatenated and fed into a multi-layer perceptron (MLP) to regress them into quality scores. Experimental results demonstrate that our model achieves state-of-the-art performance on three public social media VQA datasets.","authors":["Wei Sun","Linhan Cao","Jun Jia","Zhichao Zhang","Zicheng Zhang","Xiongkuo Min","Guangtao Zhai"],"pdf_url":"","comment":"RQ-VQA won first place in the CVPR NTIRE 2024 Short-form UGC Video Quality Assessment Challenge"},{"id":"http://arxiv.org/abs/2601.01322v1","updated":"2026-01-04T01:17:36Z","published":"2026-01-04T01:17:36Z","title":"LinMU: Multimodal Understanding Made Linear","summary":"Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\\times$ and improves token throughput by up to 9.0$\\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.","authors":["Hongjie Wang","Niraj K. Jha"],"pdf_url":"","comment":"23 pages, 7 figures"}],"Graphics":[{"id":"http://arxiv.org/abs/2506.21811v2","updated":"2026-01-04T06:07:09Z","published":"2025-03-04T08:11:27Z","title":"Revisiting Graph Analytics Benchmark","summary":"The rise of graph analytics platforms has led to the development of various benchmarks for evaluating and comparing platform performance. However, existing benchmarks often fall short of fully assessing performance due to limitations in core algorithm selection, data generation processes (and the corresponding synthetic datasets), as well as the neglect of API usability evaluation. To address these shortcomings, we propose a novel graph analytics benchmark. First, we select eight core algorithms by extensively reviewing both academic and industrial settings. Second, we design an efficient and flexible data generator and produce eight new synthetic datasets as the default datasets for our benchmark. Lastly, we introduce a multi-level large language model (LLM)-based framework for API usability evaluation-the first of its kind in graph analytics benchmarks. We conduct comprehensive experimental evaluations on existing platforms (GraphX, PowerGraph, Flash, Grape, Pregel+, Ligra and G-thinker). The experimental results demonstrate the superiority of our proposed benchmark.","authors":["Lingkai Meng","Yu Shao","Long Yuan","Longbin Lai","Peng Cheng","Xue Li","Wenyuan Yu","Wenjie Zhang","Xuemin Lin","Jingren Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01361v1","updated":"2026-01-04T04:18:22Z","published":"2026-01-04T04:18:22Z","title":"VARTS: A Tool for the Visualization and Analysis of Representative Time Series Data","summary":"Large-scale time series visualization often suffers from excessive visual clutter and redundant patterns, making it difficult for users to understand the main temporal trends. To address this challenge, we present VARTS, an interactive visual analytics tool for representative time series selection and visualization. Building upon our previous work M4-Greedy, VARTS integrates M4-based sampling, DTW-based similarity computation, and greedy selection into a unified workflow for the identification and visualization of representative series. The tool provides a responsive graphical interface that allows users to import time series datasets, perform representative selection, and visualize both raw and reduced data through multiple coordinated views. By reducing redundancy while preserving essential data patterns, VARTS effectively enhances visual clarity and interpretability for large-scale time series analysis. The demo video is available at https://youtu.be/mS9f12Rf0jo.","authors":["Duosi Jin","Jianqiu Xu","Guidong Zhang"],"pdf_url":"","comment":null}],"Signal Processing":[{"id":"http://arxiv.org/abs/2510.06355v2","updated":"2026-01-04T19:08:51Z","published":"2025-10-07T18:21:47Z","title":"PIKAN: Physics-Inspired Kolmogorov-Arnold Networks for Explainable UAV Channel Modelling","summary":"Unmanned aerial vehicle (UAV) communications demand accurate yet interpretable air-to-ground (A2G) channel models that can adapt to nonstationary propagation environments. While deterministic models offer interpretability and deep learning (DL) models provide accuracy, both approaches suffer from either rigidity or a lack of explainability. To bridge this gap, we propose the Physics-Inspired Kolmogorov-Arnold Network (PIKAN) that embeds physical principles (e.g., free-space path loss, two-ray reflections) into the learning process. Unlike physics-informed neural networks (PINNs), PIKAN is more flexible for applying physical information because it introduces them as flexible inductive biases. Thus, it enables a more flexible training process. Experiments on UAV A2G measurement data show that PIKAN achieves comparable accuracy to DL models while providing symbolic and explainable expressions aligned with propagation laws. Remarkably, PIKAN achieves this performance with only 232 parameters, making it up to 37 times lighter than multilayer perceptron (MLP) baselines with thousands of parameters, without sacrificing correlation with measurements and also providing symbolic expressions. These results highlight PIKAN as an efficient, interpretable, and scalable solution for UAV channel modelling in beyond-5G and 6G networks.","authors":["Kürşat Tekbıyık","Güneş Karabulut Kurt","Antoine Lesage-Landry"],"pdf_url":"","comment":"This paper has been accepted for IEEE Aerospace Conference"},{"id":"http://arxiv.org/abs/2601.01616v1","updated":"2026-01-04T17:51:19Z","published":"2026-01-04T17:51:19Z","title":"Real Time NILM Based Power Monitoring of Identical Induction Motors Representing Cutting Machines in Textile Industry","summary":"The textile industry in Bangladesh is one of the most energy-intensive sectors, yet its monitoring practices remain largely outdated, resulting in inefficient power usage and high operational costs. To address this, we propose a real-time Non-Intrusive Load Monitoring (NILM)-based framework tailored for industrial applications, with a focus on identical motor-driven loads representing textile cutting machines. A hardware setup comprising voltage and current sensors, Arduino Mega and ESP8266 was developed to capture aggregate and individual load data, which was stored and processed on cloud platforms. A new dataset was created from three identical induction motors and auxiliary loads, totaling over 180,000 samples, to evaluate the state-of-the-art MATNILM model under challenging industrial conditions. Results indicate that while aggregate energy estimation was reasonably accurate, per-appliance disaggregation faced difficulties, particularly when multiple identical machines operated simultaneously. Despite these challenges, the integrated system demonstrated practical real-time monitoring with remote accessibility through the Blynk application. This work highlights both the potential and limitations of NILM in industrial contexts, offering insights into future improvements such as higher-frequency data collection, larger-scale datasets and advanced deep learning approaches for handling identical loads.","authors":["Md Istiauk Hossain Rifat","Moin Khan","Mohammad Zunaed"],"pdf_url":"","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2601.01598v1","updated":"2026-01-04T16:58:55Z","published":"2026-01-04T16:58:55Z","title":"KAN-AE with Non-Linearity Score and Symbolic Regression for Energy-Efficient Channel Coding","summary":"In this paper, we investigate Kolmogorov-Arnold network-based autoencoders (KAN-AEs) with symbolic regression (SR) for energy-efficient channel coding. By using SR, we convert KAN-AEs into symbolic expressions, which enables low-complexity implementation and improved energy efficiency at the radios. To further enhance the efficiency, we introduce a new non-linearity score term in the SR process to help select lower-complexity equations when possible. Through numerical simulations, we demonstrate that KAN-AEs achieve competitive BLER performance while improving energy efficiency when paired with SR. We score the energy efficiency of a KAN-AE implementation using the proposed non-linearity metric and compare it to a multi-layer perceptron-based autoencoder (MLP-AE). Our experiment shows that the KAN-AE paired with SR uses 1.38 times less energy than the MLP-AE, supporting that KAN-AEs are a promising choice for energy-efficient deep learning-based channel coding.","authors":["Anthony Joseph Perre","Parker Huggins","Alphan Sahin"],"pdf_url":"","comment":"IEEE Consumer Communications & Networking Conference 2026 (IEEE CCNC 2026), 9-12 January 2026, Las Vegas, NV, USA"},{"id":"http://arxiv.org/abs/2601.01541v1","updated":"2026-01-04T14:32:04Z","published":"2026-01-04T14:32:04Z","title":"Sim2Real SAR Image Restoration: Metadata-Driven Models for Joint Despeckling and Sidelobes Reduction","summary":"Synthetic aperture radar (SAR) provides valuable information about the Earth's surface under all weather and illumination conditions. However, the inherent phenomenon of speckle and the presence of sidelobes around bright targets pose challenges for accurate interpretation of SAR imagery. Most existing SAR image restoration methods address despeckling and sidelobes reduction as separate tasks. In this paper, we propose a unified framework that jointly performs both tasks using neural networks (NNs) trained on a realistic SAR simulated dataset generated with MOCEM. Inference can then be performed on real SAR images, demonstrating effective simulation to real (Sim2Real) transferability. Additionally, we incorporate acquisition metadata as auxiliary input to the NNs, demonstrating improved restoration performance.","authors":["Antoine De Paepe","Pascal Nguyen","Michael Mabelle","Cédric Saleun","Antoine Jouadé","Jean-Christophe Louvigne"],"pdf_url":"","comment":"Accepted at the Conference on Artificial Intelligence for Defense (CAID), 2025, Rennes, France"},{"id":"http://arxiv.org/abs/2512.22926v2","updated":"2026-01-04T13:57:42Z","published":"2025-12-28T13:42:11Z","title":"Confidence analysis-based hybrid heartbeat detection for ballistocardiogram using template matching and deep learning","summary":"Heartbeat interval can be detected from ballistocardiogram (BCG) signals in a non-contact manner. Conventional methods achieved heartbeat detection from different perspectives, where template matching (TM) and deep learning (DL) were based on the similarity of neighboring heartbeat episodes and robust spatio-temporal characteristics, respectively, and thus, performed varied from case to case. Inspired by the above facts, we propose confidence analysis-based hybrid heartbeat detection using both TM and DL, and further explore the advantages of both methods in various scenarios. To be specific, the confidence of the heartbeat detection results was evaluated by the consistency of signal morphology and the variability of the detected heartbeat intervals, which could be formulated by the averaged correlation between each heartbeat episode and the detected template and the normalized standard deviation among detected heartbeat intervals, respectively, where the results with higher confidence were remained. In order to validate the effectiveness of the proposed hybrid method, we conducted experiments using practical clinical BCG dataset with 34 subjects including 924,235 heartbeats. Numerical results showed that the proposed hybrid method achieved an average absolute interval error of 20.73 ms, yielding a reduction of 29.28 ms and 10.13 ms compared to solo TM and DL methods, respectively. Besides, case study showed the robustness of heartbeat detection of TM and DL to individual differences and signal quality, respectively, and in turn, validated that the hybrid method could benefit from the complementary advantages of both methods, which demonstrated the superiority of the proposed hybrid method in practical BCG monitoring scenarios.","authors":["Dongli Cai","Xihe Chen","Yaosheng Chen","Hong Xian","Baoxian Yu","Han Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.05912v2","updated":"2026-01-04T13:36:15Z","published":"2024-10-08T11:08:17Z","title":"Two-Timescale Design for Movable Antenna-Enabled Multiuser MIMO Systems","summary":"Movable antennas (MAs), which can be swiftly repositioned within a defined region, offer a promising solution to the limitations of fixed-position antennas (FPAs) in adapting to spatial variations in wireless channels, thereby improving channel conditions and communication between transceivers. However, frequent MA position adjustments based on instantaneous channel state information (CSI) incur high operational complexity, making real-time CSI acquisition impractical, especially in fast-fading channels. To address these challenges, we propose a two-timescale transmission framework for MA-enabled multiuser multiple-input-multiple-output (MU-MIMO) systems. In the large timescale, statistical CSI is exploited to optimize MA positions for long-term ergodic performance, whereas, in the small timescale, beamforming vectors are designed using instantaneous CSI to handle short-term channel fluctuations. Within this new framework, we analyze the ergodic sum rate and develop efficient MA position optimization algorithms for both maximum-ratio-transmission (MRT) and zero-forcing (ZF) beamforming schemes. These algorithms employ alternating optimization (AO), successive convex approximation (SCA), and majorization-minimization (MM) techniques, iteratively optimizing antenna positions and refining surrogate functions that approximate the ergodic sum rate. Numerical results show significant ergodic sum rate gains with the proposed two-timescale MA design over conventional FPA systems, particularly under moderate to strong line-of-sight (LoS) conditions. Notably, MA with ZF beamforming consistently outperforms MA with MRT, highlighting the synergy between beamforming and MAs for superior interference management in environments with moderate Rician factors and high user density, while MA with MRT can offer a simplified alternative to complex beamforming designs in strong LoS conditions.","authors":["Ziyuan Zheng","Qingqing Wu","Wen Chen","Guojie Hu"],"pdf_url":"","comment":"16 pages, 20 figures, publicated in an IEEE journal"},{"id":"http://arxiv.org/abs/2506.14636v2","updated":"2026-01-04T13:35:08Z","published":"2025-06-17T15:30:42Z","title":"Integrating Movable Antennas and Intelligent Reflecting Surfaces (MA-IRS): Fundamentals, Practical Solutions, and ISAC","summary":"Movable antennas (MAs) and intelligent reflecting surfaces (IRSs) enable active antenna repositioning and passive phase-shift tuning for channel reconfiguration, respectively. Integrating MAs and IRSs boosts spatial degrees of freedom, significantly enhancing wireless network capacity, coverage, and reliability. In this article, we first present the fundamentals of MA-IRS integration, involving clarifying the key design issues, revealing performance gain, and identifying the conditions where MA-IRS synergy persists. Then, we examine practical challenges and propose pragmatic design solutions, including optimization schemes, hardware architectures, deployment strategies, and robust designs for hardware impairments and mobility management. In addition, we highlight how MA-IRS architectures uniquely support advanced integrated sensing and communication, enhancing sensing performance and dual-functional flexibility. Overall, MA-IRS integration emerges as a compelling approach toward next-generation reconfigurable wireless systems.","authors":["Qingqing Wu","Ziyuan Zheng","Ying Gao","Weidong Mei","Xin Wei","Wen Chen","Boyu Ning"],"pdf_url":"","comment":"8 pages, 6 figures, publicated by an IEEE Magazine"},{"id":"http://arxiv.org/abs/2510.24614v2","updated":"2026-01-04T12:14:41Z","published":"2025-10-28T16:44:11Z","title":"Semi-supervised and unsupervised learning for health indicator extraction from guided waves in aerospace composite structures","summary":"Health indicators (HIs) are central to diagnosing and prognosing the condition of aerospace composite structures, enabling efficient maintenance and operational safety. However, extracting reliable HIs remains challenging due to variability in material properties, stochastic damage evolution, and diverse damage modes. Manufacturing defects (e.g., disbonds) and in-service incidents (e.g., bird strikes) further complicate this process. This study presents a comprehensive data-driven framework that learns HIs via two learning approaches integrated with multi-domain signal processing. Because ground-truth HIs are unavailable, a semi-supervised and an unsupervised approach are proposed: (i) a diversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach augmented with continuous auxiliary labels used as hypothetical damage proxies, which overcomes the limitation of prior binary labels that only distinguish healthy and failed states while neglecting intermediate degradation, and (ii) a degradation-trend-constrained variational autoencoder (DTC-VAE), in which the monotonicity criterion is embedded via an explicit trend constraint. Guided waves with multiple excitation frequencies are used to monitor single-stiffener composite structures under fatigue loading. Time, frequency, and time-frequency representations are explored, and per-frequency HIs are fused via unsupervised ensemble learning to mitigate frequency dependence and reduce variance. Using fast Fourier transform features, the augmented Diversity-DeepSAD model achieved 81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3% performance, outperforming existing baselines.","authors":["James Josep Perry","Pablo Garcia-Conde Ortiz","George Konstantinou","Cornelie Vergouwen","Edlyn Santha Kumaran","Morteza Moradi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.13119v2","updated":"2026-01-04T09:57:34Z","published":"2025-07-17T13:33:54Z","title":"Generalized Scattering Matrix Framework for Modeling Implantable Antennas in Multilayered Spherical Media","summary":"This paper presents a unified and computationally efficient framework for modeling antennas embedded in spherically stratified media, applicable to implantable biomedical antennas and radome-enclosed systems. The method separates the characterization of the radiator from that of the surrounding medium by combining the antenna's free-space generalized scattering matrix (GSM) with a set of extended spherical scattering operators (SSOs). This decoupling enables rapid reevaluation under arbitrary changes of the spherical medium without re-simulating the antenna, yielding orders-of-magnitude speedups over traditional DGF-based MoM approaches. The SSO formulation accommodates multilayer, radially inhomogeneous, and radially uniaxial anisotropic profiles, and the GSM can be obtained from diverse numerical solvers or far-field data, supporting array-level synthesis and measurement-driven modeling. Extensive examples confirm excellent agreement with full-wave and DGF-based solutions, demonstrating the accuracy, generality, and practical versatility of the proposed framework.","authors":["Chenbo Shi","Xin Gu","Shichen Liang","Jin Pan"],"pdf_url":"","comment":null}],"Computational Geometry":[{"id":"http://arxiv.org/abs/2601.01405v1","updated":"2026-01-04T07:04:18Z","published":"2026-01-04T07:04:18Z","title":"Efficient Cover Construction for Ball Mapper via Accelerated Range Queries","summary":"Ball Mapper is an widely used tool in topological data analysis for summarizing the structure of high-dimensional data through metric-based coverings and graph representations. A central computational bottleneck in Ball Mapper is the construction of the underlying cover, which requires repeated range queries to identify data points within a fixed distance of selected landmarks. As data sets grow in size and dimensionality, naive implementations of this step become increasingly inefficient.\n  In this work, we study practical strategies for accelerating cover construction in Ball Mapper by improving the efficiency of range queries. We integrate two complementary approaches into the Ball Mapper pipeline: hierarchical geometric pruning using ball tree data structures, and hardware-aware distance computation using Facebook AI Similarity Search. We describe the underlying algorithms, discuss their trade-offs with respect to metric flexibility and dimensionality, and provide implementation details relevant to large-scale data analysis.\n  Empirical benchmarks demonstrate that both approaches yield substantial speedups over the baseline implementation, with performance gains depending on data set size, dimensionality, and choice of distance function. These results improve the practical scalability of Ball Mapper without modifying its theoretical formulation and provide guidance for the efficient implementation of metric-based exploratory tools in modern data analysis workflows.","authors":["Jay-Anne Bulauan","John Rick Manzanares"],"pdf_url":"","comment":null}],"Game Theory":[{"id":"http://arxiv.org/abs/2601.01607v1","updated":"2026-01-04T17:15:27Z","published":"2026-01-04T17:15:27Z","title":"Existence of Optimal Mechanisms for Selling Multiple Goods: An Elementary Proof","summary":"We provide an elementary proof that revenue-maximizing mechanisms exist in multi-parameter settings whenever the distribution of valuations has finite expectation.","authors":["Sergiu Hart","Noam Nisan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01581v1","updated":"2026-01-04T15:59:52Z","published":"2026-01-04T15:59:52Z","title":"CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty","summary":"The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.","authors":["Rishav Sen","Fangqi Liu","Jose Paolo Talusan","Ava Pettet","Yoshinori Suzue","Mark Bailey","Ayan Mukhopadhyay","Abhishek Dubey"],"pdf_url":"","comment":"Submitted to AAMAS 2026. 25 pages, 13 figures, 14 tables"},{"id":"http://arxiv.org/abs/2509.13729v2","updated":"2026-01-04T14:12:07Z","published":"2025-09-17T06:31:17Z","title":"The Economics of Information Pollution in the Age of AI: General Equilibrium, Welfare, and Policy Design","summary":"The advent of Large Language Models (LLMs) represents a fundamental shock to the economics of information production. By asymmetrically collapsing the marginal cost of generating low-quality, synthetic content while leaving high-quality production costly, AI systematically incentivizes information pollution. This paper develops a general equilibrium framework to analyze this challenge. We model the strategic interactions among a monopolistic platform, profit-maximizing producers, and utility-maximizing consumers in a three-stage game. The core of our model is a production technology with differential elasticities of substitution (σ_L > 1 > σ_H), which formalizes the insight that AI is a substitute for labor in low-quality production but a complement in high-quality creation. We prove the existence of a unique \"Polluted Information Equilibrium\" and demonstrate its inefficiency, which is driven by a threefold market failure: a production externality, a platform governance failure, and an information commons externality. Methodologically, we derive a theoretically-grounded Information Pollution Index (IPI) with endogenous welfare weights to measure ecosystem health. From a policy perspective, we show that a first-best outcome requires a portfolio of instruments targeting each failure. Finally, considering the challenges of deep uncertainty, we advocate for an adaptive governance framework where policy instruments are dynamically adjusted based on real-time IPI readings, offering a robust blueprint for regulating information markets in the age of AI.","authors":["Yukun Zhang","Tianyang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01496v1","updated":"2026-01-04T11:45:17Z","published":"2026-01-04T11:45:17Z","title":"The Optimal Sample Complexity of Linear Contracts","summary":"In this paper, we settle the problem of learning optimal linear contracts from data in the offline setting, where agent types are drawn from an unknown distribution and the principal's goal is to design a contract that maximizes her expected utility. Specifically, our analysis shows that the simple Empirical Utility Maximization (EUM) algorithm yields an $\\varepsilon$-approximation of the optimal linear contract with probability at least $1-δ$, using just $O(\\ln(1/δ) / \\varepsilon^2)$ samples. This result improves upon previously known bounds and matches a lower bound from Duetting et al. [2025] up to constant factors, thereby proving its optimality. Our analysis uses a chaining argument, where the key insight is to leverage a simple structural property of linear contracts: their expected reward is non-decreasing. This property, which holds even though the utility function itself is non-monotone and discontinuous, enables the construction of fine-grained nets required for the chaining argument, which in turn yields the optimal sample complexity. Furthermore, our proof establishes the stronger guarantee of uniform convergence: the empirical utility of every linear contract is a $\\varepsilon$-approximation of its true expectation with probability at least $1-δ$, using the same optimal $O(\\ln(1/δ) / \\varepsilon^2)$ sample complexity.","authors":["Mikael Møller Høgsgaard"],"pdf_url":"","comment":null}],"Information Theory":[{"id":"http://arxiv.org/abs/2601.01620v1","updated":"2026-01-04T17:59:33Z","published":"2026-01-04T17:59:33Z","title":"The Gray Area: Characterizing Moderator Disagreement on Reddit","summary":"Volunteer moderators play a crucial role in sustaining online dialogue, but they often disagree about what should or should not be allowed. In this paper, we study the complexity of content moderation with a focus on disagreements between moderators, which we term the ``gray area'' of moderation. Leveraging 5 years and 4.3 million moderation log entries from 24 subreddits of different topics and sizes, we characterize how gray area, or disputed cases, differ from undisputed cases. We show that one-in-seven moderation cases are disputed among moderators, often addressing transgressions where users' intent is not directly legible, such as in trolling and brigading, as well as tensions around community governance. This is concerning, as almost half of all gray area cases involved automated moderation decisions. Through information-theoretic evaluations, we demonstrate that gray area cases are inherently harder to adjudicate than undisputed cases and show that state-of-the-art language models struggle to adjudicate them. We highlight the key role of expert human moderators in overseeing the moderation process and provide insights about the challenges of current moderation processes and tools.","authors":["Shayan Alipour","Shruti Phadke","Seyed Shahabeddin Mousavi","Amirhossein Afsharrad","Morteza Zihayat","Mattia Samory"],"pdf_url":"","comment":"16 pages, 11 figures"},{"id":"http://arxiv.org/abs/2510.04030v3","updated":"2026-01-04T06:04:23Z","published":"2025-10-05T04:33:02Z","title":"Large Deviations Principle for Isoperimetry and Its Equivalence to Nonlinear Log-Sobolev Inequalities","summary":"The isoperimetric problem is a classic topic in geometric measure theory, yet critical questions regarding the characterization of optimal solutions -- even asymptotically optimal ones -- remain largely unresolved. In this paper, we investigate the large deviations asymptotics (governing sequences of exponentially small sets) for the isoperimetric problem on the product Riemannian manifold $M^{n}$ endowed with the product probability measure $ν^{\\otimes n}$, where $M$ is a Riemannian manifold satisfying $\\mathrm{CD}(0,\\infty)$. When the probability measure $ν$ admits a finite moment generating function for squared distance, we establish an exact characterization of the large deviations asymptotics of the isoperimetric profile, which reveals a precise equivalence between this asymptotic isoperimetry and an established strengthening of log-Sobolev inequality -- namely, nonlinear log-Sobolev inequality. It is observed that conditional typical sets, a fundamental concept from information theory, form an asymptotically optimal solution to the isoperimetric problem. This class of subsets further yields an upper bound on the isoperimetric profile in the central limit regime (concerning constant-volume sets), expressed as the Gaussian isoperimetric profile times the square root of spectral gap. Furthermore, we apply our results to establish quantitative relations among optimal constants in isoperimetric, concentration and transport inequalities, additionally covering isoperimetry for subexponentially and superexponentially small sets. Our results provide a rigorous justification from the perspective of nonlinear log-Sobolev inequalities for why isoperimetric minimizers behave fundamentally differently across spaces with distinct geometric structures. Our proof idea integrates tools from information theory, optimal transport, and geometric measure theory.","authors":["Lei Yu"],"pdf_url":"","comment":"Correct an error in Theorem 2 and add Theorem 5 and several examples"},{"id":"http://arxiv.org/abs/2601.01372v1","updated":"2026-01-04T04:54:07Z","published":"2026-01-04T04:54:07Z","title":"Probabilistic verification algorithm for linear codes","summary":"In this paper, we propose a probabilistic algorithm suitable for any linear code $C$ to determine whether a given vector $\\mathbf{x}$ belongs to $ C$. The algorithm achieves $O(n\\log n)$ time complexity, $ O(n^2)$ space complexity and with an error probability less than $1/\\mathrm{poly}(n)$ in the asymptotic sense.","authors":["Mingchao Li","Jiyou Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.15006v5","updated":"2026-01-04T02:15:41Z","published":"2025-09-18T14:38:50Z","title":"Indoor Fluid Antenna Systems Enabled by Layout-Specific Modeling and Group Relative Policy Optimization","summary":"Fluid antenna system (FAS) revolutionizes wireless communications via utilizing position-flexible antennas that dynamically optimize channel conditions and mitigate multipath fading. This innovation is particularly valuable in indoor environments, in which signal propagation is severely degraded due to structural obstructions and complex multipath reflections. In this paper, we investigate the channel modeling and the joint optimization of antenna positioning, beamforming, and power allocation for indoor FAS. In particular, we propose a layout-specific channel model, and employ the novel group relative policy optimization (GRPO) algorithm for tackling the optimization problem. Compared to the state-of-the-art Sionna model, our model achieves an 83.3% reduction in computation time with an approximately 3 dB increase in root-mean-square error (RMSE). When simplified to a two-ray model, our model allows for a closed-form antenna position solution with near-optimal performance. For the joint optimization problem, our GRPO algorithm outperforms proximal policy optimization (PPO) and other baselines in sum-rate, while requiring only 50.8% computational resources of PPO, thanks to its group advantage estimation. Simulation results show that increasing either the group size or trajectory length in GRPO does not yield significant improvements in sum-rate, suggesting that these parameters can be selected conservatively without sacrificing performance.","authors":["Tong Zhang","Qianren Li","Shuai Wang","Wanli Ni","Jiliang Zhang","Rui Wang","Kai-Kit Wong","Chan-Byoung Chae"],"pdf_url":"","comment":"16 pages, 12 figures;"}],"Discrete Mathematics":[{"id":"http://arxiv.org/abs/1807.07189v4","updated":"2026-01-04T23:30:20Z","published":"2018-07-19T00:05:47Z","title":"A Tale of Santa Claus, Hypergraphs and Matroids","summary":"A well-known problem in scheduling and approximation algorithms is the Santa Claus problem. Suppose that Santa Claus has a set of gifts, and he wants to distribute them among a set of children so that the least happy child is made as happy as possible. Here, the value that a child $i$ has for a present $j$ is of the form $p_{ij} \\in \\{ 0,p_j\\}$. A polynomial time algorithm by Annamalai et al. gives a $12.33$-approximation and is based on a modification of Haxell's hypergraph matching argument.\n  In this paper, we introduce a matroid version of the Santa Claus problem. Our algorithm is also based on Haxell's augmenting tree, but with the introduction of the matroid structure we solve a more general problem with cleaner methods. Our result can then be used as a blackbox to obtain a $(6+\\varepsilon)$-approximation for Santa Claus. This factor also compares against a natural, compact LP for Santa Claus.","authors":["Sami Davies","Thomas Rothvoss","Yihao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01375v1","updated":"2026-01-04T04:56:56Z","published":"2026-01-04T04:56:56Z","title":"From Historical Puzzles to Grammatical Constraints: Circular Partitions, Generalized Run-Length Encodings, and Polynomial-Time Decidability","summary":"Motivated by a historical combinatorial problem that resembles the well-known Josephus problem, we investigate circular partition algorithms and formulate problems in deterministic finite automata with practical algorithms. The historical problem involves arranging individuals on a circle and eliminating every k-th person until a desired group remains. We analyze both removal and non-removal approaches to circular partitioning, establishing conditions for balanced partitions and providing explicit algorithms. We introduce generalized run-length encodings over partitioned alphabets to capture alternating letter patterns, computing their cardinalities using Stirling numbers of the second kind. Connecting these combinatorial structures to formal language theory, we formulate an existence problem: given a context-free grammar over a dictionary and block-pattern constraints on letters, does a valid sentence exist? We prove decidability in polynomial time by showing block languages are regular and applying standard parsing techniques. Complete algorithms with complexity analysis are provided and validated through implementation on both historical and synthetic instances.","authors":["Omid Khormali","Ghaya Mtimet","Nuh Aydin"],"pdf_url":"","comment":null}],"Robotics":[{"id":"http://arxiv.org/abs/2601.01675v1","updated":"2026-01-04T21:59:34Z","published":"2026-01-04T21:59:34Z","title":"VisuoTactile 6D Pose Estimation of an In-Hand Object using Vision and Tactile Sensor Data","summary":"Knowledge of the 6D pose of an object can benefit in-hand object manipulation. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot's grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this paper, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot's hand. To address challenges like lack of standard representation for tactile data and sensor fusion, we propose the use of point clouds to represent object surfaces in contact with the tactile sensor and present a network architecture based on pixel-wise dense fusion. We also extend NVIDIA's Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and corresponding tactile point clouds. Results suggest that using tactile data in addition to vision data improves the 6D pose estimate, and our network generalizes successfully from synthetic training to real physical robots.","authors":["Snehal s. Dikhale","Karankumar Patel","Daksh Dhingra","Itoshi Naramura","Akinobu Hayashi","Soshi Iba","Nawid Jamali"],"pdf_url":"","comment":"Accepted for publication in IEEE Robotics and Automation Letters (RA-L), January 2022. Presented at ICRA 2022. This is the author's version of the manuscript"},{"id":"http://arxiv.org/abs/2601.01651v1","updated":"2026-01-04T20:06:01Z","published":"2026-01-04T20:06:01Z","title":"DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos","summary":"This work presents DemoBot, a learning framework that enables a dual-arm, multi-finger robotic system to acquire complex manipulation skills from a single unannotated RGB-D video demonstration. The method extracts structured motion trajectories of both hands and objects from raw video data. These trajectories serve as motion priors for a novel reinforcement learning (RL) pipeline that learns to refine them through contact-rich interactions, thereby eliminating the need to learn from scratch. To address the challenge of learning long-horizon manipulation skills, we introduce: (1) Temporal-segment based RL to enforce temporal alignment of the current state with demonstrations; (2) Success-Gated Reset strategy to balance the refinement of readily acquired skills and the exploration of subsequent task stages; and (3) Event-Driven Reward curriculum with adaptive thresholding to guide the RL learning of high-precision manipulation. The novel video processing and RL framework successfully achieved long-horizon synchronous and asynchronous bimanual assembly tasks, offering a scalable approach for direct skill acquisition from human videos.","authors":["Yucheng Xu","Xiaofeng Mao","Elle Miller","Xinyu Yi","Yang Li","Zhibin Li","Robert B. Fisher"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16262v4","updated":"2026-01-04T17:54:29Z","published":"2025-11-20T11:41:48Z","title":"How Robot Dogs See the Unseeable: Improving Visual Interpretability via Peering for Exploratory Robots","summary":"In vegetated environments, such as forests, exploratory robots play a vital role in navigating complex, cluttered environments where human access is limited and traditional equipment struggles. Visual occlusion from obstacles, such as foliage, can severely obstruct a robot's sensors, impairing scene understanding. We show that \"peering\", a characteristic side-to-side movement used by insects to overcome their visual limitations, can also allow robots to markedly improve visual reasoning under partial occlusion. This is accomplished by applying core signal processing principles, specifically optical synthetic aperture sensing, together with the vision reasoning capabilities of modern large multimodal models. Peering enables real-time, high-resolution, and wavelength-independent perception, which is crucial for vision-based scene understanding across a wide range of applications. The approach is low-cost and immediately deployable on any camera-equipped robot. We investigated different peering motions and occlusion masking strategies, demonstrating that, unlike peering, state-of-the-art multi-view 3D vision techniques fail in these conditions due to their high susceptibility to occlusion. Our experiments were carried out on an industrial-grade quadrupedal robot. However, the ability to peer is not limited to such platforms, but potentially also applicable to bipedal, hexapod, wheeled, or crawling platforms. Robots that can effectively see through partial occlusion will gain superior perception abilities - including enhanced scene understanding, situational awareness, camouflage breaking, and advanced navigation in complex environments.","authors":["Oliver Bimber","Karl Dietrich von Ellenrieder","Michael Haller","Rakesh John Amala Arokia Nathan","Gianni Lunardi","Mohamed Youssef","Marco Camurri","Santos Miguel Orozco Soto","Jeremy E. Niven"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01618v1","updated":"2026-01-04T17:53:42Z","published":"2026-01-04T17:53:42Z","title":"Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation","summary":"Long-horizon robotic manipulation is increasingly important for real-world deployment, requiring spatial disambiguation in complex layouts and temporal resilience under dynamic interaction. However, existing end-to-end and hierarchical Vision-Language-Action (VLA) policies often rely on text-only cues while keeping plan intent latent, which undermines referential grounding in cluttered or underspecified scenes, impedes effective task decomposition of long-horizon goals with close-loop interaction, and limits causal explanation by obscuring the rationale behind action choices. To address these issues, we first introduce Visual Sketch, an implausible visual intermediate that renders points, boxes, arrows, and typed relations in the robot's current views to externalize spatial intent, connect language to scene geometry. Building on Visual Sketch, we present Action-Sketcher, a VLA framework that operates in a cyclic See-Think-Sketch-Act workflow coordinated by adaptive token-gated strategy for reasoning triggers, sketch revision, and action issuance, thereby supporting reactive corrections and human interaction while preserving real-time action prediction. To enable scalable training and evaluation, we curate diverse corpus with interleaved images, text, Visual Sketch supervision, and action sequences, and train Action-Sketcher with a multi-stage curriculum recipe that combines interleaved sequence alignment for modality unification, language-to-sketch consistency for precise linguistic grounding, and imitation learning augmented with sketch-to-action reinforcement for robustness. Extensive experiments on cluttered scenes and multi-object tasks, in simulation and on real-world tasks, show improved long-horizon success, stronger robustness to dynamic scene changes, and enhanced interpretability via editable sketches and step-wise plans. Project website: https://action-sketcher.github.io","authors":["Huajie Tan","Peterson Co","Yijie Xu","Shanyu Rong","Yuheng Ji","Cheng Chi","Xiansheng Chen","Qiongyu Zhang","Zhongxia Zhao","Pengwei Wang","Zhongyuan Wang","Shanghang Zhang"],"pdf_url":"","comment":"26 pages, 14 figures"},{"id":"http://arxiv.org/abs/2505.09737v2","updated":"2026-01-04T16:58:04Z","published":"2025-05-14T18:57:51Z","title":"General Dynamic Goal Recognition using Goal-Conditioned and Meta Reinforcement Learning","summary":"Understanding an agent's goal through its behavior is a common AI problem called Goal Recognition (GR). This task becomes particularly challenging in dynamic environments where goals are numerous and ever-changing. We introduce the General Dynamic Goal Recognition (GDGR) problem, a broader definition of GR aimed at real-time adaptation of GR systems. This paper presents two novel approaches to tackle GDGR: (1) GC-AURA, generalizing to new goals using Model-Free Goal-Conditioned Reinforcement Learning, and (2) Meta-AURA, adapting to novel environments with Meta-Reinforcement Learning. We evaluate these methods across diverse environments, demonstrating their ability to achieve rapid adaptation and high GR accuracy under dynamic and noisy conditions. This work is a significant step forward in enabling GR in dynamic and unpredictable real-world environments.","authors":["Osher Elhadad","Owen Morrissey","Reuth Mirsky"],"pdf_url":"","comment":"Accepted for publication at AAMAS 2026"},{"id":"http://arxiv.org/abs/2601.01577v1","updated":"2026-01-04T15:49:46Z","published":"2026-01-04T15:49:46Z","title":"HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller","summary":"Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines","authors":["Tran Tien Dat","Nguyen Hai An","Nguyen Khanh Viet Dung","Nguyen Duy Duc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.01141v3","updated":"2026-01-04T15:40:51Z","published":"2025-06-01T19:51:05Z","title":"Standing Tall: Sim to Real Fall Classification and Lead Time Prediction for Bipedal Robots","summary":"This paper extends a previously proposed fall prediction algorithm to a real-time (online) setting, with implementations in both hardware and simulation. The system is validated on the full-sized bipedal robot Digit, where the real-time version achieves performance comparable to the offline implementation while maintaining a zero false positive rate, an average lead time (defined as the difference between the true and predicted fall time) of 1.1s (well above the required minimum of 0.2s), and a maximum lead time error of just 0.03s. It also achieves a high recovery rate of 0.97, demonstrating its effectiveness in real-world deployment. In addition to the real-time implementation, this work identifies key limitations of the original algorithm, particularly under omnidirectional faults, and introduces a fine-tuned strategy to improve robustness. The enhanced algorithm shows measurable improvements across all evaluated metrics, including a 0.05 reduction in average false positive rate and a 1.19s decrease in the maximum error of the average predicted lead time.","authors":["Gokul Prabhakaran","Jessy W. Grizzle","M. Eva Mungai"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2601.01561v1","updated":"2026-01-04T15:21:52Z","published":"2026-01-04T15:21:52Z","title":"AIMS: An Adaptive Integration of Multi-Sensor Measurements for Quadrupedal Robot Localization","summary":"This paper addresses the problem of accurate localization for quadrupedal robots operating in narrow tunnel-like environments. Due to the long and homogeneous characteristics of such scenarios, LiDAR measurements often provide weak geometric constraints, making traditional sensor fusion methods susceptible to accumulated motion estimation errors. To address these challenges, we propose AIMS, an adaptive LiDAR-IMU-leg odometry fusion method for robust quadrupedal robot localization in degenerate environments. The proposed method is formulated within an error-state Kalman filtering framework, where LiDAR and leg odometry measurements are integrated with IMU-based state prediction, and measurement noise covariance matrices are adaptively adjusted based on online degeneracy-aware reliability assessment. Experimental results obtained in narrow corridor environments demonstrate that the proposed method improves localization accuracy and robustness compared with state-of-the-art approaches.","authors":["Yujian Qiu","Yuqiu Mu","Wen Yang","Hao Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.03856v2","updated":"2026-01-04T14:39:06Z","published":"2025-06-04T11:41:28Z","title":"Phase-based Nonlinear Model Predictive Control for Humanoid Walking Stabilization with Single and Double Support Time Adjustments","summary":"The contact sequence of humanoid walking consists of single and double support phases (SSP and DSP), and their coordination through proper duration and dynamic transition based on the robot's state is crucial for maintaining walking stability. Numerous studies have investigated phase duration optimization as an effective means of improving walking stability. This paper presents a phase-based Nonlinear Model Predictive Control (NMPC) framework that jointly optimizes Zero Moment Point (ZMP) modulation, step location, SSP duration (step timing), and DSP duration within a single formulation. Specifically, the proposed framework reformulates the nonlinear DCM (Divergent Component of Motion) error dynamics into a phase-consistent representation and incorporates them as dynamic constraints within the NMPC. The proposed framework also guarantees ZMP input continuity during contact-phase transitions and disables footstep updates during the DSP, thereby enabling dynamically reliable balancing control regardless of whether the robot is in SSP or DSP. The effectiveness of the proposed method is validated through extensive simulation and hardware experiments, demonstrating improved balance performance under external disturbances.","authors":["Kwanwoo Lee","Gyeongjae Park","Myeong-Ju Kim","Jaeheung Park"],"pdf_url":"","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2505.11920v3","updated":"2026-01-04T14:01:26Z","published":"2025-05-17T09:08:36Z","title":"H2R: A Human-to-Robot Data Augmentation for Robot Pre-training from Videos","summary":"Large-scale pre-training using videos has proven effective for robot learning. However, the models pre-trained on such data can be suboptimal for robot learning due to the significant visual gap between human hands and those of different robots. To remedy this, we propose H2R, a simple data augmentation technique that detects human hand keypoints, synthesizes robot motions in simulation, and composites rendered robots into egocentric videos. This process explicitly bridges the visual gap between human and robot embodiments during pre-training. We apply H2R to augment large-scale egocentric human video datasets such as Ego4D and SSv2, replacing human hands with simulated robotic arms to generate robot-centric training data. Based on this, we construct and release a family of 1M-scale datasets covering multiple robot embodiments (UR5 with gripper/Leaphand, Franka) and data sources (SSv2, Ego4D). To verify the effectiveness of the augmentation pipeline, we introduce a CLIP-based image-text similarity metric that quantitatively evaluates the semantic fidelity of robot-rendered frames to the original human actions. We validate H2R across three simulation benchmarks: Robomimic, RLBench and PushT and real-world manipulation tasks with a UR5 robot equipped with Gripper and Leaphand end-effectors. H2R consistently improves downstream success rates, yielding gains of 5.0%-10.2% in simulation and 6.7%-23.3% in real-world tasks across various visual encoders and policy learning methods. These results indicate that H2R improves the generalization ability of robotic policies by mitigating the visual discrepancies between human and robot domains.","authors":["Guangrun Li","Yaoxu Lyu","Zhuoyang Liu","Chengkai Hou","Jieyu Zhang","Shanghang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01528v1","updated":"2026-01-04T13:36:21Z","published":"2026-01-04T13:36:21Z","title":"DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving","summary":"Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.","authors":["Yang Zhou","Hao Shao","Letian Wang","Zhuofan Zong","Hongsheng Li","Steven L. Waslander"],"pdf_url":"","comment":"10 pages, 4 figures; Project Website: https://drivinggen-bench.github.io/"},{"id":"http://arxiv.org/abs/2512.18836v2","updated":"2026-01-04T13:31:49Z","published":"2025-12-21T17:45:57Z","title":"Multimodal Classification Network Guided Trajectory Planning for Four-Wheel Independent Steering Autonomous Parking Considering Obstacle Attributes","summary":"Four-wheel Independent Steering (4WIS) vehicles have attracted increasing attention for their superior maneuverability. Human drivers typically choose to cross or drive over the low-profile obstacles (e.g., plastic bags) to efficiently navigate through narrow spaces, while existing planners neglect obstacle attributes, leading to suboptimal efficiency or planning failures. To address this issue, we propose a novel multimodal trajectory planning framework that employs a neural network for scene perception, combines 4WIS hybrid A* search to generate a warm start, and utilizes an optimal control problem (OCP) for trajectory optimization. Specifically, a multimodal perception network fusing visual information and vehicle states is employed to capture semantic and contextual scene understanding, enabling the planner to adapt the strategy according to scene complexity (hard or easy task). For hard tasks, guided points are introduced to decompose complex tasks into local subtasks, improving the search efficiency. The multiple steering modes of 4WIS vehicles, Ackermann, diagonal, and zero-turn, are also incorporated as kinematically feasible motion primitives. Moreover, a hierarchical obstacle handling strategy, which categorizes obstacles as \"non-traversable\", \"crossable\", and \"drive-over\", is incorporated into the node expansion process, explicitly linking obstacle attributes to planning actions to enable efficient decisions. Furthermore, to address dynamic obstacles with motion uncertainty, we introduce a probabilistic risk field model, constructing risk-aware driving corridors that serve as linear collision constraints in OCP. Experimental results demonstrate the proposed framework's effectiveness in generating safe, efficient, and smooth trajectories for 4WIS vehicles, especially in constrained environments.","authors":["Jingjia Teng","Yang Li","Yougang Bian","Manjiang Hu","Yingbai Hu","Guofa Li","Jianqiang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16760v2","updated":"2026-01-04T12:37:43Z","published":"2025-12-18T16:57:44Z","title":"Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future","summary":"Autonomous driving has long relied on modular \"Perception-Decision-Action\" pipelines, where hand-crafted interfaces and rule-based components often break down in complex or long-tailed scenarios. Their cascaded design further propagates perception errors, degrading downstream planning and control. Vision-Action (VA) models address some limitations by learning direct mappings from visual inputs to actions, but they remain opaque, sensitive to distribution shifts, and lack structured reasoning or instruction-following capabilities. Recent progress in Large Language Models (LLMs) and multimodal learning has motivated the emergence of Vision-Language-Action (VLA) frameworks, which integrate perception with language-grounded decision making. By unifying visual understanding, linguistic reasoning, and actionable outputs, VLAs offer a pathway toward more interpretable, generalizable, and human-aligned driving policies. This work provides a structured characterization of the emerging VLA landscape for autonomous driving. We trace the evolution from early VA approaches to modern VLA frameworks and organize existing methods into two principal paradigms: End-to-End VLA, which integrates perception, reasoning, and planning within a single model, and Dual-System VLA, which separates slow deliberation (via VLMs) from fast, safety-critical execution (via planners). Within these paradigms, we further distinguish subclasses such as textual vs. numerical action generators and explicit vs. implicit guidance mechanisms. We also summarize representative datasets and benchmarks for evaluating VLA-based driving systems and highlight key challenges and open directions, including robustness, interpretability, and instruction fidelity. Overall, this work aims to establish a coherent foundation for advancing human-compatible autonomous driving systems.","authors":["Tianshuai Hu","Xiaolu Liu","Song Wang","Yiyao Zhu","Ao Liang","Lingdong Kong","Guoyang Zhao","Zeying Gong","Jun Cen","Zhiyu Huang","Xiaoshuai Hao","Linfeng Li","Hang Song","Xiangtai Li","Jun Ma","Shaojie Shen","Jianke Zhu","Dacheng Tao","Ziwei Liu","Junwei Liang"],"pdf_url":"","comment":"Survey; 47 pages, 7 figures, 9 tables; GitHub Repo at https://github.com/worldbench/awesome-vla-for-ad"},{"id":"http://arxiv.org/abs/2512.22342v3","updated":"2026-01-04T11:05:30Z","published":"2025-12-26T19:00:12Z","title":"VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs","summary":"In most existing embodied navigation tasks, instructions are well-defined and unambiguous, such as instruction following and object searching. Under this idealized setting, agents are required solely to produce effective navigation outputs conditioned on vision and language inputs. However, real-world navigation instructions are often vague and ambiguous, requiring the agent to resolve uncertainty and infer user intent through active dialog. To address this gap, we propose Interactive Instance Goal Navigation (IIGN), a task that requires agents not only to generate navigation actions but also to produce language outputs via active dialog, thereby aligning more closely with practical settings. IIGN extends Instance Goal Navigation (IGN) by allowing agents to freely consult an oracle in natural language while navigating. Building on this task, we present the Vision Language-Language Navigation (VL-LN) benchmark, which provides a large-scale, automatically generated dataset and a comprehensive evaluation protocol for training and assessing dialog-enabled navigation models. VL-LN comprises over 41k long-horizon dialog-augmented trajectories for training and an automatic evaluation protocol with an oracle capable of responding to agent queries. Using this benchmark, we train a navigation model equipped with dialog capabilities and show that it achieves significant improvements over the baselines. Extensive experiments and analyses further demonstrate the effectiveness and reliability of VL-LN for advancing research on dialog-enabled embodied navigation. Code and dataset: https://0309hws.github.io/VL-LN.github.io/","authors":["Wensi Huang","Shaohao Zhu","Meng Wei","Jinming Xu","Xihui Liu","Hanqing Wang","Tai Wang","Feng Zhao","Jiangmiao Pang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24029v2","updated":"2026-01-04T08:57:10Z","published":"2025-12-30T07:00:30Z","title":"Evaluation of Impression Difference of a Domestic Mobile Manipulator with Autonomous and/or Remote Control in Fetch-and-Carry Tasks","summary":"A single service robot can present two distinct agencies: its onboard autonomy and an operator-mediated agency, yet users experience them through one physical body. We formalize this dual-agency structure as a User-Robot-Operator triad in an autonomous remote-control setting that integrates teleoperation with autonomous execution and human-in-the-loop remote assistance. Prior to the recent surge of language-based and multimodal interfaces, we developed and evaluated an early-stage prototype in 2020 that combined natural-language text chat with a sketch-based interface enabling freehand on-image annotation over the robot's live camera view to support remote intervention. We evaluated three modes - remote control via teleoperation, autonomous control, and autonomous remote control (a hybrid mode representing different levels of autonomy) - in controlled fetch-and-carry mobile manipulation tasks using a domestic mobile manipulator, the Human Support Robot (HSR), on a World Robot Summit 2020 rule-compliant test field. The results show systematic mode-dependent differences in user-rated affinity and perceived security, indicating that switching or blending agency within one robot measurably shapes human impressions in Human-Robot Interaction (HRI). These findings provide empirical guidance for designing human-in-the-loop mobile manipulation in domestic physical tasks.","authors":["Takashi Yamamoto","Hiroaki Yaguchi","Shohei Kato","Hiroyuki Okada"],"pdf_url":"","comment":"Published in Advanced Robotics (2020). v2 updates Abstract/Comments (metadata only); paper content unchanged. Please cite: Advanced Robotics 34(20):1291-1308, 2020. https://doi.org/10.1080/01691864.2020.1780152"},{"id":"http://arxiv.org/abs/2601.01438v1","updated":"2026-01-04T08:52:56Z","published":"2026-01-04T08:52:56Z","title":"Online Estimation and Manipulation of Articulated Objects","summary":"From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.","authors":["Russell Buchanan","Adrian Röfer","João Moura","Abhinav Valada","Sethu Vijayakumar"],"pdf_url":"","comment":"This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Autonomous Robots, and is available online at [Link will be updated when available]"},{"id":"http://arxiv.org/abs/2512.23650v2","updated":"2026-01-04T07:49:24Z","published":"2025-12-29T17:59:24Z","title":"Do You Have Freestyle? Expressive Humanoid Locomotion via Audio Control","summary":"Humans intuitively move to sound, but current humanoid robots lack expressive improvisational capabilities, confined to predefined motions or sparse commands. Generating motion from audio and then retargeting it to robots relies on explicit motion reconstruction, leading to cascaded errors, high latency, and disjointed acoustic-actuation mapping. We propose RoboPerform, the first unified audio-to-locomotion framework that can directly generate music-driven dance and speech-driven co-speech gestures from audio. Guided by the core principle of \"motion = content + style\", the framework treats audio as implicit style signals and eliminates the need for explicit motion reconstruction. RoboPerform integrates a ResMoE teacher policy for adapting to diverse motion patterns and a diffusion-based student policy for audio style injection. This retargeting-free design ensures low latency and high fidelity. Experimental validation shows that RoboPerform achieves promising results in physical plausibility and audio alignment, successfully transforming robots into responsive performers capable of reacting to audio.","authors":["Zhe Li","Cheng Chi","Yangyang Wei","Boan Zhu","Tao Huang","Zhenguo Sun","Yibo Peng","Pengwei Wang","Zhongyuan Wang","Fangzhou Liu","Chang Xu","Shanghang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23649v3","updated":"2026-01-04T07:45:19Z","published":"2025-12-29T17:59:19Z","title":"RoboMirror: Understand Before You Imitate for Video to Humanoid Locomotion","summary":"Humans learn locomotion through visual observation, interpreting visual content first before imitating actions. However, state-of-the-art humanoid locomotion systems rely on either curated motion capture trajectories or sparse text commands, leaving a critical gap between visual understanding and control. Text-to-motion methods suffer from semantic sparsity and staged pipeline errors, while video-based approaches only perform mechanical pose mimicry without genuine visual understanding. We propose RoboMirror, the first retargeting-free video-to-locomotion framework embodying \"understand before you imitate\". Leveraging VLMs, it distills raw egocentric/third-person videos into visual motion intents, which directly condition a diffusion-based policy to generate physically plausible, semantically aligned locomotion without explicit pose reconstruction or retargeting. Extensive experiments validate the effectiveness of RoboMirror, it enables telepresence via egocentric videos, drastically reduces third-person control latency by 80%, and achieves a 3.7% higher task success rate than baselines. By reframing humanoid control around video understanding, we bridge the visual understanding and action gap.","authors":["Zhe Li","Cheng Chi","Boan Zhu","Yangyang Wei","Shuanghao Bai","Yuheng Ji","Yibo Peng","Tao Huang","Pengwei Wang","Zhongyuan Wang","S. -H. Gary Chan","Chang Xu","Shanghang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01409v1","updated":"2026-01-04T07:25:37Z","published":"2026-01-04T07:25:37Z","title":"Sampling Strategy Design for Model Predictive Path Integral Control on Legged Robot Locomotion","summary":"Model Predictive Path Integral (MPPI) control has emerged as a powerful sampling-based optimal control method for complex, nonlinear, and high-dimensional systems. However, directly applying MPPI to legged robotic systems presents several challenges. This paper systematically investigates the role of sampling strategy design within the MPPI framework for legged robot locomotion. Based upon the idea of structured control parameterization, we explore and compare multiple sampling strategies within the framework, including both unstructured and spline-based approaches. Through extensive simulations on a quadruped robot platform, we evaluate how different sampling strategies affect control smoothness, task performance, robustness, and sample efficiency. The results provide new insights into the practical implications of sampling design for deploying MPPI on complex legged systems.","authors":["Chuyuan Tao","Fanxin Wang","Haolong Jiang","Jia He","Yiyang Chen","Qinglei Bu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.01850v3","updated":"2026-01-04T02:59:45Z","published":"2024-11-04T07:05:02Z","title":"ManiBox: Enhancing Embodied Spatial Generalization via Scalable Simulation Data Generations","summary":"Embodied agents require robust spatial intelligence to execute precise real-world manipulations. However, this remains a significant challenge, as current methods often struggle to accurately position objects in space. Collecting extensive data can help address this issue by enhancing the agent's spatial understanding. Nonetheless, obtaining such data with real robots is prohibitively expensive, and relying on simulation data frequently leads to visual generalization gaps during real-world deployment. To tackle these challenges, we propose ManiBox, a novel bounding-box-guided framework. By decoupling perception from policy generalization, ManiBox effectively reduces the Sim2Real gap, leverages Internet-scale data, and scales our policy data collection in simulation. Specifically, within ManiBox, the RL teacher policy efficiently generates scalable simulation data. The student policy is distilled from this data and takes bounding boxes as input, which is proven sufficient for determining objects' spatial positions, thus enabling zero-shot transfer to real robots. Comprehensive evaluations in both simulated and real-world environments demonstrate that ManiBox exhibits strong spatial generalization and adaptability across various manipulation tasks and settings. Furthermore, our empirical study provides preliminary verification of spatial scaling laws, i.e., the amount of data required for spatial generalization scales with spatial volume following a power-law relationship. At a given spatial volume level, the success rate of manipulation tasks follows Michaelis-Menten kinetics with respect to data volume, exhibiting a saturation effect as data increases. Our videos and code are available at https://thkkk.github.io/manibox","authors":["Hengkai Tan","Xuezhou Xu","Chengyang Ying","Xinyi Mao","Zeyuan Wang","Songming Liu","Xingxing Zhang","Zhizhong Su","Hang Su","Jun Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24712v2","updated":"2026-01-04T02:50:40Z","published":"2025-12-31T08:27:10Z","title":"LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving","summary":"Real-world autonomous driving must adhere to complex human social rules that extend beyond legally codified traffic regulations. Many of these semantic constraints, such as yielding to emergency vehicles, complying with traffic officers' gestures, or stopping for school buses, are intuitive for humans yet difficult to encode explicitly. Although large vision-language models (VLMs) can interpret such semantics, their inference cost makes them impractical for real-time deployment. This work proposes LSRE, a Latent Semantic Rule Encoding framework that converts sparsely sampled VLM judgments into decision boundaries within the latent space of a recurrent world model. By encoding language-defined safety semantics into a lightweight latent classifier, LSRE enables real-time semantic risk assessment at 10 Hz without per-frame VLM queries. Experiments on six semantic-failure scenarios in CARLA demonstrate that LSRE attains semantic risk detection accuracy comparable to a large VLM baseline, while providing substantially earlier hazard anticipation and maintaining low computational latency. LSRE further generalizes to rarely seen semantic-similar test cases, indicating that language-guided latent classification offers an effective and deployable mechanism for semantic safety monitoring in autonomous driving.","authors":["Qian Cheng","Weitao Zhou","Cheng Jing","Nanshan Deng","Junze Wen","Zhaoyang Liu","Kun Jiang","Diange Yang"],"pdf_url":"","comment":null}],"Dynamical Systems":[{"id":"http://arxiv.org/abs/1807.07189v4","updated":"2026-01-04T23:30:20Z","published":"2018-07-19T00:05:47Z","title":"A Tale of Santa Claus, Hypergraphs and Matroids","summary":"A well-known problem in scheduling and approximation algorithms is the Santa Claus problem. Suppose that Santa Claus has a set of gifts, and he wants to distribute them among a set of children so that the least happy child is made as happy as possible. Here, the value that a child $i$ has for a present $j$ is of the form $p_{ij} \\in \\{ 0,p_j\\}$. A polynomial time algorithm by Annamalai et al. gives a $12.33$-approximation and is based on a modification of Haxell's hypergraph matching argument.\n  In this paper, we introduce a matroid version of the Santa Claus problem. Our algorithm is also based on Haxell's augmenting tree, but with the introduction of the matroid structure we solve a more general problem with cleaner methods. Our result can then be used as a blackbox to obtain a $(6+\\varepsilon)$-approximation for Santa Claus. This factor also compares against a natural, compact LP for Santa Claus.","authors":["Sami Davies","Thomas Rothvoss","Yihao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06536v2","updated":"2026-01-04T21:43:27Z","published":"2025-06-06T21:06:23Z","title":"Modern Minimal Perfect Hashing: A Survey","summary":"Given a set $S$ of $n$ keys, a perfect hash function for $S$ maps the keys in $S$ to the first $m \\geq n$ integers without collisions. It may return an arbitrary result for any key not in $S$ and is called minimal if $m = n$. The most important parameters are its space consumption, construction time, and query time. Years of research now enable modern perfect hash functions to be extremely fast to query, very space-efficient, and scale to billions of keys. Different approaches give different trade-offs between these aspects. For example, the smallest constructions get within 0.1% of the space lower bound of $\\log_2(e)$ bits per key. Others are particularly fast to query, requiring only one memory access. Perfect hashing has many applications, for example to avoid collision resolution in static hash tables, and is used in databases, bioinformatics, and stringology.\n  Since the last comprehensive survey in 1997, significant progress has been made. This survey covers the latest developments and provides a starting point for getting familiar with the topic. Additionally, our extensive experimental evaluation can serve as a guide to select a perfect hash function for use in applications.","authors":["Hans-Peter Lehmann","Thomas Mueller","Rasmus Pagh","Giulio Ermanno Pibiri","Peter Sanders","Sebastiano Vigna","Stefan Walzer"],"pdf_url":"","comment":"Version 2 includes the new technique PHast"},{"id":"http://arxiv.org/abs/2601.01550v1","updated":"2026-01-04T14:50:15Z","published":"2026-01-04T14:50:15Z","title":"Time-Dependent Hamiltonian Simulation in the Low-Energy Subspace","summary":"Hamiltonian simulations are key subroutines in adiabatic quantum computation, quantum control, and quantum many-body physics, where quantum dynamics often happen in the low-energy sector. In contrast to time-independent Hamiltonian simulations, a comprehensive understanding of quantum simulation algorithms for time-dependent Hamiltonians under the low-energy assumption remains limited hitherto. In this paper, we investigate how much we can improve upon the standard performance guarantee assuming the initial state is supported on a low-energy subspace. In particular, we compute the Trotter number of digital quantum simulation based on product formulas for time-dependent spin Hamiltonians under the low-energy assumption that the initial state is supported on a small number of low-energy eigenstates, and show improvements over the standard cost for simulating full unitary simulations. Technically, we derive the low-energy simulation error with commutator scaling for product formulas by leveraging adiabatic perturbation theory to analyze the time-variant energy spectrum of the underlying Hamiltonian. We further discuss the applications to simulations of non-equilibrium quantum many-body dynamics and adiabatic state preparation. Finally, we prove a lower bound of query complexity for generic time-dependent Hamiltonian simulations.","authors":["Shuo Zhou","Zhaokai Pan","Weiyuan Gong","Tongyang Li"],"pdf_url":"","comment":"29 pages, 1 figure"},{"id":"http://arxiv.org/abs/2512.00506v2","updated":"2026-01-04T10:12:28Z","published":"2025-11-29T14:24:22Z","title":"Expected Cost Analysis of Online Facility Assignment on Regular Polygons (v2)","summary":"This paper analyzes the online facility assignment problem in a geometric setting where facilities with unit capacity are positioned at the vertices of a regular $n$-gon. Customers arrive sequentially at uniformly random positions along the edges. They must be assigned immediately to the nearest available facility, with ties broken by coin toss. The sequential nature and unknown future arrivals require a probabilistic analysis of the expected assignment cost. Our main contribution is a recursive characterization of the expected cost: for any occupancy state $S$, the expected remaining cost $V(S)$ equals the average over all edge positions of the immediate assignment cost plus the expected future cost after assignment. We prove that this integral equation can calculate a solution and provide the expected value for small $n$ ($n = 3, 4, 5, \\dots$). For larger values of $n$ and expected cost, we develop efficient numerical methods, including a discretized dynamic programming approach and Monte Carlo simulation. The work establishes a fundamental probabilistic approach for online assignment in polygonal environments.","authors":["Md Rawha Siddiqi Riad","Md Manzurul Hasan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01390v1","updated":"2026-01-04T06:07:00Z","published":"2026-01-04T06:07:00Z","title":"Derandomizing Pseudopolynomial Algorithms for Subset Sum","summary":"We reexamine the classical subset sum problem: given a set $X$ of $n$ positive integers and a number $t$, decide whether there exists a subset of $X$ that sums to $t$; or more generally, compute the set $\\mbox{out}$ of all numbers $y\\in\\{0,\\ldots,t\\}$ for which there exists a subset of $X$ that sums to $y$. Standard dynamic programming solves the problem in $O(tn)$ time. In SODA'17, two papers appeared giving the current best deterministic and randomized algorithms, ignoring polylogarithmic factors: Koiliaris and Xu's deterministic algorithm runs in $\\widetilde{O}(t\\sqrt{n})$ time, while Bringmann's randomized algorithm runs in $\\widetilde{O}(t)$ time. We present the first deterministic algorithm running in $\\widetilde{O}(t)$ time.\n  Our technique has a number of other applications: for example, we can also derandomize the more recent output-sensitive algorithms by Bringmann and Nakos [STOC'20] and Bringmann, Fischer, and Nakos [SODA'25] running in $\\widetilde{O}(|\\mbox{out}|^{4/3})$ and $\\widetilde{O}(|\\mbox{out}|\\sqrt{n})$ time, and we can derandomize a previous fine-grained reduction from 0-1 knapsack to min-plus convolution by Cygan et al. [ICALP'17].","authors":["Timothy M. Chan"],"pdf_url":"","comment":"To appear in SODA 2026"},{"id":"http://arxiv.org/abs/2601.01388v1","updated":"2026-01-04T06:01:16Z","published":"2026-01-04T06:01:16Z","title":"AGIS: Fast Approximate Graph Pattern Mining with Structure-Informed Sampling","summary":"Approximate Graph Pattern Mining (AGPM) is essential for analyzing large-scale graphs where exact counting is computationally prohibitive. While there exist numerous sampling-based AGPM systems, they all rely on uniform sampling and overlook the underlying probability distribution. This limitation restricts their scalability to a broader range of patterns.\n  In this paper, we introduce AGIS, an extremely fast AGPM system capable of counting arbitrary patterns from huge graphs. AGIS employs structure-informed neighbor sampling, a novel sampling technique that deviates from uniformness but allocates specific sampling probabilities based on the pattern structure. We first derive the ideal sampling distribution for AGPM and then present a practical method to approximate it. Furthermore, we develop a method that balances convergence speed and computational overhead, determining when to use the approximated distribution.\n  Experimental results demonstrate that AGIS significantly outperforms the state-of-the-art AGPM system, achieving 28.5x geometric mean speedup and more than 100,000x speedup in specific cases. Furthermore, AGIS is the only AGPM system that scales to graphs with tens of billions of edges and robustly handles diverse patterns, successfully providing accurate estimates within seconds. We will open-source AGIS to encourage further research in this field.","authors":["Seoyong Lee","Jinho Lee"],"pdf_url":"","comment":"VLDB 2026"},{"id":"http://arxiv.org/abs/2505.13552v3","updated":"2026-01-04T03:10:44Z","published":"2025-05-19T05:26:31Z","title":"New Sorting Algorithm Wave Sort (W-Sort)","summary":"Modern comparison sorts like quicksort suffer from performance inconsistencies due to suboptimal pivot selection, leading to $(O(N^2))$ worst-case complexity, while in-place merge sort variants face challenges with data movement overhead. We introduce Wave Sort, a novel in-place sorting algorithm that addresses these limitations through a dynamic pivot selection strategy. Wave Sort iteratively expands a sorted region and selects pivots from this growing sorted portion to partition adjacent unsorted data. This approach ensures robust pivot selection irrespective of dataset size, guarantees a logarithmic recursion stack depth, and enables efficient in-place sorting. Our analysis shows a best comparison complexity of $(N-1)$, average comparison complexity close to $(\\log_2(N)!)$, and worst-case comparison complexity bounded by $(O(N(\\log(N))^2))$ with a small constant factor, which could be reduced to $(O(N\\log(N)))$ with hybrid sorting. The algorithm can be easily expanded to be hybridized with other sorting algorithms. Experimental results demonstrate that Wave Sort requires significantly fewer comparisons than quicksort on average (approximately 24% less) and performs close to the theoretical minimum $(\\log_2(N)!)$. Wave Sort offers a compelling alternative for applications demanding consistent, predictable, and in-place sorting performance.","authors":["Jia Xu Wei"],"pdf_url":"","comment":"27 pages, 5 figures"},{"id":"http://arxiv.org/abs/2502.05730v3","updated":"2026-01-04T01:27:27Z","published":"2025-02-09T00:17:49Z","title":"Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation","summary":"Le Cam's two-point testing method yields perhaps the simplest lower bound for estimating the mean of a distribution: roughly, if it is impossible to well-distinguish a distribution centered at $μ$ from the same distribution centered at $μ+Δ$, then it is impossible to estimate the mean by better than $Δ/2$. It is setting-dependent whether or not a nearly matching upper bound is attainable. We study the conditions under which the two-point testing lower bound can be attained for univariate mean estimation; both in the setting of location estimation (where the distribution is known up to translation) and adaptive location estimation (unknown distribution). Roughly, we will say an estimate nearly attains the two-point testing lower bound if it incurs error that is at most polylogarithmically larger than the Hellinger modulus of continuity for $\\tildeΩ(n)$ samples.\n  Adaptive location estimation is particularly interesting as some distributions admit much better guarantees than sub-Gaussian rates (e.g. $\\operatorname{Unif}(μ-1,μ+1)$ permits error $Θ(\\frac{1}{n})$, while the sub-Gaussian rate is $Θ(\\frac{1}{\\sqrt{n}})$), yet it is not obvious whether these rates may be adaptively attained by one unified approach. Our main result designs an algorithm that nearly attains the two-point testing rate for mixtures of symmetric, log-concave distributions with a common mean. Moreover, this algorithm runs in near-linear time and is parameter-free. In contrast, we show the two-point testing rate is not nearly attainable even for symmetric, unimodal distributions.\n  We complement this with results for location estimation, showing the two-point testing rate is nearly attainable for unimodal distributions, but unattainable for symmetric distributions.","authors":["Spencer Compton","Gregory Valiant"],"pdf_url":"","comment":null}],"Computational Finance":[{"id":"http://arxiv.org/abs/2601.01642v1","updated":"2026-01-04T19:15:22Z","published":"2026-01-04T19:15:22Z","title":"Wasserstein Distributionally Robust Rare-Event Simulation","summary":"Standard rare-event simulation techniques require exact distributional specifications, which limits their effectiveness in the presence of distributional uncertainty. To address this, we develop a novel framework for estimating rare-event probabilities subject to such distributional model risk. Specifically, we focus on computing worst-case rare-event probabilities, defined as a distributionally robust bound against a Wasserstein ambiguity set centered at a specific nominal distribution. By exploiting a dual characterization of this bound, we propose Distributionally Robust Importance Sampling (DRIS), a computationally tractable methodology designed to substantially reduce the variance associated with estimating the dual components. The proposed method is simple to implement and requires low sampling costs. Most importantly, it achieves vanishing relative error, the strongest efficiency guarantee that is notoriously difficult to establish in rare-event simulation. Our numerical studies confirm the superior performance of DRIS against existing benchmarks.","authors":["Dohyun Ahn","Huiyi Chen","Lewen Zheng"],"pdf_url":"","comment":null}],"Mathematical Finance":[{"id":"http://arxiv.org/abs/2601.01505v1","updated":"2026-01-04T12:16:24Z","published":"2026-01-04T12:16:24Z","title":"Chaos and Synchronization in Financial Leverages Dynamics: Modeling Systemic Risk with Coupled Unimodal Maps","summary":"Systemic financial risk refers to the simultaneous failure or destabilization of multiple financial institutions, often triggered by contagion mechanisms or common exposures to shocks. In this paper, we present a dynamical model of bank leverage (the ratio of asset holdings to equity) a quantity that both reflects and drives risk dynamics. We model how banks, constrained by Value-at-Risk (VaR) regulations, adjust their leverage in response to changes in the price of a single asset, assumed to be held in fixed proportion across banks. This leverage-targeting behavior introduces a procyclical feedback loop between asset prices and leverage. In the dynamics, this can manifest as logistic-like behavior with a rich bifurcation structure across model parameters. By analyzing these coupled dynamics in both isolated and interconnected bank models, we outline a framework for understanding how systemic risk can emerge from seemingly rational micro-level behavior.","authors":["Marco Ioffredi","Stefano Marmi","Matteo Tanzi"],"pdf_url":"","comment":"9 pages, 9 figures. Submitted to Chaos on January 2nd, 2026"}]},"2026-01-03T00:00:00Z":{"Optimization and Control":[{"id":"http://arxiv.org/abs/2405.14741v5","updated":"2026-01-03T23:30:57Z","published":"2024-05-23T16:05:10Z","title":"Subsampled Ensemble Can Improve Generalization Tail Exponentially","summary":"Ensemble learning is a popular technique to improve the accuracy of machine learning models. It traditionally hinges on the rationale that aggregating multiple weak models can lead to better models with lower variance and hence higher stability, especially for discontinuous base learners. In this paper, we provide a new perspective on ensembling. By selecting the most frequently generated model from the base learner when repeatedly applied to subsamples, we can attain exponentially decaying tails for the excess risk, even if the base learner suffers from slow (i.e., polynomial) decay rates. This tail enhancement power of ensembling applies to base learners that have reasonable predictive power to begin with and is stronger than variance reduction in the sense of exhibiting rate improvement. We demonstrate how our ensemble methods can substantially improve out-of-sample performances in a range of numerical examples involving heavy-tailed data or intrinsically slow rates.","authors":["Huajie Qian","Donghao Ying","Henry Lam","Wotao Yin"],"pdf_url":"","comment":"46 pages, 21 figures"},{"id":"http://arxiv.org/abs/2402.02698v2","updated":"2026-01-03T20:15:33Z","published":"2024-02-05T03:21:23Z","title":"Beyond Expectations: Learning with Stochastic Dominance Made Practical","summary":"Stochastic dominance serves as a general framework for modeling a broad spectrum of decision preferences under uncertainty, with risk aversion as one notable example, as it naturally captures the intrinsic structure of the underlying uncertainty, in contrast to simply resorting to the expectations. Despite theoretical appeal, the application of stochastic dominance in machine learning has been scarce, due to the following challenges: $\\textbf{i)}$, the original concept of stochastic dominance only provides a $\\textit{partial order}$, and therefore, is not amenable to serve as a general optimality criterion; and $\\textbf{ii)}$, an efficient computational recipe remains lacking due to the continuum nature of evaluating stochastic dominance.\n  In this work, we make the first attempt towards establishing a general framework of learning with stochastic dominance. We first generalize the stochastic dominance concept to enable feasible comparisons between any arbitrary pair of random variables. We next develop a simple and computationally efficient approach for finding the optimal solution in terms of stochastic dominance, which can be seamlessly plugged into many learning tasks. Numerical experiments demonstrate that the proposed method achieves comparable performance as standard risk-neutral strategies and obtains better trade-offs against risk across a variety of applications including supervised learning, reinforcement learning, and portfolio optimization.","authors":["Shicong Cen","Jincheng Mei","Hanjun Dai","Dale Schuurmans","Yuejie Chi","Bo Dai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2311.11166v4","updated":"2026-01-03T20:11:06Z","published":"2023-11-18T21:00:14Z","title":"From Optimization to Control: Quasi Policy Iteration","summary":"Recent control algorithms for Markov decision processes (MDPs) have been designed using an implicit analogy with well-established optimization algorithms. In this paper, we adopt the quasi-Newton method (QNM) from convex optimization to introduce a novel control algorithm coined as quasi-policy iteration (QPI). In particular, QPI is based on a novel approximation of the ``Hessian'' matrix in the policy iteration algorithm, which exploits two linear structural constraints specific to MDPs and allows for the incorporation of prior information on the transition probability kernel. While the proposed algorithm has the same computational complexity as value iteration, it exhibits an empirical convergence behavior similar to that of QNM with a low sensitivity to the discount factor.","authors":["Mohammad Amin Sharifi Kolarijani","Peyman Mohajerin Esfahani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01250v1","updated":"2026-01-03T18:00:22Z","published":"2026-01-03T18:00:22Z","title":"European Options in Market Models with Multiple Defaults: the BSDE approach","summary":"We study non-linear Backward Stochastic Differential Equations (BSDEs) driven by a Brownian motion and p default martingales. The driver of the BSDE with multiple default jumps can take a generalized form involving an optional finite variation process. We first show existence and uniqueness. We then establish comparison and strict comparison results for these BSDEs, under a suitable assumption on the driver. In the case of a linear driver, we derive an explicit formula for the first component of the BSDE using an adjoint exponential semimartingale. The representation depends on whether the finite variation process is predictable or only optional. We apply our results to the problem of pricing and hedging a European option in a linear complete market with two defaultable assets and in a non-linear complete market with p defaultable assets. Two examples of the latter market model are provided: an example where the seller of the option is a large investor influencing the probability of default of a single asset and an example where the large seller's strategy affects the default probabilities of all p assets.","authors":["Miryana Grigorova","James Wheeldon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01248v1","updated":"2026-01-03T17:55:26Z","published":"2026-01-03T17:55:26Z","title":"Stochastic Control Methods for Optimization","summary":"In this work, we investigate a stochastic control framework for global optimization over both finite-dimensional Euclidean spaces and the Wasserstein space of probability measures. In the Euclidean setting, the original minimization problem is approximated by a family of regularized stochastic control problems; using dynamic programming, we analyze the associated Hamilton--Jacobi--Bellman equations and obtain tractable representations via the Cole--Hopf transform and the Feynman--Kac formula. For optimization over probability measures, we formulate a regularized mean-field control problem characterized by a master equation, and further approximate it by controlled $N$-particle systems. We establish that, as the regularization parameter tends to zero (and as the particle number tends to infinity for the optimization over probability measures), the value of the control problem converges to the global minimum of the original objective. Building on the resulting probabilistic representations, Monte Carlo-based numerical schemes are proposed and numerical experiments are reported to illustrate the practical performance of the methods and to support the theoretical convergence rates.","authors":["Jinniao Qiu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01175v1","updated":"2026-01-03T12:37:20Z","published":"2026-01-03T12:37:20Z","title":"Scalable Method for Mean Field Control with Kernel Interactions via Random Fourier Features","summary":"We develop a scalable algorithm for mean field control problems with kernel interactions by combining particle system simulations with random Fourier feature approximations. The method replaces the quadratic-cost kernel evaluations by linear-time estimates, enabling efficient stochastic gradient descent for training feedback controls in large populations. We provide theoretical complexity bounds and demonstrate through crowd motion and flocking examples that the approach preserves control performance while substantially reducing computational cost. The results indicate that random feature approximations offer an effective and practical tool for high dimensional and large scale mean field control.","authors":["Zhongyuan Cao","Kaustav Das","Nicolas Langrené","Mathieu Laurière"],"pdf_url":"","comment":null}],"Performance":[{"id":"http://arxiv.org/abs/2601.01288v1","updated":"2026-01-03T21:19:57Z","published":"2026-01-03T21:19:57Z","title":"PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS","summary":"Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.","authors":["Evgenii Rudakov","Jonathan Shock","Benjamin Ultan Cowley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01265v1","updated":"2026-01-03T19:24:00Z","published":"2026-01-03T19:24:00Z","title":"CounterPoint: Using Hardware Event Counters to Refute and Refine Microarchitectural Assumptions (Extended Version)","summary":"Hardware event counters offer the potential to reveal not only performance bottlenecks but also detailed microarchitectural behavior. In practice, this promise is undermined by their vague specifications, opaque designs, and multiplexing noise, making event counter data hard to interpret.\n  We introduce CounterPoint, a framework that tests user-specified microarchitectural models - expressed as $μ$path Decision Diagrams - for consistency with performance counter data. When mismatches occur, CounterPoint pinpoints plausible microarchitectural features that could explain them, using multi-dimensional counter confidence regions to mitigate multiplexing noise. We apply CounterPoint to the Haswell Memory Management Unit as a case study, shedding light on multiple undocumented and underdocumented microarchitectural behaviors. These include a load-store queue-side TLB prefetcher, merging page table walkers, abortable page table walks, and more.\n  Overall, CounterPoint helps experts reconcile noisy hardware performance counter measurements with their mental model of the microarchitecture - uncovering subtle, previously hidden hardware features along the way.","authors":["Nick Lindsay","Caroline Trippel","Anurag Khandelwal","Abhishek Bhattacharjee"],"pdf_url":"","comment":"This is an extended version of a paper which has been accepted to the 31st ACM International Conference on Architectural Support for Programming Languages and Operating Systems conference (ASPLOS, March 2026). 20 pages, 20 figures, 8 tables"},{"id":"http://arxiv.org/abs/2601.01031v1","updated":"2026-01-03T01:45:03Z","published":"2026-01-03T01:45:03Z","title":"A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations","summary":"We develop an integrated Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for relay-centric distributed satellite systems (DSS), capturing concurrent data dissemination, parallel computation, and result return under heterogeneous onboard processing and inter-satellite link conditions. We propose a formulation that yields closed-form expressions for optimal load allocation and completion time that explicitly quantify the joint impact of computation speed, link bandwidth, and result-size overhead. We further derive deadline feasibility conditions that enable explicit sizing of cooperative satellite clusters to meet time-critical task requirements. Extensive simulation results demonstrate that highly distributable tasks achieve substantial latency reduction, while communication-heavy tasks exhibit diminishing returns due to result-transfer overheads. To bridge theory and practice, we extend the MPCC-DLT framework with a real-time admission control mechanism that handles stochastic task arrivals and deadline constraints, enabling blocking-aware operation. Our real-time simulations illustrate how task structure and system parameters jointly govern deadline satisfaction and operating regimes. Overall, this work provides the first analytically tractable MPCC-DLT model for distributed satellite systems and offers actionable insights for application-aware scheduling and system-level design of future satellite constellations.","authors":["Bharadwaj Veeravalli"],"pdf_url":"","comment":null}],"Image and Video Processing":[{"id":"http://arxiv.org/abs/2406.18508v2","updated":"2026-01-03T21:13:02Z","published":"2024-06-26T17:29:15Z","title":"Assessment of Clonal Hematopoiesis of Indeterminate Potential and Future Cardiomyopathy from Cardiac Magnetic Resonance Imaging using Deep Learning in a Cardio-oncology Population","summary":"We propose a novel deep learning framework to identify clonal hematopoiesis of indeterminate potential (CHIP), a somatic mutation condition associated with adverse cardiovascular outcomes, using routine cardiac magnetic resonance (CMR) imaging. Utilizing 152 multi-view late gadolinium enhancement (LGE) scans from 136 cardio-oncology patients, we developed a convolutional neural network to (1) detect CHIP status and (2) stratify the risk of future cardiomyopathy specifically within the CHIP-positive cohort. To ensure robustness, we performed rigorous feature importance analysis to rule out reliance on demographic confounders such as age and immune checkpoint inhibitor usage. The model achieved an AUC of 0.71 for CHIP detection and, notably, an AUC of 0.87 for predicting future cardiomyopathy in CHIP-positive patients, significantly outperforming demographic-only baselines. These results demonstrate the feasibility of using LGE-CMR signatures as a non-invasive \"radiogenomic\" screening tool, potentially enabling accessible risk stratification and precision medicine for high-risk cardiovascular populations.","authors":["Jiarui Xing","Sangeon Ryu","Shawn Ahn","Jeacy Espinoza","James L. Cross","Stephanie Halene","James S. Duncan","Alokkumar Jha","Jennifer M Kwan","Nicha C. Dvornek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01257v1","updated":"2026-01-03T18:40:35Z","published":"2026-01-03T18:40:35Z","title":"Seamlessly Natural: Image Stitching with Natural Appearance Preservation","summary":"This paper introduces SENA (SEamlessly NAtural), a geometry-driven image stitching approach that prioritizes structural fidelity in challenging real-world scenes characterized by parallax and depth variation. Conventional image stitching relies on homographic alignment, but this rigid planar assumption often fails in dual-camera setups with significant scene depth, leading to distortions such as visible warps and spherical bulging. SENA addresses these fundamental limitations through three key contributions. First, we propose a hierarchical affine-based warping strategy, combining global affine initialization with local affine refinement and smooth free-form deformation. This design preserves local shape, parallelism, and aspect ratios, thereby avoiding the hallucinated structural distortions commonly introduced by homography-based models. Second, we introduce a geometry-driven adequate zone detection mechanism that identifies parallax-minimized regions directly from the disparity consistency of RANSAC-filtered feature correspondences, without relying on semantic segmentation. Third, building upon this adequate zone, we perform anchor-based seamline cutting and segmentation, enforcing a one-to-one geometric correspondence across image pairs by construction, which effectively eliminates ghosting, duplication, and smearing artifacts in the final panorama.\n  Extensive experiments conducted on challenging datasets demonstrate that SENA achieves alignment accuracy comparable to leading homography-based methods, while significantly outperforming them in critical visual metrics such as shape preservation, texture integrity, and overall visual realism.","authors":["Gaetane Lorna N. Tchana","Damaris Belle M. Fotso","Antonio Hendricks","Christophe Bobda"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01200v1","updated":"2026-01-03T14:58:52Z","published":"2026-01-03T14:58:52Z","title":"MS-ISSM: Objective Quality Assessment of Point Clouds Using Multi-scale Implicit Structural Similarity","summary":"The unstructured and irregular nature of point clouds poses a significant challenge for objective quality assessment (PCQA), particularly in establishing accurate perceptual feature correspondence. To tackle this, we propose the Multi-scale Implicit Structural Similarity Measurement (MS-ISSM). Unlike traditional point-to-point matching, MS-ISSM utilizes Radial Basis Functions (RBF) to represent local features continuously, transforming distortion measurement into a comparison of implicit function coefficients. This approach effectively circumvents matching errors inherent in irregular data. Additionally, we propose a ResGrouped-MLP quality assessment network, which robustly maps multi-scale feature differences to perceptual scores. The network architecture departs from traditional flat MLPs by adopting a grouped encoding strategy integrated with Residual Blocks and Channel-wise Attention mechanisms. This hierarchical design allows the model to preserve the distinct physical semantics of luma, chroma, and geometry while adaptively focusing on the most salient distortion features across High, Medium, and Low scales. Experimental results on multiple benchmarks demonstrate that MS-ISSM outperforms state-of-the-art metrics in both reliability and generalization. The source code is available at: https://github.com/ZhangChen2022/MS-ISSM.","authors":["Zhang Chen","Shuai Wan","Yuezhe Zhang","Siyu Ren","Fuzheng Yang","Junhui Hou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.10143v2","updated":"2026-01-03T13:47:22Z","published":"2024-09-16T10:13:34Z","title":"P2U-SLAM: A Monocular Wide-FoV SLAM System Based on Point Uncertainty and Pose Uncertainty","summary":"This paper presents P2U-SLAM, a visual Simultaneous Localization And Mapping (SLAM) system with a wide Field of View (FoV) camera, which utilizes pose uncertainty and point uncertainty. While the wide FoV enables considerable repetitive observations of historical map points for matching cross-view features, the data properties of the historical map points and the poses of historical keyframes have changed during the optimization process. The neglect of data property changes results in the lack of partial information matrices in optimization, increasing the risk of long-term positioning performance degradation. The purpose of our research is to mitigate the risks posed by wide-FoV visual input to the SLAM system. Based on the conditional probability model, this work reveals the definite impacts of the above data properties changes on the optimization process, concretizes these impacts as point uncertainty and pose uncertainty, and gives their specific mathematical form. P2U-SLAM embeds point uncertainty into the tracking module and pose uncertainty into the local mapping module respectively, and updates these uncertainties after each optimization operation including local mapping, map merging, and loop closing. We present an exhaustive evaluation on 27 sequences from two popular public datasets with wide-FoV visual input. P2U-SLAM shows excellent performance compared with other state-of-the-art methods. The source code will be made publicly available at https://github.com/BambValley/P2U-SLAM.","authors":["Yufan Zhang","Kailun Yang","Ze Wang","Kaiwei Wang"],"pdf_url":"","comment":"Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS). The source code will be made publicly available at https://github.com/BambValley/P2U-SLAM"},{"id":"http://arxiv.org/abs/2601.01141v1","updated":"2026-01-03T10:12:07Z","published":"2026-01-03T10:12:07Z","title":"YODA: Yet Another One-step Diffusion-based Video Compressor","summary":"While one-step diffusion models have recently excelled in perceptual image compression, their application to video remains limited. Prior efforts typically rely on pretrained 2D autoencoders that generate per-frame latent representations independently, thereby neglecting temporal dependencies. We present YODA--Yet Another One-step Diffusion-based Video Compressor--which embeds multiscale features from temporal references for both latent generation and latent coding to better exploit spatial-temporal correlations for more compact representation, and employs a linear Diffusion Transformer (DiT) for efficient one-step denoising. YODA achieves state-of-the-art perceptual performance, consistently outperforming traditional and deep-learning baselines on LPIPS, DISTS, FID, and KID. Source code will be publicly available at https://github.com/NJUVISION/YODA.","authors":["Xingchen Li","Junzhe Zhang","Junqi Shi","Ming Lu","Zhan Ma"],"pdf_url":"","comment":"Code will be available at https://github.com/NJUVISION/YODA"},{"id":"http://arxiv.org/abs/2601.01103v1","updated":"2026-01-03T07:46:59Z","published":"2026-01-03T07:46:59Z","title":"Histogram Assisted Quality Aware Generative Model for Resolution Invariant NIR Image Colorization","summary":"We present HAQAGen, a unified generative model for resolution-invariant NIR-to-RGB colorization that balances chromatic realism with structural fidelity. The proposed model introduces (i) a combined loss term aligning the global color statistics through differentiable histogram matching, perceptual image quality measure, and feature based similarity to preserve texture information, (ii) local hue-saturation priors injected via Spatially Adaptive Denormalization (SPADE) to stabilize chromatic reconstruction, and (iii) texture-aware supervision within a Mamba backbone to preserve fine details. We introduce an adaptive-resolution inference engine that further enables high-resolution translation without sacrificing quality. Our proposed NIR-to-RGB translation model simultaneously enforces global color statistics and local chromatic consistency, while scaling to native resolutions without compromising texture fidelity or generalization. Extensive evaluations on FANVID, OMSIV, VCIP2020, and RGB2NIR using different evaluation metrics demonstrate consistent improvements over state-of-the-art baseline methods. HAQAGen produces images with sharper textures, natural colors, attaining significant gains as per perceptual metrics. These results position HAQAGen as a scalable and effective solution for NIR-to-RGB translation across diverse imaging scenarios. Project Page: https://rajeev-dw9.github.io/HAQAGen/","authors":["Abhinav Attri","Rajeev Ranjan Dwivedi","Samiran Das","Vinod Kumar Kurmi"],"pdf_url":"","comment":"Accepted at WACV 2026"},{"id":"http://arxiv.org/abs/2601.01084v1","updated":"2026-01-03T06:19:18Z","published":"2026-01-03T06:19:18Z","title":"A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields","summary":"We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.","authors":["Adari Rama Sukanya","Puvvula Roopesh Naga Sri Sai","Kota Moses","Rimalapudi Sarvendranath"],"pdf_url":"","comment":"10-page dataset explanation paper"},{"id":"http://arxiv.org/abs/2601.01064v1","updated":"2026-01-03T04:19:14Z","published":"2026-01-03T04:19:14Z","title":"Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers","summary":"Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.","authors":["Jianan Li","Wangcai Zhao","Tingfa Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01008v1","updated":"2026-01-03T00:10:08Z","published":"2026-01-03T00:10:08Z","title":"An Explainable Agentic AI Framework for Uncertainty-Aware and Abstention-Enabled Acute Ischemic Stroke Imaging Decisions","summary":"Artificial intelligence models have shown strong potential in acute ischemic stroke imaging, particularly for lesion detection and segmentation using computed tomography and magnetic resonance imaging. However, most existing approaches operate as black box predictors, producing deterministic outputs without explicit uncertainty awareness or structured mechanisms to abstain under ambiguous conditions. This limitation raises serious safety and trust concerns in high risk emergency radiology settings. In this paper, we propose an explainable agentic AI framework for uncertainty aware and abstention enabled decision support in acute ischemic stroke imaging. The framework follows a modular agentic pipeline in which a perception agent performs lesion aware image analysis, an uncertainty estimation agent computes slice level predictive reliability, and a decision agent determines whether to issue a prediction or abstain based on predefined uncertainty thresholds. Unlike prior stroke imaging systems that primarily focus on improving segmentation or classification accuracy, the proposed framework explicitly prioritizes clinical safety, transparency, and clinician aligned decision behavior. Qualitative and case based analyses across representative stroke imaging scenarios demonstrate that uncertainty driven abstention naturally emerges in diagnostically ambiguous regions and low information slices. The framework further integrates visual explanation mechanisms to support both predictive and abstention decisions, addressing a key limitation of existing uncertainty aware medical imaging systems. Rather than introducing a new performance benchmark, this work presents agentic control, uncertainty awareness, and selective abstention as essential design principles for developing safe and trustworthy medical imaging AI systems.","authors":["Md Rashadul Islam"],"pdf_url":"","comment":"Preprint. Conceptual and exploratory framework focusing on uncertainty-aware and abstention-enabled decision support for acute ischemic stroke imaging"}],"Graphics":[{"id":"http://arxiv.org/abs/2601.01288v1","updated":"2026-01-03T21:19:57Z","published":"2026-01-03T21:19:57Z","title":"PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS","summary":"Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.","authors":["Evgenii Rudakov","Jonathan Shock","Benjamin Ultan Cowley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01257v1","updated":"2026-01-03T18:40:35Z","published":"2026-01-03T18:40:35Z","title":"Seamlessly Natural: Image Stitching with Natural Appearance Preservation","summary":"This paper introduces SENA (SEamlessly NAtural), a geometry-driven image stitching approach that prioritizes structural fidelity in challenging real-world scenes characterized by parallax and depth variation. Conventional image stitching relies on homographic alignment, but this rigid planar assumption often fails in dual-camera setups with significant scene depth, leading to distortions such as visible warps and spherical bulging. SENA addresses these fundamental limitations through three key contributions. First, we propose a hierarchical affine-based warping strategy, combining global affine initialization with local affine refinement and smooth free-form deformation. This design preserves local shape, parallelism, and aspect ratios, thereby avoiding the hallucinated structural distortions commonly introduced by homography-based models. Second, we introduce a geometry-driven adequate zone detection mechanism that identifies parallax-minimized regions directly from the disparity consistency of RANSAC-filtered feature correspondences, without relying on semantic segmentation. Third, building upon this adequate zone, we perform anchor-based seamline cutting and segmentation, enforcing a one-to-one geometric correspondence across image pairs by construction, which effectively eliminates ghosting, duplication, and smearing artifacts in the final panorama.\n  Extensive experiments conducted on challenging datasets demonstrate that SENA achieves alignment accuracy comparable to leading homography-based methods, while significantly outperforming them in critical visual metrics such as shape preservation, texture integrity, and overall visual realism.","authors":["Gaetane Lorna N. Tchana","Damaris Belle M. Fotso","Antonio Hendricks","Christophe Bobda"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01050v1","updated":"2026-01-03T03:08:48Z","published":"2026-01-03T03:08:48Z","title":"EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos","summary":"We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.","authors":["Hongming Fu","Wenjia Wang","Xiaozhen Qiao","Shuo Yang","Zheng Liu","Bo Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01027v1","updated":"2026-01-03T01:27:19Z","published":"2026-01-03T01:27:19Z","title":"A Platform for Interactive AI Character Experiences","summary":"From movie characters to modern science fiction - bringing characters into interactive, story-driven conversations has captured imaginations across generations. Achieving this vision is highly challenging and requires much more than just language modeling. It involves numerous complex AI challenges, such as conversational AI, maintaining character integrity, managing personality and emotions, handling knowledge and memory, synthesizing voice, generating animations, enabling real-world interactions, and integration with physical environments. Recent advancements in the development of foundation models, prompt engineering, and fine-tuning for downstream tasks have enabled researchers to address these individual challenges. However, combining these technologies for interactive characters remains an open problem. We present a system and platform for conveniently designing believable digital characters, enabling a conversational and story-driven experience while providing solutions to all of the technical challenges. As a proof-of-concept, we introduce Digital Einstein, which allows users to engage in conversations with a digital representation of Albert Einstein about his life, research, and persona. While Digital Einstein exemplifies our methods for a specific character, our system is flexible and generalizes to any story-driven or conversational character. By unifying these diverse AI components into a single, easy-to-adapt platform, our work paves the way for immersive character experiences, turning the dream of lifelike, story-based interactions into a reality.","authors":["Rafael Wampfler","Chen Yang","Dillon Elste","Nikola Kovacevic","Philine Witzig","Markus Gross"],"pdf_url":"","comment":null}],"Signal Processing":[{"id":"http://arxiv.org/abs/2601.01277v1","updated":"2026-01-03T20:20:20Z","published":"2026-01-03T20:20:20Z","title":"Pinching Antennas in Blockage-Aware Environments: Modeling, Design, and Optimization","summary":"Pinching-antenna (PA) systems have recently emerged as a promising member of the flexible-antenna family due to their ability to dynamically establish line-of-sight (LoS) links. While most existing studies assume ideal environments without obstacles, practical indoor deployments are often obstacle-rich, where LoS blockage significantly degrades performance. This paper investigates pinching-antenna systems in blockage-aware environments by developing a deterministic model for cylinder-shaped obstacles that precisely characterizes LoS conditions without relying on stochastic approximations. Based on this model, a special case is first studied where each PA serves a single user and can only be deployed at discrete positions along the waveguide. In this case, the waveguide-user assignment is obtained via the Hungarian algorithm, and PA positions are refined using a surrogate-assisted block-coordinate search. Then, a general case is considered where each PA serves all users and can be continuously placed along the waveguide. In this case, beamforming and PA positions are jointly optimized by a weighted minimum mean square error integrated deep deterministic policy gradient (WMMSE-DDPG) approach to address non-smooth LoS transitions. Simulation results demonstrate that the proposed algorithms significantly improve system throughput and LoS connectivity compared with benchmark methods. Moreover, the results reveal that pinching-antenna systems can effectively leverage obstacles to suppress co-channel interference, converting potential blockages into performance gains.","authors":["Ximing Xie","Fang Fang","Zhiguo Ding","Xianbin Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01257v1","updated":"2026-01-03T18:40:35Z","published":"2026-01-03T18:40:35Z","title":"Seamlessly Natural: Image Stitching with Natural Appearance Preservation","summary":"This paper introduces SENA (SEamlessly NAtural), a geometry-driven image stitching approach that prioritizes structural fidelity in challenging real-world scenes characterized by parallax and depth variation. Conventional image stitching relies on homographic alignment, but this rigid planar assumption often fails in dual-camera setups with significant scene depth, leading to distortions such as visible warps and spherical bulging. SENA addresses these fundamental limitations through three key contributions. First, we propose a hierarchical affine-based warping strategy, combining global affine initialization with local affine refinement and smooth free-form deformation. This design preserves local shape, parallelism, and aspect ratios, thereby avoiding the hallucinated structural distortions commonly introduced by homography-based models. Second, we introduce a geometry-driven adequate zone detection mechanism that identifies parallax-minimized regions directly from the disparity consistency of RANSAC-filtered feature correspondences, without relying on semantic segmentation. Third, building upon this adequate zone, we perform anchor-based seamline cutting and segmentation, enforcing a one-to-one geometric correspondence across image pairs by construction, which effectively eliminates ghosting, duplication, and smearing artifacts in the final panorama.\n  Extensive experiments conducted on challenging datasets demonstrate that SENA achieves alignment accuracy comparable to leading homography-based methods, while significantly outperforming them in critical visual metrics such as shape preservation, texture integrity, and overall visual realism.","authors":["Gaetane Lorna N. Tchana","Damaris Belle M. Fotso","Antonio Hendricks","Christophe Bobda"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01232v1","updated":"2026-01-03T16:39:21Z","published":"2026-01-03T16:39:21Z","title":"A 2.5 $μ$W 30 nV/$\\surd$Hz Instrumentation Amplifier for Bioimpedance Sensors with Source Degenerated Current Mirror and DTMOS Transistor","summary":"This paper proposes a low-power and low-noise instrumentation amplifier (IA) tailored for bioimpedance sensing applications. The design originates from a gain-boosted flipped voltage follower (FVF) transconductance (TC) stage and integrates two complementary circuit techniques to improve the noise performance. To achieve an optimal balance between input-referred noise and available voltage headroom, a source-degenerated current mirror (SDCM) is adopted, resulting in reducing the input-referred noise by 7.95% compared with a conventional current mirror structure. In addition, a dynamic threshold MOSFET (DTMOS) scheme is employed to enhance the effective transconductance, leading to a further 11.66% reduction in input-referred noise. Simulated in a 28 nm CMOS process demonstrate that the proposed IA achieves an input-referred noise floor of 30 nV/$\\surd$Hz and a bandwidth of 1.44 MHz, while consuming only 2.5 $μ$W from a 0.8 V supply. Compared to the baseline design, the proposed approach achieves a 32.4% reduction in power consumption without degrading noise performance. The complete design parameters are open-sourced in this paper, to ensure reproducibility and facilitate future developments.","authors":["Yu Xue","Kwantae Kim"],"pdf_url":"","comment":"11 pages, 14 figures"},{"id":"http://arxiv.org/abs/2601.01229v1","updated":"2026-01-03T16:35:45Z","published":"2026-01-03T16:35:45Z","title":"NeuroSSM: Multiscale Differential State-Space Modeling for Context-Aware fMRI Analysis","summary":"Accurate fMRI analysis requires sensitivity to temporal structure across multiple scales, as BOLD signals encode cognitive processes that emerge from fast transient dynamics to slower, large-scale fluctuations. Existing deep learning (DL) approaches to temporal modeling face challenges in jointly capturing these dynamics over long fMRI time series. Among current DL models, transformers address long-range dependencies by explicitly modeling pairwise interactions through attention, but the associated quadratic computational cost limits effective integration of temporal dependencies across long fMRI sequences. Selective state-space models (SSMs) instead model long-range temporal dependencies implicitly through latent state evolution in a dynamical system, enabling efficient propagation of dependencies over time. However, recent SSM-based approaches for fMRI commonly operate on derived functional connectivity representations and employ single-scale temporal processing. These design choices constrain the ability to jointly represent fast transient dynamics and slower global trends within a single model. We propose NeuroSSM, a selective state-space architecture designed for end-to-end analysis of raw BOLD signals in fMRI time series. NeuroSSM addresses the above limitations through two complementary design components: a multiscale state-space backbone that captures fast and slow dynamics concurrently, and a parallel differencing branch that increases sensitivity to transient state changes. Experiments on clinical and non-clinical datasets demonstrate that NeuroSSM achieves competitive performance and efficiency against state-of-the-art fMRI analysis methods.","authors":["Furkan Genç","Boran İsmet Macun","Sait Sarper Özaslan","Emine U. Saritas","Tolga Çukur"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.05438v3","updated":"2026-01-03T15:12:29Z","published":"2025-10-06T23:04:47Z","title":"Model-based Deep Learning for Joint RIS Phase Shift Compression and WMMSE Beamforming","summary":"A model-based deep learning (DL) architecture is proposed for reconfigurable intelligent surface (RIS)-assisted multi-user communications to reduce the overhead of transmitting phase shift information from the access point (AP) to the RIS controller. The phase shifts are computed at the AP, which has access to the channel state information, and then encoded into a compressed binary control message that is sent to the RIS controller for element configuration. To help reduce beamformer mismatches due to phase shift compression errors, the beamformer is updated using weighted minimum mean square error (WMMSE) based on the effective channel resulting from the actual (decompressed) RIS reflection coefficients. By unrolling the iterative WMMSE algorithm as part of the wireless communication informed DL architecture, joint phase shift compression and WMMSE beamforming can be trained end-to-end. Simulations show that accounting for phase shift compression errors during beamforming significantly improves the sum-rate performance, even when the number of control bits is lower than the number of RIS elements.","authors":["Alexander James Fernandes","Ioannis Psaromiligkos"],"pdf_url":"","comment":"5 pages, 4 figures, resubmission to IEEE Wireless Communications Letters: WCL2025-2467"},{"id":"http://arxiv.org/abs/2601.01194v1","updated":"2026-01-03T14:26:39Z","published":"2026-01-03T14:26:39Z","title":"On the Structure of the Optimal Detector for Sub-THz Multi-Hop Relays with Unknown Prior: Over-the-Air Diffusion","summary":"Amplify and forward (AF) relaying is a viable strategy to extend the coverage of sub-terahertz (sub-THz) links, but inevitably propagates noise, leading to cumulative degradation across multiple hops. At the receiver, optimal decoding is desirable, yet challenging under non-Gaussian input distributions (video, voice, etc), for which neither the Minimum Mean Square Error (MMSE) estimator nor the mutual information admits a closed form. A further open question is whether knowledge of Channel State Information (CSI) and noise statistics at the intermediate relays is necessary for optimal detection. Aiming for an optimal decoder, this paper introduces a new framework that interprets the AF relay chain as a variance-preserving diffusion process and employs denoising diffusion implicit models (DDIMs) for signal recovery. We show that each AF hop is mathematically equivalent to a diffusion step with hop-dependent attenuation and noise injection. Consequently, the entire multi-hop chain collapses to an equivalent Gaussian channel fully described by only three real scalars per block: the cumulative complex gain and the effective noise variance. At the receiver, these end-to-end sufficient statistics define a matched reverse schedule that guides the DDIM-based denoiser, enabling near-optimal Bayesian decoding without per-hop CSI. We establish the information-theoretic foundation of this equivalence, proving that decoding performance depends solely on the final effective Signal-to-Noise-Ratio (SNR), regardless of intermediate noise/channel allocation or prior distribution. Simulations under AWGN and Rician fading confirm that the proposed AF-DDIM decoder reduces mean-squared error, symbol error rate, and bit error rate, particularly at moderate SNRs and for higher-order constellations.","authors":["Ozgur Ercetin","Mohaned Chraiti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.24001v4","updated":"2026-01-03T12:34:36Z","published":"2025-05-29T20:52:54Z","title":"Multi-output Classification using a Cross-talk Architecture for Compound Fault Diagnosis of Motors in Partially Labeled Condition","summary":"The increasing complexity of rotating machinery and the diversity of operating conditions, such as rotating speed and varying torques, have amplified the challenges in fault diagnosis in scenarios requiring domain adaptation, particularly involving compound faults. This study addresses these challenges by introducing a novel multi-output classification (MOC) framework tailored for domain adaptation in partially labeled target datasets. Unlike conventional multi-class classification (MCC) approaches, the MOC framework classifies the severity levels of compound faults simultaneously. Furthermore, we explore various single-task and multi-task architectures applicable to the MOC formulation-including shared trunk and cross-talk-based designs-for compound fault diagnosis under partially labeled conditions. Based on this investigation, we propose a novel cross-talk architecture, residual neural dimension reductor (RNDR), that enables selective information sharing across diagnostic tasks, effectively enhancing classification performance in compound fault scenarios. In addition, frequency-layer normalization was incorporated to improve domain adaptation performance on motor vibration data. Compound fault conditions were implemented using a motor-based test setup and evaluated across six domain adaptation scenarios. The experimental results demonstrate its superior macro F1 performance compared to baseline models. We further showed that the structural advantage of RNDR is more pronounced in compound fault settings through a single-fault comparison. We also found that frequency-layer normalization fits the fault diagnosis task better than conventional methods. Lastly, we analyzed the RNDR with various conditions, other models with increased number of parameters, and compared with the ablated RNDR structure.","authors":["Wonjun Yi","Wonho Jung","Hyeonuk Nam","Kangmin Jang","Yong-Hwa Park"],"pdf_url":"","comment":"Published in Mechanical Systems and Signal Processing, Volume 244, 15 January 2026, Article 113786. Version of record available online on 25 December 2025"},{"id":"http://arxiv.org/abs/2601.01152v1","updated":"2026-01-03T10:44:11Z","published":"2026-01-03T10:44:11Z","title":"Towards a Theoretical Framework for Robust Node Deployment in Cooperative ISAC Networks","summary":"This paper investigates node deployment strategies for robust multi-node cooperative localization in integrated sensing and communication (ISAC) networks.We first analyze how steering vector correlation across different positions affects localization performance and introduce a novel distance-weighted correlation metric to characterize this effect. Building upon this insight, we propose a deployment optimization framework that minimizes the maximum weighted steering vector correlation by optimizing simultaneously node positions and array orientations, thereby enhancing worst-case network robustness. Then, a genetic algorithm (GA) is developed to solve this min-max optimization, yielding optimized node positions and array orientations. Extensive simulations using both multiple signal classification (MUSIC) and neural-network (NN)-based localization validate the effectiveness of the proposed methods, demonstrating significant improvements in robust localization performance.","authors":["Haojin Li","Kaiqian Qu","Chen Sun","Anbang Zhang","Xiaoxue Wang","Wenqi Zhang","Haijun Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.02223v3","updated":"2026-01-03T09:16:28Z","published":"2025-08-04T09:14:06Z","title":"The ECME Algorithm Using Factor Analysis for DOA Estimation in Nonuniform Noise","summary":"Factor analysis (FA) plays a critical role in psychometrics, econometrics, and statistics. Recently, maximum likelihood FA (MLFA) has been applied to direction of arrival (DOA) estimation in unknown nonuniform noise and a variety of iterative approaches have been developed. In particular, the Factor Analysis for Anisotropic Noise (FAAN) method proposed by Stoica and Babu has excellent convergence properties. In this article, the Expectation/Conditional Maximization Either (ECME) algorithm, an extension of the expectation-maximization algorithm, is designed again for MLFA by introducing new complete data, which can thus use two explicit formulas to sequentially update the estimates of parameters at each iteration and have excellent convergence properties. Theoretical analysis shows that the ECME algorithm has almost the same computational complexity at each iteration as the FAAN method. However, numerical results show that the ECME algorithm yields faster stable convergence and the convergence to the global optimum is easier. Importantly, MLFA is not the best choice for the subspace based DOA estimation in unknown nonuniform noise.","authors":["Mingyan Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01065v1","updated":"2026-01-03T04:21:00Z","published":"2026-01-03T04:21:00Z","title":"Tiny Machine Learning for Real-Time Aquaculture Monitoring: A Case Study in Morocco","summary":"Aquaculture, the farming of aquatic organisms, is a rapidly growing industry facing challenges such as water quality fluctuations, disease outbreaks, and inefficient feed management. Traditional monitoring methods often rely on manual labor and are time consuming, leading to potential delays in addressing issues. This paper proposes the integration of low-power edge devices using Tiny Machine Learning (TinyML) into aquaculture systems to enable real-time automated monitoring and control, such as collecting data and triggering alarms, and reducing labor requirements. The system provides real-time data on the required parameters such as pH levels, temperature, dissolved oxygen, and ammonia levels to control water quality, nutrient levels, and environmental conditions enabling better maintenance, efficient resource utilization, and optimal management of the enclosed aquaculture space. The system enables alerts in case of anomaly detection. The data collected by the sensors over time can serve for important decision-making regarding optimizing water treatment processes, feed distribution, feed pattern analysis and improve feed efficiency, reducing operational costs. This research explores the feasibility of developing TinyML-based solutions for aquaculture monitoring, considering factors such as sensor selection, algorithm design, hardware constraints, and ethical considerations. By demonstrating the potential benefits of TinyML in aquaculture, our aim is to contribute to the development of more sustainable and efficient farming practices.","authors":["Achraf Hsain","Yahya Zaki","Othman Abaakil","Hibat-allah Bekkar","Yousra Chtouki"],"pdf_url":"","comment":"Published in IEEE GCAIoT 2024"},{"id":"http://arxiv.org/abs/2601.01033v1","updated":"2026-01-03T01:55:59Z","published":"2026-01-03T01:55:59Z","title":"System-Level Comparison of Multimodal and In-Band mmWave Sensing for Beam Prediction in 6G ISAC","summary":"Integrated sensing and communication (ISAC) can reduce beam-training overhead in mmWave vehicle-to-infrastructure (V2I) links by enabling in-band sensing-based beam prediction, while exteroceptive sensors can further enhance the prediction accuracy. This work develop a system-level framework that evaluates camera, LiDAR, radar, GPS, and in-band mmWave power, both individually and in multimodal fusion using the DeepSense-6G Scenario-33 dataset. A latency-aware neural network composed of lightweight convolutional (CNN) and multilayer-perceptron (MLP) encoders predict a 64-beam index. We assess performance using Top-k accuracy alongside spectral-efficiency (SE) gap, signal-to-noise-ratio (SNR) gap, rate loss, and end-to-end latency. Results show that the mmWave power vector is a strong standalone predictor, and fusing exteroceptive sensors with it preserves high performance: mmWave alone and mmWave+LiDAR/GPS/Radar achieve 98% Top-5 accuracy, while mmWave+camera achieves 94% Top-5 accuracy. The proposed framework establishes calibrated baselines for 6G ISAC-assisted beam prediction in V2I systems.","authors":["Abidemi Orimogunje","Hyunwoo Park","Igbafe Orikumhi","Sunwoo Kim","Dejan Vukobratovic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01023v1","updated":"2026-01-03T01:15:27Z","published":"2026-01-03T01:15:27Z","title":"Wireless Dataset Similarity: Measuring Distances in Supervised and Unsupervised Machine Learning","summary":"This paper introduces a task- and model-aware framework for measuring similarity between wireless datasets, enabling applications such as dataset selection/augmentation, simulation-to-real (sim2real) comparison, task-specific synthetic data generation, and informing decisions on model training/adaptation to new deployments. We evaluate candidate dataset distance metrics by how well they predict cross-dataset transferability: if two datasets have a small distance, a model trained on one should perform well on the other. We apply the framework on an unsupervised task, channel state information (CSI) compression, using autoencoders. Using metrics based on UMAP embeddings, combined with Wasserstein and Euclidean distances, we achieve Pearson correlations exceeding 0.85 between dataset distances and train-on-one/test-on-another task performance. We also apply the framework to a supervised beam prediction in the downlink using convolutional neural networks. For this task, we derive a label-aware distance by integrating supervised UMAP and penalties for dataset imbalance. Across both tasks, the resulting distances outperform traditional baselines and consistently exhibit stronger correlations with model transferability, supporting task-relevant comparisons between wireless datasets.","authors":["João Morais","Sadjad Alikhani","Akshay Malhotra","Shahab Hamidi-Rad","Ahmed Alkhateeb"],"pdf_url":"","comment":"resources available in: https://www.wi-lab.net/research/dataset-similarity"}],"Computational Geometry":[{"id":"http://arxiv.org/abs/2601.01132v1","updated":"2026-01-03T09:37:18Z","published":"2026-01-03T09:37:18Z","title":"Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion","summary":"We address the Diverse Traveling Salesman Problem (D-TSP), a bi-criteria optimization challenge that seeks a set of $k$ distinct TSP tours. The objective requires every selected tour to have a length at most $c|T^*|$ (where $|T^*|$ is the optimal tour length) while minimizing the average Jaccard similarity across all tour pairs. This formulation is crucial for applications requiring both high solution quality and fault tolerance, such as logistics planning, robotics pathfinding or strategic patrolling. Current methods are limited: traditional heuristics, such as the Niching Memetic Algorithm (NMA) or bi-criteria optimization, incur high computational complexity $O(n^3)$, while modern neural approaches (e.g., RF-MA3S) achieve limited diversity quality and rely on complex, external mechanisms.\n  To overcome these limitations, we propose a novel hybrid framework that decomposes D-TSP into two efficient steps. First, we utilize a simple Graph Pointer Network (GPN), augmented with an approximated sequence entropy loss, to efficiently sample a large, diverse pool of high-quality tours. This simple modification effectively controls the quality-diversity trade-off without complex external mechanisms. Second, we apply a greedy algorithm that yields a 2-approximation for the dispersion problem to select the final $k$ maximally diverse tours from the generated pool. Our results demonstrate state-of-the-art performance. On the Berlin instance, our model achieves an average Jaccard index of $0.015$, significantly outperforming NMA ($0.081$) and RF-MA3S. By leveraging GPU acceleration, our GPN structure achieves a near-linear empirical runtime growth of $O(n)$. While maintaining solution diversity comparable to complex bi-criteria algorithms, our approach is over 360 times faster on large-scale instances (783 cities), delivering high-quality TSP solutions with unprecedented efficiency and simplicity.","authors":["Hao-Hsung Yang","Ssu-Yuan Lo","Kuan-Lun Chen","Ching-Kai Wang"],"pdf_url":"","comment":null}],"Game Theory":[{"id":"http://arxiv.org/abs/2601.01279v1","updated":"2026-01-03T20:38:21Z","published":"2026-01-03T20:38:21Z","title":"LLM Collusion","summary":"We study how delegating pricing to large language models (LLMs) can facilitate collusion in a duopoly when both sellers rely on the same pre-trained model. The LLM is characterized by (i) a propensity parameter capturing its internal bias toward high-price recommendations and (ii) an output-fidelity parameter measuring how tightly outputs track that bias; the propensity evolves through retraining. We show that configuring LLMs for robustness and reproducibility can induce collusion via a phase transition: there exists a critical output-fidelity threshold that pins down long-run behavior. Below it, competitive pricing is the unique long-run outcome. Above it, the system is bistable, with competitive and collusive pricing both locally stable and the realized outcome determined by the model's initial preference. The collusive regime resembles tacit collusion: prices are elevated on average, yet occasional low-price recommendations provide plausible deniability. With perfect fidelity, full collusion emerges from any interior initial condition. For finite training batches of size $b$, infrequent retraining (driven by computational costs) further amplifies collusion: conditional on starting in the collusive basin, the probability of collusion approaches one as $b$ grows, since larger batches dampen stochastic fluctuations that might otherwise tip the system toward competition. The indeterminacy region shrinks at rate $O(1/\\sqrt{b})$.","authors":["Shengyu Cao","Ming Hu"],"pdf_url":"","comment":"44 pages"},{"id":"http://arxiv.org/abs/2601.01013v1","updated":"2026-01-03T00:29:58Z","published":"2026-01-03T00:29:58Z","title":"Carroll Mechanisms: Opportunities, Challenges, and Agenda","summary":"The purpose of Carroll Mechanisms is to facilitate autonomous group sensemaking and reasoned decisionmaking by incentivizing participants to be transparent about their reasoning process, and to empower participants who are known to be capable of changing their minds. We envision Carroll Mechanisms to be built on top of a networked combinatorial LMSR foundation and thus to inherit the desriable properties of market scoring rules and automated market-makers. While we have made great strides during Fall 2025 in building out this foundation, several significant questions remain and several major new questions have arisen as a result of this work. The purpose of this document is to document the theoretical foundation, frame these questions clearly, and propose a research plan to address the questions.","authors":["Philip N. Brown","Connor McCormick"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01012v1","updated":"2026-01-03T00:27:56Z","published":"2026-01-03T00:27:56Z","title":"Bad News for Couples: Tight Lower Bounds for Fair Division of Indivisible Items","summary":"We consider the problem of fairly allocating indivisible goods to couples, where each couple consists of two agents with distinct additive valuations. We show that there exist instances of allocating indivisible items to $n$ couples for which envy-freeness up to $Ω(\\sqrt{n})$ items cannot be guaranteed. This closes the gap by matching the upper bound of Manurangsi and Suksompong, which applies to arbitrary instances with $n$ agents in total. This result is somewhat surprising, as that upper bound was conjectured not to be tight for instances consisting only of small groups.","authors":["Max Dupré la Tour"],"pdf_url":"","comment":null}],"Discrete Mathematics":[{"id":"http://arxiv.org/abs/2509.06692v2","updated":"2026-01-03T10:17:24Z","published":"2025-09-08T13:46:50Z","title":"Bounds on Codes Correcting Transpositions of Consecutive Symbols","summary":"The problem of correcting transpositions (or swaps) of consecutive symbols in $ q $-ary strings is studied. Lower bounds on asymptotically achievable rates of codes correcting $ t = τn $ transpositions are derived. The first bound is obtained by analyzing the average cardinality of ``transposition balls'' and evaluating the appropriate version of the generalized Gilbert--Varshamov bound, while the second bound follows from a construction of codes correcting an arbitrary number of transpositions (i.e., zero-error codes). Asymptotic bounds on the cardinality of optimal codes correcting $ t = \\textrm{const} $ transpositions are also derived.","authors":["Mladen Kovačević","Keshav Goyal","Han Mao Kiah"],"pdf_url":"","comment":null}],"Dynamical Systems":[{"id":"http://arxiv.org/abs/2508.01257v2","updated":"2026-01-03T12:42:54Z","published":"2025-08-02T08:14:59Z","title":"PageRank Centrality in Directed Graphs with Bounded In-Degree","summary":"We study the computational complexity of locally estimating a node's PageRank centrality in a directed graph $G$. For any node $t$, its PageRank centrality $π(t)$ is defined as the probability that a random walk in $G$, starting from a uniformly chosen node, terminates at $t$, where each step terminates with a constant probability $α\\in(0,1)$.\n  To obtain a multiplicative $\\big(1\\pm O(1)\\big)$-approximation of $π(t)$ with probability $Ω(1)$, the previously best upper bound is $O(n^{1/2}\\min\\{ Δ_{in}^{1/2},Δ_{out}^{1/2},m^{1/4}\\})$ from [Wang, Wei, Wen, Yang, STOC '24], where $n$ and $m$ denote the number of nodes and edges in $G$, and $Δ_{in}$ and $Δ_{out}$ upper bound the in-degrees and out-degrees of $G$, respectively. Using a refinement of the proof in the same paper, we establish a lower bound of $Ω(n^{1/2}\\min\\{Δ_{in}^{1/2}/n^γ,Δ_{out}^{1/2}/n^γ,m^{1/4}\\})$, where $γ=\\frac{1}{2}(2\\max\\{\\log_{1/(1-α)}Δ_{in},1\\}-1)^{-1}$. As $γ$ only depends on $Δ_{in}$ and $n^γ=O(1)$ for $Δ_{in}=Ω\\left(n^{Ω(1)}\\right)$, the known upper bound is tight if we only parameterize the complexity by $n$, $m$, and $Δ_{out}$. However, there remains a gap of $Ω(n^γ)$ when considering $Δ_{in}$, and this gap is large when $Δ_{in}$ is small. In the extreme case where $Δ_{in}\\le1/(1-α)$, we have $γ=1/2$, leading to a gap of $Ω(n^{1/2})$ between the bounds $O(n^{1/2})$ and $Ω(1)$.\n  In this paper, we present a new algorithm that achieves the above lower bound (up to logarithmic factors). The algorithm assumes that $n$ and the bounds $Δ_{in}$ and $Δ_{out}$ are known in advance. Our key technique is a novel randomized backwards propagation process that only propagates selectively based on Monte Carlo estimated PageRank scores.","authors":["Mikkel Thorup","Hanzhi Wang","Zhewei Wei","Mingji Yang"],"pdf_url":"","comment":"full version of a SODA 2026 paper, 25 pages, 2 figures; v2: revised discussion of contributions and related work, added explanations on the exponent gamma"},{"id":"http://arxiv.org/abs/2505.07681v2","updated":"2026-01-03T10:47:14Z","published":"2025-05-12T15:47:08Z","title":"Verified Purely Functional Catenable Real-Time Deques","summary":"We present OCaml and Rocq implementations of Kaplan and Tarjan's purely functional, real-time catenable deques. The correctness of our Rocq implementation is machine-checked.","authors":["Jules Viennot","Arthur Wendling","Armaël Guéneau","François Pottier"],"pdf_url":"","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2601.01298v1","updated":"2026-01-03T23:11:21Z","published":"2026-01-03T23:11:21Z","title":"Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware","summary":"Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering \"System 2\" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.","authors":["Jorge L. Ruiz Williams"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01265v1","updated":"2026-01-03T19:24:00Z","published":"2026-01-03T19:24:00Z","title":"CounterPoint: Using Hardware Event Counters to Refute and Refine Microarchitectural Assumptions (Extended Version)","summary":"Hardware event counters offer the potential to reveal not only performance bottlenecks but also detailed microarchitectural behavior. In practice, this promise is undermined by their vague specifications, opaque designs, and multiplexing noise, making event counter data hard to interpret.\n  We introduce CounterPoint, a framework that tests user-specified microarchitectural models - expressed as $μ$path Decision Diagrams - for consistency with performance counter data. When mismatches occur, CounterPoint pinpoints plausible microarchitectural features that could explain them, using multi-dimensional counter confidence regions to mitigate multiplexing noise. We apply CounterPoint to the Haswell Memory Management Unit as a case study, shedding light on multiple undocumented and underdocumented microarchitectural behaviors. These include a load-store queue-side TLB prefetcher, merging page table walkers, abortable page table walks, and more.\n  Overall, CounterPoint helps experts reconcile noisy hardware performance counter measurements with their mental model of the microarchitecture - uncovering subtle, previously hidden hardware features along the way.","authors":["Nick Lindsay","Caroline Trippel","Anurag Khandelwal","Abhishek Bhattacharjee"],"pdf_url":"","comment":"This is an extended version of a paper which has been accepted to the 31st ACM International Conference on Architectural Support for Programming Languages and Operating Systems conference (ASPLOS, March 2026). 20 pages, 20 figures, 8 tables"},{"id":"http://arxiv.org/abs/2601.01158v1","updated":"2026-01-03T11:11:47Z","published":"2026-01-03T11:11:47Z","title":"A System Architecture for Low Latency Multiprogramming Quantum Computing","summary":"As quantum systems scale, Multiprogramming Quantum Computing (MPQC) becomes essential to improve device utilization and throughput. However, current MPQC pipelines rely on expensive online compilation to co-optimize concurrently running programs, because quantum executables are device-dependent, non-portable across qubit regions, and highly susceptible to noise and crosstalk. This online step dominates runtime and impedes low-latency deployments for practical, real-world workloads in the future, such as repeatedly invoked Quantum Neural Network (QNN) services.\n  We present FLAMENCO, a fidelity-aware multi-version compilation system that enables independent offline compilation and low-latency, high-fidelity multiprogramming at runtime. At the architecture level, FLAMENCO abstracts devices into compute units to drastically shrink the search space of region allocation. At compile time, it generates diverse executable versions for each program -- each bound to a distinct qubit region -- allowing dynamic region selection at runtime and overcoming non-portability. At runtime, FLAMENCO employs a streamlined orchestrator that leverages post-compilation fidelity metrics to avoid conflicts and mitigate crosstalk, achieving reliable co-execution without online co-optimization. Comprehensive evaluations against state-of-the-art MPQC baselines show that FLAMENCO removes online compilation overhead, achieves over 5$\\times$ runtime speedup, improves execution fidelity, and maintains high utilization as concurrency increases.","authors":["Yilun Zhao","Yu Chen","Kaiyan Chang","He Li","Bing Li","Yinhe Han","Ying Wang"],"pdf_url":"","comment":null}],"Mathematical Finance":[{"id":"http://arxiv.org/abs/2601.01269v1","updated":"2026-01-03T19:33:52Z","published":"2026-01-03T19:33:52Z","title":"Critical volatility threshold for log-normal to power-law transition","summary":"Random walk models with log-normal outcomes fit local market observations remarkably well. Yet interconnected or recursive structures - layered derivatives, leveraged positions, iterative funding rounds - periodically produce power-law distributed events. We show that the transition from log-normal to power-law dynamics requires only three conditions: randomness in the underlying process, rectification of payouts, and iterative feed-forward of expected values. Using an infinite option-on-option chain as an illustrative model, we derive a critical volatility threshold at $σ^* = \\sqrt{2π} \\approx 250.66\\%$ for the unconditional case. With selective survival - where participants require minimum returns to continue - the critical threshold drops discontinuously to $σ_{\\text{th}}^{*} = \\sqrt{π/2} \\approx 125.3\\%$, and can decrease further with higher survival thresholds. The resulting outcomes follow what we term the Critical Volatility ($V^*$) Distribution - a power-law whose exponent admits closed-form expression in terms of survival pressure and conditional expected growth. The result suggests that fat tails may be an emergent property of iterative log-normal processes with selection rather than an exogenous feature.","authors":["Valerii Kremnev"],"pdf_url":"","comment":"31 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.01250v1","updated":"2026-01-03T18:00:22Z","published":"2026-01-03T18:00:22Z","title":"European Options in Market Models with Multiple Defaults: the BSDE approach","summary":"We study non-linear Backward Stochastic Differential Equations (BSDEs) driven by a Brownian motion and p default martingales. The driver of the BSDE with multiple default jumps can take a generalized form involving an optional finite variation process. We first show existence and uniqueness. We then establish comparison and strict comparison results for these BSDEs, under a suitable assumption on the driver. In the case of a linear driver, we derive an explicit formula for the first component of the BSDE using an adjoint exponential semimartingale. The representation depends on whether the finite variation process is predictable or only optional. We apply our results to the problem of pricing and hedging a European option in a linear complete market with two defaultable assets and in a non-linear complete market with p defaultable assets. Two examples of the latter market model are provided: an example where the seller of the option is a large investor influencing the probability of default of a single asset and an example where the large seller's strategy affects the default probabilities of all p assets.","authors":["Miryana Grigorova","James Wheeldon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01189v1","updated":"2026-01-03T14:05:53Z","published":"2026-01-03T14:05:53Z","title":"Central limit theorem for a partially observed interacting system of Hawkes processes I: subcritical case","summary":"We consider a system of $N$ Hawkes processes and observe the actions of a subpopulation of size $K \\le N$ up to time $t$, where $K$ is large. The influence relationships between each pair of individuals are modeled by i.i.d.Bernoulli($p$) random variables, where $p \\in [0,1]$ is an unknown parameter. Each individual acts at a {\\it baseline} rate $μ> 0$ and, additionally, at an {\\it excitation} rate of the form $N^{-1} \\sum_{j=1}^{N} θ_{ij} \\int_{0}^{t} φ(t-s)\\,dZ_s^{j,N}$, which depends on the past actions of all individuals that influence it, scaled by $N^{-1}$ (i.e. the mean-field type), with the influence of older actions discounted through a memory kernel $φ\\colon \\mathbb{R}{+} \\to \\mathbb{R}{+}$. Here, $μ$ and $φ$ are treated as nuisance parameters. The aim of this paper is to establish a central limit theorem for the estimator of $p$ proposed in \\cite{D}, under the subcritical condition $Λp < 1$.","authors":["Chenguang Liu","Liping Xu","An Zhang"],"pdf_url":"","comment":"57 pages.This work overlaps with a portion of the content from arXiv:1906.08080"},{"id":"http://arxiv.org/abs/2411.04041v3","updated":"2026-01-03T11:12:14Z","published":"2024-11-06T16:40:55Z","title":"Volatility Parametrizations with Random Coefficients: Analytic Flexibility for Implied Volatility Surfaces","summary":"It is a market practice to express market-implied volatilities in some parametric form. The most popular parametrizations are based on or inspired by an underlying stochastic model, like the Heston model (SVI method) or the SABR model (SABR parametrization). Their popularity is often driven by a closed-form representation enabling efficient calibration. However, these representations indirectly impose a model-specific volatility structure on observable market quotes. When the market's volatility does not follow the parametric model regime, the calibration procedure will fail or lead to extreme parameters, indicating inconsistency. This article addresses this critical limitation - we propose an arbitrage-free framework for letting the parameters from the parametric implied volatility formula be random. The method enhances the existing parametrizations and enables a significant widening of the spectrum of permissible shapes of implied volatilities while preserving analyticity and, therefore, computation efficiency. We demonstrate the effectiveness of the novel method on real data from short-term index and equity options, where the standard parametrizations fail to capture market dynamics. Our results show that the proposed method is particularly powerful in modeling the implied volatility curves of short expiry options preceding an earnings announcement, when the risk-neutral probability density function exhibits a bimodal form.","authors":["Nicola F. Zaugg","Leonardo Perotti","Lech A. Grzelak"],"pdf_url":"","comment":null}]},"2026-01-07T00:00:00Z":{"Optimization and Control":[{"id":"http://arxiv.org/abs/2505.23210v2","updated":"2026-01-07T18:35:23Z","published":"2025-05-29T07:52:40Z","title":"Latent Representations for Control Design with Provable Stability and Safety Guarantees","summary":"We initiate a formal study on the use of low-dimensional latent representations of dynamical systems for verifiable control synthesis. Our main goal is to enable the application of verification techniques -- such as Lyapunov or barrier functions -- that might otherwise be computationally prohibitive when applied directly to the full state representation. Towards this goal, we first provide dynamics-aware approximate conjugacy conditions which formalize the notion of reconstruction error necessary for systems analysis. We then utilize our conjugacy conditions to transfer the stability and invariance guarantees of a latent certificate function (e.g., a Lyapunov or barrier function) for a latent space controller back to the original system. Importantly, our analysis contains several important implications for learning latent spaces and dynamics, by highlighting the necessary geometric properties which need to be preserved by the latent space, in addition to providing concrete loss functions for dynamics reconstruction that are directly related to control design. We conclude by demonstrating the applicability of our theory to two case studies: (1) stabilization of a cartpole system, and (2) collision avoidance for a two vehicle system.","authors":["Paul Lutkus","Kaiyuan Wang","Lars Lindemann","Stephen Tu"],"pdf_url":"","comment":"14 pages, 3 figures. Presented at CDC 2025. Expanded version"},{"id":"http://arxiv.org/abs/2412.11850v3","updated":"2026-01-07T18:04:52Z","published":"2024-12-16T15:11:02Z","title":"Causal Invariance Learning via Efficient Nonconvex Optimization","summary":"Identifying the causal relationship among variables from observational data is an important yet challenging task. This work focuses on identifying the direct causes of an outcome and estimating their magnitude, i.e., learning the causal outcome model. Data from multiple environments provide valuable opportunities to uncover causality by exploiting the invariance principle that the causal outcome model holds across heterogeneous environments. Based on the invariance principle, we propose the Negative Weighted Distributionally Robust Optimization (NegDRO) framework to learn an invariant prediction model. NegDRO minimizes the worst-case combination of risks across multiple environments and enforces invariance by allowing potential negative weights. Under the additive interventions regime, we establish three major contributions: (i) On the statistical side, we provide sufficient and nearly necessary identification conditions under which the invariant prediction model coincides with the causal outcome model; (ii) On the optimization side, despite the nonconvexity of NegDRO, we establish its benign optimization landscape, where all stationary points lie close to the true causal outcome model; (iii) On the computational side, we develop a gradient-based algorithm that provably converges to the causal outcome model, with non-asymptotic convergence rates in both sample size and gradient-descent iterations. In particular, our method avoids exhaustive combinatorial searches over exponentially many subsets of covariates found in the literature, ensuring scalability even when the dimension of the covariates is large. To our knowledge, this is the first causal invariance learning method that finds the approximate global optimality for a nonconvex optimization problem efficiently.","authors":["Zhenyu Wang","Yifan Hu","Peter Bühlmann","Zijian Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.02970v2","updated":"2026-01-07T17:53:36Z","published":"2025-05-05T18:54:23Z","title":"A Fully Data-Driven Value Iteration for Stochastic LQR: Convergence, Robustness and Stability","summary":"Unlike traditional model-based reinforcement learning approaches that estimate system parameters from data, non-model-based data-driven control learns the optimal policy directly from input-state data without any intermediate model identification. Although this direct reinforcement learning approach offers increased adaptability and resilience to model misspecification, its reliance on raw data leaves it vulnerable to system noise and disturbances that may undermine convergence, robustness, and stability. In this article, we establish the convergence, robustness, and stability of value iteration (VI) for data-driven control of stochastic linear quadratic (LQ) systems in discrete-time with entirely unknown dynamics and cost. Our contributions are three-fold. First, we prove that VI is globally exponentially stable for any positive semidefinite initial value matrix in noise-free settings, thereby significantly relaxing restrictive assumptions on initial value functions in existing literature. Second, we extend our analysis to settings with external disturbances, proving that VI maintains small-disturbance input-to-state stability (ISS) and converges within a small neighborhood of the optimal solution when disturbances are sufficiently small. Third, we propose a new non-model-based robust adaptive dynamic programming (ADP) algorithm for adaptive optimal controller design, which, unlike existing procedures, requires no prior knowledge of an initial admissible control policy. Numerical experiments on a ``data center cooling'' problem demonstrate the convergence and stability of the algorithm compared to established methods, highlighting its robustness and adaptability for data-driven control in noisy environments. Finally, we apply the method to dynamic portfolio allocation, demonstrating its practical relevance outside traditional control tasks.","authors":["Leilei Cui","Zhong-Ping Jiang","Petter N. Kolm","Grégoire G. Macqueron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.12279v4","updated":"2026-01-07T17:42:40Z","published":"2025-01-21T16:50:33Z","title":"Spatial exponential decay of perturbations in optimal control of general evolution equations","summary":"We analyze the robustness of optimally controlled evolution equations with respect to spatially localized perturbations. We prove that if the involved operators are domain-uniformly stabilizable and detectable, then these localized perturbations only have a local effect on the optimal solution. We characterize this domain-uniform stabilizability and detectability for the transport equation with constant transport velocity, showing that even for unitary semigroups, optimality implies exponential damping. We extend this result to the case of a space-dependent transport velocity. Finally we leverage the results for the transport equation to characterize domain-uniform stabilizability of the wave equation. Numerical examples in one space dimension complement the theoretical results.","authors":["Simone Göttlich","Benedikt Oppeneiger","Manuel Schaller","Karl Worthmann"],"pdf_url":"","comment":"53 pages, 5 figures"},{"id":"http://arxiv.org/abs/2404.17789v6","updated":"2026-01-07T17:37:44Z","published":"2024-04-27T06:06:41Z","title":"BiLO: Bilevel Local Operator Learning for PDE Inverse Problems","summary":"We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. We provide a theoretical analysis that justifies our approach. Through extensive experiments over multiple PDE systems, we demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to the soft PDE constraints in many existing methods.","authors":["Ray Zirui Zhang","Christopher E. Miles","Xiaohui Xie","John S. Lowengrub"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04120v1","updated":"2026-01-07T17:30:42Z","published":"2026-01-07T17:30:42Z","title":"A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems","summary":"Optimal control of obstacle problems arises in a wide range of applications and is computationally challenging due to its nonsmoothness, nonlinearity, and bilevel structure. Classical numerical approaches rely on mesh-based discretization and typically require solving a sequence of costly subproblems. In this work, we propose a single-loop bilevel deep learning method, which is mesh-free, scalable to high-dimensional and complex domains, and avoids repeated solution of discretized subproblems. The method employs constraint-embedding neural networks to approximate the state and control and preserves the bilevel structure. To train the neural networks efficiently, we propose a Single-Loop Stochastic First-Order Bilevel Algorithm (S2-FOBA), which eliminates nested optimization and does not rely on restrictive lower-level uniqueness assumptions. We analyze the convergence behavior of S2-FOBA under mild assumptions. Numerical experiments on benchmark examples, including distributed and obstacle control problems with regular and irregular obstacles on complex domains, demonstrate that the proposed method achieves satisfactory accuracy while reducing computational cost compared to classical numerical methods.","authors":["Yongcun Song","Shangzhi Zeng","Jin Zhang","Lvgang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.14506v4","updated":"2026-01-07T16:41:10Z","published":"2024-12-19T04:06:10Z","title":"Delayed Feedback in Online Non-Convex Optimization: A Non-Stationary Approach with Applications","summary":"We study non-convex delayed-noise online optimization problems by evaluating dynamic regret in the non-stationary setting when the loss functions are quasar-convex. In particular, we consider scenarios involving quasar-convex functions either with a Lipschitz gradient or weakly smooth and, for each case, we ensure bounded dynamic regret in terms of cumulative path variation achieving sub-linear regret rates. Furthermore, we illustrate the flexibility of our framework by applying it to both theoretical settings such as zeroth-order (bandit) and also to practical applications with quadratic fractional functions. Moreover, we provide new examples of non-convex functions that are quasar-convex by proving that the class of differentiable strongly quasiconvex functions (Polyak 1966) are strongly quasar-convex on convex compact sets. Finally, several numerical experiments validate our theoretical findings, illustrating the effectiveness of our approach.","authors":["Felipe Lara","Cristian Vega"],"pdf_url":"","comment":"31 Pages, 7 Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2601.02347v2","updated":"2026-01-07T15:53:40Z","published":"2026-01-05T18:44:27Z","title":"Solving Matrix Games with Near-Optimal Matvec Complexity","summary":"We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ (or zero-sum) games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games (encompassing hard-margin SVMs), where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In both settings our results are nearly-optimal as they match lower bounds of [KS '25] up to polylogarithmic factors.","authors":["Ishani Karmarkar","Liam O'Carroll","Aaron Sidford"],"pdf_url":"","comment":"v2: A few updates to the title, abstract, and intro to reflect the near optimality of our results for $\\ell_1$-$\\ell_1$ games in light of arXiv:2412.06990 v3"},{"id":"http://arxiv.org/abs/2408.01175v3","updated":"2026-01-07T15:28:58Z","published":"2024-08-02T10:54:21Z","title":"Common Noise by Random Measures: Constructing Mean-Field Equilibria for Competitive Investment and Hedging","summary":"We construct Nash-equilibria in mean-field portfolio games of optimal investment and hedging under relative performance concerns with exponential (CARA) utility preferences. Common noise dynamics are modeled by integer-valued random measures, for instance Poisson random measures, in addition to Brownian motions. Agents differ in individual risk aversions, competition weights, and initial capital endowments, while their contingent claim liabilities depend on both common and idiosyncratic risk factors. Mean-field equilibria are characterized by solutions to McKean-Vlasov backward stochastic differential equations with jumps, for which we prove existence and uniqueness of solutions, without assuming mean field interaction to be small. Moreover, we show how the equilibrium can be constructed from the optimal strategy of a single-agent optimization problem (without mean-field interaction) via an appropriate projection. Using successive changes of measure, our derivation provides a decomposition of the equilibrium strategy into three components with clear interpretations. Finally, we show how a limiting mean-field game of quadratic (instead of utility-based) hedging with relative performance concerns arises for vanishing risk aversion.","authors":["Dirk Becherer","Stefanie Hesse"],"pdf_url":"","comment":"The first version (arXiv:2408.01175v1) of this preprint has been published under the slightly different title \"Common Noise by Random Measures: Mean-Field Equilibria for Competitive Investment and Hedging\"; the present ver3 features several new results relative to ver1 and fixes hyperref-related compilation errors present in ver2"},{"id":"http://arxiv.org/abs/2512.06119v4","updated":"2026-01-07T15:27:13Z","published":"2025-12-05T19:55:27Z","title":"Revisiting Johnson's rule for minimizing makespan in the Two-Machine Flow Shop scheduling problem","summary":"We consider Johnson's rule for minimizing the makespan in the two-machine flow shop problem. Although its worst-case time complexity is O(n log n), we show that it is possible to detect in linear time whether a full sorting of jobs can be avoided and an optimal solution can be computed in O(n) time. A probabilistic analysis indicates that linear time complexity holds with high probability under uniformly distributed processing times, a result further supported by extensive computational experimentation.","authors":["Federico Della Croce","Quentin Schau"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04003v1","updated":"2026-01-07T15:13:43Z","published":"2026-01-07T15:13:43Z","title":"Continuation methods for higher-order topology optimization","summary":"We aim to solve a topology optimization problem where the distribution of material in the design domain is represented by a density function. To obtain candidates for local minima, we want to solve the first order optimality system via Newton's method. This requires the initial guess to be sufficiently close to the a priori unknown solution. Introducing a stepsize rule often allows for less restrictions on the initial guess while still preserving convergence. In topology optimization one typically encounters nonconvex problems where this approach might fail. We therefore opt for a homotopy (continuation) approach which is based on solving a sequence of parametrized problems to approach the solution of the original problem. In the density based framework the values of the design variable are constrained by 0 from below and 1 from above. Coupling the homotopy method with a barrier strategy enforces these constraints to be satisified. The numerical results for a PDE-constrained compliance minimization problem demonstrate that this combined approach maintains feasibility of the density function and converges to a (candidate for a) locally optimal design without a priori knowledge of the solution.","authors":["P. Gangl","M. Winkler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.26428v2","updated":"2026-01-07T14:58:23Z","published":"2025-09-30T15:48:56Z","title":"Real-time Velocity Profile Optimization for Time-Optimal Maneuvering with Generic Acceleration Constraints","summary":"The computation of time-optimal velocity profiles along prescribed paths, subject to generic acceleration constraints, is a crucial problem in robot trajectory planning, with particular relevance to autonomous racing. However, the existing methods either support arbitrary acceleration constraints at high computational cost or use conservative box constraints for computational efficiency. We propose FBGA, a new \\underline{F}orward-\\underline{B}ackward algorithm with \\underline{G}eneric \\underline{A}cceleration constraints, which achieves both high accuracy and low computation time. FBGA operates forward and backward passes to maximize the velocity profile in short, discretized path segments, while satisfying user-defined performance limits. Tested on five racetracks and two vehicle classes, FBGA handles complex, non-convex acceleration constraints with custom formulations. Its maneuvers and lap times closely match optimal control baselines (within $0.11\\%$-$0.36\\%$), while being up to three orders of magnitude faster. FBGA maintains high accuracy even with coarse discretization, making it well-suited for online multi-query trajectory planning. Our open-source \\texttt{C++} implementation is available at: https://anonymous.4open.science/r/FB_public_RAL.","authors":["Mattia Piazza","Mattia Piccinini","Sebastiano Taddei","Francesco Biral","Enrico Bertolazzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.21231v3","updated":"2026-01-07T14:53:39Z","published":"2025-06-26T13:21:20Z","title":"Block Coordinate Descent Network Simplex Methods for Optimal Transport","summary":"We propose the Block Coordinate Descent Network Simplex (BCDNS) method for solving large-scale discrete Optimal Transport (OT) problems. BCDNS integrates the Network Simplex (NS) algorithm with a block coordinate descent (BCD) strategy, decomposing the full problem into smaller subproblems per iteration and reusing basis variables to ensure feasibility. We prove that BCDNS terminates in a finite number of iterations with an exact optimal solution, and we characterize its per-iteration complexity as O(s N), where s is a user-defined parameter in (0,1) and N is the total number of variables. Numerical experiments demonstrate that BCDNS matches the classical NS method in solution accuracy, reduces memory footprint compared to the Sinkhorn algorithm, achieves speed-ups of up to tens of times over the classical NS method, and exhibits runtime comparable to a high-precision Sinkhorn implementation.","authors":["Lingrui Li","Nobuo Yamashita"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03967v1","updated":"2026-01-07T14:30:45Z","published":"2026-01-07T14:30:45Z","title":"On the importance of smoothness, interface resolution and numerical sensitivities in shape and topological sensitivity analysis","summary":"In this paper we investigate the influence of the discretization of PDE constraints on shape and topological derivatives. To this end, we study a tracking-type functional and a two-material Poisson problem in one spatial dimension. We consider the discretization by a standard method and an enriched method. In the standard method we use splines of degree $p$ such that we can control the smoothness of the basis functions easily, but do not take any interface location into consideration. This includes for p=1 the usual hat basis functions. In the enriched method we additionally capture the interface locations in the ansatz space by enrichment functions. For both discretization methods shape and topological sensitivity analysis is performed. It turns out that the regularity of the shape derivative depends on the regularity of the basis functions. Furthermore, for point-wise convergence of the shape derivative the interface has to be considered in the ansatz space. For the topological derivative we show that only the enriched method converges.","authors":["M. H. Gfrerer","P. Gangl"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.07254v3","updated":"2026-01-07T14:14:05Z","published":"2025-08-10T09:14:04Z","title":"Fast Convergence of Multiobjective Inertial Gradient Systems with Time Scaling","summary":"In multiobjective optimization, inertial gradient systems accelerate convergence toward weakly Pareto optimal solutions. To achieve even faster convergence, we introduce a multiobjective inertial gradient system with time scaling (MITS), formulated as a second-order differential equation comprising an inertial term, asymptotically vanishing damping, and a time-scaled gradient term. We first establish the existence of solution trajectories for MITS. Through Lyapunov analysis, we show that with suitable parameters, the trajectory attains a convergence rate of $O(1/t^{2}β(t))$ with respect to a merit function, where $β(t)$ is a time-scaling function. Specifically, choosing $β(t)=t^{p}$ for $0\\leq p<α-3$ yields the rate $O(1/t^{2+p})$, enabling arbitrarily fast sublinear convergence by tuning $p$. We also prove that the trajectory converges to a weakly Pareto optimal solution. Furthermore, an implicit discretization of MITS leads to a multiobjective inertial proximal point method (MIPP), whose iterates share the $O(1/k^{2}β_{k})$ rate and converge to a weakly Pareto optimum under appropriate conditions. Numerical experiments support the theoretical findings.","authors":["Yingdong Yin"],"pdf_url":"","comment":"arXiv admin note: text overlap with arXiv:2508.01775, arXiv:2507.20183"},{"id":"http://arxiv.org/abs/2601.03946v1","updated":"2026-01-07T14:02:25Z","published":"2026-01-07T14:02:25Z","title":"Provably Finding a Hidden Dense Submatrix among Many Planted Dense Submatrices via Convex Programming","summary":"We consider the densest submatrix problem, which seeks the submatrix of fixed size of a given binary matrix that contains the most nonzero entries. This problem is a natural generalization of fundamental problems in combinatorial optimization, e.g., the densest subgraph, maximum clique, and maximum edge biclique problems, and has wide application the study of complex networks. Much recent research has focused on the development of sufficient conditions for exact solution of the densest submatrix problem via convex relaxation. The vast majority of these sufficient conditions establish identification of the densest submatrix within a graph containing exactly one large dense submatrix hidden by noise. The assumptions of these underlying models are not observed in real-world networks, where the data may correspond to a matrix containing many dense submatrices of varying sizes.\n  We extend and generalize these results to the more realistic setting where the input matrix may contain \\emph{many} large dense subgraphs. Specifically, we establish sufficient conditions under which we can expect to solve the densest submatrix problem in polynomial time for random input matrices sampled from a generalization of the stochastic block model. Moreover, we also provide sufficient conditions for perfect recovery under a deterministic adversarial. Numerical experiments involving randomly generated problem instances and real-world collaboration and communication networks are used empirically to verify the theoretical phase-transitions to perfect recovery given by these sufficient conditions.","authors":["Valentine Olanubi","Phineas Agar","Brendan Ames"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03931v1","updated":"2026-01-07T13:50:07Z","published":"2026-01-07T13:50:07Z","title":"Constrained dynamics for searching saddle points on general Riemannian manifolds","summary":"Finding constrained saddle points on Riemannian manifolds is significant for analyzing energy landscapes arising in physics and chemistry. Existing works have been limited to special manifolds that admit global regular level-set representations, excluding applications such as electronic excited-state calculations. In this paper, we develop a constrained saddle dynamics applicable to smooth functions on general Riemannian manifolds. Our dynamics is formulated compactly over the Grassmann bundle of the tangent bundle. By analyzing the Grassmann bundle geometry, we achieve universality via incorporating the second fundamental form, which captures variations of tangent spaces along the trajectory. We rigorously establish the local linear stability of the dynamics and the local linear convergence of the resulting algorithms. Remarkably, our analysis provides the first convergence guarantees for discretized saddle-search algorithms in manifold settings. Moreover, by respecting the intrinsic quotient structure, we remove unnecessary nondegeneracy assumptions on the eigenvalues of the Riemannian Hessian that are present in existing works. We also point out that locating saddle points can be more ill-conditioning than finding local minimizers, and requires using nonredundant parametrizations. Finally, numerical experiments on linear eigenvalue problems and electronic excited-state calculations showcase the effectiveness of the proposed algorithms and corroborate the established local theory.","authors":["Yukuan Hu","Laura Grazioli"],"pdf_url":"","comment":"35 pages, 6 figures, 2 tables. All comments are welcome"},{"id":"http://arxiv.org/abs/2601.03906v1","updated":"2026-01-07T13:16:33Z","published":"2026-01-07T13:16:33Z","title":"Exact Continuous Reformulations of Logic Constraints in Nonlinear Optimization and Optimal Control Problems","summary":"Many nonlinear optimal control and optimization problems involve constraints that combine continuous dynamics with discrete logic conditions. Standard approaches typically rely on mixed-integer programming, which introduces scalability challenges and requires specialized solvers. This paper presents an exact reformulation of broad classes of logical constraints as binary-variable-free expressions whose differentiability properties coincide with those of the underlying predicates, enabling their direct integration into nonlinear programming models. Our approach rewrites arbitrary logical propositions into conjunctive normal form, converts them into equivalent max--min constraints, and applies a smoothing procedure that preserves the exact feasible set. The method is evaluated on two benchmark problems, a quadrotor trajectory optimization with obstacle avoidance and a hybrid two-tank system with temporal logic constraints, and is shown to obtain optimal solutions more consistently and efficiently than existing binary variable elimination techniques.","authors":["Jad Wehbeh","Eric C. Kerrigan"],"pdf_url":"","comment":"8 pages, 11 figures, submitted for publication to Automatica"},{"id":"http://arxiv.org/abs/2511.18429v2","updated":"2026-01-07T10:20:29Z","published":"2025-11-23T12:50:25Z","title":"Robust Differential Evolution via Nonlinear Population Size Reduction and Adaptive Restart: The ARRDE Algorithm","summary":"This study is motivated by a robustness issue in numerical optimization of bound-constrained problems: many algorithms that perform well on a particular benchmark suite, such as the IEEE CEC2017 problems, struggle to maintain the same level of performance when applied to other suites that differ in dimensionality, landscape complexity, or the maximum number of function evaluations ($N_{\\text{max}}$). To address this, we propose the Adaptive Restart-Refine Differential Evolution (ARRDE) algorithm, a new variant of Differential Evolution (DE). ARRDE builds upon the LSHADE algorithm, incorporates key mechanisms from jSO, and introduces a nonlinear population-size reduction strategy combined with an adaptive restart-refine mechanism.\n  We evaluate ARRDE on five benchmark suites (CEC2011, CEC2017, CEC2019, CEC2020, and CEC2022) which, to the best of our knowledge, constitutes the most extensive experimental study to date in the context of algorithmic comparison, as most prior works consider only one or two suites. This broad evaluation enables a rigorous assessment of generalization across markedly different problem characteristics. To further support fair cross-suite comparisons, we also introduce a bounded accuracy-based scoring metric derived from relative error. Using both rank-based and accuracy-based metrics, and comparing against algorithms that perform strongly on CEC2017 (e.g., jSO and LSHADE-cnEpSin) as well as those that excel on CEC2020 (e.g., j2020 and NLSHADE-RSP), ARRDE consistently demonstrates top-tier performance, ranking first across all benchmark suites considered. These results highlight ARRDE's robustness and its superior generalization capability.","authors":["Khoirul Faiq Muzakka","Ahsani Hafizhu Shali","Haris Suhendar","Sören Möller","Martin Finsterbusch"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03759v1","updated":"2026-01-07T09:48:10Z","published":"2026-01-07T09:48:10Z","title":"Connecting Max-entropy With Computational Geometry, LP And SDP","summary":"We consider the well-known max-(relative) entropy problem $Θ$(y) = infQ$\\ll$P DKL(Q P ) with Kullback-Leibler divergence on a domain $Ω$ $\\subset$ R d , and with ''moment'' constraints h dQ = y, y $\\in$ R m . We show that when m $\\le$ d, $Θ$ is the Cram{é}r transform of a function v that solves a simply related computational geometry problem. Also, and remarkably, to the canonical LP: min x$\\ge$0 {c T x\\,: A x = y}, with A $\\in$ R mxd , one may associate a max-entropy problem with a suitably chosen reference measure P on R d + and linear mapping h(x) = Ax, such that its associated perspective function $ε$ $Θ$(y/$ε$) is the optimal value of the log-barrier formulation (with parameter $ε$) of the dual LP (and so it converges to the LP optimal value as $ε$ $\\rightarrow$ 0). An analogous result also holds for the canonical SDP: min X 0 { C, X\\,: A(X) = y }.","authors":["Jean B Lasserre"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03754v1","updated":"2026-01-07T09:43:51Z","published":"2026-01-07T09:43:51Z","title":"GPU-Accelerated Cholesky Factorization of Block Tridiagonal Matrices","summary":"This paper presents a GPU-accelerated framework for solving block tridiagonal linear systems that arise naturally in numerous real-time applications across engineering and scientific computing. Through a multi-stage permutation strategy based on nested dissection, we reduce the computational complexity from $\\mathcal{O}(Nn^3)$ for sequential Cholesky factorization to $\\mathcal{O}(\\log_2(N)n^3)$ when sufficient parallel resources are available, where $n$ is the block size and $N$ is the number of blocks. The algorithm is implemented using NVIDIA's Warp library and CUDA to exploit parallelism at multiple levels within the factorization algorithm. Our implementation achieves speedups exceeding 100x compared to the sparse solver QDLDL, 25x compared to a highly optimized CPU implementation using BLASFEO, and more than 2x compared to NVIDIA's CUDSS library. The logarithmic scaling with horizon length makes this approach particularly attractive for long-horizon problems in real-time applications. Comprehensive numerical experiments on NVIDIA GPUs demonstrate the practical effectiveness across different problem sizes and precisions. The framework provides a foundation for GPU-accelerated optimization solvers in robotics, autonomous systems, and other domains requiring repeated solution of structured linear systems. The implementation is open-source and available at https://github.com/PREDICT-EPFL/socu.","authors":["Roland Schwan","Daniel Kuhn","Colin N. Jones"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03747v1","updated":"2026-01-07T09:37:25Z","published":"2026-01-07T09:37:25Z","title":"Matrix Riccati BSDEs with singular terminal condition and stochastic LQ control with linear terminal constraint","summary":"We analyze a class of multidimensional linear-quadratic stochastic control problems with random coefficients, motivated by multi-asset optimal trade execution. The problems feature non-diffusive controlled state dynamics and a terminal constraint that restricts the terminal state to a prescribed random linear subspace. We derive the associated Riccati backward stochastic differential equation (BSDE) and identify a suitable formalization of its singular terminal condition. Via a penalization approach, we establish existence of a minimal supersolution of the Riccati BSDE and use it to characterize both the value function and the optimal control. We analyze the asymptotic behavior of the supersolution near terminal time and discuss special cases where closed-form solutions can be obtained.","authors":["Julia Ackermann","Thomas Kruse","Petr Petrov","Alexandre Popier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.05695v4","updated":"2026-01-07T08:26:24Z","published":"2025-04-08T05:37:38Z","title":"Architecture independent generalization bounds for overparametrized deep ReLU networks","summary":"We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove a uniform generalization bound that is independent of the network architecture. We perform computational experiments of our theoretical results with MNIST, and obtain agreement with the true test error within a 22 % margin on average.","authors":["Anandatheertha Bapu","Thomas Chen","Chun-Kai Kevin Chien","Patricia Muñoz Ewald","Andrew G. Moore"],"pdf_url":"","comment":"AMS Latex, 18 pages. Significantly updated, A. Bapu included as coauthor, Section 3 added"},{"id":"http://arxiv.org/abs/2410.12404v3","updated":"2026-01-07T07:24:51Z","published":"2024-10-16T09:35:17Z","title":"A Class of Degenerate Mean Field Games, Associated FBSDEs and Master Equations","summary":"In this paper, we study a class of degenerate mean field games (MFGs) with state-distribution dependent and unbounded functional diffusion coefficients. With a probabilistic method, we study the well-posedness of the forward-backward stochastic differential equations (FBSDEs) associated with the MFG and arising from the maximum principle, and estimate the corresponding Jacobian and Hessian flows. We further establish the classical regularity of the value functional $V$; in particular, we show that when the cost function is $C^3$ in the spatial and control variables and $C^2$ in the distribution argument, then the value functional is $C^1$ in time and $C^2$ in the spatial and distribution variables. As a consequence, the value functional $V$ is the unique classical solution of the degenerate MFG master equation.","authors":["Alain Bensoussan","Ziyu Huang","Shanjian Tang","Sheung Chi Phillip Yam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03654v1","updated":"2026-01-07T07:05:34Z","published":"2026-01-07T07:05:34Z","title":"Quantum Classical Ridgelet Neural Network For Time Series Model","summary":"In this study, we present a quantum computing method that incorporates ridglet transforms into the quantum processing pipelines for time series data. Here, the Ridgelet neural network is integrated with a single-qubit quantum computing method, which improves feature extraction and forecasting capabilities. Furthermore, experimental results using financial time series data demonstrate the superior performance of our model compared to existing models.","authors":["Bahadur Yadav","Sanjay Kumar Mohanty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.22342v2","updated":"2026-01-07T06:51:38Z","published":"2025-10-25T15:56:44Z","title":"An Interval Hessian-based line-search method for unconstrained nonconvex optimization problems","summary":"Second-order Newton-type algorithms that leverage the exact Hessian or its approximation are central to solve nonlinear optimization problems. However, their applications in solving large-scale nonconvex problems are hindered by three primary challenges: (1) the high computational cost associated with Hessian evaluations, (2) its inversion, and (3) ensuring descent direction at points where the Hessian becomes indefinite. We propose INTHOP, an interval Hessian-based optimization algorithm for nonconvex problems to deal with these primary challenges. The proposed search direction is based on approximating the original Hessian matrix by a positive definite matrix. The novelty of the proposed method is that the proposed search direction is guaranteed to be descent and requires approximation of Hessian and its inversion only at specific iterations. We prove that the difference between the calculated approximate and exact Hessian is bounded within an interval. Accordingly, the approximate Hessian matrix is reused if the iterates are in that chosen interval while computing the gradients at each iteration. We develop various algorithm variants based on the interval size updating methods and minimum eigenvalue computation methods. We also prove the global convergence of the proposed algorithm. Further, we apply the algorithm to an extensive set of test problems and compare its performance with the existing methods such as steepest descent, quasi-Newton, and Newton method. We show empirically that the proposed method solves more problems in fewer function and gradient evaluations than steepest descent and the quasi-Newton method. While in the comparison to the Newton method, we illustrate that for nonconvex optimization problems, we require substantially less $O(n^3)$ operations.","authors":["Krishan Kumar","Ashutosh Sharma","Gauransh Dingwani","Nikhil Gupta","Vaishnavi Gupta","Ishan Bajaj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.10372v2","updated":"2026-01-07T06:03:38Z","published":"2025-11-13T14:49:32Z","title":"Halpern Acceleration of the Inexact Proximal Point Method of Rockafellar","summary":"This paper investigates a Halpern acceleration of the inexact proximal point method for solving maximal monotone inclusion problems in Hilbert spaces. The proposed Halpern inexact proximal point method (HiPPM) is shown to be globally convergent, and a unified framework is developed to analyze its worst-case convergence behavior. Under mild conditions on the inexactness tolerances, HiPPM achieves an $\\mathcal{O}(1/k^{2})$ convergence rate in terms of the squared fixed-point residual. Moreover, under additional well-studied regularity conditions, the method attains a fast linear convergence rate. Building on this framework, we further extend the Halpern acceleration to the inexact augmented Lagrangian method for constrained convex optimization. In the spirit of Rockafellar's classical results, the resulting accelerated inexact augmented Lagrangian method inherits the convergence rate and iteration complexity guarantees of HiPPM. Numerical experiments are provided to support the theoretical findings.","authors":["Liwei Zhang","Fanli Zhuang","Ning Zhang"],"pdf_url":"","comment":"29pages"},{"id":"http://arxiv.org/abs/2312.01668v2","updated":"2026-01-07T05:37:34Z","published":"2023-12-04T06:36:27Z","title":"Optimal dividend payout with path-dependent drawdown constraint","summary":"This paper studies an optimal dividend problem with a drawdown constraint in a Brownian motion model, requiring the dividend payout rate to remain above a fixed proportion of its historical maximum. This leads to a path-dependent stochastic control problem, as the admissible control depends on its own past values. The associated Hamilton-Jacobi-Bellman (HJB) equation is a novel two-dimensional variational inequality with a gradient constraint, a type of problem previously only analyzed in the literature using viscosity solution techniques. In contrast, this paper employs delicate PDE methods to establish the existence of a strong solution. This stronger regularity allows us to explicitly characterize an optimal feedback control strategy, expressed in terms of two free boundaries and the running maximum surplus process. Furthermore, we derive key properties of the value function and the free boundaries, including boundedness and continuity. Numerical examples are provided to verify the theoretical results and to offer new financial insights.","authors":["Chonghu Guan","Jiacheng Fan","Zuo Quan Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.21341v2","updated":"2026-01-07T04:49:26Z","published":"2025-04-30T06:02:07Z","title":"Model-Free Design and Analysis of 2DOF PI Controller for Noisy LTI Systems","summary":"Set-point tracking for systems with unknown model parameters is a fundamental problem in control, and two-degree-of-freedom (2DOF) Proportional-Integral (PI) controllers -- consisting of a feedforward controller and PI controller -- are widely employed for this task. In this paper, we propose a model-free design of 2DOF PI controllers, establish its theoretical properties, and compare them with a model-based method from both theoretical and numerical perspectives. For the feedforward design, we extend an existing model-free algorithm to systems subject to Gaussian process and measurement noises. We derive a nonasymptotic lower bound on the required control input/output data length and characterize the resulting estimation error. For PI gain tuning, we formulate a constrained optimization problem and establish sample complexity of a zeroth-order optimization method. Moreover, we quantify how inaccuracies in the feedforward design propagate to the performance of the PI controller, highlighting an interaction that has not been examined in prior work. We further provide a theoretical comparison between the proposed method and the model-based method. In particular, for PI gain tuning, the proposed method is computationally more efficient by avoiding explicit gradient computations. Numerical experiments demonstrate that the 2DOF PI controller designed by the proposed method exhibits better control performance than the model-based method.","authors":["Taiga Kiyota","Kazuhiro Sato"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03566v1","updated":"2026-01-07T04:25:33Z","published":"2026-01-07T04:25:33Z","title":"Provably Convergent Decentralized Optimization over Directed Graphs under Generalized Smoothness","summary":"Decentralized optimization has become a fundamental tool for large-scale learning systems; however, most existing methods rely on the classical Lipschitz smoothness assumption, which is often violated in problems with rapidly varying gradients. Motivated by this limitation, we study decentralized optimization under the generalized $(L_0, L_1)$-smoothness framework, in which the Hessian norm is allowed to grow linearly with the gradient norm, thereby accommodating rapidly varying gradients beyond classical Lipschitz smoothness. We integrate gradient-tracking techniques with gradient clipping and carefully design the clipping threshold to ensure accurate convergence over directed communication graphs under generalized smoothness. In contrast to existing distributed optimization results under generalized smoothness that require a bounded gradient dissimilarity assumption, our results remain valid even when the gradient dissimilarity is unbounded, making the proposed framework more applicable to realistic heterogeneous data environments. We validate our approach via numerical experiments on standard benchmark datasets, including LIBSVM and CIFAR-10, using regularized logistic regression and convolutional neural networks, demonstrating superior stability and faster convergence over existing methods.","authors":["Yanan Bo","Yongqiang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.06366v2","updated":"2026-01-07T02:36:44Z","published":"2025-12-06T09:41:32Z","title":"Compressed Momentum-based Single-Point Zero-Order Algorithm for Stochastic Distributed Nonconvex Optimization","summary":"This paper studies a compressed momentum-based single-point zeroth-order algorithm for stochastic distributed nonconvex optimization, aiming to alleviate communication overhead and address the unavailability of explicit gradient information. In the developed framework, each agent has access only to stochastic zeroth-order information of its local objective function, performs local stochastic updates with momentum, and exchanges compressed updates with its neighbors. We theoretically prove that the proposed algorithm can achieve the exact solution with diminishing step sizes and can achieve a sublinear convergence rate towards a neighborhood of the stationary point with fixed step sizes. Numerical experiments validate the effectiveness and communication efficiency of the proposed algorithm.","authors":["Linjing Chen","Antai Xie","Xinlei Yi","Xiaoqiang Ren","Xiaofan Wang"],"pdf_url":"","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.18155v4","updated":"2026-01-07T01:42:01Z","published":"2024-03-26T23:40:13Z","title":"An inexact infeasible arc-search interior-point method for linear optimization problems","summary":"We propose an inexact infeasible arc-search interior-point method for solving linear optimization problems. The method combines an arc-search strategy with inexact solutions to Newton systems and admits a polynomial iteration complexity bound. In existing inexact infeasible interior-point methods, both the linearization error of the central path and the inexactness of the Newton system accumulate along the search direction, which forces the algorithm to take very small steps. The proposed method mitigates this effect by using an arc-search strategy: the curved search path provides a more accurate approximation of the central path, so the step size can remain larger even when the Newton system is solved inexactly. As a result, the proposed method achieves a provably tighter worst-case iteration bound than existing inexact infeasible line-search methods. Numerical experiments on NETLIB benchmark problems demonstrate that the proposed method reduces both the number of iterations and the computation time.","authors":["Einosuke Iida","Makoto Yamashita"],"pdf_url":"","comment":"36 pages, 5 figures"},{"id":"http://arxiv.org/abs/2511.15119v3","updated":"2026-01-07T22:56:14Z","published":"2025-11-19T04:46:21Z","title":"Nonholonomic Robot Parking by Feedback -- Part I: Modular Strict CLF Designs","summary":"It has been known in the robotics literature since about 1995 that, in polar coordinates, the nonholonomic unicycle is asymptotically stabilizable by smooth feedback, even globally. We introduce a modular design framework that selects the forward velocity to decouple the radial coordinate, allowing the steering subsystem to be stabilized independently. Within this structure, we develop families of feedback laws using passivity, backstepping, and integrator forwarding. Each law is accompanied by a strict control Lyapunov function, including barrier variants that enforce angular constraints. These strict CLFs provide constructive class KL convergence estimates and enable eigenvalue assignment at the target equilibrium. The framework generalizes and extends prior modular and nonmodular approaches, while preparing the ground for inverse optimal and adaptive redesigns in the sequel paper.","authors":["Velimir Todorovski","Kwang Hak Kim","Alessandro Astolfi","Miroslav Krstic"],"pdf_url":"","comment":"arXiv admin note: text overlap with arXiv:2509.25575"},{"id":"http://arxiv.org/abs/2505.05301v2","updated":"2026-01-07T22:51:33Z","published":"2025-05-08T14:43:17Z","title":"Operator-Level Quantum Acceleration of Non-Logconcave Sampling","summary":"Sampling from probability distributions of the form $σ\\propto e^{-βV}$, where $V$ is a continuous potential, is a fundamental task across physics, chemistry, biology, computer science, and statistics. However, when $V$ is non-convex, the resulting distribution becomes non-logconcave, and classical methods such as Langevin dynamics often exhibit poor performance. We introduce the first quantum algorithm that provably accelerates a broad class of continuous-time sampling dynamics. For Langevin dynamics, our method encodes the target Gibbs measure into the amplitudes of a quantum state, identified as the kernel of a block matrix derived from a factorization of the Witten Laplacian operator. This connection enables Gibbs sampling via singular value thresholding and yields up to a quartic quantum speedup over best-known classical Langevin-based methods in the non-logconcave setting. Building on this framework, we further develop the first quantum algorithm that accelerates replica exchange Langevin diffusion, a widely used method for sampling from complex, rugged energy landscapes.","authors":["Jiaqi Leng","Zhiyan Ding","Zherui Chen","Lin Lin"],"pdf_url":"","comment":"48 pages, 8 figures"},{"id":"http://arxiv.org/abs/2512.21973v3","updated":"2026-01-07T21:55:47Z","published":"2025-12-26T10:37:32Z","title":"When Indemnity Insurance Fails: Parametric Coverage under Binding Budget and Risk Constraints","summary":"In high-risk environments, traditional indemnity insurance is often unaffordable or ineffective, despite its well-known optimality under expected utility. We compare excess-of-loss indemnity insurance with parametric insurance within a common mean-variance framework, allowing for fixed costs, heterogeneous premium loadings, and binding budget constraints. We show that, once these realistic frictions are introduced, parametric insurance can yield higher welfare for risk-averse individuals, even under the same utility objective. The welfare advantage arises precisely when indemnity insurance becomes impractical, and disappears once both contracts are unconstrained. Our results help reconcile classical insurance theory with the growing use of parametric risk transfer in high-risk settings.","authors":["Benjamin Avanzi","Debbie Kusch Falden","Mogens Steffensen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04392v1","updated":"2026-01-07T20:59:18Z","published":"2026-01-07T20:59:18Z","title":"Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay","summary":"This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.","authors":["Mohsen Jalaeian-Farimani"],"pdf_url":"","comment":"Submitted to ECC26 conference"},{"id":"http://arxiv.org/abs/2601.04366v1","updated":"2026-01-07T20:13:14Z","published":"2026-01-07T20:13:14Z","title":"Machine Learning Model for Sparse PCM Completion","summary":"In this paper, we propose a machine learning model for sparse pairwise comparison matrices (PCMs), combining classical PCM approaches with graph-based learning techniques. Numerical results are provided to demonstrate the effectiveness and scalability of the proposed method.","authors":["Selcuk Koyuncu","Ronak Nouri","Stephen Providence"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.01415v2","updated":"2026-01-07T19:45:23Z","published":"2025-07-02T07:14:25Z","title":"Randomized subspace correction methods for convex optimization","summary":"This paper introduces an abstract framework for randomized subspace correction methods for convex optimization, which unifies and generalizes a broad class of existing algorithms, including domain decomposition, multigrid, and block coordinate descent methods. We provide a convergence rate analysis ranging from minimal assumptions to more practical settings, such as sharpness and strong convexity. While most existing studies on block coordinate descent methods focus on nonoverlapping decompositions and smooth or strongly convex problems, our framework extends to more general settings involving arbitrary space decompositions, inexact local solvers, and problems with weaker smoothness or convexity assumptions. The proposed framework is broadly applicable to convex optimization problems arising in areas such as nonlinear partial differential equations, imaging, and data science.","authors":["Boou Jiang","Jongho Park","Jinchao Xu"],"pdf_url":"","comment":"24 pages, 0 figures"},{"id":"http://arxiv.org/abs/2601.04334v1","updated":"2026-01-07T19:13:22Z","published":"2026-01-07T19:13:22Z","title":"Autonomous Reasoning for Spacecraft Control: A Large Language Model Framework with Group Relative Policy Optimization","summary":"This paper presents a learning-based guidance-and-control approach that couples a reasoning-enabled Large Language Model (LLM) with Group Relative Policy Optimization (GRPO). A two-stage procedure consisting of Supervised Fine-Tuning (SFT) to learn formatting and control primitives, followed by GRPO for interaction-driven policy improvement, trains controllers for each environment. The framework is demonstrated on four control problems spanning a gradient of dynamical complexity, from canonical linear systems through nonlinear oscillatory dynamics to three-dimensional spacecraft attitude control with gyroscopic coupling and thrust constraints. Results demonstrate that an LLM with explicit reasoning, optimized via GRPO, can synthesize feasible stabilizing policies under consistent training settings across both linear and nonlinear systems. The two-stage training methodology enables models to generate control sequences while providing human-readable explanations of their decision-making process. This work establishes a foundation for applying GRPO-based reasoning to autonomous control systems, with potential applications in aerospace and other safety-critical domains.","authors":["Amit Jain","Richard Linares"],"pdf_url":"","comment":null}],"Computation and Language":[{"id":"http://arxiv.org/abs/2510.17652v3","updated":"2026-01-07T18:35:28Z","published":"2025-10-20T15:27:53Z","title":"Qomhra: A Bilingual Irish and English Large Language Model","summary":"Large language model (LLM) research and development has overwhelmingly focused on the world's major languages, leading to under-representation of low-resource languages such as Irish. This paper introduces \\textbf{Qomhrá}, a bilingual Irish and English LLM, developed under extremely low-resource constraints. A complete pipeline is outlined spanning bilingual continued pre-training, instruction tuning, and the synthesis of human preference data for future alignment training. We focus on the lack of scalable methods to create human preference data by proposing a novel method to synthesise such data by prompting an LLM to generate ``accepted'' and ``rejected'' responses, which we validate as aligning with L1 Irish speakers. To select an LLM for synthesis, we evaluate the top closed-weight LLMs for Irish language generation performance. Gemini-2.5-Pro is ranked highest by L1 and L2 Irish-speakers, diverging from LLM-as-a-judge ratings, indicating a misalignment between current LLMs and the Irish-language community. Subsequently, we leverage Gemini-2.5-Pro to translate a large scale English-language instruction tuning dataset to Irish and to synthesise a first-of-its-kind Irish-language human preference dataset. We comprehensively evaluate Qomhrá across several benchmarks, testing translation, gender understanding, topic identification, and world knowledge; these evaluations show gains of up to 29\\% in Irish and 44\\% in English compared to the existing open-source Irish LLM baseline, UCCIX. The results of our framework provide insight and guidance to developing LLMs for both Irish and other low-resource languages.","authors":["Joseph McInerney","Khanh-Tung Tran","Liam Lonergan","Ailbhe Ní Chasaide","Neasa Ní Chiaráin","Barry Devereux"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.12460v3","updated":"2026-01-07T18:22:44Z","published":"2024-11-19T12:36:02Z","title":"Exploring Iterative Controllable Summarization with Large Language Models","summary":"Large language models (LLMs) have demonstrated remarkable performance in abstractive summarization tasks. However, their ability to precisely control summary attributes (e.g., length or topic) remains underexplored, limiting their adaptability to specific user preferences. In this paper, we systematically explore the controllability of LLMs. To this end, we revisit summary attribute measurements and introduce iterative evaluation metrics, failure rate and average iteration count to precisely evaluate controllability of LLMs, rather than merely assessing errors. Our findings show that LLMs struggle more with numerical attributes than with linguistic attributes. To address this challenge, we propose a guide-to-explain framework (GTE) for controllable summarization. Our GTE framework enables the model to identify misaligned attributes in the initial draft and guides it in self-explaining errors in the previous output. By allowing the model to reflect on its misalignment, GTE generates well-adjusted summaries that satisfy the desired attributes with robust effectiveness, requiring surprisingly fewer iterations than other iterative approaches.","authors":["Sangwon Ryu","Heejin Do","Daehee Kim","Hwanjo Yu","Dongwoo Kim","Yunsu Kim","Gary Geunbae Lee","Jungseul Ok"],"pdf_url":"","comment":"EACL Findings 2026"},{"id":"http://arxiv.org/abs/2601.00919v2","updated":"2026-01-07T18:20:49Z","published":"2026-01-01T08:39:15Z","title":"Attention Needs to Focus: A Unified Perspective on Attention Allocation","summary":"The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.","authors":["Zichuan Fu","Wentao Song","Guojing Li","Yejing Wang","Xian Wu","Yimin Deng","Hanyu Yan","Yefeng Zheng","Xiangyu Zhao"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2509.11963v2","updated":"2026-01-07T18:19:02Z","published":"2025-09-15T14:17:17Z","title":"ToolRM: Outcome Reward Models for Tool-Calling Large Language Models","summary":"As large language models (LLMs) increasingly interact with external tools, reward modeling for tool use has emerged as a critical yet underexplored area of research. Existing reward models, trained primarily on natural language outputs, struggle to evaluate tool-based reasoning and execution. To quantify this gap, we introduce FC-RewardBench, the first benchmark to systematically evaluate reward models in tool-calling scenarios. Our analysis shows that current reward models frequently miss key signals of effective tool use, highlighting the need for domain-specific modeling. We address this by proposing a training framework for outcome reward models using data synthesized from permissively licensed, open-weight LLMs. We introduce ToolRM - a suite of reward models for tool-use ranging from 1.7B to 14B parameters. Across diverse settings, these models consistently outperform general-purpose baselines. Notably, they achieve up to a 25% improvement with Best-of-N sampling, while also improving robustness to input noise, enabling effective data filtering, and supporting RL-training of policy models.","authors":["Mayank Agarwal","Ibrahim Abdelaziz","Kinjal Basu","Merve Unuvar","Luis A. Lastras","Yara Rizk","Pavan Kapanipathi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04160v1","updated":"2026-01-07T18:18:28Z","published":"2026-01-07T18:18:28Z","title":"All That Glisters Is Not Gold: A Benchmark for Reference-Free Counterfactual Financial Misinformation Detection","summary":"We introduce RFC Bench, a benchmark for evaluating large language models on financial misinformation under realistic news. RFC Bench operates at the paragraph level and captures the contextual complexity of financial news where meaning emerges from dispersed cues. The benchmark defines two complementary tasks: reference free misinformation detection and comparison based diagnosis using paired original perturbed inputs. Experiments reveal a consistent pattern: performance is substantially stronger when comparative context is available, while reference free settings expose significant weaknesses, including unstable predictions and elevated invalid outputs. These results indicate that current models struggle to maintain coherent belief states without external grounding. By highlighting this gap, RFC Bench provides a structured testbed for studying reference free reasoning and advancing more reliable financial misinformation detection in real world settings.","authors":["Yuechen Jiang","Zhiwei Liu","Yupeng Cao","Yueru He","Ziyang Xu","Chen Xu","Zhiyang Deng","Prayag Tiwari","Xi Chen","Alejandro Lopez-Lira","Jimin Huang","Junichi Tsujii","Sophia Ananiadou"],"pdf_url":"","comment":"39 pages; 24 figures"},{"id":"http://arxiv.org/abs/2601.01280v2","updated":"2026-01-07T18:16:54Z","published":"2026-01-03T20:39:39Z","title":"Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory","summary":"Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.","authors":["Sen Hu","Yuxiang Wei","Jiaxin Ran","Zhiyuan Yao","Xueran Han","Huacan Wang","Ronghao Chen","Lei Zou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04157v1","updated":"2026-01-07T18:12:05Z","published":"2026-01-07T18:12:05Z","title":"FLEx: Language Modeling with Few-shot Language Explanations","summary":"Language models have become effective at a wide range of tasks, from math problem solving to open-domain question answering. However, they still make mistakes, and these mistakes are often repeated across related queries. Natural language explanations can help correct these errors, but collecting them at scale may be infeasible, particularly in domains where expert annotators are required. To address this issue, we introduce FLEx ($\\textbf{F}$ew-shot $\\textbf{L}$anguage $\\textbf{Ex}$planations), a method for improving model behavior using a small number of explanatory examples. FLEx selects representative model errors using embedding-based clustering, verifies that the associated explanations correct those errors, and summarizes them into a prompt prefix that is prepended at inference-time. This summary guides the model to avoid similar errors on new inputs, without modifying model weights. We evaluate FLEx on CounterBench, GSM8K, and ReasonIF. We find that FLEx consistently outperforms chain-of-thought (CoT) prompting across all three datasets and reduces up to 83\\% of CoT's remaining errors.","authors":["Adar Avsian","Christopher Richardson","Anirudh Sundar","Larry Heck"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06303v4","updated":"2026-01-07T17:58:17Z","published":"2025-05-21T16:15:01Z","title":"Reward Is Enough: LLMs Are In-Context Reinforcement Learners","summary":"Reinforcement learning (RL) is a framework for solving sequential decision-making problems. In this work, we demonstrate that, surprisingly, RL emerges during the inference time of large language models (LLMs), a phenomenon we term in-context RL (ICRL). To reveal this capability, we introduce a simple multi-round prompting framework, we call ICRL prompting, for inference-time self-improvement. The goal of ICRL prompting is to guide LLMs to perform reinforcement learning during inference for self-improvement on a given task. After each response, the model receives numerical scalar feedback, denoted as a reward. In the next round, we prompt the LLM again together with a context that concatenates all prior responses and their associated rewards. We consistently observe that response quality improves as the context grows. In other words, the LLM can optimize scalar reward signals during inference, exhibiting behavior analogous to reinforcement learning. We evaluate ICRL prompting on Game of 24, creative writing, ScienceWorld, and Olympiad-level math competitions (AIME and HMMT), demonstrating significant improvements over baselines such as Self-Refine and Reflexion. Notably, even when the reward signals are generated by the same LLM, ICRL prompting still improves performance, highlighting a promising new paradigm for test-time scaling.","authors":["Kefan Song","Amir Moeini","Peng Wang","Lei Gong","Rohan Chandra","Shangtong Zhang","Yanjun Qi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04135v1","updated":"2026-01-07T17:49:17Z","published":"2026-01-07T17:49:17Z","title":"LLMberjack: Guided Trimming of Debate Trees for Multi-Party Conversation Creation","summary":"We present LLMberjack, a platform for creating multi-party conversations starting from existing debates, originally structured as reply trees. The system offers an interactive interface that visualizes discussion trees and enables users to construct coherent linearized dialogue sequences while preserving participant identity and discourse relations. It integrates optional large language model (LLM) assistance to support automatic editing of the messages and speakers' descriptions. We demonstrate the platform's utility by showing how tree visualization facilitates the creation of coherent, meaningful conversation threads and how LLM support enhances output quality while reducing human effort. The tool is open-source and designed to promote transparent and reproducible workflows to create multi-party conversations, addressing a lack of resources of this type.","authors":["Leonardo Bottona","Nicolò Penzo","Bruno Lepri","Marco Guerini","Sara Tonelli"],"pdf_url":"","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2601.04131v1","updated":"2026-01-07T17:45:20Z","published":"2026-01-07T17:45:20Z","title":"ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models","summary":"Large Language Models (LLMs) encode vast amounts of parametric knowledge during pre-training. As world knowledge evolves, effective deployment increasingly depends on their ability to faithfully follow externally retrieved context. When such evidence conflicts with the model's internal knowledge, LLMs often default to memorized facts, producing unfaithful outputs. In this work, we introduce ContextFocus, a lightweight activation steering approach that improves context faithfulness in such knowledge-conflict settings while preserving fluency and efficiency. Unlike prior approaches, our solution requires no model finetuning and incurs minimal inference-time overhead, making it highly efficient. We evaluate ContextFocus on the ConFiQA benchmark, comparing it against strong baselines including ContextDPO, COIECD, and prompting-based methods. Furthermore, we show that our method is complementary to prompting strategies and remains effective on larger models. Extensive experiments show that ContextFocus significantly improves contextual-faithfulness. Our results highlight the effectiveness, robustness, and efficiency of ContextFocus in improving contextual-faithfulness of LLM outputs.","authors":["Nikhil Anand","Shwetha Somasundaram","Anirudh Phukan","Apoorv Saxena","Koyel Mukherjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12976v3","updated":"2026-01-07T17:41:29Z","published":"2025-12-15T04:45:09Z","title":"Authors Should Label Their Own Documents","summary":"Third-party annotation is the status quo for labeling text, but egocentric information such as sentiment and belief can at best only be approximated by a third-person proxy. We introduce author labeling, an annotation technique where the writer of the document itself annotates the data at the moment of creation. We collaborate with a commercial chatbot with over 20,000 users to deploy an author labeling annotation system. This system identifies task-relevant queries, generates on-the-fly labeling questions, and records authors' answers in real time. We train and deploy an online-learning model architecture for product recommendation with author-labeled data to improve performance. We train our model to minimize the prediction error on questions generated for a set of predetermined subjective beliefs using author-labeled responses. Our model achieves a 537% improvement in click-through rate compared to an industry advertising baseline running concurrently. We then compare the quality and practicality of author labeling to three traditional annotation approaches for sentiment analysis and find author labeling to be higher quality, faster to acquire, and cheaper. These findings reinforce existing literature that annotations, especially for egocentric and subjective beliefs, are significantly higher quality when labeled by the author rather than a third party. To facilitate broader scientific adoption, we release an author labeling service for the research community at https://academic.echogroup.ai.","authors":["Marcus Ma","Cole Johnson","Nolan Bridges","Jackson Trager","Georgios Chochlakis","Shrikanth Narayanan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04126v1","updated":"2026-01-07T17:40:08Z","published":"2026-01-07T17:40:08Z","title":"InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training","summary":"GUI agents that interact with graphical interfaces on behalf of users represent a promising direction for practical AI assistants. However, training such agents is hindered by the scarcity of suitable environments. We present InfiniteWeb, a system that automatically generates functional web environments at scale for GUI agent training. While LLMs perform well on generating a single webpage, building a realistic and functional website with many interconnected pages faces challenges. We address these challenges through unified specification, task-centric test-driven development, and a combination of website seed with reference design image to ensure diversity. Our system also generates verifiable task evaluators enabling dense reward signals for reinforcement learning. Experiments show that InfiniteWeb surpasses commercial coding agents at realistic website construction, and GUI agents trained on our generated environments achieve significant performance improvements on OSWorld and Online-Mind2Web, demonstrating the effectiveness of proposed system.","authors":["Ziyun Zhang","Zezhou Wang","Xiaoyi Zhang","Zongyu Guo","Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2601.04098v1","updated":"2026-01-07T17:04:30Z","published":"2026-01-07T17:04:30Z","title":"Layer-wise Positional Bias in Short-Context Language Modeling","summary":"Language models often show a preference for using information from specific positions in the input regardless of semantic relevance. While positional bias has been studied in various contexts, from attention sinks to task performance degradation in long-context settings, prior work has not established how these biases evolve across individual layers and input positions, or how they vary independent of task complexity. We introduce an attribution-based framework to analyze positional effects in short-context language modeling. Using layer conductance with a sliding-window approach, we quantify how each layer distributes importance across input positions, yielding layer-wise positional importance profiles. We find that these profiles are architecture-specific, stable across inputs, and invariant to lexical scrambling. Characterizing these profiles, we find prominent recency bias that increases with depth and subtle primacy bias that diminishes through model depth. Beyond positional structure, we also show that early layers preferentially weight content words over function words across all positions, while later layers lose this word-type differentiation.","authors":["Maryam Rahimi","Mahdi Nouri","Yadollah Yaghoobzadeh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04093v1","updated":"2026-01-07T16:59:34Z","published":"2026-01-07T16:59:34Z","title":"SearchAttack: Red-Teaming LLMs against Real-World Threats via Framing Unsafe Web Information-Seeking Tasks","summary":"Recently, people have suffered and become increasingly aware of the unreliability gap in LLMs for open and knowledge-intensive tasks, and thus turn to search-augmented LLMs to mitigate this issue. However, when the search engine is triggered for harmful tasks, the outcome is no longer under the LLM's control. Once the returned content directly contains targeted, ready-to-use harmful takeaways, the LLM's safeguards cannot withdraw that exposure. Motivated by this dilemma, we identify web search as a critical attack surface and propose \\textbf{\\textit{SearchAttack}} for red-teaming. SearchAttack outsources the harmful semantics to web search, retaining only the query's skeleton and fragmented clues, and further steers LLMs to reconstruct the retrieved content via structural rubrics to achieve malicious goals. Extensive experiments are conducted to red-team the search-augmented LLMs for responsible vulnerability assessment. Empirically, SearchAttack demonstrates strong effectiveness in attacking these systems.","authors":["Yu Yan","Sheng Sun","Mingfeng Li","Zheming Yang","Chiwei Zhu","Fei Ma","Benfeng Xu","Min Liu"],"pdf_url":"","comment":"We find that the key to jailbreak the LLM is objectifying its safety responsibility, thus we delegate the open-web to inject harmful semantics and get the huge gain from unmoderated web resources"},{"id":"http://arxiv.org/abs/2601.04086v1","updated":"2026-01-07T16:54:20Z","published":"2026-01-07T16:54:20Z","title":"KDCM: Reducing Hallucination in LLMs through Explicit Reasoning Structures","summary":"To mitigate hallucinations in large language models (LLMs), we propose a framework that focuses on errors induced by prompts. Our method extends a chain-style knowledge distillation approach by incorporating a programmable module that guides knowledge graph exploration. This module is embedded as executable code within the reasoning prompt, allowing the model to leverage external structured knowledge during inference. Based on this design, we develop an enhanced distillation-based reasoning framework that explicitly regulates intermediate reasoning steps, resulting in more reliable predictions. We evaluate the proposed approach on multiple public benchmarks using GPT-4 and LLaMA-3.3. Experimental results show that code-guided reasoning significantly improves contextual modeling and reduces prompt-induced hallucinations. Specifically, HIT@1, HIT@3, and HIT@5 increase by 15.64%, 13.38%, and 13.28%, respectively, with scores exceeding 95% across several evaluation settings. These findings indicate that the proposed method effectively constrains erroneous reasoning while improving both accuracy and interpretability.","authors":["Jinbo Hao","Kai Yang","Qingzhen Su","Yifan Li","Chao Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20721v2","updated":"2026-01-07T16:46:55Z","published":"2025-10-23T16:38:26Z","title":"User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios","summary":"Large language models (LLMs) are rapidly being adopted for tasks like drafting emails, summarizing meetings, and answering health questions. In these settings, users may need to share private information (e.g., contact details, health records). To evaluate LLMs' ability to identify and redact such information, prior work introduced real-life, scenario-based benchmarks (e.g., ConfAIde, PrivacyLens) and found that LLMs can leak private information in complex scenarios. However, these evaluations relied on proxy LLMs to judge the helpfulness and privacy-preservation quality of LLM responses, rather than directly measuring users' perceptions. To understand how users perceive the helpfulness and privacy-preservation quality of LLM responses to privacy-sensitive scenarios, we conducted a user study ($n=94$) using 90 PrivacyLens scenarios. We found that users had low agreement with each other when evaluating identical LLM responses. In contrast, five proxy LLMs reached high agreement, yet each proxy LLM had low correlation with users' evaluations. These results indicate that proxy LLMs cannot accurately estimate users' wide range of perceptions of utility and privacy in privacy-sensitive scenarios. We discuss the need for more user-centered studies to measure LLMs' ability to help users while preserving privacy, and for improving alignment between LLMs and users in estimating perceived privacy and utility.","authors":["Xiaoyuan Wu","Roshni Kaushik","Wenkai Li","Lujo Bauer","Koichi Onoue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.07037v4","updated":"2026-01-07T16:45:28Z","published":"2025-10-08T14:04:14Z","title":"Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models across Modalities","summary":"Code-switching (CSW), the alternation of languages and scripts within a single utterance, remains a fundamental challenge for multilingual NLP, even amidst the rapid advances of large language models (LLMs). Amidst the rapid advances of large language models (LLMs), most LLMs still struggle with mixed-language inputs, limited Codeswitching (CSW) datasets, and evaluation biases, which hinder their deployment in multilingual societies. This survey provides the first comprehensive analysis of CSW-aware LLM research, reviewing 327 studies spanning five research areas, 15+ NLP tasks, 30+ datasets, and 80+ languages. We categorize recent advances by architecture, training strategy, and evaluation methodology, outlining how LLMs have reshaped CSW modeling and identifying the challenges that persist. The paper concludes with a roadmap that emphasizes the need for inclusive datasets, fair evaluation, and linguistically grounded models to achieve truly multilingual capabilities https://github.com/lingo-iitgn/awesome-code-mixing/.","authors":["Rajvee Sheth","Samridhi Raj Sinha","Mahavir Patil","Himanshu Beniwal","Mayank Singh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04073v1","updated":"2026-01-07T16:39:34Z","published":"2026-01-07T16:39:34Z","title":"Analyzing Reasoning Consistency in Large Multimodal Models under Cross-Modal Conflicts","summary":"Large Multimodal Models (LMMs) have demonstrated impressive capabilities in video reasoning via Chain-of-Thought (CoT). However, the robustness of their reasoning chains remains questionable. In this paper, we identify a critical failure mode termed textual inertia, where once a textual hallucination occurs in the thinking process, models tend to blindly adhere to the erroneous text while neglecting conflicting visual evidence. To systematically investigate this, we propose the LogicGraph Perturbation Protocol that structurally injects perturbations into the reasoning chains of diverse LMMs spanning both native reasoning architectures and prompt-driven paradigms to evaluate their self-reflection capabilities. The results reveal that models successfully self-correct in less than 10% of cases and predominantly succumb to blind textual error propagation. To mitigate this, we introduce Active Visual-Context Refinement, a training-free inference paradigm which orchestrates an active visual re-grounding mechanism to enforce fine-grained verification coupled with an adaptive context refinement strategy to summarize and denoise the reasoning history. Experiments demonstrate that our approach significantly stifles hallucination propagation and enhances reasoning robustness.","authors":["Zhihao Zhu","Jiafeng Liang","Shixin Jiang","Jinlan Fu","Ming Liu","Guanglu Sun","See-Kiong Ng","Bing Qin"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.04056v1","updated":"2026-01-07T16:21:19Z","published":"2026-01-07T16:21:19Z","title":"Bridging the Discrete-Continuous Gap: Unified Multimodal Generation via Coupled Manifold Discrete Absorbing Diffusion","summary":"The bifurcation of generative modeling into autoregressive approaches for discrete data (text) and diffusion approaches for continuous data (images) hinders the development of truly unified multimodal systems. While Masked Language Models (MLMs) offer efficient bidirectional context, they traditionally lack the generative fidelity of autoregressive models and the semantic continuity of diffusion models. Furthermore, extending masked generation to multimodal settings introduces severe alignment challenges and training instability. In this work, we propose \\textbf{CoM-DAD} (\\textbf{Co}upled \\textbf{M}anifold \\textbf{D}iscrete \\textbf{A}bsorbing \\textbf{D}iffusion), a novel probabilistic framework that reformulates multimodal generation as a hierarchical dual-process. CoM-DAD decouples high-level semantic planning from low-level token synthesis. First, we model the semantic manifold via a continuous latent diffusion process; second, we treat token generation as a discrete absorbing diffusion process, regulated by a \\textbf{Variable-Rate Noise Schedule}, conditioned on these evolving semantic priors. Crucially, we introduce a \\textbf{Stochastic Mixed-Modal Transport} strategy that aligns disparate modalities without requiring heavy contrastive dual-encoders. Our method demonstrates superior stability over standard masked modeling, establishing a new paradigm for scalable, unified text-image generation.","authors":["Yuanfeng Xu","Yuhao Chen","Liang Lin","Guangrun Wang"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.04055v1","updated":"2026-01-07T16:20:08Z","published":"2026-01-07T16:20:08Z","title":"Modular Prompt Optimization: Optimizing Structured Prompts with Section-Local Textual Gradients","summary":"Prompt quality plays a central role in controlling the behavior, reliability, and reasoning performance of large language models (LLMs), particularly for smaller open-source instruction-tuned models that depend heavily on explicit structure. While recent work has explored automatic prompt optimization using textual gradients and self-refinement, most existing methods treat prompts as monolithic blocks of text, making it difficult to localize errors, preserve critical instructions, or prevent uncontrolled prompt growth. We introduce Modular Prompt Optimization (MPO), a schema-based prompt optimization framework that treats prompts as structured objects composed of fixed semantic sections, including system role, context, task description, constraints, and output format. MPO applies section-local textual gradients, generated by a critic language model, to refine each section independently while keeping the overall prompt schema fixed. Section updates are consolidated through de-duplication to reduce redundancy and interference between components, yielding an interpretable and robust optimization process. We evaluate MPO on two reasoning benchmarks, ARC-Challenge and MMLU, using LLaMA-3 8B-Instruct and Mistral-7B-Instruct as solver models. Across both benchmarks and models, MPO consistently outperforms an untuned structured prompt and the TextGrad baseline, achieving substantial accuracy gains without modifying model parameters or altering prompt structure. These results demonstrate that maintaining a fixed prompt schema while applying localized, section-wise optimization is an effective and practical approach for improving reasoning performance in small open-source LMs.","authors":["Prith Sharma","Austin Z. Henley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04052v1","updated":"2026-01-07T16:16:10Z","published":"2026-01-07T16:16:10Z","title":"Stable Language Guidance for Vision-Language-Action Models","summary":"Vision-Language-Action (VLA) models have demonstrated impressive capabilities in generalized robotic control; however, they remain notoriously brittle to linguistic perturbations. We identify a critical ``modality collapse'' phenomenon where strong visual priors overwhelm sparse linguistic signals, causing agents to overfit to specific instruction phrasings while ignoring the underlying semantic intent. To address this, we propose \\textbf{Residual Semantic Steering (RSS)}, a probabilistic framework that disentangles physical affordance from semantic execution. RSS introduces two theoretical innovations: (1) \\textbf{Monte Carlo Syntactic Integration}, which approximates the true semantic posterior via dense, LLM-driven distributional expansion, and (2) \\textbf{Residual Affordance Steering}, a dual-stream decoding mechanism that explicitly isolates the causal influence of language by subtracting the visual affordance prior. Theoretical analysis suggests that RSS effectively maximizes the mutual information between action and intent while suppressing visual distractors. Empirical results across diverse manipulation benchmarks demonstrate that RSS achieves state-of-the-art robustness, maintaining performance even under adversarial linguistic perturbations.","authors":["Zhihao Zhan","Yuhao Chen","Jiaying Zhou","Qinhan Lv","Hao Liu","Keze Wang","Liang Lin","Guangrun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04043v1","updated":"2026-01-07T15:59:07Z","published":"2026-01-07T15:59:07Z","title":"When Helpers Become Hazards: A Benchmark for Analyzing Multimodal LLM-Powered Safety in Daily Life","summary":"As Multimodal Large Language Models (MLLMs) become an indispensable assistant in human life, the unsafe content generated by MLLMs poses a danger to human behavior, perpetually overhanging human society like a sword of Damocles. To investigate and evaluate the safety impact of MLLMs responses on human behavior in daily life, we introduce SaLAD, a multimodal safety benchmark which contains 2,013 real-world image-text samples across 10 common categories, with a balanced design covering both unsafe scenarios and cases of oversensitivity. It emphasizes realistic risk exposure, authentic visual inputs, and fine-grained cross-modal reasoning, ensuring that safety risks cannot be inferred from text alone. We further propose a safety-warning-based evaluation framework that encourages models to provide clear and informative safety warnings, rather than generic refusals. Results on 18 MLLMs demonstrate that the top-performing models achieve a safe response rate of only 57.2% on unsafe queries. Moreover, even popular safety alignment methods limit effectiveness of the models in our scenario, revealing the vulnerabilities of current MLLMs in identifying dangerous behaviors in daily life. Our dataset is available at https://github.com/xinyuelou/SaLAD.","authors":["Xinyue Lou","Jinan Xu","Jingyi Yin","Xiaolong Wang","Zhaolu Kang","Youwei Liao","Yixuan Wang","Xiangyu Shi","Fengran Mo","Su Yao","Kaiyu Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04036v1","updated":"2026-01-07T15:51:54Z","published":"2026-01-07T15:51:54Z","title":"Analyzing and Improving Cross-lingual Knowledge Transfer for Machine Translation","summary":"Multilingual machine translation systems aim to make knowledge accessible across languages, yet learning effective cross-lingual representations remains challenging. These challenges are especially pronounced for low-resource languages, where limited parallel data constrains generalization and transfer. Understanding how multilingual models share knowledge across languages requires examining the interaction between representations, data availability, and training strategies. In this thesis, we study cross-lingual knowledge transfer in neural models and develop methods to improve robustness and generalization in multilingual settings, using machine translation as a central testbed. We analyze how similarity between languages influences transfer, how retrieval and auxiliary supervision can strengthen low-resource translation, and how fine-tuning on parallel data can introduce unintended trade-offs in large language models. We further examine the role of language diversity during training and show that increasing translation coverage improves generalization and reduces off-target behavior. Together, this work highlights how modeling choices and data composition shape multilingual learning and offers insights toward more inclusive and resilient multilingual NLP systems.","authors":["David Stap"],"pdf_url":"","comment":"PhD dissertation defended on November 26th, 2025"},{"id":"http://arxiv.org/abs/2601.00224v2","updated":"2026-01-07T15:49:16Z","published":"2026-01-01T06:10:06Z","title":"Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback","summary":"As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.","authors":["Yan Sun","Ming Cai","Stanley Kok"],"pdf_url":"","comment":"WITS 2025 (Workshop on Information Technologies and Systems 2025)"},{"id":"http://arxiv.org/abs/2601.04029v1","updated":"2026-01-07T15:45:41Z","published":"2026-01-07T15:45:41Z","title":"SpeakerSleuth: Evaluating Large Audio-Language Models as Judges for Multi-turn Speaker Consistency","summary":"Large Audio-Language Models (LALMs) as judges have emerged as a prominent approach for evaluating speech generation quality, yet their ability to assess speaker consistency across multi-turn conversations remains unexplored. We present SpeakerSleuth, a benchmark evaluating whether LALMs can reliably judge speaker consistency in multi-turn dialogues through three tasks reflecting real-world requirements. We construct 1,818 human-verified evaluation instances across four diverse datasets spanning synthetic and real speech, with controlled acoustic difficulty. Evaluating nine widely-used LALMs, we find that models struggle to reliably detect acoustic inconsistencies. For instance, given audio samples of the same speaker's turns, some models overpredict inconsistency, whereas others are overly lenient. Models further struggle to identify the exact turns that are problematic. When other interlocutors' turns are provided together, performance degrades dramatically as models prioritize textual coherence over acoustic cues, failing to detect even obvious gender switches for a speaker. On the other hand, models perform substantially better in choosing the audio that best matches the speaker among several acoustic variants, demonstrating inherent acoustic discrimination capabilities. These findings expose a significant bias in LALMs: they tend to prioritize text over acoustics, revealing fundamental modality imbalances that need to be addressed to build reliable audio-language judges.","authors":["Jonggeun Lee","Junseong Pyo","Gyuhyeon Seo","Yohan Jo"],"pdf_url":"","comment":"28 pages"},{"id":"http://arxiv.org/abs/2601.04025v1","updated":"2026-01-07T15:44:11Z","published":"2026-01-07T15:44:11Z","title":"Simulated Students in Tutoring Dialogues: Substance or Illusion?","summary":"Advances in large language models (LLMs) enable many new innovations in education. However, evaluating the effectiveness of new technology requires real students, which is time-consuming and hard to scale up. Therefore, many recent works on LLM-powered tutoring solutions have used simulated students for both training and evaluation, often via simple prompting. Surprisingly, little work has been done to ensure or even measure the quality of simulated students. In this work, we formally define the student simulation task, propose a set of evaluation metrics that span linguistic, behavioral, and cognitive aspects, and benchmark a wide range of student simulation methods on these metrics. We experiment on a real-world math tutoring dialogue dataset, where both automated and human evaluation results show that prompting strategies for student simulation perform poorly; supervised fine-tuning and preference optimization yield much better but still limited performance, motivating future work on this challenging task.","authors":["Alexander Scarlatos","Jaewook Lee","Simon Woodhead","Andrew Lan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.01650v2","updated":"2026-01-07T15:44:03Z","published":"2025-11-03T15:05:44Z","title":"EngTrace: A Symbolic Benchmark for Verifiable Process Supervision of Engineering Reasoning","summary":"Large Language Models (LLMs) are increasingly entering specialized, safety-critical engineering workflows governed by strict quantitative standards and immutable physical laws, making rigorous evaluation of their reasoning capabilities imperative. However, existing benchmarks such as MMLU, MATH, and HumanEval assess isolated cognitive skills, failing to capture the physically grounded reasoning central to engineering, where scientific principles, quantitative modeling, and practical constraints must converge. To enable verifiable process supervision in engineering, we introduce EngTrace, a symbolic benchmark comprising 90 templates across three major engineering branches, nine core domains and 20 distinct areas. Through domain-aware parameterization, we generate 1,350 unique, contamination-resistant test cases to stress-test generalization. Moving beyond outcome matching, we introduce a verifiable two-stage evaluation framework that uses a tiered protocol to validate intermediate reasoning traces alongside final answers through automated procedural checks and a heterogeneous AI Tribunal. Our evaluation of 24 leading LLMs reveals a distinct trade-off between numeric precision and trace fidelity, identifying a complexity cliff where abstract mathematical pre-training fails to translate into the integrative reasoning required for advanced engineering tasks.","authors":["Ayesha Gull","Muhammad Usman Safder","Rania Elbadry","Fan Zhang","Veselin Stoyanov","Preslav Nakov","Zhuohan Xie"],"pdf_url":"","comment":"22 pages, includes figures and tables; introduces the EngTrace benchmark"},{"id":"http://arxiv.org/abs/2509.15577v2","updated":"2026-01-07T15:15:20Z","published":"2025-09-19T04:24:57Z","title":"Relevance to Utility: Process-Supervised Rewrite for RAG","summary":"Retrieval-augmented generation systems often suffer from a gap between optimizing retrieval relevance and generative utility. With such a gap, retrieved documents may be topically relevant but still lack the content needed for effective reasoning during generation. While existing bridge modules attempt to rewrite the retrieved text for better generation, we show how they fail by not capturing \"document utility\". In this work, we propose R2U, with a key distinction of approximating true utility through joint observation of rewriting and answering in the reasoning process. To distill, R2U scale such supervision to enhance reliability in distillation. We further construct utility-improvement supervision by measuring the generator's gain of the answer under the rewritten context, yielding signals for fine-tuning and preference optimization. We evaluate our method across multiple open-domain question-answering benchmarks. The empirical results demonstrate consistent improvements over strong bridging baselines","authors":["Jaeyoung Kim","Jongho Kim","Seung-won Hwang","Seoho Song","Young-In Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.05894v2","updated":"2026-01-07T15:11:39Z","published":"2024-11-08T14:23:02Z","title":"SSSD: Simply-Scalable Speculative Decoding","summary":"Speculative Decoding has emerged as a popular technique for accelerating inference in Large Language Models. However, most existing approaches yield only modest improvements in production serving systems. Methods that achieve substantial speedups typically rely on an additional trained draft model or auxiliary model components, increasing deployment and maintenance complexity. This added complexity reduces flexibility, particularly when serving workloads shift to tasks, domains, or languages that are not well represented in the draft model's training data.\n  We introduce Simply-Scalable Speculative Decoding (SSSD), a training-free method that combines lightweight n-gram matching with hardware-aware speculation. Relative to standard autoregressive decoding, SSSD reduces latency by up to 2.9x. It achieves performance on par with leading training-based approaches across a broad range of benchmarks, while requiring substantially lower adoption effort--no data preparation, training or tuning are needed--and exhibiting superior robustness under language and domain shift, as well as in long-context settings.","authors":["Michele Marzollo","Jiawei Zhuang","Niklas Roemer","Niklas Zwingenberger","Lorenz K. Müller","Lukas Cavigelli"],"pdf_url":"","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2601.03997v1","updated":"2026-01-07T15:06:53Z","published":"2026-01-07T15:06:53Z","title":"VotIE: Information Extraction from Meeting Minutes","summary":"Municipal meeting minutes record key decisions in local democratic processes. Unlike parliamentary proceedings, which typically adhere to standardized formats, they encode voting outcomes in highly heterogeneous, free-form narrative text that varies widely across municipalities, posing significant challenges for automated extraction. In this paper, we introduce VotIE (Voting Information Extraction), a new information extraction task aimed at identifying structured voting events in narrative deliberative records, and establish the first benchmark for this task using Portuguese municipal minutes, building on the recently introduced CitiLink corpus. Our experiments yield two key findings. First, under standard in-domain evaluation, fine-tuned encoders, specifically XLM-R-CRF, achieve the strongest performance, reaching 93.2\\% macro F1, outperforming generative approaches. Second, in a cross-municipality setting that evaluates transfer to unseen administrative contexts, these models suffer substantial performance degradation, whereas few-shot LLMs demonstrate greater robustness, with significantly smaller declines in performance. Despite this generalization advantage, the high computational cost of generative models currently constrains their practicality. As a result, lightweight fine-tuned encoders remain a more practical option for large-scale, real-world deployment. To support reproducible research in administrative NLP, we publicly release our benchmark, trained models, and evaluation framework.","authors":["José Pedro Evans","Luís Filipe Cunha","Purificação Silvano","Alípio Jorge","Nuno Guimarães","Sérgio Nunes","Ricardo Campos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03986v1","updated":"2026-01-07T14:59:03Z","published":"2026-01-07T14:59:03Z","title":"Benchmark^2: Systematic Evaluation of LLM Benchmarks","summary":"The rapid proliferation of benchmarks for evaluating large language models (LLMs) has created an urgent need for systematic methods to assess benchmark quality itself. We propose Benchmark^2, a comprehensive framework comprising three complementary metrics: (1) Cross-Benchmark Ranking Consistency, measuring whether a benchmark produces model rankings aligned with peer benchmarks; (2) Discriminability Score, quantifying a benchmark's ability to differentiate between models; and (3) Capability Alignment Deviation, identifying problematic instances where stronger models fail but weaker models succeed within the same model family. We conduct extensive experiments across 15 benchmarks spanning mathematics, reasoning, and knowledge domains, evaluating 11 LLMs across four model families. Our analysis reveals significant quality variations among existing benchmarks and demonstrates that selective benchmark construction based on our metrics can achieve comparable evaluation performance with substantially reduced test sets.","authors":["Qi Qian","Chengsong Huang","Jingwen Xu","Changze Lv","Muling Wu","Wenhao Liu","Xiaohua Wang","Zhenghua Wang","Zisu Huang","Muzhao Tian","Jianhan Xu","Kun Hu","He-Da Wang","Yao Hu","Xuanjing Huang","Xiaoqing Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03981v1","updated":"2026-01-07T14:52:15Z","published":"2026-01-07T14:52:15Z","title":"RADAR: Retrieval-Augmented Detector with Adversarial Refinement for Robust Fake News Detection","summary":"To efficiently combat the spread of LLM-generated misinformation, we present RADAR, a retrieval-augmented detector with adversarial refinement for robust fake news detection. Our approach employs a generator that rewrites real articles with factual perturbations, paired with a lightweight detector that verifies claims using dense passage retrieval. To enable effective co-evolution, we introduce verbal adversarial feedback (VAF). Rather than relying on scalar rewards, VAF issues structured natural-language critiques; these guide the generator toward more sophisticated evasion attempts, compelling the detector to adapt and improve. On a fake news detection benchmark, RADAR achieves 86.98% ROC-AUC, significantly outperforming general-purpose LLMs with retrieval. Ablation studies confirm that detector-side retrieval yields the largest gains, while VAF and few-shot demonstrations provide critical signals for robust training.","authors":["Song-Duo Ma","Yi-Hung Liu","Hsin-Yu Lin","Pin-Yu Chen","Hong-Yan Huang","Shau-Yung Hsu","Yun-Nung Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03979v1","updated":"2026-01-07T14:50:41Z","published":"2026-01-07T14:50:41Z","title":"SoK: Privacy Risks and Mitigations in Retrieval-Augmented Generation Systems","summary":"The continued promise of Large Language Models (LLMs), particularly in their natural language understanding and generation capabilities, has driven a rapidly increasing interest in identifying and developing LLM use cases. In an effort to complement the ingrained \"knowledge\" of LLMs, Retrieval-Augmented Generation (RAG) techniques have become widely popular. At its core, RAG involves the coupling of LLMs with domain-specific knowledge bases, whereby the generation of a response to a user question is augmented with contextual and up-to-date information. The proliferation of RAG has sparked concerns about data privacy, particularly with the inherent risks that arise when leveraging databases with potentially sensitive information. Numerous recent works have explored various aspects of privacy risks in RAG systems, from adversarial attacks to proposed mitigations. With the goal of surveying and unifying these works, we ask one simple question: What are the privacy risks in RAG, and how can they be measured and mitigated? To answer this question, we conduct a systematic literature review of RAG works addressing privacy, and we systematize our findings into a comprehensive set of privacy risks, mitigation techniques, and evaluation strategies. We supplement these findings with two primary artifacts: a Taxonomy of RAG Privacy Risks and a RAG Privacy Process Diagram. Our work contributes to the study of privacy in RAG not only by conducting the first systematization of risks and mitigations, but also by uncovering important considerations when mitigating privacy risks in RAG systems and assessing the current maturity of proposed mitigations.","authors":["Andreea-Elena Bodea","Stephen Meisenbacher","Alexandra Klymenko","Florian Matthes"],"pdf_url":"","comment":"17 pages, 3 figures, 5 tables. This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML 2026). The final version will be available on IEEE Xplore"},{"id":"http://arxiv.org/abs/2601.03973v1","updated":"2026-01-07T14:40:48Z","published":"2026-01-07T14:40:48Z","title":"Muse: Towards Reproducible Long-Form Song Generation with Fine-Grained Style Control","summary":"Recent commercial systems such as Suno demonstrate strong capabilities in long-form song generation, while academic research remains largely non-reproducible due to the lack of publicly available training data, hindering fair comparison and progress. To this end, we release a fully open-source system for long-form song generation with fine-grained style conditioning, including a licensed synthetic dataset, training and evaluation pipelines, and Muse, an easy-to-deploy song generation model. The dataset consists of 116k fully licensed synthetic songs with automatically generated lyrics and style descriptions paired with audio synthesized by SunoV5. We train Muse via single-stage supervised finetuning of a Qwen-based language model extended with discrete audio tokens using MuCodec, without task-specific losses, auxiliary objectives, or additional architectural components. Our evaluations find that although Muse is trained with a modest data scale and model size, it achieves competitive performance on phoneme error rate, text--music style similarity, and audio aesthetic quality, while enabling controllable segment-level generation across different musical structures. All data, model weights, and training and evaluation pipelines will be publicly released, paving the way for continued progress in controllable long-form song generation research. The project repository is available at https://github.com/yuhui1038/Muse.","authors":["Changhao Jiang","Jiahao Chen","Zhenghao Xiang","Zhixiong Yang","Hanchen Wang","Jiabao Zhuang","Xinmeng Che","Jiajun Sun","Hui Li","Yifei Cao","Shihan Dou","Ming Zhang","Junjie Ye","Tao Ji","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.09631v3","updated":"2026-01-07T14:31:16Z","published":"2025-09-11T17:16:52Z","title":"DiFlow-TTS: Compact and Low-Latency Zero-Shot Text-to-Speech with Factorized Discrete Flow Matching","summary":"This paper introduces DiFlow-TTS, a novel zero-shot text-to-speech (TTS) system that employs discrete flow matching for generative speech modeling. We position this work as an entry point that may facilitate further advances in this research direction. Through extensive empirical evaluation, we analyze both the strengths and limitations of this approach across key aspects, including naturalness, expressive attributes, speaker identity, and inference latency. To this end, we leverage factorized speech representations and design a deterministic Phoneme-Content Mapper for modeling linguistic content, together with a Factorized Discrete Flow Denoiser that jointly models multiple discrete token streams corresponding to prosody and acoustics to capture expressive speech attributes. Experimental results demonstrate that DiFlow-TTS achieves strong performance across multiple metrics while maintaining a compact model size, up to 11.7 times smaller, and enabling low-latency inference that is up to 34 times faster than recent state-of-the-art baselines. Audio samples are available on our demo page: https://diflow-tts.github.io.","authors":["Ngoc-Son Nguyen","Thanh V. T. Tran","Hieu-Nghia Huynh-Nguyen","Truong-Son Hy","Van Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03969v1","updated":"2026-01-07T14:31:07Z","published":"2026-01-07T14:31:07Z","title":"Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models","summary":"Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods.","authors":["Wei Wu","Liyi Chen","Congxi Xiao","Tianfu Wang","Qimeng Wang","Chengqiang Lu","Yan Gao","Yi Wu","Yao Hu","Hui Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13935v2","updated":"2026-01-07T14:13:11Z","published":"2025-10-15T15:51:13Z","title":"Big Reasoning with Small Models: Instruction Retrieval at Inference Time","summary":"Small language models (SLMs) enable low-cost, private, on-device inference, but they often fail on problems that require specialized domain knowledge or multi-step reasoning. Existing approaches for improving reasoning either rely on scale (e.g., chain-of-thought prompting), require task-specific training that limits reuse and generality (e.g., distillation), or retrieve unstructured information that still leaves the SLM to determine an appropriate reasoning strategy. We propose instruction retrieval, an inference-time intervention that augments an SLM with structured, reusable reasoning procedures rather than raw passages. We construct an Instruction Corpus by clustering similar training questions and using a teacher model to generate generalizable guides that pair domain background with explicit step-by-step procedures. At inference, the SLM retrieves the instructions most relevant to a given query and executes the associated procedures without any additional fine-tuning. Across three challenging domains: medicine, law, and mathematics, instruction retrieval yields consistent gains for models with at least 3B parameters, improving accuracy by 9.4%, 7.9%, and 5.1%, respectively, with the strongest 14B model surpassing GPT-4o's zero-shot performance on knowledge-intensive tasks.","authors":["Kenan Alkiek","David Jurgens","Vinod Vydiswaran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03940v1","updated":"2026-01-07T13:58:29Z","published":"2026-01-07T13:58:29Z","title":"Large-Scale Aspect-Based Sentiment Analysis with Reasoning-Infused LLMs","summary":"We introduce Arctic-ABSA, a collection of powerful models for real-life aspect-based sentiment analysis (ABSA). Our models are tailored to commercial needs, trained on a large corpus of public data alongside carefully generated synthetic data, resulting in a dataset 20 times larger than SemEval14. We extend typical ABSA models by expanding the number of sentiment classes from the standard three (positive, negative, neutral) to five, adding mixed and unknown classes, while also jointly predicting overall text sentiment and supporting multiple languages. We experiment with reasoning injection by fine-tuning on Chain-of-Thought (CoT) examples and introduce a novel reasoning pretraining technique for encoder-only models that significantly improves downstream fine-tuning and generalization. Our 395M-parameter encoder and 8B-parameter decoder achieve up to 10 percentage points higher accuracy than GPT-4o and Claude 3.5 Sonnet, while setting new state-of-the-art results on the SemEval14 benchmark. A single multilingual model maintains 87-91% accuracy across six languages without degrading English performance. We release ABSA-mix, a large-scale benchmark aggregating 17 public ABSA datasets across 92 domains.","authors":["Paweł Liskowski","Krzysztof Jankowski"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03938v1","updated":"2026-01-07T13:55:14Z","published":"2026-01-07T13:55:14Z","title":"FOREVER: Forgetting Curve-Inspired Memory Replay for Language Model Continual Learning","summary":"Continual learning (CL) for large language models (LLMs) aims to enable sequential knowledge acquisition without catastrophic forgetting. Memory replay methods are widely used for their practicality and effectiveness, but most rely on fixed, step-based heuristics that often misalign with the model's actual learning progress, since identical training steps can result in varying degrees of parameter change. Motivated by recent findings that LLM forgetting mirrors the Ebbinghaus human forgetting curve, we propose FOREVER (FORgEtting curVe-inspired mEmory Replay), a novel CL framework that aligns replay schedules with a model-centric notion of time. FOREVER defines model time using the magnitude of optimizer updates, allowing forgetting curve-inspired replay intervals to align with the model's internal evolution rather than raw training steps. Building on this approach, FOREVER incorporates a forgetting curve-based replay scheduler to determine when to replay and an intensity-aware regularization mechanism to adaptively control how to replay. Extensive experiments on three CL benchmarks and models ranging from 0.6B to 13B parameters demonstrate that FOREVER consistently mitigates catastrophic forgetting.","authors":["Yujie Feng","Hao Wang","Jian Li","Xu Chu","Zhaolu Kang","Yiran Liu","Yasha Wang","Philip S. Yu","Xiao-Ming Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03928v1","updated":"2026-01-07T13:48:12Z","published":"2026-01-07T13:48:12Z","title":"FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection","summary":"Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while preserving positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Preserving positional continuity during visual token selection. We find that general visual token pruning methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.","authors":["Mingyu Ouyang","Kevin Qinghong Lin","Mike Zheng Shou","Hwee Tou Ng"],"pdf_url":"","comment":"14 pages, 13 figures"},{"id":"http://arxiv.org/abs/2601.03926v1","updated":"2026-01-07T13:45:39Z","published":"2026-01-07T13:45:39Z","title":"Doc-PP: Document Policy Preservation Benchmark for Large Vision-Language Models","summary":"The deployment of Large Vision-Language Models (LVLMs) for real-world document question answering is often constrained by dynamic, user-defined policies that dictate information disclosure based on context. While ensuring adherence to these explicit constraints is critical, existing safety research primarily focuses on implicit social norms or text-only settings, overlooking the complexities of multimodal documents. In this paper, we introduce Doc-PP (Document Policy Preservation Benchmark), a novel benchmark constructed from real-world reports requiring reasoning across heterogeneous visual and textual elements under strict non-disclosure policies. Our evaluation highlights a systemic Reasoning-Induced Safety Gap: models frequently leak sensitive information when answers must be inferred through complex synthesis or aggregated across modalities, effectively circumventing existing safety constraints. Furthermore, we identify that providing extracted text improves perception but inadvertently facilitates leakage. To address these vulnerabilities, we propose DVA (Decompose-Verify-Aggregation), a structural inference framework that decouples reasoning from policy verification. Experimental results demonstrate that DVA significantly outperforms standard prompting defenses, offering a robust baseline for policy-compliant document understanding","authors":["Haeun Jang","Hwan Chang","Hwanhee Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03914v1","updated":"2026-01-07T13:27:48Z","published":"2026-01-07T13:27:48Z","title":"When Models Decide and When They Bind: A Two-Stage Computation for Multiple-Choice Question-Answering","summary":"Multiple-choice question answering (MCQA) is easy to evaluate but adds a meta-task: models must both solve the problem and output the symbol that *represents* the answer, conflating reasoning errors with symbol-binding failures. We study how language models implement MCQA internally using representational analyses (PCA, linear probes) as well as causal interventions. We find that option-boundary (newline) residual states often contain strong linearly decodable signals related to per-option correctness. Winner-identity probing reveals a two-stage progression: the winning *content position* becomes decodable immediately after the final option is processed, while the *output symbol* is represented closer to the answer emission position. Tests under symbol and content permutations support a two-stage mechanism in which models first select a winner in content space and then bind or route that winner to the appropriate symbol to emit.","authors":["Hugh Mee Wong","Rick Nouwen","Albert Gatt"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2601.03908v1","updated":"2026-01-07T13:20:59Z","published":"2026-01-07T13:20:59Z","title":"Decide Then Retrieve: A Training-Free Framework with Uncertainty-Guided Triggering and Dual-Path Retrieval","summary":"Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge, but existing approaches indiscriminately trigger retrieval and rely on single-path evidence construction, often introducing noise and limiting performance gains. In this work, we propose Decide Then Retrieve (DTR), a training-free framework that adaptively determines when retrieval is necessary and how external information should be selected. DTR leverages generation uncertainty to guide retrieval triggering and introduces a dual-path retrieval mechanism with adaptive information selection to better handle sparse and ambiguous queries. Extensive experiments across five open-domain QA benchmarks, multiple model scales, and different retrievers demonstrate that DTR consistently improves EM and F1 over standard RAG and strong retrieval-enhanced baselines, while reducing unnecessary retrievals. The code and data used in this paper are available at https://github.com/ChenWangHKU/DTR.","authors":["Wang Chen","Guanqiang Qi","Weikang Li","Yang Li","Deguo Xia","Jizhou Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.20118v4","updated":"2026-01-07T13:19:41Z","published":"2025-05-26T15:20:51Z","title":"TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent","summary":"As large language models (LLMs) become integrated into sensitive workflows, concerns grow over their potential to leak confidential information. We propose TrojanStego, a novel threat model in which an adversary fine-tunes an LLM to embed sensitive context information into natural-looking outputs via linguistic steganography, without requiring explicit control over inference inputs. We introduce a taxonomy outlining risk factors for compromised LLMs, and use it to evaluate the risk profile of the threat. To implement TrojanStego, we propose a practical encoding scheme based on vocabulary partitioning learnable by LLMs via fine-tuning. Experimental results show that compromised models reliably transmit 32-bit secrets with 87% accuracy on held-out prompts, reaching over 97% accuracy using majority voting across three generations. Further, they maintain high utility, can evade human detection, and preserve coherence. These results highlight a new class of LLM data exfiltration attacks that are passive, covert, practical, and dangerous.","authors":["Dominik Meier","Jan Philip Wahle","Paul Röttger","Terry Ruas","Bela Gipp"],"pdf_url":"","comment":"9 pages, 5 figures To be presented in the Conference on Empirical Methods in Natural Language Processing, 2025"},{"id":"http://arxiv.org/abs/2601.03905v1","updated":"2026-01-07T13:15:23Z","published":"2026-01-07T13:15:23Z","title":"Current Agents Fail to Leverage World Model as Tool for Foresight","summary":"Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.","authors":["Cheng Qian","Emre Can Acikgoz","Bingxuan Li","Xiusi Chen","Yuji Zhang","Bingxiang He","Qinyu Luo","Dilek Hakkani-Tür","Gokhan Tur","Yunzhu Li","Heng Ji","Heng Ji"],"pdf_url":"","comment":"36 Pages, 13 Figures, 17 Tables"},{"id":"http://arxiv.org/abs/2507.11832v3","updated":"2026-01-07T13:08:34Z","published":"2025-07-16T01:39:32Z","title":"ILID: Native Script Language Identification for Indian Languages","summary":"The language identification task is a crucial fundamental step in NLP. Often it serves as a pre-processing step for widely used NLP applications such as multilingual machine translation, information retrieval, question and answering, and text summarization. The core challenge of language identification lies in distinguishing languages in noisy, short, and code-mixed environments. This becomes even harder in case of diverse Indian languages that exhibit lexical and phonetic similarities, but have distinct differences. Many Indian languages share the same script, making the task even more challenging. Taking all these challenges into account, we develop and release a dataset of 250K sentences consisting of 23 languages including English and all 22 official Indian languages labeled with their language identifiers, where data in most languages are newly created. We also develop and release baseline models using state-of-the-art approaches in machine learning and fine-tuning pre-trained transformer models. Our models outperforms the state-of-the-art pre-trained transformer models for the language identification task. The dataset and the codes are available at https://yashingle-ai.github.io/ILID/ and in Huggingface open source libraries.","authors":["Yash Ingle","Pruthwik Mishra"],"pdf_url":"","comment":"10 pages, 1 figure, 6 tables"},{"id":"http://arxiv.org/abs/2601.03895v1","updated":"2026-01-07T13:04:52Z","published":"2026-01-07T13:04:52Z","title":"Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training","summary":"Group Relative Policy Optimization (GRPO) has emerged as a popular algorithm for reinforcement learning with large language models (LLMs). However, upon analyzing its clipping mechanism, we argue that it is suboptimal in certain scenarios. With appropriate modifications, GRPO can be significantly enhanced to improve both flexibility and generalization. To this end, we propose Adaptive-Boundary-Clipping GRPO (ABC-GRPO), an asymmetric and adaptive refinement of the original GRPO framework. We demonstrate that ABC-GRPO achieves superior performance over standard GRPO on mathematical reasoning tasks using the Qwen3 LLMs. Moreover, ABC-GRPO maintains substantially higher entropy throughout training, thereby preserving the model's exploration capacity and mitigating premature convergence. The implementation code is available online to ease reproducibility https://github.com/chi2liu/ABC-GRPO.","authors":["Chi Liu","Xin Chen"],"pdf_url":"","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.18484v2","updated":"2026-01-07T12:57:26Z","published":"2025-03-24T09:38:37Z","title":"PM4Bench: Benchmarking Large Vision-Language Models with Parallel Multilingual Multi-Modal Multi-task Corpus","summary":"While Large Vision-Language Models (LVLMs) demonstrate promising multilingual capabilities, their evaluation is currently hindered by two critical limitations: (1) the use of non-parallel corpora, which conflates inherent language capability gaps with dataset artifacts, precluding a fair assessment of cross-lingual alignment; and (2) disjointed multimodal inputs, which deviate from real-world scenarios where most texts are embedded within visual contexts. To address these challenges, we propose PM4Bench, the first Multilingual Multi-Modal Multi-task Benchmark constructed on a strictly parallel corpus across 10 languages. By eliminating content divergence, our benchmark enables a fair comparison of model capabilities across different languages. We also introduce a vision setting where textual queries are visually fused into images, compelling models to jointly \"see,\" \"read,\" and \"think\". Extensive evaluation of 10 LVLMs uncover a substantial performance drop in the Vision setting compared to standard inputs. Further analysis reveals that OCR capability is not only a general bottleneck but also contributes to cross-lingual performance disparities, suggesting that improving multilingual OCR is essential for advancing LVLM performance. We will release PM4Bench at https://github.com/opendatalab/PM4Bench .","authors":["Junyuan Gao","Jiahe Song","Jiang Wu","Runchuan Zhu","Guanlin Shen","Shasha Wang","Xingjian Wei","Haote Yang","Songyang Zhang","Weijia Li","Bin Wang","Dahua Lin","Lijun Wu","Conghui He"],"pdf_url":"","comment":"Equal contribution: Junyuan Gao, Jiahe Song, Jiang Wu; Corresponding author: Conghui He"},{"id":"http://arxiv.org/abs/2601.03874v1","updated":"2026-01-07T12:39:31Z","published":"2026-01-07T12:39:31Z","title":"Evaluating Small Decoder-Only Language Models for Grammar Correction and Text Simplification","summary":"Large language models have become extremely popular recently due to their ability to achieve strong performance on a variety of tasks, such as text generation and rewriting, but their size and computation cost make them difficult to access, deploy, and secure in many settings. This paper investigates whether small, decoder-only language models can provide an efficient alternative for the tasks of grammar correction and text simplification. The experiments in this paper focus on testing small language models out of the box, fine-tuned, and run sequentially on the JFLEG and ASSET datasets using established metrics. The results show that while SLMs may learn certain behaviors well, their performance remains below strong baselines and current LLMs. The results also show that SLMs struggle with retaining meaning and hallucinations. These findings suggest that despite their efficiency advantages, current SLMs are not yet competitive enough with modern LLMs for rewriting, and further advances in training are required for SLMs to close the performance gap between them and today's LLMs.","authors":["Anthony Lamelas"],"pdf_url":"","comment":"9 pages, 12 figures"},{"id":"http://arxiv.org/abs/2601.03872v1","updated":"2026-01-07T12:38:33Z","published":"2026-01-07T12:38:33Z","title":"Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning","summary":"The integration of large language models (LLMs) with external tools has significantly expanded the capabilities of AI agents. However, as the diversity of both LLMs and tools increases, selecting the optimal model-tool combination becomes a high-dimensional optimization challenge. Existing approaches often rely on a single model or fixed tool-calling logic, failing to exploit the performance variations across heterogeneous model-tool pairs. In this paper, we present ATLAS (Adaptive Tool-LLM Alignment and Synergistic Invocation), a dual-path framework for dynamic tool usage in cross-domain complex reasoning. ATLAS operates via a dual-path approach: (1) \\textbf{training-free cluster-based routing} that exploits empirical priors for domain-specific alignment, and (2) \\textbf{RL-based multi-step routing} that explores autonomous trajectories for out-of-distribution generalization. Extensive experiments across 15 benchmarks demonstrate that our method outperforms closed-source models like GPT-4o, surpassing existing routing methods on both in-distribution (+10.1%) and out-of-distribution (+13.1%) tasks. Furthermore, our framework shows significant gains in visual reasoning by orchestrating specialized multi-modal tools.","authors":["Jinyang Wu","Guocheng Zhai","Ruihan Jin","Jiahao Yuan","Yuhao Shen","Shuai Zhang","Zhengqi Wen","Jianhua Tao"],"pdf_url":"","comment":null}],"computadora Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2601.04194v1","updated":"2026-01-07T18:59:40Z","published":"2026-01-07T18:59:40Z","title":"Choreographing a World of Dynamic Objects","summary":"Dynamic objects in our physical 4D (3D + time) world are constantly evolving, deforming, and interacting with other objects, leading to diverse 4D scene dynamics. In this paper, we present a universal generative pipeline, CHORD, for CHOReographing Dynamic objects and scenes and synthesizing this type of phenomena. Traditional rule-based graphics pipelines to create these dynamics are based on category-specific heuristics, yet are labor-intensive and not scalable. Recent learning-based methods typically demand large-scale datasets, which may not cover all object categories in interest. Our approach instead inherits the universality from the video generative models by proposing a distillation-based pipeline to extract the rich Lagrangian motion information hidden in the Eulerian representations of 2D videos. Our method is universal, versatile, and category-agnostic. We demonstrate its effectiveness by conducting experiments to generate a diverse range of multi-body 4D dynamics, show its advantage compared to existing methods, and demonstrate its applicability in generating robotics manipulation policies. Project page: https://yanzhelyu.github.io/chord","authors":["Yanzhe Lyu","Chen Geng","Karthik Dharmarajan","Yunzhi Zhang","Hadi Alzayer","Shangzhe Wu","Jiajun Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04185v1","updated":"2026-01-07T18:51:51Z","published":"2026-01-07T18:51:51Z","title":"ImLoc: Revisiting Visual Localization with Image-based Representation","summary":"Existing visual localization methods are typically either 2D image-based, which are easy to build and maintain but limited in effective geometric reasoning, or 3D structure-based, which achieve high accuracy but require a centralized reconstruction and are difficult to update. In this work, we revisit visual localization with a 2D image-based representation and propose to augment each image with estimated depth maps to capture the geometric structure. Supported by the effective use of dense matchers, this representation is not only easy to build and maintain, but achieves highest accuracy in challenging conditions. With compact compression and a GPU-accelerated LO-RANSAC implementation, the whole pipeline is efficient in both storage and computation and allows for a flexible trade-off between accuracy and highest memory efficiency. Our method achieves a new state-of-the-art accuracy on various standard benchmarks and outperforms existing memory-efficient methods at comparable map sizes. Code will be available at https://github.com/cvg/Hierarchical-Localization.","authors":["Xudong Jiang","Fangjinhua Wang","Silvano Galliani","Christoph Vogel","Marc Pollefeys"],"pdf_url":"","comment":"Code will be available at https://github.com/cvg/Hierarchical-Localization"},{"id":"http://arxiv.org/abs/2412.04416v2","updated":"2026-01-07T18:33:05Z","published":"2024-12-05T18:42:29Z","title":"FedDUAL: A Dual-Strategy with Adaptive Loss and Dynamic Aggregation for Mitigating Data Heterogeneity in Federated Learning","summary":"Federated Learning (FL) marks a transformative approach to distributed model training by combining locally optimized models from various clients into a unified global model. While FL preserves data privacy by eliminating centralized storage, it encounters significant challenges such as performance degradation, slower convergence, and reduced robustness of the global model due to the heterogeneity in client data distributions. Among the various forms of data heterogeneity, label skew emerges as a particularly formidable and prevalent issue, especially in domains such as image classification. To address these challenges, we begin with comprehensive experiments to pinpoint the underlying issues in the FL training process. Based on our findings, we then introduce an innovative dual-strategy approach designed to effectively resolve these issues. First, we introduce an adaptive loss function for client-side training, meticulously crafted to preserve previously acquired knowledge while maintaining an optimal equilibrium between local optimization and global model coherence. Secondly, we develop a dynamic aggregation strategy for aggregating client models at the server. This approach adapts to each client's unique learning patterns, effectively addressing the challenges of diverse data across the network. Our comprehensive evaluation, conducted across three diverse real-world datasets, coupled with theoretical convergence guarantees, demonstrates the superior efficacy of our method compared to several established state-of-the-art approaches.","authors":["Pranab Sahoo","Ashutosh Tripathi","Sriparna Saha","Samrat Mondal"],"pdf_url":"","comment":"Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2601.04163v1","updated":"2026-01-07T18:24:12Z","published":"2026-01-07T18:24:12Z","title":"Scanner-Induced Domain Shifts Undermine the Robustness of Pathology Foundation Models","summary":"Pathology foundation models (PFMs) have become central to computational pathology, aiming to offer general encoders for feature extraction from whole-slide images (WSIs). Despite strong benchmark performance, PFM robustness to real-world technical domain shifts, such as variability from whole-slide scanner devices, remains poorly understood. We systematically evaluated the robustness of 14 PFMs to scanner-induced variability, including state-of-the-art models, earlier self-supervised models, and a baseline trained on natural images. Using a multiscanner dataset of 384 breast cancer WSIs scanned on five devices, we isolated scanner effects independently from biological and laboratory confounders. Robustness is assessed via complementary unsupervised embedding analyses and a set of clinicopathological supervised prediction tasks. Our results demonstrate that current PFMs are not invariant to scanner-induced domain shifts. Most models encode pronounced scanner-specific variability in their embedding spaces. While AUC often remains stable, this masks a critical failure mode: scanner variability systematically alters the embedding space and impacts calibration of downstream model predictions, resulting in scanner-dependent bias that can impact reliability in clinical use cases. We further show that robustness is not a simple function of training data scale, model size, or model recency. None of the models provided reliable robustness against scanner-induced variability. While the models trained on the most diverse data, here represented by vision-language models, appear to have an advantage with respect to robustness, they underperformed on downstream supervised tasks. We conclude that development and evaluation of PFMs requires moving beyond accuracy-centric benchmarks toward explicit evaluation and optimisation of embedding stability and calibration under realistic acquisition variability.","authors":["Erik Thiringer","Fredrik K. Gustafsson","Kajsa Ledesma Eriksson","Mattias Rantalainen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04159v1","updated":"2026-01-07T18:15:09Z","published":"2026-01-07T18:15:09Z","title":"ToTMNet: FFT-Accelerated Toeplitz Temporal Mixing Network for Lightweight Remote Photoplethysmography","summary":"Remote photoplethysmography (rPPG) estimates a blood volume pulse (BVP) waveform from facial videos captured by commodity cameras. Although recent deep models improve robustness compared to classical signal-processing approaches, many methods increase computational cost and parameter count, and attention-based temporal modeling introduces quadratic scaling with respect to the temporal length. This paper proposes ToTMNet, a lightweight rPPG architecture that replaces temporal attention with an FFT-accelerated Toeplitz temporal mixing layer. The Toeplitz operator provides full-sequence temporal receptive field using a linear number of parameters in the clip length and can be applied in near-linear time using circulant embedding and FFT-based convolution. ToTMNet integrates the global Toeplitz temporal operator into a compact gated temporal mixer that combines a local depthwise temporal convolution branch with gated global Toeplitz mixing, enabling efficient long-range temporal filtering while only having 63k parameters. Experiments on two datasets, UBFC-rPPG (real videos) and SCAMPS (synthetic videos), show that ToTMNet achieves strong heart-rate estimation accuracy with a compact design. On UBFC-rPPG intra-dataset evaluation, ToTMNet reaches 1.055 bpm MAE with Pearson correlation 0.996. In a synthetic-to-real setting (SCAMPS to UBFC-rPPG), ToTMNet reaches 1.582 bpm MAE with Pearson correlation 0.994. Ablation results confirm that the gating mechanism is important for effectively using global Toeplitz mixing, especially under domain shift. The main limitation of this preprint study is the use of only two datasets; nevertheless, the results indicate that Toeplitz-structured temporal mixing is a practical and efficient alternative to attention for rPPG.","authors":["Vladimir Frants","Sos Agaian","Karen Panetta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04153v1","updated":"2026-01-07T18:05:08Z","published":"2026-01-07T18:05:08Z","title":"Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning","summary":"Direct Preference Optimization (DPO) has recently improved Text-to-Video (T2V) generation by enhancing visual fidelity and text alignment. However, current methods rely on non-differentiable preference signals from human annotations or learned reward models. This reliance makes training label-intensive, bias-prone, and easy-to-game, which often triggers reward hacking and unstable training. We propose Diffusion-DRF, a differentiable reward flow for fine-tuning video diffusion models using a frozen, off-the-shelf Vision-Language Model (VLM) as a training-free critic. Diffusion-DRF directly backpropagates VLM feedback through the diffusion denoising chain, converting logit-level responses into token-aware gradients for optimization. We propose an automated, aspect-structured prompting pipeline to obtain reliable multi-dimensional VLM feedback, while gradient checkpointing enables efficient updates through the final denoising steps. Diffusion-DRF improves video quality and semantic alignment while mitigating reward hacking and collapse -- without additional reward models or preference datasets. It is model-agnostic and readily generalizes to other diffusion-based generative tasks.","authors":["Yifan Wang","Yanyu Li","Sergey Tulyakov","Yun Fu","Anil Kag"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04151v1","updated":"2026-01-07T18:03:45Z","published":"2026-01-07T18:03:45Z","title":"Klear: Unified Multi-Task Audio-Video Joint Generation","summary":"Audio-video joint generation has progressed rapidly, yet substantial challenges still remain. Non-commercial approaches still suffer audio-visual asynchrony, poor lip-speech alignment, and unimodal degradation, which can be stemmed from weak audio-visual correspondence modeling, limited generalization, and scarce high-quality dense-caption data. To address these issues, we introduce Klear and delve into three axes--model architecture, training strategy, and data curation. Architecturally, we adopt a single-tower design with unified DiT blocks and an Omni-Full Attention mechanism, achieving tight audio-visual alignment and strong scalability. Training-wise, we adopt a progressive multitask regime--random modality masking to joint optimization across tasks, and a multistage curriculum, yielding robust representations, strengthening A-V aligned world knowledge, and preventing unimodal collapse. For datasets, we present the first large-scale audio-video dataset with dense captions, and introduce a novel automated data-construction pipeline which annotates and filters millions of diverse, high-quality, strictly aligned audio-video-caption triplets. Building on this, Klear scales to large datasets, delivering high-fidelity, semantically and temporally aligned, instruction-following generation in both joint and unimodal settings while generalizing robustly to out-of-distribution scenarios. Across tasks, it substantially outperforms prior methods by a large margin and achieves performance comparable to Veo 3, offering a unified, scalable path toward next-generation audio-video synthesis.","authors":["Jun Wang","Chunyu Qiang","Yuxin Guo","Yiran Wang","Xijuan Zeng","Chen Zhang","Pengfei Wan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04137v1","updated":"2026-01-07T17:50:37Z","published":"2026-01-07T17:50:37Z","title":"Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test","summary":"As world models gain momentum in Embodied AI, an increasing number of works explore using video foundation models as predictive world models for downstream embodied tasks like 3D prediction or interactive generation. However, before exploring these downstream tasks, video foundation models still have two critical questions unanswered: (1) whether their generative generalization is sufficient to maintain perceptual fidelity in the eyes of human observers, and (2) whether they are robust enough to serve as a universal prior for real-world embodied agents. To provide a standardized framework for answering these questions, we introduce the Embodied Turing Test benchmark: WoW-World-Eval (Wow,wo,val). Building upon 609 robot manipulation data, Wow-wo-val examines five core abilities, including perception, planning, prediction, generalization, and execution. We propose a comprehensive evaluation protocol with 22 metrics to assess the models' generation ability, which achieves a high Pearson Correlation between the overall score and human preference (>0.93) and establishes a reliable foundation for the Human Turing Test. On Wow-wo-val, models achieve only 17.27 on long-horizon planning and at best 68.02 on physical consistency, indicating limited spatiotemporal consistency and physical reasoning. For the Inverse Dynamic Model Turing Test, we first use an IDM to evaluate the video foundation models' execution accuracy in the real world. However, most models collapse to $\\approx$ 0% success, while WoW maintains a 40.74% success rate. These findings point to a noticeable gap between the generated videos and the real world, highlighting the urgency and necessity of benchmarking World Model in Embodied AI.","authors":["Chun-Kai Fan","Xiaowei Chi","Xiaozhu Ju","Hao Li","Yong Bao","Yu-Kai Wang","Lizhang Chen","Zhiyuan Jiang","Kuangzhi Ge","Ying Li","Weishi Mi","Qingpo Wuwu","Peidong Jia","Yulin Luo","Kevin Zhang","Zhiyuan Qin","Yong Dai","Sirui Han","Yike Guo","Shanghang Zhang","Jian Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04127v1","updated":"2026-01-07T17:41:11Z","published":"2026-01-07T17:41:11Z","title":"Pixel-Wise Multimodal Contrastive Learning for Remote Sensing Images","summary":"Satellites continuously generate massive volumes of data, particularly for Earth observation, including satellite image time series (SITS). However, most deep learning models are designed to process either entire images or complete time series sequences to extract meaningful features for downstream tasks. In this study, we propose a novel multimodal approach that leverages pixel-wise two-dimensional (2D) representations to encode visual property variations from SITS more effectively. Specifically, we generate recurrence plots from pixel-based vegetation index time series (NDVI, EVI, and SAVI) as an alternative to using raw pixel values, creating more informative representations. Additionally, we introduce PIxel-wise Multimodal Contrastive (PIMC), a new multimodal self-supervision approach that produces effective encoders based on two-dimensional pixel time series representations and remote sensing imagery (RSI). To validate our approach, we assess its performance on three downstream tasks: pixel-level forecasting and classification using the PASTIS dataset, and land cover classification on the EuroSAT dataset. Moreover, we compare our results to state-of-the-art (SOTA) methods on all downstream tasks. Our experimental results show that the use of 2D representations significantly enhances feature extraction from SITS, while contrastive learning improves the quality of representations for both pixel time series and RSI. These findings suggest that our multimodal method outperforms existing models in various Earth observation tasks, establishing it as a robust self-supervision framework for processing both SITS and RSI. Code avaliable on","authors":["Leandro Stival","Ricardo da Silva Torres","Helio Pedrini"],"pdf_url":"","comment":"21 pages, 9 Figures"},{"id":"http://arxiv.org/abs/2601.04126v1","updated":"2026-01-07T17:40:08Z","published":"2026-01-07T17:40:08Z","title":"InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training","summary":"GUI agents that interact with graphical interfaces on behalf of users represent a promising direction for practical AI assistants. However, training such agents is hindered by the scarcity of suitable environments. We present InfiniteWeb, a system that automatically generates functional web environments at scale for GUI agent training. While LLMs perform well on generating a single webpage, building a realistic and functional website with many interconnected pages faces challenges. We address these challenges through unified specification, task-centric test-driven development, and a combination of website seed with reference design image to ensure diversity. Our system also generates verifiable task evaluators enabling dense reward signals for reinforcement learning. Experiments show that InfiniteWeb surpasses commercial coding agents at realistic website construction, and GUI agents trained on our generated environments achieve significant performance improvements on OSWorld and Online-Mind2Web, demonstrating the effectiveness of proposed system.","authors":["Ziyun Zhang","Zezhou Wang","Xiaoyi Zhang","Zongyu Guo","Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2601.04121v1","updated":"2026-01-07T17:32:24Z","published":"2026-01-07T17:32:24Z","title":"MORPHFED: Federated Learning for Cross-institutional Blood Morphology Analysis","summary":"Automated blood morphology analysis can support hematological diagnostics in low- and middle-income countries (LMICs) but remains sensitive to dataset shifts from staining variability, imaging differences, and rare morphologies. Building centralized datasets to capture this diversity is often infeasible due to privacy regulations and data-sharing restrictions. We introduce a federated learning framework for white blood cell morphology analysis that enables collaborative training across institutions without exchanging training data. Using blood films from multiple clinical sites, our federated models learn robust, domain-invariant representations while preserving complete data privacy. Evaluations across convolutional and transformer-based architectures show that federated training achieves strong cross-site performance and improved generalization to unseen institutions compared to centralized training. These findings highlight federated learning as a practical and privacy-preserving approach for developing equitable, scalable, and generalizable medical imaging AI in resource-limited healthcare environments.","authors":["Gabriel Ansah","Eden Ruffell","Delmiro Fernandez-Reyes","Petru Manescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20617v2","updated":"2026-01-07T17:31:29Z","published":"2025-12-23T18:59:46Z","title":"SpatialTree: How Spatial Abilities Branch Out in MLLMs","summary":"Cognitive science suggests that spatial ability develops progressively-from perception to reasoning and interaction. Yet in multimodal LLMs (MLLMs), this hierarchy remains poorly understood, as most studies focus on a narrow set of tasks. We introduce SpatialTree, a cognitive-science-inspired hierarchy that organizes spatial abilities into four levels: low-level perception (L1), mental mapping (L2), simulation (L3), and agentic competence (L4). Based on this taxonomy, we construct the first capability-centric hierarchical benchmark, thoroughly evaluating mainstream MLLMs across 27 sub-abilities. The evaluation results reveal a clear structure: L1 skills are largely orthogonal, whereas higher-level skills are strongly correlated, indicating increasing interdependency. Through targeted supervised fine-tuning, we uncover a surprising transfer dynamic-negative transfer within L1, but strong cross-level transfer from low- to high-level abilities with notable synergy. Finally, we explore how to improve the entire hierarchy. We find that naive RL that encourages extensive \"thinking\" is unreliable: it helps complex reasoning but hurts intuitive perception. We propose a simple auto-think strategy that suppresses unnecessary deliberation, enabling RL to consistently improve performance across all levels. By building SpatialTree, we provide a proof-of-concept framework for understanding and systematically scaling spatial abilities in MLLMs.","authors":["Yuxi Xiao","Longfei Li","Shen Yan","Xinhang Liu","Sida Peng","Yunchao Wei","Xiaowei Zhou","Bingyi Kang"],"pdf_url":"","comment":"webpage: https://spatialtree.github.io/"},{"id":"http://arxiv.org/abs/2601.04118v1","updated":"2026-01-07T17:26:41Z","published":"2026-01-07T17:26:41Z","title":"GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning","summary":"The evolution of Remote Sensing Vision-Language Models(RS-VLMs) emphasizes the importance of transitioning from perception-centric recognition toward high-level deductive reasoning to enhance cognitive reliability in complex spatial tasks. However, current models often suffer from logical hallucinations, where correct answers are derived from flawed reasoning chains or rely on positional shortcuts rather than spatial logic. This decoupling undermines reliability in strategic spatial decision-making. To address this, we present GeoReason, a framework designed to synchronize internal thinking with final decisions. We first construct GeoReason-Bench, a logic-driven dataset containing 4,000 reasoning trajectories synthesized from geometric primitives and expert knowledge. We then formulate a two-stage training strategy: (1) Supervised Knowledge Initialization to equip the model with reasoning syntax and domain expertise, and (2) Consistency-Aware Reinforcement Learning to refine deductive reliability. This second stage integrates a novel Logical Consistency Reward, which penalizes logical drift via an option permutation strategy to anchor decisions in verifiable reasoning traces. Experimental results demonstrate that our framework significantly enhances the cognitive reliability and interpretability of RS-VLMs, achieving state-of-the-art performance compared to other advanced methods.","authors":["Wenshuai Li","Xiantai Xiang","Zixiao Wen","Guangyao Zhou","Ben Niu","Feng Wang","Lijia Huang","Qiantong Wang","Yuxin Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16942v2","updated":"2026-01-07T16:58:00Z","published":"2025-04-10T20:16:02Z","title":"S2Vec: Self-Supervised Geospatial Embeddings for the Built Environment","summary":"Scalable general-purpose representations of the built environment are crucial for geospatial artificial intelligence applications. This paper introduces S2Vec, a novel self-supervised framework for learning such geospatial embeddings. S2Vec uses the S2 Geometry library to partition large areas into discrete S2 cells, rasterizes built environment feature vectors within cells as images, and applies masked autoencoding on these rasterized images to encode the feature vectors. This approach yields task-agnostic embeddings that capture local feature characteristics and broader spatial relationships. We evaluate S2Vec on several large-scale geospatial prediction tasks, both random train/test splits (interpolation) and zero-shot geographic adaptation (extrapolation). Our experiments show S2Vec's competitive performance against several baselines on socioeconomic tasks, especially the geographic adaptation variant, with room for improvement on environmental tasks. We also explore combining S2Vec embeddings with image-based embeddings downstream, showing that such multimodal fusion can often improve performance. Our findings highlight how S2Vec can learn effective general-purpose geospatial representations of the built environment features it is provided, and how it can complement other data modalities in geospatial artificial intelligence.","authors":["Shushman Choudhury","Elad Aharoni","Chandrakumari Suvarna","Iveel Tsogsuren","Abdul Rahman Kreidieh","Chun-Ta Lu","Neha Arora"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04090v1","updated":"2026-01-07T16:57:30Z","published":"2026-01-07T16:57:30Z","title":"Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction","summary":"We present Gen3R, a method that bridges the strong priors of foundational reconstruction models and video diffusion models for scene-level 3D generation. We repurpose the VGGT reconstruction model to produce geometric latents by training an adapter on its tokens, which are regularized to align with the appearance latents of pre-trained video diffusion models. By jointly generating these disentangled yet aligned latents, Gen3R produces both RGB videos and corresponding 3D geometry, including camera poses, depth maps, and global point clouds. Experiments demonstrate that our approach achieves state-of-the-art results in single- and multi-image conditioned 3D scene generation. Additionally, our method can enhance the robustness of reconstruction by leveraging generative priors, demonstrating the mutual benefit of tightly coupling reconstruction and generative models.","authors":["Jiaxin Huang","Yuanbo Yang","Bangbang Yang","Lin Ma","Yuewen Ma","Yiyi Liao"],"pdf_url":"","comment":"Project page: https://xdimlab.github.io/Gen3R/"},{"id":"http://arxiv.org/abs/2601.04073v1","updated":"2026-01-07T16:39:34Z","published":"2026-01-07T16:39:34Z","title":"Analyzing Reasoning Consistency in Large Multimodal Models under Cross-Modal Conflicts","summary":"Large Multimodal Models (LMMs) have demonstrated impressive capabilities in video reasoning via Chain-of-Thought (CoT). However, the robustness of their reasoning chains remains questionable. In this paper, we identify a critical failure mode termed textual inertia, where once a textual hallucination occurs in the thinking process, models tend to blindly adhere to the erroneous text while neglecting conflicting visual evidence. To systematically investigate this, we propose the LogicGraph Perturbation Protocol that structurally injects perturbations into the reasoning chains of diverse LMMs spanning both native reasoning architectures and prompt-driven paradigms to evaluate their self-reflection capabilities. The results reveal that models successfully self-correct in less than 10% of cases and predominantly succumb to blind textual error propagation. To mitigate this, we introduce Active Visual-Context Refinement, a training-free inference paradigm which orchestrates an active visual re-grounding mechanism to enforce fine-grained verification coupled with an adaptive context refinement strategy to summarize and denoise the reasoning history. Experiments demonstrate that our approach significantly stifles hallucination propagation and enhances reasoning robustness.","authors":["Zhihao Zhu","Jiafeng Liang","Shixin Jiang","Jinlan Fu","Ming Liu","Guanglu Sun","See-Kiong Ng","Bing Qin"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2510.17347v2","updated":"2026-01-07T16:35:09Z","published":"2025-10-20T09:45:13Z","title":"Semantic-E2VID: a Semantic-Enriched Paradigm for Event-to-Video Reconstruction","summary":"Event cameras provide a promising sensing modality for high-speed and high-dynamic-range vision by asynchronously capturing brightness changes. A fundamental task in event-based vision is event-to-video (E2V) reconstruction, which aims to recover intensity videos from event streams. Most existing E2V approaches formulate reconstruction as a temporal--spatial signal recovery problem, relying on temporal aggregation and spatial feature learning to infer intensity frames. While effective to some extent, this formulation overlooks a critical limitation of event data: due to the change-driven sensing mechanism, event streams are inherently semantically under-determined, lacking object-level structure and contextual information that are essential for faithful reconstruction. In this work, we revisit E2V from a semantic perspective and argue that effective reconstruction requires going beyond temporal and spatial modeling to explicitly account for missing semantic information. Based on this insight, we propose \\textit{Semantic-E2VID}, a semantic-enriched end-to-end E2V framework that reformulates reconstruction as a process of semantic learning, fusing and decoding. Our approach first performs semantic abstraction by bridging event representations with semantics extracted from a pretrained Segment Anything Model (SAM), while avoiding modality-induced feature drift. The learned semantics are then fused into the event latent space in a representation-compatible manner, enabling event features to capture object-level structure and contextual cues. Furthermore, semantic-aware supervision is introduced to explicitly guide the reconstruction process toward semantically meaningful regions, complementing conventional pixel-level and temporal objectives. Extensive experiments on six public benchmarks demonstrate that Semantic-E2VID consistently outperforms state-of-the-art E2V methods.","authors":["Jingqian Wu","Yunbo Jia","Shengpeng Xu","Edmund Y. Lam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04068v1","updated":"2026-01-07T16:32:17Z","published":"2026-01-07T16:32:17Z","title":"Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models","summary":"Aligning text-to-video diffusion models with human preferences is crucial for generating high-quality videos. Existing Direct Preference Otimization (DPO) methods rely on multi-sample ranking and task-specific critic models, which is inefficient and often yields ambiguous global supervision. To address these limitations, we propose LocalDPO, a novel post-training framework that constructs localized preference pairs from real videos and optimizes alignment at the spatio-temporal region level. We design an automated pipeline to efficiently collect preference pair data that generates preference pairs with a single inference per prompt, eliminating the need for external critic models or manual annotation. Specifically, we treat high-quality real videos as positive samples and generate corresponding negatives by locally corrupting them with random spatio-temporal masks and restoring only the masked regions using the frozen base model. During training, we introduce a region-aware DPO loss that restricts preference learning to corrupted areas for rapid convergence. Experiments on Wan2.1 and CogVideoX demonstrate that LocalDPO consistently improves video fidelity, temporal coherence and human preference scores over other post-training approaches, establishing a more efficient and fine-grained paradigm for video generator alignment.","authors":["Zitong Huang","Kaidong Zhang","Yukang Ding","Chao Gao","Rui Ding","Ying Chen","Wangmeng Zuo"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2601.04065v1","updated":"2026-01-07T16:29:52Z","published":"2026-01-07T16:29:52Z","title":"Unsupervised Modular Adaptive Region Growing and RegionMix Classification for Wind Turbine Segmentation","summary":"Reliable operation of wind turbines requires frequent inspections, as even minor surface damages can degrade aerodynamic performance, reduce energy output, and accelerate blade wear. Central to automating these inspections is the accurate segmentation of turbine blades from visual data. This task is traditionally addressed through dense, pixel-wise deep learning models. However, such methods demand extensive annotated datasets, posing scalability challenges. In this work, we introduce an annotation-efficient segmentation approach that reframes the pixel-level task into a binary region classification problem. Image regions are generated using a fully unsupervised, interpretable Modular Adaptive Region Growing technique, guided by image-specific Adaptive Thresholding and enhanced by a Region Merging process that consolidates fragmented areas into coherent segments. To improve generalization and classification robustness, we introduce RegionMix, an augmentation strategy that synthesizes new training samples by combining distinct regions. Our framework demonstrates state-of-the-art segmentation accuracy and strong cross-site generalization by consistently segmenting turbine blades across distinct windfarms.","authors":["Raül Pérez-Gonzalo","Riccardo Magro","Andreas Espersen","Antonio Agudo"],"pdf_url":"","comment":"Accepted to WACV 2026"},{"id":"http://arxiv.org/abs/2601.04061v1","updated":"2026-01-07T16:26:33Z","published":"2026-01-07T16:26:33Z","title":"CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos","summary":"Generalist Vision-Language-Action models are currently hindered by the scarcity of robotic data compared to the abundance of human video demonstrations. Existing Latent Action Models attempt to leverage video data but often suffer from visual entanglement, capturing noise rather than manipulation skills. To address this, we propose Contrastive Latent Action Pretraining (CLAP), a framework that aligns the visual latent space from videos with a proprioceptive latent space from robot trajectories. By employing contrastive learning, CLAP maps video transitions onto a quantized, physically executable codebook. Building on this representation, we introduce a dual-formulation VLA framework offering both CLAP-NTP, an autoregressive model excelling at instruction following and object generalization, and CLAP-RF, a Rectified Flow-based policy designed for high-frequency, precise manipulation. Furthermore, we propose a Knowledge Matching (KM) regularization strategy to mitigate catastrophic forgetting during fine-tuning. Extensive experiments demonstrate that CLAP significantly outperforms strong baselines, enabling the effective transfer of skills from human videos to robotic execution. Project page: https://lin-shan.com/CLAP/.","authors":["Chubin Zhang","Jianan Wang","Zifeng Gao","Yue Su","Tianru Dai","Cai Zhou","Jiwen Lu","Yansong Tang"],"pdf_url":"","comment":"Project page: https://lin-shan.com/CLAP/"},{"id":"http://arxiv.org/abs/2510.08377v3","updated":"2026-01-07T16:04:47Z","published":"2025-10-09T16:01:30Z","title":"UniVideo: Unified Understanding, Generation, and Editing for Videos","summary":"Unified multimodal models have shown promising results in multimodal content generation and editing but remain largely limited to the image domain. In this work, we present UniVideo, a versatile framework that extends unified modeling to the video domain. UniVideo adopts a dual-stream design, combining a Multimodal Large Language Model (MLLM) for instruction understanding with a Multimodal DiT (MMDiT) for video generation. This design preserves the MLLM's original text generation capabilities, enables accurate interpretation of complex multimodal instructions, and maintains visual consistency in the generated content. Built on this architecture, UniVideo unifies diverse video generation and editing tasks under a single multimodal instruction paradigm and is jointly trained across them. Extensive experiments demonstrate that UniVideo matches or surpasses state-of-the-art task-specific baselines in text/image-to-video generation, in-context video generation and in-context video editing. Notably, the unified design of UniVideo enables two forms of generalization. First, UniVideo supports task composition, such as combining editing with style transfer, by integrating multiple capabilities within a single instruction. Second, even without explicit training on free-form video editing, UniVideo transfers its editing capability from large-scale image editing data to this setting, handling unseen instructions such as changing the environment or altering materials within a video. Beyond these core capabilities, UniVideo also supports visual-prompt-based video generation, where the MLLM interprets visual prompts and guides the MMDiT during synthesis. To foster future research, we released our model and code.","authors":["Cong Wei","Quande Liu","Zixuan Ye","Qiulin Wang","Xintao Wang","Pengfei Wan","Kun Gai","Wenhu Chen"],"pdf_url":"","comment":"Project Website https://congwei1230.github.io/UniVideo/"},{"id":"http://arxiv.org/abs/2601.04033v1","updated":"2026-01-07T15:47:14Z","published":"2026-01-07T15:47:14Z","title":"Thinking with Frames: Generative Video Distortion Evaluation via Frame Reward Model","summary":"Recent advances in video reward models and post-training strategies have improved text-to-video (T2V) generation. While these models typically assess visual quality, motion quality, and text alignment, they often overlook key structural distortions, such as abnormal object appearances and interactions, which can degrade the overall quality of the generative video. To address this gap, we introduce REACT, a frame-level reward model designed specifically for structural distortions evaluation in generative videos. REACT assigns point-wise scores and attribution labels by reasoning over video frames, focusing on recognizing distortions. To support this, we construct a large-scale human preference dataset, annotated based on our proposed taxonomy of structural distortions, and generate additional data using a efficient Chain-of-Thought (CoT) synthesis pipeline. REACT is trained with a two-stage framework: ((1) supervised fine-tuning with masked loss for domain knowledge injection, followed by (2) reinforcement learning with Group Relative Policy Optimization (GRPO) and pairwise rewards to enhance reasoning capability and align output scores with human preferences. During inference, a dynamic sampling mechanism is introduced to focus on frames most likely to exhibit distortion. We also present REACT-Bench, a benchmark for generative video distortion evaluation. Experimental results demonstrate that REACT complements existing reward models in assessing structutal distortion, achieving both accurate quantitative evaluations and interpretable attribution analysis.","authors":["Yuan Wang","Borui Liao","Huijuan Huang","Jinda Lu","Ouxiang Li","Kuien Liu","Meng Wang","Xiang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01513v2","updated":"2026-01-07T15:36:31Z","published":"2026-01-04T12:46:35Z","title":"FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation","summary":"Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.","authors":["Gen Li","Peiyu Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04005v1","updated":"2026-01-07T15:15:30Z","published":"2026-01-07T15:15:30Z","title":"Padé Neurons for Efficient Neural Models","summary":"Neural networks commonly employ the McCulloch-Pitts neuron model, which is a linear model followed by a point-wise non-linear activation. Various researchers have already advanced inherently non-linear neuron models, such as quadratic neurons, generalized operational neurons, generative neurons, and super neurons, which offer stronger non-linearity compared to point-wise activation functions. In this paper, we introduce a novel and better non-linear neuron model called Padé neurons (Paons), inspired by Padé approximants. Paons offer several advantages, such as diversity of non-linearity, since each Paon learns a different non-linear function of its inputs, and layer efficiency, since Paons provide stronger non-linearity in much fewer layers compared to piecewise linear approximation. Furthermore, Paons include all previously proposed neuron models as special cases, thus any neuron model in any network can be replaced by Paons. We note that there has been a proposal to employ the Padé approximation as a generalized point-wise activation function, which is fundamentally different from our model. To validate the efficacy of Paons, in our experiments, we replace classic neurons in some well-known neural image super-resolution, compression, and classification models based on the ResNet architecture with Paons. Our comprehensive experimental results and analyses demonstrate that neural models built by Paons provide better or equal performance than their classic counterparts with a smaller number of layers. The PyTorch implementation code for Paon is open-sourced at https://github.com/onur-keles/Paon.","authors":["Onur Keleş","A. Murat Tekalp"],"pdf_url":"","comment":"Accepted for Publication in IEEE TRANSACTIONS ON IMAGE PROCESSING; 13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2601.03993v1","updated":"2026-01-07T15:04:24Z","published":"2026-01-07T15:04:24Z","title":"PosterVerse: A Full-Workflow Framework for Commercial-Grade Poster Generation with HTML-Based Scalable Typography","summary":"Commercial-grade poster design demands the seamless integration of aesthetic appeal with precise, informative content delivery. Current automated poster generation systems face significant limitations, including incomplete design workflows, poor text rendering accuracy, and insufficient flexibility for commercial applications. To address these challenges, we propose PosterVerse, a full-workflow, commercial-grade poster generation method that seamlessly automates the entire design process while delivering high-density and scalable text rendering. PosterVerse replicates professional design through three key stages: (1) blueprint creation using fine-tuned LLMs to extract key design elements from user requirements, (2) graphical background generation via customized diffusion models to create visually appealing imagery, and (3) unified layout-text rendering with an MLLM-powered HTML engine to guarantee high text accuracy and flexible customization. In addition, we introduce PosterDNA, a commercial-grade, HTML-based dataset tailored for training and validating poster design models. To the best of our knowledge, PosterDNA is the first Chinese poster generation dataset to introduce HTML typography files, enabling scalable text rendering and fundamentally solving the challenges of rendering small and high-density text. Experimental results demonstrate that PosterVerse consistently produces commercial-grade posters with appealing visuals, accurate text alignment, and customizable layouts, making it a promising solution for automating commercial poster design. The code and model are available at https://github.com/wuhaer/PosterVerse.","authors":["Junle Liu","Peirong Zhang","Yuyi Zhang","Pengyu Yan","Hui Zhou","Xinyue Zhou","Fengjun Guo","Lianwen Jin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.11830v3","updated":"2026-01-07T14:58:44Z","published":"2025-05-17T04:34:32Z","title":"VISTA: Mitigating Semantic Inertia in Video-LLMs via Training-Free Dynamic Chain-of-Thought Routing","summary":"Recent advancements in Large Language Models have successfully transitioned towards System 2 reasoning, yet applying these paradigms to video understanding remains challenging. While prevailing research attributes failures in Video-LLMs to perceptual limitations, our empirical analysis reveals a cognitive misalignment termed Semantic Inertia, where models suppress valid visual evidence in favor of dominant language priors. To rectify this, we propose VISTA, a training-free framework designed to align perception with logical deduction. By dynamically routing inference paths and materializing implicit visual features into explicit textual anchors, our approach effectively counterbalances the influence of parametric knowledge. Furthermore, we incorporate a Latent Reasoning Consensus mechanism to mitigate stochastic hallucinations. VISTA showed outstanding results on a wide range of benchmarks, and outperforms its base model by 9.3% on Egochema and 5.6% on VideoEspresso, rivalling or even surpassing larger and proprietary models. Our codebase will be publicly available soon.","authors":["Hongbo Jin","Jiayu Ding","Siyi Xie","Guibo Luo","Ge Li"],"pdf_url":"","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2509.09631v3","updated":"2026-01-07T14:31:16Z","published":"2025-09-11T17:16:52Z","title":"DiFlow-TTS: Compact and Low-Latency Zero-Shot Text-to-Speech with Factorized Discrete Flow Matching","summary":"This paper introduces DiFlow-TTS, a novel zero-shot text-to-speech (TTS) system that employs discrete flow matching for generative speech modeling. We position this work as an entry point that may facilitate further advances in this research direction. Through extensive empirical evaluation, we analyze both the strengths and limitations of this approach across key aspects, including naturalness, expressive attributes, speaker identity, and inference latency. To this end, we leverage factorized speech representations and design a deterministic Phoneme-Content Mapper for modeling linguistic content, together with a Factorized Discrete Flow Denoiser that jointly models multiple discrete token streams corresponding to prosody and acoustics to capture expressive speech attributes. Experimental results demonstrate that DiFlow-TTS achieves strong performance across multiple metrics while maintaining a compact model size, up to 11.7 times smaller, and enabling low-latency inference that is up to 34 times faster than recent state-of-the-art baselines. Audio samples are available on our demo page: https://diflow-tts.github.io.","authors":["Ngoc-Son Nguyen","Thanh V. T. Tran","Hieu-Nghia Huynh-Nguyen","Truong-Son Hy","Van Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.08925v4","updated":"2026-01-07T14:29:09Z","published":"2024-10-11T15:50:31Z","title":"An Overview of Prototype Formulations for Interpretable Deep Learning","summary":"Prototypical part networks offer interpretable alternatives to black-box deep learning models by learning visual prototypes for classification. This work provides a comprehensive analysis of prototype formulations, comparing point-based and probabilistic approaches in both Euclidean and hyperspherical latent spaces.\n  We introduce HyperPG, a probabilistic prototype representation using Gaussian distributions on hyperspheres. Experiments on CUB-200-2011, Stanford Cars, and Oxford Flowers datasets show that hyperspherical prototypes outperform standard Euclidean formulations. Critically, hyperspherical prototypes maintain competitive performance under simplified training schemes, while Euclidean prototypes require extensive hyperparameter tuning.","authors":["Maximilian Xiling Li","Korbinian Franz Rudolf","Paul Mattes","Nils Blank","Rudolf Lioutikov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01457v2","updated":"2026-01-07T14:19:12Z","published":"2026-01-04T09:59:43Z","title":"Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation","summary":"Relative-depth foundation models transfer well, yet monocular metric depth remains ill-posed due to unidentifiable global scale and heightened domain-shift sensitivity. Under a frozen-backbone calibration setting, we recover metric depth via an image-specific affine transform in inverse depth and train only lightweight calibration heads while keeping the relative-depth backbone and the CLIP text encoder fixed. Since captions provide coarse but noisy scale cues that vary with phrasing and missing objects, we use language to predict an uncertainty-aware envelope that bounds feasible calibration parameters in an unconstrained space, rather than committing to a text-only point estimate. We then use pooled multi-scale frozen visual features to select an image-specific calibration within this envelope. During training, a closed-form least-squares oracle in inverse depth provides per-image supervision for learning the envelope and the selected calibration. Experiments on NYUv2 and KITTI improve in-domain accuracy, while zero-shot transfer to SUN-RGBD and DDAD demonstrates improved robustness over strong language-only baselines.","authors":["Mingxing Zhan","Li Zhang","Beibei Wang","Yingjie Wang","Zenglin Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03959v1","updated":"2026-01-07T14:18:59Z","published":"2026-01-07T14:18:59Z","title":"FUSION: Full-Body Unified Motion Prior for Body and Hands via Diffusion","summary":"Hands are central to interacting with our surroundings and conveying gestures, making their inclusion essential for full-body motion synthesis. Despite this, existing human motion synthesis methods fall short: some ignore hand motions entirely, while others generate full-body motions only for narrowly scoped tasks under highly constrained settings. A key obstacle is the lack of large-scale datasets that jointly capture diverse full-body motion with detailed hand articulation. While some datasets capture both, they are limited in scale and diversity. Conversely, large-scale datasets typically focus either on body motion without hands or on hand motions without the body. To overcome this, we curate and unify existing hand motion datasets with large-scale body motion data to generate full-body sequences that capture both hand and body. We then propose the first diffusion-based unconditional full-body motion prior, FUSION, which jointly models body and hand motion. Despite using a pose-based motion representation, FUSION surpasses state-of-the-art skeletal control models on the Keypoint Tracking task in the HumanML3D dataset and achieves superior motion naturalness. Beyond standard benchmarks, we demonstrate that FUSION can go beyond typical uses of motion priors through two applications: (1) generating detailed full-body motion including fingers during interaction given the motion of an object, and (2) generating Self-Interaction motions using an LLM to transform natural language cues into actionable motion constraints. For these applications, we develop an optimization pipeline that refines the latent space of our diffusion model to generate task-specific motions. Experiments on these tasks highlight precise control over hand motion while maintaining plausible full-body coordination. The code will be public.","authors":["Enes Duran","Nikos Athanasiou","Muhammed Kocabas","Michael J. Black","Omid Taheri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.18719v2","updated":"2026-01-07T14:18:33Z","published":"2025-03-24T14:30:38Z","title":"Boosting Resolution Generalization of Diffusion Transformers with Randomized Positional Encodings","summary":"Resolution generalization in image generation tasks enables the production of higher-resolution images with lower training resolution overhead. However, a key obstacle for diffusion transformers in addressing this problem is the mismatch between positional encodings seen at inference and those used during training. Existing strategies such as positional encodings interpolation, extrapolation, or hybrids, do not fully resolve this mismatch. In this paper, we propose a novel two-dimensional randomized positional encodings, namely RPE-2D, that prioritizes the order of image patches rather than their absolute distances, enabling seamless high- and low-resolution generation without training on multiple resolutions. Concretely, RPE-2D independently samples positions along the horizontal and vertical axes over an expanded range during training, ensuring that the encodings used at inference lie within the training distribution and thereby improving resolution generalization. We further introduce a simple random resize-and-crop augmentation to strengthen order modeling and add micro-conditioning to indicate the applied cropping pattern. On the ImageNet dataset, RPE-2D achieves state-of-the-art resolution generalization performance, outperforming competitive methods when trained at $256^2$ and evaluated at $384^2$ and $512^2$, and when trained at $512^2$ and evaluated at $768^2$ and $1024^2$. RPE-2D also exhibits outstanding capabilities in low-resolution image generation, multi-stage training acceleration, and multi-resolution inheritance.","authors":["Liang Hou","Cong Liu","Mingwu Zheng","Xin Tao","Pengfei Wan","Di Zhang","Kun Gai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03955v1","updated":"2026-01-07T14:09:18Z","published":"2026-01-07T14:09:18Z","title":"ResTok: Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation","summary":"Existing 1D visual tokenizers for autoregressive (AR) generation largely follow the design principles of language modeling, as they are built directly upon transformers whose priors originate in language, yielding single-hierarchy latent tokens and treating visual data as flat sequential token streams. However, this language-like formulation overlooks key properties of vision, particularly the hierarchical and residual network designs that have long been essential for convergence and efficiency in visual models. To bring \"vision\" back to vision, we propose the Residual Tokenizer (ResTok), a 1D visual tokenizer that builds hierarchical residuals for both image tokens and latent tokens. The hierarchical representations obtained through progressively merging enable cross-level feature fusion at each layer, substantially enhancing representational capacity. Meanwhile, the semantic residuals between hierarchies prevent information overlap, yielding more concentrated latent distributions that are easier for AR modeling. Cross-level bindings consequently emerge without any explicit constraints. To accelerate the generation process, we further introduce a hierarchical AR generator that substantially reduces sampling steps by predicting an entire level of latent tokens at once rather than generating them strictly token-by-token. Extensive experiments demonstrate that restoring hierarchical residual priors in visual tokenization significantly improves AR image generation, achieving a gFID of 2.34 on ImageNet-256 with only 9 sampling steps. Code is available at https://github.com/Kwai-Kolors/ResTok.","authors":["Xu Zhang","Cheng Da","Huan Yang","Kun Gai","Ming Lu","Zhan Ma"],"pdf_url":"","comment":"Technical report"},{"id":"http://arxiv.org/abs/2512.18455v2","updated":"2026-01-07T13:56:52Z","published":"2025-12-20T18:01:57Z","title":"Plasticine: A Traceable Diffusion Model for Medical Image Translation","summary":"Domain gaps arising from variations in imaging devices and population distributions pose significant challenges for machine learning in medical image analysis. Existing image-to-image translation methods primarily aim to learn mappings between domains, often generating diverse synthetic data with variations in anatomical scale and shape, but they usually overlook spatial correspondence during the translation process. For clinical applications, traceability, defined as the ability to provide pixel-level correspondences between original and translated images, is equally important. This property enhances clinical interpretability but has been largely overlooked in previous approaches. To address this gap, we propose Plasticine, which is, to the best of our knowledge, the first end-to-end image-to-image translation framework explicitly designed with traceability as a core objective. Our method combines intensity translation and spatial transformation within a denoising diffusion framework. This design enables the generation of synthetic images with interpretable intensity transitions and spatially coherent deformations, supporting pixel-wise traceability throughout the translation process.","authors":["Tianyang Zhang","Xinxing Cheng","Jun Cheng","Shaoming Zheng","He Zhao","Huazhu Fu","Alejandro F Frangi","Jiang Liu","Jinming Duan"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2601.03928v1","updated":"2026-01-07T13:48:12Z","published":"2026-01-07T13:48:12Z","title":"FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection","summary":"Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while preserving positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Preserving positional continuity during visual token selection. We find that general visual token pruning methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.","authors":["Mingyu Ouyang","Kevin Qinghong Lin","Mike Zheng Shou","Hwee Tou Ng"],"pdf_url":"","comment":"14 pages, 13 figures"},{"id":"http://arxiv.org/abs/2601.03924v1","updated":"2026-01-07T13:45:20Z","published":"2026-01-07T13:45:20Z","title":"A low-complexity method for efficient depth-guided image deblurring","summary":"Image deblurring is a challenging problem in imaging due to its highly ill-posed nature. Deep learning models have shown great success in tackling this problem but the quest for the best image quality has brought their computational complexity up, making them impractical on anything but powerful servers. Meanwhile, recent works have shown that mobile Lidars can provide complementary information in the form of depth maps that enhance deblurring quality. In this paper, we introduce a novel low-complexity neural network for depth-guided image deblurring. We show that the use of the wavelet transform to separate structural details and reduce spatial redundancy as well as efficient feature conditioning on the depth information are essential ingredients in developing a low-complexity model. Experimental results show competitive image quality against recent state-of-the-art models while reducing complexity by up to two orders of magnitude.","authors":["Ziyao Yi","Diego Valsesia","Tiziano Bianchi","Enrico Magli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03915v1","updated":"2026-01-07T13:31:33Z","published":"2026-01-07T13:31:33Z","title":"HemBLIP: A Vision-Language Model for Interpretable Leukemia Cell Morphology Analysis","summary":"Microscopic evaluation of white blood cell morphology is central to leukemia diagnosis, yet current deep learning models often act as black boxes, limiting clinical trust and adoption. We introduce HemBLIP, a vision language model designed to generate interpretable, morphology aware descriptions of peripheral blood cells. Using a newly constructed dataset of 14k healthy and leukemic cells paired with expert-derived attribute captions, we adapt a general-purpose VLM via both full fine-tuning and LoRA based parameter efficient training, and benchmark against the biomedical foundation model MedGEMMA. HemBLIP achieves higher caption quality and morphological accuracy, while LoRA adaptation provides further gains with significantly reduced computational cost. These results highlight the promise of vision language models for transparent and scalable hematological diagnostics.","authors":["Julie van Logtestijn","Petru Manescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.18414v3","updated":"2026-01-07T13:23:00Z","published":"2025-03-24T07:46:00Z","title":"U-REPA: Aligning Diffusion U-Nets to ViTs","summary":"Representation Alignment (REPA) that aligns Diffusion Transformer (DiT) hidden-states with ViT visual encoders has proven highly effective in DiT training, demonstrating superior convergence properties, but it has not been validated on the canonical diffusion U-Net architecture that shows faster convergence compared to DiTs. However, adapting REPA to U-Net architectures presents unique challenges: (1) different block functionalities necessitate revised alignment strategies; (2) spatial-dimension inconsistencies emerge from U-Net's spatial downsampling operations; (3) space gaps between U-Net and ViT hinder the effectiveness of tokenwise alignment. To encounter these challenges, we propose \\textbf{U-REPA}, a representation alignment paradigm that bridges U-Net hidden states and ViT features as follows: Firstly, we propose via observation that due to skip connection, the middle stage of U-Net is the best alignment option. Secondly, we propose upsampling of U-Net features after passing them through MLPs. Thirdly, we observe difficulty when performing tokenwise similarity alignment, and further introduces a manifold loss that regularizes the relative similarity between samples. Experiments indicate that the resulting U-REPA could achieve excellent generation quality and greatly accelerates the convergence speed. With CFG guidance interval, U-REPA could reach $FID<1.5$ in 200 epochs or 1M iterations on ImageNet 256 $\\times$ 256, and needs only half the total epochs to perform better than REPA under sd-vae-ft-ema. Codes: https://github.com/YuchuanTian/U-REPA","authors":["Yuchuan Tian","Hanting Chen","Mengyu Zheng","Yuchen Liang","Chao Xu","Yunhe Wang"],"pdf_url":"","comment":"22 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.18484v2","updated":"2026-01-07T12:57:26Z","published":"2025-03-24T09:38:37Z","title":"PM4Bench: Benchmarking Large Vision-Language Models with Parallel Multilingual Multi-Modal Multi-task Corpus","summary":"While Large Vision-Language Models (LVLMs) demonstrate promising multilingual capabilities, their evaluation is currently hindered by two critical limitations: (1) the use of non-parallel corpora, which conflates inherent language capability gaps with dataset artifacts, precluding a fair assessment of cross-lingual alignment; and (2) disjointed multimodal inputs, which deviate from real-world scenarios where most texts are embedded within visual contexts. To address these challenges, we propose PM4Bench, the first Multilingual Multi-Modal Multi-task Benchmark constructed on a strictly parallel corpus across 10 languages. By eliminating content divergence, our benchmark enables a fair comparison of model capabilities across different languages. We also introduce a vision setting where textual queries are visually fused into images, compelling models to jointly \"see,\" \"read,\" and \"think\". Extensive evaluation of 10 LVLMs uncover a substantial performance drop in the Vision setting compared to standard inputs. Further analysis reveals that OCR capability is not only a general bottleneck but also contributes to cross-lingual performance disparities, suggesting that improving multilingual OCR is essential for advancing LVLM performance. We will release PM4Bench at https://github.com/opendatalab/PM4Bench .","authors":["Junyuan Gao","Jiahe Song","Jiang Wu","Runchuan Zhu","Guanlin Shen","Shasha Wang","Xingjian Wei","Haote Yang","Songyang Zhang","Weijia Li","Bin Wang","Dahua Lin","Lijun Wu","Conghui He"],"pdf_url":"","comment":"Equal contribution: Junyuan Gao, Jiahe Song, Jiang Wu; Corresponding author: Conghui He"},{"id":"http://arxiv.org/abs/2601.03884v1","updated":"2026-01-07T12:51:28Z","published":"2026-01-07T12:51:28Z","title":"FLNet: Flood-Induced Agriculture Damage Assessment using Super Resolution of Satellite Images","summary":"Distributing government relief efforts after a flood is challenging. In India, the crops are widely affected by floods; therefore, making rapid and accurate crop damage assessment is crucial for effective post-disaster agricultural management. Traditional manual surveys are slow and biased, while current satellite-based methods face challenges like cloud cover and low spatial resolution. Therefore, to bridge this gap, this paper introduced FLNet, a novel deep learning based architecture that used super-resolution to enhance the 10 m spatial resolution of Sentinel-2 satellite images into 3 m resolution before classifying damage. We tested our model on the Bihar Flood Impacted Croplands Dataset (BFCD-22), and the results showed an improved critical \"Full Damage\" F1-score from 0.83 to 0.89, nearly matching the 0.89 score of commercial high-resolution imagery. This work presented a cost-effective and scalable solution, paving the way for a nationwide shift from manual to automated, high-fidelity damage assessment.","authors":["Sanidhya Ghosal","Anurag Sharma","Sushil Ghildiyal","Mukesh Saini"],"pdf_url":"","comment":"Accepted for oral presentation at the 10th International Conference on Computer Vision and Image Processing (CVIP 2025)"},{"id":"http://arxiv.org/abs/2601.03875v1","updated":"2026-01-07T12:39:54Z","published":"2026-01-07T12:39:54Z","title":"Staged Voxel-Level Deep Reinforcement Learning for 3D Medical Image Segmentation with Noisy Annotations","summary":"Deep learning has achieved significant advancements in medical image segmentation. Currently, obtaining accurate segmentation outcomes is critically reliant on large-scale datasets with high-quality annotations. However, noisy annotations are frequently encountered owing to the complex morphological structures of organs in medical images and variations among different annotators, which can substantially limit the efficacy of segmentation models. Motivated by the fact that medical imaging annotator can correct labeling errors during segmentation based on prior knowledge, we propose an end-to-end Staged Voxel-Level Deep Reinforcement Learning (SVL-DRL) framework for robust medical image segmentation under noisy annotations. This framework employs a dynamic iterative update strategy to automatically mitigate the impact of erroneous labels without requiring manual intervention. The key advancements of SVL-DRL over existing works include: i) formulating noisy annotations as a voxel-dependent problem and addressing it through a novel staged reinforcement learning framework which guarantees robust model convergence; ii) incorporating a voxel-level asynchronous advantage actor-critic (vA3C) module that conceptualizes each voxel as an autonomous agent, which allows each agent to dynamically refine its own state representation during training, thereby directly mitigating the influence of erroneous labels; iii) designing a novel action space for the agents, along with a composite reward function that strategically combines the Dice value and a spatial continuity metric to significantly boost segmentation accuracy while maintain semantic integrity. Experiments on three public medical image datasets demonstrates State-of-The-Art (SoTA) performance under various experimental settings, with an average improvement of over 3\\% in both Dice and IoU scores.","authors":["Yuyang Fu","Xiuzhen Guo","Ji Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03869v1","updated":"2026-01-07T12:32:39Z","published":"2026-01-07T12:32:39Z","title":"Bayesian Monocular Depth Refinement via Neural Radiance Fields","summary":"Monocular depth estimation has applications in many fields, such as autonomous navigation and extended reality, making it an essential computer vision task. However, current methods often produce smooth depth maps that lack the fine geometric detail needed for accurate scene understanding. We propose MDENeRF, an iterative framework that refines monocular depth estimates using depth information from Neural Radiance Fields (NeRFs). MDENeRF consists of three components: (1) an initial monocular estimate for global structure, (2) a NeRF trained on perturbed viewpoints, with per-pixel uncertainty, and (3) Bayesian fusion of the noisy monocular and NeRF depths. We derive NeRF uncertainty from the volume rendering process to iteratively inject high-frequency fine details. Meanwhile, our monocular prior maintains global structure. We demonstrate superior performance on key metrics and experiments using indoor scenes from the SUN RGB-D dataset.","authors":["Arun Muthukkumar"],"pdf_url":"","comment":"IEEE 8th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025). Oral presentation; Best Presenter Award"},{"id":"http://arxiv.org/abs/2601.02299v2","updated":"2026-01-07T12:06:35Z","published":"2026-01-05T17:34:50Z","title":"SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting","summary":"The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.","authors":["Sara Inácio","Hugo Proença","João C. Neves"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2601.02730v2","updated":"2026-01-07T11:45:43Z","published":"2026-01-06T05:48:47Z","title":"HOLO: Homography-Guided Pose Estimator Network for Fine-Grained Visual Localization on SD Maps","summary":"Visual localization on standard-definition (SD) maps has emerged as a promising low-cost and scalable solution for autonomous driving. However, existing regression-based approaches often overlook inherent geometric priors, resulting in suboptimal training efficiency and limited localization accuracy. In this paper, we propose a novel homography-guided pose estimator network for fine-grained visual localization between multi-view images and standard-definition (SD) maps. We construct input pairs that satisfy a homography constraint by projecting ground-view features into the BEV domain and enforcing semantic alignment with map features. Then we leverage homography relationships to guide feature fusion and restrict the pose outputs to a valid feasible region, which significantly improves training efficiency and localization accuracy compared to prior methods relying on attention-based fusion and direct 3-DoF pose regression. To the best of our knowledge, this is the first work to unify BEV semantic reasoning with homography learning for image-to-map localization. Furthermore, by explicitly modeling homography transformations, the proposed framework naturally supports cross-resolution inputs, enhancing model flexibility. Extensive experiments on the nuScenes dataset demonstrate that our approach significantly outperforms existing state-of-the-art visual localization methods. Code and pretrained models will be publicly released to foster future research.","authors":["Xuchang Zhong","Xu Cao","Jinke Feng","Hao Fang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03824v1","updated":"2026-01-07T11:37:57Z","published":"2026-01-07T11:37:57Z","title":"IDESplat: Iterative Depth Probability Estimation for Generalizable 3D Gaussian Splatting","summary":"Generalizable 3D Gaussian Splatting aims to directly predict Gaussian parameters using a feed-forward network for scene reconstruction. Among these parameters, Gaussian means are particularly difficult to predict, so depth is usually estimated first and then unprojected to obtain the Gaussian sphere centers. Existing methods typically rely solely on a single warp to estimate depth probability, which hinders their ability to fully leverage cross-view geometric cues, resulting in unstable and coarse depth maps. To address this limitation, we propose IDESplat, which iteratively applies warp operations to boost depth probability estimation for accurate Gaussian mean prediction. First, to eliminate the inherent instability of a single warp, we introduce a Depth Probability Boosting Unit (DPBU) that integrates epipolar attention maps produced by cascading warp operations in a multiplicative manner. Next, we construct an iterative depth estimation process by stacking multiple DPBUs, progressively identifying potential depth candidates with high likelihood. As IDESplat iteratively boosts depth probability estimates and updates the depth candidates, the depth map is gradually refined, resulting in accurate Gaussian means. We conduct experiments on RealEstate10K, ACID, and DL3DV. IDESplat achieves outstanding reconstruction quality and state-of-the-art performance with real-time efficiency. On RE10K, it outperforms DepthSplat by 0.33 dB in PSNR, using only 10.7% of the parameters and 70% of the memory. Additionally, our IDESplat improves PSNR by 2.95 dB over DepthSplat on the DTU dataset in cross-dataset experiments, demonstrating its strong generalization ability.","authors":["Wei Long","Haifeng Wu","Shiyin Jiang","Jinhua Zhang","Xinchun Ji","Shuhang Gu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.04666v3","updated":"2026-01-07T11:29:55Z","published":"2024-12-05T23:33:03Z","title":"PhysDepth: Plug-and-Play Physical Refinement for Monocular Depth Estimation in Challenging Environments","summary":"State-of-the-art monocular depth estimation (MDE) models often struggle in challenging environments, primarily because they overlook robust physical information. To demonstrate this, we first conduct an empirical study by computing the covariance between a model's prediction error and atmospheric attenuation. We find that the error of existing SOTAs increases with atmospheric attenuation. Based on this finding, we propose PhysDepth, a plug-and-play framework that solves this fragility by infusing physical priors into modern SOTA backbones. PhysDepth incorporates two key components: a Physical Prior Module (PPM) that leverages Rayleigh Scattering theory to extract robust features from the high-SNR red channel, and a physics-derived Red Channel Attenuation Loss (RCA) that enforces model to learn the Beer-Lambert law. Extensive evaluations demonstrate that PhysDepth achieves SOTA accuracy in challenging conditions.","authors":["Kebin Peng","Haotang Li","Zhenyu Qi","Huashan Chen","Zi Wang","Wei Zhang","Sen He","Huanrui Yang","Qing Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02439v2","updated":"2026-01-07T11:21:44Z","published":"2026-01-05T09:35:11Z","title":"WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks","summary":"We present WebGym, the largest-to-date open-source environment for training realistic visual web agents. Real websites are non-stationary and diverse, making artificial or small-scale task sets insufficient for robust policy learning. WebGym contains nearly 300,000 tasks with rubric-based evaluations across diverse, real-world websites and difficulty levels. We train agents with a simple reinforcement learning (RL) recipe, which trains on the agent's own interaction traces (rollouts), using task rewards as feedback to guide learning. To enable scaling RL, we speed up sampling of trajectories in WebGym by developing a high-throughput asynchronous rollout system, designed specifically for web agents. Our system achieves a 4-5x rollout speedup compared to naive implementations. Second, we scale the task set breadth, depth, and size, which results in continued performance improvement. Fine-tuning a strong base vision-language model, Qwen-3-VL-8B-Instruct, on WebGym results in an improvement in success rate on an out-of-distribution test set from 26.2% to 42.9%, significantly outperforming agents based on proprietary models such as GPT-4o and GPT-5-Thinking that achieve 27.1% and 29.8%, respectively. This improvement is substantial because our test set consists only of tasks on websites never seen during training, unlike many other prior works on training visual web agents.","authors":["Hao Bai","Alexey Taymanov","Tong Zhang","Aviral Kumar","Spencer Whitehead"],"pdf_url":"","comment":"Slightly modified format; added Table 3 for better illustration of the scaling results"},{"id":"http://arxiv.org/abs/2601.03811v1","updated":"2026-01-07T11:16:49Z","published":"2026-01-07T11:16:49Z","title":"EvalBlocks: A Modular Pipeline for Rapidly Evaluating Foundation Models in Medical Imaging","summary":"Developing foundation models in medical imaging requires continuous monitoring of downstream performance. Researchers are burdened with tracking numerous experiments, design choices, and their effects on performance, often relying on ad-hoc, manual workflows that are inherently slow and error-prone. We introduce EvalBlocks, a modular, plug-and-play framework for efficient evaluation of foundation models during development. Built on Snakemake, EvalBlocks supports seamless integration of new datasets, foundation models, aggregation methods, and evaluation strategies. All experiments and results are tracked centrally and are reproducible with a single command, while efficient caching and parallel execution enable scalable use on shared compute infrastructure. Demonstrated on five state-of-the-art foundation models and three medical imaging classification tasks, EvalBlocks streamlines model evaluation, enabling researchers to iterate faster and focus on model innovation rather than evaluation logistics. The framework is released as open source software at https://github.com/DIAGNijmegen/eval-blocks.","authors":["Jan Tagscherer","Sarah de Boer","Lena Philipp","Fennie van der Graaf","Dré Peeters","Joeran Bosma","Lars Leijten","Bogdan Obreja","Ewoud Smit","Alessa Hering"],"pdf_url":"","comment":"Accepted at BVM 2026"},{"id":"http://arxiv.org/abs/2601.03808v1","updated":"2026-01-07T11:13:02Z","published":"2026-01-07T11:13:02Z","title":"From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs","summary":"Large language models (LLMs) have achieved notable performance in code synthesis; however, data-aware augmentation remains a limiting factor, handled via heuristic design or brute-force approaches. We introduce a performance-aware, closed-loop solution in the NNGPT ecosystem of projects that enables LLMs to autonomously engineer optimal transformations by internalizing empirical performance cues. We fine-tune LLMs with Low-Rank Adaptation on a novel repository of more than 6,000 empirically evaluated PyTorch augmentation functions, each annotated solely by downstream model accuracy. Training uses pairwise performance ordering (better-worse transformations), enabling alignment through empirical feedback without reinforcement learning, reward models, or symbolic objectives. This reduces the need for exhaustive search, achieving up to 600x times fewer evaluated candidates than brute-force discovery while maintaining competitive peak accuracy and shifting generation from random synthesis to task-aligned design. Ablation studies show that structured Chain-of-Thought prompting introduces syntactic noise and degrades performance, whereas direct prompting ensures stable optimization in performance-critical code tasks. Qualitative and quantitative analyses demonstrate that the model internalizes semantic performance cues rather than memorizing syntax. These results show that LLMs can exhibit task-level reasoning through non-textual feedback loops, bypassing explicit symbolic rewards.","authors":["Usha Shrestha","Dmitry Ignatov","Radu Timofte"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.18342v2","updated":"2026-01-07T11:06:48Z","published":"2024-12-24T11:00:23Z","title":"Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set Domain Generalization","summary":"Open-Set Domain Generalization (OSDG) is a challenging task requiring models to accurately predict familiar categories while minimizing confidence for unknown categories to effectively reject them in unseen domains. While the OSDG field has seen considerable advancements, the impact of label noise--a common issue in real-world datasets--has been largely overlooked. Label noise can mislead model optimization, thereby exacerbating the challenges of open-set recognition in novel domains. In this study, we take the first step towards addressing Open-Set Domain Generalization under Noisy Labels (OSDG-NL) by constructing dedicated benchmarks derived from widely used OSDG datasets, including PACS and DigitsDG. We evaluate baseline approaches by integrating techniques from both label denoising and OSDG methodologies, highlighting the limitations of existing strategies in handling label noise effectively. To address these limitations, we propose HyProMeta, a novel framework that integrates hyperbolic category prototypes for label noise-aware meta-learning alongside a learnable new-category agnostic prompt designed to enhance generalization to unseen classes. Our extensive experiments demonstrate the superior performance of HyProMeta compared to state-of-the-art methods across the newly established benchmarks. The source code of this work is released at https://github.com/KPeng9510/HyProMeta.","authors":["Kunyu Peng","Di Wen","M. Saquib Sarfraz","Yufan Chen","Junwei Zheng","David Schneider","Kailun Yang","Jiamin Wu","Alina Roitberg","Rainer Stiefelhagen"],"pdf_url":"","comment":"Accepted to International Journal of Computer Vision (IJCV). The source code of this work is released at https://github.com/KPeng9510/HyProMeta"},{"id":"http://arxiv.org/abs/2512.07198v2","updated":"2026-01-07T10:37:15Z","published":"2025-12-08T06:18:44Z","title":"Generating Storytelling Images with Rich Chains-of-Reasoning","summary":"A single image can convey a compelling story through logically connected visual clues, forming Chains-of-Reasoning (CoRs). We define these semantically rich images as Storytelling Images. By conveying multi-layered information that inspires active interpretation, these images enable a wide range of applications, such as illustration and cognitive screening. Despite their potential, such images are scarce and complex to create. To address this, we introduce the Storytelling Image Generation task and propose StorytellingPainter, a two-stage pipeline combining the reasoning of Large Language Models (LLMs) with Text-to-Image (T2I) synthesis. We also develop a dedicated evaluation framework assessing semantic complexity, diversity, and text-image alignment. Furthermore, given the critical role of story generation in the task, we introduce lightweight Mini-Storytellers to bridge the performance gap between small-scale and proprietary LLMs. Experimental results demonstrate the feasibility of our approaches.","authors":["Xiujie Song","Qi Jia","Shota Watanabe","Xiaoyi Pang","Ruijie Chen","Mengyue Wu","Kenny Q. Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03784v1","updated":"2026-01-07T10:34:26Z","published":"2026-01-07T10:34:26Z","title":"A Comparative Study of 3D Model Acquisition Methods for Synthetic Data Generation of Agricultural Products","summary":"In the manufacturing industry, computer vision systems based on artificial intelligence (AI) are widely used to reduce costs and increase production. Training these AI models requires a large amount of training data that is costly to acquire and annotate, especially in high-variance, low-volume manufacturing environments. A popular approach to reduce the need for real data is the use of synthetic data that is generated by leveraging computer-aided design (CAD) models available in the industry. However, in the agricultural industry these models are not readily available, increasing the difficulty in leveraging synthetic data. In this paper, we present different techniques for substituting CAD files to create synthetic datasets. We measure their relative performance when used to train an AI object detection model to separate stones and potatoes in a bin picking environment. We demonstrate that using highly representative 3D models acquired by scanning or using image-to-3D approaches can be used to generate synthetic data for training object detection models. Finetuning on a small real dataset can significantly improve the performance of the models and even get similar performance when less representative models are used.","authors":["Steven Moonen","Rob Salaets","Kenneth Batstone","Abdellatif Bey-Temsamani","Nick Michiels"],"pdf_url":"","comment":"6 pages, 3 figures, 1 table, presented at 4th International Conference on Responsible Consumption and Production, https://link.springer.com/book/9783032173546"},{"id":"http://arxiv.org/abs/2410.18987v5","updated":"2026-01-07T10:32:04Z","published":"2024-10-09T17:19:22Z","title":"Point Cloud Synthesis Using Inner Product Transforms","summary":"Point cloud synthesis, i.e. the generation of novel point clouds from an input distribution, remains a challenging task, for which numerous complex machine learning models have been devised. We develop a novel method that encodes geometrical-topological characteristics of point clouds using inner products, leading to a highly-efficient point cloud representation with provable expressivity properties. Integrated into deep learning models, our encoding exhibits high quality in typical tasks like reconstruction, generation, and interpolation, with inference times orders of magnitude faster than existing methods.","authors":["Ernst Röell","Bastian Rieck"],"pdf_url":"","comment":"Accepted at the 39th Conference on Neural Information Processing Systems (NeurIPS) 2025. Our code is available at https://github.com/aidos-lab/inner-product-transforms"},{"id":"http://arxiv.org/abs/2310.08106v4","updated":"2026-01-07T10:30:41Z","published":"2023-10-12T08:01:11Z","title":"Generalized Logit Adjustment: Calibrating Fine-tuned Models by Removing Label Bias in Foundation Models","summary":"Foundation models like CLIP allow zero-shot transfer on various tasks without additional training data. Yet, the zero-shot performance is less competitive than a fully supervised one. Thus, to enhance the performance, fine-tuning and ensembling are also commonly adopted to better fit the downstream tasks. However, we argue that such prior work has overlooked the inherent biases in foundation models. Due to the highly imbalanced Web-scale training set, these foundation models are inevitably skewed toward frequent semantics, and thus the subsequent fine-tuning or ensembling is still biased. In this study, we systematically examine the biases in foundation models and demonstrate the efficacy of our proposed Generalized Logit Adjustment (GLA) method. Note that bias estimation in foundation models is challenging, as most pre-train data cannot be explicitly accessed like in traditional long-tailed classification tasks. To this end, GLA has an optimization-based bias estimation approach for debiasing foundation models. As our work resolves a fundamental flaw in the pre-training, the proposed GLA demonstrates significant improvements across a diverse range of tasks: it achieves 1.5 pp accuracy gains on ImageNet, an large average improvement (1.4-4.6 pp) on 11 few-shot datasets, 2.4 pp gains on long-tailed classification. Codes are in https://github.com/BeierZhu/GLA.","authors":["Beier Zhu","Kaihua Tang","Qianru Sun","Hanwang Zhang"],"pdf_url":"","comment":"Accepted by NeurIPS2023"},{"id":"http://arxiv.org/abs/2601.03782v1","updated":"2026-01-07T10:29:12Z","published":"2026-01-07T10:29:12Z","title":"PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation","summary":"Humans anticipate, from a glance and a contemplated action of their bodies, how the 3D world will respond, a capability that is equally vital for robotic manipulation. We introduce PointWorld, a large pre-trained 3D world model that unifies state and action in a shared 3D space as 3D point flows: given one or few RGB-D images and a sequence of low-level robot action commands, PointWorld forecasts per-pixel displacements in 3D that respond to the given actions. By representing actions as 3D point flows instead of embodiment-specific action spaces (e.g., joint positions), this formulation directly conditions on physical geometries of robots while seamlessly integrating learning across embodiments. To train our 3D world model, we curate a large-scale dataset spanning real and simulated robotic manipulation in open-world environments, enabled by recent advances in 3D vision and simulated environments, totaling about 2M trajectories and 500 hours across a single-arm Franka and a bimanual humanoid. Through rigorous, large-scale empirical studies of backbones, action representations, learning objectives, partial observability, data mixtures, domain transfers, and scaling, we distill design principles for large-scale 3D world modeling. With a real-time (0.1s) inference speed, PointWorld can be efficiently integrated in the model-predictive control (MPC) framework for manipulation. We demonstrate that a single pre-trained checkpoint enables a real-world Franka robot to perform rigid-body pushing, deformable and articulated object manipulation, and tool use, without requiring any demonstrations or post-training and all from a single image captured in-the-wild. Project website at https://point-world.github.io/.","authors":["Wenlong Huang","Yu-Wei Chao","Arsalan Mousavian","Ming-Yu Liu","Dieter Fox","Kaichun Mo","Li Fei-Fei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03781v1","updated":"2026-01-07T10:25:48Z","published":"2026-01-07T10:25:48Z","title":"MVP: Enhancing Video Large Language Models via Self-supervised Masked Video Prediction","summary":"Reinforcement learning based post-training paradigms for Video Large Language Models (VideoLLMs) have achieved significant success by optimizing for visual-semantic tasks such as captioning or VideoQA. However, while these approaches effectively enhance perception abilities, they primarily target holistic content understanding, often lacking explicit supervision for intrinsic temporal coherence and inter-frame correlations. This tendency limits the models' ability to capture intricate dynamics and fine-grained visual causality. To explicitly bridge this gap, we propose a novel post-training objective: Masked Video Prediction (MVP). By requiring the model to reconstruct a masked continuous segment from a set of challenging distractors, MVP forces the model to attend to the sequential logic and temporal context of events. To support scalable training, we introduce a scalable data synthesis pipeline capable of transforming arbitrary video corpora into MVP training samples, and further employ Group Relative Policy Optimization (GRPO) with a fine-grained reward function to enhance the model's understanding of video context and temporal properties. Comprehensive evaluations demonstrate that MVP enhances video reasoning capabilities by directly reinforcing temporal reasoning and causal understanding.","authors":["Xiaokun Sun","Zezhong Wu","Zewen Ding","Linli Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12631v2","updated":"2026-01-07T10:24:02Z","published":"2025-11-16T14:52:54Z","title":"Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation","summary":"While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and text inputs, eliminating discrepancies between heterogeneous modality representations. The framework facilitates comprehensive multimodal feature interaction through stacked, newly designed multivariate transformer blocks that process all conditions synchronously. Additionally, we design a novel decoupled attention mechanism by dissociating implicit dependencies between mask tokens and temporal embeddings. This mechanism segregates internal computations into dynamic and static pathways, enabling caching and reuse of features computed in static pathways after initial calculation, thereby reducing additional computational overhead introduced by mask condition by over 94% while maintaining performance. Extensive experiments demonstrate that MDiTFace significantly outperforms other competing methods in terms of both facial fidelity and conditional consistency.","authors":["Yushe Cao","Dianxi Shi","Xing Fu","Xuechao Zou","Haikuo Peng","Xueqi Li","Chun Yu","Junliang Xing"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.14435v2","updated":"2026-01-07T10:07:59Z","published":"2025-06-17T11:53:49Z","title":"MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models","summary":"Large multimodal Mixture-of-Experts (MoEs) effectively scale the model size to boost performance while maintaining fixed active parameters. However, previous works primarily utilized full-precision experts during sparse up-cycling. Despite they show superior performance on end tasks, the large amount of experts introduces higher memory footprint, which poses significant challenges for the deployment on edge devices. In this work, we propose MoTE, a scalable and memory-efficient approach to train Mixture-of-Ternary-Experts models from dense checkpoint. Instead of training fewer high-precision experts, we propose to train more low-precision experts during up-cycling. Specifically, we use the pre-trained FFN as a shared expert and train ternary routed experts with parameters in {-1, 0, 1}. Extensive experiments show that our approach has promising scaling trend along model size. MoTE achieves comparable performance to full-precision baseline MoE-LLaVA while offering lower memory footprint. Furthermore, our approach is compatible with post-training quantization methods and the advantage further amplifies when memory-constraint goes lower. Given the same amount of expert memory footprint of 3.4GB and combined with post-training quantization, MoTE outperforms MoE-LLaVA by a gain of 4.3% average accuracy on end tasks, demonstrating its effectiveness and potential for memory-constrained devices.","authors":["Hongyu Wang","Jiayu Xu","Ruiping Wang","Yan Feng","Yitao Zhai","Peng Pei","Xunliang Cai","Xilin Chen"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2512.17394v2","updated":"2026-01-07T09:58:06Z","published":"2025-12-19T09:47:38Z","title":"Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?","summary":"Theory of Mind (ToM) - the ability to attribute beliefs and intents to others - is fundamental for social intelligence, yet Vision-Language Model (VLM) evaluations remain largely Western-centric. In this work, we introduce CulturalToM-VQA, a benchmark of 5,095 visually situated ToM probes across diverse cultural contexts, rituals, and social norms. Constructed through a frontier proprietary MLLM, human-verified pipeline, the dataset spans a taxonomy of six ToM tasks and four complexity levels. We benchmark 10 VLMs (2023-2025) and observe a significant performance leap: while earlier models struggle, frontier models achieve high accuracy (>93%). However, significant limitations persist: models struggle with false belief reasoning (19-83% accuracy) and show high regional variance (20-30% gaps). Crucially, we find that SOTA models exhibit social desirability bias - systematically favoring semantically positive answer choices over negative ones. Ablation experiments reveal that some frontier models rely heavily on parametric social priors, frequently defaulting to safety-aligned predictions. Furthermore, while Chain-of-Thought prompting aids older models, it yields minimal gains for newer ones. Overall, our work provides a testbed for cross-cultural social reasoning, underscoring that despite architectural gains, achieving robust, visually grounded understanding remains an open challenge.","authors":["Zabir Al Nazi","GM Shahariar","Md. Abrar Hossain","Wei Peng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.01993v2","updated":"2026-01-07T09:50:21Z","published":"2024-12-31T18:47:54Z","title":"A Novel Convolution and Attention Mechanism-based Model for 6D Object Pose Estimation","summary":"This paper proposes PoseLecTr, a graph-based encoder-decoder framework that integrates a novel Legendre convolution with attention mechanisms for six-degree-of-freedom (6-DOF) object pose estimation from monocular RGB images. Conventional learning-based approaches predominantly rely on grid-structured convolutions, which can limit their ability to model higher-order and long-range dependencies among image features, especially in cluttered or occluded scenes. PoseLecTr addresses this limitation by constructing a graph representation from image features, where spatial relationships are explicitly modeled through graph connectivity. The proposed framework incorporates a Legendre convolution layer to improve numerical stability in graph convolution, together with spatial-attention and self-attention distillation to enhance feature selection. Experiments conducted on the LINEMOD, Occluded LINEMOD, and YCB-VIDEO datasets demonstrate that our method achieves competitive performance and shows consistent improvements across a wide range of objects and scene complexities.","authors":["Alexander Du","Xiujin Liu"],"pdf_url":"","comment":"6 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2601.03741v1","updated":"2026-01-07T09:29:57Z","published":"2026-01-07T09:29:57Z","title":"I2E: From Image Pixels to Actionable Interactive Environments for Text-Guided Image Editing","summary":"Existing text-guided image editing methods primarily rely on end-to-end pixel-level inpainting paradigm. Despite its success in simple scenarios, this paradigm still significantly struggles with compositional editing tasks that require precise local control and complex multi-object spatial reasoning. This paradigm is severely limited by 1) the implicit coupling of planning and execution, 2) the lack of object-level control granularity, and 3) the reliance on unstructured, pixel-centric modeling. To address these limitations, we propose I2E, a novel \"Decompose-then-Action\" paradigm that revisits image editing as an actionable interaction process within a structured environment. I2E utilizes a Decomposer to transform unstructured images into discrete, manipulable object layers and then introduces a physics-aware Vision-Language-Action Agent to parse complex instructions into a series of atomic actions via Chain-of-Thought reasoning. Further, we also construct I2E-Bench, a benchmark designed for multi-instance spatial reasoning and high-precision editing. Experimental results on I2E-Bench and multiple public benchmarks demonstrate that I2E significantly outperforms state-of-the-art methods in handling complex compositional instructions, maintaining physical plausibility, and ensuring multi-turn editing stability.","authors":["Jinghan Yu","Junhao Xiao","Chenyu Zhu","Jiaming Li","Jia Li","HanMing Deng","Xirui Wang","Guoli Jia","Jianjun Li","Zhiyuan Ma","Xiang Bai","Bowen Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18795v3","updated":"2026-01-07T09:27:16Z","published":"2025-10-21T16:48:49Z","title":"ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder","summary":"The original CLIP text encoder is limited by a maximum input length of 77 tokens, which hampers its ability to effectively process long texts and perform fine-grained semantic understanding. In addition, the CLIP text encoder lacks support for multilingual inputs. All these limitations significantly restrict its applicability across a broader range of tasks. Recent studies have attempted to replace the CLIP text encoder with an LLM-based embedder to enhance its ability in processing long texts, multilingual understanding, and fine-grained semantic comprehension. However, because the representation spaces of LLMs and the vision-language space of CLIP are pretrained independently without alignment priors, direct alignment using contrastive learning can disrupt the intrinsic vision-language alignment in the CLIP image encoder, leading to an underutilization of the knowledge acquired during pre-training. To address this challenge, we propose ProCLIP, a curriculum learning-based progressive vision-language alignment framework to effectively align the CLIP image encoder with an LLM-based embedder. Specifically, ProCLIP first distills knowledge from CLIP's text encoder into the LLM-based embedder to leverage CLIP's rich pretrained knowledge while establishing initial alignment between the LLM embedder and CLIP image encoder. Subsequently, ProCLIP further aligns the CLIP image encoder with the LLM-based embedder through image-text contrastive tuning, employing self-distillation regularization to avoid overfitting. To achieve a more effective alignment, instance semantic alignment loss and embedding structure alignment loss are employed during representation inheritance and contrastive tuning. The Code is available at https://github.com/VisionXLab/ProCLIP.","authors":["Xiaoxing Hu","Kaicheng Yang","Ziyang Gong","Qi Ming","Zonghao Guo","Yu Tian","Xiang An","Ziyong Feng","Xue Yang"],"pdf_url":"","comment":"17 pages, 5 fiugres"},{"id":"http://arxiv.org/abs/2601.03736v1","updated":"2026-01-07T09:26:32Z","published":"2026-01-07T09:26:32Z","title":"HyperCOD: The First Challenging Benchmark and Baseline for Hyperspectral Camouflaged Object Detection","summary":"RGB-based camouflaged object detection struggles in real-world scenarios where color and texture cues are ambiguous. While hyperspectral image offers a powerful alternative by capturing fine-grained spectral signatures, progress in hyperspectral camouflaged object detection (HCOD) has been critically hampered by the absence of a dedicated, large-scale benchmark. To spur innovation, we introduce HyperCOD, the first challenging benchmark for HCOD. Comprising 350 high-resolution hyperspectral images, It features complex real-world scenarios with minimal objects, intricate shapes, severe occlusions, and dynamic lighting to challenge current models. The advent of foundation models like the Segment Anything Model (SAM) presents a compelling opportunity. To adapt the Segment Anything Model (SAM) for HCOD, we propose HyperSpectral Camouflage-aware SAM (HSC-SAM). HSC-SAM ingeniously reformulates the hyperspectral image by decoupling it into a spatial map fed to SAM's image encoder and a spectral saliency map that serves as an adaptive prompt. This translation effectively bridges the modality gap. Extensive experiments show that HSC-SAM sets a new state-of-the-art on HyperCOD and generalizes robustly to other public HSI datasets. The HyperCOD dataset and our HSC-SAM baseline provide a robust foundation to foster future research in this emerging area.","authors":["Shuyan Bai","Tingfa Xu","Peifu Liu","Yuhao Qiu","Huiyan Bai","Huan Chen","Yanyan Peng","Jianan Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03733v1","updated":"2026-01-07T09:25:04Z","published":"2026-01-07T09:25:04Z","title":"RadDiff: Describing Differences in Radiology Image Sets with Natural Language","summary":"Understanding how two radiology image sets differ is critical for generating clinical insights and for interpreting medical AI systems. We introduce RadDiff, a multimodal agentic system that performs radiologist-style comparative reasoning to describe clinically meaningful differences between paired radiology studies. RadDiff builds on a proposer-ranker framework from VisDiff, and incorporates four innovations inspired by real diagnostic workflows: (1) medical knowledge injection through domain-adapted vision-language models; (2) multimodal reasoning that integrates images with their clinical reports; (3) iterative hypothesis refinement across multiple reasoning rounds; and (4) targeted visual search that localizes and zooms in on salient regions to capture subtle findings. To evaluate RadDiff, we construct RadDiffBench, a challenging benchmark comprising 57 expert-validated radiology study pairs with ground-truth difference descriptions. On RadDiffBench, RadDiff achieves 47% accuracy, and 50% accuracy when guided by ground-truth reports, significantly outperforming the general-domain VisDiff baseline. We further demonstrate RadDiff's versatility across diverse clinical tasks, including COVID-19 phenotype comparison, racial subgroup analysis, and discovery of survival-related imaging features. Together, RadDiff and RadDiffBench provide the first method-and-benchmark foundation for systematically uncovering meaningful differences in radiological data.","authors":["Xiaoxian Shen","Yuhui Zhang","Sahithi Ankireddy","Xiaohan Wang","Maya Varma","Henry Guo","Curtis Langlotz","Serena Yeung-Levy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03729v1","updated":"2026-01-07T09:21:45Z","published":"2026-01-07T09:21:45Z","title":"MATANet: A Multi-context Attention and Taxonomy-Aware Network for Fine-Grained Underwater Recognition of Marine Species","summary":"Fine-grained classification of marine animals supports ecology, biodiversity and habitat conservation, and evidence-based policy-making. However, existing methods often overlook contextual interactions from the surrounding environment and insufficiently incorporate the hierarchical structure of marine biological taxonomy. To address these challenges, we propose MATANet (Multi-context Attention and Taxonomy-Aware Network), a novel model designed for fine-grained marine species classification. MATANet mimics expert strategies by using taxonomy and environmental context to interpret ambiguous features of underwater animals. It consists of two key components: a Multi-Context Environmental Attention Module (MCEAM), which learns relationships between regions of interest (ROIs) and their surrounding environments, and a Hierarchical Separation-Induced Learning Module (HSLM), which encodes taxonomic hierarchy into the feature space. MATANet combines instance and environmental features with taxonomic structure to enhance fine-grained classification. Experiments on the FathomNet2025, FAIR1M, and LifeCLEF2015-Fish datasets demonstrate state-of-the-art performance. The source code is available at: https://github.com/dhlee-work/fathomnet-cvpr2025-ssl","authors":["Donghwan Lee","Byeongjin Kim","Geunhee Kim","Hyukjin Kwon","Nahyeon Maeng","Wooju Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03728v1","updated":"2026-01-07T09:21:38Z","published":"2026-01-07T09:21:38Z","title":"CSMCIR: CoT-Enhanced Symmetric Alignment with Memory Bank for Composed Image Retrieval","summary":"Composed Image Retrieval (CIR) enables users to search for target images using both a reference image and manipulation text, offering substantial advantages over single-modality retrieval systems. However, existing CIR methods suffer from representation space fragmentation: queries and targets comprise heterogeneous modalities and are processed by distinct encoders, forcing models to bridge misaligned representation spaces only through post-hoc alignment, which fundamentally limits retrieval performance. This architectural asymmetry manifests as three distinct, well-separated clusters in the feature space, directly demonstrating how heterogeneous modalities create fundamentally misaligned representation spaces from initialization. In this work, we propose CSMCIR, a unified representation framework that achieves efficient query-target alignment through three synergistic components. First, we introduce a Multi-level Chain-of-Thought (MCoT) prompting strategy that guides Multimodal Large Language Models to generate discriminative, semantically compatible captions for target images, establishing modal symmetry. Building upon this, we design a symmetric dual-tower architecture where both query and target sides utilize the identical shared-parameter Q-Former for cross-modal encoding, ensuring consistent feature representations and further reducing the alignment gap. Finally, this architectural symmetry enables an entropy-based, temporally dynamic Memory Bank strategy that provides high-quality negative samples while maintaining consistency with the evolving model state. Extensive experiments on four benchmark datasets demonstrate that our CSMCIR achieves state-of-the-art performance with superior training efficiency. Comprehensive ablation studies further validate the effectiveness of each proposed component.","authors":["Zhipeng Qian","Zihan Liang","Yufei Ma","Ben Chen","Huangyu Dai","Yiwei Ma","Jiayi Ji","Chenyi Lei","Han Li","Xiaoshuai Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.07828v2","updated":"2026-01-07T09:16:59Z","published":"2025-07-10T15:01:23Z","title":"Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles","summary":"Content-based puzzle solvers have been extensively studied, demonstrating significant progress in computational techniques. However, their evaluation often lacks realistic challenges crucial for real-world applications, such as the reassembly of fragmented artefacts or shredded documents. In this work, we investigate the robustness of State-Of-The-Art content-based puzzle solvers introducing three types of jigsaw puzzle corruptions: missing pieces, eroded edges, and eroded contents. Evaluating both heuristic and deep learning-based solvers, we analyse their ability to handle these corruptions and identify key limitations. Our results show that solvers developed for standard puzzles have a rapid decline in performance if more pieces are corrupted. However, deep learning models can significantly improve their robustness through fine-tuning with augmented data. Notably, the advanced Positional Diffusion model adapts particularly well, outperforming its competitors in most experiments. Based on our findings, we highlight promising research directions for enhancing the automated reconstruction of real-world artefacts.","authors":["Richard Dirauf","Florian Wolz","Dario Zanca","Björn Eskofier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.09818v3","updated":"2026-01-07T09:15:28Z","published":"2025-08-13T13:54:16Z","title":"ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video","summary":"This study investigates the use of large language models (LLMs) for human behavior understanding by jointly leveraging motion and video data. We argue that integrating these complementary modalities is essential for capturing both fine-grained motion dynamics and contextual semantics of human actions, addressing the limitations of prior motion-only or video-only approaches. To this end, we propose ViMoNet, a multimodal vision-language framework trained through a two-stage alignment and instruction-tuning strategy that combines precise motion-text supervision with large-scale video-text data. We further introduce VIMOS, a multimodal dataset comprising human motion sequences, videos, and instruction-level annotations, along with ViMoNet-Bench, a standardized benchmark for evaluating behavior-centric reasoning. Experimental results demonstrate that ViMoNet consistently outperforms existing methods across caption generation, motion understanding, and human behavior interpretation tasks. The proposed framework shows significant potential in assistive healthcare applications, such as elderly monitoring, fall detection, and early identification of health risks in aging populations. This work contributes to the United Nations Sustainable Development Goal 3 (SDG 3: Good Health and Well-being) by enabling accessible AI-driven tools that promote universal health coverage, reduce preventable health issues, and enhance overall well-being.","authors":["Rajan Das Gupta","Lei Wei","Md Yeasin Rahat","Nafiz Fahad","Abir Ahmed","Liew Tze Hui"],"pdf_url":"","comment":"This is the preprint version of the manuscript. It is currently being prepared for submission to an academic conference"},{"id":"http://arxiv.org/abs/2411.18109v2","updated":"2026-01-07T09:14:25Z","published":"2024-11-27T07:42:06Z","title":"Difficulty Controlled Diffusion Model for Synthesizing Effective Training Data","summary":"Generative models have become a powerful tool for synthesizing training data in computer vision tasks. Current approaches solely focus on aligning generated images with the target dataset distribution. As a result, they capture only the common features in the real dataset and mostly generate 'easy samples', which are already well learned by models trained on real data. In contrast, those rare 'hard samples', with atypical features but crucial for enhancing performance, cannot be effectively generated. Consequently, these approaches must synthesize large volumes of data to yield appreciable performance gains, yet the improvement remains limited. To overcome this limitation, we present a novel method that can learn to control the learning difficulty of samples during generation while also achieving domain alignment. Thus, it can efficiently generate valuable 'hard samples' that yield significant performance improvements for target tasks. This is achieved by incorporating learning difficulty as an additional conditioning signal in generative models, together with a designed encoder structure and training-generation strategy. Experimental results across multiple datasets show that our method can achieve higher performance with lower generation cost. Specifically, we obtain the best performance with only 10% additional synthetic data, saving 63.4 GPU hours of generation time compared to the previous SOTA on ImageNet. Moreover, our method provides insightful visualizations of category-specific hard factors, serving as a tool for analyzing datasets.","authors":["Zerun Wang","Jiafeng Mao","Xueting Wang","Toshihiko Yamasaki"],"pdf_url":"","comment":"AAAI 2026 accepted"},{"id":"http://arxiv.org/abs/2601.03718v1","updated":"2026-01-07T09:13:20Z","published":"2026-01-07T09:13:20Z","title":"Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation","summary":"Active Alignment (AA) is a key technology for the large-scale automated assembly of high-precision optical systems. Compared with labor-intensive per-model on-device calibration, a digital-twin pipeline built on optical simulation offers a substantial advantage in generating large-scale labeled data. However, complex imaging conditions induce a domain gap between simulation and real-world images, limiting the generalization of simulation-trained models. To address this, we propose augmenting a simulation baseline with minimal unlabeled real-world images captured at random misalignment positions, mitigating the gap from a domain adaptation perspective. We introduce Domain Adaptive Active Alignment (DA3), which utilizes an autoregressive domain transformation generator and an adversarial-based feature alignment strategy to distill real-world domain information via self-supervised learning. This enables the extraction of domain-invariant image degradation features to facilitate robust misalignment prediction. Experiments on two lens types reveal that DA3 improves accuracy by 46% over a purely simulation pipeline. Notably, it approaches the performance achieved with precisely labeled real-world data collected on 3 lens samples, while reducing on-device data collection time by 98.7%. The results demonstrate that domain adaptation effectively endows simulation-trained models with robust real-world performance, validating the digital-twin pipeline as a practical solution to significantly enhance the efficiency of large-scale optical assembly.","authors":["Wenyong Lia","Qi Jiang","Weijian Hu","Kailun Yang","Zhanjun Zhang","Wenjun Tian","Kaiwei Wang","Jian Bai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03714v1","updated":"2026-01-07T09:01:23Z","published":"2026-01-07T09:01:23Z","title":"Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR","summary":"DeepSeek-OCR utilizes an optical 2D mapping approach to achieve high-ratio vision-text compression, claiming to decode text tokens exceeding ten times the input visual tokens. While this suggests a promising solution for the LLM long-context bottleneck, we investigate a critical question: \"Visual merit or linguistic crutch - which drives DeepSeek-OCR's performance?\" By employing sentence-level and word-level semantic corruption, we isolate the model's intrinsic OCR capabilities from its language priors. Results demonstrate that without linguistic support, DeepSeek-OCR's performance plummets from approximately 90% to 20%. Comparative benchmarking against 13 baseline models reveals that traditional pipeline OCR methods exhibit significantly higher robustness to such semantic perturbations than end-to-end methods. Furthermore, we find that lower visual token counts correlate with increased reliance on priors, exacerbating hallucination risks. Context stress testing also reveals a total model collapse around 10,000 text tokens, suggesting that current optical compression techniques may paradoxically aggravate the long-context bottleneck. This study empirically defines DeepSeek-OCR's capability boundaries and offers essential insights for future optimizations of the vision-text compression paradigm. We release all data, results and scripts used in this study at https://github.com/dududuck00/DeepSeekOCR.","authors":["Yunhao Liang","Ruixuan Ying","Bo Li","Hong Li","Kai Yan","Qingwen Li","Min Yang","Okamoto Satoshi","Zhe Cui","Shiwen Ni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03713v1","updated":"2026-01-07T09:00:52Z","published":"2026-01-07T09:00:52Z","title":"BREATH-VL: Vision-Language-Guided 6-DoF Bronchoscopy Localization via Semantic-Geometric Fusion","summary":"Vision-language models (VLMs) have recently shown remarkable performance in navigation and localization tasks by leveraging large-scale pretraining for semantic understanding. However, applying VLMs to 6-DoF endoscopic camera localization presents several challenges: 1) the lack of large-scale, high-quality, densely annotated, and localization-oriented vision-language datasets in real-world medical settings; 2) limited capability for fine-grained pose regression; and 3) high computational latency when extracting temporal features from past frames. To address these issues, we first construct BREATH dataset, the largest in-vivo endoscopic localization dataset to date, collected in the complex human airway. Building on this dataset, we propose BREATH-VL, a hybrid framework that integrates semantic cues from VLMs with geometric information from vision-based registration methods for accurate 6-DoF pose estimation. Our motivation lies in the complementary strengths of both approaches: VLMs offer generalizable semantic understanding, while registration methods provide precise geometric alignment. To further enhance the VLM's ability to capture temporal context, we introduce a lightweight context-learning mechanism that encodes motion history as linguistic prompts, enabling efficient temporal reasoning without expensive video-level computation. Extensive experiments demonstrate that the vision-language module delivers robust semantic localization in challenging surgical scenes. Building on this, our BREATH-VL outperforms state-of-the-art vision-only localization methods in both accuracy and generalization, reducing translational error by 25.5% compared with the best-performing baseline, while achieving competitive computational latency.","authors":["Qingyao Tian","Bingyu Yang","Huai Liao","Xinyan Huang","Junyong Li","Dong Yi","Hongbin Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.03826v4","updated":"2026-01-07T08:59:53Z","published":"2025-02-06T07:22:57Z","title":"FairT2I: Mitigating Social Bias in Text-to-Image Generation via Large Language Model-Assisted Detection and Attribute Rebalancing","summary":"Text-to-image (T2I) models have advanced creative content generation, yet their reliance on large uncurated datasets often reproduces societal biases. We present FairT2I, a training-free and interactive framework grounded in a mathematically principled latent variable guidance formulation. This formulation decomposes the generative score function into attribute-conditioned components and reweights them according to a defined distribution, providing a unified and flexible mechanism for bias-aware generation that also subsumes many existing ad hoc debiasing approaches as special cases. Building upon this foundation, FairT2I incorporates (1) latent variable guidance as the core mechanism, (2) LLM-based bias detection to automatically infer bias-prone categories and attributes from text prompts as part of the latent structure, and (3) attribute resampling, which allows users to adjust or redefine the attribute distribution based on uniform, real-world, or user-specified statistics. The accompanying user interface supports this pipeline by enabling users to inspect detected biases, modify attributes or weights, and generate debiased images in real time. Experimental results show that LLMs outperform average human annotators in the number and granularity of detected bias categories and attributes. Moreover, FairT2I achieves superior performance to baseline models in both societal bias mitigation and image diversity, while preserving image quality and prompt fidelity.","authors":["Jinya Sakurai","Yuki Koyama","Issei Sato"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.05319v2","updated":"2026-01-07T08:54:15Z","published":"2025-11-07T15:17:40Z","title":"$\\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models","summary":"Despite remarkable progress in steganography, embedding semantically rich, sentence-level information into carriers remains a challenging problem. In this work, we present a novel concept of Semantic Steganography, which aims to hide semantically meaningful and structured content, such as sentences or paragraphs, in cover media. Based on this concept, we present Sentence-to-Image Steganography as an instance that enables the hiding of arbitrary sentence-level messages within a cover image. To accomplish this feat, we propose S^2LM: Semantic Steganographic Language Model, which leverages large language models (LLMs) to embed high-level textual information into images. Unlike traditional bit-level approaches, S^2LM redesigns the entire pipeline, involving the LLM throughout the process to enable the hiding and recovery of arbitrary sentences. Furthermore, we establish a benchmark named Invisible Text (IVT), comprising a diverse set of sentence-level texts as secret messages to evaluate semantic steganography methods. Experimental results demonstrate that S^2LM effectively enables direct sentence recovery beyond bit-level steganography. The source code and IVT dataset will be released soon.","authors":["Huanqi Wu","Huangbiao Xu","Runfeng Xie","Jiaxin Cai","Kaixin Zhang","Xiao Ke"],"pdf_url":"","comment":"30 Pages, 24 Figures"},{"id":"http://arxiv.org/abs/2601.02329v2","updated":"2026-01-07T08:44:10Z","published":"2026-01-05T18:21:02Z","title":"BEDS : Bayesian Emergent Dissipative Structures : A Formal Framework for Continuous Inference Under Energy Constraints","summary":"We introduce BEDS (Bayesian Emergent Dissipative Structures), a formal framework for analyzing inference systems that must maintain beliefs continuously under energy constraints. Unlike classical computational models that assume perfect memory and focus on one-shot computation, BEDS explicitly incorporates dissipation (information loss over time) as a fundamental constraint.\n  We prove a central result linking energy, precision, and dissipation: maintaining a belief with precision $τ$ against dissipation rate $γ$ requires power $P \\geq γk_{\\rm B} T / 2$, with scaling $P \\propto γ\\cdot τ$. This establishes a fundamental thermodynamic cost for continuous inference.\n  We define three classes of problems -- BEDS-attainable, BEDS-maintainable, and BEDS-crystallizable -- and show these are distinct from classical decidability. We propose the Gödel-Landauer-Prigogine conjecture, suggesting that closure pathologies across formal systems, computation, and thermodynamics share a common structure.","authors":["Laurent Caraffa"],"pdf_url":"","comment":"11 pages"},{"id":"http://arxiv.org/abs/2512.21944v2","updated":"2026-01-07T08:41:35Z","published":"2025-12-26T09:43:24Z","title":"Data relativistic uncertainty framework for low-illumination anime scenery image enhancement","summary":"By contrast with the prevailing works of low-light enhancement in natural images and videos, this study copes with the low-illumination quality degradation in anime scenery images to bridge the domain gap. For such an underexplored enhancement task, we first curate images from various sources and construct an unpaired anime scenery dataset with diverse environments and illumination conditions to address the data scarcity. To exploit the power of uncertainty information inherent with the diverse illumination conditions, we propose a Data Relativistic Uncertainty (DRU) framework, motivated by the idea from Relativistic GAN. By analogy with the wave-particle duality of light, our framework interpretably defines and quantifies the illumination uncertainty of dark/bright samples, which is leveraged to dynamically adjust the objective functions to recalibrate the model learning under data uncertainty. Extensive experiments demonstrate the effectiveness of DRU framework by training several versions of EnlightenGANs, yielding superior perceptual and aesthetic qualities beyond the state-of-the-art methods that are incapable of learning from data uncertainty perspective. We hope our framework can expose a novel paradigm of data-centric learning for potential visual and language domains. Code is available.","authors":["Yiquan Gao","John See"],"pdf_url":"","comment":"Add data"},{"id":"http://arxiv.org/abs/2402.16825v5","updated":"2026-01-07T08:38:00Z","published":"2024-02-26T18:51:15Z","title":"Efficient 3D affinely equivariant CNNs with adaptive fusion of augmented spherical Fourier-Bessel bases","summary":"Filter-decomposition-based group equivariant convolutional neural networks (CNNs) have shown promising stability and data efficiency for 3D image feature extraction. However, these networks, which rely on parameter sharing and discrete transformation groups, often underperform in modern deep neural network architectures for processing volumetric images with dense 3D textures, such as the common 3D medical images. To address these limitations, this paper presents an efficient non-parameter-sharing continuous 3D affine group equivariant neural network for volumetric images. This network uses an adaptive aggregation of Monte Carlo augmented spherical Fourier-Bessel filter bases to improve the efficiency and flexibility of 3D group equivariant CNNs for volumetric data. Unlike existing methods that focus only on angular orthogonality in filter bases, the introduced spherical Bessel Fourier filter base incorporates both angular and radial orthogonality to improve feature extraction. Experiments on four medical image segmentation datasets and two seismic datasets show that the proposed methods achieve better affine group equivariance and superior segmentation accuracy than existing 3D group equivariant convolutional neural network layers, significantly improving the training stability and data efficiency of conventional CNN layers (at 0.05 significance level). The code is available at https://github.com/ZhaoWenzhao/WMCSFB.","authors":["Wenzhao Zhao","Steffen Albert","Barbara D. Wichtmann","Angelika Maurer","Ulrike Attenberger","Frank G. Zöllner","Jürgen Hesser"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12302v2","updated":"2026-01-07T08:27:06Z","published":"2025-12-13T11:59:51Z","title":"From Human Intention to Action Prediction: Intention-Driven End-to-End Autonomous Driving","summary":"While end-to-end autonomous driving has achieved remarkable progress in geometric control, current systems remain constrained by a command-following paradigm that relies on simple navigational instructions. Transitioning to genuinely intelligent agents requires the capability to interpret and fulfill high-level, abstract human intentions. However, this advancement is hindered by the lack of dedicated benchmarks and semantic-aware evaluation metrics. In this paper, we formally define the task of Intention-Driven End-to-End Autonomous Driving and present Intention-Drive, a comprehensive benchmark designed to bridge this gap. We construct a large-scale dataset featuring complex natural language intentions paired with high-fidelity sensor data. To overcome the limitations of conventional trajectory-based metrics, we introduce the Imagined Future Alignment (IFA), a novel evaluation protocol leveraging generative world models to assess the semantic fulfillment of human goals beyond mere geometric accuracy. Furthermore, we explore the solution space by proposing two distinct paradigms: an end-to-end vision-language planner and a hierarchical agent-based framework. The experiments reveal a critical dichotomy where existing models exhibit satisfactory driving stability but struggle significantly with intention fulfillment. Notably, the proposed frameworks demonstrate superior alignment with human intentions.","authors":["Huan Zheng","Yucheng Zhou","Tianyi Yan","Jiayi Su","Hongjun Chen","Dubing Chen","Xingtai Gui","Wencheng Han","Runzhou Tao","Zhongying Qiu","Jianfei Yang","Jianbing Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08849v3","updated":"2026-01-07T07:58:47Z","published":"2025-06-10T14:37:51Z","title":"Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis","summary":"Vision-Language Models (VLMs) have demonstrated remarkable generalization capabilities, yet their application to medical ultrasound remains constrained by the significant domain shift between natural images and sonographic data. The unique physics of ultrasound, manifesting as speckle noise, shadowing, and variable artifacts, often leads to suboptimal performance when applying off-the-shelf foundation models. To address this, we propose a novel Hybrid-tuning (HT) strategy for the efficient adaptation of CLIP-based models to ultrasound analysis. Our method introduces a lightweight adapter module integrated into the frozen visual backbone, featuring frequency-domain filtering to suppress periodic artifacts and dynamic noise estimation to calibrate feature representations. Furthermore, we design specialized segmentation and classification heads that employ multi-scale feature aggregation to maximize the utility of pre-trained semantic priors. Extensive evaluations across six multi-center datasets (covering lymph nodes, breast, thyroid, and prostate) reveal that our HT-enhanced models significantly outperform existing state-of-the-art methods, including BiomedCLIP and standard LoRA fine-tuning. The results highlight the superior data efficiency and robustness of our approach, paving the way for practical, foundational intelligence in automated ultrasound diagnosis. The source code is available at https://github.com/jinggqu/NextGen-UIA.","authors":["Jingguo Qu","Xinyang Han","Jia Ai","Juan Wu","Tong Zhao","Tonghuan Xiao","Sheng Ning","Yuqi Yang","Jing Qin","Ann Dorothy King","Winnie Chiu-Wing Chu","Jing Cai","Michael Tin-Cheung Ying"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.02930v5","updated":"2026-01-07T07:57:16Z","published":"2024-12-04T00:50:33Z","title":"Video LLMs for Temporal Reasoning in Long Videos","summary":"We introduce TemporalVLM, a video large language model (video LLM) for temporal reasoning and fine-grained understanding in long videos. Our approach includes a visual encoder for mapping a long-term video into features which are time-aware and contain both local and global cues. It first divides an input video into short-term clips, which are jointly encoded with timestamps and fused across overlapping temporal windows into time-sensitive local features. Next, the local features are passed through a bidirectional long short-term memory (BiLSTM) module for global feature aggregation. Moreover, to facilitate the evaluation of TemporalVLM, we present a large-scale long video dataset of industry assembly processes, namely IndustryASM, consisting of videos recorded on factory floors with actions and timestamps annotated by industrial engineers for time and motion studies and temporal action segmentation evaluation. Finally, extensive experiments show that TemporalVLM outperforms previous methods across temporal reasoning and fine-grained understanding tasks, i.e., dense video captioning, temporal video grounding, video highlight detection, and temporal action segmentation. To our best knowledge, our work is the first to incorporate LSTMs into video LLMs.","authors":["Fawad Javed Fateh","Umer Ahmed","Hamza Khan","M. Zeeshan Zia","Quoc-Huy Tran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03667v1","updated":"2026-01-07T07:41:57Z","published":"2026-01-07T07:41:57Z","title":"TRec: Egocentric Action Recognition using 2D Point Tracks","summary":"We present a novel approach for egocentric action recognition that leverages 2D point tracks as an additional motion cue. While most existing methods rely on RGB appearance, human pose estimation, or their combination, our work demonstrates that tracking randomly sampled image points across video frames can substantially improve recognition accuracy. Unlike prior approaches, we do not detect hands, objects, or interaction regions. Instead, we employ CoTracker to follow a set of randomly initialized points through each video and use the resulting trajectories, together with the corresponding image frames, as input to a Transformer-based recognition model. Surprisingly, our method achieves notable gains even when only the initial frame and its associated point tracks are provided, without incorporating the full video sequence. Experimental results confirm that integrating 2D point tracks consistently enhances performance compared to the same model trained without motion information, highlighting their potential as a lightweight yet effective representation for egocentric action understanding.","authors":["Dennis Holzmann","Sven Wachsmuth"],"pdf_url":"","comment":"submitted to ICPR 2026"},{"id":"http://arxiv.org/abs/2601.03666v1","updated":"2026-01-07T07:39:40Z","published":"2026-01-07T07:39:40Z","title":"e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings","summary":"Modern information systems often involve different types of items, e.g., a text query, an image, a video clip, or an audio segment. This motivates omni-modal embedding models that map heterogeneous modalities into a shared space for direct comparison. However, most recent omni-modal embeddings still rely heavily on implicit alignment inherited from pretrained vision-language model (VLM) backbones. In practice, this causes three common issues: (i) similarity logits have modality-dependent sharpness, so scores are not on a consistent scale; (ii) in-batch negatives become less effective over time because mixed-modality batches create an imbalanced hardness distribution; as a result, many negatives quickly become trivial and contribute little gradient; and (iii) embeddings across modalities show mismatched first- and second-order statistics, which makes rankings less stable. To tackle these problems, we propose e5-omni, a lightweight explicit alignment recipe that adapts off-the-shelf VLMs into robust omni-modal embedding models. e5-omni combines three simple components: (1) modality-aware temperature calibration to align similarity scales, (2) a controllable negative curriculum with debiasing to focus on confusing negatives while reducing the impact of false negatives, and (3) batch whitening with covariance regularization to better match cross-modal geometry in the shared embedding space. Experiments on MMEB-V2 and AudioCaps show consistent gains over strong bi-modal and omni-modal baselines, and the same recipe also transfers well to other VLM backbones. We release our model checkpoint at https://huggingface.co/Haon-Chen/e5-omni-7B.","authors":["Haonan Chen","Sicheng Gao","Radu Timofte","Tetsuya Sakai","Zhicheng Dou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03665v1","updated":"2026-01-07T07:38:58Z","published":"2026-01-07T07:38:58Z","title":"PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance","summary":"Current video generation models produce high-quality aesthetic videos but often struggle to learn representations of real-world physics dynamics, resulting in artifacts such as unnatural object collisions, inconsistent gravity, and temporal flickering. In this work, we propose PhysVideoGenerator, a proof-of-concept framework that explicitly embeds a learnable physics prior into the video generation process. We introduce a lightweight predictor network, PredictorP, which regresses high-level physical features extracted from a pre-trained Video Joint Embedding Predictive Architecture (V-JEPA 2) directly from noisy diffusion latents. These predicted physics tokens are injected into the temporal attention layers of a DiT-based generator (Latte) via a dedicated cross-attention mechanism. Our primary contribution is demonstrating the technical feasibility of this joint training paradigm: we show that diffusion latents contain sufficient information to recover V-JEPA 2 physical representations, and that multi-task optimization remains stable over training. This report documents the architectural design, technical challenges, and validation of training stability, establishing a foundation for future large-scale evaluation of physics-aware generative models.","authors":["Siddarth Nilol Kundur Satish","Devesh Jaiswal","Hongyu Chen","Abhishek Bakshi"],"pdf_url":"","comment":"9 pages, 2 figures, project page: https://github.com/CVFall2025-Project/PhysVideoGenerator"},{"id":"http://arxiv.org/abs/2601.03660v1","updated":"2026-01-07T07:16:46Z","published":"2026-01-07T07:16:46Z","title":"MGPC: Multimodal Network for Generalizable Point Cloud Completion With Modality Dropout and Progressive Decoding","summary":"Point cloud completion aims to recover complete 3D geometry from partial observations caused by limited viewpoints and occlusions. Existing learning-based works, including 3D Convolutional Neural Network (CNN)-based, point-based, and Transformer-based methods, have achieved strong performance on synthetic benchmarks. However, due to the limitations of modality, scalability, and generative capacity, their generalization to novel objects and real-world scenarios remains challenging. In this paper, we propose MGPC, a generalizable multimodal point cloud completion framework that integrates point clouds, RGB images, and text within a unified architecture. MGPC introduces an innovative modality dropout strategy, a Transformer-based fusion module, and a novel progressive generator to improve robustness, scalability, and geometric modeling capability. We further develop an automatic data generation pipeline and construct MGPC-1M, a large-scale benchmark with over 1,000 categories and one million training pairs. Extensive experiments on MGPC-1M and in-the-wild data demonstrate that the proposed method consistently outperforms prior baselines and exhibits strong generalization under real-world conditions.","authors":["Jiangyuan Liu","Hongxuan Ma","Yuhao Zhao","Zhe Liu","Jian Wang","Wei Zou"],"pdf_url":"","comment":"Code and dataset are available at https://github.com/L-J-Yuan/MGPC"},{"id":"http://arxiv.org/abs/2601.03655v1","updated":"2026-01-07T07:10:32Z","published":"2026-01-07T07:10:32Z","title":"VideoMemory: Toward Consistent Video Generation via Memory Integration","summary":"Maintaining consistent characters, props, and environments across multiple shots is a central challenge in narrative video generation. Existing models can produce high-quality short clips but often fail to preserve entity identity and appearance when scenes change or when entities reappear after long temporal gaps. We present VideoMemory, an entity-centric framework that integrates narrative planning with visual generation through a Dynamic Memory Bank. Given a structured script, a multi-agent system decomposes the narrative into shots, retrieves entity representations from memory, and synthesizes keyframes and videos conditioned on these retrieved states. The Dynamic Memory Bank stores explicit visual and semantic descriptors for characters, props, and backgrounds, and is updated after each shot to reflect story-driven changes while preserving identity. This retrieval-update mechanism enables consistent portrayal of entities across distant shots and supports coherent long-form generation. To evaluate this setting, we construct a 54-case multi-shot consistency benchmark covering character-, prop-, and background-persistent scenarios. Extensive experiments show that VideoMemory achieves strong entity-level coherence and high perceptual quality across diverse narrative sequences.","authors":["Jinsong Zhou","Yihua Du","Xinli Xu","Luozhou Wang","Zijie Zhuang","Yehang Zhang","Shuaibo Li","Xiaojun Hu","Bolan Su","Ying-cong Chen"],"pdf_url":"","comment":"Project page: https://hit-perfect.github.io/VideoMemory/"},{"id":"http://arxiv.org/abs/2509.20823v3","updated":"2026-01-07T07:03:34Z","published":"2025-09-25T07:10:03Z","title":"CaTS-Bench: Can Language Models Describe Time Series?","summary":"Time series captioning, the task of describing time series in natural language, requires numeric and temporal reasoning, trend interpretation, and contextual understanding. Existing benchmarks, however, often rely on fully synthetic or generic captions, and typically neglect metadata and visual representations. We introduce \\textbf{CaTS-Bench}, a comprehensive benchmark for \\textbf{C}ontext-\\textbf{a}ware \\textbf{T}ime \\textbf{S}eries reasoning across $11$ diverse domains, centered on a gold-standard evaluation set of $1746$ human-rewritten captions that measure how effectively models translate numeric trends into immediately interpretable narratives. To address the scarcity of human-annotated data, we also propose a scalable pipeline for generating high-fidelity synthetic captions, the quality of which we validate. We evaluate leading Vision-Language Models on our benchmark, revealing that even proprietary models struggle to capture numeric nuances in temporal descriptions, while finetuning open-source models on synthetic data yields substantial performance gains. Finally, we release a diagnostic suite of $910$ multiple-choice questions and tailored numeric metrics to gauge time-series-specific reasoning capabilities, establishing CaTS-Bench as a reliable foundation for grounded, multimodal language generation in numeric domains.","authors":["Luca Zhou","Pratham Yashwante","Marshall Fisher","Alessio Sampieri","Zihao Zhou","Fabio Galasso","Rose Yu"],"pdf_url":"","comment":"8 pages, 6 figures, 3 tables in the main paper. Many more in the appendix"},{"id":"http://arxiv.org/abs/2512.13683v2","updated":"2026-01-07T06:29:58Z","published":"2025-12-15T18:59:13Z","title":"I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners","summary":"Generalization remains the central challenge for interactive 3D scene generation. Existing learning-based approaches ground spatial understanding in limited scene dataset, restricting generalization to new layouts. We instead reprogram a pre-trained 3D instance generator to act as a scene level learner, replacing dataset-bounded supervision with model-centric spatial supervision. This reprogramming unlocks the generator transferable spatial knowledge, enabling generalization to unseen layouts and novel object compositions. Remarkably, spatial reasoning still emerges even when the training scenes are randomly composed objects. This demonstrates that the generator's transferable scene prior provides a rich learning signal for inferring proximity, support, and symmetry from purely geometric cues. Replacing widely used canonical space, we instantiate this insight with a view-centric formulation of the scene space, yielding a fully feed-forward, generalizable scene generator that learns spatial relations directly from the instance model. Quantitative and qualitative results show that a 3D instance generator is an implicit spatial learner and reasoner, pointing toward foundation models for interactive 3D scene understanding and generation. Project page: https://luling06.github.io/I-Scene-project/","authors":["Lu Ling","Yunhao Ge","Yichen Sheng","Aniket Bera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03637v1","updated":"2026-01-07T06:28:16Z","published":"2026-01-07T06:28:16Z","title":"CrackSegFlow: Controllable Flow-Matching Synthesis for Generalizable Crack Segmentation with the CSF-50K Benchmark","summary":"Automated crack segmentation is essential for scalable condition assessment of pavements and civil infrastructure, yet practical deployment is limited by scarce pixel-level labels and severe domain shift across sensors, illumination, textures, and annotation conventions. This paper presents CrackSegFlow, a controllable flow-matching synthesis framework that generates photorealistic crack images conditioned on binary masks while preserving strict mask-image alignment. The generator combines topology-preserving mask injection with boundary-gated modulation to maintain thin-structure continuity and suppress texture-driven false positives. A second class-conditional flow-matching model synthesizes crack masks with explicit control over crack coverage, enabling balanced, topology-diverse paired data without additional manual annotation. We further inject crack masks into crack-free backgrounds to diversify illumination and surface artifacts and reduce false positives caused by shadows, joints, and pavement markings. Experiments on five benchmarks spanning four asphalt datasets and the crack class of a concrete-domain dataset demonstrate consistent improvements under an established hybrid CNN--Transformer segmentation backbone and a fixed training protocol. With real plus synthesized pairs, in-domain performance improves on average by 5.37 mIoU and 5.13 F1, and target-guided cross-domain synthesis yields average gains of 13.12 mIoU and 14.82 F1 using only limited target mask statistics. Compared with diffusion-based semantic synthesis, CrackSegFlow provides substantially faster deterministic sampling and improves fidelity and mask-image alignment for thin-structure crack geometry. Finally, we release CSF-50K, a public dataset of 50,000 paired crack images and pixel-accurate masks for large-scale benchmarking of generalizable crack segmentation.","authors":["Babak Asadi","Peiyang Wu","Mani Golparvar-Fard","Ramez Hajj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03633v1","updated":"2026-01-07T06:24:26Z","published":"2026-01-07T06:24:26Z","title":"MFC-RFNet: A Multi-scale Guided Rectified Flow Network for Radar Sequence Prediction","summary":"Accurate and high-resolution precipitation nowcasting from radar echo sequences is crucial for disaster mitigation and economic planning, yet it remains a significant challenge. Key difficulties include modeling complex multi-scale evolution, correcting inter-frame feature misalignment caused by displacement, and efficiently capturing long-range spatiotemporal context without sacrificing spatial fidelity. To address these issues, we present the Multi-scale Feature Communication Rectified Flow (RF) Network (MFC-RFNet), a generative framework that integrates multi-scale communication with guided feature fusion. To enhance multi-scale fusion while retaining fine detail, a Wavelet-Guided Skip Connection (WGSC) preserves high-frequency components, and a Feature Communication Module (FCM) promotes bidirectional cross-scale interaction. To correct inter-frame displacement, a Condition-Guided Spatial Transform Fusion (CGSTF) learns spatial transforms from conditioning echoes to align shallow features. The backbone adopts rectified flow training to learn near-linear probability-flow trajectories, enabling few-step sampling with stable fidelity. Additionally, lightweight Vision-RWKV (RWKV) blocks are placed at the encoder tail, the bottleneck, and the first decoder layer to capture long-range spatiotemporal dependencies at low spatial resolutions with moderate compute. Evaluations on four public datasets (SEVIR, MeteoNet, Shanghai, and CIKM) demonstrate consistent improvements over strong baselines, yielding clearer echo morphology at higher rain-rate thresholds and sustained skill at longer lead times. These results suggest that the proposed synergy of RF training with scale-aware communication, spatial alignment, and frequency-aware fusion presents an effective and robust approach for radar-based nowcasting.","authors":["Wenjie Luo","Chuanhu Deng","Chaorong Li","Rongyao Deng","Qiang Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16925v2","updated":"2026-01-07T06:16:41Z","published":"2025-11-04T07:24:45Z","title":"V-Agent: An Interactive Video Search System Using Vision-Language Models","summary":"We introduce V-Agent, a novel multi-agent platform designed for advanced video search and interactive user-system conversations. By fine-tuning a vision-language model (VLM) with a small video preference dataset and enhancing it with a retrieval vector from an image-text retrieval model, we overcome the limitations of traditional text-based retrieval systems in multimodal scenarios. The VLM-based retrieval model independently embeds video frames and audio transcriptions from an automatic speech recognition (ASR) module into a shared multimodal representation space, enabling V-Agent to interpret both visual and spoken content for context-aware video search. This system consists of three agents-a routing agent, a search agent, and a chat agent-that work collaboratively to address user intents by refining search outputs and communicating with users. The search agent utilizes the VLM-based retrieval model together with an additional re-ranking module to further enhance video retrieval quality. Our proposed framework demonstrates state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark, highlighting its potential for both academic research and real-world applications. The retrieval model and demo videos are available at https://huggingface.co/NCSOFT/multimodal-embedding.","authors":["SunYoung Park","Jong-Hyeon Lee","Youngjune Kim","Daegyu Sung","Younghyun Yu","Young-rok Cha","Jeongho Ju"],"pdf_url":"","comment":"CIKM 2025 MMGENSR Workshop"},{"id":"http://arxiv.org/abs/2601.03625v1","updated":"2026-01-07T06:12:05Z","published":"2026-01-07T06:12:05Z","title":"Shape Classification using Approximately Convex Segment Features","summary":"The existing object classification techniques based on descriptive features rely on object alignment to compute the similarity of objects for classification. This paper replaces the necessity of object alignment through sorting of feature. The object boundary is normalized and segmented into approximately convex segments and the segments are then sorted in descending order of their length. The segment length, number of extreme points in segments, area of segments, the base and the width of the segments - a bag of features - is used to measure the similarity between image boundaries. The proposed method is tested on datasets and acceptable results are observed.","authors":["Bimal Kumar Ray"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04514v2","updated":"2026-01-07T06:02:37Z","published":"2025-10-06T06:05:36Z","title":"ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering","summary":"Recent multimodal LLMs have shown promise in chart-based visual question answering, but their performance declines sharply on unannotated charts-those requiring precise visual interpretation rather than relying on textual shortcuts. To address this, we introduce ChartAgent, a novel agentic framework that explicitly performs visual reasoning directly within the chart's spatial domain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively decomposes queries into visual subtasks and actively manipulates and interacts with chart images through specialized actions such as drawing annotations, cropping regions (e.g., segmenting pie slices, isolating bars), and localizing axes, using a library of chart-specific vision tools to fulfill each subtask. This iterative reasoning process closely mirrors human cognitive strategies for chart comprehension. ChartAgent achieves state-of-the-art accuracy on the ChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07% absolute gain overall and 17.31% on unannotated, numerically intensive queries. Furthermore, our analyses show that ChartAgent is (a) effective across diverse chart types, (b) achieves the highest scores across varying visual and reasoning complexity levels, and (c) serves as a plug-and-play framework that boosts performance across diverse underlying LLMs. Our work is among the first to demonstrate visually grounded reasoning for chart understanding using tool-augmented multimodal agents.","authors":["Rachneet Kaur","Nishan Srishankar","Zhen Zeng","Sumitra Ganesh","Manuela Veloso"],"pdf_url":"","comment":"NeurIPS 2025 Multimodal Algorithmic Reasoning Workshop (https://marworkshop.github.io/neurips25/) (Oral Paper Presentation)"},{"id":"http://arxiv.org/abs/2601.03617v1","updated":"2026-01-07T05:57:19Z","published":"2026-01-07T05:57:19Z","title":"Systematic Evaluation of Depth Backbones and Semantic Cues for Monocular Pseudo-LiDAR 3D Detection","summary":"Monocular 3D object detection offers a low-cost alternative to LiDAR, yet remains less accurate due to the difficulty of estimating metric depth from a single image. We systematically evaluate how depth backbones and feature engineering affect a monocular Pseudo-LiDAR pipeline on the KITTI validation split. Specifically, we compare NeWCRFs (supervised metric depth) against Depth Anything V2 Metric-Outdoor (Base) under an identical pseudo-LiDAR generation and PointRCNN detection protocol. NeWCRFs yields stronger downstream 3D detection, achieving 10.50\\% AP$_{3D}$ at IoU$=0.7$ on the Moderate split using grayscale intensity (Exp~2). We further test point-cloud augmentations using appearance cues (grayscale intensity) and semantic cues (instance segmentation confidence). Contrary to the expectation that semantics would substantially close the gap, these features provide only marginal gains, and mask-based sampling can degrade performance by removing contextual geometry. Finally, we report a depth-accuracy-versus-distance diagnostic using ground-truth 2D boxes (including Ped/Cyc), highlighting that coarse depth correctness does not fully predict strict 3D IoU. Overall, under an off-the-shelf LiDAR detector, depth-backbone choice and geometric fidelity dominate performance, outweighing secondary feature injection.","authors":["Samson Oseiwe Ajadalu"],"pdf_url":"","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.03609v1","updated":"2026-01-07T05:37:29Z","published":"2026-01-07T05:37:29Z","title":"Unveiling Text in Challenging Stone Inscriptions: A Character-Context-Aware Patching Strategy for Binarization","summary":"Binarization is a popular first step towards text extraction in historical artifacts. Stone inscription images pose severe challenges for binarization due to poor contrast between etched characters and the stone background, non-uniform surface degradation, distracting artifacts, and highly variable text density and layouts. These conditions frequently cause existing binarization techniques to fail and struggle to isolate coherent character regions. Many approaches sub-divide the image into patches to improve text fragment resolution and improve binarization performance. With this in mind, we present a robust and adaptive patching strategy to binarize challenging Indic inscriptions. The patches from our approach are used to train an Attention U-Net for binarization. The attention mechanism allows the model to focus on subtle structural cues, while our dynamic sampling and patch selection method ensures that the model learns to overcome surface noise and layout irregularities. We also introduce a carefully annotated, pixel-precise dataset of Indic stone inscriptions at the character-fragment level. We demonstrate that our novel patching mechanism significantly boosts binarization performance across classical and deep learning baselines. Despite training only on single script Indic dataset, our model exhibits strong zero-shot generalization to other Indic and non-indic scripts, highlighting its robustness and script-agnostic generalization capabilities. By producing clean, structured representations of inscription content, our method lays the foundation for downstream tasks such as script identification, OCR, and historical text analysis. Project page: https://ihdia.iiit.ac.in/shilalekhya-binarization/","authors":["Pratyush Jena","Amal Joseph","Arnav Sharma","Ravi Kiran Sarvadevabhatla"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13720v2","updated":"2026-01-07T05:36:57Z","published":"2025-11-17T18:59:57Z","title":"Back to Basics: Let Denoising Generative Models Denoise","summary":"Today's denoising diffusion models do not \"denoise\" in the classical sense, i.e., they do not directly predict clean images. Rather, the neural networks predict noise or a noised quantity. In this paper, we suggest that predicting clean data and predicting noised quantities are fundamentally different. According to the manifold assumption, natural data should lie on a low-dimensional manifold, whereas noised quantities do not. With this assumption, we advocate for models that directly predict clean data, which allows apparently under-capacity networks to operate effectively in very high-dimensional spaces. We show that simple, large-patch Transformers on pixels can be strong generative models: using no tokenizer, no pre-training, and no extra loss. Our approach is conceptually nothing more than \"Just image Transformers\", or JiT, as we call it. We report competitive results using JiT with large patch sizes of 16 and 32 on ImageNet at resolutions of 256 and 512, where predicting high-dimensional noised quantities can fail catastrophically. With our networks mapping back to the basics of the manifold, our research goes back to basics and pursues a self-contained paradigm for Transformer-based diffusion on raw natural data.","authors":["Tianhong Li","Kaiming He"],"pdf_url":"","comment":"Tech report. Code at https://github.com/LTH14/JiT"},{"id":"http://arxiv.org/abs/2601.03596v1","updated":"2026-01-07T05:27:12Z","published":"2026-01-07T05:27:12Z","title":"Adaptive Attention Distillation for Robust Few-Shot Segmentation under Environmental Perturbations","summary":"Few-shot segmentation (FSS) aims to rapidly learn novel class concepts from limited examples to segment specific targets in unseen images, and has been widely applied in areas such as medical diagnosis and industrial inspection. However, existing studies largely overlook the complex environmental factors encountered in real world scenarios-such as illumination, background, and camera viewpoint-which can substantially increase the difficulty of test images. As a result, models trained under laboratory conditions often fall short of practical deployment requirements. To bridge this gap, in this paper, an environment-robust FSS setting is introduced that explicitly incorporates challenging test cases arising from complex environments-such as motion blur, small objects, and camouflaged targets-to enhance model's robustness under realistic, dynamic conditions. An environment robust FSS benchmark (ER-FSS) is established, covering eight datasets across multiple real world scenarios. In addition, an Adaptive Attention Distillation (AAD) method is proposed, which repeatedly contrasts and distills key shared semantics between known (support) and unknown (query) images to derive class-specific attention for novel categories. This strengthens the model's ability to focus on the correct targets in complex environments, thereby improving environmental robustness. Comparative experiments show that AAD improves mIoU by 3.3% - 8.5% across all datasets and settings, demonstrating superior performance and strong generalization. The source code and dataset are available at: https://github.com/guoqianyu-alberta/Adaptive-Attention-Distillation-for-FSS.","authors":["Qianyu Guo","Jingrong Wu","Jieji Ren","Weifeng Ge","Wenqiang Zhang"],"pdf_url":"","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.03590v1","updated":"2026-01-07T05:13:52Z","published":"2026-01-07T05:13:52Z","title":"Can LLMs See Without Pixels? Benchmarking Spatial Intelligence from Textual Descriptions","summary":"Recent advancements in Spatial Intelligence (SI) have predominantly relied on Vision-Language Models (VLMs), yet a critical question remains: does spatial understanding originate from visual encoders or the fundamental reasoning backbone? Inspired by this question, we introduce SiT-Bench, a novel benchmark designed to evaluate the SI performance of Large Language Models (LLMs) without pixel-level input, comprises over 3,800 expert-annotated items across five primary categories and 17 subtasks, ranging from egocentric navigation and perspective transformation to fine-grained robotic manipulation. By converting single/multi-view scenes into high-fidelity, coordinate-aware textual descriptions, we challenge LLMs to perform symbolic textual reasoning rather than visual pattern matching. Evaluation results of state-of-the-art (SOTA) LLMs reveals that while models achieve proficiency in localized semantic tasks, a significant \"spatial gap\" remains in global consistency. Notably, we find that explicit spatial reasoning significantly boosts performance, suggesting that LLMs possess latent world-modeling potential. Our proposed dataset SiT-Bench serves as a foundational resource to foster the development of spatially-grounded LLM backbones for future VLMs and embodied agents. Our code and benchmark will be released at https://github.com/binisalegend/SiT-Bench .","authors":["Zhongbin Guo","Zhen Yang","Yushan Li","Xinyue Zhang","Wenyu Gao","Jiacheng Wang","Chengzhi Li","Xiangrui Liu","Ping Jian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03586v1","updated":"2026-01-07T05:00:13Z","published":"2026-01-07T05:00:13Z","title":"Detecting AI-Generated Images via Distributional Deviations from Real Images","summary":"The rapid advancement of generative models has significantly enhanced the quality of AI-generated images, raising concerns about misinformation and the erosion of public trust. Detecting AI-generated images has thus become a critical challenge, particularly in terms of generalizing to unseen generative models. Existing methods using frozen pre-trained CLIP models show promise in generalization but treat the image encoder as a basic feature extractor, failing to fully exploit its potential. In this paper, we perform an in-depth analysis of the frozen CLIP image encoder (CLIP-ViT), revealing that it effectively clusters real images in a high-level, abstract feature space. However, it does not truly possess the ability to distinguish between real and AI-generated images. Based on this analysis, we propose a Masking-based Pre-trained model Fine-Tuning (MPFT) strategy, which introduces a Texture-Aware Masking (TAM) mechanism to mask textured areas containing generative model-specific patterns during fine-tuning. This approach compels CLIP-ViT to attend to the \"distributional deviations\"from authentic images for AI-generated image detection, thereby achieving enhanced generalization performance. Extensive experiments on the GenImage and UniversalFakeDetect datasets demonstrate that our method, fine-tuned with only a minimal number of images, significantly outperforms existing approaches, achieving up to 98.2% and 94.6% average accuracy on the two datasets, respectively.","authors":["Yakun Niu","Yingjian Chen","Lei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03579v1","updated":"2026-01-07T04:50:39Z","published":"2026-01-07T04:50:39Z","title":"SpatiaLoc: Leveraging Multi-Level Spatial Enhanced Descriptors for Cross-Modal Localization","summary":"Cross-modal localization using text and point clouds enables robots to localize themselves via natural language descriptions, with applications in autonomous navigation and interaction between humans and robots. In this task, objects often recur across text and point clouds, making spatial relationships the most discriminative cues for localization. Given this characteristic, we present SpatiaLoc, a framework utilizing a coarse-to-fine strategy that emphasizes spatial relationships at both the instance and global levels. In the coarse stage, we introduce a Bezier Enhanced Object Spatial Encoder (BEOSE) that models spatial relationships at the instance level using quadratic Bezier curves. Additionally, a Frequency Aware Encoder (FAE) generates spatial representations in the frequency domain at the global level. In the fine stage, an Uncertainty Aware Gaussian Fine Localizer (UGFL) regresses 2D positions by modeling predictions as Gaussian distributions with a loss function aware of uncertainty. Extensive experiments on KITTI360Pose demonstrate that SpatiaLoc significantly outperforms existing state-of-the-art (SOTA) methods.","authors":["Tianyi Shang","Pengjie Xu","Zhaojun Deng","Zhenyu Li","Zhicong Chen","Lijun Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16923v2","updated":"2026-01-07T04:38:06Z","published":"2025-12-18T18:59:59Z","title":"Generative Refocusing: Flexible Defocus Control from a Single Image","summary":"Depth-of-field control is essential in photography, but getting the perfect focus often takes several tries or special equipment. Single-image refocusing is still difficult. It involves recovering sharp content and creating realistic bokeh. Current methods have significant drawbacks. They need all-in-focus inputs, depend on synthetic data from simulators, and have limited control over aperture. We introduce Generative Refocusing, a two-step process that uses DeblurNet to recover all-in-focus images from various inputs and BokehNet for creating controllable bokeh. Our main innovation is semi-supervised training. This method combines synthetic paired data with unpaired real bokeh images, using EXIF metadata to capture real optical characteristics beyond what simulators can provide. Our experiments show we achieve top performance in defocus deblurring, bokeh synthesis, and refocusing benchmarks. Additionally, our Generative Refocusing allows text-guided adjustments and custom aperture shapes.","authors":["Chun-Wei Tuan Mu","Jia-Bin Huang","Yu-Lun Liu"],"pdf_url":"","comment":"Project website: https://generative-refocusing.github.io/"},{"id":"http://arxiv.org/abs/2412.00112v3","updated":"2026-01-07T04:18:46Z","published":"2024-11-28T05:42:47Z","title":"BiPO: Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis","summary":"Generating natural and expressive human motions from textual descriptions is challenging due to the complexity of coordinating full-body dynamics and capturing nuanced motion patterns over extended sequences that accurately reflect the given text. To address this, we introduce BiPO, Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis, a novel model that enhances text-to-motion synthesis by integrating part-based generation with a bidirectional autoregressive architecture. This integration allows BiPO to consider both past and future contexts during generation while enhancing detailed control over individual body parts without requiring ground-truth motion length. To relax the interdependency among body parts caused by the integration, we devise the Partial Occlusion technique, which probabilistically occludes the certain motion part information during training. In our comprehensive experiments, BiPO achieves state-of-the-art performance on the HumanML3D dataset, outperforming recent methods such as ParCo, MoMask, and BAMM in terms of FID scores and overall motion quality. Notably, BiPO excels not only in the text-to-motion generation task but also in motion editing tasks that synthesize motion based on partially generated motion sequences and textual descriptions. These results reveal the BiPO's effectiveness in advancing text-to-motion synthesis and its potential for practical applications.","authors":["Seong-Eun Hong","Soobin Lim","Juyeong Hwang","Minwook Chang","Hyeongyeop Kang"],"pdf_url":"","comment":"18 pages, 11 figures. Accepted to WACV 2026"},{"id":"http://arxiv.org/abs/2509.22496v4","updated":"2026-01-07T03:38:30Z","published":"2025-09-26T15:38:42Z","title":"Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation","summary":"Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in aligning visual inputs with natural language outputs. Yet, the extent to which generated tokens depend on visual modalities remains poorly understood, limiting interpretability and reliability. In this work, we present EAGLE, a lightweight black-box framework for explaining autoregressive token generation in MLLMs. EAGLE attributes any selected tokens to compact perceptual regions while quantifying the relative influence of language priors and perceptual evidence. The framework introduces an objective function that unifies sufficiency (insight score) and indispensability (necessity score), optimized via greedy search over sparsified image regions for faithful and efficient attribution. Beyond spatial attribution, EAGLE performs modality-aware analysis that disentangles what tokens rely on, providing fine-grained interpretability of model decisions. Extensive experiments across open-source MLLMs show that EAGLE consistently outperforms existing methods in faithfulness, localization, and hallucination diagnosis, while requiring substantially less GPU memory. These results highlight its effectiveness and practicality for advancing the interpretability of MLLMs.","authors":["Ruoyu Chen","Xiaoqing Guo","Kangwei Liu","Siyuan Liang","Shiming Liu","Qunli Zhang","Laiyuan Wang","Hua Zhang","Xiaochun Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03549v1","updated":"2026-01-07T03:32:28Z","published":"2026-01-07T03:32:28Z","title":"EASLT: Emotion-Aware Sign Language Translation","summary":"Sign Language Translation (SLT) is a complex cross-modal task requiring the integration of Manual Signals (MS) and Non-Manual Signals (NMS). While recent gloss-free SLT methods have made strides in translating manual gestures, they frequently overlook the semantic criticality of facial expressions, resulting in ambiguity when distinct concepts share identical manual articulations. To address this, we present **EASLT** (**E**motion-**A**ware **S**ign **L**anguage **T**ranslation), a framework that treats facial affect not as auxiliary information, but as a robust semantic anchor. Unlike methods that relegate facial expressions to a secondary role, EASLT incorporates a dedicated emotional encoder to capture continuous affective dynamics. These representations are integrated via a novel *Emotion-Aware Fusion* (EAF) module, which adaptively recalibrates spatio-temporal sign features based on affective context to resolve semantic ambiguities. Extensive evaluations on the PHOENIX14T and CSL-Daily benchmarks demonstrate that EASLT establishes advanced performance among gloss-free methods, achieving BLEU-4 scores of 26.15 and 22.80, and BLEURT scores of 61.0 and 57.8, respectively. Ablation studies confirm that explicitly modeling emotion effectively decouples affective semantics from manual dynamics, significantly enhancing translation fidelity. Code is available at https://github.com/TuGuobin/EASLT.","authors":["Guobin Tu","Di Weng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.00412v2","updated":"2026-01-07T03:25:48Z","published":"2025-08-01T08:10:54Z","title":"Sortblock: Similarity-Aware Feature Reuse for Diffusion Model","summary":"Diffusion Transformers (DiTs) have demonstrated remarkable generative capabilities, particularly benefiting from Transformer architectures that enhance visual and artistic fidelity. However, their inherently sequential denoising process results in high inference latency, limiting their deployment in real-time scenarios. Existing training-free acceleration approaches typically reuse intermediate features at fixed timesteps or layers, overlooking the evolving semantic focus across denoising stages and Transformer blocks.To address this, we propose Sortblock, a training-free inference acceleration framework that dynamically caches block-wise features based on their similarity across adjacent timesteps. By ranking the evolution of residuals, Sortblock adaptively determines a recomputation ratio, selectively skipping redundant computations while preserving generation quality. Furthermore, we incorporate a lightweight linear prediction mechanism to reduce accumulated errors in skipped blocks.Extensive experiments across various tasks and DiT architectures demonstrate that Sortblock achieves over 2$\\times$ inference speedup with minimal degradation in output quality, offering an effective and generalizable solution for accelerating diffusion-based generative models.","authors":["Hanqi Chen","Xu Zhang","Xiaoliu Guan","Lielin Jiang","Guanzhong Wang","Zeyu Chen","Yi Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17306v2","updated":"2026-01-07T03:10:43Z","published":"2025-12-19T07:44:43Z","title":"Deep But Reliable: Advancing Multi-turn Reasoning for Thinking with Images","summary":"Recent advances in large Vision-Language Models (VLMs) have exhibited strong reasoning capabilities on complex visual tasks by thinking with images in their Chain-of-Thought (CoT), which is achieved by actively invoking tools to analyze visual inputs rather than merely perceiving them. However, existing models often struggle to reflect on and correct themselves when attempting incorrect reasoning trajectories. To address this limitation, we propose DRIM, a model that enables deep but reliable multi-turn reasoning when thinking with images in its multimodal CoT. Our pipeline comprises three stages: data construction, cold-start SFT and RL. Based on a high-resolution image dataset, we construct high-difficulty and verifiable visual question-answer pairs, where solving each task requires multi-turn tool calls to reach the correct answer. In the SFT stage, we collect tool trajectories as cold-start data, guiding a multi-turn reasoning pattern. In the RL stage, we introduce redundancy-penalized policy optimization, which incentivizes the model to develop a self-reflective reasoning pattern. The basic idea is to impose judgment on reasoning trajectories and penalize those that produce incorrect answers without sufficient multi-scale exploration. Extensive experiments demonstrate that DRIM achieves superior performance on visual understanding benchmarks.","authors":["Wenhao Yang","Yu Xia","Jinlong Huang","Shiyin Lu","Qing-Guo Chen","Zhao Xu","Weihua Luo","Kaifu Zhang","Yuanyu Wan","Lijun Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03534v1","updated":"2026-01-07T02:46:51Z","published":"2026-01-07T02:46:51Z","title":"Persona-aware and Explainable Bikeability Assessment: A Vision-Language Model Approach","summary":"Bikeability assessment is essential for advancing sustainable urban transportation and creating cyclist-friendly cities, and it requires incorporating users' perceptions of safety and comfort. Yet existing perception-based bikeability assessment approaches face key limitations in capturing the complexity of road environments and adequately accounting for heterogeneity in subjective user perceptions. This paper proposes a persona-aware Vision-Language Model framework for bikeability assessment with three novel contributions: (i) theory-grounded persona conditioning based on established cyclist typology that generates persona-specific explanations via chain-of-thought reasoning; (ii) multi-granularity supervised fine-tuning that combines scarce expert-annotated reasoning with abundant user ratings for joint prediction and explainable assessment; and (iii) AI-enabled data augmentation that creates controlled paired data to isolate infrastructure variable impacts. To test and validate this framework, we developed a panoramic image-based crowdsourcing system and collected 12,400 persona-conditioned assessments from 427 cyclists. Experiment results show that the proposed framework offers competitive bikeability rating prediction while uniquely enabling explainable factor attribution.","authors":["Yilong Dai","Ziyi Wang","Chenguang Wang","Kexin Zhou","Yiheng Qian","Susu Xu","Xiang Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.09632v2","updated":"2026-01-07T02:46:01Z","published":"2025-03-11T20:52:01Z","title":"Adaptive Anomaly Recovery for Telemanipulation: A Diffusion Model Approach to Vision-Based Tracking","summary":"Dexterous telemanipulation critically relies on the continuous and stable tracking of the human operator's commands to ensure robust operation. Vison-based tracking methods are widely used but have low stability due to anomalies such as occlusions, inadequate lighting, and loss of sight. Traditional filtering, regression, and interpolation methods are commonly used to compensate for explicit information such as angles and positions. These approaches are restricted to low-dimensional data and often result in information loss compared to the original high-dimensional image and video data. Recent advances in diffusion-based approaches, which can operate on high-dimensional data, have achieved remarkable success in video reconstruction and generation. However, these methods have not been fully explored in continuous control tasks in robotics. This work introduces the Diffusion-Enhanced Telemanipulation (DET) framework, which incorporates the Frame-Difference Detection (FDD) technique to identify and segment anomalies in video streams. These anomalous clips are replaced after reconstruction using diffusion models, ensuring robust telemanipulation performance under challenging visual conditions. We validated this approach in various anomaly scenarios and compared it with the baseline methods. Experiments show that DET achieves an average RMSE reduction of 17.2% compared to the cubic spline and 51.1% compared to FFT-based interpolation for different occlusion durations.","authors":["Haoyang Wang","Haoran Guo","Lingfeng Tao","Zhengxiong Li"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2512.22298v2","updated":"2026-01-07T02:45:57Z","published":"2025-12-26T00:54:24Z","title":"Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware","summary":"In-cabin driver monitoring systems (DMS) must recognize distraction- and drowsiness-related behaviors with low latency under strict constraints on compute, power, and cost. We present a single-camera in-cabin driver behavior recognition system designed for deployment on two low-cost edge platforms: Raspberry Pi 5 (CPU-only) and the Google Coral development board with an Edge Tensor Processing Unit (Edge TPU) accelerator. The proposed pipeline combines (i) a compact per-frame vision model, (ii) a confounder-aware label taxonomy to reduce confusions among visually similar behaviors, and (iii) a temporal decision head that triggers alerts only when predictions are both confident and sustained. The system supports 17 behavior classes. Training and evaluation use licensed datasets plus in-house collection (over 800,000 labeled frames) with driver-disjoint splits, and we further validate the deployed system in live in-vehicle tests. End-to-end performance reaches approximately 16 FPS on Raspberry Pi 5 using 8-bit integer (INT8) inference (per-frame latency <60 ms) and approximately 25 FPS on Coral Edge TPU (end-to-end latency ~40 ms), enabling real-time monitoring and stable alert generation on embedded hardware. Finally, we discuss how reliable in-cabin perception can serve as an upstream signal for human-centered vehicle intelligence, including emerging agentic vehicle concepts.","authors":["Vesal Ahsani","Babak Hossein Khalaj","Hamed Shah-Mansouri"],"pdf_url":"","comment":"27 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2601.03528v1","updated":"2026-01-07T02:31:17Z","published":"2026-01-07T02:31:17Z","title":"CloudMatch: Weak-to-Strong Consistency Learning for Semi-Supervised Cloud Detection","summary":"Due to the high cost of annotating accurate pixel-level labels, semi-supervised learning has emerged as a promising approach for cloud detection. In this paper, we propose CloudMatch, a semi-supervised framework that effectively leverages unlabeled remote sensing imagery through view-consistency learning combined with scene-mixing augmentations. An observation behind CloudMatch is that cloud patterns exhibit structural diversity and contextual variability across different scenes and within the same scene category. Our key insight is that enforcing prediction consistency across diversely augmented views, incorporating both inter-scene and intra-scene mixing, enables the model to capture the structural diversity and contextual richness of cloud patterns. Specifically, CloudMatch generates one weakly augmented view along with two complementary strongly augmented views for each unlabeled image: one integrates inter-scene patches to simulate contextual variety, while the other employs intra-scene mixing to preserve semantic coherence. This approach guides pseudolabel generation and enhances generalization. Extensive experiments show that CloudMatch achieves good performance, demonstrating its capability to utilize unlabeled data efficiently and advance semi-supervised cloud detection.","authors":["Jiayi Zhao","Changlu Chen","Jingsheng Li","Tianxiang Xue","Kun Zhan"],"pdf_url":"","comment":"Journal of Applied Remote Sensing"},{"id":"http://arxiv.org/abs/2601.03526v1","updated":"2026-01-07T02:30:27Z","published":"2026-01-07T02:30:27Z","title":"Physics-Constrained Cross-Resolution Enhancement Network for Optics-Guided Thermal UAV Image Super-Resolution","summary":"Optics-guided thermal UAV image super-resolution has attracted significant research interest due to its potential in all-weather monitoring applications. However, existing methods typically compress optical features to match thermal feature dimensions for cross-modal alignment and fusion, which not only causes the loss of high-frequency information that is beneficial for thermal super-resolution, but also introduces physically inconsistent artifacts such as texture distortions and edge blurring by overlooking differences in the imaging physics between modalities. To address these challenges, we propose PCNet to achieve cross-resolution mutual enhancement between optical and thermal modalities, while physically constraining the optical guidance process via thermal conduction to enable robust thermal UAV image super-resolution. In particular, we design a Cross-Resolution Mutual Enhancement Module (CRME) to jointly optimize thermal image super-resolution and optical-to-thermal modality conversion, facilitating effective bidirectional feature interaction across resolutions while preserving high-frequency optical priors. Moreover, we propose a Physics-Driven Thermal Conduction Module (PDTM) that incorporates two-dimensional heat conduction into optical guidance, modeling spatially-varying heat conduction properties to prevent inconsistent artifacts. In addition, we introduce a temperature consistency loss that enforces regional distribution consistency and boundary gradient smoothness to ensure generated thermal images align with real-world thermal radiation principles. Extensive experiments on VGTSR2.0 and DroneVehicle datasets demonstrate that PCNet significantly outperforms state-of-the-art methods on both reconstruction quality and downstream tasks including semantic segmentation and object detection.","authors":["Zhicheng Zhao","Fengjiao Peng","Jinquan Yan","Wei Lu","Chenglong Li","Jin Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03517v1","updated":"2026-01-07T02:06:26Z","published":"2026-01-07T02:06:26Z","title":"Semantic Belief-State World Model for 3D Human Motion Prediction","summary":"Human motion prediction has traditionally been framed as a sequence regression problem where models extrapolate future joint coordinates from observed pose histories. While effective over short horizons this approach does not separate observation reconstruction with dynamics modeling and offers no explicit representation of the latent causes governing motion. As a result, existing methods exhibit compounding drift, mean-pose collapse, and poorly calibrated uncertainty when rolled forward beyond the training regime. Here we propose a Semantic Belief-State World Model (SBWM) that reframes human motion prediction as latent dynamical simulation on the human body manifold. Rather than predicting poses directly, SBWM maintains a recurrent probabilistic belief state whose evolution is learned independently of pose reconstruction and explicitly aligned with the SMPL-X anatomical parameterization. This alignment imposes a structural information bottleneck that prevents the latent state from encoding static geometry or sensor noise, forcing it to capture motion dynamics, intent, and control-relevant structure. Inspired by belief-state world models developed for model-based reinforcement learning, SBWM adapts stochastic latent transitions and rollout-centric training to the domain of human motion. In contrast to RSSM-based, transformer, and diffusion approaches optimized for reconstruction fidelity, SBWM prioritizes stable forward simulation. We demonstrate coherent long-horizon rollouts, and competitive accuracy at substantially lower computational cost. These results suggest that treating the human body as part of the world models state space rather than its output fundamentally changes how motion is simulated, and predicted.","authors":["Sarim Chaudhry"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03510v1","updated":"2026-01-07T01:44:29Z","published":"2026-01-07T01:44:29Z","title":"G2P: Gaussian-to-Point Attribute Alignment for Boundary-Aware 3D Semantic Segmentation","summary":"Semantic segmentation on point clouds is critical for 3D scene understanding. However, sparse and irregular point distributions provide limited appearance evidence, making geometry-only features insufficient to distinguish objects with similar shapes but distinct appearances (e.g., color, texture, material). We propose Gaussian-to-Point (G2P), which transfers appearance-aware attributes from 3D Gaussian Splatting to point clouds for more discriminative and appearance-consistent segmentation. Our G2P address the misalignment between optimized Gaussians and original point geometry by establishing point-wise correspondences. By leveraging Gaussian opacity attributes, we resolve the geometric ambiguity that limits existing models. Additionally, Gaussian scale attributes enable precise boundary localization in complex 3D scenes. Extensive experiments demonstrate that our approach achieves superior performance on standard benchmarks and shows significant improvements on geometrically challenging classes, all without any 2D or language supervision.","authors":["Hojun Song","Chae-yeong Song","Jeong-hun Hong","Chaewon Moon","Dong-hwi Kim","Gahyeon Kim","Soo Ye Kim","Yiyi Liao","Jaehyup Lee","Sang-hyo Park"],"pdf_url":"","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2601.03507v1","updated":"2026-01-07T01:41:46Z","published":"2026-01-07T01:41:46Z","title":"REFA: Real-time Egocentric Facial Animations for Virtual Reality","summary":"We present a novel system for real-time tracking of facial expressions using egocentric views captured from a set of infrared cameras embedded in a virtual reality (VR) headset. Our technology facilitates any user to accurately drive the facial expressions of virtual characters in a non-intrusive manner and without the need of a lengthy calibration step. At the core of our system is a distillation based approach to train a machine learning model on heterogeneous data and labels coming form multiple sources, \\eg synthetic and real images. As part of our dataset, we collected 18k diverse subjects using a lightweight capture setup consisting of a mobile phone and a custom VR headset with extra cameras. To process this data, we developed a robust differentiable rendering pipeline enabling us to automatically extract facial expression labels. Our system opens up new avenues for communication and expression in virtual environments, with applications in video conferencing, gaming, entertainment, and remote collaboration.","authors":["Qiang Zhang","Tong Xiao","Haroun Habeeb","Larissa Laich","Sofien Bouaziz","Patrick Snape","Wenjing Zhang","Matthew Cioffi","Peizhao Zhang","Pavel Pidlypenskyi","Winnie Lin","Luming Ma","Mengjiao Wang","Kunpeng Li","Chengjiang Long","Steven Song","Martin Prazak","Alexander Sjoholm","Ajinkya Deogade","Jaebong Lee","Julio Delgado Mangas","Amaury Aubel"],"pdf_url":"","comment":"CVPR 2024 Workshop"},{"id":"http://arxiv.org/abs/2601.03500v1","updated":"2026-01-07T01:27:58Z","published":"2026-01-07T01:27:58Z","title":"SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models","summary":"Large Vision-Language Models (LVLMs) demonstrate significant progress in multimodal understanding and reasoning, yet object hallucination remains a critical challenge. While existing research focuses on mitigating language priors or high-level statistical biases, they often overlook the internal complexities of the visual encoding process. We identify that visual statistical bias, arising from the inherent Bag-of-Patches behavior of Vision Encoders under weak structural supervision, acts as a contributing factor of object hallucinations. Under this bias, models prioritize local texture features within individual patches over holistic geometric structures. This tendency may induce spurious visual confidence and result in hallucinations. To address this, we introduce a training-free algorithm called Structure-Disrupted Contrastive Decoding (SDCD), which performs contrastive calibration of the output distribution by introducing a shuffled structure-disrupted view. By penalizing tokens that maintain high confidence under this structure-less view, SDCD effectively suppresses the texture-driven bias. Experimental results demonstrate that SDCD significantly mitigates hallucinations across multiple benchmarks and enhances the overall multimodal capabilities of LVLMs.","authors":["Yuxuan Xia","Siheng Wang","Peng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03499v1","updated":"2026-01-07T01:27:20Z","published":"2026-01-07T01:27:20Z","title":"GeoDiff-SAR: A Geometric Prior Guided Diffusion Model for SAR Image Generation","summary":"Synthetic Aperture Radar (SAR) imaging results are highly sensitive to observation geometries and the geometric parameters of targets. However, existing generative methods primarily operate within the image domain, neglecting explicit geometric information. This limitation often leads to unsatisfactory generation quality and the inability to precisely control critical parameters such as azimuth angles. To address these challenges, we propose GeoDiff-SAR, a geometric prior guided diffusion model for high-fidelity SAR image generation. Specifically, GeoDiff-SAR first efficiently simulates the geometric structures and scattering relationships inherent in real SAR imaging by calculating SAR point clouds at specific azimuths, which serves as a robust physical guidance. Secondly, to effectively fuse multi-modal information, we employ a feature fusion gating network based on Feature-wise Linear Modulation (FiLM) to dynamically regulate the weight distribution of 3D physical information, image control parameters, and textual description parameters. Thirdly, we utilize the Low-Rank Adaptation (LoRA) architecture to perform lightweight fine-tuning on the advanced Stable Diffusion 3.5 (SD3.5) model, enabling it to rapidly adapt to the distribution characteristics of the SAR domain. To validate the effectiveness of GeoDiff-SAR, extensive comparative experiments were conducted on real-world SAR datasets. The results demonstrate that data generated by GeoDiff-SAR exhibits high fidelity and effectively enhances the accuracy of downstream classification tasks. In particular, it significantly improves recognition performance across different azimuth angles, thereby underscoring the superiority of physics-guided generation.","authors":["Fan Zhang","Xuanting Wu","Fei Ma","Qiang Yin","Yuxin Hu"],"pdf_url":"","comment":"22 pages, 17 figures"},{"id":"http://arxiv.org/abs/2601.03490v1","updated":"2026-01-07T01:02:39Z","published":"2026-01-07T01:02:39Z","title":"CroBIM-U: Uncertainty-Driven Referring Remote Sensing Image Segmentation","summary":"Referring remote sensing image segmentation aims to localize specific targets described by natural language within complex overhead imagery. However, due to extreme scale variations, dense similar distractors, and intricate boundary structures, the reliability of cross-modal alignment exhibits significant \\textbf{spatial non-uniformity}. Existing methods typically employ uniform fusion and refinement strategies across the entire image, which often introduces unnecessary linguistic perturbations in visually clear regions while failing to provide sufficient disambiguation in confused areas. To address this, we propose an \\textbf{uncertainty-guided framework} that explicitly leverages a pixel-wise \\textbf{referring uncertainty map} as a spatial prior to orchestrate adaptive inference. Specifically, we introduce a plug-and-play \\textbf{Referring Uncertainty Scorer (RUS)}, which is trained via an online error-consistency supervision strategy to interpretably predict the spatial distribution of referential ambiguity. Building on this prior, we design two plug-and-play modules: 1) \\textbf{Uncertainty-Gated Fusion (UGF)}, which dynamically modulates language injection strength to enhance constraints in high-uncertainty regions while suppressing noise in low-uncertainty ones; and 2) \\textbf{Uncertainty-Driven Local Refinement (UDLR)}, which utilizes uncertainty-derived soft masks to focus refinement on error-prone boundaries and fine details. Extensive experiments demonstrate that our method functions as a unified, plug-and-play solution that significantly improves robustness and geometric fidelity in complex remote sensing scenes without altering the backbone architecture.","authors":["Yuzhe Sun","Zhe Dong","Haochen Jiang","Tianzhu Liu","Yanfeng Gu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.07960v4","updated":"2026-01-07T00:56:18Z","published":"2025-04-10T17:59:42Z","title":"VisualCloze: A Universal Image Generation Framework via Visual In-Context Learning","summary":"Recent progress in diffusion models significantly advances various image generation tasks. However, the current mainstream approach remains focused on building task-specific models, which have limited efficiency when supporting a wide range of different needs. While universal models attempt to address this limitation, they face critical challenges, including generalizable task instruction, appropriate task distributions, and unified architectural design. To tackle these challenges, we propose VisualCloze, a universal image generation framework, which supports a wide range of in-domain tasks, generalization to unseen ones, unseen unification of multiple tasks, and reverse generation. Unlike existing methods that rely on language-based task instruction, leading to task ambiguity and weak generalization, we integrate visual in-context learning, allowing models to identify tasks from visual demonstrations. Meanwhile, the inherent sparsity of visual task distributions hampers the learning of transferable knowledge across tasks. To this end, we introduce Graph200K, a graph-structured dataset that establishes various interrelated tasks, enhancing task density and transferable knowledge. Furthermore, we uncover that our unified image generation formulation shared a consistent objective with image infilling, enabling us to leverage the strong generative priors of pre-trained infilling models without modifying the architectures.","authors":["Zhong-Yu Li","Ruoyi Du","Juncheng Yan","Le Zhuo","Qilong Wu","Zhen Li","Peng Gao","Zhanyu Ma","Ming-Ming Cheng"],"pdf_url":"","comment":"Accepted at ICCV 2025. Project page: https://visualcloze.github.io"},{"id":"http://arxiv.org/abs/2509.01217v3","updated":"2026-01-07T00:21:44Z","published":"2025-09-01T08:03:07Z","title":"Learn2Reg 2024: New Benchmark Datasets Driving Progress on New Challenges","summary":"Medical image registration is critical for clinical applications, and fair benchmarking of different methods is essential for monitoring ongoing progress in the field. To date, the Learn2Reg 2020-2023 challenges have released several complementary datasets and established metrics for evaluations. Building on this foundation, the 2024 edition expands the challenge's scope to cover a wider range of registration scenarios, particularly in terms of modality diversity and task complexity, by introducing three new tasks, including large-scale multi-modal registration and unsupervised inter-subject brain registration, as well as the first microscopy-focused benchmark within Learn2Reg. The new datasets also inspired new method developments, including invertibility constraints, pyramid features, keypoints alignment and instance optimisation.\n  Visit Learn2Reg at https://learn2reg.grand-challenge.org.","authors":["Lasse Hansen","Wiebke Heyer","Christoph Großbröhmer","Frederic Madesta","Thilo Sentker","Wang Jiazheng","Yuxi Zhang","Hang Zhang","Min Liu","Junyi Wang","Xi Zhu","Yuhua Li","Liwen Wang","Daniil Morozov","Nazim Haouchine","Joel Honkamaa","Pekka Marttinen","Yichao Zhou","Zuopeng Tan","Zhuoyuan Wang","Yi Wang","Hongchao Zhou","Shunbo Hu","Yi Zhang","Qian Tao","Lukas Förner","Thomas Wendler","Bailiang Jian","Christian Wachinger","Jin Kim","Dan Ruan","Marek Wodzinski","Henning Müller","Tony C. W. Mok","Xi Jia","Jinming Duan","Mikael Brudfors","Seyed-Ahmad Ahmadi","Yunzheng Zhu","William Hsu","Tina Kapur","William M. Wells","Alexandra Golby","Aaron Carass","Harrison Bai","Yihao Liu","Perrine Paul-Gilloteaux","Joakim Lindblad","Nataša Sladoje","Andreas Walter","Junyu Chen","Reuben Dorent","Alessa Hering","Mattias P. Heinrich"],"pdf_url":"","comment":"Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:034"},{"id":"http://arxiv.org/abs/2601.04453v1","updated":"2026-01-07T23:49:52Z","published":"2026-01-07T23:49:52Z","title":"UniDrive-WM: Unified Understanding, Planning and Generation World Model For Autonomous Driving","summary":"World models have become central to autonomous driving, where accurate scene understanding and future prediction are crucial for safe control. Recent work has explored using vision-language models (VLMs) for planning, yet existing approaches typically treat perception, prediction, and planning as separate modules. We propose UniDrive-WM, a unified VLM-based world model that jointly performs driving-scene understanding, trajectory planning, and trajectory-conditioned future image generation within a single architecture. UniDrive-WM's trajectory planner predicts a future trajectory, which conditions a VLM-based image generator to produce plausible future frames. These predictions provide additional supervisory signals that enhance scene understanding and iteratively refine trajectory generation. We further compare discrete and continuous output representations for future image prediction, analyzing their influence on downstream driving performance. Experiments on the challenging Bench2Drive benchmark show that UniDrive-WM produces high-fidelity future images and improves planning performance by 5.9% in L2 trajectory error and 9.2% in collision rate over the previous best method. These results demonstrate the advantages of tightly integrating VLM-driven reasoning, planning, and generative world modeling for autonomous driving. The project page is available at https://unidrive-wm.github.io/UniDrive-WM .","authors":["Zhexiao Xiong","Xin Ye","Burhan Yaman","Sheng Cheng","Yiren Lu","Jingru Luo","Nathan Jacobs","Liu Ren"],"pdf_url":"","comment":"Project Page: https://unidrive-wm.github.io/UniDrive-WM"},{"id":"http://arxiv.org/abs/2511.22009v2","updated":"2026-01-07T23:08:18Z","published":"2025-11-27T01:20:27Z","title":"StreamFlow: Theory, Algorithm, and Implementation for High-Efficiency Rectified Flow Generation","summary":"New technologies such as Rectified Flow and Flow Matching have significantly improved the performance of generative models in the past two years, especially in terms of control accuracy, generation quality, and generation efficiency. However, due to some differences in its theory, design, and existing diffusion models, the existing acceleration methods cannot be directly applied to the Rectified Flow model. In this article, we have comprehensively implemented an overall acceleration pipeline from the aspects of theory, design, and reasoning strategies. This pipeline uses new methods such as batch processing with a new velocity field, vectorization of heterogeneous time-step batch processing, and dynamic TensorRT compilation for the new methods to comprehensively accelerate related models based on flow models. Currently, the existing public methods usually achieve an acceleration of 18%, while experiments have proved that our new method can accelerate the 512*512 image generation speed to up to 611%, which is far beyond the current non-generalized acceleration methods.","authors":["Sen Fang","Hongbin Zhong","Yalin Feng","Yanxin Zhang","Dimitris N. Metaxas"],"pdf_url":"","comment":"Improved the quality. Project Page at https://world-snapshot.github.io/StreamFlow/"},{"id":"http://arxiv.org/abs/2601.04442v1","updated":"2026-01-07T23:05:17Z","published":"2026-01-07T23:05:17Z","title":"Addressing Overthinking in Large Vision-Language Models via Gated Perception-Reasoning Optimization","summary":"Large Vision-Language Models (LVLMs) have exhibited strong reasoning capabilities through chain-of-thought mechanisms that generate step-by-step rationales. However, such slow-thinking approaches often lead to overthinking, where models produce excessively verbose responses even for simple queries, resulting in test-time inefficiency and even degraded accuracy. Prior work has attempted to mitigate this issue via adaptive reasoning strategies, but these methods largely overlook a fundamental bottleneck: visual perception failures. We argue that stable reasoning critically depends on low-level visual grounding, and that reasoning errors often originate from imperfect perception rather than insufficient deliberation. To address this limitation, we propose Gated Perception-Reasoning Optimization (GPRO), a meta-reasoning controller that dynamically routes computation among three decision paths at each generation step: a lightweight fast path, a slow perception path for re-examining visual inputs, and a slow reasoning path for internal self-reflection. To learn this distinction, we derive large-scale failure attribution supervision from approximately 790k samples, using teacher models to distinguish perceptual hallucinations from reasoning errors. We then train the controller with multi-objective reinforcement learning to optimize the trade-off between task accuracy and computational cost under uncertainty. Experiments on five benchmarks demonstrate that GPRO substantially improves both accuracy and efficiency, outperforming recent slow-thinking methods while generating significantly shorter responses.","authors":["Xingjian Diao","Zheyuan Liu","Chunhui Zhang","Weiyi Wu","Keyi Kong","Lin Shi","Kaize Ding","Soroush Vosoughi","Jiang Gui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.01839v2","updated":"2026-01-07T22:38:14Z","published":"2025-03-03T18:58:46Z","title":"Jailbreaking Safeguarded Text-to-Image Models via Large Language Models","summary":"Text-to-Image models may generate harmful content, such as pornographic images, particularly when unsafe prompts are submitted. To address this issue, safety filters are often added on top of text-to-image models, or the models themselves are aligned to reduce harmful outputs. However, these defenses remain vulnerable when an attacker strategically designs adversarial prompts to bypass these safety guardrails. In this work, we propose \\alg, a method to jailbreak text-to-image models with safety guardrails using a fine-tuned large language model. Unlike other query-based jailbreak attacks that require repeated queries to the target model, our attack generates adversarial prompts efficiently after fine-tuning our AttackLLM. We evaluate our method on three datasets of unsafe prompts and against five safety guardrails. Our results demonstrate that our approach effectively bypasses safety guardrails, outperforms existing no-box attacks, and also facilitates other query-based attacks.","authors":["Zhengyuan Jiang","Yuepeng Hu","Yuchen Yang","Yinzhi Cao","Neil Zhenqiang Gong"],"pdf_url":"","comment":"Accepted by EACL 2026 Findings"},{"id":"http://arxiv.org/abs/2601.04428v1","updated":"2026-01-07T22:23:56Z","published":"2026-01-07T22:23:56Z","title":"CRUNet-MR-Univ: A Foundation Model for Diverse Cardiac MRI Reconstruction","summary":"In recent years, deep learning has attracted increasing attention in the field of Cardiac MRI (CMR) reconstruction due to its superior performance over traditional methods, particularly in handling higher acceleration factors, highlighting its potential for real-world clinical applications. However, current deep learning methods remain limited in generalizability. CMR scans exhibit wide variability in image contrast, sampling patterns, scanner vendors, anatomical structures, and disease types. Most existing models are designed to handle only a single or narrow subset of these variations, leading to performance degradation when faced with distribution shifts. Therefore, it is beneficial to develop a unified model capable of generalizing across diverse CMR scenarios. To this end, we propose CRUNet-MR-Univ, a foundation model that leverages spatio-temporal correlations and prompt-based priors to effectively handle the full diversity of CMR scans. Our approach consistently outperforms baseline methods across a wide range of settings, highlighting its effectiveness and promise.","authors":["Donghang Lyu","Marius Staring","Hildo Lamb","Mariya Doneva"],"pdf_url":"","comment":"STACOM 2025"},{"id":"http://arxiv.org/abs/2601.04405v1","updated":"2026-01-07T21:23:35Z","published":"2026-01-07T21:23:35Z","title":"From Preoperative CT to Postmastoidectomy Mesh Construction:1Mastoidectomy Shape Prediction for Cochlear Implant Surgery","summary":"Cochlear Implant (CI) surgery treats severe hearing loss by inserting an electrode array into the cochlea to stimulate the auditory nerve. An important step in this procedure is mastoidectomy, which removes part of the mastoid region of the temporal bone to provide surgical access. Accurate mastoidectomy shape prediction from preoperative imaging improves pre-surgical planning, reduces risks, and enhances surgical outcomes. Despite its importance, there are limited deep-learning-based studies regarding this topic due to the challenges of acquiring ground-truth labels. We address this gap by investigating self-supervised and weakly-supervised learning models to predict the mastoidectomy region without human annotations. We propose a hybrid self-supervised and weakly-supervised learning framework to predict the mastoidectomy region directly from preoperative CT scans, where the mastoid remains intact. Our hybrid method achieves a mean Dice score of 0.72 when predicting the complex and boundary-less mastoidectomy shape, surpassing state-of-the-art approaches and demonstrating strong performance. The method provides groundwork for constructing 3D postmastoidectomy surfaces directly from the corresponding preoperative CT scans. To our knowledge, this is the first work that integrating self-supervised and weakly-supervised learning for mastoidectomy shape prediction, offering a robust and efficient solution for CI surgical planning while leveraging 3D T-distribution loss in weakly-supervised medical imaging.","authors":["Yike Zhang","Eduardo Davalos","Dingjie Su","Ange Lou","Jack Noble"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:2505.18368"},{"id":"http://arxiv.org/abs/2601.04404v1","updated":"2026-01-07T21:23:05Z","published":"2026-01-07T21:23:05Z","title":"3D-Agent:Tri-Modal Multi-Agent Collaboration for Scalable 3D Object Annotation","summary":"Driven by applications in autonomous driving robotics and augmented reality 3D object annotation presents challenges beyond 2D annotation including spatial complexity occlusion and viewpoint inconsistency Existing approaches based on single models often struggle to address these issues effectively We propose Tri MARF a novel framework that integrates tri modal inputs including 2D multi view images textual descriptions and 3D point clouds within a multi agent collaborative architecture to enhance large scale 3D annotation Tri MARF consists of three specialized agents a vision language model agent for generating multi view descriptions an information aggregation agent for selecting optimal descriptions and a gating agent that aligns textual semantics with 3D geometry for refined captioning Extensive experiments on Objaverse LVIS Objaverse XL and ABO demonstrate that Tri MARF substantially outperforms existing methods achieving a CLIPScore of 88 point 7 compared to prior state of the art methods retrieval accuracy of 45 point 2 and 43 point 8 on ViLT R at 5 and a throughput of up to 12000 objects per hour on a single NVIDIA A100 GPU","authors":["Jusheng Zhang","Yijia Fan","Zimo Wen","Jian Wang","Keze Wang"],"pdf_url":"","comment":"Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2601.04397v1","updated":"2026-01-07T21:15:16Z","published":"2026-01-07T21:15:16Z","title":"Performance Analysis of Image Classification on Bangladeshi Datasets","summary":"Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification tasks; however, the choice between designing a custom CNN from scratch and employing established pre-trained architectures remains an important practical consideration. In this work, we present a comparative analysis of a custom-designed CNN and several widely used deep learning architectures, including VGG-16, ResNet-50, and MobileNet, for an image classification task. The custom CNN is developed and trained from scratch, while the popular architectures are employed using transfer learning under identical experimental settings. All models are evaluated using standard performance metrics such as accuracy, precision, recall, and F1-score. Experimental results show that pre-trained CNN architectures consistently outperform the custom CNN in terms of classification accuracy and convergence speed, particularly when training data is limited. However, the custom CNN demonstrates competitive performance with significantly fewer parameters and reduced computational complexity. This study highlights the trade-offs between model complexity, performance, and computational efficiency, and provides practical insights into selecting appropriate CNN architectures for image classification problems.","authors":["Mohammed Sami Khan","Fabiha Muniat","Rowzatul Zannat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04382v1","updated":"2026-01-07T20:44:04Z","published":"2026-01-07T20:44:04Z","title":"In-SRAM Radiant Foam Rendering on a Graph Processor","summary":"Many emerging many-core accelerators replace a single large device memory with hundreds to thousands of lightweight cores, each owning only a small local SRAM and exchanging data via explicit on-chip communication. This organization offers high aggregate bandwidth, but it breaks a key assumption behind many volumetric rendering techniques: that rays can randomly access a large, unified scene representation. Rendering efficiently on such hardware therefore requires distributing both data and computation, keeping ray traversal mostly local, and structuring communication into predictable routes.\n  We present a fully in-SRAM, distributed renderer for the \\emph{Radiant Foam} Voronoi-cell volumetric representation on the Graphcore Mk2 IPU, a many-core accelerator with tile-local SRAM and explicit inter-tile communication. Our system shards the scene across tiles and forwards rays between shards through a hierarchical routing overlay, enabling ray marching entirely from on-chip SRAM with predictable communication. On Mip-NeRF~360 scenes, the system attains near-interactive throughput (\\(\\approx\\)1\\,fps at \\mbox{$640\\times480$}) with image and depth quality close to the original GPU-based Radiant Foam implementation, while keeping all scene data and ray state in on-chip SRAM. Beyond demonstrating feasibility, we analyze routing, memory, and scheduling bottlenecks that inform how future distributed-memory accelerators can better support irregular, data-movement-heavy rendering workloads.","authors":["Zulkhuu Tuya","Ignacio Alzugaray","Nicholas Fry","Andrew J. Davison"],"pdf_url":"","comment":"24 pages, 26 figures"},{"id":"http://arxiv.org/abs/2601.04381v1","updated":"2026-01-07T20:41:26Z","published":"2026-01-07T20:41:26Z","title":"Few-Shot LoRA Adaptation of a Flow-Matching Foundation Model for Cross-Spectral Object Detection","summary":"Foundation models for vision are predominantly trained on RGB data, while many safety-critical applications rely on non-visible modalities such as infrared (IR) and synthetic aperture radar (SAR). We study whether a single flow-matching foundation model pre-trained primarily on RGB images can be repurposed as a cross-spectral translator using only a few co-measured examples, and whether the resulting synthetic data can enhance downstream detection. Starting from FLUX.1 Kontext, we insert low-rank adaptation (LoRA) modules and fine-tune them on just 100 paired images per domain for two settings: RGB to IR on the KAIST dataset and RGB to SAR on the M4-SAR dataset. The adapted model translates RGB images into pixel-aligned IR/SAR, enabling us to reuse existing bounding boxes and train object detection models purely in the target modality. Across a grid of LoRA hyperparameters, we find that LPIPS computed on only 50 held-out pairs is a strong proxy for downstream performance: lower LPIPS consistently predicts higher mAP for YOLOv11n on both IR and SAR, and for DETR on KAIST IR test data. Using the best LPIPS-selected LoRA adapter, synthetic IR from external RGB datasets (LLVIP, FLIR ADAS) improves KAIST IR pedestrian detection, and synthetic SAR significantly boosts infrastructure detection on M4-SAR when combined with limited real SAR. Our results suggest that few-shot LoRA adaptation of flow-matching foundation models is a promising path toward foundation-style support for non-visible modalities.","authors":["Maxim Clouser","Kia Khezeli","John Kalantari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04378v1","updated":"2026-01-07T20:35:02Z","published":"2026-01-07T20:35:02Z","title":"Aligned explanations in neural networks","summary":"Feature attribution is the dominant paradigm for explaining deep neural networks. However, most existing methods only loosely reflect the model's prediction-making process, thereby merely white-painting the black box. We argue that explanatory alignment is a key aspect of trustworthiness in prediction tasks: explanations must be directly linked to predictions, rather than serving as post-hoc rationalizations. We present model readability as a design principle enabling alignment, and PiNets as a modeling framework to pursue it in a deep learning context. PiNets are pseudo-linear networks that produce instance-wise linear predictions in an arbitrary feature space, making them linearly readable. We illustrate their use on image classification and segmentation tasks, demonstrating how PiNets produce explanations that are faithful across multiple criteria in addition to alignment.","authors":["Corentin Lobet","Francesca Chiaromonte"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04376v1","updated":"2026-01-07T20:32:34Z","published":"2026-01-07T20:32:34Z","title":"Combining facial videos and biosignals for stress estimation during driving","summary":"Reliable stress recognition from facial videos is challenging due to stress's subjective nature and voluntary facial control. While most methods rely on Facial Action Units, the role of disentangled 3D facial geometry remains underexplored. We address this by analyzing stress during distracted driving using EMOCA-derived 3D expression and pose coefficients. Paired hypothesis tests between baseline and stressor phases reveal that 41 of 56 coefficients show consistent, phase-specific stress responses comparable to physiological markers. Building on this, we propose a Transformer-based temporal modeling framework and assess unimodal, early-fusion, and cross-modal attention strategies. Cross-Modal Attention fusion of EMOCA and physiological signals achieves best performance (AUROC 92\\%, Accuracy 86.7\\%), with EMOCA-gaze fusion also competitive (AUROC 91.8\\%). This highlights the effectiveness of temporal modeling and cross-modal attention for stress recognition.","authors":["Paraskevi Valergaki","Vassilis C. Nicodemou","Iason Oikonomidis","Antonis Argyros","Anastasios Roussos"],"pdf_url":"","comment":"UNDER SUBMISSION TO ICPR 2026"},{"id":"http://arxiv.org/abs/2511.08897v3","updated":"2026-01-07T20:25:39Z","published":"2025-11-12T02:15:02Z","title":"Improving VisNet for Object Recognition","summary":"Object recognition plays a fundamental role in how biological organisms perceive and interact with their environment. While the human visual system performs this task with remarkable efficiency, reproducing similar capabilities in artificial systems remains challenging. This study investigates VisNet, a biologically inspired neural network model, and several enhanced variants incorporating radial basis function neurons, Mahalanobis distance based learning, and retinal like preprocessing for both general object recognition and symmetry classification. By leveraging principles of Hebbian learning and temporal continuity associating temporally adjacent views to build invariant representations. VisNet and its extensions capture robust and transformation invariant features. Experimental results across multiple datasets, including MNIST, CIFAR10, and custom symmetric object sets, show that these enhanced VisNet variants substantially improve recognition accuracy compared with the baseline model. These findings underscore the adaptability and biological relevance of VisNet inspired architectures, offering a powerful and interpretable framework for visual recognition in both neuroscience and artificial intelligence.\n  Keywords: VisNet, Object Recognition, Symmetry Detection, Hebbian Learning, RBF Neurons, Mahalanobis Distance, Biologically Inspired Models, Invariant Representations","authors":["Mehdi Fatan Serj","C. Alejandro Parraga","Xavier Otazu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04370v1","updated":"2026-01-07T20:19:11Z","published":"2026-01-07T20:19:11Z","title":"End-to-end differentiable design of geometric waveguide displays","summary":"Geometric waveguides are a promising architecture for optical see-through augmented reality displays, but their performance is severely bottlenecked by the difficulty of jointly optimizing non-sequential light transport and polarization-dependent multilayer thin-film coatings. Here we present the first end-to-end differentiable optimization framework for geometric waveguide that couples non-sequential Monte Carlo polarization ray tracing with a differentiable transfer-matrix thin-film solver. A differentiable Monte Carlo ray tracer avoids the exponential growth of deterministic ray splitting while enabling gradients backpropagation from eyebox metrics to design parameters. With memory-saving strategies, we optimize more than one thousand layer-thickness parameters and billions of non-sequential ray-surface intersections on a single multi-GPU workstation. Automated layer pruning is achieved by starting from over-parameterized stacks and driving redundant layers to zero thickness under discrete manufacturability constraints, effectively performing topology optimization to discover optimal coating structures. On a representative design, starting from random initialization within thickness bounds, our method increases light efficiency from 4.1\\% to 33.5\\% and improves eyebox and FoV uniformity by $\\sim$17$\\times$ and $\\sim$11$\\times$, respectively. Furthermore, we jointly optimize the waveguide and an image preprocessing network to improve perceived image quality. Our framework not only enables system-level, high-dimensional coating optimization inside the waveguide, but also expands the scope of differentiable optics for next-generation optical design.","authors":["Xinge Yang","Zhaocheng Liu","Zhaoyu Nie","Qingyuan Fan","Zhimin Shi","Jim Bonar","Wolfgang Heidrich"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02564v2","updated":"2026-01-07T19:52:19Z","published":"2026-01-05T21:34:32Z","title":"Comparative Analysis of Binarization Methods For Medical Image Hashing On Odir Dataset","summary":"In this study, we evaluated four binarization methods. Locality-Sensitive Hashing (LSH), Iterative Quantization (ITQ), Kernel-based Supervised Hashing (KSH), and Supervised Discrete Hashing (SDH) on the ODIR dataset using deep feature embeddings. Experimental results show that SDH achieved the best performance, with an mAP@100 of 0.9184 using only 32-bit codes, outperforming LSH, ITQ, and KSH. Compared with prior studies, our method proved highly competitive: Fang et al. reported 0.7528 (Fundus-iSee, 48 bits) and 0.8856 (ASOCT-Cataract, 48 bits), while Wijesinghe et al. achieved 94.01 (KVASIR, 256 bits). Despite using significantly fewer bits, our SDH-based framework reached retrieval accuracy close to the state-of-the-art. These findings demonstrate that SDH is the most effective approach among those tested, offering a practical balance of accuracy, storage, and efficiency for medical image retrieval and device inventory management.","authors":["Nedim Muzoglu"],"pdf_url":"","comment":"After publication of the conference version, we identified fundamental methodological and evaluation issues that affect the validity of the reported results. These issues are intrinsic to the current work and cannot be addressed through a simple revision. Therefore, we request full withdrawal of this submission rather than replacement"},{"id":"http://arxiv.org/abs/2601.04359v1","updated":"2026-01-07T19:51:06Z","published":"2026-01-07T19:51:06Z","title":"PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache","summary":"A unified autoregressive model is a Transformer-based framework that addresses diverse multimodal tasks (e.g., text, image, video) as a single sequence modeling problem under a shared token space. Such models rely on the KV-cache mechanism to reduce attention computation from O(T^2) to O(T); however, KV-cache size grows linearly with the number of generated tokens, and it rapidly becomes the dominant bottleneck limiting inference efficiency and generative length. Unified autoregressive video generation inherits this limitation. Our analysis reveals that KV-cache tokens exhibit distinct spatiotemporal properties: (i) text and conditioning-image tokens act as persistent semantic anchors that consistently receive high attention, and (ii) attention to previous frames naturally decays with temporal distance. Leveraging these observations, we introduce PackCache, a training-free KV-cache management method that dynamically compacts the KV cache through three coordinated mechanisms: condition anchoring that preserves semantic references, cross-frame decay modeling that allocates cache budget according to temporal distance, and spatially preserving position embedding that maintains coherent 3D structure under cache removal. In terms of efficiency, PackCache accelerates end-to-end generation by 1.7-2.2x on 48-frame long sequences, showcasing its strong potential for enabling longer-sequence video generation. Notably, the final four frames - the portion most impacted by the progressively expanding KV-cache and thus the most expensive segment of the clip - PackCache delivers a 2.6x and 3.7x acceleration on A40 and H200, respectively, for 48-frame videos.","authors":["Kunyang Li","Mubarak Shah","Yuzhang Shang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.11041v3","updated":"2026-01-07T19:50:32Z","published":"2024-10-14T19:42:09Z","title":"Beyond Fixed Topologies: Unregistered Training and Comprehensive Evaluation Metrics for 3D Talking Heads","summary":"Generating speech-driven 3D talking heads presents numerous challenges; among those is dealing with varying mesh topologies where no point-wise correspondence exists across the meshes the model can animate. While previous literature works assume fixed mesh structures, in this work we present the first framework capable of animating 3D faces in arbitrary topologies, including real scanned data. Our approach leverages heat diffusion to predict features that are robust to the mesh topology. We explore two training settings: a registered one, in which meshes in a training sequences share a fixed topology but any mesh can be animated at test time, and an fully unregistered one, which allows effective training with varying mesh structures. Additionally, we highlight the limitations of current evaluation metrics and propose new metrics for better lip-syncing evaluation. An extensive evaluation shows our approach performs favorably compared to fixed topology techniques, setting a new benchmark by offering a versatile and high-fidelity solution for 3D talking heads where the topology constraint is dropped. The code along with the pre-trained model are available.","authors":["Federico Nocentini","Thomas Besnier","Claudio Ferrari","Sylvain Arguillere","Mohamed Daoudi","Stefano Berretti"],"pdf_url":"","comment":"https://fedenoce.github.io/scantalk/"},{"id":"http://arxiv.org/abs/2601.04356v1","updated":"2026-01-07T19:43:16Z","published":"2026-01-07T19:43:16Z","title":"UNIC: Learning Unified Multimodal Extrinsic Contact Estimation","summary":"Contact-rich manipulation requires reliable estimation of extrinsic contacts-the interactions between a grasped object and its environment which provide essential contextual information for planning, control, and policy learning. However, existing approaches often rely on restrictive assumptions, such as predefined contact types, fixed grasp configurations, or camera calibration, that hinder generalization to novel objects and deployment in unstructured environments. In this paper, we present UNIC, a unified multimodal framework for extrinsic contact estimation that operates without any prior knowledge or camera calibration. UNIC directly encodes visual observations in the camera frame and integrates them with proprioceptive and tactile modalities in a fully data-driven manner. It introduces a unified contact representation based on scene affordance maps that captures diverse contact formations and employs a multimodal fusion mechanism with random masking, enabling robust multimodal representation learning. Extensive experiments demonstrate that UNIC performs reliably. It achieves a 9.6 mm average Chamfer distance error on unseen contact locations, performs well on unseen objects, remains robust under missing modalities, and adapts to dynamic camera viewpoints. These results establish extrinsic contact estimation as a practical and versatile capability for contact-rich manipulation.","authors":["Zhengtong Xu","Yuki Shirai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04352v1","updated":"2026-01-07T19:36:41Z","published":"2026-01-07T19:36:41Z","title":"Comparative Analysis of Custom CNN Architectures versus Pre-trained Models and Transfer Learning: A Study on Five Bangladesh Datasets","summary":"This study presents a comprehensive comparative analysis of custom-built Convolutional Neural Networks (CNNs) against popular pre-trained architectures (ResNet-18 and VGG-16) using both feature extraction and transfer learning approaches. We evaluated these models across five diverse image classification datasets from Bangladesh: Footpath Vision, Auto Rickshaw Detection, Mango Image Classification, Paddy Variety Recognition, and Road Damage Detection. Our experimental results demonstrate that transfer learning with fine-tuning consistently outperforms both custom CNNs built from scratch and feature extraction methods, achieving accuracy improvements ranging from 3% to 76% across different datasets. Notably, ResNet-18 with fine-tuning achieved perfect 100% accuracy on the Road Damage BD dataset. While custom CNNs offer advantages in model size (3.4M parameters vs. 11-134M for pre-trained models) and training efficiency on simpler tasks, pre-trained models with transfer learning provide superior performance, particularly on complex classification tasks with limited training data. This research provides practical insights for practitioners in selecting appropriate deep learning approaches based on dataset characteristics, computational resources, and performance requirements.","authors":["Ibrahim Tanvir","Alif Ruslan","Sartaj Solaiman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04348v1","updated":"2026-01-07T19:34:51Z","published":"2026-01-07T19:34:51Z","title":"SCAR-GS: Spatial Context Attention for Residuals in Progressive Gaussian Splatting","summary":"Recent advances in 3D Gaussian Splatting have allowed for real-time, high-fidelity novel view synthesis. Nonetheless, these models have significant storage requirements for large and medium-sized scenes, hindering their deployment over cloud and streaming services. Some of the most recent progressive compression techniques for these models rely on progressive masking and scalar quantization techniques to reduce the bitrate of Gaussian attributes using spatial context models. While effective, scalar quantization may not optimally capture the correlations of high-dimensional feature vectors, which can potentially limit the rate-distortion performance.\n  In this work, we introduce a novel progressive codec for 3D Gaussian Splatting that replaces traditional methods with a more powerful Residual Vector Quantization approach to compress the primitive features. Our key contribution is an auto-regressive entropy model, guided by a multi-resolution hash grid, that accurately predicts the conditional probability of each successive transmitted index, allowing for coarse and refinement layers to be compressed with high efficiency.","authors":["Diego Revilla","Pooja Suresh","Anand Bhojan","Ooi Wei Tsang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04342v1","updated":"2026-01-07T19:26:30Z","published":"2026-01-07T19:26:30Z","title":"ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers","summary":"Recent advances in video diffusion models have shifted towards transformer-based architectures, achieving state-of-the-art video generation but at the cost of quadratic attention complexity, which severely limits scalability for longer sequences. We introduce ReHyAt, a Recurrent Hybrid Attention mechanism that combines the fidelity of softmax attention with the efficiency of linear attention, enabling chunk-wise recurrent reformulation and constant memory usage. Unlike the concurrent linear-only SANA Video, ReHyAt's hybrid design allows efficient distillation from existing softmax-based models, reducing the training cost by two orders of magnitude to ~160 GPU hours, while being competitive in the quality. Our light-weight distillation and finetuning pipeline provides a recipe that can be applied to future state-of-the-art bidirectional softmax-based models. Experiments on VBench and VBench-2.0, as well as a human preference study, demonstrate that ReHyAt achieves state-of-the-art video quality while reducing attention cost from quadratic to linear, unlocking practical scalability for long-duration and on-device video generation. Project page is available at https://qualcomm-ai-research.github.io/rehyat.","authors":["Mohsen Ghafoorian","Amirhossein Habibian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04339v1","updated":"2026-01-07T19:19:44Z","published":"2026-01-07T19:19:44Z","title":"Unified Text-Image Generation with Weakness-Targeted Post-Training","summary":"Unified multimodal generation architectures that jointly produce text and images have recently emerged as a promising direction for text-to-image (T2I) synthesis. However, many existing systems rely on explicit modality switching, generating reasoning text before switching manually to image generation. This separate, sequential inference process limits cross-modal coupling and prohibits automatic multimodal generation. This work explores post-training to achieve fully unified text-image generation, where models autonomously transition from textual reasoning to visual synthesis within a single inference process. We examine the impact of joint text-image generation on T2I performance and the relative importance of each modality during post-training. We additionally explore different post-training data strategies, showing that a targeted dataset addressing specific limitations achieves superior results compared to broad image-caption corpora or benchmark-aligned data. Using offline, reward-weighted post-training with fully self-generated synthetic data, our approach enables improvements in multimodal image generation across four diverse T2I benchmarks, demonstrating the effectiveness of reward-weighting both modalities and strategically designed post-training data.","authors":["Jiahui Chen","Philippe Hansen-Estruch","Xiaochuang Han","Yushi Hu","Emily Dinan","Amita Kamath","Michal Drozdzal","Reyhane Askari-Hemmat","Luke Zettlemoyer","Marjan Ghazvininejad"],"pdf_url":"","comment":null}],"Image and Video Processing":[{"id":"http://arxiv.org/abs/2601.04163v1","updated":"2026-01-07T18:24:12Z","published":"2026-01-07T18:24:12Z","title":"Scanner-Induced Domain Shifts Undermine the Robustness of Pathology Foundation Models","summary":"Pathology foundation models (PFMs) have become central to computational pathology, aiming to offer general encoders for feature extraction from whole-slide images (WSIs). Despite strong benchmark performance, PFM robustness to real-world technical domain shifts, such as variability from whole-slide scanner devices, remains poorly understood. We systematically evaluated the robustness of 14 PFMs to scanner-induced variability, including state-of-the-art models, earlier self-supervised models, and a baseline trained on natural images. Using a multiscanner dataset of 384 breast cancer WSIs scanned on five devices, we isolated scanner effects independently from biological and laboratory confounders. Robustness is assessed via complementary unsupervised embedding analyses and a set of clinicopathological supervised prediction tasks. Our results demonstrate that current PFMs are not invariant to scanner-induced domain shifts. Most models encode pronounced scanner-specific variability in their embedding spaces. While AUC often remains stable, this masks a critical failure mode: scanner variability systematically alters the embedding space and impacts calibration of downstream model predictions, resulting in scanner-dependent bias that can impact reliability in clinical use cases. We further show that robustness is not a simple function of training data scale, model size, or model recency. None of the models provided reliable robustness against scanner-induced variability. While the models trained on the most diverse data, here represented by vision-language models, appear to have an advantage with respect to robustness, they underperformed on downstream supervised tasks. We conclude that development and evaluation of PFMs requires moving beyond accuracy-centric benchmarks toward explicit evaluation and optimisation of embedding stability and calibration under realistic acquisition variability.","authors":["Erik Thiringer","Fredrik K. Gustafsson","Kajsa Ledesma Eriksson","Mattias Rantalainen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04005v1","updated":"2026-01-07T15:15:30Z","published":"2026-01-07T15:15:30Z","title":"Padé Neurons for Efficient Neural Models","summary":"Neural networks commonly employ the McCulloch-Pitts neuron model, which is a linear model followed by a point-wise non-linear activation. Various researchers have already advanced inherently non-linear neuron models, such as quadratic neurons, generalized operational neurons, generative neurons, and super neurons, which offer stronger non-linearity compared to point-wise activation functions. In this paper, we introduce a novel and better non-linear neuron model called Padé neurons (Paons), inspired by Padé approximants. Paons offer several advantages, such as diversity of non-linearity, since each Paon learns a different non-linear function of its inputs, and layer efficiency, since Paons provide stronger non-linearity in much fewer layers compared to piecewise linear approximation. Furthermore, Paons include all previously proposed neuron models as special cases, thus any neuron model in any network can be replaced by Paons. We note that there has been a proposal to employ the Padé approximation as a generalized point-wise activation function, which is fundamentally different from our model. To validate the efficacy of Paons, in our experiments, we replace classic neurons in some well-known neural image super-resolution, compression, and classification models based on the ResNet architecture with Paons. Our comprehensive experimental results and analyses demonstrate that neural models built by Paons provide better or equal performance than their classic counterparts with a smaller number of layers. The PyTorch implementation code for Paon is open-sourced at https://github.com/onur-keles/Paon.","authors":["Onur Keleş","A. Murat Tekalp"],"pdf_url":"","comment":"Accepted for Publication in IEEE TRANSACTIONS ON IMAGE PROCESSING; 13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2601.03924v1","updated":"2026-01-07T13:45:20Z","published":"2026-01-07T13:45:20Z","title":"A low-complexity method for efficient depth-guided image deblurring","summary":"Image deblurring is a challenging problem in imaging due to its highly ill-posed nature. Deep learning models have shown great success in tackling this problem but the quest for the best image quality has brought their computational complexity up, making them impractical on anything but powerful servers. Meanwhile, recent works have shown that mobile Lidars can provide complementary information in the form of depth maps that enhance deblurring quality. In this paper, we introduce a novel low-complexity neural network for depth-guided image deblurring. We show that the use of the wavelet transform to separate structural details and reduce spatial redundancy as well as efficient feature conditioning on the depth information are essential ingredients in developing a low-complexity model. Experimental results show competitive image quality against recent state-of-the-art models while reducing complexity by up to two orders of magnitude.","authors":["Ziyao Yi","Diego Valsesia","Tiziano Bianchi","Enrico Magli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03899v1","updated":"2026-01-07T13:10:04Z","published":"2026-01-07T13:10:04Z","title":"Ensemble Models for Predicting Treatment Response in Pediatric Low-Grade Glioma Managed with Chemotherapy","summary":"In this paper, we introduce a novel pipeline for predicting chemotherapy response in pediatric brain tumors that are not amenable to complete surgical resection, using pre-treatment magnetic resonance imaging combined with clinical information. Our method integrates a state-of-the-art pediatric brain tumor segmentation framework with radiomic feature extraction and clinical data through an ensemble of a Swin UNETR encoder and XGBoost classifier. The segmentation model delineates four tumor subregions enhancing tumor, non-enhancing tumor, cystic component and edema which are used to extract imaging biomarkers and generate predictive features. The Swin UNETR network classifies the response to treatment directly from these segmented MRI scans, while XGBoost predicts response using radiomics and clinical variables including legal sex, ethnicity, race, age at event (in days), molecular subtype, tumor locations, initial surgery status, metastatic status, metastasis location, chemotherapy type, protocol name and chemotherapy agents. The ensemble output provides a non-invasive estimate of chemotherapy response in this historically challenging population characterized by lower progression-free survival. Among compared approaches, our Swin-Ensemble achieved the best performance (precision for non effective cases=0.68, recall for non effective cases=0.85, precision for chemotherapy effective cases=0.64 and overall accuracy=0.69), outperforming Mamba-FeatureFuse, Swin UNETR encoder, and Swin-FeatureFuse models. Our findings suggest that this ensemble framework represents a promising step toward personalized therapy response prediction for pediatric low-grade glioma patients in need of chemotherapy treatment who are not suitable for complete surgical resection, a population with significantly lower progression free survival and for whom chemotherapy remains the primary treatment option.","authors":["Max Bengtsson","Elif Keles","Angela J. Waanders","Ulas Bagci"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03875v1","updated":"2026-01-07T12:39:54Z","published":"2026-01-07T12:39:54Z","title":"Staged Voxel-Level Deep Reinforcement Learning for 3D Medical Image Segmentation with Noisy Annotations","summary":"Deep learning has achieved significant advancements in medical image segmentation. Currently, obtaining accurate segmentation outcomes is critically reliant on large-scale datasets with high-quality annotations. However, noisy annotations are frequently encountered owing to the complex morphological structures of organs in medical images and variations among different annotators, which can substantially limit the efficacy of segmentation models. Motivated by the fact that medical imaging annotator can correct labeling errors during segmentation based on prior knowledge, we propose an end-to-end Staged Voxel-Level Deep Reinforcement Learning (SVL-DRL) framework for robust medical image segmentation under noisy annotations. This framework employs a dynamic iterative update strategy to automatically mitigate the impact of erroneous labels without requiring manual intervention. The key advancements of SVL-DRL over existing works include: i) formulating noisy annotations as a voxel-dependent problem and addressing it through a novel staged reinforcement learning framework which guarantees robust model convergence; ii) incorporating a voxel-level asynchronous advantage actor-critic (vA3C) module that conceptualizes each voxel as an autonomous agent, which allows each agent to dynamically refine its own state representation during training, thereby directly mitigating the influence of erroneous labels; iii) designing a novel action space for the agents, along with a composite reward function that strategically combines the Dice value and a spatial continuity metric to significantly boost segmentation accuracy while maintain semantic integrity. Experiments on three public medical image datasets demonstrates State-of-The-Art (SoTA) performance under various experimental settings, with an average improvement of over 3\\% in both Dice and IoU scores.","authors":["Yuyang Fu","Xiuzhen Guo","Ji Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.18342v2","updated":"2026-01-07T11:06:48Z","published":"2024-12-24T11:00:23Z","title":"Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set Domain Generalization","summary":"Open-Set Domain Generalization (OSDG) is a challenging task requiring models to accurately predict familiar categories while minimizing confidence for unknown categories to effectively reject them in unseen domains. While the OSDG field has seen considerable advancements, the impact of label noise--a common issue in real-world datasets--has been largely overlooked. Label noise can mislead model optimization, thereby exacerbating the challenges of open-set recognition in novel domains. In this study, we take the first step towards addressing Open-Set Domain Generalization under Noisy Labels (OSDG-NL) by constructing dedicated benchmarks derived from widely used OSDG datasets, including PACS and DigitsDG. We evaluate baseline approaches by integrating techniques from both label denoising and OSDG methodologies, highlighting the limitations of existing strategies in handling label noise effectively. To address these limitations, we propose HyProMeta, a novel framework that integrates hyperbolic category prototypes for label noise-aware meta-learning alongside a learnable new-category agnostic prompt designed to enhance generalization to unseen classes. Our extensive experiments demonstrate the superior performance of HyProMeta compared to state-of-the-art methods across the newly established benchmarks. The source code of this work is released at https://github.com/KPeng9510/HyProMeta.","authors":["Kunyu Peng","Di Wen","M. Saquib Sarfraz","Yufan Chen","Junwei Zheng","David Schneider","Kailun Yang","Jiamin Wu","Alina Roitberg","Rainer Stiefelhagen"],"pdf_url":"","comment":"Accepted to International Journal of Computer Vision (IJCV). The source code of this work is released at https://github.com/KPeng9510/HyProMeta"},{"id":"http://arxiv.org/abs/2601.03718v1","updated":"2026-01-07T09:13:20Z","published":"2026-01-07T09:13:20Z","title":"Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation","summary":"Active Alignment (AA) is a key technology for the large-scale automated assembly of high-precision optical systems. Compared with labor-intensive per-model on-device calibration, a digital-twin pipeline built on optical simulation offers a substantial advantage in generating large-scale labeled data. However, complex imaging conditions induce a domain gap between simulation and real-world images, limiting the generalization of simulation-trained models. To address this, we propose augmenting a simulation baseline with minimal unlabeled real-world images captured at random misalignment positions, mitigating the gap from a domain adaptation perspective. We introduce Domain Adaptive Active Alignment (DA3), which utilizes an autoregressive domain transformation generator and an adversarial-based feature alignment strategy to distill real-world domain information via self-supervised learning. This enables the extraction of domain-invariant image degradation features to facilitate robust misalignment prediction. Experiments on two lens types reveal that DA3 improves accuracy by 46% over a purely simulation pipeline. Notably, it approaches the performance achieved with precisely labeled real-world data collected on 3 lens samples, while reducing on-device data collection time by 98.7%. The results demonstrate that domain adaptation effectively endows simulation-trained models with robust real-world performance, validating the digital-twin pipeline as a practical solution to significantly enhance the efficiency of large-scale optical assembly.","authors":["Wenyong Lia","Qi Jiang","Weijian Hu","Kailun Yang","Zhanjun Zhang","Wenjun Tian","Kaiwei Wang","Jian Bai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.11100v3","updated":"2026-01-07T03:53:49Z","published":"2025-08-14T22:39:24Z","title":"Full-Wave Modeling of Transcranial Ultrasound using Volume-Surface Integral Equations and CT-Derived Heterogeneous Skull Data","summary":"Transcranial ultrasound therapy uses focused acoustic energy to induce therapeutic bioeffects in the brain. Ultrasound must be transmitted through the skull, which is highly attenuating and heterogeneous, causing beam distortion, reducing focal pressure, and shifting the target location. Computational models are frequently used to predict beam aberration, assess cranial heating, and correct the phase of ultrasound transducers. These models often rely on computed tomography (CT) images to build patient-specific geometries and estimate skull acoustic properties. However, the coarse voxel resolution of CT limits accuracy for differential equation solvers at ultrasound frequencies. This paper presents an efficient numerical method based on volume-surface integral equations to model full-wave acoustic propagation through heterogeneous skull bone. We show that our approach effectively simulates transcranial ultrasound, even when using the original CT voxels as the computational mesh, where the 0.5 mm voxel length is relatively coarse compared to the shortest wavelength of 3 mm. The method is validated against a high-resolution boundary element model using an averaged skull representation. Simulations using a CT-based skull model and a bowl transducer reveal significant beam distortion of 7.8 mm attributed to the skull's heterogeneous acoustical properties.","authors":["Alberto Almuna-Morales","Danilo Aballay","Pierre Gélat","Reza Haqshenas","Elwin van 't Wout"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22298v2","updated":"2026-01-07T02:45:57Z","published":"2025-12-26T00:54:24Z","title":"Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware","summary":"In-cabin driver monitoring systems (DMS) must recognize distraction- and drowsiness-related behaviors with low latency under strict constraints on compute, power, and cost. We present a single-camera in-cabin driver behavior recognition system designed for deployment on two low-cost edge platforms: Raspberry Pi 5 (CPU-only) and the Google Coral development board with an Edge Tensor Processing Unit (Edge TPU) accelerator. The proposed pipeline combines (i) a compact per-frame vision model, (ii) a confounder-aware label taxonomy to reduce confusions among visually similar behaviors, and (iii) a temporal decision head that triggers alerts only when predictions are both confident and sustained. The system supports 17 behavior classes. Training and evaluation use licensed datasets plus in-house collection (over 800,000 labeled frames) with driver-disjoint splits, and we further validate the deployed system in live in-vehicle tests. End-to-end performance reaches approximately 16 FPS on Raspberry Pi 5 using 8-bit integer (INT8) inference (per-frame latency <60 ms) and approximately 25 FPS on Coral Edge TPU (end-to-end latency ~40 ms), enabling real-time monitoring and stable alert generation on embedded hardware. Finally, we discuss how reliable in-cabin perception can serve as an upstream signal for human-centered vehicle intelligence, including emerging agentic vehicle concepts.","authors":["Vesal Ahsani","Babak Hossein Khalaj","Hamed Shah-Mansouri"],"pdf_url":"","comment":"27 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2601.03499v1","updated":"2026-01-07T01:27:20Z","published":"2026-01-07T01:27:20Z","title":"GeoDiff-SAR: A Geometric Prior Guided Diffusion Model for SAR Image Generation","summary":"Synthetic Aperture Radar (SAR) imaging results are highly sensitive to observation geometries and the geometric parameters of targets. However, existing generative methods primarily operate within the image domain, neglecting explicit geometric information. This limitation often leads to unsatisfactory generation quality and the inability to precisely control critical parameters such as azimuth angles. To address these challenges, we propose GeoDiff-SAR, a geometric prior guided diffusion model for high-fidelity SAR image generation. Specifically, GeoDiff-SAR first efficiently simulates the geometric structures and scattering relationships inherent in real SAR imaging by calculating SAR point clouds at specific azimuths, which serves as a robust physical guidance. Secondly, to effectively fuse multi-modal information, we employ a feature fusion gating network based on Feature-wise Linear Modulation (FiLM) to dynamically regulate the weight distribution of 3D physical information, image control parameters, and textual description parameters. Thirdly, we utilize the Low-Rank Adaptation (LoRA) architecture to perform lightweight fine-tuning on the advanced Stable Diffusion 3.5 (SD3.5) model, enabling it to rapidly adapt to the distribution characteristics of the SAR domain. To validate the effectiveness of GeoDiff-SAR, extensive comparative experiments were conducted on real-world SAR datasets. The results demonstrate that data generated by GeoDiff-SAR exhibits high fidelity and effectively enhances the accuracy of downstream classification tasks. In particular, it significantly improves recognition performance across different azimuth angles, thereby underscoring the superiority of physics-guided generation.","authors":["Fan Zhang","Xuanting Wu","Fei Ma","Qiang Yin","Yuxin Hu"],"pdf_url":"","comment":"22 pages, 17 figures"},{"id":"http://arxiv.org/abs/2509.01217v3","updated":"2026-01-07T00:21:44Z","published":"2025-09-01T08:03:07Z","title":"Learn2Reg 2024: New Benchmark Datasets Driving Progress on New Challenges","summary":"Medical image registration is critical for clinical applications, and fair benchmarking of different methods is essential for monitoring ongoing progress in the field. To date, the Learn2Reg 2020-2023 challenges have released several complementary datasets and established metrics for evaluations. Building on this foundation, the 2024 edition expands the challenge's scope to cover a wider range of registration scenarios, particularly in terms of modality diversity and task complexity, by introducing three new tasks, including large-scale multi-modal registration and unsupervised inter-subject brain registration, as well as the first microscopy-focused benchmark within Learn2Reg. The new datasets also inspired new method developments, including invertibility constraints, pyramid features, keypoints alignment and instance optimisation.\n  Visit Learn2Reg at https://learn2reg.grand-challenge.org.","authors":["Lasse Hansen","Wiebke Heyer","Christoph Großbröhmer","Frederic Madesta","Thilo Sentker","Wang Jiazheng","Yuxi Zhang","Hang Zhang","Min Liu","Junyi Wang","Xi Zhu","Yuhua Li","Liwen Wang","Daniil Morozov","Nazim Haouchine","Joel Honkamaa","Pekka Marttinen","Yichao Zhou","Zuopeng Tan","Zhuoyuan Wang","Yi Wang","Hongchao Zhou","Shunbo Hu","Yi Zhang","Qian Tao","Lukas Förner","Thomas Wendler","Bailiang Jian","Christian Wachinger","Jin Kim","Dan Ruan","Marek Wodzinski","Henning Müller","Tony C. W. Mok","Xi Jia","Jinming Duan","Mikael Brudfors","Seyed-Ahmad Ahmadi","Yunzheng Zhu","William Hsu","Tina Kapur","William M. Wells","Alexandra Golby","Aaron Carass","Harrison Bai","Yihao Liu","Perrine Paul-Gilloteaux","Joakim Lindblad","Nataša Sladoje","Andreas Walter","Junyu Chen","Reuben Dorent","Alessa Hering","Mattias P. Heinrich"],"pdf_url":"","comment":"Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:034"},{"id":"http://arxiv.org/abs/2504.18882v2","updated":"2026-01-07T00:00:11Z","published":"2025-04-26T10:05:04Z","title":"SPD Matrix Learning for Neuroimaging Analysis: Perspectives, Methods, and Challenges","summary":"Neuroimaging provides essential tools for characterizing brain activity by quantifying connectivity strength between remote regions, using different modalities that capture different aspects of connectivity. Yet, decoding meaningful neural signatures must contend with modality-specific challenges, including measurement noise, spatial and temporal distortions, heterogeneous acquisition protocols, and limited sample sizes. A unifying perspective emerges when these data are expressed through symmetric positive definite (SPD)-valued representations: across neuroimaging modalities, SPD-valued representations naturally give rise to SPD matrices that capture dependencies between sensors or brain regions. Endowing the SPD space with Riemannian metrics equips it with a non-Euclidean geometric structure, enabling principled statistical modeling and machine learning on the resulting manifold.\n  This review consolidates machine learning methodologies that operate on the SPD manifold under a unified framework termed SPD matrix learning. SPD matrix learning brings conceptual clarity across multiple modalities, establishes continuity with decades of geometric statistics in neuroimaging, and positions SPD modeling as a methodological bridge between classical analysis and emerging AI-driven paradigms. We show that (i) modeling on the SPD manifold is mathematically natural and numerically stable, preserving symmetry and positive definiteness while avoiding degeneracies inherent to Euclidean embeddings; (ii) SPD matrix learning extends a broad family of established geometric statistical tools used across neuroimaging; and (iii) SPD matrix learning integrates new-generation AI technologies, driving a new class of neuroimaging problems that were previously out of reach. Taken together, SPD matrix learning offers a principled and forward-looking framework for next-generation neuroimaging analytics.","authors":["Ce Ju","Reinmar Kobler","Antoine Collas","Motoaki Kawanabe","Cuntai Guan","Bertrand Thirion"],"pdf_url":"","comment":"20 pages, 2 figures, 1 table; This paper has been submitted for possible publication, and is currently under review"},{"id":"http://arxiv.org/abs/2503.20107v2","updated":"2026-01-07T21:43:09Z","published":"2025-03-25T23:08:36Z","title":"Federated Learning: A new frontier in the exploration of multi-institutional medical imaging data","summary":"Artificial intelligence has transformed the perspective of medical imaging, leading to a genuine technological revolution in modern computer-assisted healthcare systems. However, ubiquitously featured deep learning (DL) systems require access to a considerable amount of data, facilitating proper knowledge extraction and generalization. Access to such extensive resources may be hindered due to the time and effort required to convey ethical agreements, set up and carry the acquisition procedures through, and manage the datasets adequately with a particular emphasis on proper anonymization. One of the pivotal challenges in the DL field is data integration from various sources acquired using different hardware vendors, diverse acquisition protocols, experimental setups, and even inter-operator variabilities. In this paper, we review the federated learning (FL) concept that fosters the integration of large-scale heterogeneous datasets from multiple institutions in training DL models. In contrast to a centralized approach, the decentralized FL procedure promotes training DL models while preserving data privacy at each institution involved. We formulate the FL principle and comprehensively review general and specialized medical imaging aggregation and learning algorithms, enabling the generation of a globally generalized model. We meticulously go through the challenges in constructing FL-based systems, such as data and model heterogeneities across the institutions, resilience to potential attacks on data privacy, and the variability in computational and communication resources among the entangled sites that might induce efficiency issues of the entire system. Finally, we explore the up-to-date open frameworks for rapid FL-based algorithm prototyping, comprehensively present real-world implementations of FL systems and shed light on future directions in this intensively growing field.","authors":["Dominika Ciupek","Maciej Malawski","Tomasz Pieciak"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02564v2","updated":"2026-01-07T19:52:19Z","published":"2026-01-05T21:34:32Z","title":"Comparative Analysis of Binarization Methods For Medical Image Hashing On Odir Dataset","summary":"In this study, we evaluated four binarization methods. Locality-Sensitive Hashing (LSH), Iterative Quantization (ITQ), Kernel-based Supervised Hashing (KSH), and Supervised Discrete Hashing (SDH) on the ODIR dataset using deep feature embeddings. Experimental results show that SDH achieved the best performance, with an mAP@100 of 0.9184 using only 32-bit codes, outperforming LSH, ITQ, and KSH. Compared with prior studies, our method proved highly competitive: Fang et al. reported 0.7528 (Fundus-iSee, 48 bits) and 0.8856 (ASOCT-Cataract, 48 bits), while Wijesinghe et al. achieved 94.01 (KVASIR, 256 bits). Despite using significantly fewer bits, our SDH-based framework reached retrieval accuracy close to the state-of-the-art. These findings demonstrate that SDH is the most effective approach among those tested, offering a practical balance of accuracy, storage, and efficiency for medical image retrieval and device inventory management.","authors":["Nedim Muzoglu"],"pdf_url":"","comment":"After publication of the conference version, we identified fundamental methodological and evaluation issues that affect the validity of the reported results. These issues are intrinsic to the current work and cannot be addressed through a simple revision. Therefore, we request full withdrawal of this submission rather than replacement"},{"id":"http://arxiv.org/abs/2502.10452v3","updated":"2026-01-07T19:42:54Z","published":"2025-02-12T00:13:40Z","title":"Quaternion-Hadamard Network: A Novel Defense Against Adversarial Attacks with a New Dataset","summary":"Adverse-weather image restoration (e.g., rain, snow, haze) models remain highly vulnerable to gradient-based white-box adversarial attacks, wherein minimal loss-aligned perturbations cause substantial degradation in the restored output. This paper presents QHNet, a computationally efficient purification-based defense that precedes the restoration network and targets perturbation suppression in the transform and quaternion domains. QHNet incorporates a Quaternion Hadamard Polynomial Denoising Block (QHPDB) and a Quaternion Denoising Residual Block (QDRB) within an encoder-decoder framework to remove high-frequency adversarial noise while preserving fine structural details. Robustness is evaluated using PSNR and SSIM across rain, snow, and haze removal tasks, and further validated under adaptive, defense-aware white-box attacks employing Projected Gradient Descent (PGD), Backward Pass Differentiable Approximation (BPDA), and Expectation Over Transformation (EOT). Experimental results demonstrate that QHNet delivers superior restoration fidelity and significantly improved robustness compared to state-of-the-art purification baselines, confirming its effectiveness for low-level vision pipelines.","authors":["Vladimir Frants","Sos Agaian"],"pdf_url":"","comment":null}],"Graphics":[{"id":"http://arxiv.org/abs/2601.04194v1","updated":"2026-01-07T18:59:40Z","published":"2026-01-07T18:59:40Z","title":"Choreographing a World of Dynamic Objects","summary":"Dynamic objects in our physical 4D (3D + time) world are constantly evolving, deforming, and interacting with other objects, leading to diverse 4D scene dynamics. In this paper, we present a universal generative pipeline, CHORD, for CHOReographing Dynamic objects and scenes and synthesizing this type of phenomena. Traditional rule-based graphics pipelines to create these dynamics are based on category-specific heuristics, yet are labor-intensive and not scalable. Recent learning-based methods typically demand large-scale datasets, which may not cover all object categories in interest. Our approach instead inherits the universality from the video generative models by proposing a distillation-based pipeline to extract the rich Lagrangian motion information hidden in the Eulerian representations of 2D videos. Our method is universal, versatile, and category-agnostic. We demonstrate its effectiveness by conducting experiments to generate a diverse range of multi-body 4D dynamics, show its advantage compared to existing methods, and demonstrate its applicability in generating robotics manipulation policies. Project page: https://yanzhelyu.github.io/chord","authors":["Yanzhe Lyu","Chen Geng","Karthik Dharmarajan","Yunzhi Zhang","Hadi Alzayer","Shangzhe Wu","Jiajun Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/1001.4002v2","updated":"2026-01-07T18:29:10Z","published":"2010-01-22T18:23:27Z","title":"Aplicación Gráfica para el estudio de un Modelo de Celda Electrolítica usando Técnicas de Visualización de Campos Vectoriales","summary":"The use of floating bipolar electrodes in copper electro-winning cells represents an emerging technology that promises economic and operational impacts. This thesis presents EWCellCAD, a computational tool designed for the simulation and analysis of these electrochemical systems. Based on the generalization and optimization of an existing 2D finite difference model for calculating electrical variables in rectangular cells, EWCellCAD implements a new 3D model capable of processing complex geometries, not necessarily rectangular, which also accelerates calculations by several orders of magnitude. At the same time, a new analytical method for estimating potentials in floating electrodes is introduced, overcoming the inaccuracies of previous heuristic approaches. The analysis of the results is supported by an interactive visualization technique of three-dimensional vector fields as flow lines.","authors":["César Mena"],"pdf_url":"","comment":"in Spanish language, B.Sc. Thesis in Electronic Engineering (part of the research project FONDECYT 1970955), Universidad de Concepción, 2000, 105 pages, 22 figures, in Spanish. Related publication: arXiv:1001.3974 [cs.GR]. Metadata-only update: Author name standardized (maternal surname removed; paternal surname as sole last name). Title orthography corrected with TeX accents. Abstract refined"},{"id":"http://arxiv.org/abs/1001.3974v3","updated":"2026-01-07T17:25:45Z","published":"2010-01-22T12:57:59Z","title":"Modelación y Visualización Tridimensional Interactiva de Variables Eléctricas en Celdas de Electro-Obtención con Electrodos Bipolares","summary":"The use of floating bipolar electrodes in copper electro-winning cells represents an emerging technology that promises economic and operational impacts. This article presents a computational tool designed for the simulation and analysis of these electrochemical systems. Based on the generalization and optimization of an existing 2D finite difference model for calculating electrical variables in rectangular cells, a new 3D model capable of processing complex geometries, not necessarily rectangular, has been developed. At the same time, a new analytical method for estimating potentials in floating electrodes is introduced, overcoming the inaccuracies of previous heuristic approaches. The analysis of the results is supported by an interactive visualization technique of three-dimensional vector fields as flow lines.","authors":["César Mena","Ricardo Sánchez","Lautaro Salazar"],"pdf_url":"","comment":"6 pages, 3 figures, in Spanish. For more details, see arXiv:1001.4002 [cs.GR]. Metadata-only update: Authors' names standardized (maternal surnames removed; paternal surnames as sole last name). Title orthography corrected with TeX accents. Abstract refined"},{"id":"http://arxiv.org/abs/2601.03885v1","updated":"2026-01-07T12:54:06Z","published":"2026-01-07T12:54:06Z","title":"Local Interpolation via Low-Rank Tensor Trains","summary":"Tensor Train (TT) decompositions provide a powerful framework to compress grid-structured data, such as sampled function values, on regular Cartesian grids. Such high compression, in turn, enables efficient high-dimensional computations. Exact TT representations are only available for simple analytic functions. Furthermore, global polynomial or Fourier expansions typically yield TT-ranks that grow proportionally with the number of basis terms. State-of-the-art methods are often prohibitively expensive or fail to recover the underlying low-rank structure. We propose a low-rank TT interpolation framework that, given a TT describing a discrete (scalar-, vector-, or tensor-valued) function on a coarse regular grid with $n$ cores, constructs a finer-scale version of the same function represented by a TT with $n+m$ cores, where the last $m$ cores maintain constant rank. Our method guarantees a $\\ell^{2}$-norm error bound independent of the total number of cores, achieves exponential compression at fixed accuracy, and admits logarithmic complexity with respect of the number of grid points. We validate its performance through numerical experiments, including 1D, 2D, and 3D applications such as: 2D and 3D airfoil mask embeddings, image super-resolution, and synthetic noise fields such as 3D synthetic turbulence. In particular, we generate fractal noise fields directly in TT format with logarithmic complexity and memory. This work opens a path to scalable TT-native solvers with complex geometries and multiscale generative models, with implications from scientific simulation to imaging and real-time graphics.","authors":["Siddhartha E. Guzman","Egor Tiunov","Leandro Aolita"],"pdf_url":"","comment":"22 pages, 16 figures"},{"id":"http://arxiv.org/abs/2601.03869v1","updated":"2026-01-07T12:32:39Z","published":"2026-01-07T12:32:39Z","title":"Bayesian Monocular Depth Refinement via Neural Radiance Fields","summary":"Monocular depth estimation has applications in many fields, such as autonomous navigation and extended reality, making it an essential computer vision task. However, current methods often produce smooth depth maps that lack the fine geometric detail needed for accurate scene understanding. We propose MDENeRF, an iterative framework that refines monocular depth estimates using depth information from Neural Radiance Fields (NeRFs). MDENeRF consists of three components: (1) an initial monocular estimate for global structure, (2) a NeRF trained on perturbed viewpoints, with per-pixel uncertainty, and (3) Bayesian fusion of the noisy monocular and NeRF depths. We derive NeRF uncertainty from the volume rendering process to iteratively inject high-frequency fine details. Meanwhile, our monocular prior maintains global structure. We demonstrate superior performance on key metrics and experiments using indoor scenes from the SUN RGB-D dataset.","authors":["Arun Muthukkumar"],"pdf_url":"","comment":"IEEE 8th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025). Oral presentation; Best Presenter Award"},{"id":"http://arxiv.org/abs/2412.00112v3","updated":"2026-01-07T04:18:46Z","published":"2024-11-28T05:42:47Z","title":"BiPO: Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis","summary":"Generating natural and expressive human motions from textual descriptions is challenging due to the complexity of coordinating full-body dynamics and capturing nuanced motion patterns over extended sequences that accurately reflect the given text. To address this, we introduce BiPO, Bidirectional Partial Occlusion Network for Text-to-Motion Synthesis, a novel model that enhances text-to-motion synthesis by integrating part-based generation with a bidirectional autoregressive architecture. This integration allows BiPO to consider both past and future contexts during generation while enhancing detailed control over individual body parts without requiring ground-truth motion length. To relax the interdependency among body parts caused by the integration, we devise the Partial Occlusion technique, which probabilistically occludes the certain motion part information during training. In our comprehensive experiments, BiPO achieves state-of-the-art performance on the HumanML3D dataset, outperforming recent methods such as ParCo, MoMask, and BAMM in terms of FID scores and overall motion quality. Notably, BiPO excels not only in the text-to-motion generation task but also in motion editing tasks that synthesize motion based on partially generated motion sequences and textual descriptions. These results reveal the BiPO's effectiveness in advancing text-to-motion synthesis and its potential for practical applications.","authors":["Seong-Eun Hong","Soobin Lim","Juyeong Hwang","Minwook Chang","Hyeongyeop Kang"],"pdf_url":"","comment":"18 pages, 11 figures. Accepted to WACV 2026"},{"id":"http://arxiv.org/abs/2508.08930v2","updated":"2026-01-07T03:50:59Z","published":"2025-08-12T13:32:18Z","title":"How Does a Virtual Agent Decide Where to Look? Symbolic Cognitive Reasoning for Embodied Head Rotation","summary":"Natural head rotation is critical for believable embodied virtual agents, yet this micro-level behavior remains largely underexplored. While head-rotation prediction algorithms could, in principle, reproduce this behavior, they typically focus on visually salient stimuli and overlook the cognitive motives that guide head rotation. This yields agents that look at conspicuous objects while overlooking obstacles or task-relevant cues, diminishing realism in a virtual environment. We introduce SCORE, a Symbolic Cognitive Reasoning framework for Embodied Head Rotation, a data-agnostic framework that produces context-aware head movements without task-specific training or hand-tuned heuristics. A controlled VR study (N=20) identifies five motivational drivers of human head movements: Interest, Information Seeking, Safety, Social Schema, and Habit. SCORE encodes these drivers as symbolic predicates, perceives the scene with a Vision-Language Model (VLM), and plans head poses with a Large Language Model (LLM). The framework employs a hybrid workflow: the VLM-LLM reasoning is executed offline, after which a lightweight FastVLM performs online validation to suppress hallucinations while maintaining responsiveness to scene dynamics. The result is an agent that predicts not only where to look but also why, generalizing to unseen scenes and multi-agent crowds while retaining behavioral plausibility.","authors":["Juyeong Hwang","Seong-Eun Hong","JaeYoung Seon","Hyeongyeop Kang"],"pdf_url":"","comment":"13 pages, 8 figures. Accepted to SIGGRAPH Asia Conference Papers '25"},{"id":"http://arxiv.org/abs/2601.04382v1","updated":"2026-01-07T20:44:04Z","published":"2026-01-07T20:44:04Z","title":"In-SRAM Radiant Foam Rendering on a Graph Processor","summary":"Many emerging many-core accelerators replace a single large device memory with hundreds to thousands of lightweight cores, each owning only a small local SRAM and exchanging data via explicit on-chip communication. This organization offers high aggregate bandwidth, but it breaks a key assumption behind many volumetric rendering techniques: that rays can randomly access a large, unified scene representation. Rendering efficiently on such hardware therefore requires distributing both data and computation, keeping ray traversal mostly local, and structuring communication into predictable routes.\n  We present a fully in-SRAM, distributed renderer for the \\emph{Radiant Foam} Voronoi-cell volumetric representation on the Graphcore Mk2 IPU, a many-core accelerator with tile-local SRAM and explicit inter-tile communication. Our system shards the scene across tiles and forwards rays between shards through a hierarchical routing overlay, enabling ray marching entirely from on-chip SRAM with predictable communication. On Mip-NeRF~360 scenes, the system attains near-interactive throughput (\\(\\approx\\)1\\,fps at \\mbox{$640\\times480$}) with image and depth quality close to the original GPU-based Radiant Foam implementation, while keeping all scene data and ray state in on-chip SRAM. Beyond demonstrating feasibility, we analyze routing, memory, and scheduling bottlenecks that inform how future distributed-memory accelerators can better support irregular, data-movement-heavy rendering workloads.","authors":["Zulkhuu Tuya","Ignacio Alzugaray","Nicholas Fry","Andrew J. Davison"],"pdf_url":"","comment":"24 pages, 26 figures"},{"id":"http://arxiv.org/abs/2601.04370v1","updated":"2026-01-07T20:19:11Z","published":"2026-01-07T20:19:11Z","title":"End-to-end differentiable design of geometric waveguide displays","summary":"Geometric waveguides are a promising architecture for optical see-through augmented reality displays, but their performance is severely bottlenecked by the difficulty of jointly optimizing non-sequential light transport and polarization-dependent multilayer thin-film coatings. Here we present the first end-to-end differentiable optimization framework for geometric waveguide that couples non-sequential Monte Carlo polarization ray tracing with a differentiable transfer-matrix thin-film solver. A differentiable Monte Carlo ray tracer avoids the exponential growth of deterministic ray splitting while enabling gradients backpropagation from eyebox metrics to design parameters. With memory-saving strategies, we optimize more than one thousand layer-thickness parameters and billions of non-sequential ray-surface intersections on a single multi-GPU workstation. Automated layer pruning is achieved by starting from over-parameterized stacks and driving redundant layers to zero thickness under discrete manufacturability constraints, effectively performing topology optimization to discover optimal coating structures. On a representative design, starting from random initialization within thickness bounds, our method increases light efficiency from 4.1\\% to 33.5\\% and improves eyebox and FoV uniformity by $\\sim$17$\\times$ and $\\sim$11$\\times$, respectively. Furthermore, we jointly optimize the waveguide and an image preprocessing network to improve perceived image quality. Our framework not only enables system-level, high-dimensional coating optimization inside the waveguide, but also expands the scope of differentiable optics for next-generation optical design.","authors":["Xinge Yang","Zhaocheng Liu","Zhaoyu Nie","Qingyuan Fan","Zhimin Shi","Jim Bonar","Wolfgang Heidrich"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04348v1","updated":"2026-01-07T19:34:51Z","published":"2026-01-07T19:34:51Z","title":"SCAR-GS: Spatial Context Attention for Residuals in Progressive Gaussian Splatting","summary":"Recent advances in 3D Gaussian Splatting have allowed for real-time, high-fidelity novel view synthesis. Nonetheless, these models have significant storage requirements for large and medium-sized scenes, hindering their deployment over cloud and streaming services. Some of the most recent progressive compression techniques for these models rely on progressive masking and scalar quantization techniques to reduce the bitrate of Gaussian attributes using spatial context models. While effective, scalar quantization may not optimally capture the correlations of high-dimensional feature vectors, which can potentially limit the rate-distortion performance.\n  In this work, we introduce a novel progressive codec for 3D Gaussian Splatting that replaces traditional methods with a more powerful Residual Vector Quantization approach to compress the primitive features. Our key contribution is an auto-regressive entropy model, guided by a multi-resolution hash grid, that accurately predicts the conditional probability of each successive transmitted index, allowing for coarse and refinement layers to be compressed with high efficiency.","authors":["Diego Revilla","Pooja Suresh","Anand Bhojan","Ooi Wei Tsang"],"pdf_url":"","comment":null}],"Signal Processing":[{"id":"http://arxiv.org/abs/2601.04190v1","updated":"2026-01-07T18:57:19Z","published":"2026-01-07T18:57:19Z","title":"Solar Panel-based Visible Light Communication for Batteryless Systems","summary":"This paper presents a batteryless wireless communication node for the Internet of Things, powered entirely by ambient light and capable of receiving data through visible light communication. A solar panel serves dual functions as an energy harvester and an optical antenna, capturing modulated signals from LED light sources. A lightweight analog front-end filters and digitizes the signals for an 8-bit low-power processor, which manages the system's operational states based on stored energy levels. The main processor is selectively activated to minimize energy consumption. Data reception is synchronized with the harvester's open-circuit phase, reducing interference and improving signal quality. The prototype reliably decodes 32-bit VLC frames at 800\\,Herz, consuming less than 2.8\\,mJ, and maintains sleep-mode power below 30\\,uW.","authors":["Juan F. Gutierrez","Nhung Nguyen","Jesus M. Quintero","Andres Gomez"],"pdf_url":"","comment":"This is an open-access, author-archived version of a manuscript published in ApplePies 2025 Conference"},{"id":"http://arxiv.org/abs/2601.04166v1","updated":"2026-01-07T18:30:00Z","published":"2026-01-07T18:30:00Z","title":"Expectation Propagation for Distributed Inference in Grant-Free Cell-Free Massive MIMO","summary":"Grant-free cell-free massive multiple-input multiple-output (GF-CF-MaMIMO) systems are anticipated to be a key enabling technology for next-generation Internet-of-Things (IoT) networks, as they support massive connectivity without explicit scheduling. However, the large amount of connected devices prevents the use of orthogonal pilot sequences, resulting in severe pilot contamination (PC) that degrades channel estimation and data detection performance. Furthermore, scalable GF-CF-MaMIMO networks inherently rely on distributed signal processing. In this work, we consider the uplink of a GF-CF-MaMIMO system and propose two novel distributed algorithms for joint activity detection, channel estimation, and data detection (JACD) based on expectation propagation (EP). The first algorithm, denoted as JACD-EP, uses Gaussian approximations for the channel variables, whereas the second, referred to as JACD-EP-BG, models them as Bernoulli-Gaussian (BG) random variables. To integrate the BG distribution into the EP framework, we derive its exponential family representation and develop the two algorithms as efficient message passing over a factor graph constructed from the a posteriori probability (APP) distribution. The proposed framework is inherently scalable with respect to both the number of access points (APs) and user equipments (UEs). Simulation results show the efficient mitigation of PC by the proposed distributed algorithms and their superior detection accuracy compared to (genie-aided) centralized linear detectors.","authors":["Christian Forsch","Laura Cottatellucci"],"pdf_url":"","comment":"13 pages, 5 figures, submitted for possible journal publication"},{"id":"http://arxiv.org/abs/2601.04069v1","updated":"2026-01-07T16:33:01Z","published":"2026-01-07T16:33:01Z","title":"Hybrid Downlink Beamforming with Outage Constraints under Imperfect CSI using Model-Driven Deep Learning","summary":"We consider energy-efficient multi-user hybrid downlink beamforming (BF) and power allocation under imperfect channel state information (CSI) and probabilistic outage constraints. In this domain, classical optimization methods resort to computationally costly conic optimization problems. Meanwhile, generic deep network (DN) architectures lack interpretability and require large training data sets to generalize well. In this paper, we therefore propose a lightweight model-aided deep learning architecture based on a greedy selection algorithm for analog beam codewords. The architecture relies on an instance-adaptive augmentation of the signal model to estimate the impact of the CSI error. To learn the DN parameters, we derive a novel and efficient implicit representation of the nested constrained BF problem and prove sufficient conditions for the existence of the corresponding gradient. In the loss function, we utilize an annealing-based approximation of the outage compared to conventional quantile-based loss terms. This approximation adaptively anneals towards the exact probabilistic constraint depending on the current level of quality of service (QoS) violation. Simulations validate that the proposed DN can achieve the nominal outage level under CSI error due to channel estimation and channel compression, while allocating less power than benchmarks. Thereby, a single trained model generalizes to different numbers of users, QoS requirements and levels of CSI quality. We further show that the adaptive annealing-based loss function can accelerate the training and yield a better power-outage trade-off.","authors":["Lukas Schynol","Marius Pesavento"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04011v1","updated":"2026-01-07T15:20:26Z","published":"2026-01-07T15:20:26Z","title":"Flexible-Duplex Cell-Free Architecture for Secure Uplink Communications in Low-Altitude Wireless Networks","summary":"Low-altitude wireless networks (LAWNs) are expected to play a central role in future 6G infrastructures, yet uplink transmissions of uncrewed aerial vehicles (UAVs) remain vulnerable to eavesdropping due to their limited transmit power, constrained antenna resources, and highly exposed air-ground propagation conditions. To address this fundamental bottleneck, we propose a flexible-duplex cell-free (CF) architecture in which each distributed access point (AP) can dynamically operate either as a receive AP for UAV uplink collection or as a transmit AP that generates cooperative artificial noise (AN) for secrecy enhancement. Such AP-level duplex flexibility introduces an additional spatial degree of freedom that enables distributed and adaptive protection against wiretapping in LAWNs. Building upon this architecture, we formulate a max-min secrecy-rate problem that jointly optimizes AP mode selection, receive combining, and AN covariance design. This tightly coupled and nonconvex optimization is tackled by first deriving the optimal receive combiners in closed form, followed by developing a penalty dual decomposition (PDD) algorithm with guaranteed convergence to a stationary solution. To further reduce computational burden, we propose a low-complexity sequential scheme that determines AP modes via a heuristic metric and then updates the AN covariance matrices through closed-form iterations embedded in the PDD framework. Simulation results show that the proposed flexible-duplex architecture yields substantial secrecy-rate gains over CF systems with fixed AP roles. The joint optimization method attains the highest secrecy performance, while the low-complexity approach achieves over 90% of the optimal performance with an order-of-magnitude lower computational complexity, offering a practical solution for secure uplink communications in LAWNs.","authors":["Wei Shi","Wei Xu","Yongming Huang","Jiacheng Yao","Wenhao Hu","Dongming Wang"],"pdf_url":"","comment":"Submitted to an IEEE Journal"},{"id":"http://arxiv.org/abs/2601.03944v1","updated":"2026-01-07T14:01:10Z","published":"2026-01-07T14:01:10Z","title":"ASVspoof 5: Evaluation of Spoofing, Deepfake, and Adversarial Attack Detection Using Crowdsourced Speech","summary":"ASVspoof 5 is the fifth edition in a series of challenges which promote the study of speech spoofing and deepfake detection solutions. A significant change from previous challenge editions is a new crowdsourced database collected from a substantially greater number of speakers under diverse recording conditions, and a mix of cutting-edge and legacy generative speech technology. With the new database described elsewhere, we provide in this paper an overview of the ASVspoof 5 challenge results for the submissions of 53 participating teams. While many solutions perform well, performance degrades under adversarial attacks and the application of neural encoding/compression schemes. Together with a review of post-challenge results, we also report a study of calibration in addition to other principal challenges and outline a road-map for the future of ASVspoof.","authors":["Xin Wang","Héctor Delgado","Nicholas Evans","Xuechen Liu","Tomi Kinnunen","Hemlata Tak","Kong Aik Lee","Ivan Kukanov","Md Sahidullah","Massimiliano Todisco","Junichi Yamagishi"],"pdf_url":"","comment":"Submitted"},{"id":"http://arxiv.org/abs/2512.22686v2","updated":"2026-01-07T13:47:50Z","published":"2025-12-27T19:30:51Z","title":"Multistatic Radar Performance in the Presence of Distributed Wireless Synchronization","summary":"This paper proposes a multistatic radar (MSR) system utilizing a distributed wireless synchronization protocol. The wireless synchronization protocol uses a two-tone waveform exchange for frequency synchronization and a bi-directional waveform exchange for time synchronization, independent of GPS. A Bayesian Cramer-Rao lower bound (BCRLB) framework is developed to quantify the impact of synchronization offsets on joint delay and Doppler estimation, and consequently, on target localization and velocity estimation accuracy. Simulation results derived from the analytical expressions establish the extent to which the residual synchronization offsets degrade the MSR's performance. The performance of the synchronization links primarily depends on the synchronization-link channel and transmit parameters; optimizing these parameters enables the MSR configuration to surpass the monostatic performance and approach the ideal case. Furthermore, the simulated synchronization-link parameters suggest that practical implementation is feasible.","authors":["Kumar Sai Bondada","Daniel J. Jakubisin","R. Michael Buehrer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.05103v4","updated":"2026-01-07T13:25:31Z","published":"2024-12-06T15:01:19Z","title":"Integrating Semantic Communication and Human Decision-Making into an End-to-End Sensing-Decision Framework","summary":"As early as 1949, Weaver defined communication in a very broad sense to include all procedures by which one mind or technical system can influence another, thus establishing the idea of semantic communication. With the recent success of machine learning in expert assistance systems where sensed information is wirelessly provided to a human to assist task execution, the need to design effective and efficient communications has become increasingly apparent. In particular, semantic communication aims to convey the meaning behind the sensed information relevant for Human Decision-Making (HDM). Regarding the interplay between semantic communication and HDM, many questions remain, such as how to model the entire end-to-end sensing-decision-making process, how to design semantic communication for the HDM and which information should be provided for HDM. To address these questions, we propose to integrate semantic communication and HDM into one probabilistic end-to-end sensing-decision framework that bridges communications and psychology. In our interdisciplinary framework, we model the human through a HDM process, allowing us to explore how feature extraction from semantic communication can best support HDM both in theory and in simulations. In this sense, our study reveals the fundamental design trade-off between maximizing the relevant semantic information and matching the cognitive capabilities of the HDM model. Our initial analysis shows how semantic communication can balance the level of detail with human cognitive capabilities while demanding less bandwidth, power, and latency.","authors":["Edgar Beck","Hsuan-Yu Lin","Patrick Rückert","Yongping Bao","Bettina von Helversen","Sebastian Fehrler","Kirsten Tracht","Armin Dekorsy"],"pdf_url":"","comment":"Accepted in the Open Journal of the Communications Society. Code available in https://github.com/ant-uni-bremen/SINFONY"},{"id":"http://arxiv.org/abs/2601.03831v1","updated":"2026-01-07T11:52:32Z","published":"2026-01-07T11:52:32Z","title":"Low-Complexity Planar Beyond-Diagonal RIS Architecture Design Using Graph Theory","summary":"Reconfigurable intelligent surfaces (RISs) enable programmable control of the wireless propagation environment and are key enablers for future networks. Beyond-diagonal RIS (BD-RIS) architectures enhance conventional RIS by interconnecting elements through tunable impedance components, offering greater flexibility with higher circuit complexity. However, excessive interconnections between BD-RIS elements require multi-layer printed circuit board (PCB) designs, increasing fabrication difficulty. In this letter, we use graph theory to characterize the BD-RIS architectures that can be realized on double-layer PCBs, denoted as planar-connected RISs. Among the possible planar-connected RISs, we identify the ones with the most degrees of freedom, expected to achieve the best performance under practical constraints.","authors":["Matteo Nerini","Zheyu Wu","Shanpu Shen","Bruno Clerckx"],"pdf_url":"","comment":"Submitted to IEEE for publication"},{"id":"http://arxiv.org/abs/2601.03789v1","updated":"2026-01-07T10:48:33Z","published":"2026-01-07T10:48:33Z","title":"CSI-MAE: A Masked Autoencoder-based Channel Foundation Model","summary":"Self-Supervised Learning (SSL) has emerged as a key technique in machine learning, tackling challenges such as limited labeled data, high annotation costs, and variable wireless channel conditions. It is essential for developing Channel Foundation Models (CFMs), which extract latent features from channel state information (CSI) and adapt to different wireless settings. Yet, existing CFMs have notable drawbacks: heavy reliance on scenario-specific data hinders generalization, they focus on single/dual tasks, and lack zero-shot learning ability. In this paper, we propose CSI-MAE, a generalized CFM leveraging masked autoencoder for cross-scenario generalization. Trained on 3GPP channel model datasets, it integrates sensing and communication via CSI perception and generation, proven effective across diverse tasks. A lightweight decoder finetuning strategy cuts training costs while maintaining competitive performance. Under this approach, CSI-MAE matches or surpasses supervised models. With full-parameter finetuning, it achieves the state-of-the-art performance. Its exceptional zero-shot transferability also rivals supervised techniques in cross-scenario applications, driving wireless communication innovation.","authors":["Jun Jiang","Xiaolong Ruan","Shugong Xu"],"pdf_url":"","comment":"6 pages"},{"id":"http://arxiv.org/abs/2601.03745v1","updated":"2026-01-07T09:33:30Z","published":"2026-01-07T09:33:30Z","title":"Two-stage Multi-beam Training for Multiuser Millimeter-Wave Communications","summary":"In this letter, we study an efficient multi-beam training method for multiuser millimeter-wave communication systems. Unlike the conventional single-beam training method that relies on exhaustive search, multi-beam training design faces a key challenge in balancing the trade-off between beam training overhead and success beam-identification rate, exacerbated by severe inter-beam interference. To tackle this challenge, we propose a new two-stage multi-beam training method with two distinct multi-beam patterns to enable fast and accurate user angle identification. Specifically, in the first stage, the antenna array is divided into sparse subarrays to generate multiple beams (with high array gains), for identifying candidate user angles. In the second stage, the array is redivided into dense subarrays to generate flexibly steered wide beams, for which a cross-validation method is employed to effectively resolve the remaining angular ambiguity in the first stage. Last, numerical results demonstrate that the proposed method significantly improves the success beam-identification rate compared to existing multi-beam training methods, while retaining or even reducing the required beam training overhead.","authors":["Weijia Wang","Changsheng You","Xiaodan Shao","Rui Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03735v1","updated":"2026-01-07T09:25:33Z","published":"2026-01-07T09:25:33Z","title":"Cramer-Rao Bound for Angle of Arrival Estimates in True-Time-Delay Systems","summary":"In the context of joint communication and sensing JC&S, the challenge of obtaining accurate parameter estimates is of interest. Parameter estimates, such as the AoA can be utilized for solving the initial access problem, interference mitigation, localization of users or monitoring of the environment and synchronization of MIMO systems. Recently, TTD systems have gained attention for fast beam training during initial access and mitigation of beam squinting. This work derives the CRB for angle estimates in typical TTD systems. Properties of the CRB and the Fisher information are investigated and numerically evaluated. Finally, methods for angle estimation such as ML and established estimators are utilized to solve the angle estimation problem using a uniform linear array.","authors":["Carl Collmann","Ahmad Nimr","Gerhard Fettweis"],"pdf_url":"","comment":"5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.02827v2","updated":"2026-01-07T08:51:42Z","published":"2026-01-06T08:59:31Z","title":"AI-Native 6G Physical Layer with Cross-Module Optimization and Cooperative Control Agents","summary":"In this article, a framework of AI-native cross-module optimized physical layer with cooperative control agents is proposed, which involves optimization across global AI/ML modules of the physical layer with innovative design of multiple enhancement mechanisms and control strategies. Specifically, it achieves simultaneous optimization across global modules of uplink AI/ML-based joint source-channel coding with modulation, and downlink AI/ML-based modulation with precoding and corresponding data detection, reducing traditional inter-module information barriers to facilitate end-to-end optimization toward global objectives. Moreover, multiple enhancement mechanisms are also proposed, including i) an AI/ML-based cross-layer modulation approach with theoretical analysis for downlink transmission that breaks the isolation of inter-layer features to expand the solution space for determining improved constellation, ii) a utility-oriented precoder construction method that shifts the role of the AI/ML-based CSI feedback decoder from recovering the original CSI to directly generating precoding matrices aiming to improve end-to-end performance, and iii) incorporating modulation into AI/ML-based CSI feedback to bypass bit-level bottlenecks that introduce quantization errors, non-differentiable gradients, and limitations in constellation solution spaces. Furthermore, AI/ML based control agents for optimized transmission schemes are proposed that leverage AI/ML to perform model switching according to channel state, thereby enabling integrated control for global throughput optimization. Finally, simulation results demonstrate the superiority of the proposed solutions in terms of BLER and throughput. These extensive simulations employ more practical assumptions that are aligned with the requirements of the 3GPP, which hopefully provides valuable insights for future standardization discussions.","authors":["Xufei Zheng","Han Xiao","Shi Jin","Zhiqin Wang","Wenqiang Tian","Wendong Liu","Jianfei Cao","Jia Shen","Zhihua Shi","Zhi Zhang","Ning Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.18757v4","updated":"2026-01-07T08:15:13Z","published":"2024-10-24T14:09:09Z","title":"Short-time Fourier Transform-based Signal Recovery for Modulo Analog-to-Digital Converters","summary":"This study introduces a short-time Fourier transform-based method for reconstructing signals encoded using modulo analog-to-digital converters with 1-bit folding information. In contrast to existing Fourier-based reconstruction approaches that require complete access to the entire observation, the proposed technique performs reconstruction over short, overlapping segments, enabling significantly lower latency while preserving the recovery accuracy. We also address the spectral leakage introduced by the windowing operation by selecting window parameters that balance the leakage suppression and the computational complexity of the algorithm. In addition, we establish conditions under which the correct unfolding of the modulo samples is guaranteed, leading to a reconstruction error determined solely by the quantization noise at the output. The numerical results demonstrate that the proposed method enables modulo analog-to-digital converters to surpass the mean squared error performance of conventional analog-to-digital converters. Furthermore, the proposed recovery method offers improved reconstruction performance compared with higher-order difference-based recovery, particularly in low-resolution and low-sampling rate regimes.","authors":["Neil Irwin Bernardo"],"pdf_url":"","comment":"17 pages, 11 figures, this work has been accepted for publication in an IEEE journal"},{"id":"http://arxiv.org/abs/2402.11352v9","updated":"2026-01-07T07:35:25Z","published":"2024-02-17T18:03:47Z","title":"On Achievable Spectral Efficiency Using Adaptive Transmission Over Terrestrial Coherent FSO Links","summary":"Terrestrial free-space optical (FSO) communication systems, while designed to operate on large unlicensed optical bandwidths, are power-constrained due to strict eye safety regulations. The channel fluctuation inherent in terrestrial FSO links also limits the received optical power. Consequently, the available signal-to-noise ratio (SNR) per Hz could become limited; this holds for future terrestrial systems based on coherent optical communications. An efficient and adaptive transmission mechanism is thus crucial at the optical transmitter. However, a critical assessment of the impact of adaptive transmission in terrestrial FSO systems has received less attention in the literature. This work studies terrestrial coherent FSO communication systems employing adaptive beam transmission while detection receiver operate under shot noise-limited conditions. Specifically, we propose a novel exact closed-form expression for the average spectral efficiency of a coherent FSO system with optimal adaptive transmissions over the gamma-gamma turbulence channel with pointing errors. More importantly, we provide a detailed assessment of the impact of turbulence and pointing error impairments on the coherent FSO system performance, revealing several novel and counterintuitive insights. In particular, the extensive numerical results help elucidate the intricacies of analyzing these terrestrial FSO systems and clarify a few misconceptions alluded to in recent related literature.","authors":["Himani Verma","Kamal Singh","Ranjan K. Mallik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03639v1","updated":"2026-01-07T06:33:13Z","published":"2026-01-07T06:33:13Z","title":"Zak-OTFS ISAC with Bistatic Sensing via Semi-Blind Atomic Norm Denoising Scheme","summary":"Integrated sensing and communication (ISAC) through Zak-transform-based orthogonal time frequency space (Zak-OTFS) modulation is a promising solution for high-mobility scenarios. Realizing accurate bistatic sensing and robust communication necessitates precise channel estimation; however, this remains a formidable challenge in doubly dispersive environments, where fractional delay-Doppler shifts induce severe channel spreading. This paper proposes a semi-blind atomic norm denoising scheme for Zak-OTFS ISAC with bistatic sensing. We first derive the discrete-time input-output (I/O) relationship of Zak-OTFS under fractional delay-Doppler shifts and rectangular windowing. Based on this I/O relation, we formulate the joint channel parameter estimation and data detection task as an atomic norm denoising problem, utilizing the negative square penalty method to handle the non-convex discrete constellation constraints. To solve this problem efficiently, we develop an accelerated iterative algorithm that integrates majorization-minimization, accelerated projected gradient, and inexact accelerated proximal gradient methods. We provide a rigorous convergence proof for the proposed algorithm. Simulation results demonstrate that the proposed scheme achieves super-resolution sensing accuracy and communication performance approaching the perfect channel state information lower bound.","authors":["Kecheng Zhang","Weijie Yuan","Maria Sabrina Greco"],"pdf_url":"","comment":"Submitted to IEEE for possible publication"},{"id":"http://arxiv.org/abs/2601.03601v1","updated":"2026-01-07T05:31:10Z","published":"2026-01-07T05:31:10Z","title":"F$^4$-CKM: Learning Channel Knowledge Map with Radio Frequency Radiance Field Rendering","summary":"In 6G mobile communications, acquiring accurate and timely channel state information (CSI) becomes increasingly challenging due to the growing antenna array size and bandwidth. To alleviate the CSI feedback burden, the channel knowledge map (CKM) has emerged as a promising approach by leveraging environment-aware techniques to predict CSI based solely on user locations. However, how to effectively construct a CKM remains an open issue. In this paper, we propose F$^4$-CKM, a novel CKM construction framework characterized by four distinctive features: radiance Field rendering, spatial-Frequency-awareness, location-Free usage, and Fast learning. Central to our design is the adaptation of radiance field rendering techniques from computer vision to the radio frequency (RF) domain, enabled by a novel Wireless Radiator Representation (WiRARE) network that captures the spatial-frequency characteristics of wireless channels. Additionally, a novel shaping filter module and an angular sampling strategy are introduced to facilitate CKM construction. Extensive experiments demonstrate that F$^4$-CKM significantly outperforms existing baselines in terms of wireless channel prediction accuracy and efficiency.","authors":["Kequan Zhou","Guangyi Zhang","Hanlei Li","Yunlong Cai","Shengli Liu","Guanding Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.09912v2","updated":"2026-01-07T05:17:38Z","published":"2025-04-14T06:18:11Z","title":"Parameter Convergence Radar Detector Based on VAMP Deep Unfolding","summary":"Compared with the sparse recovery process in traditional compressed sensing (CS) radar detector CAMP, vector AMP deep unfolding (VAMP-DU) can achieve sparse recovery over a broader range of observation matrices, with faster convergence speed and higher recovery accuracy. However, the distribution of the error term in VAMP-DU remains unknown, which renders the distribution of the test statistic in CS radar detection undetermined and thus hinders threshold setting under a given false alarm rate when VAMP-DU is applied to CS radar detection. In this work, we theoretically prove that the error term in VAMP-DU follows a Gaussian distribution by leveraging a general state evolution (SE). Based on the Gaussianity, we propose a new parameter convergence radar detector (PCRD) as the CS detector to calculate the distribution parameter of the test statistic and realize target detection under a given false alarm rate. Specifically, PCRD exploits the Gaussian property of error term in VAMP-DU to exhibit superior false alarm control capability, while leveraging the improved recovery accuracy of VAMP-DU to further enhance target detection performance. Numerical simulations validate the Gaussianity of the error term in VAMP-DU and show the superiority of the VAMP-DU-based PCRD over existing approaches in both false alarm control accuracy and target detection performance.","authors":["Haoyun Zhang","Jianghong Han","Xueqian Wang","Gang Li","Xiao-Ping Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03535v1","updated":"2026-01-07T02:48:21Z","published":"2026-01-07T02:48:21Z","title":"OpenISAC: An Open-Source Real-Time Experimentation Platform for OFDM-ISAC with Over-the-Air Synchronization","summary":"Integrated sensing and communication (ISAC) is envisioned to be one of the key usage scenarios for the sixth generation (6G) mobile communication networks. While significant progresses have been achieved for the theoretical studies, the further advancement of ISAC is hampered by the lack of accessible, open-source, and real-time experimental platforms. To address this gap, we introduce OpenISAC, a versatile and high-performance open-source platform for real-time ISAC experimentation. OpenISAC utilizes orthogonal frequency division multiplexing (OFDM) waveform and implements crucial sensing functionalities, including both monostatic and bistatic delay-Doppler sensing. A key feature of our platform is a novel over-the-air (OTA) synchronization mechanism that enables robust bistatic operations without requiring a wired connection between nodes. The platform is built entirely on open-source software, leveraging the universal software radio peripheral (USRP) hardware driver (UHD) library, thus eliminating the need for any commercial licenses. It supports a wide range of software-defined radios, from the cost-effective USRP B200 series to the high-performance X400 series. The physical layer modulator and demodulator are implemented with C++ for high-speed processing, while the sensing data is streamed to a Python environment, providing a user-friendly interface for rapid prototyping and validation of sensing signal processing algorithms. With flexible parameter selection and real-time communication and sensing operation, OpenISAC serves as a powerful and accessible tool for the academic and research communities to explore and innovate within the field of OFDM-ISAC.","authors":["Zhiwen Zhou","Chaoyue Zhang","Xiaoli Xu","Yong Zeng"],"pdf_url":"","comment":"Submitted to IEEE Transactions on Wireless Communications for possible publication"},{"id":"http://arxiv.org/abs/2601.03527v1","updated":"2026-01-07T02:30:35Z","published":"2026-01-07T02:30:35Z","title":"Intensity Fluctuation Dynamics in XPM","summary":"Cross-Phase Modulation (XPM) constitutes a critical nonlinear impairment in high-capacity Wavelength Division Multiplexing (WDM) systems, significantly driven by intensity fluctuations (IFs) that evolve due to chromatic dispersion. This paper presents an enhanced XPM model that explicitly incorporates frequency-domain IF growth along the fiber, improving upon prior models that focused primarily on temporal pulse deformation. A direct correlation between this frequency-domain growth and XPM-induced phase distortions is established and analyzed. Results demonstrate that IF evolution, particularly at lower frequencies, profoundly affects XPM phase fluctuation spectra and phase variance. Validated through simulations, the model accurately predicts these spectral characteristics across various system parameters. Furthermore, the derived phase variance enables accurate prediction of system performance in terms of Bit Error Ratio (BER). These findings highlight the necessity of modeling frequency-domain IF evolution to accurately characterize XPM impairments, offering guidance for the design of advanced optical networks.","authors":["Ravneel Prasad","Emanuele Viterbo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.07770v4","updated":"2026-01-07T01:55:47Z","published":"2025-06-09T13:46:44Z","title":"Channel Estimation for RIS-Assisted mmWave Systems via Diffusion Models","summary":"Reconfigurable intelligent surface (RIS) has been recognized as a promising technology for next-generation wireless communications. However, the performance of RIS-assisted systems critically depends on accurate channel state information (CSI). To address this challenge, this letter proposes a novel channel estimation method for RIS-aided millimeter-wave (mmWave) systems based on diffusion models (DMs). Specifically, the forward diffusion process of the original signal is formulated to model the received signal as a noisy observation within the framework of DMs. Subsequently, the channel estimation task is formulated as the reverse diffusion process, and a sampling algorithm based on denoising diffusion implicit models (DDIMs) is developed to enable effective inference. Furthermore, a lightweight neural network, termed BRCNet, is introduced to replace the conventional U-Net, significantly reducing the number of parameters and computational complexity. Extensive experiments conducted under various scenarios demonstrate that the proposed method consistently outperforms existing baselines.","authors":["Yang Wang","Yin Xu","Cixiao Zhang","Zhiyong Chen","Mingzeng Dai","Haiming Wang","Bingchao Liu","Dazhi He","Meixia Tao"],"pdf_url":"","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2601.04443v1","updated":"2026-01-07T23:12:03Z","published":"2026-01-07T23:12:03Z","title":"Large Language Models for Detecting Cyberattacks on Smart Grid Protective Relays","summary":"This paper presents a large language model (LLM)-based framework for detecting cyberattacks on transformer current differential relays (TCDRs), which, if undetected, may trigger false tripping of critical transformers. The proposed approach adapts and fine-tunes compact LLMs such as DistilBERT to distinguish cyberattacks from actual faults using textualized multidimensional TCDR current measurements recorded before and after tripping. Our results demonstrate that DistilBERT detects 97.6% of cyberattacks without compromising TCDR dependability and achieves inference latency below 6 ms on a commercial workstation. Additional evaluations confirm the framework's robustness under combined time-synchronization and false-data-injection attacks, resilience to measurement noise, and stability across prompt formulation variants. Furthermore, GPT-2 and DistilBERT+LoRA achieve comparable performance, highlighting the potential of LLMs for enhancing smart grid cybersecurity. We provide the full dataset used in this study for reproducibility.","authors":["Ahmad Mohammad Saber","Saeed Jafari","Zhengmao Ouyang","Paul Budnarain","Amr Youssef","Deepa Kundur"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04433v1","updated":"2026-01-07T22:41:35Z","published":"2026-01-07T22:41:35Z","title":"Achievable Rate and Coding Principle for MIMO Multicarrier Systems With Cross-Domain MAMP Receiver Over Doubly Selective Channels","summary":"The integration of multicarrier modulation and multiple-input-multiple-output (MIMO) is critical for reliable transmission of wireless signals in complex environments, which significantly improve spectrum efficiency. Existing studies have shown that popular orthogonal time frequency space (OTFS) and affine frequency division multiplexing (AFDM) offer significant advantages over orthogonal frequency division multiplexing (OFDM) in uncoded doubly selective channels. However, it remains uncertain whether these benefits extend to coded systems. Meanwhile, the information-theoretic limit analysis of coded MIMO multicarrier systems and the corresponding low-complexity receiver design remain unclear. To overcome these challenges, this paper proposes a multi-slot cross-domain memory approximate message passing (MS-CD-MAMP) receiver as well as develops its information-theoretic (i.e., achievable rate) limit and optimal coding principle for MIMO-multicarrier modulation (e.g., OFDM, OTFS, and AFDM) systems. The proposed MS-CD-MAMP receiver can exploit not only the time domain channel sparsity for low complexity but also the corresponding symbol domain constellation constraints for performance enhancement. Meanwhile, limited by the high-dimensional complex state evolution (SE), a simplified single-input single-output variational SE is proposed to derive the achievable rate of MS-CD-MAMP and the optimal coding principle with the goal of maximizing the achievable rate. Numerical results show that coded MIMO-OFDM/OTFS/AFDM with MS-CD-MAMP achieve the same maximum achievable rate in doubly selective channels, whose finite-length performance with practical optimized low-density parity-check (LDPC) codes is only 0.5 $\\sim$ 1.8 dB away from the associated theoretical limit, and has 0.8 $\\sim$ 4.4 dB gain over the well-designed point-to-point LDPC codes.","authors":["Yuhao Chi","Zhiyuan Peng","Lei Liu","Ying Li","Yao Ge","Chau Yuen"],"pdf_url":"","comment":"16 pages, 11 figures, accepted in IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2601.04415v1","updated":"2026-01-07T21:46:40Z","published":"2026-01-07T21:46:40Z","title":"Towards Radar-Agnostic Gait Analysis Across UWB and FMCW Systems","summary":"Radar sensing has emerged in recent years as a promising solution for unobtrusive and continuous in-home gait monitoring. This study evaluates whether a unified processing framework can be applied to radar-based spatiotemporal gait analysis independent of radar modality. The framework is validated using collocated impulse-radio ultra-wideband (IR-UWB) and frequency-modulated continuous-wave (FMCW) radars under identical processing settings, without modality-specific tuning, during repeated overground walking trials with 10 healthy participants. A modality-independent approach for automatic walking-segment identification is also introduced to ensure fair and reproducible modality performance assessment. Clinically relevant spatiotemporal gait parameters, including stride time, stride length, walking speed, swing time, and stance time, extracted from each modality were compared against gold-standard motion capture reference estimates. Across all parameters, both radar modalities achieved comparably high mean estimation accuracy in the range of 85-98%, with inter-modality differences remaining below 4.1%, resulting in highly overlapping accuracy distributions. Correlation and Bland-Altman analyses revealed minimal bias, comparable limits of agreement, and strong agreement with reference estimates, while intraclass correlation analysis demonstrated high consistency between radar modalities. These findings indicate that no practically meaningful performance differences arise from radar modality when using a shared processing framework, supporting the feasibility of radar-agnostic gait analysis systems.","authors":["Charalambos Hadjipanayi","Maowen Yin","Alan Bannon","Ziwei Chen","Timothy G. Constandinou"],"pdf_url":"","comment":null}],"Computational Geometry":[{"id":"http://arxiv.org/abs/2601.03954v1","updated":"2026-01-07T14:08:13Z","published":"2026-01-07T14:08:13Z","title":"Computing the Intrinsic Delaunay Triangulation of a Closed Polyhedral Surface","summary":"Every surface that is intrinsically polyhedral can be represented by a portalgon: a collection of polygons in the Euclidean plane with some pairs of equally long edges abstractly identified. While this representation is arguably simpler than meshes (flat polygons in R3 forming a surface), it has unbounded happiness: a shortest path in the surface may visit the same polygon arbitrarily many times. This pathological behavior is an obstacle towards efficient algorithms. On the other hand, Löffler, Ophelders, Staals, and Silveira (SoCG 2023) recently proved that the (intrinsic) Delaunay triangulations have bounded happiness.\n  In this paper, given a closed polyhedral surface S, represented by a triangular portalgon T, we provide an algorithm to compute the Delaunay triangulation of S whose vertices are the singularities of S (the points whose surrounding angle is distinct from 2pi). The time complexity of our algorithm is polynomial in the number of triangles and in the logarithm of the aspect ratio r of T. Within our model of computation, we show that the dependency in log(r) is unavoidable. Our algorithm can be used to pre-process a triangular portalgon before computing shortest paths on its surface, and to determine whether the surfaces of two triangular portalgons are isometric.","authors":["Loïc Dubois"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03516v1","updated":"2026-01-07T02:05:35Z","published":"2026-01-07T02:05:35Z","title":"Linear-Time $(1+\\varepsilon)$-Approximation Algorithms for Two-Line-Center Problems","summary":"Given a set $S$ of $n$ points in the plane, we study the two-line-center problem: finding two lines that minimize the maximum distance from each point in $S$ to its closest line. We present a $(1+\\varepsilon)$-approximation algorithm for the two-line-center problem that runs in $O((n/\\varepsilon) \\log (1/\\varepsilon))$ time, which improves the previously best $O(n\\log n + ({n}/{\\varepsilon^2}) \\log ({1}/{\\varepsilon}) + (1/\\varepsilon^3)\\log ({1}/{\\varepsilon}))$-time algorithm. We also consider three variants of this problem, in which the orientations of the two lines are restricted: (1) the orientation of one of the two lines is fixed, (2) the orientations of both lines are fixed, and (3) the two lines are required to be parallel. For each of these three variants, we give the first $(1+\\varepsilon)$-approximation algorithm that runs in linear time. In particular, for the variant where the orientation of one of the two lines is fixed, we also give an improved exact algorithm that runs in $O(n \\log n)$ time and show that it is optimal.","authors":["Chaeyoon Chung","Anil Maheshwari","Michiel Smid"],"pdf_url":"","comment":null}],"Data Structure and Algorithm":[{"id":"http://arxiv.org/abs/2411.03413v3","updated":"2026-01-07T18:51:45Z","published":"2024-11-05T18:54:39Z","title":"Rapid Mixing at the Uniqueness Threshold","summary":"Over the past decades, a fascinating computational phase transition has been identified in sampling from Gibbs distributions. Though, the computational complexity at the critical point remains poorly understood, as previous algorithmic and hardness results all required a constant slack from this threshold.\n  In this paper, we resolve this open question at the critical phase transition threshold, thus completing the picture of the computational phase transition. We show that for the hardcore model on graphs with maximum degree $Δ\\ge 3$ at the uniqueness threshold $λ= λ_c(Δ)$, the mixing time of Glauber dynamics is upper bounded by a polynomial in $n$, but is not nearly linear in the worst case.\n  For the Ising model (either antiferromagnetic or ferromagnetic), we establish similar results. For the Ising model on graphs with maximum degree $Δ\\ge 3$ at the critical temperature $β$ where $|β| = β_c(Δ)$, with the tree-uniqueness threshold $β_c(Δ)$, we show that the mixing time of Glauber dynamics is upper bounded by $\\tilde{O}\\left(n^{3 + O(1/Δ)}\\right)$ and lower bounded by $Ω\\left(n^{3/2}\\right)$ in the worst case. For the Ising model specified by a critical interaction matrix $J$ with $\\left \\lVert J \\right \\rVert_2=1$, we obtain an upper bound $\\tilde{O}(n^{3/2})$ for the mixing time, matching the lower bound $Ω\\left(n^{3/2}\\right)$ on the complete graph up to a logarithmic factor.\n  Our mixing time upper bounds are derived from a new interpretation and analysis of the localization scheme method introduced by Chen and Eldan (2022), applied to the field dynamics for the hardcore model and the proximal sampler for the Ising model. As key steps in both our upper and lower bounds, we establish sub-linear upper and lower bounds for spectral independence at the critical point for worst-case instances.","authors":["Xiaoyu Chen","Zongchen Chen","Yitong Yin","Xinyuan Zhang"],"pdf_url":"","comment":"Remove the incorrectly claimed square-root spectral independence result for the critical graphical Ising model; see Remark 1.6 for details"},{"id":"http://arxiv.org/abs/2601.04169v1","updated":"2026-01-07T18:36:25Z","published":"2026-01-07T18:36:25Z","title":"A Polynomial Kernel for Face Cover on Non-Embedded Planar Graphs","summary":"Given a planar graph, a subset of its vertices called terminals, and $k \\in \\mathbb{N}$, the Face Cover Number problem asks whether the terminals lie on the boundaries of at most $k$ faces of some embedding of the input graph. When a plane graph is given in the input, the problem is known to have a polynomial kernel~\\cite{GarneroST17}. In this paper, we present the first polynomial kernel for Face Cover Number when the input is a planar graph (without a fixed embedding). Our approach overcomes the challenge of not having a predefined set of face boundaries by building a kernel bottom-up on an SPR-tree while preserving the essential properties of the face cover along the way.","authors":["Thekla Hamm","Sukanya Pandey","Krisztina Szilágyi"],"pdf_url":"","comment":"Accepted to STACS 2026"},{"id":"http://arxiv.org/abs/2601.02347v2","updated":"2026-01-07T15:53:40Z","published":"2026-01-05T18:44:27Z","title":"Solving Matrix Games with Near-Optimal Matvec Complexity","summary":"We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ (or zero-sum) games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games (encompassing hard-margin SVMs), where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In both settings our results are nearly-optimal as they match lower bounds of [KS '25] up to polylogarithmic factors.","authors":["Ishani Karmarkar","Liam O'Carroll","Aaron Sidford"],"pdf_url":"","comment":"v2: A few updates to the title, abstract, and intro to reflect the near optimality of our results for $\\ell_1$-$\\ell_1$ games in light of arXiv:2412.06990 v3"},{"id":"http://arxiv.org/abs/2507.17878v3","updated":"2026-01-07T14:47:09Z","published":"2025-07-23T19:11:32Z","title":"Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa","summary":"We introduce a new notion of sparsification, called \\emph{strong sparsification}, in which constraints are not removed but variables can be merged. As our main result, we present a strong sparsification algorithm for 1-in-3-SAT. The correctness of the algorithm relies on establishing a sub-quadratic bound on the size of certain sets of vectors in $\\mathbb{F}_2^d$. This result, obtained using the recent \\emph{Polynomial Freiman-Ruzsa Theorem} (Gowers, Green, Manners and Tao, Ann. Math. 2025), could be of independent interest. As an application, we improve the state-of-the-art algorithm for approximating linearly-ordered colourings of 3-uniform hypergraphs (Håstad, Martinsson, Nakajima and{Ž}ivn{ý}, APPROX 2024).","authors":["Benjamin Bedert","Tamio-Vesa Nakajima","Karolina Okrasa","Stanislav Živný"],"pdf_url":"","comment":"Full version of a FOCS'25 paper; v2 has more results; v3 proves Conjecture 33 from v2, giving a tight bound on strong sparsifiability of 1-in-k-SAT (in possibly exponential time)"},{"id":"http://arxiv.org/abs/2601.03934v1","updated":"2026-01-07T13:52:28Z","published":"2026-01-07T13:52:28Z","title":"Complexity of Perfect and Ideal Resilience Verification in Fast Re-Route Networks","summary":"To achieve fast recovery from link failures, most modern communication networks feature fully decentralized fast re-routing mechanisms. These re-routing mechanisms rely on pre-installed static re-routing rules at the nodes (the routers), which depend only on local failure information, namely on the failed links incident to the node. Ideally, a network is perfectly resilient: the re-routing rules ensure that packets are always successfully routed to their destinations as long as the source and the destination are still physically connected in the underlying network after the failures. Unfortunately, there are examples where achieving perfect resilience is not possible. Surprisingly, only very little is known about the algorithmic aspect of when and how perfect resilience can be achieved.\n  We investigate the computational complexity of analyzing such local fast re-routing mechanisms. Our main result is a negative one: we show that even checking whether a given set of static re-routing rules ensures perfect resilience is coNP-complete. We also show coNP-completeness of the so-called ideal resilience, a weaker notion of resilience often considered in the literature. Additionally, we investigate other fundamental variations of the problem. In particular, we show that our coNP-completeness proof also applies to scenarios where the re-routing rules have specific patterns (known as skipping in the literature).\n  On the positive side, for scenarios where nodes do not have information about the link from which a packet arrived (the so-called in-port), we present linear-time algorithms for both the verification and synthesis problem for perfect resilience.","authors":["Matthias Bentert","Esra Ceylan-Kettler","Valentin Hübner","Stefan Schmid","Jiří Srba"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03897v1","updated":"2026-01-07T13:06:07Z","published":"2026-01-07T13:06:07Z","title":"Implementing Binary Search Trees in GP 2 (Extended Abstract)","summary":"We present an approach to implement binary search trees in the rule-based graph programming language GP 2. Our implementation uses GP 2's rooted graph transformation rules to be fast and supports insertion, deletion and query operations. We argue that the worst-case runtime for each of the operations is O(n) for a tree with n nodes. In addition, we expect that, on average, the operations run in time O(log(n)). Hence the implementation would match the time complexity of binary search trees implementations in imperative languages.","authors":["Ziad Ismaili Alaoui","Detlef Plump"],"pdf_url":"","comment":"In Proceedings GCM 2025, arXiv:2601.03249"},{"id":"http://arxiv.org/abs/2109.02997v5","updated":"2026-01-07T11:49:02Z","published":"2021-09-07T11:17:59Z","title":"Worst-case optimal adaptive alphabetic prefix-free coding","summary":"We give the first algorithm for adaptive alphabetic prefix-free coding that is worst-case optimal in terms of time and compression when $σ\\in o \\left( \\frac{n^{1 / 2}}{\\log n} \\right)$, where $σ$ is the size of the alphabet and $n$ is the length of the input.","authors":["Travis Gagie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.15531v3","updated":"2026-01-07T07:59:36Z","published":"2025-09-19T02:31:17Z","title":"Sparse Neighborhood Graph-Based Approximate Nearest Neighbor Search Revisited: Theoretical Analysis and Optimization","summary":"Graph-based approaches to approximate nearest neighbor search (ANNS) enable fast, high-recall retrieval on billion-scale vector datasets. Among them, the Sparse Neighborhood Graph (SNG) is widely used due to its strong search performance. However, the lack of theoretical understanding of SNG leads to expensive tuning of the truncation parameter that controls graph sparsification. In this work, we present OPT-SNG, a principled framework for analyzing and optimizing SNG construction. We introduce a martingale-based model of the pruning process that characterizes the stochastic evolution of candidate sets during graph construction. Using this framework, we prove that SNG has a maximum out-degree of \\(O(n^{2/3+ε})\\), where \\(ε>0\\) is an arbitrarily small constant, and an expected search path length of \\(O(\\log n)\\). Building on these insights, we derive a closed-form rule for selecting the optimal truncation parameter \\(R\\), thereby eliminating the need for costly parameter sweeping. Extensive experiments on real-world datasets demonstrate that OPT-SNG achieves an average \\(5.9\\times\\) speedup in index construction time, with peak improvements reaching \\(15.4\\times\\), while consistently maintaining or improving search performance.","authors":["Xinran Ma","Zhaoqi Zhou","Chuan Zhou","Zaijiu Shang","Guoliang Li","Zhiming Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.05124v2","updated":"2026-01-07T07:58:46Z","published":"2025-08-07T08:01:59Z","title":"Text Indexing and Pattern Matching with Ephemeral Edits","summary":"A sequence $e_0,e_1,\\ldots$ of edit operations in a string $T$ is called ephemeral if operation $e_i$ constructing string $T^i$, for all $i=2k$ with $k\\in\\mathbb{N}$, is reverted by operation $e_{i+1}$ that reconstructs $T$. Such a sequence arises when processing a stream of independent edits or testing hypothetical edits.\n  We introduce text indexing with ephemeral substring edits, a new version of text indexing. Our goal is to design a data structure over a given text that supports subsequent pattern matching queries with ephemeral substring insertions, deletions, or substitutions in the text; we require insertions and substitutions to be of constant length. In particular, we preprocess a text $T=T[0\\mathinner{.\\,.} n)$ over an integer alphabet $Σ=[0,σ)$ with $σ=n^{\\mathcal{O}(1)}$ in $\\mathcal{O}(n)$ time. Then, we can preprocess any arbitrary pattern $P=P[0\\mathinner{.\\,.} m)$ given online in $\\mathcal{O}(m\\log\\log m)$ time and $\\mathcal{O}(m)$ space and allow any ephemeral sequence of edit operations in $T$. Before reverting the $i$th operation, we report all Occ occurrences of $P$ in $T^i$ in $\\mathcal{O}(\\log\\log n + \\text{Occ})$ time.\n  We also introduce pattern matching with ephemeral edits. In particular, we preprocess two strings $T$ and $P$, each of length at most $n$, over an integer alphabet $Σ=[0,σ)$ with $σ=n^{\\mathcal{O}(1)}$ in $\\mathcal{O}(n)$ time. Then, we allow any ephemeral sequence of edit operations in $T$. Before reverting the $i$th operation, we report all Occ occurrences of $P$ in $T^i$ in the optimal $\\mathcal{O}(\\text{Occ})$ time. Along our way to this result, we also give an optimal solution for pattern matching with ephemeral block deletions.","authors":["Solon P. Pissis"],"pdf_url":"","comment":"SOSA 2026 (abstract abridged to satisfy arXiv requirements)"},{"id":"http://arxiv.org/abs/2601.03643v1","updated":"2026-01-07T06:48:01Z","published":"2026-01-07T06:48:01Z","title":"On $k$-connectivity oracles in $k$-connected graphs","summary":"A $k$-connectivity oracle for a graph $G=(V,E)$ is a data structure that given $s,t \\in V$ determines whether there are at least $k+1$ internally disjoint $st$-paths in $G$. For undirected graphs, Pettie, Saranurak & Yin [STOC 2022, pp. 151-161] proved that any $k$-connectivity oracle requires $Ω(kn)$ bits of space. They asked whether $Ω(kn)$ bits are still necessary if $G$ is $k$-connected. We will show by a very simple proof that this is so even if $G$ is $k$-connected, answering this open question.","authors":["Zeev Nutov"],"pdf_url":"","comment":null}],"Game Theory":[{"id":"http://arxiv.org/abs/2601.02347v2","updated":"2026-01-07T15:53:40Z","published":"2026-01-05T18:44:27Z","title":"Solving Matrix Games with Near-Optimal Matvec Complexity","summary":"We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ (or zero-sum) games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games (encompassing hard-margin SVMs), where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In both settings our results are nearly-optimal as they match lower bounds of [KS '25] up to polylogarithmic factors.","authors":["Ishani Karmarkar","Liam O'Carroll","Aaron Sidford"],"pdf_url":"","comment":"v2: A few updates to the title, abstract, and intro to reflect the near optimality of our results for $\\ell_1$-$\\ell_1$ games in light of arXiv:2412.06990 v3"},{"id":"http://arxiv.org/abs/2601.03853v1","updated":"2026-01-07T12:09:13Z","published":"2026-01-07T12:09:13Z","title":"From No-Regret to Strategically Robust Learning in Repeated Auctions","summary":"In Bayesian single-item auctions, a monotone bidding strategy--one that prescribes a higher bid for a higher value type--can be equivalently represented as a partition of the quantile space into consecutive intervals corresponding to increasing bids. Kumar et al. (2024) prove that agile online gradient descent (OGD), when used to update a monotone bidding strategy through its quantile representation, is strategically robust in repeated first-price auctions: when all bidders employ agile OGD in this way, the auctioneer's average revenue per round is at most the revenue of Myerson's optimal auction, regardless of how she adjusts the reserve price over time.\n  In this work, we show that this strategic robustness guarantee is not unique to agile OGD or to the first-price auction: any no-regret learning algorithm, when fed gradient feedback with respect to the quantile representation, is strategically robust, even if the auction format changes every round, provided the format satisfies allocation monotonicity and voluntary participation. In particular, the multiplicative weights update (MWU) algorithm simultaneously achieves the optimal regret guarantee and the best-known strategic robustness guarantee. At a technical level, our results are established via a simple relation that bridges Myerson's auction theory and standard no-regret learning theory. This showcases the potential of translating standard regret guarantees into strategic robustness guarantees for specific games, without explicitly minimizing any form of swap regret.","authors":["Junyao Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.12629v2","updated":"2026-01-07T10:15:04Z","published":"2025-11-16T14:50:44Z","title":"Bandit Learning in Housing Markets","summary":"The housing market, also known as one-sided matching market, is a classic exchange economy model where each agent on the demand side initially owns an indivisible good (a house) and has a personal preference over all goods. The goal is to find a core-stable allocation that exhausts all mutually beneficial exchanges among subgroups of agents. While this model has been extensively studied in economics and computer science due to its broad applications, little attention has been paid to settings where preferences are unknown and must be learned through repeated interactions. In this paper, we propose a statistical learning model within the multi-player multi-armed bandit framework, where players (agents) learn their preferences over arms (goods) from stochastic rewards. We introduce the notion of \\emph{core regret} for each player as the market objective. We study both centralized and decentralized approaches, proving $O(\\log T / Δ^2)$ upper bounds on regret, where $T$ is the time horizon and $Δ$ is the minimum preference gap among players. For the decentralized setting, we also establish a matching lower bound, demonstrating that our algorithm is order-optimal.","authors":["Shiyun Lin"],"pdf_url":"","comment":"Accepted to AAAI 2026 as oral"},{"id":"http://arxiv.org/abs/2601.03757v1","updated":"2026-01-07T09:45:58Z","published":"2026-01-07T09:45:58Z","title":"Incentive Mechanism Design for Resource Management in Satellite Networks: A Comprehensive Survey","summary":"Resource management is one of the challenges in satellite networks due to their high mobility, wide coverage, long propagation distances, and stringent constraints on energy, communication, and computation resources. Traditional resource allocation approaches rely only on hard and rigid system performance metrics. Meanwhile, incentive mechanisms, which are based on game theory and auction theory, investigate systems from the \"economic\" perspective in addition to the \"system\" perspective. Particularly, incentive mechanisms are able to take into account rationality and other behavior of human users into account, which guarantees benefits/utility of all system entities, thereby improving the scalability, adaptability, and fairness in resource allocation. This paper presents a comprehensive survey of incentive mechanism design for resource management in satellite networks. The paper covers key issues in the satellite networks, such as communication resource allocation, computation offloading, privacy and security, and coordination. We conclude with future research directions including learning-based mechanism design for satellite networks.","authors":["Nguyen Cong Luong","Zeping Sui","Duc Van Le","Jie Cao","Bo Ma","Nguyen Duc Hai","Ruichen Zhang","Vu Van Quang","Dusit Niyato","Shaohan Feng"],"pdf_url":"","comment":"28 pages, 8 figures, accepted by IEEE IoTJ"},{"id":"http://arxiv.org/abs/2502.03616v3","updated":"2026-01-07T00:21:32Z","published":"2025-02-05T21:05:03Z","title":"Noncooperative Consensus via a Trading-based Auction","summary":"Noncooperative multi-agent systems often face coordination challenges due to conflicting preferences among agents. In particular, when agents act in their own self-interest, they may prefer different choices among multiple feasible outcomes, leading to suboptimal outcomes or even safety concerns. We propose an algorithm named trading auction for consensus (TACo), a decentralized approach that enables noncooperative agents to reach consensus without communicating directly or disclosing private valuations. TACo facilitates coordination through a structured trading-based auction, where agents iteratively select choices of interest and provably reach an agreement within an a priori bounded number of steps. A series of numerical experiments validate that the termination guarantees of TACo hold in practice, and show that TACo achieves a median performance that minimizes the total cost across all agents, while allocating resources significantly more fairly than baseline approaches.","authors":["Jaehan Im","Filippos Fotiadis","Daniel Delahaye","Ufuk Topcu","David Fridovich-Keil"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04387v1","updated":"2026-01-07T20:49:45Z","published":"2026-01-07T20:49:45Z","title":"The Language of Bargaining: Linguistic Effects in LLM Negotiations","summary":"Negotiation is a core component of social intelligence, requiring agents to balance strategic reasoning, cooperation, and social norms. Recent work shows that LLMs can engage in multi-turn negotiation, yet nearly all evaluations occur exclusively in English. Using controlled multi-agent simulations across Ultimatum, Buy-Sell, and Resource Exchange games, we systematically isolate language effects across English and four Indic framings (Hindi, Punjabi, Gujarati, Marwadi) by holding game rules, model parameters, and incentives constant across all conditions. We find that language choice can shift outcomes more strongly than changing models, reversing proposer advantages and reallocating surplus. Crucially, effects are task-contingent: Indic languages reduce stability in distributive games yet induce richer exploration in integrative settings. Our results demonstrate that evaluating LLM negotiation solely in English yields incomplete and potentially misleading conclusions. These findings caution against English-only evaluation of LLMs and suggest that culturally-aware evaluation is essential for fair deployment.","authors":["Stuti Sinha","Himanshu Kumar","Aryan Raju Mandapati","Rakshit Sakhuja","Dhruv Kumar"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2507.15735v2","updated":"2026-01-07T20:04:01Z","published":"2025-07-21T15:42:41Z","title":"The Root of Revenue Continuity","summary":"In the setup of selling one or more goods, various papers have shown, in various forms and for various purposes, that a small change in the distribution of a buyer's valuations may cause only a small change in the possible revenue that can be extracted. We prove a simple, clean, convenient, and general statement to this effect: let $X$ and $Y$ be random valuations on $k$ additive goods, and let $W(X,Y)$ be the Wasserstein (or \"earth mover's\") distance between them; then $$\\left\\vert \\sqrt{Rev(X)}-\\sqrt{Rev(Y)}\\right\\vert \\le \\sqrt{W(X,Y)}.$$ This further implies that a simple explicit modification of any optimal mechanism for $X$, namely, \"uniform discounting,\" is guaranteed to be almost optimal for any $Y$ that is close to $X$ in the Wasserstein distance.","authors":["Sergiu Hart","Noam Nisan"],"pdf_url":"","comment":"v2: updated Section 7 to include deterministic mechanisms as well"}],"Information Theory":[{"id":"http://arxiv.org/abs/2601.04193v1","updated":"2026-01-07T18:59:07Z","published":"2026-01-07T18:59:07Z","title":"A discrete Benamou-Brenier formulation of Optimal Transport on graphs","summary":"We propose a discrete transport equation on graphs which connects distributions on both vertices and edges. We then derive a discrete analogue of the Benamou-Brenier formulation for Wasserstein-$1$ distance on a graph and as a result classify all $W_1$ geodesics on graphs.","authors":["Kieran Morris","Oliver Johnson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04166v1","updated":"2026-01-07T18:30:00Z","published":"2026-01-07T18:30:00Z","title":"Expectation Propagation for Distributed Inference in Grant-Free Cell-Free Massive MIMO","summary":"Grant-free cell-free massive multiple-input multiple-output (GF-CF-MaMIMO) systems are anticipated to be a key enabling technology for next-generation Internet-of-Things (IoT) networks, as they support massive connectivity without explicit scheduling. However, the large amount of connected devices prevents the use of orthogonal pilot sequences, resulting in severe pilot contamination (PC) that degrades channel estimation and data detection performance. Furthermore, scalable GF-CF-MaMIMO networks inherently rely on distributed signal processing. In this work, we consider the uplink of a GF-CF-MaMIMO system and propose two novel distributed algorithms for joint activity detection, channel estimation, and data detection (JACD) based on expectation propagation (EP). The first algorithm, denoted as JACD-EP, uses Gaussian approximations for the channel variables, whereas the second, referred to as JACD-EP-BG, models them as Bernoulli-Gaussian (BG) random variables. To integrate the BG distribution into the EP framework, we derive its exponential family representation and develop the two algorithms as efficient message passing over a factor graph constructed from the a posteriori probability (APP) distribution. The proposed framework is inherently scalable with respect to both the number of access points (APs) and user equipments (UEs). Simulation results show the efficient mitigation of PC by the proposed distributed algorithms and their superior detection accuracy compared to (genie-aided) centralized linear detectors.","authors":["Christian Forsch","Laura Cottatellucci"],"pdf_url":"","comment":"13 pages, 5 figures, submitted for possible journal publication"},{"id":"http://arxiv.org/abs/2503.21002v3","updated":"2026-01-07T18:02:05Z","published":"2025-03-26T21:34:18Z","title":"Covert Entanglement Generation and Secrecy","summary":"We determine the covert capacity for entanglement generation over a noisy quantum channel. While secrecy guarantees that the transmitted information remains inaccessible to an adversary, covert communication ensures that the transmission itself remains undetectable. The entanglement dimension follows a square root law (SRL) in the covert setting, i.e., $O(\\sqrt{n})$ EPR pairs can be distributed covertly and reliably over $n$ channel uses. We begin with covert communication of classical information under a secrecy constraint. We then leverage this result to construct a coding scheme for covert entanglement generation.","authors":["Ohad Kimelfeld","Boulat A. Bash","Uzi Pereg"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.15400v4","updated":"2026-01-07T16:36:18Z","published":"2025-06-18T12:18:37Z","title":"The maximum-average subtensor problem: equilibrium and out-of-equilibrium properties","summary":"In this paper we introduce and study the Maximum-Average Subtensor ($p$-MAS) problem, in which one wants to find a subtensor of size $k$ of a given random tensor of size $N$, both of order $p$, with maximum sum of entries. We are motivated by recent work on the matrix case of the problem in which several equilibrium and non-equilibrium properties have been characterized analytically in the asymptotic regime $1 \\ll k \\ll N$, and a puzzling phenomenon was observed involving the coexistence of a clustered equilibrium phase and an efficient algorithm which produces submatrices in this phase. Here we extend previous results on equilibrium and algorithmic properties for the matrix case to the tensor case. We show that the tensor case has a similar equilibrium phase diagram as the matrix case, and an overall similar phenomenology for the considered algorithms. Additionally, we consider out-of-equilibrium landscape properties using Overlap Gap Properties and Franz-Parisi analysis, and discuss the implications or lack-thereof for average-case algorithmic hardness.","authors":["Vittorio Erba","Nathan Malo Kupferschmid","Rodrigo Pérez Ortiz","Lenka Zdeborová"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04041v1","updated":"2026-01-07T15:57:03Z","published":"2026-01-07T15:57:03Z","title":"Serving Every Symbol: All-Symbol PIR and Batch Codes","summary":"A $t$-all-symbol PIR code and a $t$-all-symbol batch code of dimension $k$ consist of $n$ servers storing linear combinations of $k$ linearly independent information symbols with the following recovery property: any symbol stored by a server can be recovered from $t$ pairwise disjoint subsets of servers. In the batch setting, we further require that any multiset of size $t$ of stored symbols can be recovered from $t$ disjoint subsets of servers. This framework unifies and extends several well-known code families, including one-step majority-logic decodable codes, (functional) PIR codes, and (functional) batch codes.\n  In this paper, we determine the minimum code length for some small values of $k$ and $t$, characterize structural properties of codes attaining this optimum, and derive bounds that show the trade-offs between length, dimension, minimum distance, and $t$. In addition, we study MDS codes and the simplex code, demonstrating how these classical families fit within our framework, and establish new cases of an open conjecture from \\cite{YAAKOBI2020} concerning the minimal $t$ for which the simplex code is a $t$-functional batch code.","authors":["Avital Boruchovsky","Anina Gruica","Jonathan Niemann","Eitan Yaakobi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04011v1","updated":"2026-01-07T15:20:26Z","published":"2026-01-07T15:20:26Z","title":"Flexible-Duplex Cell-Free Architecture for Secure Uplink Communications in Low-Altitude Wireless Networks","summary":"Low-altitude wireless networks (LAWNs) are expected to play a central role in future 6G infrastructures, yet uplink transmissions of uncrewed aerial vehicles (UAVs) remain vulnerable to eavesdropping due to their limited transmit power, constrained antenna resources, and highly exposed air-ground propagation conditions. To address this fundamental bottleneck, we propose a flexible-duplex cell-free (CF) architecture in which each distributed access point (AP) can dynamically operate either as a receive AP for UAV uplink collection or as a transmit AP that generates cooperative artificial noise (AN) for secrecy enhancement. Such AP-level duplex flexibility introduces an additional spatial degree of freedom that enables distributed and adaptive protection against wiretapping in LAWNs. Building upon this architecture, we formulate a max-min secrecy-rate problem that jointly optimizes AP mode selection, receive combining, and AN covariance design. This tightly coupled and nonconvex optimization is tackled by first deriving the optimal receive combiners in closed form, followed by developing a penalty dual decomposition (PDD) algorithm with guaranteed convergence to a stationary solution. To further reduce computational burden, we propose a low-complexity sequential scheme that determines AP modes via a heuristic metric and then updates the AN covariance matrices through closed-form iterations embedded in the PDD framework. Simulation results show that the proposed flexible-duplex architecture yields substantial secrecy-rate gains over CF systems with fixed AP roles. The joint optimization method attains the highest secrecy performance, while the low-complexity approach achieves over 90% of the optimal performance with an order-of-magnitude lower computational complexity, offering a practical solution for secure uplink communications in LAWNs.","authors":["Wei Shi","Wei Xu","Yongming Huang","Jiacheng Yao","Wenhao Hu","Dongming Wang"],"pdf_url":"","comment":"Submitted to an IEEE Journal"},{"id":"http://arxiv.org/abs/2601.03982v1","updated":"2026-01-07T14:55:45Z","published":"2026-01-07T14:55:45Z","title":"Unique Decoding of Hyperderivative Reed-Solomon Codes","summary":"Error-correcting codes are combinatorial objects designed to cope with the problem of reliable transmission of information on a noisy channel. A fundamental problem in coding theory and practice is to efficiently decode the received word with errors to obtain the transmitted codeword. In this paper, we consider the decoding problem of Hyperderivative Reed-Solomon (HRS) codes with respect to the NRT metric. Specifically, we propose a Welch-Berlekamp algorithm for the unique decoding of NRT HRS codes.","authors":["Haojie Gu","Jun Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02844v2","updated":"2026-01-07T12:39:42Z","published":"2026-01-06T09:24:02Z","title":"The Sequence Reconstruction of Permutations under Hamming Metric with Small Errors","summary":"The sequence reconstruction problem asks for the recovery of a sequence from multiple noisy copies, where each copy may contain up to $r$ errors. In the case of permutations on \\(n\\) letters under the Hamming metric, this problem is closely related to the parameter $N(n,r)$, the maximum intersection size of two Hamming balls of radius $r$. While previous work has resolved \\(N(n,r)\\) for small radii (\\(r \\leq 4\\)) and established asymptotic bounds for larger \\(r\\), we present new exact formulas for \\(r \\in \\{5,6,7\\}\\) using group action techniques. In addition, we develop a formula for \\(N(n,r)\\) based on the irreducible characters of the symmetric group \\(S_n\\), along with an algorithm that enables computation of \\(N(n,r)\\) for larger parameters, including cases such as \\(N(43,8)\\) and \\(N(24,14)\\).","authors":["A. Abdollahi","J. Bagherian","H. Eskandari","F. Jafari","M. Khatami","F. Parvaresh","R. Sobhani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03831v1","updated":"2026-01-07T11:52:32Z","published":"2026-01-07T11:52:32Z","title":"Low-Complexity Planar Beyond-Diagonal RIS Architecture Design Using Graph Theory","summary":"Reconfigurable intelligent surfaces (RISs) enable programmable control of the wireless propagation environment and are key enablers for future networks. Beyond-diagonal RIS (BD-RIS) architectures enhance conventional RIS by interconnecting elements through tunable impedance components, offering greater flexibility with higher circuit complexity. However, excessive interconnections between BD-RIS elements require multi-layer printed circuit board (PCB) designs, increasing fabrication difficulty. In this letter, we use graph theory to characterize the BD-RIS architectures that can be realized on double-layer PCBs, denoted as planar-connected RISs. Among the possible planar-connected RISs, we identify the ones with the most degrees of freedom, expected to achieve the best performance under practical constraints.","authors":["Matteo Nerini","Zheyu Wu","Shanpu Shen","Bruno Clerckx"],"pdf_url":"","comment":"Submitted to IEEE for publication"},{"id":"http://arxiv.org/abs/2109.02997v5","updated":"2026-01-07T11:49:02Z","published":"2021-09-07T11:17:59Z","title":"Worst-case optimal adaptive alphabetic prefix-free coding","summary":"We give the first algorithm for adaptive alphabetic prefix-free coding that is worst-case optimal in terms of time and compression when $σ\\in o \\left( \\frac{n^{1 / 2}}{\\log n} \\right)$, where $σ$ is the size of the alphabet and $n$ is the length of the input.","authors":["Travis Gagie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16225v3","updated":"2026-01-07T10:29:28Z","published":"2025-04-22T19:35:55Z","title":"Towards a Generalized Theory of Observers","summary":"We propose a formal framework for understanding and unifying the concept of observers across physics, computer science, philosophy, and related fields. Building on cybernetic feedback models, we introduce an operational definition of minimal observers, explore their role in shaping foundational concepts, and identify what remains unspecified in their absence. Drawing upon insights from quantum gravity, digital physics, second-order cybernetics, and recent ruliological and pregeometric approaches, we argue that observers serve as indispensable reference points for measurement, reference frames, and the emergence of meaning. We show how this formalism sheds new light on debates related to consciousness, quantum measurement, and computational boundaries; by way of theorems on observer equivalences and complexity measures. This perspective opens new avenues for investigating how complexity and structure arise in both natural and artificial systems.","authors":["Hatem Elshatlawy","Dean Rickles","Xerxes D. Arsiwalla"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03734v1","updated":"2026-01-07T09:25:07Z","published":"2026-01-07T09:25:07Z","title":"Computational hardness of estimating quantum entropies via binary entropy bounds","summary":"We investigate the computational hardness of estimating the quantum $α$-Rényi entropy ${\\rm S}^{\\tt R}_α(ρ) = \\frac{\\ln {\\rm Tr}(ρ^α)}{1-α}$ and the quantum $q$-Tsallis entropy ${\\rm S}^{\\tt T}_q(ρ) = \\frac{1-{\\rm Tr}(ρ^q)}{q-1}$, both converging to the von Neumann entropy as the order approaches $1$. The promise problems Quantum $α$-Rényi Entropy Approximation (RényiQEA$_α$) and Quantum $q$-Tsallis Entropy Approximation (TsallisQEA$_q$) ask whether $ {\\rm S}^ {\\tt R}_α(ρ)$ or ${\\rm S}^{\\tt T}_q(ρ)$, respectively, is at least $τ_{\\tt Y}$ or at most $τ_{\\tt N}$, where $τ_{\\tt Y} - τ_{\\tt N}$ is typically a positive constant. Previous hardness results cover only the von Neumann entropy (order $1$) and some cases of the quantum $q$-Tsallis entropy, while existing approaches do not readily extend to other orders.\n  We establish that for all positive real orders, the rank-$2$ variants Rank2RényiQEA$_α$ and Rank2TsallisQEA$_q$ are ${\\sf BQP}$-hard. Combined with prior (rank-dependent) quantum query algorithms in Wang, Guan, Liu, Zhang, and Ying (TIT 2024), Wang, Zhang, and Li (TIT 2024), and Liu and Wang (SODA 2025), our results imply:\n  - For all real orders $α> 0$ and $0 < q \\leq 1$, LowRankRényiQEA$_α$ and LowRankTsallisQEA$_q$ are ${\\sf BQP}$-complete, where both are restricted versions of RényiQEA$_α$ and TsallisQEA$_q$ with $ρ$ of polynomial rank.\n  - For all real order $q>1$, TsallisQEA$_q$ is ${\\sf BQP}$-complete.\n  Our hardness results stem from reductions based on new inequalities relating the $α$-Rényi or $q$-Tsallis binary entropies of different orders, where the reductions differ substantially from previous approaches, and the inequalities are also of independent interest.","authors":["Yupan Liu"],"pdf_url":"","comment":"39 pages, 3 tables. To appear in STACS 2026"},{"id":"http://arxiv.org/abs/2410.18757v4","updated":"2026-01-07T08:15:13Z","published":"2024-10-24T14:09:09Z","title":"Short-time Fourier Transform-based Signal Recovery for Modulo Analog-to-Digital Converters","summary":"This study introduces a short-time Fourier transform-based method for reconstructing signals encoded using modulo analog-to-digital converters with 1-bit folding information. In contrast to existing Fourier-based reconstruction approaches that require complete access to the entire observation, the proposed technique performs reconstruction over short, overlapping segments, enabling significantly lower latency while preserving the recovery accuracy. We also address the spectral leakage introduced by the windowing operation by selecting window parameters that balance the leakage suppression and the computational complexity of the algorithm. In addition, we establish conditions under which the correct unfolding of the modulo samples is guaranteed, leading to a reconstruction error determined solely by the quantization noise at the output. The numerical results demonstrate that the proposed method enables modulo analog-to-digital converters to surpass the mean squared error performance of conventional analog-to-digital converters. Furthermore, the proposed recovery method offers improved reconstruction performance compared with higher-order difference-based recovery, particularly in low-resolution and low-sampling rate regimes.","authors":["Neil Irwin Bernardo"],"pdf_url":"","comment":"17 pages, 11 figures, this work has been accepted for publication in an IEEE journal"},{"id":"http://arxiv.org/abs/2402.11352v9","updated":"2026-01-07T07:35:25Z","published":"2024-02-17T18:03:47Z","title":"On Achievable Spectral Efficiency Using Adaptive Transmission Over Terrestrial Coherent FSO Links","summary":"Terrestrial free-space optical (FSO) communication systems, while designed to operate on large unlicensed optical bandwidths, are power-constrained due to strict eye safety regulations. The channel fluctuation inherent in terrestrial FSO links also limits the received optical power. Consequently, the available signal-to-noise ratio (SNR) per Hz could become limited; this holds for future terrestrial systems based on coherent optical communications. An efficient and adaptive transmission mechanism is thus crucial at the optical transmitter. However, a critical assessment of the impact of adaptive transmission in terrestrial FSO systems has received less attention in the literature. This work studies terrestrial coherent FSO communication systems employing adaptive beam transmission while detection receiver operate under shot noise-limited conditions. Specifically, we propose a novel exact closed-form expression for the average spectral efficiency of a coherent FSO system with optimal adaptive transmissions over the gamma-gamma turbulence channel with pointing errors. More importantly, we provide a detailed assessment of the impact of turbulence and pointing error impairments on the coherent FSO system performance, revealing several novel and counterintuitive insights. In particular, the extensive numerical results help elucidate the intricacies of analyzing these terrestrial FSO systems and clarify a few misconceptions alluded to in recent related literature.","authors":["Himani Verma","Kamal Singh","Ranjan K. Mallik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03653v1","updated":"2026-01-07T07:04:38Z","published":"2026-01-07T07:04:38Z","title":"Rank metric codes from Drinfeld modules","summary":"We establish a connection between Drinfeld modules and rank metric codes, focusing on the case of semifield codes. Our framework constructs rank metric codes from linear subspaces of endomorphisms of a Drinfeld module, using tools such as characteristic polynomials on Tate modules and the Chebotarev density theorem. We show that Sheekey's construction [She20] fits naturally into this setting, yielding a short conceptual proof of one of his main results. We then give a new construction of infinite families of semifield codes arising from Drinfeld modules defined over finite fields.","authors":["Giacomo Micheli","Mihran Papikian"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2601.03623v1","updated":"2026-01-07T06:06:20Z","published":"2026-01-07T06:06:20Z","title":"Strip-Symmetric Quantum Codes for Biased Noise: Z-Decoupling in Stabilizer and Floquet Codes","summary":"Bias-tailored codes such as the XZZX surface code and the domain wall color code achieve high dephasing-biased thresholds because, in the infinite-bias limit, their $Z$ syndromes decouple into one-dimensional repetition-like chains; the $X^3Z^3$ Floquet code shows an analogous strip-wise structure for detector events in spacetime. We capture this common mechanism by defining strip-symmetric biased codes, a class of static stabilizer and dynamical (Floquet) codes for which, under pure dephasing and perfect measurements, each elementary $Z$ fault is confined to a strip and the Z-detector--fault incidence matrix is block diagonal. For such codes the Z-detector hypergraph decomposes into independent strip components and maximum-likelihood $Z$ decoding factorizes across strips, yielding complexity savings for matching-based decoders. We characterize strip symmetry via per-strip stabilizer products, viewed as a $\\mathbb{Z}_2$ 1-form symmetry, place XZZX, the domain wall color code, and $X^3Z^3$ in this framework, and introduce synthetic strip-symmetric detector models and domain-wise Clifford constructions that serve as design tools for new bias-tailored Floquet codes.","authors":["Mohammad Rowshan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01620v2","updated":"2026-01-07T03:46:43Z","published":"2026-01-04T17:59:33Z","title":"The Gray Area: Characterizing Moderator Disagreement on Reddit","summary":"Volunteer moderators play a crucial role in sustaining online dialogue, but they often disagree about what should or should not be allowed. In this paper, we study the complexity of content moderation with a focus on disagreements between moderators, which we term the ``gray area'' of moderation. Leveraging 5 years and 4.3 million moderation log entries from 24 subreddits of different topics and sizes, we characterize how gray area, or disputed cases, differ from undisputed cases. We show that one-in-seven moderation cases are disputed among moderators, often addressing transgressions where users' intent is not directly legible, such as in trolling and brigading, as well as tensions around community governance. This is concerning, as almost half of all gray area cases involved automated moderation decisions. Through information-theoretic evaluations, we demonstrate that gray area cases are inherently harder to adjudicate than undisputed cases and show that state-of-the-art language models struggle to adjudicate them. We highlight the key role of expert human moderators in overseeing the moderation process and provide insights about the challenges of current moderation processes and tools.","authors":["Shayan Alipour","Shruti Phadke","Seyed Shahabeddin Mousavi","Amirhossein Afsharrad","Morteza Zihayat","Mattia Samory"],"pdf_url":"","comment":"Accepted at ICWSM 2026"},{"id":"http://arxiv.org/abs/2601.03501v1","updated":"2026-01-07T01:29:49Z","published":"2026-01-07T01:29:49Z","title":"The strong topological Rokhlin property and Medvedev degrees of SFTs","summary":"We prove that if a recursively presented group admits a (nonempty) subshift of finite type with nonzero Medvedev degree then it fails to have the strong topological Rokhlin property. This result simplifies a known criterion and provides new examples of recursively presented groups without this property.","authors":["Nicanor Carrasco-Vargas"],"pdf_url":"","comment":"8 pages, comments welcome!"},{"id":"http://arxiv.org/abs/2601.03498v1","updated":"2026-01-07T01:26:20Z","published":"2026-01-07T01:26:20Z","title":"A Quantifiable Information-Processing Hierarchy Provides a Necessary Condition for Detecting Agency","summary":"As intelligent systems are developed across diverse substrates - from machine learning models and neuromorphic hardware to in vitro neural cultures - understanding what gives a system agency has become increasingly important. Existing definitions, however, tend to rely on top-down descriptions that are difficult to quantify. We propose a bottom-up framework grounded in a system's information-processing order: the extent to which its transformation of input evolves over time. We identify three orders of information processing. Class I systems are reactive and memoryless, mapping inputs directly to outputs. Class II systems incorporate internal states that provide memory but follow fixed transformation rules. Class III systems are adaptive; their transformation rules themselves change as a function of prior activity. While not sufficient on their own, these dynamics represent necessary informational conditions for genuine agency. This hierarchy offers a measurable, substrate-independent way to identify the informational precursors of agency. We illustrate the framework with neurophysiological and computational examples, including thermostats and receptor-like memristors, and discuss its implications for the ethical and functional evaluation of systems that may exhibit agency.","authors":["Brett J. Kagan","Valentina Baccetti","Brian D. Earp","J. Lomax Boyd","Julian Savulescu","Adeel Razi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03492v1","updated":"2026-01-07T01:11:31Z","published":"2026-01-07T01:11:31Z","title":"Hermitian LCD $2$-Quasi Abelian Codes over Finite Chain Rings","summary":"This paper introduces a class of Hermitian LCD $2$-quasi-abelian codes over finite fields and presents a comprehensive enumeration of these codes in which relative minimum weights are small. We show that such codes are asymptotically good over finite fields. Furthermore, we extend our analysis to finite chain rings by characterizing $2$-quasi-abelian codes in this setting and proving the existence of asymptotically good Hermitian LCD $2$-quasi-abelian codes over finite chain rings as well.","authors":["Sanjit Bhowmick","Kuntal Deka"],"pdf_url":"","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2505.01538v3","updated":"2026-01-07T18:49:03Z","published":"2025-05-02T18:59:31Z","title":"HONEYBEE: Efficient Role-based Access Control for Vector Databases via Dynamic Partitioning[Technical Report]","summary":"Enterprise deployments of vector databases require access control policies to protect sensitive data. These systems often implement access control through hybrid vector queries that combine nearest-neighbor search with relational predicates based on user permissions. However, existing approaches face a fundamental trade-off: dedicated per-user indexes minimize query latency but incur high memory redundancy, while shared indexes with post-search filtering reduce memory overhead at the cost of increased latency. This paper introduces HONEYBEE, a dynamic partitioning framework that leverages the structure of Role-Based Access Control (RBAC) policies to create a smooth trade-off between these extremes. RBAC policies organize users into roles and assign permissions at the role level, creating a natural ``thin waist`` in the permission structure that is ideal for partitioning decisions. Specifically, HONEYBEE produces overlapping partitions where vectors can be strategically replicated across different partitions to reduce query latency while controlling memory overhead. To guide these decisions, HONEYBEE develops analytical models of vector search performance and recall, and formulates partitioning as a constrained optimization problem that balances memory usage, query efficiency, and recall. Evaluations on RBAC workloads demonstrate that HONEYBEE achieves up to 13.5X lower query latency than row-level security with only a 1.24X increase in memory usage, while achieving comparable query performance to dedicated, per-role indexes with 90.4% reduction in additional memory consumption, offering a practical middle ground for secure and efficient vector search.","authors":["Hongbin Zhong","Matthew Lentz","Nina Narodytska","Adriana Szekeres","Kexin Rong"],"pdf_url":"","comment":"Accepted by SIGMOD 2026"},{"id":"http://arxiv.org/abs/2601.01291v2","updated":"2026-01-07T15:44:12Z","published":"2026-01-03T21:35:01Z","title":"Curator: Efficient Vector Search with Low-Selectivity Filters","summary":"Embedding-based dense retrieval has become the cornerstone of many critical applications, where approximate nearest neighbor search (ANNS) queries are often combined with filters on labels such as dates and price ranges. Graph-based indexes achieve state-of-the-art performance on unfiltered ANNS but encounter connectivity breakdown on low-selectivity filtered queries, where qualifying vectors become sparse and the graph structure among them fragments. Recent research proposes specialized graph indexes that address this issue by expanding graph degree, which incurs prohibitively high construction costs. Given these inherent limitations of graph-based methods, we argue for a dual-index architecture and present Curator, a partition-based index that complements existing graph-based approaches for low-selectivity filtered ANNS. Curator builds specialized indexes for different labels within a shared clustering tree, where each index adapts to the distribution of its qualifying vectors to ensure efficient search while sharing structure to minimize memory overhead. The system also supports incremental updates and handles arbitrary complex predicates beyond single-label filters by efficiently constructing temporary indexes on the fly. Our evaluation demonstrates that integrating Curator with state-of-the-art graph indexes reduces low-selectivity query latency by up to 20.9x compared to pre-filtering fallback, while increasing construction time and memory footprint by only 5.5% and 4.3%, respectively.","authors":["Yicheng Jin","Yongji Wu","Wenjun Hu","Bruce M. Maggs","Jun Yang","Xiao Zhang","Danyang Zhuo"],"pdf_url":"","comment":"Accepted at SIGMOD 2026"},{"id":"http://arxiv.org/abs/2601.04019v1","updated":"2026-01-07T15:34:15Z","published":"2026-01-07T15:34:15Z","title":"Modeling Behavioral Patterns in News Recommendations Using Fuzzy Neural Networks","summary":"News recommender systems are increasingly driven by black-box models, offering little transparency for editorial decision-making. In this work, we introduce a transparent recommender system that uses fuzzy neural networks to learn human-readable rules from behavioral data for predicting article clicks. By extracting the rules at configurable thresholds, we can control rule complexity and thus, the level of interpretability. We evaluate our approach on two publicly available news datasets (i.e., MIND and EB-NeRD) and show that we can accurately predict click behavior compared to several established baselines, while learning human-readable rules. Furthermore, we show that the learned rules reveal news consumption patterns, enabling editors to align content curation goals with target audience behavior.","authors":["Kevin Innerebner","Stephan Bartl","Markus Reiter-Haas","Elisabeth Lex"],"pdf_url":"","comment":"Accepted for the IR for Good track at ECIR'26"},{"id":"http://arxiv.org/abs/2601.03903v1","updated":"2026-01-07T13:14:12Z","published":"2026-01-07T13:14:12Z","title":"Unleashing the Potential of Neighbors: Diffusion-based Latent Neighbor Generation for Session-based Recommendation","summary":"Session-based recommendation aims to predict the next item that anonymous users may be interested in, based on their current session interactions. Recent studies have demonstrated that retrieving neighbor sessions to augment the current session can effectively alleviate the data sparsity issue and improve recommendation performance. However, existing methods typically rely on explicitly observed session data, neglecting latent neighbors - not directly observed but potentially relevant within the interest space - thereby failing to fully exploit the potential of neighbor sessions in recommendation. To address the above limitation, we propose a novel model of diffusion-based latent neighbor generation for session-based recommendation, named DiffSBR. Specifically, DiffSBR leverages two diffusion modules, including retrieval-augmented diffusion and self-augmented diffusion, to generate high-quality latent neighbors. In the retrieval-augmented diffusion module, we leverage retrieved neighbors as guiding signals to constrain and reconstruct the distribution of latent neighbors. Meanwhile, we adopt a training strategy that enables the retriever to learn from the feedback provided by the generator. In the self-augmented diffusion module, we explicitly guide the generation of latent neighbors by injecting the current session's multi-modal signals through contrastive learning. After obtaining the generated latent neighbors, we utilize them to enhance session representations for improving session-based recommendation. Extensive experiments on four public datasets show that DiffSBR generates effective latent neighbors and improves recommendation performance against state-of-the-art baselines.","authors":["Yuhan Yang","Jie Zou","Guojia An","Jiwei Wei","Yang Yang","Heng Tao Shen"],"pdf_url":"","comment":"This paper has been accepted by KDD 2026"},{"id":"http://arxiv.org/abs/2509.19695v2","updated":"2026-01-07T10:51:43Z","published":"2025-09-24T02:06:26Z","title":"DyBBT: Dynamic Balance via Bandit inspired Targeting for Dialog Policy with Cognitive Dual-Systems","summary":"Task oriented dialog systems often rely on static exploration strategies that do not adapt to dynamic dialog contexts, leading to inefficient exploration and suboptimal performance. We propose DyBBT, a novel dialog policy learning framework that formalizes the exploration challenge through a structured cognitive state space capturing dialog progression, user uncertainty, and slot dependency. DyBBT proposes a bandit inspired meta-controller that dynamically switches between a fast intuitive inference (System 1) and a slow deliberative reasoner (System 2) based on real-time cognitive states and visitation counts. Extensive experiments on single- and multi-domain benchmarks show that DyBBT achieves state-of-the-art performance in success rate, efficiency, and generalization, with human evaluations confirming its decisions are well aligned with expert judgment. Code is available at https://github.com/carsonz/DyBBT.","authors":["Shuyu Zhang","Yifan Wei","Jialuo Yuan","Xinru Wang","Yanmin Zhu","Bin Li","Yujie Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.19742v3","updated":"2026-01-07T10:51:23Z","published":"2025-09-24T03:44:16Z","title":"HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST","summary":"Zero-shot Dialog State Tracking (zs-DST) is essential for enabling Task-Oriented Dialog Systems (TODs) to generalize to new domains without costly data annotation. A central challenge lies in the semantic misalignment between dynamic dialog contexts and static prompts, leading to inflexible cross-layer coordination, domain interference, and catastrophic forgetting. To tackle this, we propose Hierarchical Collaborative Low-Rank Adaptation (HiCoLoRA), a framework that enhances zero-shot slot inference through robust prompt alignment. It features a hierarchical LoRA architecture for dynamic layer-specific processing (combining lower-layer heuristic grouping and higher-layer full interaction), integrates Spectral Joint Domain-Slot Clustering to identify transferable associations (feeding an Adaptive Linear Fusion Mechanism), and employs Semantic-Enhanced SVD Initialization (SemSVD-Init) to preserve pre-trained knowledge. Experiments on multi-domain datasets MultiWOZ and SGD show that HiCoLoRA outperforms baselines, achieving SOTA in zs-DST. Code is available at https://github.com/carsonz/HiCoLoRA.","authors":["Shuyu Zhang","Yifan Wei","Xinru Wang","Yanmin Zhu","Yangfan He","Yixuan Weng","Bin Li","Yujie Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03793v1","updated":"2026-01-07T10:50:18Z","published":"2026-01-07T10:50:18Z","title":"Prompt Tuning without Labeled Samples for Zero-Shot Node Classification in Text-Attributed Graphs","summary":"Node classification is a fundamental problem in information retrieval with many real-world applications, such as community detection in social networks, grouping articles published online and product categorization in e-commerce. Zero-shot node classification in text-attributed graphs (TAGs) presents a significant challenge, particularly due to the absence of labeled data. In this paper, we propose a novel Zero-shot Prompt Tuning (ZPT) framework to address this problem by leveraging a Universal Bimodal Conditional Generator (UBCG). Our approach begins with pre-training a graph-language model to capture both the graph structure and the associated textual descriptions of each node. Following this, a conditional generative model is trained to learn the joint distribution of nodes in both graph and text modalities, enabling the generation of synthetic samples for each class based solely on the class name. These synthetic node and text embeddings are subsequently used to perform continuous prompt tuning, facilitating effective node classification in a zero-shot setting. Furthermore, we conduct extensive experiments on multiple benchmark datasets, demonstrating that our framework performs better than existing state-of-the-art baselines. We also provide ablation studies to validate the contribution of the bimodal generator. The code is provided at: https://github.com/Sethup123/ZPT.","authors":["Sethupathy Parameswaran","Suresh Sundaram","Yuan Fang"],"pdf_url":"","comment":"Accepted by WSDM 2026"},{"id":"http://arxiv.org/abs/2601.03748v1","updated":"2026-01-07T09:37:36Z","published":"2026-01-07T09:37:36Z","title":"Bridging OLAP and RAG: A Multidimensional Approach to the Design of Corpus Partitioning","summary":"Retrieval-Augmented Generation (RAG) systems are increasingly deployed on large-scale document collections, often comprising millions of documents and tens of millions of text chunks. In industrial-scale retrieval platforms, scalability is typically addressed through horizontal sharding and a combination of Approximate Nearest-Neighbor search, hybrid indexing, and optimized metadata filtering. Although effective from an efficiency perspective, these mechanisms rely on bottom-up, similarity-driven organization and lack a conceptual rationale for corpus partitioning. In this paper, we claim that the design of large-scale RAG systems may benefit from the combination of two orthogonal strategies: semantic clustering, which optimizes locality in embedding space, and multidimensional partitioning, which governs where retrieval should occur based on conceptual dimensions such as time and organizational context. Although such dimensions are already implicitly present in current systems, they are used in an ad hoc and poorly structured manner. We propose the Dimensional Fact Model (DFM) as a conceptual framework to guide the design of multidimensional partitions for RAG corpora. The DFM provides a principled way to reason about facts, dimensions, hierarchies, and granularity in retrieval-oriented settings. This framework naturally supports hierarchical routing and controlled fallback strategies, ensuring that retrieval remains robust even in the presence of incomplete metadata, while transforming the search process from a 'black-box' similarity matching into a governable and deterministic workflow. This work is intended as a position paper; its goal is to bridge the gap between OLAP-style multidimensional modeling and modern RAG architectures, and to stimulate further research on principled, explainable, and governable retrieval strategies at scale.","authors":["Dario Maio","Stefano Rizzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03730v1","updated":"2026-01-07T09:21:59Z","published":"2026-01-07T09:21:59Z","title":"Perception-Aware Bias Detection for Query Suggestions","summary":"Bias in web search has been in the spotlight of bias detection research for quite a while. At the same time, little attention has been paid to query suggestions in this regard. Awareness of the problem of biased query suggestions has been raised. Likewise, there is a rising need for automatic bias detection approaches. This paper adds on the bias detection pipeline for bias detection in query suggestions of person-related search developed by Bonart et al. \\cite{Bonart_2019a}. The sparseness and lack of contextual metadata of query suggestions make them a difficult subject for bias detection. Furthermore, query suggestions are perceived very briefly and subliminally. To overcome these issues, perception-aware metrics are introduced. Consequently, the enhanced pipeline is able to better detect systematic topical bias in search engine query suggestions for person-related searches. The results of an analysis performed with the developed pipeline confirm this assumption. Due to the perception-aware bias detection metrics, findings produced by the pipeline can be assumed to reflect bias that users would discern.","authors":["Fabian Haak","Philipp Schaer"],"pdf_url":"","comment":"13 pages (pp. 130-142); 2 figures; 2 tables; Workshop paper (BIAS 2021) published in CCIS vol. 1418 (Springer)"},{"id":"http://arxiv.org/abs/2601.03628v1","updated":"2026-01-07T06:17:04Z","published":"2026-01-07T06:17:04Z","title":"Global research trends and collaborations in Fibrodysplasia Ossificans Progressiva: A bibliometric analysis (1989-2023)","summary":"Fibrodysplasia Ossificans Progressiva (FOP) is a rare and debilitating genetic disorder characterized by the progressive formation of bone in muscles and connective tissues. This scientometric analysis examines the global research trends on FOP between 1989 and 2023 using bibliographic data from Web of Science. The study highlights key patterns in publication productivity, influential journals, institutions, and the geographical distribution of research. The findings reveal that the United States leads both in terms of total publications and citation impact, with significant contributions from the UK, Italy, Japan, and other European countries. Additionally, the analysis identifies the major document types, including articles and reviews, and evaluates the collaborative efforts across institutions. The study offers valuable insights into the global research landscape of FOP, providing a foundation for future studies and international collaborations.","authors":["Muneer Ahmad","Undie Felicia Nkatv","Sajid Saleem"],"pdf_url":"","comment":"23 page, 4 figures, Research article"},{"id":"http://arxiv.org/abs/2512.16925v2","updated":"2026-01-07T06:16:41Z","published":"2025-11-04T07:24:45Z","title":"V-Agent: An Interactive Video Search System Using Vision-Language Models","summary":"We introduce V-Agent, a novel multi-agent platform designed for advanced video search and interactive user-system conversations. By fine-tuning a vision-language model (VLM) with a small video preference dataset and enhancing it with a retrieval vector from an image-text retrieval model, we overcome the limitations of traditional text-based retrieval systems in multimodal scenarios. The VLM-based retrieval model independently embeds video frames and audio transcriptions from an automatic speech recognition (ASR) module into a shared multimodal representation space, enabling V-Agent to interpret both visual and spoken content for context-aware video search. This system consists of three agents-a routing agent, a search agent, and a chat agent-that work collaboratively to address user intents by refining search outputs and communicating with users. The search agent utilizes the VLM-based retrieval model together with an additional re-ranking module to further enhance video retrieval quality. Our proposed framework demonstrates state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark, highlighting its potential for both academic research and real-world applications. The retrieval model and demo videos are available at https://huggingface.co/NCSOFT/multimodal-embedding.","authors":["SunYoung Park","Jong-Hyeon Lee","Youngjune Kim","Daegyu Sung","Younghyun Yu","Young-rok Cha","Jeongho Ju"],"pdf_url":"","comment":"CIKM 2025 MMGENSR Workshop"},{"id":"http://arxiv.org/abs/2601.03600v1","updated":"2026-01-07T05:30:53Z","published":"2026-01-07T05:30:53Z","title":"ALERT: Zero-shot LLM Jailbreak Detection via Internal Discrepancy Amplification","summary":"Despite rich safety alignment strategies, large language models (LLMs) remain highly susceptible to jailbreak attacks, which compromise safety guardrails and pose serious security risks. Existing detection methods mainly detect jailbreak status relying on jailbreak templates present in the training data. However, few studies address the more realistic and challenging zero-shot jailbreak detection setting, where no jailbreak templates are available during training. This setting better reflects real-world scenarios where new attacks continually emerge and evolve. To address this challenge, we propose a layer-wise, module-wise, and token-wise amplification framework that progressively magnifies internal feature discrepancies between benign and jailbreak prompts. We uncover safety-relevant layers, identify specific modules that inherently encode zero-shot discriminative signals, and localize informative safety tokens. Building upon these insights, we introduce ALERT (Amplification-based Jailbreak Detector), an efficient and effective zero-shot jailbreak detector that introduces two independent yet complementary classifiers on amplified representations. Extensive experiments on three safety benchmarks demonstrate that ALERT achieves consistently strong zero-shot detection performance. Specifically, (i) across all datasets and attack strategies, ALERT reliably ranks among the top two methods, and (ii) it outperforms the second-best baseline by at least 10% in average Accuracy and F1-score, and sometimes by up to 40%.","authors":["Xiao Lin","Philip Li","Zhichen Zeng","Tingwei Li","Tianxin Wei","Xuying Ning","Gaotang Li","Yuzhong Chen","Hanghang Tong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03496v1","updated":"2026-01-07T01:23:44Z","published":"2026-01-07T01:23:44Z","title":"STELLA: Self-Reflective Terminology-Aware Framework for Building an Aerospace Information Retrieval Benchmark","summary":"Tasks in the aerospace industry heavily rely on searching and reusing large volumes of technical documents, yet there is no public information retrieval (IR) benchmark that reflects the terminology- and query-intent characteristics of this domain. To address this gap, this paper proposes the STELLA (Self-Reflective TErminoLogy-Aware Framework for BuiLding an Aerospace Information Retrieval Benchmark) framework. Using this framework, we introduce the STELLA benchmark, an aerospace-specific IR evaluation set constructed from NASA Technical Reports Server (NTRS) documents via a systematic pipeline that comprises document layout detection, passage chunking, terminology dictionary construction, synthetic query generation, and cross-lingual extension. The framework generates two types of queries: the Terminology Concordant Query (TCQ), which includes the terminology verbatim to evaluate lexical matching, and the Terminology Agnostic Query (TAQ), which utilizes the terminology's description to assess semantic matching. This enables a disentangled evaluation of the lexical and semantic matching capabilities of embedding models. In addition, we combine Chain-of-Density (CoD) and the Self-Reflection method with query generation to improve quality and implement a hybrid cross-lingual extension that reflects real user querying practices. Evaluation of seven embedding models on the STELLA benchmark shows that large decoder-based embedding models exhibit the strongest semantic understanding, while lexical matching methods such as BM25 remain highly competitive in domains where exact lexical matching technical term is crucial. The STELLA benchmark provides a reproducible foundation for reliable performance evaluation and improvement of embedding models in aerospace-domain IR tasks. The STELLA benchmark can be found in https://huggingface.co/datasets/telepix/STELLA.","authors":["Bongmin Kim"],"pdf_url":"","comment":"25 pages, 2 figures"},{"id":"http://arxiv.org/abs/2601.03479v1","updated":"2026-01-07T00:15:44Z","published":"2026-01-07T00:15:44Z","title":"Efficient Sequential Recommendation for Long Term User Interest Via Personalization","summary":"Recent years have witnessed success of sequential modeling, generative recommender, and large language model for recommendation. Though the scaling law has been validated for sequential models, it showed inefficiency in computational capacity when considering real-world applications like recommendation, due to the non-linear(quadratic) increasing nature of the transformer model. To improve the efficiency of the sequential model, we introduced a novel approach to sequential recommendation that leverages personalization techniques to enhance efficiency and performance. Our method compresses long user interaction histories into learnable tokens, which are then combined with recent interactions to generate recommendations. This approach significantly reduces computational costs while maintaining high recommendation accuracy. Our method could be applied to existing transformer based recommendation models, e.g., HSTU and HLLM. Extensive experiments on multiple sequential models demonstrate its versatility and effectiveness. Source code is available at \\href{https://github.com/facebookresearch/PerSRec}{https://github.com/facebookresearch/PerSRec}.","authors":["Qiang Zhang","Hanchao Yu","Ivan Ji","Chen Yuan","Yi Zhang","Chihuang Liu","Xiaolong Wang","Christopher E. Lambert","Ren Chen","Chen Kovacs","Xinzhu Bei","Renqin Cai","Rui Li","Lizhu Zhang","Xiangjun Fan","Qunshu Zhang","Benyu Zhang"],"pdf_url":"","comment":"ICDM 2025"},{"id":"http://arxiv.org/abs/2601.03474v1","updated":"2026-01-07T00:02:30Z","published":"2026-01-07T00:02:30Z","title":"SegNSP: Revisiting Next Sentence Prediction for Linear Text Segmentation","summary":"Linear text segmentation is a long-standing problem in natural language processing (NLP), focused on dividing continuous text into coherent and semantically meaningful units. Despite its importance, the task remains challenging due to the complexity of defining topic boundaries, the variability in discourse structure, and the need to balance local coherence with global context. These difficulties hinder downstream applications such as summarization, information retrieval, and question answering. In this work, we introduce SegNSP, framing linear text segmentation as a next sentence prediction (NSP) task. Although NSP has largely been abandoned in modern pre-training, its explicit modeling of sentence-to-sentence continuity makes it a natural fit for detecting topic boundaries. We propose a label-agnostic NSP approach, which predicts whether the next sentence continues the current topic without requiring explicit topic labels, and enhance it with a segmentation-aware loss combined with harder negative sampling to better capture discourse continuity. Unlike recent proposals that leverage NSP alongside auxiliary topic classification, our approach avoids task-specific supervision. We evaluate our model against established baselines on two datasets, CitiLink-Minutes, for which we establish the first segmentation benchmark, and WikiSection. On CitiLink-Minutes, SegNSP achieves a B-$F_1$ of 0.79, closely aligning with human-annotated topic transitions, while on WikiSection it attains a B-F$_1$ of 0.65, outperforming the strongest reproducible baseline, TopSeg, by 0.17 absolute points. These results demonstrate competitive and robust performance, highlighting the effectiveness of modeling sentence-to-sentence continuity for improving segmentation quality and supporting downstream NLP applications.","authors":["José Isidro","Filipe Cunha","Purificação Silvano","Alípio Jorge","Nuno Guimarães","Sérgio Nunes","Ricardo Campos"],"pdf_url":"","comment":null}],"Discrete Mathematics":[{"id":"http://arxiv.org/abs/2601.04169v1","updated":"2026-01-07T18:36:25Z","published":"2026-01-07T18:36:25Z","title":"A Polynomial Kernel for Face Cover on Non-Embedded Planar Graphs","summary":"Given a planar graph, a subset of its vertices called terminals, and $k \\in \\mathbb{N}$, the Face Cover Number problem asks whether the terminals lie on the boundaries of at most $k$ faces of some embedding of the input graph. When a plane graph is given in the input, the problem is known to have a polynomial kernel~\\cite{GarneroST17}. In this paper, we present the first polynomial kernel for Face Cover Number when the input is a planar graph (without a fixed embedding). Our approach overcomes the challenge of not having a predefined set of face boundaries by building a kernel bottom-up on an SPR-tree while preserving the essential properties of the face cover along the way.","authors":["Thekla Hamm","Sukanya Pandey","Krisztina Szilágyi"],"pdf_url":"","comment":"Accepted to STACS 2026"},{"id":"http://arxiv.org/abs/2601.04040v1","updated":"2026-01-07T15:56:54Z","published":"2026-01-07T15:56:54Z","title":"Trade-off between spread and width for tree decompositions","summary":"We study the trade-off between (average) spread and width in tree decompositions, answering several questions from Wood [arXiv:2509.01140]. The spread of a vertex $v$ in a tree decomposition is the number of bags that contain $v$. Wood asked for which $c>0$, there exists $c'$ such that each graph $G$ has a tree decomposition of width $c\\cdot tw(G)$ in which each vertex $v$ has spread at most $c'(d(v)+1)$. We show that $c\\geq 2$ is necessary and that $c>3$ is sufficient. Moreover, we answer a second question fully by showing that near-optimal average spread can be achieved simultaneously with width $O(tw(G))$.","authors":["Hans L. Bodlaender","Carla Groenland"],"pdf_url":"","comment":"14 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.17878v3","updated":"2026-01-07T14:47:09Z","published":"2025-07-23T19:11:32Z","title":"Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa","summary":"We introduce a new notion of sparsification, called \\emph{strong sparsification}, in which constraints are not removed but variables can be merged. As our main result, we present a strong sparsification algorithm for 1-in-3-SAT. The correctness of the algorithm relies on establishing a sub-quadratic bound on the size of certain sets of vectors in $\\mathbb{F}_2^d$. This result, obtained using the recent \\emph{Polynomial Freiman-Ruzsa Theorem} (Gowers, Green, Manners and Tao, Ann. Math. 2025), could be of independent interest. As an application, we improve the state-of-the-art algorithm for approximating linearly-ordered colourings of 3-uniform hypergraphs (Håstad, Martinsson, Nakajima and{Ž}ivn{ý}, APPROX 2024).","authors":["Benjamin Bedert","Tamio-Vesa Nakajima","Karolina Okrasa","Stanislav Živný"],"pdf_url":"","comment":"Full version of a FOCS'25 paper; v2 has more results; v3 proves Conjecture 33 from v2, giving a tight bound on strong sparsifiability of 1-in-k-SAT (in possibly exponential time)"},{"id":"http://arxiv.org/abs/2601.03488v1","updated":"2026-01-07T00:57:16Z","published":"2026-01-07T00:57:16Z","title":"Exact Dominion of the Prism Graph: Enumeration by Congruence Class via Cyclic Words","summary":"Let G_n = C_n square P_2 denote the prism (circular ladder) graph on 2n vertices. By encoding column configurations as cyclic words, domination is reduced to local Boolean constraints on adjacent factors. This framework yields explicit formulas for the dominion zeta(G_n), stratified by n mod 4, with the exceptional cases n in {3, 6} confirmed computationally. Together with the known domination numbers gamma(G_n), these results expose distinct arithmetic regimes governing optimal domination, ranging from rigid forcing to substantial enumerative flexibility, and motivate quantitative parameters for assessing structural robustness in parametric graph families.","authors":["Julian Allagan"],"pdf_url":"","comment":"17 pages, 3 tables"},{"id":"http://arxiv.org/abs/2601.03485v1","updated":"2026-01-07T00:47:54Z","published":"2026-01-07T00:47:54Z","title":"Four Dominion Growth Regimes in Trees: Forcing, Fibonacci Enumeration, Periodicity, and Stability","summary":"We study the dominion zeta(G), defined as the number of minimum dominating sets of a graph G, and analyze how local forcing and boundary effects control the flexibility of optimal domination in trees. For path-based pendant constructions, we identify a sharp forcing threshold: attaching a single pendant vertex to each path vertex yields complete independence with zeta = 2^gamma, whereas attaching two or more pendant vertices forces a unique minimum dominating set. Between these extremes, sparse pendant patterns produce intermediate behavior: removing endpoint pendants gives zeta = 2^(gamma - 2), while alternating pendant attachments induce Fibonacci growth zeta asymptotic to phi^gamma, where phi is the golden ratio. For complete binary trees T_h, we establish a rigid period-3 law zeta(T_h) in {1, 3} despite exponential growth in |V(T_h)|. We further prove a sharp stability bound under leaf deletions, zeta(T_h - X) <= 2^{m_1(X)} zeta(T_h), where m_1(X) counts parents that lose exactly one child; in particular, deleting a single leaf preserves the domination number and exactly doubles the dominion.","authors":["Julian Allagan","Erin Gray","Jennifer Sawyer","Gabrielle Morgan"],"pdf_url":"","comment":"12 pages, 1 figure, 2 tables"}],"Symbolic Computation":[{"id":"http://arxiv.org/abs/2412.14043v2","updated":"2026-01-07T12:32:53Z","published":"2024-12-18T16:58:48Z","title":"Algebraic and Algorithmic Methods for Computing Polynomial Loop Invariants","summary":"Loop invariants are properties of a program loop that hold both before and after each iteration of the loop. They are often used to verify programs and ensure that algorithms consistently produce correct results during execution. Consequently, generating invariants becomes a crucial task for loops. We specifically focus on polynomial loops, where both the loop conditions and the assignments within the loop are expressed as polynomials. Although computing polynomial invariants for general loops is undecidable, efficient algorithms have been developed for certain classes of loops. For instance, when all assignments within a while loop involve linear polynomials, the loop becomes solvable. In this work, we study the more general case, where the polynomials can have arbitrary degrees.\n  Using tools from algebraic geometry, we present two algorithms designed to generate all polynomial invariants within a given vector subspace, for a branching loop with nondeterministic conditional statements. These algorithms combine linear algebraic subroutines with computations on polynomial ideals. They differ depending on whether the initial values of the loop variables are specified or treated as parameters. Additionally, we present a much more efficient algorithm for generating polynomial invariants of a specific form, applicable to all initial values. This algorithm avoids expensive ideal computations.","authors":["Erdenebayar Bayarmagnai","Fatemeh Mohammadi","Rémi Prébet"],"pdf_url":"","comment":"44 pages, 1 figure"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2505.01538v3","updated":"2026-01-07T18:49:03Z","published":"2025-05-02T18:59:31Z","title":"HONEYBEE: Efficient Role-based Access Control for Vector Databases via Dynamic Partitioning[Technical Report]","summary":"Enterprise deployments of vector databases require access control policies to protect sensitive data. These systems often implement access control through hybrid vector queries that combine nearest-neighbor search with relational predicates based on user permissions. However, existing approaches face a fundamental trade-off: dedicated per-user indexes minimize query latency but incur high memory redundancy, while shared indexes with post-search filtering reduce memory overhead at the cost of increased latency. This paper introduces HONEYBEE, a dynamic partitioning framework that leverages the structure of Role-Based Access Control (RBAC) policies to create a smooth trade-off between these extremes. RBAC policies organize users into roles and assign permissions at the role level, creating a natural ``thin waist`` in the permission structure that is ideal for partitioning decisions. Specifically, HONEYBEE produces overlapping partitions where vectors can be strategically replicated across different partitions to reduce query latency while controlling memory overhead. To guide these decisions, HONEYBEE develops analytical models of vector search performance and recall, and formulates partitioning as a constrained optimization problem that balances memory usage, query efficiency, and recall. Evaluations on RBAC workloads demonstrate that HONEYBEE achieves up to 13.5X lower query latency than row-level security with only a 1.24X increase in memory usage, while achieving comparable query performance to dedicated, per-role indexes with 90.4% reduction in additional memory consumption, offering a practical middle ground for secure and efficient vector search.","authors":["Hongbin Zhong","Matthew Lentz","Nina Narodytska","Adriana Szekeres","Kexin Rong"],"pdf_url":"","comment":"Accepted by SIGMOD 2026"},{"id":"http://arxiv.org/abs/2601.04181v1","updated":"2026-01-07T18:48:31Z","published":"2026-01-07T18:48:31Z","title":"Lightweight Test-Time Adaptation for EMG-Based Gesture Recognition","summary":"Reliable long-term decoding of surface electromyography (EMG) is hindered by signal drift caused by electrode shifts, muscle fatigue, and posture changes. While state-of-the-art models achieve high intra-session accuracy, their performance often degrades sharply. Existing solutions typically demand large datasets or high-compute pipelines that are impractical for energy-efficient wearables. We propose a lightweight framework for Test-Time Adaptation (TTA) using a Temporal Convolutional Network (TCN) backbone. We introduce three deployment-ready strategies: (i) causal adaptive batch normalization for real-time statistical alignment; (ii) a Gaussian Mixture Model (GMM) alignment with experience replay to prevent forgetting; and (iii) meta-learning for rapid, few-shot calibration. Evaluated on the NinaPro DB6 multi-session dataset, our framework significantly bridges the inter-session accuracy gap with minimal overhead. Our results show that experience-replay updates yield superior stability under limited data, while meta-learning achieves competitive performance in one- and two-shot regimes using only a fraction of the data required by current benchmarks. This work establishes a path toward robust, \"plug-and-play\" myoelectric control for long-term prosthetic use.","authors":["Nia Touko","Matthew O A Ellis","Cristiano Capone","Alessio Burrello","Elisa Donati","Luca Manneschi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04176v1","updated":"2026-01-07T18:43:11Z","published":"2026-01-07T18:43:11Z","title":"Robust Physics Discovery from Highly Corrupted Data: A PINN Framework Applied to the Nonlinear Schrödinger Equation","summary":"We demonstrate a deep learning framework capable of recovering physical parameters from the Nonlinear Schrodinger Equation (NLSE) under severe noise conditions. By integrating Physics-Informed Neural Networks (PINNs) with automatic differentiation, we achieve reconstruction of the nonlinear coefficient beta with less than 0.2 percent relative error using only 500 sparse, randomly sampled data points corrupted by 20 percent additive Gaussian noise, a regime where traditional finite difference methods typically fail due to noise amplification in numerical derivatives. We validate the method's generalization capabilities across different physical regimes (beta between 0.5 and 2.0) and varying data availability (between 100 and 1000 training points), demonstrating consistent sub-1 percent accuracy. Statistical analysis over multiple independent runs confirms robustness (standard deviation less than 0.15 percent for beta equals 1.0). The complete pipeline executes in approximately 80 minutes on modest cloud GPU resources (NVIDIA Tesla T4), making the approach accessible for widespread adoption. Our results indicate that physics-based regularization acts as an effective filter against high measurement uncertainty, positioning PINNs as a viable alternative to traditional optimization methods for inverse problems in spatiotemporal dynamics where experimental data is scarce and noisy. All code is made publicly available to facilitate reproducibility.","authors":["Pietro de Oliveira Esteves"],"pdf_url":"","comment":"9 pages, 4 figures, 2 tables. Code available at https://github.com/p-esteves/pinn-nlse-2026"},{"id":"http://arxiv.org/abs/2601.04171v1","updated":"2026-01-07T18:38:23Z","published":"2026-01-07T18:38:23Z","title":"Agentic Rubrics as Contextual Verifiers for SWE Agents","summary":"Verification is critical for improving agents: it provides the reward signal for Reinforcement Learning and enables inference-time gains through Test-Time Scaling (TTS). Despite its importance, verification in software engineering (SWE) agent settings often relies on code execution, which can be difficult to scale due to environment setup overhead. Scalable alternatives such as patch classifiers and heuristic methods exist, but they are less grounded in codebase context and harder to interpret. To this end, we explore Agentic Rubrics: an expert agent interacts with the repository to create a context-grounded rubric checklist, and candidate patches are then scored against it without requiring test execution. On SWE-Bench Verified under parallel TTS evaluation, Agentic Rubrics achieve a score of 54.2% on Qwen3-Coder-30B-A3B and 40.6% on Qwen3-32B, with at least a +3.5 percentage-point gain over the strongest baseline in our comparison set. We further analyze rubric behavior, showing that rubric scores are consistent with ground-truth tests while also flagging issues that tests do not capture. Our ablations show that agentic context gathering is essential for producing codebase-specific, unambiguous criteria. Together, these results suggest that Agentic Rubrics provide an efficient, scalable, and granular verification signal for SWE agents.","authors":["Mohit Raghavendra","Anisha Gunjal","Bing Liu","Yunzhong He"],"pdf_url":"","comment":"31 pages, 11 Figures"},{"id":"http://arxiv.org/abs/2412.04416v2","updated":"2026-01-07T18:33:05Z","published":"2024-12-05T18:42:29Z","title":"FedDUAL: A Dual-Strategy with Adaptive Loss and Dynamic Aggregation for Mitigating Data Heterogeneity in Federated Learning","summary":"Federated Learning (FL) marks a transformative approach to distributed model training by combining locally optimized models from various clients into a unified global model. While FL preserves data privacy by eliminating centralized storage, it encounters significant challenges such as performance degradation, slower convergence, and reduced robustness of the global model due to the heterogeneity in client data distributions. Among the various forms of data heterogeneity, label skew emerges as a particularly formidable and prevalent issue, especially in domains such as image classification. To address these challenges, we begin with comprehensive experiments to pinpoint the underlying issues in the FL training process. Based on our findings, we then introduce an innovative dual-strategy approach designed to effectively resolve these issues. First, we introduce an adaptive loss function for client-side training, meticulously crafted to preserve previously acquired knowledge while maintaining an optimal equilibrium between local optimization and global model coherence. Secondly, we develop a dynamic aggregation strategy for aggregating client models at the server. This approach adapts to each client's unique learning patterns, effectively addressing the challenges of diverse data across the network. Our comprehensive evaluation, conducted across three diverse real-world datasets, coupled with theoretical convergence guarantees, demonstrates the superior efficacy of our method compared to several established state-of-the-art approaches.","authors":["Pranab Sahoo","Ashutosh Tripathi","Sriparna Saha","Samrat Mondal"],"pdf_url":"","comment":"Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2601.04164v1","updated":"2026-01-07T18:25:02Z","published":"2026-01-07T18:25:02Z","title":"Clinical Data Goes MEDS? Let's OWL make sense of it","summary":"The application of machine learning on healthcare data is often hindered by the lack of standardized and semantically explicit representation, leading to limited interoperability and reproducibility across datasets and experiments. The Medical Event Data Standard (MEDS) addresses these issues by introducing a minimal, event-centric data model designed for reproducible machine-learning workflows from health data. However, MEDS is defined as a data-format specification and does not natively provide integration with the Semantic Web ecosystem. In this article, we introduce MEDS-OWL, a lightweight OWL ontology that provides formal concepts and relations to enable representing MEDS datasets as RDF graphs. Additionally, we implemented meds2rdf, a Python conversion library that transforms MEDS events into RDF graphs, ensuring conformance with the ontology. We demonstrate the approach on a synthetic clinical dataset that describes patient care pathways for ruptured intracranial aneurysms and validate the resulting graph using SHACL constraints. The first release of MEDS-OWL comprises 13 classes, 10 object properties, 20 data properties, and 24 OWL axioms. Combined with meds2rdf, it enables data transformation into FAIR-aligned datasets, provenance-aware publishing, and interoperability of event-based clinical data. By bridging MEDS with the Semantic Web, this work contributes a reusable semantic layer for event-based clinical data and establishes a robust foundation for subsequent graph-based analytics.","authors":["Alberto Marfoglia","Jong Ho Jhee","Adrien Coulet"],"pdf_url":"","comment":"12 pages, 5 tables, 4 figures"},{"id":"http://arxiv.org/abs/2601.04163v1","updated":"2026-01-07T18:24:12Z","published":"2026-01-07T18:24:12Z","title":"Scanner-Induced Domain Shifts Undermine the Robustness of Pathology Foundation Models","summary":"Pathology foundation models (PFMs) have become central to computational pathology, aiming to offer general encoders for feature extraction from whole-slide images (WSIs). Despite strong benchmark performance, PFM robustness to real-world technical domain shifts, such as variability from whole-slide scanner devices, remains poorly understood. We systematically evaluated the robustness of 14 PFMs to scanner-induced variability, including state-of-the-art models, earlier self-supervised models, and a baseline trained on natural images. Using a multiscanner dataset of 384 breast cancer WSIs scanned on five devices, we isolated scanner effects independently from biological and laboratory confounders. Robustness is assessed via complementary unsupervised embedding analyses and a set of clinicopathological supervised prediction tasks. Our results demonstrate that current PFMs are not invariant to scanner-induced domain shifts. Most models encode pronounced scanner-specific variability in their embedding spaces. While AUC often remains stable, this masks a critical failure mode: scanner variability systematically alters the embedding space and impacts calibration of downstream model predictions, resulting in scanner-dependent bias that can impact reliability in clinical use cases. We further show that robustness is not a simple function of training data scale, model size, or model recency. None of the models provided reliable robustness against scanner-induced variability. While the models trained on the most diverse data, here represented by vision-language models, appear to have an advantage with respect to robustness, they underperformed on downstream supervised tasks. We conclude that development and evaluation of PFMs requires moving beyond accuracy-centric benchmarks toward explicit evaluation and optimisation of embedding stability and calibration under realistic acquisition variability.","authors":["Erik Thiringer","Fredrik K. Gustafsson","Kajsa Ledesma Eriksson","Mattias Rantalainen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.00919v2","updated":"2026-01-07T18:20:49Z","published":"2026-01-01T08:39:15Z","title":"Attention Needs to Focus: A Unified Perspective on Attention Allocation","summary":"The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.","authors":["Zichuan Fu","Wentao Song","Guojing Li","Yejing Wang","Xian Wu","Yimin Deng","Hanyu Yan","Yefeng Zheng","Xiangyu Zhao"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2601.04157v1","updated":"2026-01-07T18:12:05Z","published":"2026-01-07T18:12:05Z","title":"FLEx: Language Modeling with Few-shot Language Explanations","summary":"Language models have become effective at a wide range of tasks, from math problem solving to open-domain question answering. However, they still make mistakes, and these mistakes are often repeated across related queries. Natural language explanations can help correct these errors, but collecting them at scale may be infeasible, particularly in domains where expert annotators are required. To address this issue, we introduce FLEx ($\\textbf{F}$ew-shot $\\textbf{L}$anguage $\\textbf{Ex}$planations), a method for improving model behavior using a small number of explanatory examples. FLEx selects representative model errors using embedding-based clustering, verifies that the associated explanations correct those errors, and summarizes them into a prompt prefix that is prepended at inference-time. This summary guides the model to avoid similar errors on new inputs, without modifying model weights. We evaluate FLEx on CounterBench, GSM8K, and ReasonIF. We find that FLEx consistently outperforms chain-of-thought (CoT) prompting across all three datasets and reduces up to 83\\% of CoT's remaining errors.","authors":["Adar Avsian","Christopher Richardson","Anirudh Sundar","Larry Heck"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.00995v2","updated":"2026-01-07T18:11:26Z","published":"2024-10-01T18:35:44Z","title":"CktGen: Automated Analog Circuit Design with Generative Artificial Intelligence","summary":"The automatic synthesis of analog circuits presents significant challenges. Most existing approaches formulate the problem as a single-objective optimization task, overlooking that design specifications for a given circuit type vary widely across applications. To address this, we introduce specification-conditioned analog circuit generation, a task that directly generates analog circuits based on target specifications. The motivation is to leverage existing well-designed circuits to improve automation in analog circuit design. Specifically, we propose CktGen, a simple yet effective variational autoencoder that maps discretized specifications and circuits into a joint latent space and reconstructs the circuit from that latent vector. Notably, as a single specification may correspond to multiple valid circuits, naively fusing specification information into the generative model does not capture these one-to-many relationships. To address this, we decouple the encoding of circuits and specifications and align their mapped latent space. Then, we employ contrastive training with a filter mask to maximize differences between encoded circuits and specifications. Furthermore, classifier guidance along with latent feature alignment promotes the clustering of circuits sharing the same specification, avoiding model collapse into trivial one-to-one mappings. By canonicalizing the latent space with respect to specifications, we can search for an optimal circuit that meets valid target specifications. We conduct comprehensive experiments on the open circuit benchmark and introduce metrics to evaluate cross-model consistency. Experimental results demonstrate that CktGen achieves substantial improvements over state-of-the-art methods.","authors":["Yuxuan Hou","Hehe Fan","Jianrong Zhang","Yue Zhang","Hua Chen","Min Zhou","Faxin Yu","Roger Zimmermann","Yi Yang"],"pdf_url":"","comment":"Paper accepted by Engineering"},{"id":"http://arxiv.org/abs/2412.11850v3","updated":"2026-01-07T18:04:52Z","published":"2024-12-16T15:11:02Z","title":"Causal Invariance Learning via Efficient Nonconvex Optimization","summary":"Identifying the causal relationship among variables from observational data is an important yet challenging task. This work focuses on identifying the direct causes of an outcome and estimating their magnitude, i.e., learning the causal outcome model. Data from multiple environments provide valuable opportunities to uncover causality by exploiting the invariance principle that the causal outcome model holds across heterogeneous environments. Based on the invariance principle, we propose the Negative Weighted Distributionally Robust Optimization (NegDRO) framework to learn an invariant prediction model. NegDRO minimizes the worst-case combination of risks across multiple environments and enforces invariance by allowing potential negative weights. Under the additive interventions regime, we establish three major contributions: (i) On the statistical side, we provide sufficient and nearly necessary identification conditions under which the invariant prediction model coincides with the causal outcome model; (ii) On the optimization side, despite the nonconvexity of NegDRO, we establish its benign optimization landscape, where all stationary points lie close to the true causal outcome model; (iii) On the computational side, we develop a gradient-based algorithm that provably converges to the causal outcome model, with non-asymptotic convergence rates in both sample size and gradient-descent iterations. In particular, our method avoids exhaustive combinatorial searches over exponentially many subsets of covariates found in the literature, ensuring scalability even when the dimension of the covariates is large. To our knowledge, this is the first causal invariance learning method that finds the approximate global optimality for a nonconvex optimization problem efficiently.","authors":["Zhenyu Wang","Yifan Hu","Peter Bühlmann","Zijian Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04149v1","updated":"2026-01-07T18:02:11Z","published":"2026-01-07T18:02:11Z","title":"A Theoretical and Empirical Taxonomy of Imbalance in Binary Classification","summary":"Class imbalance significantly degrades classification performance, yet its effects are rarely analyzed from a unified theoretical perspective. We propose a principled framework based on three fundamental scales: the imbalance coefficient $η$, the sample--dimension ratio $κ$, and the intrinsic separability $Δ$. Starting from the Gaussian Bayes classifier, we derive closed-form Bayes errors and show how imbalance shifts the discriminant boundary, yielding a deterioration slope that predicts four regimes: Normal, Mild, Extreme, and Catastrophic. Using a balanced high-dimensional genomic dataset, we vary only $η$ while keeping $κ$ and $Δ$ fixed. Across parametric and non-parametric models, empirical degradation closely follows theoretical predictions: minority Recall collapses once $\\log(η)$ exceeds $Δ\\sqrtκ$, Precision increases asymmetrically, and F1-score and PR-AUC decline in line with the predicted regimes. These results show that the triplet $(η,κ,Δ)$ provides a model-agnostic, geometrically grounded explanation of imbalance-induced deterioration.","authors":["Rose Yvette Bandolo Essomba","Ernest Fokoué"],"pdf_url":"","comment":"24 pages, 10 figures"},{"id":"http://arxiv.org/abs/2506.06303v4","updated":"2026-01-07T17:58:17Z","published":"2025-05-21T16:15:01Z","title":"Reward Is Enough: LLMs Are In-Context Reinforcement Learners","summary":"Reinforcement learning (RL) is a framework for solving sequential decision-making problems. In this work, we demonstrate that, surprisingly, RL emerges during the inference time of large language models (LLMs), a phenomenon we term in-context RL (ICRL). To reveal this capability, we introduce a simple multi-round prompting framework, we call ICRL prompting, for inference-time self-improvement. The goal of ICRL prompting is to guide LLMs to perform reinforcement learning during inference for self-improvement on a given task. After each response, the model receives numerical scalar feedback, denoted as a reward. In the next round, we prompt the LLM again together with a context that concatenates all prior responses and their associated rewards. We consistently observe that response quality improves as the context grows. In other words, the LLM can optimize scalar reward signals during inference, exhibiting behavior analogous to reinforcement learning. We evaluate ICRL prompting on Game of 24, creative writing, ScienceWorld, and Olympiad-level math competitions (AIME and HMMT), demonstrating significant improvements over baselines such as Self-Refine and Reflexion. Notably, even when the reward signals are generated by the same LLM, ICRL prompting still improves performance, highlighting a promising new paradigm for test-time scaling.","authors":["Kefan Song","Amir Moeini","Peng Wang","Lei Gong","Rohan Chandra","Shangtong Zhang","Yanjun Qi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04131v1","updated":"2026-01-07T17:45:20Z","published":"2026-01-07T17:45:20Z","title":"ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models","summary":"Large Language Models (LLMs) encode vast amounts of parametric knowledge during pre-training. As world knowledge evolves, effective deployment increasingly depends on their ability to faithfully follow externally retrieved context. When such evidence conflicts with the model's internal knowledge, LLMs often default to memorized facts, producing unfaithful outputs. In this work, we introduce ContextFocus, a lightweight activation steering approach that improves context faithfulness in such knowledge-conflict settings while preserving fluency and efficiency. Unlike prior approaches, our solution requires no model finetuning and incurs minimal inference-time overhead, making it highly efficient. We evaluate ContextFocus on the ConFiQA benchmark, comparing it against strong baselines including ContextDPO, COIECD, and prompting-based methods. Furthermore, we show that our method is complementary to prompting strategies and remains effective on larger models. Extensive experiments show that ContextFocus significantly improves contextual-faithfulness. Our results highlight the effectiveness, robustness, and efficiency of ContextFocus in improving contextual-faithfulness of LLM outputs.","authors":["Nikhil Anand","Shwetha Somasundaram","Anirudh Phukan","Apoorv Saxena","Koyel Mukherjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2404.17789v6","updated":"2026-01-07T17:37:44Z","published":"2024-04-27T06:06:41Z","title":"BiLO: Bilevel Local Operator Learning for PDE Inverse Problems","summary":"We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. We provide a theoretical analysis that justifies our approach. Through extensive experiments over multiple PDE systems, we demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to the soft PDE constraints in many existing methods.","authors":["Ray Zirui Zhang","Christopher E. Miles","Xiaohui Xie","John S. Lowengrub"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04121v1","updated":"2026-01-07T17:32:24Z","published":"2026-01-07T17:32:24Z","title":"MORPHFED: Federated Learning for Cross-institutional Blood Morphology Analysis","summary":"Automated blood morphology analysis can support hematological diagnostics in low- and middle-income countries (LMICs) but remains sensitive to dataset shifts from staining variability, imaging differences, and rare morphologies. Building centralized datasets to capture this diversity is often infeasible due to privacy regulations and data-sharing restrictions. We introduce a federated learning framework for white blood cell morphology analysis that enables collaborative training across institutions without exchanging training data. Using blood films from multiple clinical sites, our federated models learn robust, domain-invariant representations while preserving complete data privacy. Evaluations across convolutional and transformer-based architectures show that federated training achieves strong cross-site performance and improved generalization to unseen institutions compared to centralized training. These findings highlight federated learning as a practical and privacy-preserving approach for developing equitable, scalable, and generalizable medical imaging AI in resource-limited healthcare environments.","authors":["Gabriel Ansah","Eden Ruffell","Delmiro Fernandez-Reyes","Petru Manescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04120v1","updated":"2026-01-07T17:30:42Z","published":"2026-01-07T17:30:42Z","title":"A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems","summary":"Optimal control of obstacle problems arises in a wide range of applications and is computationally challenging due to its nonsmoothness, nonlinearity, and bilevel structure. Classical numerical approaches rely on mesh-based discretization and typically require solving a sequence of costly subproblems. In this work, we propose a single-loop bilevel deep learning method, which is mesh-free, scalable to high-dimensional and complex domains, and avoids repeated solution of discretized subproblems. The method employs constraint-embedding neural networks to approximate the state and control and preserves the bilevel structure. To train the neural networks efficiently, we propose a Single-Loop Stochastic First-Order Bilevel Algorithm (S2-FOBA), which eliminates nested optimization and does not rely on restrictive lower-level uniqueness assumptions. We analyze the convergence behavior of S2-FOBA under mild assumptions. Numerical experiments on benchmark examples, including distributed and obstacle control problems with regular and irregular obstacles on complex domains, demonstrate that the proposed method achieves satisfactory accuracy while reducing computational cost compared to classical numerical methods.","authors":["Yongcun Song","Shangzhi Zeng","Jin Zhang","Lvgang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.07947v3","updated":"2026-01-07T17:17:56Z","published":"2025-07-10T17:32:26Z","title":"Low Resource Reconstruction Attacks Through Benign Prompts","summary":"Recent advances in generative models, such as diffusion models, have raised concerns related to privacy, copyright infringement, and data stewardship. To better understand and control these risks, prior work has introduced techniques and attacks that reconstruct images, or parts of images, from training data. While these results demonstrate that training data can be recovered, existing methods often rely on high computational resources, partial access to the training set, or carefully engineered prompts.\n  In this work, we present a new attack that requires low resources, assumes little to no access to the training data, and identifies seemingly benign prompts that can lead to potentially risky image reconstruction. We further show that such reconstructions may occur unintentionally, even for users without specialized knowledge. For example, we observe that for one existing model, the prompt ``blue Unisex T-Shirt'' generates the face of a real individual. Moreover, by combining the identified vulnerabilities with real-world prompt data, we discover prompts that reproduce memorized visual elements.\n  Our approach builds on insights from prior work and leverages domain knowledge to expose a fundamental vulnerability arising from the use of scraped e-commerce data, where templated layouts and images are closely tied to pattern-like textual prompts.\n  The code for our attack is publicly available at https://github.com/TheSolY/lr-tmi.","authors":["Sol Yarkoni","Mahmood Sharif","Roi Livni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04110v1","updated":"2026-01-07T17:16:39Z","published":"2026-01-07T17:16:39Z","title":"Causal Data Augmentation for Robust Fine-Tuning of Tabular Foundation Models","summary":"Fine-tuning tabular foundation models (TFMs) under data scarcity is challenging, as early stopping on even scarcer validation data often fails to capture true generalization performance. We propose CausalMixFT, a method that enhances fine-tuning robustness and downstream performance by generating structurally consistent synthetic samples using Structural Causal Models (SCMs) fitted on the target dataset. This approach augments limited real data with causally informed synthetic examples, preserving feature dependencies while expanding training diversity. Evaluated across 33 classification datasets from TabArena and over 2300 fine-tuning runs, our CausalMixFT method consistently improves median normalized ROC-AUC from 0.10 (standard fine-tuning) to 0.12, outperforming purely statistical generators such as CTGAN (-0.01), TabEBM (-0.04), and TableAugment (-0.09). Moreover, it narrows the median validation-test performance correlation gap from 0.67 to 0.30, enabling more reliable validation-based early stopping, a key step toward improving fine-tuning stability under data scarcity. These results demonstrate that incorporating causal structure into data augmentation provides an effective and principled route to fine-tuning tabular foundation models in low-data regimes.","authors":["Magnus Bühler","Lennart Purucker","Frank Hutter"],"pdf_url":"","comment":"Accepted for oral presentation at the EurIPS 2025 Workshop on AI for Tabular Data (Copenhagen)"},{"id":"http://arxiv.org/abs/2601.04104v1","updated":"2026-01-07T17:09:04Z","published":"2026-01-07T17:09:04Z","title":"Equivariant Neural Networks for Force-Field Models of Lattice Systems","summary":"Machine-learning (ML) force fields enable large-scale simulations with near-first-principles accuracy at substantially reduced computational cost. Recent work has extended ML force-field approaches to adiabatic dynamical simulations of condensed-matter lattice models with coupled electronic and structural or magnetic degrees of freedom. However, most existing formulations rely on hand-crafted, symmetry-aware descriptors, whose construction is often system-specific and can hinder generality and transferability across different lattice Hamiltonians. Here we introduce a symmetry-preserving framework based on equivariant neural networks (ENNs) that provides a general, data-driven mapping from local configurations of dynamical variables to the associated on-site forces in a lattice Hamiltonian. In contrast to ENN architectures developed for molecular systems -- where continuous Euclidean symmetries dominate -- our approach aims to embed the discrete point-group and internal symmetries intrinsic to lattice models directly into the neural-network representation of the force field. As a proof of principle, we construct an ENN-based force-field model for the adiabatic dynamics of the Holstein Hamiltonian on a square lattice, a canonical system for electron-lattice physics. The resulting ML-enabled large-scale dynamical simulations faithfully capture mesoscale evolution of the symmetry-breaking phase, illustrating the utility of lattice-equivariant architectures for linking microscopic electronic processes to emergent dynamical behavior in condensed-matter lattice systems.","authors":["Yunhao Fan","Gia-Wei Chern"],"pdf_url":"","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2310.10359v3","updated":"2026-01-07T16:54:12Z","published":"2023-10-16T12:51:26Z","title":"An Anytime Algorithm for Good Arm Identification","summary":"In good arm identification (GAI), the goal is to identify one arm whose average performance exceeds a given threshold, referred to as a good arm, if it exists. Few works have studied GAI in the fixed-budget setting when the sampling budget is fixed beforehand, or in the anytime setting, when a recommendation can be asked at any time. We propose APGAI, an anytime and parameter-free sampling rule for GAI in stochastic bandits. APGAI can be straightforwardly used in fixed-confidence and fixed-budget settings. First, we derive upper bounds on its probability of error at any time. They show that adaptive strategies can be more efficient in detecting the absence of good arms than uniform sampling in several diverse instances. Second, when APGAI is combined with a stopping rule, we prove upper bounds on the expected sampling complexity, holding at any confidence level. Finally, we show the good empirical performance of APGAI on synthetic and real-world data. Our work offers an extensive overview of the GAI problem in all settings.","authors":["Marc Jourdan","Andrée Delahaye-Duriez","Clémence Réda"],"pdf_url":"","comment":"90 pages, 23 figures, 14 tables. To be published in the Journal of Machine Learning Research"},{"id":"http://arxiv.org/abs/2601.04083v1","updated":"2026-01-07T16:51:33Z","published":"2026-01-07T16:51:33Z","title":"Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning","summary":"The widespread deployment of 5G networks, together with the coexistence of 4G/LTE networks, provides mobile devices a diverse set of candidate cells to connect to. However, associating mobile devices to cells to maximize overall network performance, a.k.a. cell (re)selection, remains a key challenge for mobile operators. Today, cell (re)selection parameters are typically configured manually based on operator experience and rarely adapted to dynamic network conditions. In this work, we ask: Can an agent automatically learn and adapt cell (re)selection parameters to consistently improve network performance? We present a reinforcement learning (RL)-based framework called CellPilot that adaptively tunes cell (re)selection parameters by learning spatiotemporal patterns of mobile network dynamics. Our study with real-world data demonstrates that even a lightweight RL agent can outperform conventional heuristic reconfigurations by up to 167%, while generalizing effectively across different network scenarios. These results indicate that data-driven approaches can significantly improve cell (re)selection configurations and enhance mobile network performance.","authors":["Marvin Illian","Ramin Khalili","Antonio A. de A. Rocha","Lin Wang"],"pdf_url":"","comment":"11 pages, 12 figures"},{"id":"http://arxiv.org/abs/2507.05216v3","updated":"2026-01-07T16:39:36Z","published":"2025-07-07T17:29:13Z","title":"Bridging Prediction and Intervention Problems in Social Systems","summary":"Many automated decision systems (ADS) are designed to solve prediction problems -- where the goal is to learn patterns from a sample of the population and apply them to individuals from the same population. In reality, these prediction systems operationalize holistic policy interventions in deployment. Once deployed, ADS can shape impacted population outcomes through an effective policy change in how decision-makers operate, while also being defined by past and present interactions between stakeholders and the limitations of existing organizational, as well as societal, infrastructure and context. In this work, we consider the ways in which we must shift from a prediction-focused paradigm to an intervention-oriented paradigm when considering the impact of ADS within social systems. We argue this requires a new default problem setup for ADS beyond prediction, to instead consider predictions as decision support, final decisions, and outcomes. We highlight how this perspective unifies modern statistical frameworks and other tools to study the design, implementation, and evaluation of ADS systems, and point to the research directions necessary to operationalize this paradigm shift. Using these tools, we characterize the limitations of focusing on isolated prediction tasks, and lay the foundation for a more intervention-oriented approach to developing and deploying ADS.","authors":["Lydia T. Liu","Inioluwa Deborah Raji","Angela Zhou","Luke Guerdan","Jessica Hullman","Daniel Malinsky","Bryan Wilder","Simone Zhang","Hammaad Adam","Amanda Coston","Ben Laufer","Ezinne Nwankwo","Michael Zanger-Tishler","Eli Ben-Michael","Solon Barocas","Avi Feller","Marissa Gerchick","Talia Gillis","Shion Guha","Daniel Ho","Lily Hu","Kosuke Imai","Sayash Kapoor","Joshua Loftus","Razieh Nabi","Arvind Narayanan","Ben Recht","Juan Carlos Perdomo","Matthew Salganik","Mark Sendak","Alexander Tolbert","Berk Ustun","Suresh Venkatasubramanian","Angelina Wang","Ashia Wilson"],"pdf_url":"","comment":"updated version - local edits, cuts"},{"id":"http://arxiv.org/abs/2601.02081v2","updated":"2026-01-07T16:32:29Z","published":"2026-01-05T13:10:09Z","title":"A Differentiable Adversarial Framework for Task-Aware Data Subsampling","summary":"The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduce the antagonistic soft selection subsampling (ASSS) framework as a novel paradigm that reconstructs data reduction into a differentiable end-to-end learning problem. ASSS uses the adversarial game between selector network and task network, and selector network learning assigns continuous importance weights to samples. This direct optimization implemented by Gumbel-Softmax relaxation allows the selector to identify and retain samples with the maximum amount of information for a specific task target under the guidance of the loss function that balances the fidelity and sparsity of the prediction. Theoretical analysis links this framework with the information bottleneck principle. Comprehensive experiments on four large-scale real world datasets show that ASSS has always been better than heuristic subsampling baselines such as clustering and nearest neighbor thinning in maintaining model performance. It is worth noting that ASSS can not only match, but also sometimes exceed the training performance of the entire dataset, showcasing the effect of intelligent denoising. This work establishes task aware data subsampling as a learnable component, providing a principled solution for effective large-scale data learning.","authors":["Jiacheng Lyu","Bihua Bao"],"pdf_url":"","comment":"14 pages"},{"id":"http://arxiv.org/abs/2601.04065v1","updated":"2026-01-07T16:29:52Z","published":"2026-01-07T16:29:52Z","title":"Unsupervised Modular Adaptive Region Growing and RegionMix Classification for Wind Turbine Segmentation","summary":"Reliable operation of wind turbines requires frequent inspections, as even minor surface damages can degrade aerodynamic performance, reduce energy output, and accelerate blade wear. Central to automating these inspections is the accurate segmentation of turbine blades from visual data. This task is traditionally addressed through dense, pixel-wise deep learning models. However, such methods demand extensive annotated datasets, posing scalability challenges. In this work, we introduce an annotation-efficient segmentation approach that reframes the pixel-level task into a binary region classification problem. Image regions are generated using a fully unsupervised, interpretable Modular Adaptive Region Growing technique, guided by image-specific Adaptive Thresholding and enhanced by a Region Merging process that consolidates fragmented areas into coherent segments. To improve generalization and classification robustness, we introduce RegionMix, an augmentation strategy that synthesizes new training samples by combining distinct regions. Our framework demonstrates state-of-the-art segmentation accuracy and strong cross-site generalization by consistently segmenting turbine blades across distinct windfarms.","authors":["Raül Pérez-Gonzalo","Riccardo Magro","Andreas Espersen","Antonio Agudo"],"pdf_url":"","comment":"Accepted to WACV 2026"},{"id":"http://arxiv.org/abs/2601.04058v1","updated":"2026-01-07T16:21:47Z","published":"2026-01-07T16:21:47Z","title":"Minimum distance classification for nonlinear dynamical systems","summary":"We address the problem of classifying trajectory data generated by some nonlinear dynamics, where each class corresponds to a distinct dynamical system. We propose Dynafit, a kernel-based method for learning a distance metric between training trajectories and the underlying dynamics. New observations are assigned to the class with the most similar dynamics according to the learned metric. The learning algorithm approximates the Koopman operator which globally linearizes the dynamics in a (potentially infinite) feature space associated with a kernel function. The distance metric is computed in feature space independently of its dimensionality by using the kernel trick common in machine learning. We also show that the kernel function can be tailored to incorporate partial knowledge of the dynamics when available. Dynafit is applicable to various classification tasks involving nonlinear dynamical systems and sensors. We illustrate its effectiveness on three examples: chaos detection with the logistic map, recognition of handwritten dynamics and of visual dynamic textures.","authors":["Dominique Martinez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04057v1","updated":"2026-01-07T16:21:27Z","published":"2026-01-07T16:21:27Z","title":"Using Legacy Polysomnography Data to Train a Radar System to Quantify Sleep in Older Adults and People living with Dementia","summary":"Objective: Ultra-wideband radar technology offers a promising solution for unobtrusive and cost-effective in-home sleep monitoring. However, the limited availability of radar sleep data poses challenges in building robust models that generalize across diverse cohorts and environments. This study proposes a novel deep transfer learning framework to enhance sleep stage classification using radar data. Methods: An end-to-end neural network was developed to classify sleep stages based on nocturnal respiratory and motion signals. The network was trained using a combination of large-scale polysomnography (PSG) datasets and radar data. A domain adaptation approach employing adversarial learning was utilized to bridge the knowledge gap between PSG and radar signals. Validation was performed on a radar dataset of 47 older adults (mean age: 71.2), including 18 participants with prodromal or mild Alzheimer disease. Results: The proposed network structure achieves an accuracy of 79.5% with a Kappa value of 0.65 when classifying wakefulness, rapid eye movement, light sleep and deep sleep. Experimental results confirm that our deep transfer learning approach significantly enhances automatic sleep staging performance in the target domain. Conclusion: This method effectively addresses challenges associated with data variability and limited sample size, substantially improving the reliability of automatic sleep staging models, especially in contexts where radar data is limited. Significance: The findings underscore the viability of UWB radar as a nonintrusive, forward-looking sleep assessment tool that could significantly benefit care for older people and people with neurodegenerative disorders.","authors":["M. Yin","K. G. Ravindran","C. Hadjipanayi","A. Bannon","A. Rapeaux","C. Della Monica","T. S. Lande","Derk-Jan Dijk","T. G. Constandinou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04054v1","updated":"2026-01-07T16:19:11Z","published":"2026-01-07T16:19:11Z","title":"LinkD: AutoRegressive Diffusion Model for Mechanical Linkage Synthesis","summary":"Designing mechanical linkages to achieve target end-effector trajectories presents a fundamental challenge due to the intricate coupling between continuous node placements, discrete topological configurations, and nonlinear kinematic constraints. The highly nonlinear motion-to-configuration relationship means small perturbations in joint positions drastically alter trajectories, while the combinatorially expanding design space renders conventional optimization and heuristic methods computationally intractable. We introduce an autoregressive diffusion framework that exploits the dyadic nature of linkage assembly by representing mechanisms as sequentially constructed graphs, where nodes correspond to joints and edges to rigid links. Our approach combines a causal transformer with a Denoising Diffusion Probabilistic Model (DDPM), both conditioned on target trajectories encoded via a transformer encoder. The causal transformer autoregressively predicts discrete topology node-by-node, while the DDPM refines each node's spatial coordinates and edge connectivity to previously generated nodes. This sequential generation enables adaptive trial-and-error synthesis where problematic nodes exhibiting kinematic locking or collisions can be selectively regenerated, allowing autonomous correction of degenerate configurations during design. Our graph-based, data-driven methodology surpasses traditional optimization approaches, enabling scalable inverse design that generalizes to mechanisms with arbitrary node counts. We demonstrate successful synthesis of linkage systems containing up to 20 nodes with extensibility to N-node architectures. This work advances autoregressive graph generation methodologies and computational kinematic synthesis, establishing new paradigms for scalable inverse design of complex mechanical systems.","authors":["Yayati Jadhav","Amir Barati Farimani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04051v1","updated":"2026-01-07T16:12:14Z","published":"2026-01-07T16:12:14Z","title":"Symbolic Regression for Shared Expressions: Introducing Partial Parameter Sharing","summary":"Symbolic Regression aims to find symbolic expressions that describe datasets. Due to better interpretability, it is a machine learning paradigm particularly powerful for scientific discovery. In recent years, several works have expanded the concept to allow the description of similar phenomena using a single expression with varying sets of parameters, thereby introducing categorical variables. Some previous works allow only \"non-shared\" (category-value-specific) parameters, and others also incorporate \"shared\" (category-value-agnostic) parameters. We expand upon those efforts by considering multiple categorical variables, and introducing intermediate levels of parameter sharing. With two categorical variables, an intermediate level of parameter sharing emerges, i.e., parameters which are shared across either category but change across the other. The new approach potentially decreases the number of parameters, while revealing additional information about the problem. Using a synthetic, fitting-only example, we test the limits of this setup in terms of data requirement reduction and transfer learning. As a real-world symbolic regression example, we demonstrate the benefits of the proposed approach on an astrophysics dataset used in a previous study, which considered only one categorical variable. We achieve a similar fit quality but require significantly fewer individual parameters, and extract additional information about the problem.","authors":["Viktor Martinek","Roland Herzog"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03959v4","updated":"2026-01-07T16:04:11Z","published":"2025-10-04T21:59:45Z","title":"Operational early warning of thunderstorm-driven power outages from open data: a two-stage machine learning approach","summary":"Thunderstorm-driven power outages are difficult to predict because most storms do not cause damage, convective processes occur rapidly and chaotically, and the available public data are noisy and incomplete. Severe convective storms now account for a large and rising share of U.S. weather losses, yet thunderstorm-induced outages remain understudied. We develop a 48-hour early-warning model for summer thunderstorm-related outages in Michigan using only open-source outage (EAGLE-I) and weather (METAR) data. Relative to prior work, we (i) rely solely on public data, (ii) preserve convective extremes from a sparse station network via parameter-specific kriging and causal spatiotemporal features, and (iii) use a multi-level LSTM-based architecture evaluated on event-centric peak metrics. The pipeline builds rolling and k-NN inverse-distance aggregates to capture moisture advection, wind shifts, and pressure drops. A two-stage design uses a logistic gate followed by a long short-term memory (LSTM) regressor to filter routine periods and limit noise exposure. Evaluation focuses on state-level peaks of at least 50,000 customers without power, using hits, misses, false alarms, and peak-conditional MASE (cMASE) within 48-hour windows, with uncertainty quantified by block bootstrapping. On the test sample, the Two-Stage model detects more peaks with only one additional false alarm and reduces cMASE near peaks, providing event-focused early warnings without the utility-specific data.","authors":["Iryna Stanishevska","Seth Guikema"],"pdf_url":"","comment":"24 pages (main), 80 pages incl. appendices; figures & tables as in manuscript. Code (main figure, synthetic data): https://github.com/IrynaStanishevska/peak-outage-forecasting- License: CC BY 4.0 (preprint)"},{"id":"http://arxiv.org/abs/2511.01650v2","updated":"2026-01-07T15:44:03Z","published":"2025-11-03T15:05:44Z","title":"EngTrace: A Symbolic Benchmark for Verifiable Process Supervision of Engineering Reasoning","summary":"Large Language Models (LLMs) are increasingly entering specialized, safety-critical engineering workflows governed by strict quantitative standards and immutable physical laws, making rigorous evaluation of their reasoning capabilities imperative. However, existing benchmarks such as MMLU, MATH, and HumanEval assess isolated cognitive skills, failing to capture the physically grounded reasoning central to engineering, where scientific principles, quantitative modeling, and practical constraints must converge. To enable verifiable process supervision in engineering, we introduce EngTrace, a symbolic benchmark comprising 90 templates across three major engineering branches, nine core domains and 20 distinct areas. Through domain-aware parameterization, we generate 1,350 unique, contamination-resistant test cases to stress-test generalization. Moving beyond outcome matching, we introduce a verifiable two-stage evaluation framework that uses a tiered protocol to validate intermediate reasoning traces alongside final answers through automated procedural checks and a heterogeneous AI Tribunal. Our evaluation of 24 leading LLMs reveals a distinct trade-off between numeric precision and trace fidelity, identifying a complexity cliff where abstract mathematical pre-training fails to translate into the integrative reasoning required for advanced engineering tasks.","authors":["Ayesha Gull","Muhammad Usman Safder","Rania Elbadry","Fan Zhang","Veselin Stoyanov","Preslav Nakov","Zhuohan Xie"],"pdf_url":"","comment":"22 pages, includes figures and tables; introduces the EngTrace benchmark"},{"id":"http://arxiv.org/abs/2509.22056v2","updated":"2026-01-07T15:40:45Z","published":"2025-09-26T08:37:54Z","title":"Towards Understanding Feature Learning in Parameter Transfer","summary":"Parameter transfer is a central paradigm in transfer learning, enabling knowledge reuse across tasks and domains by sharing model parameters between upstream and downstream models. However, when only a subset of parameters from the upstream model is transferred to the downstream model, there remains a lack of theoretical understanding of the conditions under which such partial parameter reuse is beneficial and of the factors that govern its effectiveness. To address this gap, we analyze a setting in which both the upstream and downstream models are ReLU convolutional neural networks (CNNs). Within this theoretical framework, we characterize how the inherited parameters act as carriers of universal knowledge and identify key factors that amplify their beneficial impact on the target task. Furthermore, our analysis provides insight into why, in certain cases, transferring parameters can lead to lower test accuracy on the target task than training a new model from scratch. To our best knowledge, our theory is the first to provide a dynamic analysis for parameter transfer and also the first to prove the existence of negative transfer theoretically. Numerical experiments and real-world data experiments are conducted to empirically validate our theoretical findings.","authors":["Hua Yuan","Xuran Meng","Qiufeng Wang","Shiyu Xia","Ning Xu","Xu Yang","Jing Wang","Xin Geng","Yong Rui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16680v2","updated":"2026-01-07T15:37:21Z","published":"2025-04-23T12:58:15Z","title":"Uncertainty-Aware Robotic World Model Makes Offline Model-Based Reinforcement Learning Work on Real Robots","summary":"Reinforcement Learning (RL) has achieved impressive results in robotics, yet high-performing pipelines remain highly task-specific, with little reuse of prior data. Offline Model-based RL (MBRL) offers greater data efficiency by training policies entirely from existing datasets, but suffers from compounding errors and distribution shift in long-horizon rollouts. Although existing methods have shown success in controlled simulation benchmarks, robustly applying them to the noisy, biased, and partially observed datasets typical of real-world robotics remains challenging. We present a principled pipeline for making offline MBRL effective on physical robots. Our RWM-U extends autoregressive world models with epistemic uncertainty estimation, enabling temporally consistent multi-step rollouts with uncertainty effectively propagated over long horizons. We combine RWM-U with MOPO-PPO, which adapts uncertainty-penalized policy optimization to the stable, on-policy PPO framework for real-world control. We evaluate our approach on diverse manipulation and locomotion tasks in simulation and on real quadruped and humanoid, training policies entirely from offline datasets. The resulting policies consistently outperform model-free and uncertainty-unaware model-based baselines, and fusing real-world data in model learning further yields robust policies that surpass online model-free baselines trained solely in simulation.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04019v1","updated":"2026-01-07T15:34:15Z","published":"2026-01-07T15:34:15Z","title":"Modeling Behavioral Patterns in News Recommendations Using Fuzzy Neural Networks","summary":"News recommender systems are increasingly driven by black-box models, offering little transparency for editorial decision-making. In this work, we introduce a transparent recommender system that uses fuzzy neural networks to learn human-readable rules from behavioral data for predicting article clicks. By extracting the rules at configurable thresholds, we can control rule complexity and thus, the level of interpretability. We evaluate our approach on two publicly available news datasets (i.e., MIND and EB-NeRD) and show that we can accurately predict click behavior compared to several established baselines, while learning human-readable rules. Furthermore, we show that the learned rules reveal news consumption patterns, enabling editors to align content curation goals with target audience behavior.","authors":["Kevin Innerebner","Stephan Bartl","Markus Reiter-Haas","Elisabeth Lex"],"pdf_url":"","comment":"Accepted for the IR for Good track at ECIR'26"},{"id":"http://arxiv.org/abs/2512.01868v3","updated":"2026-01-07T15:27:09Z","published":"2025-12-01T16:51:00Z","title":"The Mean-Field Dynamics of Transformers","summary":"We develop a mathematical framework that interprets Transformer attention as an interacting particle system and studies its continuum (mean-field) limits. By idealizing attention on the sphere, we connect Transformer dynamics to Wasserstein gradient flows, synchronization models (Kuramoto), and mean-shift clustering. Central to our results is a global clustering phenomenon whereby tokens cluster asymptotically after long metastable states where they are arranged into multiple clusters. We further analyze a tractable equiangular reduction to obtain exact clustering rates, show how commonly used normalization schemes alter contraction speeds, and identify a phase transition for long-context attention. The results highlight both the mechanisms that drive representation collapse and the regimes that preserve expressive, multi-cluster structure in deep attention architectures.","authors":["Philippe Rigollet"],"pdf_url":"","comment":"to appear as Proceedings of the ICM2026, Philadelphia, USA"},{"id":"http://arxiv.org/abs/2411.05894v2","updated":"2026-01-07T15:11:39Z","published":"2024-11-08T14:23:02Z","title":"SSSD: Simply-Scalable Speculative Decoding","summary":"Speculative Decoding has emerged as a popular technique for accelerating inference in Large Language Models. However, most existing approaches yield only modest improvements in production serving systems. Methods that achieve substantial speedups typically rely on an additional trained draft model or auxiliary model components, increasing deployment and maintenance complexity. This added complexity reduces flexibility, particularly when serving workloads shift to tasks, domains, or languages that are not well represented in the draft model's training data.\n  We introduce Simply-Scalable Speculative Decoding (SSSD), a training-free method that combines lightweight n-gram matching with hardware-aware speculation. Relative to standard autoregressive decoding, SSSD reduces latency by up to 2.9x. It achieves performance on par with leading training-based approaches across a broad range of benchmarks, while requiring substantially lower adoption effort--no data preparation, training or tuning are needed--and exhibiting superior robustness under language and domain shift, as well as in long-context settings.","authors":["Michele Marzollo","Jiawei Zhuang","Niklas Roemer","Niklas Zwingenberger","Lorenz K. Müller","Lukas Cavigelli"],"pdf_url":"","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2407.04522v4","updated":"2026-01-07T15:09:22Z","published":"2024-07-05T14:07:15Z","title":"Graph Reinforcement Learning for Power Grids: A Comprehensive Survey","summary":"The increasing share of renewable energy and distributed electricity generation requires the development of deep learning approaches to address the lack of flexibility inherent in traditional power grid methods. In this context, Graph Neural Networks are a promising solution due to their ability to learn from graph-structured data. Combined with Reinforcement Learning, they can be used as control approaches to determine remedial actions. This review analyses how Graph Reinforcement Learning can improve representation learning and decision-making in power grid applications, particularly transmission and distribution grids. We analyze the reviewed approaches in terms of the graph structure, the Graph Neural Network architecture, and the Reinforcement Learning approach. Although Graph Reinforcement Learning has demonstrated adaptability to unpredictable events and noisy data, its current stage is primarily proof-of-concept, and it is not yet deployable to real-world applications. We highlight the open challenges and limitations for real-world applications.","authors":["Mohamed Hassouna","Clara Holzhüter","Pawel Lytaev","Josephine Thomas","Bernhard Sick","Christoph Scholz"],"pdf_url":"","comment":"Accepted in Energy & AI, in-press"},{"id":"http://arxiv.org/abs/2601.03988v1","updated":"2026-01-07T15:00:22Z","published":"2026-01-07T15:00:22Z","title":"Using Small Language Models to Reverse-Engineer Machine Learning Pipelines Structures","summary":"Background: Extracting the stages that structure Machine Learning (ML) pipelines from source code is key for gaining a deeper understanding of data science practices. However, the diversity caused by the constant evolution of the ML ecosystem (e.g., algorithms, libraries, datasets) makes this task challenging. Existing approaches either depend on non-scalable, manual labeling, or on ML classifiers that do not properly support the diversity of the domain. These limitations highlight the need for more flexible and reliable solutions.\n  Objective: We evaluate whether Small Language Models (SLMs) can leverage their code understanding and classification abilities to address these limitations, and subsequently how they can advance our understanding of data science practices.\n  Method: We conduct a confirmatory study based on two reference works selected for their relevance regarding current state-of-the-art's limitations. First, we compare several SLMs using Cochran's Q test. The best-performing model is then evaluated against the reference studies using two distinct McNemar's tests. We further analyze how variations in taxonomy definitions affect performance through an additional Cochran's Q test. Finally, a goodness-of-fit analysis is conducted using Pearson's chi-squared tests to compare our insights on data science practices with those from prior studies.","authors":["Nicolas Lacroix","Mireille Blay-Fornarino","Sébastien Mosser","Frederic Precioso"],"pdf_url":"","comment":"SANER 2026 Registered Report"},{"id":"http://arxiv.org/abs/2502.15016v3","updated":"2026-01-07T14:46:52Z","published":"2025-02-20T20:12:04Z","title":"TimeDistill: Efficient Long-Term Time Series Forecasting with MLP via Cross-Architecture Distillation","summary":"Transformer-based and CNN-based methods demonstrate strong performance in long-term time series forecasting. However, their high computational and storage requirements can hinder large-scale deployment. To address this limitation, we propose integrating lightweight MLP with advanced architectures using knowledge distillation (KD). Our preliminary study reveals different models can capture complementary patterns, particularly multi-scale and multi-period patterns in the temporal and frequency domains. Based on this observation, we introduce TimeDistill, a cross-architecture KD framework that transfers these patterns from teacher models (e.g., Transformers, CNNs) to MLP. Additionally, we provide a theoretical analysis, demonstrating that our KD approach can be interpreted as a specialized form of mixup data augmentation. TimeDistill improves MLP performance by up to 18.6%, surpassing teacher models on eight datasets. It also achieves up to 7X faster inference and requires 130X fewer parameters. Furthermore, we conduct extensive evaluations to highlight the versatility and effectiveness of TimeDistill.","authors":["Juntong Ni","Zewen Liu","Shiyu Wang","Ming Jin","Wei Jin"],"pdf_url":"","comment":"Accepted at KDD 2026, we release our code publicly at https://github.com/LingFengGold/TimeDistill"},{"id":"http://arxiv.org/abs/2601.03977v1","updated":"2026-01-07T14:44:04Z","published":"2026-01-07T14:44:04Z","title":"Stage-specific cancer survival prediction enriched by explainable machine learning","summary":"Despite the fact that cancer survivability rates vary greatly between stages, traditional survival prediction models have frequently been trained and assessed using examples from all combined phases of the disease. This method may result in an overestimation of performance and ignore the stage-specific variations. Using the SEER dataset, we created and verified explainable machine learning (ML) models to predict stage-specific cancer survivability in colorectal, stomach, and liver cancers. ML-based cancer survival analysis has been a long-standing topic in the literature; however, studies involving the explainability and transparency of ML survivability models are limited. Our use of explainability techniques, including SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME), enabled us to illustrate significant feature-cancer stage interactions that would have remained hidden in traditional black-box models. We identified how certain demographic and clinical variables influenced survival differently across cancer stages and types. These insights provide not only transparency but also clinical relevance, supporting personalized treatment planning. By focusing on stage-specific models, this study provides new insights into the most important factors at each stage of cancer, offering transparency and potential clinical relevance to support personalized treatment planning.","authors":["Parisa Poorhasani","Bogdan Iancu"],"pdf_url":"","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.08925v4","updated":"2026-01-07T14:29:09Z","published":"2024-10-11T15:50:31Z","title":"An Overview of Prototype Formulations for Interpretable Deep Learning","summary":"Prototypical part networks offer interpretable alternatives to black-box deep learning models by learning visual prototypes for classification. This work provides a comprehensive analysis of prototype formulations, comparing point-based and probabilistic approaches in both Euclidean and hyperspherical latent spaces.\n  We introduce HyperPG, a probabilistic prototype representation using Gaussian distributions on hyperspheres. Experiments on CUB-200-2011, Stanford Cars, and Oxford Flowers datasets show that hyperspherical prototypes outperform standard Euclidean formulations. Critically, hyperspherical prototypes maintain competitive performance under simplified training schemes, while Euclidean prototypes require extensive hyperparameter tuning.","authors":["Maximilian Xiling Li","Korbinian Franz Rudolf","Paul Mattes","Nils Blank","Rudolf Lioutikov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03946v1","updated":"2026-01-07T14:02:25Z","published":"2026-01-07T14:02:25Z","title":"Provably Finding a Hidden Dense Submatrix among Many Planted Dense Submatrices via Convex Programming","summary":"We consider the densest submatrix problem, which seeks the submatrix of fixed size of a given binary matrix that contains the most nonzero entries. This problem is a natural generalization of fundamental problems in combinatorial optimization, e.g., the densest subgraph, maximum clique, and maximum edge biclique problems, and has wide application the study of complex networks. Much recent research has focused on the development of sufficient conditions for exact solution of the densest submatrix problem via convex relaxation. The vast majority of these sufficient conditions establish identification of the densest submatrix within a graph containing exactly one large dense submatrix hidden by noise. The assumptions of these underlying models are not observed in real-world networks, where the data may correspond to a matrix containing many dense submatrices of varying sizes.\n  We extend and generalize these results to the more realistic setting where the input matrix may contain \\emph{many} large dense subgraphs. Specifically, we establish sufficient conditions under which we can expect to solve the densest submatrix problem in polynomial time for random input matrices sampled from a generalization of the stochastic block model. Moreover, we also provide sufficient conditions for perfect recovery under a deterministic adversarial. Numerical experiments involving randomly generated problem instances and real-world collaboration and communication networks are used empirically to verify the theoretical phase-transitions to perfect recovery given by these sufficient conditions.","authors":["Valentine Olanubi","Phineas Agar","Brendan Ames"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03938v1","updated":"2026-01-07T13:55:14Z","published":"2026-01-07T13:55:14Z","title":"FOREVER: Forgetting Curve-Inspired Memory Replay for Language Model Continual Learning","summary":"Continual learning (CL) for large language models (LLMs) aims to enable sequential knowledge acquisition without catastrophic forgetting. Memory replay methods are widely used for their practicality and effectiveness, but most rely on fixed, step-based heuristics that often misalign with the model's actual learning progress, since identical training steps can result in varying degrees of parameter change. Motivated by recent findings that LLM forgetting mirrors the Ebbinghaus human forgetting curve, we propose FOREVER (FORgEtting curVe-inspired mEmory Replay), a novel CL framework that aligns replay schedules with a model-centric notion of time. FOREVER defines model time using the magnitude of optimizer updates, allowing forgetting curve-inspired replay intervals to align with the model's internal evolution rather than raw training steps. Building on this approach, FOREVER incorporates a forgetting curve-based replay scheduler to determine when to replay and an intensity-aware regularization mechanism to adaptively control how to replay. Extensive experiments on three CL benchmarks and models ranging from 0.6B to 13B parameters demonstrate that FOREVER consistently mitigates catastrophic forgetting.","authors":["Yujie Feng","Hao Wang","Jian Li","Xu Chu","Zhaolu Kang","Yiran Liu","Yasha Wang","Philip S. Yu","Xiao-Ming Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03930v1","updated":"2026-01-07T13:49:57Z","published":"2026-01-07T13:49:57Z","title":"Bayes-PD: Exploring a Sequence to Binding Bayesian Neural Network model trained on Phage Display data","summary":"Phage display is a powerful laboratory technique used to study the interactions between proteins and other molecules, whether other proteins, peptides, DNA or RNA. The under-utilisation of this data in conjunction with deep learning models for protein design may be attributed to; high experimental noise levels; the complex nature of data pre-processing; and difficulty interpreting these experimental results. In this work, we propose a novel approach utilising a Bayesian Neural Network within a training loop, in order to simulate the phage display experiment and its associated noise. Our goal is to investigate how understanding the experimental noise and model uncertainty can enable the reliable application of such models to reliably interpret phage display experiments. We validate our approach using actual binding affinity measurements instead of relying solely on proxy values derived from 'held-out' phage display rounds.","authors":["Ilann Amiaud-Plachy","Michael Blank","Oliver Bent","Sebastien Boyer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03919v1","updated":"2026-01-07T13:40:30Z","published":"2026-01-07T13:40:30Z","title":"A Gap Between Decision Trees and Neural Networks","summary":"We study when geometric simplicity of decision boundaries, used here as a notion of interpretability, can conflict with accurate approximation of axis-aligned decision trees by shallow neural networks. Decision trees induce rule-based, axis-aligned decision regions (finite unions of boxes), whereas shallow ReLU networks are typically trained as score models whose predictions are obtained by thresholding. We analyze the infinite-width, bounded-norm, single-hidden-layer ReLU class through the Radon total variation ($\\mathrm{R}\\mathrm{TV}$) seminorm, which controls the geometric complexity of level sets.\n  We first show that the hard tree indicator $1_A$ has infinite $\\mathrm{R}\\mathrm{TV}$. Moreover, two natural split-wise continuous surrogates--piecewise-linear ramp smoothing and sigmoidal (logistic) smoothing--also have infinite $\\mathrm{R}\\mathrm{TV}$ in dimensions $d>1$, while Gaussian convolution yields finite $\\mathrm{R}\\mathrm{TV}$ but with an explicit exponential dependence on $d$.\n  We then separate two goals that are often conflated: classification after thresholding (recovering the decision set) versus score learning (learning a calibrated score close to $1_A$). For classification, we construct a smooth barrier score $S_A$ with finite $\\mathrm{R}\\mathrm{TV}$ whose fixed threshold $τ=1$ exactly recovers the box. Under a mild tube-mass condition near $\\partial A$, we prove an $L_1(P)$ calibration bound that decays polynomially in a sharpness parameter, along with an explicit $\\mathrm{R}\\mathrm{TV}$ upper bound in terms of face measures. Experiments on synthetic unions of rectangles illustrate the resulting accuracy--complexity tradeoff and how threshold selection shifts where training lands along it.","authors":["Akash Kumar"],"pdf_url":"","comment":"45 pages"},{"id":"http://arxiv.org/abs/2412.05103v4","updated":"2026-01-07T13:25:31Z","published":"2024-12-06T15:01:19Z","title":"Integrating Semantic Communication and Human Decision-Making into an End-to-End Sensing-Decision Framework","summary":"As early as 1949, Weaver defined communication in a very broad sense to include all procedures by which one mind or technical system can influence another, thus establishing the idea of semantic communication. With the recent success of machine learning in expert assistance systems where sensed information is wirelessly provided to a human to assist task execution, the need to design effective and efficient communications has become increasingly apparent. In particular, semantic communication aims to convey the meaning behind the sensed information relevant for Human Decision-Making (HDM). Regarding the interplay between semantic communication and HDM, many questions remain, such as how to model the entire end-to-end sensing-decision-making process, how to design semantic communication for the HDM and which information should be provided for HDM. To address these questions, we propose to integrate semantic communication and HDM into one probabilistic end-to-end sensing-decision framework that bridges communications and psychology. In our interdisciplinary framework, we model the human through a HDM process, allowing us to explore how feature extraction from semantic communication can best support HDM both in theory and in simulations. In this sense, our study reveals the fundamental design trade-off between maximizing the relevant semantic information and matching the cognitive capabilities of the HDM model. Our initial analysis shows how semantic communication can balance the level of detail with human cognitive capabilities while demanding less bandwidth, power, and latency.","authors":["Edgar Beck","Hsuan-Yu Lin","Patrick Rückert","Yongping Bao","Bettina von Helversen","Sebastian Fehrler","Kirsten Tracht","Armin Dekorsy"],"pdf_url":"","comment":"Accepted in the Open Journal of the Communications Society. Code available in https://github.com/ant-uni-bremen/SINFONY"},{"id":"http://arxiv.org/abs/2601.03910v1","updated":"2026-01-07T13:21:44Z","published":"2026-01-07T13:21:44Z","title":"An Algebraic Representation Theorem for Linear GENEOs in Geometric Machine Learning","summary":"Geometric and Topological Deep Learning are rapidly growing research areas that enhance machine learning through the use of geometric and topological structures. Within this framework, Group Equivariant Non-Expansive Operators (GENEOs) have emerged as a powerful class of operators for encoding symmetries and designing efficient, interpretable neural architectures. Originally introduced in Topological Data Analysis, GENEOs have since found applications in Deep Learning as tools for constructing equivariant models with reduced parameter complexity. GENEOs provide a unifying framework bridging Geometric and Topological Deep Learning and include the operator computing persistence diagrams as a special case. Their theoretical foundations rely on group actions, equivariance, and compactness properties of operator spaces, grounding them in algebra and geometry while enabling both mathematical rigor and practical relevance. While a previous representation theorem characterized linear GENEOs acting on data of the same type, many real-world applications require operators between heterogeneous data spaces. In this work, we address this limitation by introducing a new representation theorem for linear GENEOs acting between different perception pairs, based on generalized T-permutant measures. Under mild assumptions on the data domains and group actions, our result provides a complete characterization of such operators. We also prove the compactness and convexity of the space of linear GENEOs. We further demonstrate the practical impact of this theory by applying the proposed framework to improve the performance of autoencoders, highlighting the relevance of GENEOs in modern machine learning applications.","authors":["Francesco Conti","Patrizio Frosini","Nicola Quercioli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03905v1","updated":"2026-01-07T13:15:23Z","published":"2026-01-07T13:15:23Z","title":"Current Agents Fail to Leverage World Model as Tool for Foresight","summary":"Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.","authors":["Cheng Qian","Emre Can Acikgoz","Bingxuan Li","Xiusi Chen","Yuji Zhang","Bingxiang He","Qinyu Luo","Dilek Hakkani-Tür","Gokhan Tur","Yunzhu Li","Heng Ji","Heng Ji"],"pdf_url":"","comment":"36 Pages, 13 Figures, 17 Tables"},{"id":"http://arxiv.org/abs/2601.03895v1","updated":"2026-01-07T13:04:52Z","published":"2026-01-07T13:04:52Z","title":"Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training","summary":"Group Relative Policy Optimization (GRPO) has emerged as a popular algorithm for reinforcement learning with large language models (LLMs). However, upon analyzing its clipping mechanism, we argue that it is suboptimal in certain scenarios. With appropriate modifications, GRPO can be significantly enhanced to improve both flexibility and generalization. To this end, we propose Adaptive-Boundary-Clipping GRPO (ABC-GRPO), an asymmetric and adaptive refinement of the original GRPO framework. We demonstrate that ABC-GRPO achieves superior performance over standard GRPO on mathematical reasoning tasks using the Qwen3 LLMs. Moreover, ABC-GRPO maintains substantially higher entropy throughout training, thereby preserving the model's exploration capacity and mitigating premature convergence. The implementation code is available online to ease reproducibility https://github.com/chi2liu/ABC-GRPO.","authors":["Chi Liu","Xin Chen"],"pdf_url":"","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.03892v1","updated":"2026-01-07T13:01:33Z","published":"2026-01-07T13:01:33Z","title":"Lightweight and perceptually-guided voice conversion for electro-laryngeal speech","summary":"Electro-laryngeal (EL) speech is characterized by constant pitch, limited prosody, and mechanical noise, reducing naturalness and intelligibility. We propose a lightweight adaptation of the state-of-the-art StreamVC framework to this setting by removing pitch and energy modules and combining self-supervised pretraining with supervised fine-tuning on parallel EL and healthy (HE) speech data, guided by perceptual and intelligibility losses. Objective and subjective evaluations across different loss configurations confirm their influence: the best model variant, based on WavLM features and human-feedback predictions (+WavLM+HF), drastically reduces character error rate (CER) of EL inputs, raises naturalness mean opinion score (nMOS) from 1.1 to 3.3, and consistently narrows the gap to HE ground-truth speech in all evaluated metrics. These findings demonstrate the feasibility of adapting lightweight voice conversion architectures to EL voice rehabilitation while also identifying prosody generation and intelligibility improvements as the main remaining bottlenecks.","authors":["Benedikt Mayrhofer","Franz Pernkopf","Philipp Aichinger","Martin Hagmüller"],"pdf_url":"","comment":"5 pages, 5 figures. Audio samples available at https://spsc-tugraz.github.io/lw-elvc-icassp26/ Preprint submitted to ICASSP"},{"id":"http://arxiv.org/abs/2601.03889v1","updated":"2026-01-07T12:59:37Z","published":"2026-01-07T12:59:37Z","title":"Spectral Manifold Regularization for Stable and Modular Routing in Deep MoE Architectures","summary":"Mixture of Experts (MoE) architectures enable efficient scaling of neural networks but suffer from expert collapse, where routing converges to a few dominant experts. This reduces model capacity and causes catastrophic interference during adaptation. We propose the Spectrally-Regularized Mixture of Experts (SR-MoE), which imposes geometric constraints on the routing manifold to enforce structural modularity. Our method uses dual regularization: spectral norm constraints bound routing function Lipschitz continuity, while stable rank penalties preserve high-dimensional feature diversity in expert selection. We evaluate SR-MoE across architectural scales and dataset complexities using modular one-shot adaptation tasks. Results show that traditional linear gating fails with increasing depth (accuracy drops up to 4.72% due to expert entanglement), while SR-MoE maintains structural integrity (mean interference -0.32%). Our spectral constraints facilitate positive knowledge transfer, enabling localized expert updates without global performance decay. SR-MoE provides a general solution for building high-capacity, modular networks capable of stable lifelong learning.","authors":["Ibrahim Delibasoglu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03882v1","updated":"2026-01-07T12:48:16Z","published":"2026-01-07T12:48:16Z","title":"Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences","summary":"One-shot federated learning (OSFL) reduces the communication cost and privacy risks of iterative federated learning by constructing a global model with a single round of communication. However, most existing methods struggle to achieve robust performance on real-world domains such as medical imaging, or are inefficient when handling non-IID (Independent and Identically Distributed) data. To address these limitations, we introduce FALCON, a framework that enhances the effectiveness of OSFL over non-IID image data. The core idea of FALCON is to leverage the feature-aware hierarchical token sequences generation and knowledge distillation into OSFL. First, each client leverages a pretrained visual encoder with hierarchical scale encoding to compress images into hierarchical token sequences, which capture multi-scale semantics. Second, a multi-scale autoregressive transformer generator is used to model the distribution of these token sequences and generate the synthetic sequences. Third, clients upload the synthetic sequences along with the local classifier trained on the real token sequences to the server. Finally, the server incorporates knowledge distillation into global training to reduce reliance on precise distribution modeling. Experiments on medical and natural image datasets validate the effectiveness of FALCON in diverse non-IID scenarios, outperforming the best OSFL baselines by 9.58% in average accuracy.","authors":["Shudong Liu","Hanwen Zhang","Xiuling Wang","Yuesheng Zhu","Guibo Luo"],"pdf_url":"","comment":"9 pages; 6 figures"},{"id":"http://arxiv.org/abs/2601.03869v1","updated":"2026-01-07T12:32:39Z","published":"2026-01-07T12:32:39Z","title":"Bayesian Monocular Depth Refinement via Neural Radiance Fields","summary":"Monocular depth estimation has applications in many fields, such as autonomous navigation and extended reality, making it an essential computer vision task. However, current methods often produce smooth depth maps that lack the fine geometric detail needed for accurate scene understanding. We propose MDENeRF, an iterative framework that refines monocular depth estimates using depth information from Neural Radiance Fields (NeRFs). MDENeRF consists of three components: (1) an initial monocular estimate for global structure, (2) a NeRF trained on perturbed viewpoints, with per-pixel uncertainty, and (3) Bayesian fusion of the noisy monocular and NeRF depths. We derive NeRF uncertainty from the volume rendering process to iteratively inject high-frequency fine details. Meanwhile, our monocular prior maintains global structure. We demonstrate superior performance on key metrics and experiments using indoor scenes from the SUN RGB-D dataset.","authors":["Arun Muthukkumar"],"pdf_url":"","comment":"IEEE 8th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025). Oral presentation; Best Presenter Award"},{"id":"http://arxiv.org/abs/2203.01717v5","updated":"2026-01-07T12:27:12Z","published":"2022-03-03T13:55:38Z","title":"Practitioner Motives to Use Different Hyperparameter Optimization Methods","summary":"Programmatic hyperparameter optimization (HPO) methods, such as Bayesian optimization and evolutionary algorithms, are highly sample-efficient in identifying optimal hyperparameter configurations for machine learning (ML) models. However, practitioners frequently use less efficient methods, such as grid search, which can lead to under-optimized models. We suspect this behavior is driven by a range of practitioner-specific motives. Practitioner motives, however, still need to be clarified to enhance user-centered development of HPO tools. To uncover practitioner motives to use different HPO methods, we conducted 20 semi-structured interviews and an online survey with 49 ML experts. By presenting main goals (e.g., increase ML model understanding) and contextual factors affecting practitioners' selection of HPO methods (e.g., available computer resources), this study offers a conceptual foundation to better understand why practitioners use different HPO methods, supporting development of more user-centered and context-adaptive HPO tools in automated ML.","authors":["Niclas Kannengießer","Niklas Hasebrook","Felix Morsbach","Marc-André Zöller","Jörg Franke","Marius Lindauer","Frank Hutter","Ali Sunyaev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.09598v3","updated":"2026-01-07T12:19:33Z","published":"2025-11-12T15:13:27Z","title":"Parametric Expensive Multi-Objective Optimization via Generative Solution Modeling","summary":"Many real-world applications require solving families of expensive multi-objective optimization problems~(EMOPs) under varying operational conditions. This gives rise to parametric expensive multi-objective optimization problems (P-EMOPs) where each task parameter defines a distinct optimization instance. Current multi-objective Bayesian optimization methods have been widely used for finding finite sets of Pareto optimal solutions for individual tasks. However, P-EMOPs present a fundamental challenge: the continuous task parameter space can contain infinite distinct problems, each requiring separate expensive evaluations. This demands learning an inverse model that can directly predict optimized solutions for any task-preference query without expensive re-evaluation. This paper introduces a novel parametric multi-task multi-objective Bayesian optimizer that learns this inverse model by alternating between (1) acquisition-driven search leveraging inter-task synergies and (2) generative solution sampling via conditional generative models. This approach enables efficient optimization across related tasks and finally achieves direct solution prediction for unseen parameterized EMOPs without additional expensive evaluations. We theoretically justify the faster convergence by leveraging inter-task synergies through task-aware Gaussian processes. Meanwhile, based on that, empirical studies of our optimizer and inverse model in synthetic and real-world benchmarks further verify the effectiveness of the proposed generative alternating framework.","authors":["Tingyang Wei","Jiao Liu","Abhishek Gupta","Chin Chun Ooi","Puay Siew Tan","Yew-Soon Ong"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2512.07782v2","updated":"2026-01-07T12:18:13Z","published":"2025-12-08T18:11:06Z","title":"GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory","summary":"Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \\textit{Associative Memory} interpretation, its difference-style update renders the training objective effectively \\emph{unbounded}. In contrast, Softmax attention normalizes updates, leading to \\emph{memory shrinkage and gradient vanishing}. We propose GatedFWA: a Memory-\\underline{Gated} (\\underline{F}lash) \\underline{W}indowed \\underline{A}ttention mechanism that preserves SWAs efficiency while stabilizing memory updates and making gradient flow controllable. In essence, GatedFWA accumulate a per-token/head gate into a decay bias added to the attention logits, acting as a learnable contraction in the memory recurrence. We implement a fused one-pass gate preprocessing and a FlashAttention-compatible kernel that injects the gate under a sliding mask, ensuring I/O efficiency and numerical stability. On language modelling benchmarks, GatedFWA delivers competitive throughput with negligible overhead and better use of global context, and it integrates cleanly with token compression/selection methods such as NSA and generalizes to various autoregressive domains.","authors":["Jiaxu Liu","Yuhe Bai","Xiangyu Yin","Christos-Savvas Bouganis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03853v1","updated":"2026-01-07T12:09:13Z","published":"2026-01-07T12:09:13Z","title":"From No-Regret to Strategically Robust Learning in Repeated Auctions","summary":"In Bayesian single-item auctions, a monotone bidding strategy--one that prescribes a higher bid for a higher value type--can be equivalently represented as a partition of the quantile space into consecutive intervals corresponding to increasing bids. Kumar et al. (2024) prove that agile online gradient descent (OGD), when used to update a monotone bidding strategy through its quantile representation, is strategically robust in repeated first-price auctions: when all bidders employ agile OGD in this way, the auctioneer's average revenue per round is at most the revenue of Myerson's optimal auction, regardless of how she adjusts the reserve price over time.\n  In this work, we show that this strategic robustness guarantee is not unique to agile OGD or to the first-price auction: any no-regret learning algorithm, when fed gradient feedback with respect to the quantile representation, is strategically robust, even if the auction format changes every round, provided the format satisfies allocation monotonicity and voluntary participation. In particular, the multiplicative weights update (MWU) algorithm simultaneously achieves the optimal regret guarantee and the best-known strategic robustness guarantee. At a technical level, our results are established via a simple relation that bridges Myerson's auction theory and standard no-regret learning theory. This showcases the potential of translating standard regret guarantees into strategic robustness guarantees for specific games, without explicitly minimizing any form of swap regret.","authors":["Junyao Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03839v1","updated":"2026-01-07T12:04:49Z","published":"2026-01-07T12:04:49Z","title":"Logic Tensor Network-Enhanced Generative Adversarial Network","summary":"In this paper, we introduce Logic Tensor Network-Enhanced Generative Adversarial Network (LTN-GAN), a novel framework that enhances Generative Adversarial Networks (GANs) by incorporating Logic Tensor Networks (LTNs) to enforce domain-specific logical constraints during the sample generation process. Although GANs have shown remarkable success in generating realistic data, they often lack mechanisms to incorporate prior knowledge or enforce logical consistency, limiting their applicability in domains requiring rule adherence. LTNs provide a principled way to integrate first-order logic with neural networks, enabling models to reason over and satisfy logical constraints. By combining the strengths of GANs for realistic data synthesis with LTNs for logical reasoning, we gain valuable insights into how logical constraints influence the generative process while improving both the diversity and logical consistency of the generated samples. We evaluate LTN-GAN across multiple datasets, including synthetic datasets (gaussian, grid, rings) and the MNIST dataset, demonstrating that our model significantly outperforms traditional GANs in terms of adherence to predefined logical constraints while maintaining the quality and diversity of generated samples. This work highlights the potential of neuro-symbolic approaches to enhance generative modeling in knowledge-intensive domains.","authors":["Nijesh Upreti","Vaishak Belle"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2506.17776v3","updated":"2026-01-07T12:03:57Z","published":"2025-06-21T18:13:13Z","title":"Machine Learning Model Integration with Open World Temporal Logic for Process Automation","summary":"Recent advances in Machine Learning (ML) have produced models that extract structured information from complex data. However, a significant challenge lies in translating these perceptual or extractive outputs into actionable and explainable decisions within complex operational workflows. To address these challenges, this paper introduces a novel approach that integrates the outputs of various machine learning models directly with the PyReason framework, an open-world temporal logic programming reasoning engine. PyReason's foundation in generalized annotated logic allows for the incorporation of real-valued outputs (e.g., probabilities, confidence scores) from a diverse set of ML models, treating them as truth intervals within its logical framework. Crucially, PyReason provides mechanisms, implemented in Python, to continuously poll ML model outputs, convert them into logical facts, and dynamically recompute the minimal model to enable decision-making in real-time. Furthermore, its native support for temporal reasoning, knowledge graph integration, and fully explainable interface traces enables an analysis of time-sensitive process data and existing organizational knowledge. By combining the strengths of perception and extraction from ML models with the logical deduction and transparency of PyReason, we aim to create a powerful system for automating complex processes. This integration is well suited for use cases in numerous domains, including manufacturing, healthcare, and business operations.","authors":["Dyuman Aditya","Colton Payne","Mario Leiva","Paulo Shakarian"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2512.23405v2","updated":"2026-01-07T12:00:49Z","published":"2025-12-29T11:53:37Z","title":"On the Sample Complexity of Learning for Blind Inverse Problems","summary":"Blind inverse problems arise in many experimental settings where the forward operator is partially or entirely unknown. In this context, methods developed for the non-blind case cannot be adapted in a straightforward manner. Recently, data-driven approaches have been proposed to address blind inverse problems, demonstrating strong empirical performance and adaptability. However, these methods often lack interpretability and are not supported by rigorous theoretical guarantees, limiting their reliability in applied domains such as imaging inverse problems. In this work, we shed light on learning in blind inverse problems within the simplified yet insightful framework of Linear Minimum Mean Square Estimators (LMMSEs). We provide an in-depth theoretical analysis, deriving closed-form expressions for optimal estimators and extending classical results. In particular, we establish equivalences with suitably chosen Tikhonov-regularized formulations, where the regularization depends explicitly on the distributions of the unknown signal, the noise, and the random forward operators. We also prove convergence results under appropriate source condition assumptions. Furthermore, we derive rigorous finite-sample error bounds that characterize the performance of learned estimators as a function of the noise level, problem conditioning, and number of available samples. These bounds explicitly quantify the impact of operator randomness and reveal the associated convergence rates as this randomness vanishes. Finally, we validate our theoretical findings through illustrative numerical experiments that confirm the predicted convergence behavior.","authors":["Nathan Buskulic","Luca Calatroni","Lorenzo Rosasco","Silvia Villa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12069v2","updated":"2026-01-07T11:45:25Z","published":"2025-12-12T22:31:38Z","title":"Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring","summary":"Large Vision-Language Models (LVLMs) are vulnerable to a growing array of multimodal jailbreak attacks, necessitating defenses that are both generalizable to novel threats and efficient for practical deployment. Many current strategies fall short, either targeting specific attack patterns, which limits generalization, or imposing high computational overhead. While lightweight anomaly-detection methods offer a promising direction, we find that their common one-class design tends to confuse novel benign inputs with malicious ones, leading to unreliable over-rejection. To address this, we propose Representational Contrastive Scoring (RCS), a framework built on a key insight: the most potent safety signals reside within the LVLM's own internal representations. Our approach inspects the internal geometry of these representations, learning a lightweight projection to maximally separate benign and malicious inputs in safety-critical layers. This enables a simple yet powerful contrastive score that differentiates true malicious intent from mere novelty. Our instantiations, MCD (Mahalanobis Contrastive Detection) and KCD (K-nearest Contrastive Detection), achieve state-of-the-art performance on a challenging evaluation protocol designed to test generalization to unseen attack types. This work demonstrates that effective jailbreak detection can be achieved by applying simple, interpretable statistical methods to the appropriate internal representations, offering a practical path towards safer LVLM deployment. Our code is available on Github https://github.com/sarendis56/Jailbreak_Detection_RCS.","authors":["Peichun Hua","Hao Li","Shanghao Shi","Zhiyuan Yu","Ning Zhang"],"pdf_url":"","comment":"37 pages, 13 figures"},{"id":"http://arxiv.org/abs/2601.03825v1","updated":"2026-01-07T11:40:02Z","published":"2026-01-07T11:40:02Z","title":"Beyond Physical Labels: Redefining Domains for Robust WiFi-based Gesture Recognition","summary":"In this paper, we propose GesFi, a novel WiFi-based gesture recognition system that introduces WiFi latent domain mining to redefine domains directly from the data itself. GesFi first processes raw sensing data collected from WiFi receivers using CSI-ratio denoising, Short-Time Fast Fourier Transform, and visualization techniques to generate standardized input representations. It then employs class-wise adversarial learning to suppress gesture semantic and leverages unsupervised clustering to automatically uncover latent domain factors responsible for distributional shifts. These latent domains are then aligned through adversarial learning to support robust cross-domain generalization. Finally, the system is applied to the target environment for robust gesture inference. We deployed GesFi under both single-pair and multi-pair settings using commodity WiFi transceivers, and evaluated it across multiple public datasets and real-world environments. Compared to state-of-the-art baselines, GesFi achieves up to 78% and 50% performance improvements over existing adversarial methods, and consistently outperforms prior generalization approaches across most cross-domain tasks.","authors":["Xiang Zhang","Huan Yan","Jinyang Huang","Bin Liu","Yuanhao Feng","Jianchun Liu","Meng Li","Fusang Zhang","Zhi Liu"],"pdf_url":"","comment":"Accepted by IMWUT/Ubicomp 2026"},{"id":"http://arxiv.org/abs/2601.02439v2","updated":"2026-01-07T11:21:44Z","published":"2026-01-05T09:35:11Z","title":"WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks","summary":"We present WebGym, the largest-to-date open-source environment for training realistic visual web agents. Real websites are non-stationary and diverse, making artificial or small-scale task sets insufficient for robust policy learning. WebGym contains nearly 300,000 tasks with rubric-based evaluations across diverse, real-world websites and difficulty levels. We train agents with a simple reinforcement learning (RL) recipe, which trains on the agent's own interaction traces (rollouts), using task rewards as feedback to guide learning. To enable scaling RL, we speed up sampling of trajectories in WebGym by developing a high-throughput asynchronous rollout system, designed specifically for web agents. Our system achieves a 4-5x rollout speedup compared to naive implementations. Second, we scale the task set breadth, depth, and size, which results in continued performance improvement. Fine-tuning a strong base vision-language model, Qwen-3-VL-8B-Instruct, on WebGym results in an improvement in success rate on an out-of-distribution test set from 26.2% to 42.9%, significantly outperforming agents based on proprietary models such as GPT-4o and GPT-5-Thinking that achieve 27.1% and 29.8%, respectively. This improvement is substantial because our test set consists only of tasks on websites never seen during training, unlike many other prior works on training visual web agents.","authors":["Hao Bai","Alexey Taymanov","Tong Zhang","Aviral Kumar","Spencer Whitehead"],"pdf_url":"","comment":"Slightly modified format; added Table 3 for better illustration of the scaling results"},{"id":"http://arxiv.org/abs/2601.03811v1","updated":"2026-01-07T11:16:49Z","published":"2026-01-07T11:16:49Z","title":"EvalBlocks: A Modular Pipeline for Rapidly Evaluating Foundation Models in Medical Imaging","summary":"Developing foundation models in medical imaging requires continuous monitoring of downstream performance. Researchers are burdened with tracking numerous experiments, design choices, and their effects on performance, often relying on ad-hoc, manual workflows that are inherently slow and error-prone. We introduce EvalBlocks, a modular, plug-and-play framework for efficient evaluation of foundation models during development. Built on Snakemake, EvalBlocks supports seamless integration of new datasets, foundation models, aggregation methods, and evaluation strategies. All experiments and results are tracked centrally and are reproducible with a single command, while efficient caching and parallel execution enable scalable use on shared compute infrastructure. Demonstrated on five state-of-the-art foundation models and three medical imaging classification tasks, EvalBlocks streamlines model evaluation, enabling researchers to iterate faster and focus on model innovation rather than evaluation logistics. The framework is released as open source software at https://github.com/DIAGNijmegen/eval-blocks.","authors":["Jan Tagscherer","Sarah de Boer","Lena Philipp","Fennie van der Graaf","Dré Peeters","Joeran Bosma","Lars Leijten","Bogdan Obreja","Ewoud Smit","Alessa Hering"],"pdf_url":"","comment":"Accepted at BVM 2026"},{"id":"http://arxiv.org/abs/2601.00604v2","updated":"2026-01-07T11:15:05Z","published":"2026-01-02T08:19:26Z","title":"Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load","summary":"Predicting cycling duration for a given route is essential for training planning and event preparation. Existing solutions rely on physics-based models that require extensive parameterization, including aerodynamic drag coefficients and real-time wind forecasts, parameters impractical for most amateur cyclists. This work presents a machine learning approach that predicts ride duration using route topology features combined with the athlete's current fitness state derived from training load metrics. The model learns athlete-specific performance patterns from historical data, substituting complex physical measurements with historical performance proxies. We evaluate the approach using a single-athlete dataset (N=96 rides) in an N-of-1 study design. After rigorous feature engineering to eliminate data leakage, we find that Lasso regression with Topology + Fitness features achieves MAE=6.60 minutes and R2=0.922. Notably, integrating fitness metrics (Chronic Training Load (CTL), Acute Training Load (ATL)) reduces error by 14% compared to topology alone (MAE=7.66 min), demonstrating that physiological state meaningfully constrains performance even in self-paced efforts. Progressive checkpoint predictions enable dynamic race planning as route difficulty becomes apparent.","authors":["Francisco Aguilera Moreno"],"pdf_url":"","comment":"29 pages, 22 figures"},{"id":"http://arxiv.org/abs/2601.03808v1","updated":"2026-01-07T11:13:02Z","published":"2026-01-07T11:13:02Z","title":"From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs","summary":"Large language models (LLMs) have achieved notable performance in code synthesis; however, data-aware augmentation remains a limiting factor, handled via heuristic design or brute-force approaches. We introduce a performance-aware, closed-loop solution in the NNGPT ecosystem of projects that enables LLMs to autonomously engineer optimal transformations by internalizing empirical performance cues. We fine-tune LLMs with Low-Rank Adaptation on a novel repository of more than 6,000 empirically evaluated PyTorch augmentation functions, each annotated solely by downstream model accuracy. Training uses pairwise performance ordering (better-worse transformations), enabling alignment through empirical feedback without reinforcement learning, reward models, or symbolic objectives. This reduces the need for exhaustive search, achieving up to 600x times fewer evaluated candidates than brute-force discovery while maintaining competitive peak accuracy and shifting generation from random synthesis to task-aligned design. Ablation studies show that structured Chain-of-Thought prompting introduces syntactic noise and degrades performance, whereas direct prompting ensures stable optimization in performance-critical code tasks. Qualitative and quantitative analyses demonstrate that the model internalizes semantic performance cues rather than memorizing syntax. These results show that LLMs can exhibit task-level reasoning through non-textual feedback loops, bypassing explicit symbolic rewards.","authors":["Usha Shrestha","Dmitry Ignatov","Radu Timofte"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.15008v4","updated":"2026-01-07T11:09:58Z","published":"2025-08-20T18:56:26Z","title":"Neural Network Quantization for Microcontrollers: A Comprehensive Survey of Methods, Platforms, and Applications","summary":"The deployment of Quantized Neural Networks (QNNs) on resource-constrained edge devices, such as microcontrollers (MCUs), introduces fundamental challenges in balancing model performance, computational complexity, and memory constraints. Tiny Machine Learning (TinyML) addresses these issues by jointly advancing machine learning algorithms, hardware architectures, and software optimization techniques to enable deep neural network inference on embedded systems. This survey provides a hardware-oriented perspective on neural network quantization, systematically reviewing the quantization methods most relevant to MCUs and extreme-edge devices. Particular emphasis is placed on the critical trade-offs between model performance and the capabilities of MCU-class hardware, including memory hierarchies, numerical representations, and accelerator support. The survey further reviews contemporary MCU hardware platforms, including ARM-based and RISC-V-based designs, as well as MCUs integrating neural processing units (NPUs) for low-precision inference, together with the supporting software stacks. In addition, we analyze real-world deployments of quantized models on MCUs and consolidate the application domains in which such systems are used. Finally, we discuss open challenges and outline promising future directions toward scalable, energy-efficient, and sustainable AI deployment on edge devices.","authors":["Hamza A. Abushahla","Dara Varam","Ariel Justine N. Panopio","Mohamed I. AlHajri"],"pdf_url":"","comment":"40 pages, 16 figures, 8 Tables"},{"id":"http://arxiv.org/abs/2412.18342v2","updated":"2026-01-07T11:06:48Z","published":"2024-12-24T11:00:23Z","title":"Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set Domain Generalization","summary":"Open-Set Domain Generalization (OSDG) is a challenging task requiring models to accurately predict familiar categories while minimizing confidence for unknown categories to effectively reject them in unseen domains. While the OSDG field has seen considerable advancements, the impact of label noise--a common issue in real-world datasets--has been largely overlooked. Label noise can mislead model optimization, thereby exacerbating the challenges of open-set recognition in novel domains. In this study, we take the first step towards addressing Open-Set Domain Generalization under Noisy Labels (OSDG-NL) by constructing dedicated benchmarks derived from widely used OSDG datasets, including PACS and DigitsDG. We evaluate baseline approaches by integrating techniques from both label denoising and OSDG methodologies, highlighting the limitations of existing strategies in handling label noise effectively. To address these limitations, we propose HyProMeta, a novel framework that integrates hyperbolic category prototypes for label noise-aware meta-learning alongside a learnable new-category agnostic prompt designed to enhance generalization to unseen classes. Our extensive experiments demonstrate the superior performance of HyProMeta compared to state-of-the-art methods across the newly established benchmarks. The source code of this work is released at https://github.com/KPeng9510/HyProMeta.","authors":["Kunyu Peng","Di Wen","M. Saquib Sarfraz","Yufan Chen","Junwei Zheng","David Schneider","Kailun Yang","Jiamin Wu","Alina Roitberg","Rainer Stiefelhagen"],"pdf_url":"","comment":"Accepted to International Journal of Computer Vision (IJCV). The source code of this work is released at https://github.com/KPeng9510/HyProMeta"},{"id":"http://arxiv.org/abs/2601.03805v1","updated":"2026-01-07T11:04:04Z","published":"2026-01-07T11:04:04Z","title":"Detecting Semantic Backdoors in a Mystery Shopping Scenario","summary":"Detecting semantic backdoors in classification models--where some classes can be activated by certain natural, but out-of-distribution inputs--is an important problem that has received relatively little attention. Semantic backdoors are significantly harder to detect than backdoors that are based on trigger patterns due to the lack of such clearly identifiable patterns. We tackle this problem under the assumption that the clean training dataset and the training recipe of the model are both known. These assumptions are motivated by a consumer protection scenario, in which the responsible authority performs mystery shopping to test a machine learning service provider. In this scenario, the authority uses the provider's resources and tools to train a model on a given dataset and tests whether the provider included a backdoor. In our proposed approach, the authority creates a reference model pool by training a small number of clean and poisoned models using trusted infrastructure, and calibrates a model distance threshold to identify clean models. We propose and experimentally analyze a number of approaches to compute model distances and we also test a scenario where the provider performs an adaptive attack to avoid detection. The most reliable method is based on requesting adversarial training from the provider. The model distance is best measured using a set of input samples generated by inverting the models in such a way as to maximize the distance from clean samples. With these settings, our method can often completely separate clean and poisoned models, and it proves to be superior to state-of-the-art backdoor detectors as well.","authors":["Arpad Berta","Gabor Danner","Istvan Hegedus","Mark Jelasity"],"pdf_url":"","comment":"Source code available at https://github.com/szegedai/SemanticBackdoorDetection"},{"id":"http://arxiv.org/abs/2601.03802v1","updated":"2026-01-07T11:02:03Z","published":"2026-01-07T11:02:03Z","title":"Quantum vs. Classical Machine Learning: A Benchmark Study for Financial Prediction","summary":"In this paper, we present a reproducible benchmarking framework that systematically compares QML models with architecture-matched classical counterparts across three financial tasks: (i) directional return prediction on U.S. and Turkish equities, (ii) live-trading simulation with Quantum LSTMs versus classical LSTMs on the S\\&P 500, and (iii) realized volatility forecasting using Quantum Support Vector Regression. By standardizing data splits, features, and evaluation metrics, our study provides a fair assessment of when current-generation QML models can match or exceed classical methods. Our results reveal that quantum approaches show performance gains when data structure and circuit design are well aligned. In directional classification, hybrid quantum neural networks surpass the parameter-matched ANN by \\textbf{+3.8 AUC} and \\textbf{+3.4 accuracy points} on \\texttt{AAPL} stock and by \\textbf{+4.9 AUC} and \\textbf{+3.6 accuracy points} on Turkish stock \\texttt{KCHOL}. In live trading, the QLSTM achieves higher risk-adjusted returns in \\textbf{two of four} S\\&P~500 regimes. For volatility forecasting, an angle-encoded QSVR attains the \\textbf{lowest QLIKE} on \\texttt{KCHOL} and remains within $\\sim$0.02-0.04 QLIKE of the best classical kernels on \\texttt{S\\&P~500} and \\texttt{AAPL}. Our benchmarking framework clearly identifies the scenarios where current QML architectures offer tangible improvements and where established classical methods continue to dominate.","authors":["Rehan Ahmad","Muhammad Kashif","Nouhaila Innan","Muhammad Shafique"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03801v1","updated":"2026-01-07T10:59:24Z","published":"2026-01-07T10:59:24Z","title":"Physically Consistent Machine Learning for Melting Temperature Prediction of Refractory High-Entropy Alloys","summary":"Predicting the melting temperature (Tm) of multi-component and high-entropy alloys (HEAs) is critical for high-temperature applications but computationally expensive using traditional CALPHAD or DFT methods. In this work, we develop a gradient-boosted decision tree (XGBoost) model to predict Tm for complex alloys based on elemental properties. To ensure physical consistency, we address the issue of data leakage by excluding temperature-dependent thermodynamic descriptors (such as Gibbs free energy of mixing) and instead rely on physically motivated elemental features. The optimized model achieves a coefficient of determination (R2) of 0.948 and a Mean Squared Error (MSE) of 9928 which is about 5% relative error for HEAs on a validation set of approximately 1300 compositions. Crucially, we validate the model using the Valence Electron Concentration (VEC) rule. Without explicit constraints during training, the model successfully captures the known stability transition between BCC and FCC phases at a VEC of approximately 6.87. These results demonstrate that data-driven models, when properly feature-engineered, can capture fundamental metallurgical principles for rapid alloy screening.","authors":["Mohd Hasnain"],"pdf_url":"","comment":"6 Pages, 3 figures, code available at Github"},{"id":"http://arxiv.org/abs/2601.03793v1","updated":"2026-01-07T10:50:18Z","published":"2026-01-07T10:50:18Z","title":"Prompt Tuning without Labeled Samples for Zero-Shot Node Classification in Text-Attributed Graphs","summary":"Node classification is a fundamental problem in information retrieval with many real-world applications, such as community detection in social networks, grouping articles published online and product categorization in e-commerce. Zero-shot node classification in text-attributed graphs (TAGs) presents a significant challenge, particularly due to the absence of labeled data. In this paper, we propose a novel Zero-shot Prompt Tuning (ZPT) framework to address this problem by leveraging a Universal Bimodal Conditional Generator (UBCG). Our approach begins with pre-training a graph-language model to capture both the graph structure and the associated textual descriptions of each node. Following this, a conditional generative model is trained to learn the joint distribution of nodes in both graph and text modalities, enabling the generation of synthetic samples for each class based solely on the class name. These synthetic node and text embeddings are subsequently used to perform continuous prompt tuning, facilitating effective node classification in a zero-shot setting. Furthermore, we conduct extensive experiments on multiple benchmark datasets, demonstrating that our framework performs better than existing state-of-the-art baselines. We also provide ablation studies to validate the contribution of the bimodal generator. The code is provided at: https://github.com/Sethup123/ZPT.","authors":["Sethupathy Parameswaran","Suresh Sundaram","Yuan Fang"],"pdf_url":"","comment":"Accepted by WSDM 2026"},{"id":"http://arxiv.org/abs/2512.13872v2","updated":"2026-01-07T10:40:39Z","published":"2025-12-15T20:03:16Z","title":"Measuring Uncertainty Calibration","summary":"We make two contributions to the problem of estimating the $L_1$ calibration error of a binary classifier from a finite dataset. First, we provide an upper bound for any classifier where the calibration function has bounded variation. Second, we provide a method of modifying any classifier so that its calibration error can be upper bounded efficiently without significantly impacting classifier performance and without any restrictive assumptions. All our results are non-asymptotic and distribution-free. We conclude by providing advice on how to measure calibration error in practice. Our methods yield practical procedures that can be run on real-world datasets with modest overhead.","authors":["Kamil Ciosek","Nicolò Felicioni","Sina Ghiassian","Juan Elenter Litwin","Francesco Tonolini","David Gustafsson","Eva Garcia-Martin","Carmen Barcena Gonzalez","Raphaëlle Bertrand-Lalo"],"pdf_url":"","comment":"28 pages"},{"id":"http://arxiv.org/abs/2601.03786v1","updated":"2026-01-07T10:36:46Z","published":"2026-01-07T10:36:46Z","title":"Compact Example-Based Explanations for Language Models","summary":"Training data influence estimation methods quantify the contribution of training documents to a model's output, making them a promising source of information for example-based explanations. As humans cannot interpret thousands of documents, only a small subset of the training data can be presented as an explanation. Although the choice of which documents to include directly affects explanation quality, previous evaluations of such systems have largely ignored any selection strategies. To address this, we propose a novel selection relevance score, a retraining-free metric that quantifies how useful a set of examples is for explaining a model's output. We validate this score through fine-tuning experiments, confirming that it can predict whether a set of examples supports or undermines the model's predictions. Using this metric, we further show that common selection strategies often underperform random selection. Motivated by this finding, we propose a strategy that balances influence and representativeness, enabling better use of selection budgets than naively selecting the highest-ranking examples.","authors":["Loris Schoenegger","Benjamin Roth"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2510.09668v2","updated":"2026-01-07T10:34:27Z","published":"2025-10-08T09:55:18Z","title":"A Hybrid Computational Intelligence Framework with Metaheuristic Optimization for Drug-Drug Interaction Prediction","summary":"Drug-drug interactions (DDIs) are a leading cause of preventable adverse events, often complicating treatment and increasing healthcare costs. At the same time, knowing which drugs do not interact is equally important, as such knowledge supports safer prescriptions and better patient outcomes. In this study, we propose an interpretable and efficient framework that blends modern machine learning with domain knowledge to improve DDI prediction. Our approach combines two complementary molecular embeddings - Mol2Vec, which captures fragment-level structural patterns, and SMILES-BERT, which learns contextual chemical features - together with a leakage-free, rule-based clinical score (RBScore) that injects pharmacological knowledge without relying on interaction labels. A lightweight neural classifier is then optimized using a novel three-stage metaheuristic strategy (RSmpl-ACO-PSO), which balances global exploration and local refinement for stable performance. Experiments on real-world datasets demonstrate that the model achieves high predictive accuracy (ROC-AUC 0.911, PR-AUC 0.867 on DrugBank) and generalizes well to a clinically relevant Type 2 Diabetes Mellitus cohort. Beyond raw performance, studies show how embedding fusion, RBScore, and the optimizer each contribute to precision and robustness. Together, these results highlight a practical pathway for building reliable, interpretable, and computationally efficient models that can support safer drug therapies and clinical decision-making.","authors":["Maryam Abdollahi Shamami","Babak Teimourpour","Farshad Sharifi"],"pdf_url":"","comment":"After further internal review, we identified that the methodological contribution claimed in Section 3 substantially overlaps with prior published work and lacks sufficient novel theoretical or empirical justification. As this affects the core contribution, the authors request withdrawal rather than replacement"},{"id":"http://arxiv.org/abs/2410.18987v5","updated":"2026-01-07T10:32:04Z","published":"2024-10-09T17:19:22Z","title":"Point Cloud Synthesis Using Inner Product Transforms","summary":"Point cloud synthesis, i.e. the generation of novel point clouds from an input distribution, remains a challenging task, for which numerous complex machine learning models have been devised. We develop a novel method that encodes geometrical-topological characteristics of point clouds using inner products, leading to a highly-efficient point cloud representation with provable expressivity properties. Integrated into deep learning models, our encoding exhibits high quality in typical tasks like reconstruction, generation, and interpolation, with inference times orders of magnitude faster than existing methods.","authors":["Ernst Röell","Bastian Rieck"],"pdf_url":"","comment":"Accepted at the 39th Conference on Neural Information Processing Systems (NeurIPS) 2025. Our code is available at https://github.com/aidos-lab/inner-product-transforms"},{"id":"http://arxiv.org/abs/2210.10179v3","updated":"2026-01-07T10:32:04Z","published":"2022-10-18T21:58:58Z","title":"Inference in conditioned dynamics through causality restoration","summary":"Computing observables from conditioned dynamics is typically computationally hard, because, although obtaining independent samples efficiently from the unconditioned dynamics is usually feasible, generally most of the samples must be discarded (in a form of importance sampling) because they do not satisfy the imposed conditions. Sampling directly from the conditioned distribution is non-trivial, as conditioning breaks the causal properties of the dynamics which ultimately renders the sampling procedure efficient. One standard way of achieving it is through a Metropolis Monte-Carlo procedure, but this procedure is normally slow and a very large number of Monte-Carlo steps is needed to obtain a small number of statistically independent samples. In this work, we propose an alternative method to produce independent samples from a conditioned distribution. The method learns the parameters of a generalized dynamical model that optimally describe the conditioned distribution in a variational sense. The outcome is an effective, unconditioned, dynamical model, from which one can trivially obtain independent samples, effectively restoring causality of the conditioned distribution. The consequences are twofold: on the one hand, it allows us to efficiently compute observables from the conditioned dynamics by simply averaging over independent samples. On the other hand, the method gives an effective unconditioned distribution which is easier to interpret. The method is flexible and can be applied virtually to any dynamics. We discuss an important application of the method, namely the problem of epidemic risk assessment from (imperfect) clinical tests, for a large family of time-continuous epidemic models endowed with a Gillespie-like sampler. We show that the method compares favorably against the state of the art, including the soft-margin approach and mean-field methods.","authors":["Alfredo Braunstein","Giovanni Catania","Luca Dall'Asta","Matteo Mariani","Anna Paola Muntoni"],"pdf_url":"","comment":"22 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.06684v4","updated":"2026-01-07T10:17:03Z","published":"2025-02-10T17:11:20Z","title":"EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks","summary":"Recent foundational models for tabular data, such as TabPFN, excel at adapting to new tasks via in-context learning, but remain constrained to a fixed, pre-defined number of target dimensions-often necessitating costly ensembling strategies. We trace this constraint to a deeper architectural shortcoming: these models lack target equivariance, so that permuting target dimension orderings alters their predictions. This deficiency gives rise to an irreducible \"equivariance gap\", an error term that introduces instability in predictions. We eliminate this gap by designing a fully target-equivariant architecture-ensuring permutation invariance via equivariant encoders, decoders, and a bi-attention mechanism. Empirical evaluation on standard classification benchmarks shows that, on datasets with more classes than those seen during pre-training, our model matches or surpasses existing methods while incurring lower computational overhead.","authors":["Michael Arbel","David Salinas","Frank Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03776v1","updated":"2026-01-07T10:13:40Z","published":"2026-01-07T10:13:40Z","title":"Improving Compactness and Reducing Ambiguity of CFIRE Rule-Based Explanations","summary":"Models trained on tabular data are widely used in sensitive domains, increasing the demand for explanation methods to meet transparency needs. CFIRE is a recent algorithm in this domain that constructs compact surrogate rule models from local explanations. While effective, CFIRE may assign rules associated with different classes to the same sample, introducing ambiguity. We investigate this ambiguity and propose a post-hoc pruning strategy that removes rules with low contribution or conflicting coverage, yielding smaller and less ambiguous models while preserving fidelity. Experiments across multiple datasets confirm these improvements with minimal impact on predictive performance.","authors":["Sebastian Müller","Tobias Schneider","Ruben Kemna","Vanessa Toborek"],"pdf_url":"","comment":"Prepared for ESANN 2026 submission"},{"id":"http://arxiv.org/abs/2506.14435v2","updated":"2026-01-07T10:07:59Z","published":"2025-06-17T11:53:49Z","title":"MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models","summary":"Large multimodal Mixture-of-Experts (MoEs) effectively scale the model size to boost performance while maintaining fixed active parameters. However, previous works primarily utilized full-precision experts during sparse up-cycling. Despite they show superior performance on end tasks, the large amount of experts introduces higher memory footprint, which poses significant challenges for the deployment on edge devices. In this work, we propose MoTE, a scalable and memory-efficient approach to train Mixture-of-Ternary-Experts models from dense checkpoint. Instead of training fewer high-precision experts, we propose to train more low-precision experts during up-cycling. Specifically, we use the pre-trained FFN as a shared expert and train ternary routed experts with parameters in {-1, 0, 1}. Extensive experiments show that our approach has promising scaling trend along model size. MoTE achieves comparable performance to full-precision baseline MoE-LLaVA while offering lower memory footprint. Furthermore, our approach is compatible with post-training quantization methods and the advantage further amplifies when memory-constraint goes lower. Given the same amount of expert memory footprint of 3.4GB and combined with post-training quantization, MoTE outperforms MoE-LLaVA by a gain of 4.3% average accuracy on end tasks, demonstrating its effectiveness and potential for memory-constrained devices.","authors":["Hongyu Wang","Jiayu Xu","Ruiping Wang","Yan Feng","Yitao Zhai","Peng Pei","Xunliang Cai","Xilin Chen"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2601.02075v3","updated":"2026-01-07T10:06:36Z","published":"2026-01-05T12:56:51Z","title":"MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics","summary":"Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials science, yet writing LAMMPS scripts remains highly specialized and time-consuming tasks. Although LLMs show promise in code generation and domain-specific question answering, their performance in MD scenarios is limited by scarce domain data, the high deployment cost of state-of-the-art LLMs, and low code executability. Building upon our prior MDAgent, we present MDAgent2, the first end-to-end framework capable of performing both knowledge Q&A and code generation within the MD domain. We construct a domain-specific data-construction pipeline that yields three high-quality datasets spanning MD knowledge, question answering, and code generation. Based on these datasets, we adopt a three stage post-training strategy--continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning (RL)--to train two domain-adapted models, MD-Instruct and MD-Code. Furthermore, we introduce MD-GRPO, a closed-loop RL method that leverages simulation outcomes as reward signals and recycles low-reward trajectories for continual refinement. We further build MDAgent2-RUNTIME, a deployable multi-agent system that integrates code generation, execution, evaluation, and self-correction. Together with MD-EvalBench proposed in this work, the first benchmark for LAMMPS code generation and question answering, our models and system achieve performance surpassing several strong baselines.This work systematically demonstrates the adaptability and generalization capability of large language models in industrial simulation tasks, laying a methodological foundation for automatic code generation in AI for Science and industrial-scale simulations. URL: https://github.com/FredericVAN/PKU_MDAgent2","authors":["Zhuofan Shi","Hubao A","Yufei Shao","Dongliang Huang","Hongxu An","Chunxiao Xin","Haiyang Shen","Zhenyu Wang","Yunshan Na","Gang Huang","Xiang Jing"],"pdf_url":"","comment":"24 pages,4 figures"},{"id":"http://arxiv.org/abs/2601.03764v1","updated":"2026-01-07T10:00:17Z","published":"2026-01-07T10:00:17Z","title":"Learning Shrinks the Hard Tail: Training-Dependent Inference Scaling in a Solvable Linear Model","summary":"We analyze neural scaling laws in a solvable model of last-layer fine-tuning where targets have intrinsic, instance-heterogeneous difficulty. In our Latent Instance Difficulty (LID) model, each input's target variance is governed by a latent ``precision'' drawn from a heavy-tailed distribution. While generalization loss recovers standard scaling laws, our main contribution connects this to inference. The pass@$k$ failure rate exhibits a power-law decay, $k^{-β_\\text{eff}}$, but the observed exponent $β_\\text{eff}$ is training-dependent. It grows with sample size $N$ before saturating at an intrinsic limit $β$ set by the difficulty distribution's tail. This coupling reveals that learning shrinks the ``hard tail'' of the error distribution: improvements in the model's generalization error steepen the pass@$k$ curve until irreducible target variance dominates. The LID model yields testable, closed-form predictions for this behavior, including a compute-allocation rule that favors training before saturation and inference attempts after. We validate these predictions in simulations and in two real-data proxies: CIFAR-10H (human-label variance) and a maths teacher-student distillation task.","authors":["Noam Levi"],"pdf_url":"","comment":"10 pages"},{"id":"http://arxiv.org/abs/2501.01993v2","updated":"2026-01-07T09:50:21Z","published":"2024-12-31T18:47:54Z","title":"A Novel Convolution and Attention Mechanism-based Model for 6D Object Pose Estimation","summary":"This paper proposes PoseLecTr, a graph-based encoder-decoder framework that integrates a novel Legendre convolution with attention mechanisms for six-degree-of-freedom (6-DOF) object pose estimation from monocular RGB images. Conventional learning-based approaches predominantly rely on grid-structured convolutions, which can limit their ability to model higher-order and long-range dependencies among image features, especially in cluttered or occluded scenes. PoseLecTr addresses this limitation by constructing a graph representation from image features, where spatial relationships are explicitly modeled through graph connectivity. The proposed framework incorporates a Legendre convolution layer to improve numerical stability in graph convolution, together with spatial-attention and self-attention distillation to enhance feature selection. Experiments conducted on the LINEMOD, Occluded LINEMOD, and YCB-VIDEO datasets demonstrate that our method achieves competitive performance and shows consistent improvements across a wide range of objects and scene complexities.","authors":["Alexander Du","Xiujin Liu"],"pdf_url":"","comment":"6 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2601.03753v1","updated":"2026-01-07T09:43:36Z","published":"2026-01-07T09:43:36Z","title":"Probabilistic Transformers for Joint Modeling of Global Weather Dynamics and Decision-Centric Variables","summary":"Weather forecasts sit upstream of high-stakes decisions in domains such as grid operations, aviation, agriculture, and emergency response. Yet forecast users often face a difficult trade-off. Many decision-relevant targets are functionals of the atmospheric state variables, such as extrema, accumulations, and threshold exceedances, rather than state variables themselves. As a result, users must estimate these targets via post-processing, which can be suboptimal and can introduce structural bias. The core issue is that decisions depend on distributions over these functionals that the model is not trained to learn directly.\n  In this work, we introduce GEM-2, a probabilistic transformer that jointly learns global atmospheric dynamics alongside a suite of variables that users directly act upon. Using this training recipe, we show that a lightweight (~275M params) and computationally efficient (~20-100x training speedup relative to state-of-the-art) transformer trained on the CRPS objective can directly outperform operational numerical weather prediction (NWP) models and be competitive with ML models that rely on expensive multi-step diffusion processes or require bespoke multi-stage fine-tuning strategies. We further demonstrate state-of-the-art economic value metrics under decision-theoretic evaluation, stable convergence to climatology at S2S and seasonal timescales, and a surprising insensitivity to many commonly assumed architectural and training design choices.","authors":["Paulius Rauba","Viktor Cikojevic","Fran Bartolic","Sam Levang","Ty Dickinson","Chase Dwelle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.17512v2","updated":"2026-01-07T09:32:46Z","published":"2025-01-29T09:30:21Z","title":"A survey on Clustered Federated Learning: Taxonomy, Analysis and Applications","summary":"As Federated Learning (FL) expands, the challenge of non-independent and identically distributed (non-IID) data becomes critical. Clustered Federated Learning (CFL) addresses this by training multiple specialized models, each representing a group of clients with similar data distributions. However, the term ''CFL'' has increasingly been applied to operational strategies unrelated to data heterogeneity, creating significant ambiguity. This survey provides a systematic review of the CFL literature and introduces a principled taxonomy that classifies algorithms into Server-side, Client-side, and Metadata-based approaches. Our analysis reveals a distinct dichotomy: while theoretical research prioritizes privacy-preserving Server/Client-side methods, real-world applications in IoT, Mobility, and Energy overwhelmingly favor Metadata-based efficiency. Furthermore, we explicitly distinguish ''Core CFL'' (grouping clients for non-IID data) from ''Clustered X FL'' (operational variants for system heterogeneity). Finally, we outline lessons learned and future directions to bridge the gap between theoretical privacy and practical efficiency.","authors":["Michael Ben Ali","Omar El-Rifai","Imen Megdiche","André Peninou","Olivier Teste"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03733v1","updated":"2026-01-07T09:25:04Z","published":"2026-01-07T09:25:04Z","title":"RadDiff: Describing Differences in Radiology Image Sets with Natural Language","summary":"Understanding how two radiology image sets differ is critical for generating clinical insights and for interpreting medical AI systems. We introduce RadDiff, a multimodal agentic system that performs radiologist-style comparative reasoning to describe clinically meaningful differences between paired radiology studies. RadDiff builds on a proposer-ranker framework from VisDiff, and incorporates four innovations inspired by real diagnostic workflows: (1) medical knowledge injection through domain-adapted vision-language models; (2) multimodal reasoning that integrates images with their clinical reports; (3) iterative hypothesis refinement across multiple reasoning rounds; and (4) targeted visual search that localizes and zooms in on salient regions to capture subtle findings. To evaluate RadDiff, we construct RadDiffBench, a challenging benchmark comprising 57 expert-validated radiology study pairs with ground-truth difference descriptions. On RadDiffBench, RadDiff achieves 47% accuracy, and 50% accuracy when guided by ground-truth reports, significantly outperforming the general-domain VisDiff baseline. We further demonstrate RadDiff's versatility across diverse clinical tasks, including COVID-19 phenotype comparison, racial subgroup analysis, and discovery of survival-related imaging features. Together, RadDiff and RadDiffBench provide the first method-and-benchmark foundation for systematically uncovering meaningful differences in radiological data.","authors":["Xiaoxian Shen","Yuhui Zhang","Sahithi Ankireddy","Xiaohan Wang","Maya Varma","Henry Guo","Curtis Langlotz","Serena Yeung-Levy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03725v1","updated":"2026-01-07T09:20:05Z","published":"2026-01-07T09:20:05Z","title":"EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning","summary":"Domain-specific large language models (LLMs), typically developed by fine-tuning a pre-trained general-purpose LLM on specialized datasets, represent a significant advancement in applied AI. A common strategy in LLM fine-tuning is curriculum learning, which pre-orders training samples based on metrics like difficulty to improve learning efficiency compared to a random sampling strategy. However, most existing methods for LLM fine-tuning rely on a static curriculum, designed prior to training, which lacks adaptability to the model's evolving needs during fine-tuning. To address this, we propose EDCO, a novel framework based on two key concepts: inference entropy and dynamic curriculum orchestration. Inspired by recent findings that maintaining high answer entropy benefits long-term reasoning gains, EDCO prioritizes samples with high inference entropy in a continuously adapted curriculum. EDCO integrates three core components: an efficient entropy estimator that uses prefix tokens to approximate full-sequence entropy, an entropy-based curriculum generator that selects data points with the highest inference entropy, and an LLM trainer that optimizes the model on the selected curriculum. Comprehensive experiments in communication, medicine and law domains, EDCO outperforms traditional curriculum strategies for fine-tuning Qwen3-4B and Llama3.2-3B models under supervised and reinforcement learning settings. Furthermore, the proposed efficient entropy estimation reduces computational time by 83.5% while maintaining high accuracy.","authors":["Jing-Cheng Pang","Liu Sun","Chang Zhou","Xian Tang","Haichuan Ma","Kun Jiang","Jianlong Wang","Kai Zhang","Sijie Wu","Haoran Cai","Chenwei Wu","Xubin Li","Xin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03723v1","updated":"2026-01-07T09:19:53Z","published":"2026-01-07T09:19:53Z","title":"ETR: Outcome-Guided Elastic Trust Regions for Policy Optimization","summary":"Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an important paradigm for unlocking reasoning capabilities in large language models, exemplified by the success of OpenAI o1 and DeepSeek-R1. Currently, Group Relative Policy Optimization (GRPO) stands as the dominant algorithm in this domain due to its stable training and critic-free efficiency. However, we argue that GRPO suffers from a structural limitation: it imposes a uniform, static trust region constraint across all samples. This design implicitly assumes signal homogeneity, a premise misaligned with the heterogeneous nature of outcome-driven learning, where advantage magnitudes and variances fluctuate significantly. Consequently, static constraints fail to fully exploit high-quality signals while insufficiently suppressing noise, often precipitating rapid entropy collapse. To address this, we propose \\textbf{E}lastic \\textbf{T}rust \\textbf{R}egions (\\textbf{ETR}), a dynamic mechanism that aligns optimization constraints with signal quality. ETR constructs a signal-aware landscape through dual-level elasticity: at the micro level, it scales clipping boundaries based on advantage magnitude to accelerate learning from high-confidence paths; at the macro level, it leverages group variance to implicitly allocate larger update budgets to tasks in the optimal learning zone. Extensive experiments on AIME and MATH benchmarks demonstrate that ETR consistently outperforms GRPO, achieving superior accuracy while effectively mitigating policy entropy degradation to ensure sustained exploration.","authors":["Shijie Zhang","Kevin Zhang","Zheyuan Gu","Xiang Guo","Rujun Guo","Shaoyu Liu","Guanjun Jiang","Xiaozhao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08473v3","updated":"2026-01-07T09:13:57Z","published":"2025-06-10T05:59:48Z","title":"AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin","summary":"Fine-tuning large language models (LLMs) improves performance but introduces critical safety vulnerabilities: even minimal harmful data can severely compromise safety measures. We observe that perturbations orthogonal to the alignment direction - defined by weight differences between aligned (safe) and unaligned models - rapidly compromise model safety. In contrast, updates along the alignment direction largely preserve it, revealing the parameter space as a \"narrow safety basin\". To address this, we propose AsFT (Anchoring Safety in Fine-Tuning) to maintain safety by explicitly constraining update directions during fine-tuning. By penalizing updates orthogonal to the alignment direction, AsFT effectively constrains the model within the \"narrow safety basin,\" thus preserving its inherent safety. Extensive experiments on multiple datasets and models show that AsFT reduces harmful behaviors by up to 7.60%, improves task performance by 3.44%, and consistently outperforms existing methods across multiple tasks.","authors":["Shuo Yang","Qihui Zhang","Yuyang Liu","Xiaojun Jia","Kunpeng Ning","Jiayu Yao","Jigang Wang","Hailiang Dai","Yibing Song","Li Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00088v2","updated":"2026-01-07T09:09:57Z","published":"2025-10-30T01:25:34Z","title":"Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail","summary":"End-to-end architectures trained via imitation learning have advanced autonomous driving by scaling model size and data, yet performance remains brittle in safety-critical long-tail scenarios where supervision is sparse and causal understanding is limited. We introduce Alpamayo-R1 (AR1), a vision-language-action model (VLA) that integrates Chain of Causation reasoning with trajectory planning for complex driving scenarios. Our approach features three key innovations: (1) the Chain of Causation (CoC) dataset, built through a hybrid auto-labeling and human-in-the-loop pipeline producing decision-grounded, causally linked reasoning traces aligned with driving behaviors; (2) a modular VLA architecture combining Cosmos-Reason, a vision-language model pre-trained for Physical AI, with a diffusion-based trajectory decoder that generates dynamically feasible trajectories in real time; (3) a multi-stage training strategy using supervised fine-tuning to elicit reasoning and reinforcement learning (RL) to enforce reasoning-action consistency and optimize reasoning quality. AR1 achieves up to a 12% improvement in planning accuracy on challenging cases compared to a trajectory-only baseline, with a 35% reduction in close encounter rate in closed-loop simulation. RL post-training improves reasoning quality by 45% and reasoning-action consistency by 37%. Model scaling from 0.5B to 7B parameters shows consistent improvements. On-vehicle road tests confirm real-time performance (99 ms latency) and successful urban deployment. By bridging interpretable reasoning with precise control, AR1 demonstrates a practical path towards Level 4 autonomous driving. Model weights are available at https://huggingface.co/nvidia/Alpamayo-R1-10B with inference code at https://github.com/NVlabs/alpamayo.","authors":[" NVIDIA"," :","Yan Wang","Wenjie Luo","Junjie Bai","Yulong Cao","Tong Che","Ke Chen","Yuxiao Chen","Jenna Diamond","Yifan Ding","Wenhao Ding","Liang Feng","Greg Heinrich","Jack Huang","Peter Karkus","Boyi Li","Pinyi Li","Tsung-Yi Lin","Dongran Liu","Ming-Yu Liu","Langechuan Liu","Zhijian Liu","Jason Lu","Yunxiang Mao","Pavlo Molchanov","Lindsey Pavao","Zhenghao Peng","Mike Ranzinger","Ed Schmerling","Shida Shen","Yunfei Shi","Sarah Tariq","Ran Tian","Tilman Wekel","Xinshuo Weng","Tianjun Xiao","Eric Yang","Xiaodong Yang","Yurong You","Xiaohui Zeng","Wenyuan Zhang","Boris Ivanovic","Marco Pavone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03715v1","updated":"2026-01-07T09:04:52Z","published":"2026-01-07T09:04:52Z","title":"R$^3$L: Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification","summary":"Reinforcement learning drives recent advances in LLM reasoning and agentic capabilities, yet current approaches struggle with both exploration and exploitation. Exploration suffers from low success rates on difficult tasks and high costs of repeated rollouts from scratch. Exploitation suffers from coarse credit assignment and training instability: Trajectory-level rewards penalize valid prefixes for later errors, and failure-dominated groups overwhelm the few positive signals, leaving optimization without constructive direction. To this end, we propose R$^3$L, Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification. To synthesize high-quality trajectories, R$^3$L shifts from stochastic sampling to active synthesis via reflect-then-retry, leveraging language feedback to diagnose errors, transform failed attempts into successful ones, and reduce rollout costs by restarting from identified failure points. With errors diagnosed and localized, Pivotal Credit Assignment updates only the diverging suffix where contrastive signals exist, excluding the shared prefix from gradient update. Since failures dominate on difficult tasks and reflect-then-retry produces off-policy data, risking training instability, Positive Amplification upweights successful trajectories to ensure positive signals guide the optimization process. Experiments on agentic and reasoning tasks demonstrate 5\\% to 52\\% relative improvements over baselines while maintaining training stability. Our code is released at https://github.com/shiweijiezero/R3L.","authors":["Weijie Shi","Yanxi Chen","Zexi Li","Xuchen Pan","Yuchang Sun","Jiajie Xu","Xiaofang Zhou","Yaliang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.10664v2","updated":"2026-01-07T08:52:05Z","published":"2024-08-20T09:05:44Z","title":"Federated Clustering: An Unsupervised Cluster-Wise Training for Decentralized Data Distributions","summary":"Federated Learning (FL) is a pivotal approach in decentralized machine learning, especially when data privacy is crucial and direct data sharing is impractical. While FL is typically associated with supervised learning, its potential in unsupervised scenarios is underexplored. This paper introduces a novel unsupervised federated learning methodology designed to identify the complete set of categories (global K) across multiple clients within label-free, non-uniform data distributions, a process known as Federated Clustering. Our approach, Federated Cluster-Wise Refinement (FedCRef), involves clients that collaboratively train models on clusters with similar data distributions. Initially, clients with diverse local data distributions (local K) train models on their clusters to generate compressed data representations. These local models are then shared across the network, enabling clients to compare them through reconstruction error analysis, leading to the formation of federated groups.In these groups, clients collaboratively train a shared model representing each data distribution, while continuously refining their local clusters to enhance data association accuracy. This iterative process allows our system to identify all potential data distributions across the network and develop robust representation models for each. To validate our approach, we compare it with traditional centralized methods, establishing a performance baseline and showcasing the advantages of our distributed solution. We also conduct experiments on the EMNIST and KMNIST datasets, demonstrating FedCRef's ability to refine and align cluster models with actual data distributions, significantly improving data representation precision in unsupervised federated settings.","authors":["Mirko Nardi","Lorenzo Valerio","Andrea Passarella"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03706v1","updated":"2026-01-07T08:44:03Z","published":"2026-01-07T08:44:03Z","title":"The Geometry of the Pivot: A Note on Lazy Pivoted Cholesky and Farthest Point Sampling","summary":"Low-rank approximations of large kernel matrices are ubiquitous in machine learning, particularly for scaling Gaussian Processes to massive datasets. The Pivoted Cholesky decomposition is a standard tool for this task, offering a computationally efficient, greedy low-rank approximation. While its algebraic properties are well-documented in numerical linear algebra, its geometric intuition within the context of kernel methods often remains obscure. In this note, we elucidate the geometric interpretation of the algorithm within the Reproducing Kernel Hilbert Space (RKHS). We demonstrate that the pivotal selection step is mathematically equivalent to Farthest Point Sampling (FPS) using the kernel metric, and that the Cholesky factor construction is an implicit Gram-Schmidt orthogonalization. We provide a concise derivation and a minimalist Python implementation to bridge the gap between theory and practice.","authors":["Gil Shabat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03704v1","updated":"2026-01-07T08:43:08Z","published":"2026-01-07T08:43:08Z","title":"Investigating Knowledge Distillation Through Neural Networks for Protein Binding Affinity Prediction","summary":"The trade-off between predictive accuracy and data availability makes it difficult to predict protein--protein binding affinity accurately. The lack of experimentally resolved protein structures limits the performance of structure-based machine learning models, which generally outperform sequence-based methods. In order to overcome this constraint, we suggest a regression framework based on knowledge distillation that uses protein structural data during training and only needs sequence data during inference. The suggested method uses binding affinity labels and intermediate feature representations to jointly supervise the training of a sequence-based student network under the guidance of a structure-informed teacher network. Leave-One-Complex-Out (LOCO) cross-validation was used to assess the framework on a non-redundant protein--protein binding affinity benchmark dataset. A maximum Pearson correlation coefficient (P_r) of 0.375 and an RMSE of 2.712 kcal/mol were obtained by sequence-only baseline models, whereas a P_r of 0.512 and an RMSE of 2.445 kcal/mol were obtained by structure-based models. With a P_r of 0.481 and an RMSE of 2.488 kcal/mol, the distillation-based student model greatly enhanced sequence-only performance. Improved agreement and decreased bias were further confirmed by thorough error analyses. With the potential to close the performance gap between sequence-based and structure-based models as larger datasets become available, these findings show that knowledge distillation is an efficient method for transferring structural knowledge to sequence-based predictors. The source code for running inference with the proposed distillation-based binding affinity predictor can be accessed at https://github.com/wajidarshad/ProteinAffinityKD.","authors":["Wajid Arshad Abbasi","Syed Ali Abbas","Maryum Bibi","Saiqa Andleeb","Muhammad Naveed Akhtar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03703v1","updated":"2026-01-07T08:42:14Z","published":"2026-01-07T08:42:14Z","title":"TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL","summary":"Reinforcement learning with group-based objectives, such as Group Relative Policy Optimization (GRPO), is a common framework for aligning large language models on complex reasoning tasks. However, standard GRPO treats each rollout trajectory as an independent flat sequence and assigns a single sequence-level advantage to all tokens, which leads to sample inefficiency and a length bias toward verbose, redundant chains of thought without improving logical depth. We introduce TreeAdv (Tree-Structured Advantage Redistribution for Group-Based RL), which makes the tree structure of group rollouts explicit for both exploration and advantage assignment. Specifically, TreeAdv builds a group of trees (a forest) based on an entropy-driven sampling method where each tree branches at high-uncertainty decisions while sharing low-uncertainty tokens across rollouts. Then, TreeAdv aggregates token-level advantages for internal tree segments by redistributing the advantages of complete rollouts (all leaf nodes), and TreeAdv can easily apply to group-based objectives such as GRPO or GSPO. Across 10 math reasoning benchmarks, TreeAdv consistently outperforms GRPO and GSPO, while using substantially fewer generated tokens under identical supervision, data, and decoding budgets.","authors":["Lang Cao","Hui Ruan","Yongqian Li","Peng Chao","Wu Ning","Haonan Song","Renhong Chen","Yitong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21944v2","updated":"2026-01-07T08:41:35Z","published":"2025-12-26T09:43:24Z","title":"Data relativistic uncertainty framework for low-illumination anime scenery image enhancement","summary":"By contrast with the prevailing works of low-light enhancement in natural images and videos, this study copes with the low-illumination quality degradation in anime scenery images to bridge the domain gap. For such an underexplored enhancement task, we first curate images from various sources and construct an unpaired anime scenery dataset with diverse environments and illumination conditions to address the data scarcity. To exploit the power of uncertainty information inherent with the diverse illumination conditions, we propose a Data Relativistic Uncertainty (DRU) framework, motivated by the idea from Relativistic GAN. By analogy with the wave-particle duality of light, our framework interpretably defines and quantifies the illumination uncertainty of dark/bright samples, which is leveraged to dynamically adjust the objective functions to recalibrate the model learning under data uncertainty. Extensive experiments demonstrate the effectiveness of DRU framework by training several versions of EnlightenGANs, yielding superior perceptual and aesthetic qualities beyond the state-of-the-art methods that are incapable of learning from data uncertainty perspective. We hope our framework can expose a novel paradigm of data-centric learning for potential visual and language domains. Code is available.","authors":["Yiquan Gao","John See"],"pdf_url":"","comment":"Add data"},{"id":"http://arxiv.org/abs/2601.03701v1","updated":"2026-01-07T08:38:13Z","published":"2026-01-07T08:38:13Z","title":"Inference Attacks Against Graph Generative Diffusion Models","summary":"Graph generative diffusion models have recently emerged as a powerful paradigm for generating complex graph structures, effectively capturing intricate dependencies and relationships within graph data. However, the privacy risks associated with these models remain largely unexplored. In this paper, we investigate information leakage in such models through three types of black-box inference attacks. First, we design a graph reconstruction attack, which can reconstruct graphs structurally similar to those training graphs from the generated graphs. Second, we propose a property inference attack to infer the properties of the training graphs, such as the average graph density and the distribution of densities, from the generated graphs. Third, we develop two membership inference attacks to determine whether a given graph is present in the training set. Extensive experiments on three different types of graph generative diffusion models and six real-world graphs demonstrate the effectiveness of these attacks, significantly outperforming the baseline approaches. Finally, we propose two defense mechanisms that mitigate these inference attacks and achieve a better trade-off between defense strength and target model utility than existing methods. Our code is available at https://zenodo.org/records/17946102.","authors":["Xiuling Wang","Xin Huang","Guibo Luo","Jianliang Xu"],"pdf_url":"","comment":"This work has been accepted by USENIX Security 2026"},{"id":"http://arxiv.org/abs/2510.08224v2","updated":"2026-01-07T08:32:47Z","published":"2025-10-09T13:45:54Z","title":"Investigating Counterclaims in Causality Extraction from Text","summary":"Many causal claims, such as \"sugar causes hyperactivity,\" are disputed or outdated. Yet research on causality extraction from text has almost entirely neglected counterclaims of causation. To close this gap, we conduct a thorough literature review of causality extraction, compile an extensive inventory of linguistic realizations of countercausal claims, and develop rigorous annotation guidelines that explicitly incorporate countercausal language. We also highlight how counterclaims of causation are an integral part of causal reasoning. Based on our guidelines, we construct a new dataset comprising 1028 causal claims, 952 counterclaims, and 1435 uncausal statements, achieving substantial inter-annotator agreement (Cohen's $κ= 0.74$). In our experiments, state-of-the-art models trained solely on causal claims misclassify counterclaims more than 10 times as often as models trained on our dataset.","authors":["Tim Hagen","Niklas Deckers","Felix Wolter","Harrisen Scells","Martin Potthast"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.05695v4","updated":"2026-01-07T08:26:24Z","published":"2025-04-08T05:37:38Z","title":"Architecture independent generalization bounds for overparametrized deep ReLU networks","summary":"We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove a uniform generalization bound that is independent of the network architecture. We perform computational experiments of our theoretical results with MNIST, and obtain agreement with the true test error within a 22 % margin on average.","authors":["Anandatheertha Bapu","Thomas Chen","Chun-Kai Kevin Chien","Patricia Muñoz Ewald","Andrew G. Moore"],"pdf_url":"","comment":"AMS Latex, 18 pages. Significantly updated, A. Bapu included as coauthor, Section 3 added"},{"id":"http://arxiv.org/abs/2601.03689v1","updated":"2026-01-07T08:24:08Z","published":"2026-01-07T08:24:08Z","title":"A Pre-trained Reaction Embedding Descriptor Capturing Bond Transformation Patterns","summary":"With the rise of data-driven reaction prediction models, effective reaction descriptors are crucial for bridging the gap between real-world chemistry and digital representations. However, general-purpose, reaction-wise descriptors remain scarce. This study introduces RXNEmb, a novel reaction-level descriptor derived from RXNGraphormer, a model pre-trained to distinguish real reactions from fictitious ones with erroneous bond changes, thereby learning intrinsic bond formation and cleavage patterns. We demonstrate its utility by data-driven re-clustering of the USPTO-50k dataset, yielding a classification that more directly reflects bond-change similarities than rule-based categories. Combined with dimensionality reduction, RXNEmb enables visualization of reaction space diversity. Furthermore, attention weight analysis reveals the model's focus on chemically critical sites, providing mechanistic insight. RXNEmb serves as a powerful, interpretable tool for reaction fingerprinting and analysis, paving the way for more data-centric approaches in reaction analysis and discovery.","authors":["Weiqi Liu","Fenglei Cao","Yuan Qi","Li-Cheng Xu"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.03683v1","updated":"2026-01-07T08:16:55Z","published":"2026-01-07T08:16:55Z","title":"Rethinking Recurrent Neural Networks for Time Series Forecasting: A Reinforced Recurrent Encoder with Prediction-Oriented Proximal Policy Optimization","summary":"Time series forecasting plays a crucial role in contemporary engineering information systems for supporting decision-making across various industries, where Recurrent Neural Networks (RNNs) have been widely adopted due to their capability in modeling sequential data. Conventional RNN-based predictors adopt an encoder-only strategy with sliding historical windows as inputs to forecast future values. However, this approach treats all time steps and hidden states equally without considering their distinct contributions to forecasting, leading to suboptimal performance. To address this limitation, we propose a novel Reinforced Recurrent Encoder with Prediction-oriented Proximal Policy Optimization, RRE-PPO4Pred, which significantly improves time series modeling capacity and forecasting accuracy of the RNN models. The core innovations of this method are: (1) A novel Reinforced Recurrent Encoder (RRE) framework that enhances RNNs by formulating their internal adaptation as a Markov Decision Process, creating a unified decision environment capable of learning input feature selection, hidden skip connection, and output target selection; (2) An improved Prediction-oriented Proximal Policy Optimization algorithm, termed PPO4Pred, which is equipped with a Transformer-based agent for temporal reasoning and develops a dynamic transition sampling strategy to enhance sampling efficiency; (3) A co-evolutionary optimization paradigm to facilitate the learning of the RNN predictor and the policy agent, providing adaptive and interactive time series modeling. Comprehensive evaluations on five real-world datasets indicate that our method consistently outperforms existing baselines, and attains accuracy better than state-of-the-art Transformer models, thus providing an advanced time series predictor in engineering informatics.","authors":["Xin Lai","Shiming Deng","Lu Yu","Yumin Lai","Shenghao Qiao","Xinze Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.20408v2","updated":"2026-01-07T08:08:55Z","published":"2025-02-13T04:42:39Z","title":"Brain-Inspired Exploration of Functional Networks and Key Neurons in Large Language Models","summary":"In recent years, the rapid advancement of large language models (LLMs) in natural language processing has sparked significant interest among researchers to understand their mechanisms and functional characteristics. Although prior studies have attempted to explain LLM functionalities by identifying and interpreting specific neurons, these efforts mostly focus on individual neuron contributions, neglecting the fact that human brain functions are realized through intricate interaction networks. Inspired by research on functional brain networks (FBNs) in the field of neuroscience, we utilize similar methodologies estabilished in FBN analysis to explore the \"functional networks\" within LLMs in this study. Experimental results highlight that, much like the human brain, LLMs exhibit certain functional networks that recur frequently during their operation. Further investigation reveals that these functional networks are indispensable for LLM performance. Inhibiting key functional networks severely impairs the model's capabilities. Conversely, amplifying the activity of neurons within these networks can enhance either the model's overall performance or its performance on specific tasks. This suggests that these functional networks are strongly associated with either specific tasks or the overall performance of the LLM. Code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.","authors":["Yiheng Liu","Zhengliang Liu","Zihao Wu","Junhao Ning","Haiyang Sun","Sichen Xia","Yang Yang","Xiaohui Gao","Ning Qiang","Bao Ge","Tianming Liu","Junwei Han","Xintao Hu"],"pdf_url":"","comment":"21 pages, 18 figures"},{"id":"http://arxiv.org/abs/2512.12602v2","updated":"2026-01-07T08:08:46Z","published":"2025-12-14T08:51:02Z","title":"Error-Free Linear Attention is a Free Lunch: Exact Solution from Continuous-Time Dynamics","summary":"Linear-time attention and State Space Models (SSMs) promise to solve the quadratic cost bottleneck in long-context language models employing softmax attention. We introduce Error-Free Linear Attention (EFLA), a numerically stable, fully parallelism and generalized formulation of the delta rule. Specifically, we formulate the online learning update as a continuous-time dynamical system and prove that its exact solution is not only attainable but also computable in linear time with full parallelism. By leveraging the rank-1 structure of the dynamics matrix, we directly derive the exact closed-form solution effectively corresponding to the infinite-order Runge-Kutta method. This attention mechanism is theoretically free from error accumulation, perfectly capturing the continuous dynamics while preserving the linear-time complexity. Through an extensive suite of experiments, we show that EFLA enables robust performance in noisy environments, achieving lower language modeling perplexity and superior downstream benchmark performance than DeltaNet without introducing additional parameters. Our work provides a new theoretical foundation for building high-fidelity, scalable linear-time attention models.","authors":["Jingdi Lei","Di Zhang","Soujanya Poria"],"pdf_url":"","comment":"17 pages, 2 figures"},{"id":"http://arxiv.org/abs/2601.03679v1","updated":"2026-01-07T08:00:43Z","published":"2026-01-07T08:00:43Z","title":"Accounting for Optimal Control in the Sizing of Isolated Hybrid Renewable Energy Systems Using Imitation Learning","summary":"Decarbonization of isolated or off-grid energy systems through phase-in of large shares of intermittent solar or wind generation requires co-installation of energy storage or continued use of existing fossil dispatchable power sources to balance supply and demand. The effective CO2 emission reduction depends on the relative capacity of the energy storage and renewable sources, the stochasticity of the renewable generation, and the optimal control or dispatch of the isolated energy system. While the operations of the energy storage and dispatchable sources may impact the optimal sizing of the system, it is challenging to account for the effect of finite horizon, optimal control at the stage of system sizing. Here, we present a flexible and computationally efficient sizing framework for energy storage and renewable capacity in isolated energy systems, accounting for uncertainty in the renewable generation and the optimal feedback control. To this end, we implement an imitation learning approach to stochastic neural model predictive control (MPC) which allows us to relate the battery storage and wind peak capacities to the emissions reduction and investment costs while accounting for finite horizon, optimal control. Through this approach, decision makers can evaluate the effective emission reduction and costs of different storage and wind capacities at any price point while accounting for uncertainty in the renewable generation with limited foresight. We evaluate the proposed sizing framework on a case study of an offshore energy system with a gas turbine, a wind farm and a battery energy storage system (BESS). In this case, we find a nonlinear, nontrivial relationship between the investment costs and reduction in gas usage relative to the wind and BESS capacities, emphasizing the complexity and importance of accounting for optimal control in the design of isolated energy systems.","authors":["Simon Halvdansson","Lucas Ferreira Bernardino","Brage Rugstad Knudsen"],"pdf_url":"","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2601.03673v1","updated":"2026-01-07T07:54:09Z","published":"2026-01-07T07:54:09Z","title":"Disentangling Aleatoric and Epistemic Uncertainty in Physics-Informed Neural Networks. Application to Insulation Material Degradation Prognostics","summary":"Physics-Informed Neural Networks (PINNs) provide a framework for integrating physical laws with data. However, their application to Prognostics and Health Management (PHM) remains constrained by the limited uncertainty quantification (UQ) capabilities. Most existing PINN-based prognostics approaches are deterministic or account only for epistemic uncertainty, limiting their suitability for risk-aware decision-making. This work introduces a heteroscedastic Bayesian Physics-Informed Neural Network (B-PINN) framework that jointly models epistemic and aleatoric uncertainty, yielding full predictive posteriors for spatiotemporal insulation material ageing estimation. The approach integrates Bayesian Neural Networks (BNNs) with physics-based residual enforcement and prior distributions, enabling probabilistic inference within a physics-informed learning architecture. The framework is evaluated on transformer insulation ageing application, validated with a finite-element thermal model and field measurements from a solar power plant, and benchmarked against deterministic PINNs, dropout-based PINNs (d-PINNs), and alternative B-PINN variants. Results show that the proposed B-PINN provides improved predictive accuracy and better-calibrated uncertainty estimates than competing approaches. A systematic sensitivity study further analyzes the impact of boundary-condition, initial-condition, and residual sampling strategies on accuracy, calibration, and generalization. Overall, the findings highlight the potential of Bayesian physics-informed learning to support uncertainty-aware prognostics and informed decision-making in transformer asset management.","authors":["Ibai Ramirez","Jokin Alcibar","Joel Pino","Mikel Sanz","Jose I. Aizpurua"],"pdf_url":"","comment":"24 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2601.03671v1","updated":"2026-01-07T07:50:47Z","published":"2026-01-07T07:50:47Z","title":"NeuronScope: A Multi-Agent Framework for Explaining Polysemantic Neurons in Language Models","summary":"Neuron-level interpretation in large language models (LLMs) is fundamentally challenged by widespread polysemanticity, where individual neurons respond to multiple distinct semantic concepts. Existing single-pass interpretation methods struggle to faithfully capture such multi-concept behavior. In this work, we propose NeuronScope, a multi-agent framework that reformulates neuron interpretation as an iterative, activation-guided process. NeuronScope explicitly deconstructs neuron activations into atomic semantic components, clusters them into distinct semantic modes, and iteratively refines each explanation using neuron activation feedback. Experiments demonstrate that NeuronScope uncovers hidden polysemanticity and produces explanations with significantly higher activation correlation compared to single-pass baselines.","authors":["Weiqi Liu","Yongliang Miao","Haiyan Zhao","Yanguang Liu","Mengnan Du"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03668v1","updated":"2026-01-07T07:43:30Z","published":"2026-01-07T07:43:30Z","title":"Discontinuous Galerkin finite element operator network for solving non-smooth PDEs","summary":"We introduce Discontinuous Galerkin Finite Element Operator Network (DG--FEONet), a data-free operator learning framework that combines the strengths of the discontinuous Galerkin (DG) method with neural networks to solve parametric partial differential equations (PDEs) with discontinuous coefficients and non-smooth solutions. Unlike traditional operator learning models such as DeepONet and Fourier Neural Operator, which require large paired datasets and often struggle near sharp features, our approach minimizes the residual of a DG-based weak formulation using the Symmetric Interior Penalty Galerkin (SIPG) scheme. DG-FEONet predicts element-wise solution coefficients via a neural network, enabling data-free training without the need for precomputed input-output pairs. We provide theoretical justification through convergence analysis and validate the model's performance on a series of one- and two-dimensional PDE problems, demonstrating accurate recovery of discontinuities, strong generalization across parameter space, and reliable convergence rates. Our results highlight the potential of combining local discretization schemes with machine learning to achieve robust, singularity-aware operator approximation in challenging PDE settings.","authors":["Kapil Chawla","Youngjoon Hong","Jae Yong Lee","Sanghyun Lee"],"pdf_url":"","comment":"24 pages, 11 figures"},{"id":"http://arxiv.org/abs/2601.03667v1","updated":"2026-01-07T07:41:57Z","published":"2026-01-07T07:41:57Z","title":"TRec: Egocentric Action Recognition using 2D Point Tracks","summary":"We present a novel approach for egocentric action recognition that leverages 2D point tracks as an additional motion cue. While most existing methods rely on RGB appearance, human pose estimation, or their combination, our work demonstrates that tracking randomly sampled image points across video frames can substantially improve recognition accuracy. Unlike prior approaches, we do not detect hands, objects, or interaction regions. Instead, we employ CoTracker to follow a set of randomly initialized points through each video and use the resulting trajectories, together with the corresponding image frames, as input to a Transformer-based recognition model. Surprisingly, our method achieves notable gains even when only the initial frame and its associated point tracks are provided, without incorporating the full video sequence. Experimental results confirm that integrating 2D point tracks consistently enhances performance compared to the same model trained without motion information, highlighting their potential as a lightweight yet effective representation for egocentric action understanding.","authors":["Dennis Holzmann","Sven Wachsmuth"],"pdf_url":"","comment":"submitted to ICPR 2026"},{"id":"http://arxiv.org/abs/2306.08529v3","updated":"2026-01-07T07:38:44Z","published":"2023-06-14T14:23:19Z","title":"SQL2Circuits: Estimating Cardinalities, Execution Times, and Costs for SQL Queries with Quantum Natural Language Processing","summary":"Recent advances in quantum computing have led to progress in exploring quantum applications across diverse fields, including databases and data management. This work presents a quantum machine learning model that tackles the challenge of estimating metrics, such as cardinalities, execution times, and costs, for SQL queries in relational databases. Precise estimations are crucial for the query optimizer to optimize query processing in relational databases efficiently. Our proposed quantum machine learning model consists of a novel query encoding mechanism, which maps SQL queries into high-dimensional Hilbert spaces using grammatical representations of the queries. The encoding mechanism translates SQL queries into parameterized quantum circuits, forming the core of the quantum machine learning model. The parameters in this model are tuned using standard quantum machine learning techniques. This encoding was first developed in quantum natural language processing (QNLP), and this work demonstrates its natural application in database optimization. Because the encoding mechanism is mathematically robust, the quantum machine learning model is also explainable, allowing us to draw a one-to-one correspondence between the elements in SQL queries and the model's parameters. The method is also scalable because it consists of multiple circuits, and we train and evaluate the model with hundreds of queries. Compared to previous research, our model achieves high accuracy, supporting the results obtained in the original QNLP research. We extend the previous QNLP work by adding 4-class and 8-class classification tasks and comparing the cardinality estimation results with those from state-of-the-art databases. We theoretically analyze the quantum machine learning model by calculating its expressibility and entangling capabilities.","authors":["Valter Uotila"],"pdf_url":"","comment":"12 pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2601.03664v1","updated":"2026-01-07T07:37:38Z","published":"2026-01-07T07:37:38Z","title":"Stochastic Voronoi Ensembles for Anomaly Detection","summary":"Anomaly detection aims to identify data instances that deviate significantly from majority of data, which has been widely used in fraud detection, network security, and industrial quality control. Existing methods struggle with datasets exhibiting varying local densities: distance-based methods miss local anomalies, while density-based approaches require careful parameter selection and incur quadratic time complexity. We observe that local anomalies, though indistinguishable under global analysis, become conspicuous when the data space is decomposed into restricted regions and each region is examined independently. Leveraging this geometric insight, we propose SVEAD (Stochastic Voronoi Ensembles Anomaly Detector), which constructs ensemble random Voronoi diagrams and scores points by normalized cell-relative distances weighted by local scale. The proposed method achieves linear time complexity and constant space complexity. Experiments on 45 datasets demonstrate that SVEAD outperforms 12 state-of-the-art approaches.","authors":["Yang Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03661v1","updated":"2026-01-07T07:22:58Z","published":"2026-01-07T07:22:58Z","title":"AMIR-GRPO: Inducing Implicit Preference Signals into GRPO","summary":"Reinforcement learning has become the primary paradigm for aligning large language models (LLMs) on complex reasoning tasks, with group relative policy optimization (GRPO) widely used in large-scale post-training. However, GRPO faces structural limitations in reasoning-heavy settings: sequence-level advantage normalization introduces systematic length bias, penalties for low-quality trajectories are diluted, and the scalar objective discards rich pairwise preference information embedded in within-group reward rankings. As a result, valuable supervision from costly rollouts remains underutilized.\n  We propose AMIR-GRPO, which augments GRPO with an implicit DPO-style contrastive regularizer constructed directly from intra-group reward rankings, requiring no additional annotations. This mechanism amplifies suppression of low-reward trajectories, attenuates response-level length bias, and transforms each rollout group into a denser set of supervision constraints. Across multiple mathematical reasoning benchmarks, AMIR-GRPO consistently outperforms strong GRPO baselines, yields clearer separation between correct and incorrect reasoning chains, and delivers broader coverage gains beyond the subset of instances solved by standard GRPO.","authors":["Amir Hossein Yari","Fajri Koto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.20382v2","updated":"2026-01-07T07:15:16Z","published":"2025-02-27T18:56:01Z","title":"Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization","summary":"We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks. Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinematic retargeting and trajectory optimization to adapt them across various robot embodiments and physical parameters. This process yields a diverse, physically consistent dataset that enables cross-embodiment data transfer, and offers the potential to reuse legacy datasets collected under different hardware configurations or physical parameters. We validate the pipeline's effectiveness by training diffusion policies from the generated datasets for challenging contact-rich manipulation tasks across multiple robot embodiments, including a floating Allegro hand and bimanual robot arms. The trained policies are deployed zero-shot on hardware for bimanual iiwa arms, achieving high success rates with minimal human input. Project website: https://lujieyang.github.io/physicsgen/.","authors":["Lujie Yang","H. J. Terry Suh","Tong Zhao","Bernhard Paus Graesdal","Tarik Kelestemur","Jiuguang Wang","Tao Pang","Russ Tedrake"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03658v1","updated":"2026-01-07T07:15:11Z","published":"2026-01-07T07:15:11Z","title":"Group and Exclusive Sparse Regularization-based Continual Learning of CNNs","summary":"We present a regularization-based approach for continual learning (CL) of fixed capacity convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when learning multiple tasks sequentially. This method referred to as Group and Exclusive Sparsity based Continual Learning (GESCL) avoids forgetting of previous tasks by ensuring the stability of the CNN via a stability regularization term, which prevents filters detected as important for past tasks to deviate too much when learning a new task. On top of that, GESCL makes the network plastic via a plasticity regularization term that leverage the over-parameterization of CNNs to efficiently sparsify the network and tunes unimportant filters making them relevant for future tasks. Doing so, GESCL deals with significantly less parameters and computation compared to CL approaches that either dynamically expand the network or memorize past tasks' data. Experiments on popular CL vision benchmarks show that GESCL leads to significant improvements over state-of-the-art method in terms of overall CL performance, as measured by classification accuracy as well as in terms of avoiding catastrophic forgetting.","authors":["Basile Tousside","Janis Mohr","Jörg Frochte"],"pdf_url":"","comment":"12 pages, Canadian Artificial Intelligence Association (CAIAC)"},{"id":"http://arxiv.org/abs/2601.03657v1","updated":"2026-01-07T07:13:01Z","published":"2026-01-07T07:13:01Z","title":"In Search of Grandmother Cells: Tracing Interpretable Neurons in Tabular Representations","summary":"Foundation models are powerful yet often opaque in their decision-making. A topic of continued interest in both neuroscience and artificial intelligence is whether some neurons behave like grandmother cells, i.e., neurons that are inherently interpretable because they exclusively respond to single concepts. In this work, we propose two information-theoretic measures that quantify the neuronal saliency and selectivity for single concepts. We apply these metrics to the representations of TabPFN, a tabular foundation model, and perform a simple search across neuron-concept pairs to find the most salient and selective pair. Our analysis provides the first evidence that some neurons in such models show moderate, statistically significant saliency and selectivity for high-level concepts. These findings suggest that interpretable neurons can emerge naturally and that they can, in some cases, be identified without resorting to more complex interpretability techniques.","authors":["Ricardo Knauer","Erik Rodner"],"pdf_url":"","comment":"EurIPS 2025 Workshop on AI for Tabular Data"},{"id":"http://arxiv.org/abs/2601.03654v1","updated":"2026-01-07T07:05:34Z","published":"2026-01-07T07:05:34Z","title":"Quantum Classical Ridgelet Neural Network For Time Series Model","summary":"In this study, we present a quantum computing method that incorporates ridglet transforms into the quantum processing pipelines for time series data. Here, the Ridgelet neural network is integrated with a single-qubit quantum computing method, which improves feature extraction and forecasting capabilities. Furthermore, experimental results using financial time series data demonstrate the superior performance of our model compared to existing models.","authors":["Bahadur Yadav","Sanjay Kumar Mohanty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.20823v3","updated":"2026-01-07T07:03:34Z","published":"2025-09-25T07:10:03Z","title":"CaTS-Bench: Can Language Models Describe Time Series?","summary":"Time series captioning, the task of describing time series in natural language, requires numeric and temporal reasoning, trend interpretation, and contextual understanding. Existing benchmarks, however, often rely on fully synthetic or generic captions, and typically neglect metadata and visual representations. We introduce \\textbf{CaTS-Bench}, a comprehensive benchmark for \\textbf{C}ontext-\\textbf{a}ware \\textbf{T}ime \\textbf{S}eries reasoning across $11$ diverse domains, centered on a gold-standard evaluation set of $1746$ human-rewritten captions that measure how effectively models translate numeric trends into immediately interpretable narratives. To address the scarcity of human-annotated data, we also propose a scalable pipeline for generating high-fidelity synthetic captions, the quality of which we validate. We evaluate leading Vision-Language Models on our benchmark, revealing that even proprietary models struggle to capture numeric nuances in temporal descriptions, while finetuning open-source models on synthetic data yields substantial performance gains. Finally, we release a diagnostic suite of $910$ multiple-choice questions and tailored numeric metrics to gauge time-series-specific reasoning capabilities, establishing CaTS-Bench as a reliable foundation for grounded, multimodal language generation in numeric domains.","authors":["Luca Zhou","Pratham Yashwante","Marshall Fisher","Alessio Sampieri","Zihao Zhou","Fabio Galasso","Rose Yu"],"pdf_url":"","comment":"8 pages, 6 figures, 3 tables in the main paper. Many more in the appendix"},{"id":"http://arxiv.org/abs/2503.23314v2","updated":"2026-01-07T06:55:19Z","published":"2025-03-30T04:45:32Z","title":"SPIO: Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science","summary":"Large Language Models (LLMs) have enabled dynamic reasoning in automated data analytics, yet recent multi-agent systems remain limited by rigid, single-path workflows that restrict strategic exploration and often lead to suboptimal outcomes. To overcome these limitations, we propose SPIO (Sequential Plan Integration and Optimization), a framework that replaces rigid workflows with adaptive, multi-path planning across four core modules: data preprocessing, feature engineering, model selection, and hyperparameter tuning. In each module, specialized agents generate diverse candidate strategies, which are cascaded and refined by an optimization agent. SPIO offers two operating modes: SPIO-S for selecting a single optimal pipeline, and SPIO-E for ensembling top-k pipelines to maximize robustness. Extensive evaluations on Kaggle and OpenML benchmarks show that SPIO consistently outperforms state-of-the-art baselines, achieving an average performance gain of 5.6%. By explicitly exploring and integrating multiple solution paths, SPIO delivers a more flexible, accurate, and reliable foundation for automated data science.","authors":["Wonduk Seo","Juhyeon Lee","Yanjun Shao","Qingshan Zhou","Seunghyun Lee","Yi Bu"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2601.03646v1","updated":"2026-01-07T06:50:56Z","published":"2026-01-07T06:50:56Z","title":"ReLA: Representation Learning and Aggregation for Job Scheduling with Reinforcement Learning","summary":"Job scheduling is widely used in real-world manufacturing systems to assign ordered job operations to machines under various constraints. Existing solutions remain limited by long running time or insufficient schedule quality, especially when problem scale increases. In this paper, we propose ReLA, a reinforcement-learning (RL) scheduler built on structured representation learning and aggregation. ReLA first learns diverse representations from scheduling entities, including job operations and machines, using two intra-entity learning modules with self-attention and convolution and one inter-entity learning module with cross-attention. These modules are applied in a multi-scale architecture, and their outputs are aggregated to support RL decision-making. Across experiments on small, medium, and large job instances, ReLA achieves the best makespan in most tested settings over the latest solutions. On non-large instances, ReLA reduces the optimality gap of the SOTA baseline by 13.0%, while on large-scale instances it reduces the gap by 78.6%, with the average optimality gaps lowered to 7.3% and 2.1%, respectively. These results confirm that ReLA's learned representations and aggregation provide strong decision support for RL scheduling, and enable fast job completion and decision-making for real-world applications.","authors":["Zhengyi Kwan","Zhang Wei","Aik Beng Ng","Zhengkui Wang","Simon See"],"pdf_url":"","comment":"15 pages"},{"id":"http://arxiv.org/abs/2601.02813v2","updated":"2026-01-07T06:28:16Z","published":"2026-01-06T08:40:55Z","title":"HAL: Inducing Human-likeness in LLMs with Alignment","summary":"Conversational human-likeness plays a central role in human-AI interaction, yet it has remained difficult to define, measure, and optimize. As a result, improvements in human-like behavior are largely driven by scale or broad supervised training, rather than targeted alignment. We introduce Human Aligning LLMs (HAL), a framework for aligning language models to conversational human-likeness using an interpretable, data-driven reward. HAL derives explicit conversational traits from contrastive dialogue data, combines them into a compact scalar score, and uses this score as a transparent reward signal for alignment with standard preference optimization methods. Using this approach, we align models of varying sizes without affecting their overall performance. In large-scale human evaluations, models aligned with HAL are more frequently perceived as human-like in conversation. Because HAL operates over explicit, interpretable traits, it enables inspection of alignment behavior and diagnosis of unintended effects. More broadly, HAL demonstrates how soft, qualitative properties of language--previously outside the scope for alignment--can be made measurable and aligned in an interpretable and explainable way.","authors":["Masum Hasan","Junjie Zhao","Ehsan Hoque"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03634v1","updated":"2026-01-07T06:25:40Z","published":"2026-01-07T06:25:40Z","title":"Kantorovich-Type Stochastic Neural Network Operators for the Mean-Square Approximation of Certain Second-Order Stochastic Processes","summary":"Artificial neural network operators (ANNOs) have been widely used for approximating deterministic input-output functions; however, their extension to random dynamics remains comparatively unexplored. In this paper, we construct a new class of \\textbf{Kantorovich-type Stochastic Neural Network Operators (K-SNNOs)} in which randomness is incorporated not at the coefficient level, but through \\textbf{stochastic neurons} driven by stochastic integrators. This framework enables the operator to inherit the probabilistic structure of the underlying process, making it suitable for modeling and approximating stochastic signals. We establish mean-square convergence of K-SNNOs to the target stochastic process and derive quantitative error estimates expressing the rate of approximation in terms of the modulus of continuity. Numerical simulations further validate the theoretical results by demonstrating accurate reconstruction of sample paths and rapid decay of the mean square error (MSE). Graphical results, including sample-wise approximations and empirical MSE behaviour, illustrate the robustness and effectiveness of the proposed stochastic-neuron-based operator.","authors":["Sachin Saini","Uaday Singh"],"pdf_url":"","comment":"18 Pages, 7 Figures"},{"id":"http://arxiv.org/abs/2601.03629v1","updated":"2026-01-07T06:19:04Z","published":"2026-01-07T06:19:04Z","title":"Learning Shortest Paths When Data is Scarce","summary":"Digital twins and other simulators are increasingly used to support routing decisions in large-scale networks. However, simulator outputs often exhibit systematic bias, while ground-truth measurements are costly and scarce. We study a stochastic shortest-path problem in which a planner has access to abundant synthetic samples, limited real-world observations, and an edge-similarity structure capturing expected behavioral similarity across links. We model the simulator-to-reality discrepancy as an unknown, edge-specific bias that varies smoothly over the similarity graph, and estimate it using Laplacian-regularized least squares. This approach yields calibrated edge cost estimates even in data-scarce regimes. We establish finite-sample error bounds, translate estimation error into path-level suboptimality guarantees, and propose a computable, data-driven certificate that verifies near-optimality of a candidate route. For cold-start settings without initial real data, we develop a bias-aware active learning algorithm that leverages the simulator and adaptively selects edges to measure until a prescribed accuracy is met. Numerical experiments on multiple road networks and traffic graphs further demonstrate the effectiveness of our methods.","authors":["Dmytro Matsypura","Yu Pan","Hanzhao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.24067v2","updated":"2026-01-07T06:16:53Z","published":"2025-03-31T13:26:24Z","title":"TransMamba: A Sequence-Level Hybrid Transformer-Mamba Language Model","summary":"Transformers are the cornerstone of modern large language models, but their quadratic computational complexity limits efficiency in long-sequence processing. Recent advancements in Mamba, a state space model (SSM) with linear complexity, offer promising efficiency gains but suffer from unstable contextual learning and multitask generalization. Some works conduct layer-level hybrid structures that combine Transformer and Mamba layers, aiming to make full use of both advantages. This paper proposes TransMamba, a novel sequence-level hybrid framework that unifies Transformer and Mamba through shared parameter matrices (QKV and CBx), and thus could dynamically switch between attention and SSM mechanisms at different token lengths and layers. We design the Memory Converter to bridge Transformer and Mamba by converting attention outputs into SSM-compatible states, ensuring seamless information flow at TransPoints where the transformation happens. The TransPoint scheduling is also thoroughly explored for balancing effectiveness and efficiency. We conducted extensive experiments demonstrating that TransMamba achieves superior training efficiency and performance compared to single and hybrid baselines, and validated the deeper consistency between Transformer and Mamba paradigms at sequence level, offering a scalable solution for next-generation language modeling. Code and data are available at https://github.com/Yixing-Li/TransMamba","authors":["Yixing Li","Ruobing Xie","Zhen Yang","Xingwu Sun","Shuaipeng Li","Weidong Han","Zhanhui Kang","Yu Cheng","Chengzhong Xu","Di Wang","Jie Jiang"],"pdf_url":"","comment":"Accepted by AAAI 2026. Code: https://github.com/Yixing-Li/TransMamba"},{"id":"http://arxiv.org/abs/2508.18609v3","updated":"2026-01-07T06:14:48Z","published":"2025-08-26T02:24:55Z","title":"Task-Stratified Knowledge Scaling Laws for Post-Training Quantized Large Language Models","summary":"Post-Training Quantization (PTQ) is a critical strategy for efficient Large Language Models (LLMs) deployment. However, existing scaling laws primarily focus on general performance, overlooking crucial fine-grained factors and how quantization differentially impacts diverse knowledge capabilities. To address this, we establish Task-Stratified Knowledge Scaling Laws. By stratifying capabilities into memorization, application, and reasoning, we develop a framework that unifies model size, bit-width, and fine-grained factors: group size and calibration set size. Validated on 293 diverse PTQ configurations, our framework demonstrates strong fit and cross-architecture consistency. It reveals distinct sensitivities across knowledge capabilities: reasoning is precision-critical, application is scale-responsive, and memorization is calibration-sensitive. We highlight that in low-bit scenarios, optimizing these fine-grained factors is essential for preventing performance collapse. These findings provide an empirically-backed foundation for designing knowledge-aware quantization strategies.","authors":["Chenxi Zhou","Pengfei Cao","Jiang Li","Bohan Yu","Jinyu Ye","Jun Zhao","Kang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03626v1","updated":"2026-01-07T06:12:48Z","published":"2026-01-07T06:12:48Z","title":"Learning from Limited Labels: Transductive Graph Label Propagation for Indian Music Analysis","summary":"Supervised machine learning frameworks rely on extensive labeled datasets for robust performance on real-world tasks. However, there is a lack of large annotated datasets in audio and music domains, as annotating such recordings is resource-intensive, laborious, and often require expert domain knowledge. In this work, we explore the use of label propagation (LP), a graph-based semi-supervised learning technique, for automatically labeling the unlabeled set in an unsupervised manner. By constructing a similarity graph over audio embeddings, we propagate limited label information from a small annotated subset to a larger unlabeled corpus in a transductive, semi-supervised setting. We apply this method to two tasks in Indian Art Music (IAM): Raga identification and Instrument classification. For both these tasks, we integrate multiple public datasets along with additional recordings we acquire from Prasar Bharati Archives to perform LP. Our experiments demonstrate that LP significantly reduces labeling overhead and produces higher-quality annotations compared to conventional baseline methods, including those based on pretrained inductive models. These results highlight the potential of graph-based semi-supervised learning to democratize data annotation and accelerate progress in music information retrieval.","authors":["Parampreet Singh","Akshay Raina","Sayeedul Islam Sheikh","Vipul Arora"],"pdf_url":"","comment":"Published at Journal of Acoustical Society of India, 2025"},{"id":"http://arxiv.org/abs/2511.06294v3","updated":"2026-01-07T06:09:09Z","published":"2025-11-09T09:12:50Z","title":"Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention","summary":"Recent advances in Transformer-based Neural Operators have enabled significant progress in data-driven solvers for Partial Differential Equations (PDEs). Most current research has focused on reducing the quadratic complexity of attention to address the resulting low training and inference efficiency. Among these works, Transolver stands out as a representative method that introduces Physics-Attention to reduce computational costs. Physics-Attention projects grid points into slices for slice attention, then maps them back through deslicing. However, we observe that Physics-Attention can be reformulated as a special case of linear attention, and that the slice attention may even hurt the model performance. Based on these observations, we argue that its effectiveness primarily arises from the slice and deslice operations rather than interactions between slices. Building on this insight, we propose a two-step transformation to redesign Physics-Attention into a canonical linear attention, which we call Linear Attention Neural Operator (LinearNO). Our method achieves state-of-the-art performance on six standard PDE benchmarks, while reducing the number of parameters by an average of 40.0% and computational cost by 36.2%. Additionally, it delivers superior performance on two challenging, industrial-level datasets: AirfRANS and Shape-Net Car.","authors":["Wenjie Hu","Sidun Liu","Peng Qiao","Zhenglun Sun","Yong Dou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03617v1","updated":"2026-01-07T05:57:19Z","published":"2026-01-07T05:57:19Z","title":"Systematic Evaluation of Depth Backbones and Semantic Cues for Monocular Pseudo-LiDAR 3D Detection","summary":"Monocular 3D object detection offers a low-cost alternative to LiDAR, yet remains less accurate due to the difficulty of estimating metric depth from a single image. We systematically evaluate how depth backbones and feature engineering affect a monocular Pseudo-LiDAR pipeline on the KITTI validation split. Specifically, we compare NeWCRFs (supervised metric depth) against Depth Anything V2 Metric-Outdoor (Base) under an identical pseudo-LiDAR generation and PointRCNN detection protocol. NeWCRFs yields stronger downstream 3D detection, achieving 10.50\\% AP$_{3D}$ at IoU$=0.7$ on the Moderate split using grayscale intensity (Exp~2). We further test point-cloud augmentations using appearance cues (grayscale intensity) and semantic cues (instance segmentation confidence). Contrary to the expectation that semantics would substantially close the gap, these features provide only marginal gains, and mask-based sampling can degrade performance by removing contextual geometry. Finally, we report a depth-accuracy-versus-distance diagnostic using ground-truth 2D boxes (including Ped/Cyc), highlighting that coarse depth correctness does not fully predict strict 3D IoU. Overall, under an off-the-shelf LiDAR detector, depth-backbone choice and geometric fidelity dominate performance, outweighing secondary feature injection.","authors":["Samson Oseiwe Ajadalu"],"pdf_url":"","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.03612v1","updated":"2026-01-07T05:40:09Z","published":"2026-01-07T05:40:09Z","title":"Mathematical Foundations of Polyphonic Music Generation via Structural Inductive Bias","summary":"This monograph introduces a novel approach to polyphonic music generation by addressing the \"Missing Middle\" problem through structural inductive bias. Focusing on Beethoven's piano sonatas as a case study, we empirically verify the independence of pitch and hand attributes using normalized mutual information (NMI=0.167) and propose the Smart Embedding architecture, achieving a 48.30% reduction in parameters. We provide rigorous mathematical proofs using information theory (negligible loss bounded at 0.153 bits), Rademacher complexity (28.09% tighter generalization bound), and category theory to demonstrate improved stability and generalization. Empirical results show a 9.47% reduction in validation loss, confirmed by SVD analysis and an expert listening study (N=53). This dual theoretical and applied framework bridges gaps in AI music generation, offering verifiable insights for mathematically grounded deep learning.","authors":["Joonwon Seo"],"pdf_url":"","comment":"Monograph. Code available at https://github.com/Chooseredone/Smart-Embedding-Music-Generation"},{"id":"http://arxiv.org/abs/2601.03606v1","updated":"2026-01-07T05:35:16Z","published":"2026-01-07T05:35:16Z","title":"Policy-Guided Search on Tree-of-Thoughts for Efficient Problem Solving with Bounded Language Model Queries","summary":"Recent studies explored integrating state-space search algorithms with Language Models (LM) to perform look-ahead on the token generation process, the ''Tree-of-Thoughts'' (ToT), generated by LMs, thereby improving performance on problem-solving tasks. However, the affiliated search algorithms often overlook the significant computational costs associated with LM inference, particularly in scenarios with constrained computational budgets. Consequently, we address the problem of improving LM performance on problem-solving tasks under limited computational budgets. We demonstrate how the probabilities assigned to thoughts by LMs can serve as a heuristic to guide search within the ToT framework, thereby reducing the number of thought evaluations. Building on this insight, we adapt a heuristic search algorithm, Levin Tree Search (LTS), to the ToT framework, which leverages LMs as policies to guide the tree exploration efficiently. We extend the theoretical results of LTS by showing that, for ToT (a pruned tree), LTS guarantees a bound on the number of states expanded, and consequently, on the number of thoughts generated. Additionally, we analyze the sensitivity of this bound to the temperature values commonly used in the final softmax layer of the LM. Empirical evaluation under a fixed LM query budget demonstrates that LTS consistently achieves comparable or higher accuracy than baseline search algorithms within the ToT framework, across three domains (Blocksworld, PrOntoQA, Array Sorting) and four distinct LMs. These findings highlight the efficacy of LTS on ToT, particularly in enabling cost-effective and time-efficient problem-solving, making it well-suited for latency-critical and resource-constrained applications.","authors":["Sumedh Pendurkar","Guni Sharon"],"pdf_url":"","comment":"Published in Transactions on Machine Learning Research (TMLR), 2025. Available at https://openreview.net/forum?id=Rlk1bWe2ii"},{"id":"http://arxiv.org/abs/2601.03603v1","updated":"2026-01-07T05:33:00Z","published":"2026-01-07T05:33:00Z","title":"A Comparative Study of Traditional Machine Learning, Deep Learning, and Large Language Models for Mental Health Forecasting using Smartphone Sensing Data","summary":"Smartphone sensing offers an unobtrusive and scalable way to track daily behaviors linked to mental health, capturing changes in sleep, mobility, and phone use that often precede symptoms of stress, anxiety, or depression. While most prior studies focus on detection that responds to existing conditions, forecasting mental health enables proactive support through Just-in-Time Adaptive Interventions. In this paper, we present the first comprehensive benchmarking study comparing traditional machine learning (ML), deep learning (DL), and large language model (LLM) approaches for mental health forecasting using the College Experience Sensing (CES) dataset, the most extensive longitudinal dataset of college student mental health to date. We systematically evaluate models across temporal windows, feature granularities, personalization strategies, and class imbalance handling. Our results show that DL models, particularly Transformer (Macro-F1 = 0.58), achieve the best overall performance, while LLMs show strength in contextual reasoning but weaker temporal modeling. Personalization substantially improves forecasts of severe mental health states. By revealing how different modeling approaches interpret phone sensing behavioral data over time, this work lays the groundwork for next-generation, adaptive, and human-centered mental health technologies that can advance both research and real-world well-being.","authors":["Kaidong Feng","Zhu Sun","Roy Ka-Wei Lee","Xun Jiang","Yin-Leng Theng","Yi Ding"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03600v1","updated":"2026-01-07T05:30:53Z","published":"2026-01-07T05:30:53Z","title":"ALERT: Zero-shot LLM Jailbreak Detection via Internal Discrepancy Amplification","summary":"Despite rich safety alignment strategies, large language models (LLMs) remain highly susceptible to jailbreak attacks, which compromise safety guardrails and pose serious security risks. Existing detection methods mainly detect jailbreak status relying on jailbreak templates present in the training data. However, few studies address the more realistic and challenging zero-shot jailbreak detection setting, where no jailbreak templates are available during training. This setting better reflects real-world scenarios where new attacks continually emerge and evolve. To address this challenge, we propose a layer-wise, module-wise, and token-wise amplification framework that progressively magnifies internal feature discrepancies between benign and jailbreak prompts. We uncover safety-relevant layers, identify specific modules that inherently encode zero-shot discriminative signals, and localize informative safety tokens. Building upon these insights, we introduce ALERT (Amplification-based Jailbreak Detector), an efficient and effective zero-shot jailbreak detector that introduces two independent yet complementary classifiers on amplified representations. Extensive experiments on three safety benchmarks demonstrate that ALERT achieves consistently strong zero-shot detection performance. Specifically, (i) across all datasets and attack strategies, ALERT reliably ranks among the top two methods, and (ii) it outperforms the second-best baseline by at least 10% in average Accuracy and F1-score, and sometimes by up to 40%.","authors":["Xiao Lin","Philip Li","Zhichen Zeng","Tingwei Li","Tianxin Wei","Xuying Ning","Gaotang Li","Yuzhong Chen","Hanghang Tong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03584v1","updated":"2026-01-07T04:58:18Z","published":"2026-01-07T04:58:18Z","title":"Local Gradient Regulation Stabilizes Federated Learning under Client Heterogeneity","summary":"Federated learning (FL) enables collaborative model training across distributed clients without sharing raw data, yet its stability is fundamentally challenged by statistical heterogeneity in realistic deployments. Here, we show that client heterogeneity destabilizes FL primarily by distorting local gradient dynamics during client-side optimization, causing systematic drift that accumulates across communication rounds and impedes global convergence. This observation highlights local gradients as a key regulatory lever for stabilizing heterogeneous FL systems. Building on this insight, we develop a general client-side perspective that regulates local gradient contributions without incurring additional communication overhead. Inspired by swarm intelligence, we instantiate this perspective through Exploratory--Convergent Gradient Re-aggregation (ECGR), which balances well-aligned and misaligned gradient components to preserve informative updates while suppressing destabilizing effects. Theoretical analysis and extensive experiments, including evaluations on the LC25000 medical imaging dataset, demonstrate that regulating local gradient dynamics consistently stabilizes federated learning across state-of-the-art methods under heterogeneous data distributions.","authors":["Ping Luo","Jiahuan Wang","Ziqing Wen","Tao Sun","Dongsheng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21451v2","updated":"2026-01-07T04:54:59Z","published":"2025-12-25T00:18:41Z","title":"An approach to Fisher-Rao metric for infinite dimensional non-parametric information geometry","summary":"Being infinite dimensional, non-parametric information geometry has long faced an \"intractability barrier\" due to the fact that the Fisher-Rao metric is now a functional incurring difficulties in defining its inverse. This paper introduces a novel framework to resolve the intractability with an Orthogonal Decomposition of the Tangent Space ($T_fM = S \\oplus S^{\\perp}$), where $S$ represents an observable covariate subspace. Through the decomposition, we derive the Covariate Fisher Information Matrix (cFIM), denoted as ${\\bf G}_f$, which is a finite-dimensional and computable representative of information extractable from the manifold's geometry. Significantly, by proving the Trace Theorem: $H_G(f) = \\text{Tr}({\\bf G}_f)$, we establish a rigorous foundation for the G-entropy previously introduced by us, thereby identifying it as a fundamental geometric invariant representing the total explainable statistical information captured by the probability distribution associated with a model. Furthermore, we establish a link between ${\\bf G}_f$ and the second derivative (i.e. the curvature) of the KL-divergence, leading to the notion of Covariate Cramér-Rao Lower Bound(CRLB). We demonstrate that ${\\bf G}_f$ is congruent to the Efficient Fisher Information Matrix, thereby providing fundamental limits of variance for semi-parametric estimators. Finally, we apply our geometric framework to the Manifold Hypothesis, lifting the latter from a heuristic assumption into a testable condition of rank-deficiency within the cFIM. By defining the Information Capture Ratio, we provide a rigorous method for estimating intrinsic dimensionality in high-dimensional data. In short, our work bridges the gap between abstract information geometry and the demand of explainable AI, by providing a tractable path for assessing the statistical coverage and the efficiency of non-parametric models.","authors":["Bing Cheng","Howell Tong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03577v1","updated":"2026-01-07T04:45:07Z","published":"2026-01-07T04:45:07Z","title":"Variational Inference, Entropy, and Orthogonality: A Unified Theory of Mixture-of-Experts","summary":"Mixture-of-Experts models enable large language models to scale efficiently, as they only activate a subset of experts for each input. Their core mechanisms, Top-k routing and auxiliary load balancing, remain heuristic, however, lacking a cohesive theoretical underpinning to support them. To this end, we build the first unified theoretical framework that rigorously derives these practices as optimal sparse posterior approximation and prior regularization from a Bayesian perspective, while simultaneously framing them as mechanisms to minimize routing ambiguity and maximize channel capacity from an information-theoretic perspective. We also pinpoint the inherent combinatorial hardness of routing, defining it as the NP-hard sparse subset selection problem. We rigorously prove the existence of a \"Coherence Barrier\"; when expert representations exhibit high mutual coherence, greedy routing strategies theoretically fail to recover the optimal expert subset. Importantly, we formally verify that imposing geometric orthogonality in the expert feature space is sufficient to narrow the divide between the NP-hard global optimum and polynomial-time greedy approximation. Our comparative analyses confirm orthogonality regularization as the optimal engineering relaxation for large-scale models. Our work offers essential theoretical support and technical assurance for a deeper understanding and novel designs of MoE.","authors":["Ye Su","Yong Liu"],"pdf_url":"","comment":"27 pages, 3 figures"},{"id":"http://arxiv.org/abs/2506.12227v2","updated":"2026-01-07T04:43:38Z","published":"2025-06-13T21:04:03Z","title":"Uncovering Bias Paths with LLM-guided Causal Discovery: An Active Learning and Dynamic Scoring Approach","summary":"Ensuring fairness in machine learning requires understanding how sensitive attributes like race or gender causally influence outcomes. Existing causal discovery (CD) methods often struggle to recover fairness-relevant pathways in the presence of noise, confounding, or data corruption. Large language models (LLMs) offer a complementary signal by leveraging semantic priors from variable metadata. We propose a hybrid LLM-guided CD framework that extends a breadth-first search strategy with active learning and dynamic scoring. Variable pairs are prioritized for querying using a composite score combining mutual information, partial correlation, and LLM confidence, enabling more efficient and robust structure discovery. To evaluate fairness sensitivity, we introduce a semi-synthetic benchmark based on the UCI Adult dataset, embedding domain-informed bias pathways alongside noise and latent confounders. We assess how well CD methods recover both global graph structure and fairness-critical paths (e.g., sex-->education-->income). Our results demonstrate that LLM-guided methods, including our active, dynamically scored variant, outperform baselines in recovering fairness-relevant structure under noisy conditions. We analyze when LLM-driven insights complement statistical dependencies and discuss implications for fairness auditing in high-stakes domains.","authors":["Khadija Zanna","Akane Sano"],"pdf_url":"","comment":"To be presented at AAAI 2026"},{"id":"http://arxiv.org/abs/2510.11184v2","updated":"2026-01-07T04:36:05Z","published":"2025-10-13T09:19:13Z","title":"Reinforcement Learning for Tool-Integrated Interleaved Thinking towards Cross-Domain Generalization","summary":"Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in reasoning and tool utilization. However, the generalization of tool-augmented reinforcement learning (RL) across diverse domains remains a significant challenge. Standard paradigms often treat tool usage as a linear or isolated event, which becomes brittle when transferring skills from restricted domains (e.g., mathematics) to open-ended tasks. In this work, we investigate the cross-domain generalization of an LLM agent trained exclusively on mathematical problem-solving. To facilitate robust skill transfer, we propose a {\\textbf{R}einforcement Learning for \\textbf{I}nterleaved \\textbf{T}ool \\textbf{E}xecution (RITE)}. Unlike traditional methods, RITE enforces a continuous ``Plan-Action-Reflection'' cycle, allowing the model to ground its reasoning in intermediate tool outputs and self-correct during long-horizon tasks. To effectively train this complex interleaved policy, we introduce {Dr. GRPO}, a robust optimization objective that utilizes token-level loss aggregation with importance sampling to mitigate reward sparsity and high-variance credit assignment. Furthermore, we employ a dual-component reward system and dynamic curriculum via online rollout filtering to ensure structural integrity and sample efficiency. Extensive experiments reveal that our approach, despite being trained solely on math tasks, achieves state-of-the-art performance across diverse reasoning domains, demonstrating high token efficiency and strong generalization capabilities.","authors":["Zhengyu Chen","Jinluan Yang","Teng Xiao","Ruochen Zhou","Luan Zhang","Xiangyu Xi","Xiaowei Shi","Wei Wang","Jinggang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03569v1","updated":"2026-01-07T04:29:05Z","published":"2026-01-07T04:29:05Z","title":"Local Intrinsic Dimensionality of Ground Motion Data for Early Detection of Complex Catastrophic Slope Failure","summary":"Local Intrinsic Dimensionality (LID) has shown strong potential for identifying anomalies and outliers in high-dimensional data across a wide range of real-world applications, including landslide failure detection in granular media. Early and accurate identification of failure zones in landslide-prone areas is crucial for effective geohazard mitigation. While existing approaches typically rely on surface displacement data analyzed through statistical or machine learning techniques, they often fall short in capturing both the spatial correlations and temporal dynamics that are inherent in such data. To address this gap, we focus on ground-monitored landslides and introduce a novel approach that jointly incorporates spatial and temporal information, enabling the detection of complex landslides and including multiple successive failures occurring in distinct areas of the same slope. To be specific, our method builds upon an existing LID-based technique, known as sLID. We extend its capabilities in three key ways. (1) Kinematic enhancement: we incorporate velocity into the sLID computation to better capture short-term temporal dependencies and deformation rate relationships. (2) Spatial fusion: we apply Bayesian estimation to aggregate sLID values across spatial neighborhoods, effectively embedding spatial correlations into the LID scores. (3) Temporal modeling: we introduce a temporal variant, tLID, that learns long-term dynamics from time series data, providing a robust temporal representation of displacement behavior. Finally, we integrate both components into a unified framework, referred to as spatiotemporal LID (stLID), to identify samples that are anomalous in either or both dimensions. Extensive experiments show that stLID consistently outperforms existing methods in failure detection precision and lead-time.","authors":["Yuansan Liu","Antoinette Tordesillas","James Bailey"],"pdf_url":"","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2507.18937v2","updated":"2026-01-07T04:27:51Z","published":"2025-07-25T04:19:05Z","title":"CNN-based Surface Temperature Forecasts with Ensemble Numerical Weather Prediction over Medium-range Forecast Periods","summary":"In this study, a method that integrates convolutional neural networks (CNNs) with ensemble numerical weather prediction (NWP) models is proposed. This method enables surface temperature forecasting with lead times beyond the short-range, extending up to five days. Due to limited computational resources, operational medium-range temperature forecasts typically rely on low-resolution NWP models, which are prone to systematic and random errors. To resolve these limitations, the proposed method applies CNN-based post-processing (bias correction and spatial super-resolution) to an ensemble NWP system. First, the post-processing is applied to each ensemble member to reduce systematic errors and reconstruct high-resolution temperature fields from low-resolution model outputs. This approach reduces the systematic and random errors in NWP model outputs and outperforms operational post-processing. Second, the CNN is applied to all ensemble members to construct a new ensemble forecasting system, in which deterministic forecast accuracy, probabilistic reliability, and representation of ensemble spread are improved compared with those of the original system. We demonstrate that this CNN-based post-processing is fundamentally different from the artificial error reduction caused by smoothing inherent in ensemble averaging because the post-processing reduces forecast errors without degrading the forecast information. These results indicate that the proposed method provides a practical and scalable solution for improving medium-range temperature forecasts and is particularly valuable for use in operational centers with limited computational resources.","authors":["Takuya Inoue","Takuya Kawabata"],"pdf_url":"","comment":"41 pages, 12 figures"},{"id":"http://arxiv.org/abs/2509.21042v2","updated":"2026-01-07T04:26:09Z","published":"2025-09-25T11:48:24Z","title":"LayerNorm Induces Recency Bias in Transformer Decoders","summary":"Causal self-attention provides positional information to Transformer decoders. Prior work has shown that stacks of causal self-attention layers alone induce a positional bias in attention scores toward earlier tokens. However, this differs from the bias toward later tokens typically observed in Transformer decoders, known as recency bias. We address this discrepancy by analyzing the interaction between causal self-attention and other architectural components. We show that stacked causal self-attention layers combined with LayerNorm induce recency bias. Furthermore, we examine the effects of residual connections and the distribution of input token embeddings on this bias. Our results provide new theoretical insights into how positional information interacts with architectural components and suggest directions for improving positional encoding strategies.","authors":["Junu Kim","Xiao Liu","Zhenghao Lin","Lei Ji","Yeyun Gong","Edward Choi"],"pdf_url":"","comment":"Codes available at: https://github.com/starmpcc/layernorm_recency_bias"},{"id":"http://arxiv.org/abs/2601.03566v1","updated":"2026-01-07T04:25:33Z","published":"2026-01-07T04:25:33Z","title":"Provably Convergent Decentralized Optimization over Directed Graphs under Generalized Smoothness","summary":"Decentralized optimization has become a fundamental tool for large-scale learning systems; however, most existing methods rely on the classical Lipschitz smoothness assumption, which is often violated in problems with rapidly varying gradients. Motivated by this limitation, we study decentralized optimization under the generalized $(L_0, L_1)$-smoothness framework, in which the Hessian norm is allowed to grow linearly with the gradient norm, thereby accommodating rapidly varying gradients beyond classical Lipschitz smoothness. We integrate gradient-tracking techniques with gradient clipping and carefully design the clipping threshold to ensure accurate convergence over directed communication graphs under generalized smoothness. In contrast to existing distributed optimization results under generalized smoothness that require a bounded gradient dissimilarity assumption, our results remain valid even when the gradient dissimilarity is unbounded, making the proposed framework more applicable to realistic heterogeneous data environments. We validate our approach via numerical experiments on standard benchmark datasets, including LIBSVM and CIFAR-10, using regularized logistic regression and convolutional neural networks, demonstrating superior stability and faster convergence over existing methods.","authors":["Yanan Bo","Yongqiang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03565v1","updated":"2026-01-07T04:23:47Z","published":"2026-01-07T04:23:47Z","title":"A Proposed Paradigm for Imputing Missing Multi-Sensor Data in the Healthcare Domain","summary":"Chronic diseases such as diabetes pose significant management challenges, particularly due to the risk of complications like hypoglycemia, which require timely detection and intervention. Continuous health monitoring through wearable sensors offers a promising solution for early prediction of glycemic events. However, effective use of multisensor data is hindered by issues such as signal noise and frequent missing values. This study examines the limitations of existing datasets and emphasizes the temporal characteristics of key features relevant to hypoglycemia prediction. A comprehensive analysis of imputation techniques is conducted, focusing on those employed in state-of-the-art studies. Furthermore, imputation methods derived from machine learning and deep learning applications in other healthcare contexts are evaluated for their potential to address longer gaps in time-series data. Based on this analysis, a systematic paradigm is proposed, wherein imputation strategies are tailored to the nature of specific features and the duration of missing intervals. The review concludes by emphasizing the importance of investigating the temporal dynamics of individual features and the implementation of multiple, feature-specific imputation techniques to effectively address heterogeneous temporal patterns inherent in the data.","authors":["Vaibhav Gupta","Florian Grensing","Beyza Cinar","Maria Maleshkova"],"pdf_url":"","comment":"21 Pages, 6 Figures, 7 Tables"},{"id":"http://arxiv.org/abs/2510.06640v2","updated":"2026-01-07T04:15:51Z","published":"2025-10-08T04:46:11Z","title":"A Comparative Analysis of Contextual Representation Flow in State-Space and Transformer Architectures","summary":"State Space Models (SSMs) have recently emerged as efficient alternatives to Transformer-Based Models (TBMs) for long-sequence processing with linear scaling, yet how contextual information flows across layers in these architectures remains understudied. We present the first unified, token- and layer-wise analysis of representation propagation in SSMs and TBMs. Using centered kernel alignment, variance-based metrics, and probing, we characterize how representations evolve within and across layers. We find a key divergence: TBMs rapidly homogenize token representations, with diversity reemerging only in later layers, while SSMs preserve token uniqueness early but converge to homogenization deeper. Theoretical analysis and parameter randomization further reveal that oversmoothing in TBMs stems from architectural design, whereas in SSMs, it arises mainly from training dynamics. These insights clarify the inductive biases of both architectures and inform future model and training designs for long-context reasoning.","authors":["Nhat M. Hoang","Do Xuan Long","Cong-Duy Nguyen","Min-Yen Kan","Luu Anh Tuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03561v1","updated":"2026-01-07T04:01:25Z","published":"2026-01-07T04:01:25Z","title":"Green's-Function Spherical Neural Operators for Biological Heterogeneity","summary":"Spherical deep learning has been widely applied to a broad range of real-world problems. Existing approaches often face challenges in balancing strong spherical geometric inductive biases with the need to model real-world heterogeneity. To solve this while retaining spherical geometry, we first introduce a designable Green's function framework (DGF) to provide new spherical operator solution strategy: Design systematic Green's functions under rotational group. Based on DGF, to model biological heterogeneity, we propose Green's-Function Spherical Neural Operator (GSNO) fusing 3 operator solutions: (1) Equivariant Solution derived from Equivariant Green's Function for symmetry-consistent modeling; (2) Invariant Solution derived from Invariant Green's Function to eliminate nuisance heterogeneity, e.g., consistent background field; (3) Anisotropic Solution derived from Anisotropic Green's Function to model anisotropic systems, especially fibers with preferred direction. Therefore, the resulting model, GSNO can adapt to real-world heterogeneous systems with nuisance variability and anisotropy while retaining spectral efficiency. Evaluations on spherical MNIST, Shallow Water Equation, diffusion MRI fiber prediction, cortical parcellation and molecule structure modeling demonstrate the superiority of GSNO.","authors":["Hao Tang","Hao Chen","Hao Li","Chao Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.03178v3","updated":"2026-01-07T03:50:11Z","published":"2025-03-05T04:48:14Z","title":"Active operator learning with predictive uncertainty quantification for partial differential equations","summary":"With the increased prevalence of neural operators being used to provide rapid solutions to partial differential equations (PDEs), understanding the accuracy of model predictions and the associated error levels is necessary for deploying reliable surrogate models in scientific applications. Existing uncertainty quantification (UQ) frameworks employ ensembles or Bayesian methods, which can incur substantial computational costs during both training and inference. We propose a lightweight predictive UQ method tailored for Deep operator networks (DeepONets) that also generalizes to other operator networks. Numerical experiments on linear and nonlinear PDEs demonstrate that the framework's uncertainty estimates are unbiased and provide accurate out-of-distribution uncertainty predictions with a sufficiently large training dataset. Our framework provides fast inference and uncertainty estimates that can efficiently drive outer-loop analyses that would be prohibitively expensive with conventional solvers. We demonstrate how predictive uncertainties can be used in the context of Bayesian optimization and active learning problems to yield improvements in accuracy and data-efficiency for outer-loop optimization procedures. In the active learning setup, we extend the framework to Fourier Neural Operators (FNO) and describe a generalized method for other operator networks. To enable real-time deployment, we introduce an inference strategy based on precomputed trunk outputs and a sparse placement matrix, reducing evaluation time by more than a factor of five. Our method provides a practical route to uncertainty-aware operator learning in time-sensitive settings.","authors":["Nick Winovich","Mitchell Daneker","Lu Lu","Guang Lin"],"pdf_url":"","comment":"Submitted to the Journal of Computational Physics"},{"id":"http://arxiv.org/abs/2601.00834v2","updated":"2026-01-07T03:43:58Z","published":"2025-12-26T12:41:05Z","title":"Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds","summary":"Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the continuous parametric domain. By embedding the Riemannian metric tensor into the automatic differentiation graph, our architecture analytically reconstructs the Laplace-Beltrami operator, decoupling solution complexity from geometric discretization. We validate the framework on a \"Stochastic Cloth\" manifold with extreme Gaussian curvature fluctuations ($K \\in [-2489, 3580]$), where traditional adaptive refinement fails to resolve anisotropic Turing instabilities. Using a dual-stream architecture with Fourier feature embeddings to mitigate spectral bias, the IM-PINN recovers the \"splitting spot\" and \"labyrinthine\" regimes of the Gray-Scott model. Benchmarking against the Surface Finite Element Method (SFEM) reveals superior physical rigor: the IM-PINN achieves global mass conservation error of $\\mathcal{E}_{mass} \\approx 0.157$ versus SFEM's $0.258$, acting as a thermodynamically consistent global solver that eliminates mass drift inherent in semi-implicit integration. The framework offers a memory-efficient, resolution-independent paradigm for simulating biological pattern formation on evolving surfaces, bridging differential geometry and physics-informed machine learning.","authors":["Julian Evan Chrisnanto","Salsabila Rahma Alia","Nurfauzi Fadillah","Yulison Herry Chrisnanto"],"pdf_url":"","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.09149v2","updated":"2026-01-07T03:39:11Z","published":"2025-11-12T09:37:22Z","title":"Enabling Agents to Communicate Entirely in Latent Space","summary":"While natural language is the de facto communication medium for LLM-based agents, it presents a fundamental constraint. The process of downsampling rich, internal latent states into discrete tokens inherently limits the depth and nuance of information that can be transmitted, thereby hindering collaborative problem-solving. Inspired by telepathy, which bypasses symbolic language in communication, we propose Interlat (Inter-agent Latent Space Communication), a paradigm that leverages the continuous last hidden states of an LLM as a representation of its thought for direct communication (termed latent communication). An additional learned compression process further compresses latent communication via latent space reasoning. Experiments demonstrate that Interlat outperforms both fine-tuned chain-of-thought (CoT) prompting and single-agent baselines, even across heterogeneous models, promoting more exploratory behavior and enabling genuine utilization of latent information. Further compression not only substantially accelerates inference by up to 24 times but also maintains competitive performance through an efficient information-preserving mechanism. We position this work as a feasibility study of entirely latent space inter-agent communication, and our results highlight its potential, offering valuable insights for future research.","authors":["Zhuoyun Du","Runze Wang","Huiyu Bai","Zouying Cao","Xiaoyong Zhu","Yu Cheng","Bo Zheng","Wei Chen","Haochao Ying"],"pdf_url":"","comment":"Work in progess"},{"id":"http://arxiv.org/abs/2601.03546v1","updated":"2026-01-07T03:30:42Z","published":"2026-01-07T03:30:42Z","title":"Value-Action Alignment in Large Language Models under Privacy-Prosocial Conflict","summary":"Large language models (LLMs) are increasingly used to simulate decision-making tasks involving personal data sharing, where privacy concerns and prosocial motivations can push choices in opposite directions. Existing evaluations often measure privacy-related attitudes or sharing intentions in isolation, which makes it difficult to determine whether a model's expressed values jointly predict its downstream data-sharing actions as in real human behaviors. We introduce a context-based assessment protocol that sequentially administers standardized questionnaires for privacy attitudes, prosocialness, and acceptance of data sharing within a bounded, history-carrying session. To evaluate value-action alignments under competing attitudes, we use multi-group structural equation modeling (MGSEM) to identify relations from privacy concerns and prosocialness to data sharing. We propose Value-Action Alignment Rate (VAAR), a human-referenced directional agreement metric that aggregates path-level evidence for expected signs. Across multiple LLMs, we observe stable but model-specific Privacy-PSA-AoDS profiles, and substantial heterogeneity in value-action alignment.","authors":["Guanyu Chen","Chenxiao Yu","Xiyang Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.09655v3","updated":"2026-01-07T03:24:59Z","published":"2025-05-14T02:02:32Z","title":"DRA-GRPO: Your GRPO Needs to Know Diverse Reasoning Paths for Mathematical Reasoning","summary":"Post-training LLMs with Reinforcement Learning, specifically Group Relative Policy Optimization (GRPO), has emerged as a paradigm for enhancing mathematical reasoning. However, standard GRPO relies on scalar correctness rewards that are often non-injective with respect to semantic content: distinct reasoning paths receive identical rewards. This leads to a Diversity-Quality Inconsistency, where the policy collapses into a narrow set of dominant modes while ignoring equally valid but structurally novel strategies. To bridge this gap, we propose Diversity-aware Reward Adjustment (DRA), a theoretically grounded framework that calibrates the reward signal using the semantic density of sampled groups. By leveraging Submodular Mutual Information (SMI), DRA implements an Inverse Propensity Scoring (IPS) mechanism that effectively de-biases the gradient estimation. This creates a repulsive force against redundancy, driving the policy to achieve better coverage of the high-reward landscape. Our method is plug-and-play and integrates seamlessly with GRPO variants. Empirical evaluations on five math benchmarks demonstrate that DRA-GRPO consistently outperforms strong baselines, achieving an average accuracy of 58.2% on DeepSeek-R1-Distill-Qwen-1.5B with only 7,000 training samples and $55 cost, highlighting the critical role of diversity calibration in data-efficient alignment.","authors":["Xiwen Chen","Wenhui Zhu","Peijie Qiu","Xuanzhao Dong","Hao Wang","Haiyu Wu","Huayu Li","Aristeidis Sotiras","Yalin Wang","Abolfazl Razi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.26519v2","updated":"2026-01-07T03:04:54Z","published":"2025-10-30T14:14:15Z","title":"Think Outside the Policy: In-Context Steered Policy Optimization","summary":"Existing Reinforcement Learning from Verifiable Rewards (RLVR) methods, such as Group Relative Policy Optimization (GRPO), have achieved remarkable progress in improving the reasoning capabilities of Large Reasoning Models (LRMs). However, they exhibit limited exploration due to reliance on on-policy rollouts which are confined to the current policy's distribution, resulting in narrow trajectory diversity. Recent approaches attempt to expand policy coverage by incorporating trajectories generated from stronger expert models, yet this reliance increases computational cost and such advanced models are often inaccessible. To address these issues, we propose In-Context Steered Policy Optimization (ICPO), a unified framework that leverages the inherent in-context learning capability of LRMs to provide expert guidance using existing datasets. ICPO introduces mixed-policy GRPO with implicit expert forcing, which expands exploration beyond the current policy distribution without requiring advanced LRM trajectories. To further stabilize optimization, ICPO integrates expert region reject sampling to filter unreliable off-policy trajectories and annealed expert-bonus reward shaping to balance early expert guidance with later autonomous improvement. Results demonstrate that ICPO consistently enhances RLVR performance and training stability on mathematical reasoning benchmarks, revealing a scalable and effective RLVR paradigm for LRMs. Our code is available at https://anonymous.4open.science/r/ICPO.","authors":["Hsiu-Yuan Huang","Chenming Tang","Weijie Liu","Clive Bai","Saiyong Yang","Yunfang Wu"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2506.02006v2","updated":"2026-01-07T03:04:41Z","published":"2025-05-24T06:12:31Z","title":"MorphServe: Efficient and Workload-Aware LLM Serving via Runtime Quantized Layer Swapping and KV Cache Resizing","summary":"Efficiently serving large language models (LLMs) under dynamic and bursty workloads remains a key challenge for real-world deployment. Existing serving frameworks and static model compression techniques fail to adapt to workload fluctuations, leading to either service-level objective (SLO) violations under full-precision serving or persistent accuracy degradation with static quantization. We present MorphServe, a dynamic, workload-aware LLM serving framework based on morphological adaptation. MorphServe introduces two asynchronous, token-level runtime mechanisms: quantized layer swapping, which selectively replaces less impactful layers with quantized alternatives during high-load periods, and pressure-aware KV cache resizing, which dynamically adjusts KV cache capacity in response to memory pressure. These mechanisms enable state-preserving transitions with minimum runtime overhead and are fully compatible with modern scheduling and attention techniques. Extensive experiments on Vicuna and Llama family models with real-world workloads demonstrate that MorphServe reduces average SLO violations by 92.45 percent and improves the P95 TTFT latency by 2.2x-3.9x compared to full-precision serving, without compromising generation quality. These results establish MorphServe as a practical and elastic solution for LLM deployment in dynamic environments.","authors":["Zhaoyuan Su","Zeyu Zhang","Tingfeng Lan","Zirui Wang","Haiying Shen","Juncheng Yang","Yue Cheng"],"pdf_url":"","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.01223v15","updated":"2026-01-07T03:00:50Z","published":"2024-10-02T04:02:21Z","title":"Statistical Taylor Expansion: A New and Path-Independent Method for Uncertainty Analysis","summary":"As a rigorous statistical approach, statistical Taylor expansion extends the conventional Taylor expansion by replacing precise input variables with random variables of known distributions, to compute means and standard deviations of the results. Statistical Taylor expansion traces the dependency of the input uncertainties in the intermediate steps, so that the variables in the intermediate analytic expressions can no longer be regarded as independent of each other, and the result of the analytic expression is path independent. Thus, it differs fundamentally from the conventional common approaches in applied mathematics which optimize execution path for each calculation. In fact, statistical Taylor expansion may standardize numerical calculations for analytic expressions. Its statistical nature allows religious testing of its result when the sample size is large enough. This paper also introduces an implementation of statistical Taylor expansion called variance arithmetic and presents corresponding test results in a very wide range of mathematical applications.\n  Another important conclusion of this paper is that the numerical errors in the library function can have significant effects on the result. For example, the periodic numerical errors in the trigonometric library functions can resonate with periodic signals, producing large numerical errors in the results.","authors":["Chengpu Wang"],"pdf_url":"","comment":"84 pages, 67 figures"}],"Artificial Intelligence Learning":[{"id":"http://arxiv.org/abs/2601.04191v1","updated":"2026-01-07T18:57:32Z","published":"2026-01-07T18:57:32Z","title":"Embedding Autonomous Agents in Resource-Constrained Robotic Platforms","summary":"Many embedded devices operate under resource constraints and in dynamic environments, requiring local decision-making capabilities. Enabling devices to make independent decisions in such environments can improve the responsiveness of the system and reduce the dependence on constant external control. In this work, we integrate an autonomous agent, programmed using AgentSpeak, with a small two-wheeled robot that explores a maze using its own decision-making and sensor data. Experimental results show that the agent successfully solved the maze in 59 seconds using 287 reasoning cycles, with decision phases taking less than one millisecond. These results indicate that the reasoning process is efficient enough for real-time execution on resource-constrained hardware. This integration demonstrates how high-level agent-based control can be applied to resource-constrained embedded systems for autonomous operation.","authors":["Negar Halakou","Juan F. Gutierrez","Ye Sun","Han Jiang","Xueming Wu","Yilun Song","Andres Gomez"],"pdf_url":"","comment":"This is an open-access, author-archived version of a manuscript published in European Conference on Multi-Agent Systems 2025"},{"id":"http://arxiv.org/abs/2601.04170v1","updated":"2026-01-07T18:37:26Z","published":"2026-01-07T18:37:26Z","title":"Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions","summary":"Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretical framework for understanding drift phenomena, proposing three distinct manifestations: semantic drift (progressive deviation from original intent), coordination drift (breakdown in multi-agent consensus mechanisms), and behavioral drift (emergence of unintended strategies).\n  We introduce the Agent Stability Index (ASI), a novel composite metric framework for quantifying drift across twelve dimensions, including response consistency, tool usage patterns, reasoning pathway stability, and inter-agent agreement rates. Through simulation-based analysis and theoretical modeling, we demonstrate how unchecked agent drift can lead to substantial reductions in task completion accuracy and increased human intervention requirements.\n  We propose three mitigation strategies: episodic memory consolidation, drift-aware routing protocols, and adaptive behavioral anchoring. Theoretical analysis suggests these approaches can significantly reduce drift-related errors while maintaining system throughput. This work establishes a foundational methodology for monitoring, measuring, and mitigating agent drift in production agentic AI systems, with direct implications for enterprise deployment reliability and AI safety research.","authors":["Abhishek Rath"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.04416v2","updated":"2026-01-07T18:33:05Z","published":"2024-12-05T18:42:29Z","title":"FedDUAL: A Dual-Strategy with Adaptive Loss and Dynamic Aggregation for Mitigating Data Heterogeneity in Federated Learning","summary":"Federated Learning (FL) marks a transformative approach to distributed model training by combining locally optimized models from various clients into a unified global model. While FL preserves data privacy by eliminating centralized storage, it encounters significant challenges such as performance degradation, slower convergence, and reduced robustness of the global model due to the heterogeneity in client data distributions. Among the various forms of data heterogeneity, label skew emerges as a particularly formidable and prevalent issue, especially in domains such as image classification. To address these challenges, we begin with comprehensive experiments to pinpoint the underlying issues in the FL training process. Based on our findings, we then introduce an innovative dual-strategy approach designed to effectively resolve these issues. First, we introduce an adaptive loss function for client-side training, meticulously crafted to preserve previously acquired knowledge while maintaining an optimal equilibrium between local optimization and global model coherence. Secondly, we develop a dynamic aggregation strategy for aggregating client models at the server. This approach adapts to each client's unique learning patterns, effectively addressing the challenges of diverse data across the network. Our comprehensive evaluation, conducted across three diverse real-world datasets, coupled with theoretical convergence guarantees, demonstrates the superior efficacy of our method compared to several established state-of-the-art approaches.","authors":["Pranab Sahoo","Ashutosh Tripathi","Sriparna Saha","Samrat Mondal"],"pdf_url":"","comment":"Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2601.04164v1","updated":"2026-01-07T18:25:02Z","published":"2026-01-07T18:25:02Z","title":"Clinical Data Goes MEDS? Let's OWL make sense of it","summary":"The application of machine learning on healthcare data is often hindered by the lack of standardized and semantically explicit representation, leading to limited interoperability and reproducibility across datasets and experiments. The Medical Event Data Standard (MEDS) addresses these issues by introducing a minimal, event-centric data model designed for reproducible machine-learning workflows from health data. However, MEDS is defined as a data-format specification and does not natively provide integration with the Semantic Web ecosystem. In this article, we introduce MEDS-OWL, a lightweight OWL ontology that provides formal concepts and relations to enable representing MEDS datasets as RDF graphs. Additionally, we implemented meds2rdf, a Python conversion library that transforms MEDS events into RDF graphs, ensuring conformance with the ontology. We demonstrate the approach on a synthetic clinical dataset that describes patient care pathways for ruptured intracranial aneurysms and validate the resulting graph using SHACL constraints. The first release of MEDS-OWL comprises 13 classes, 10 object properties, 20 data properties, and 24 OWL axioms. Combined with meds2rdf, it enables data transformation into FAIR-aligned datasets, provenance-aware publishing, and interoperability of event-based clinical data. By bridging MEDS with the Semantic Web, this work contributes a reusable semantic layer for event-based clinical data and establishes a robust foundation for subsequent graph-based analytics.","authors":["Alberto Marfoglia","Jong Ho Jhee","Adrien Coulet"],"pdf_url":"","comment":"12 pages, 5 tables, 4 figures"},{"id":"http://arxiv.org/abs/2411.12460v3","updated":"2026-01-07T18:22:44Z","published":"2024-11-19T12:36:02Z","title":"Exploring Iterative Controllable Summarization with Large Language Models","summary":"Large language models (LLMs) have demonstrated remarkable performance in abstractive summarization tasks. However, their ability to precisely control summary attributes (e.g., length or topic) remains underexplored, limiting their adaptability to specific user preferences. In this paper, we systematically explore the controllability of LLMs. To this end, we revisit summary attribute measurements and introduce iterative evaluation metrics, failure rate and average iteration count to precisely evaluate controllability of LLMs, rather than merely assessing errors. Our findings show that LLMs struggle more with numerical attributes than with linguistic attributes. To address this challenge, we propose a guide-to-explain framework (GTE) for controllable summarization. Our GTE framework enables the model to identify misaligned attributes in the initial draft and guides it in self-explaining errors in the previous output. By allowing the model to reflect on its misalignment, GTE generates well-adjusted summaries that satisfy the desired attributes with robust effectiveness, requiring surprisingly fewer iterations than other iterative approaches.","authors":["Sangwon Ryu","Heejin Do","Daehee Kim","Hwanjo Yu","Dongwoo Kim","Yunsu Kim","Gary Geunbae Lee","Jungseul Ok"],"pdf_url":"","comment":"EACL Findings 2026"},{"id":"http://arxiv.org/abs/2601.00919v2","updated":"2026-01-07T18:20:49Z","published":"2026-01-01T08:39:15Z","title":"Attention Needs to Focus: A Unified Perspective on Attention Allocation","summary":"The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.","authors":["Zichuan Fu","Wentao Song","Guojing Li","Yejing Wang","Xian Wu","Yimin Deng","Hanyu Yan","Yefeng Zheng","Xiangyu Zhao"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2601.01280v2","updated":"2026-01-07T18:16:54Z","published":"2026-01-03T20:39:39Z","title":"Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory","summary":"Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.","authors":["Sen Hu","Yuxiang Wei","Jiaxin Ran","Zhiyuan Yao","Xueran Han","Huacan Wang","Ronghao Chen","Lei Zou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04151v1","updated":"2026-01-07T18:03:45Z","published":"2026-01-07T18:03:45Z","title":"Klear: Unified Multi-Task Audio-Video Joint Generation","summary":"Audio-video joint generation has progressed rapidly, yet substantial challenges still remain. Non-commercial approaches still suffer audio-visual asynchrony, poor lip-speech alignment, and unimodal degradation, which can be stemmed from weak audio-visual correspondence modeling, limited generalization, and scarce high-quality dense-caption data. To address these issues, we introduce Klear and delve into three axes--model architecture, training strategy, and data curation. Architecturally, we adopt a single-tower design with unified DiT blocks and an Omni-Full Attention mechanism, achieving tight audio-visual alignment and strong scalability. Training-wise, we adopt a progressive multitask regime--random modality masking to joint optimization across tasks, and a multistage curriculum, yielding robust representations, strengthening A-V aligned world knowledge, and preventing unimodal collapse. For datasets, we present the first large-scale audio-video dataset with dense captions, and introduce a novel automated data-construction pipeline which annotates and filters millions of diverse, high-quality, strictly aligned audio-video-caption triplets. Building on this, Klear scales to large datasets, delivering high-fidelity, semantically and temporally aligned, instruction-following generation in both joint and unimodal settings while generalizing robustly to out-of-distribution scenarios. Across tasks, it substantially outperforms prior methods by a large margin and achieves performance comparable to Veo 3, offering a unified, scalable path toward next-generation audio-video synthesis.","authors":["Jun Wang","Chunyu Qiang","Yuxin Guo","Yiran Wang","Xijuan Zeng","Chen Zhang","Pengfei Wan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06303v4","updated":"2026-01-07T17:58:17Z","published":"2025-05-21T16:15:01Z","title":"Reward Is Enough: LLMs Are In-Context Reinforcement Learners","summary":"Reinforcement learning (RL) is a framework for solving sequential decision-making problems. In this work, we demonstrate that, surprisingly, RL emerges during the inference time of large language models (LLMs), a phenomenon we term in-context RL (ICRL). To reveal this capability, we introduce a simple multi-round prompting framework, we call ICRL prompting, for inference-time self-improvement. The goal of ICRL prompting is to guide LLMs to perform reinforcement learning during inference for self-improvement on a given task. After each response, the model receives numerical scalar feedback, denoted as a reward. In the next round, we prompt the LLM again together with a context that concatenates all prior responses and their associated rewards. We consistently observe that response quality improves as the context grows. In other words, the LLM can optimize scalar reward signals during inference, exhibiting behavior analogous to reinforcement learning. We evaluate ICRL prompting on Game of 24, creative writing, ScienceWorld, and Olympiad-level math competitions (AIME and HMMT), demonstrating significant improvements over baselines such as Self-Refine and Reflexion. Notably, even when the reward signals are generated by the same LLM, ICRL prompting still improves performance, highlighting a promising new paradigm for test-time scaling.","authors":["Kefan Song","Amir Moeini","Peng Wang","Lei Gong","Rohan Chandra","Shangtong Zhang","Yanjun Qi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04137v1","updated":"2026-01-07T17:50:37Z","published":"2026-01-07T17:50:37Z","title":"Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test","summary":"As world models gain momentum in Embodied AI, an increasing number of works explore using video foundation models as predictive world models for downstream embodied tasks like 3D prediction or interactive generation. However, before exploring these downstream tasks, video foundation models still have two critical questions unanswered: (1) whether their generative generalization is sufficient to maintain perceptual fidelity in the eyes of human observers, and (2) whether they are robust enough to serve as a universal prior for real-world embodied agents. To provide a standardized framework for answering these questions, we introduce the Embodied Turing Test benchmark: WoW-World-Eval (Wow,wo,val). Building upon 609 robot manipulation data, Wow-wo-val examines five core abilities, including perception, planning, prediction, generalization, and execution. We propose a comprehensive evaluation protocol with 22 metrics to assess the models' generation ability, which achieves a high Pearson Correlation between the overall score and human preference (>0.93) and establishes a reliable foundation for the Human Turing Test. On Wow-wo-val, models achieve only 17.27 on long-horizon planning and at best 68.02 on physical consistency, indicating limited spatiotemporal consistency and physical reasoning. For the Inverse Dynamic Model Turing Test, we first use an IDM to evaluate the video foundation models' execution accuracy in the real world. However, most models collapse to $\\approx$ 0% success, while WoW maintains a 40.74% success rate. These findings point to a noticeable gap between the generated videos and the real world, highlighting the urgency and necessity of benchmarking World Model in Embodied AI.","authors":["Chun-Kai Fan","Xiaowei Chi","Xiaozhu Ju","Hao Li","Yong Bao","Yu-Kai Wang","Lizhang Chen","Zhiyuan Jiang","Kuangzhi Ge","Ying Li","Weishi Mi","Qingpo Wuwu","Peidong Jia","Yulin Luo","Kevin Zhang","Zhiyuan Qin","Yong Dai","Sirui Han","Yike Guo","Shanghang Zhang","Jian Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04131v1","updated":"2026-01-07T17:45:20Z","published":"2026-01-07T17:45:20Z","title":"ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models","summary":"Large Language Models (LLMs) encode vast amounts of parametric knowledge during pre-training. As world knowledge evolves, effective deployment increasingly depends on their ability to faithfully follow externally retrieved context. When such evidence conflicts with the model's internal knowledge, LLMs often default to memorized facts, producing unfaithful outputs. In this work, we introduce ContextFocus, a lightweight activation steering approach that improves context faithfulness in such knowledge-conflict settings while preserving fluency and efficiency. Unlike prior approaches, our solution requires no model finetuning and incurs minimal inference-time overhead, making it highly efficient. We evaluate ContextFocus on the ConFiQA benchmark, comparing it against strong baselines including ContextDPO, COIECD, and prompting-based methods. Furthermore, we show that our method is complementary to prompting strategies and remains effective on larger models. Extensive experiments show that ContextFocus significantly improves contextual-faithfulness. Our results highlight the effectiveness, robustness, and efficiency of ContextFocus in improving contextual-faithfulness of LLM outputs.","authors":["Nikhil Anand","Shwetha Somasundaram","Anirudh Phukan","Apoorv Saxena","Koyel Mukherjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04127v1","updated":"2026-01-07T17:41:11Z","published":"2026-01-07T17:41:11Z","title":"Pixel-Wise Multimodal Contrastive Learning for Remote Sensing Images","summary":"Satellites continuously generate massive volumes of data, particularly for Earth observation, including satellite image time series (SITS). However, most deep learning models are designed to process either entire images or complete time series sequences to extract meaningful features for downstream tasks. In this study, we propose a novel multimodal approach that leverages pixel-wise two-dimensional (2D) representations to encode visual property variations from SITS more effectively. Specifically, we generate recurrence plots from pixel-based vegetation index time series (NDVI, EVI, and SAVI) as an alternative to using raw pixel values, creating more informative representations. Additionally, we introduce PIxel-wise Multimodal Contrastive (PIMC), a new multimodal self-supervision approach that produces effective encoders based on two-dimensional pixel time series representations and remote sensing imagery (RSI). To validate our approach, we assess its performance on three downstream tasks: pixel-level forecasting and classification using the PASTIS dataset, and land cover classification on the EuroSAT dataset. Moreover, we compare our results to state-of-the-art (SOTA) methods on all downstream tasks. Our experimental results show that the use of 2D representations significantly enhances feature extraction from SITS, while contrastive learning improves the quality of representations for both pixel time series and RSI. These findings suggest that our multimodal method outperforms existing models in various Earth observation tasks, establishing it as a robust self-supervision framework for processing both SITS and RSI. Code avaliable on","authors":["Leandro Stival","Ricardo da Silva Torres","Helio Pedrini"],"pdf_url":"","comment":"21 pages, 9 Figures"},{"id":"http://arxiv.org/abs/2601.04126v1","updated":"2026-01-07T17:40:08Z","published":"2026-01-07T17:40:08Z","title":"InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training","summary":"GUI agents that interact with graphical interfaces on behalf of users represent a promising direction for practical AI assistants. However, training such agents is hindered by the scarcity of suitable environments. We present InfiniteWeb, a system that automatically generates functional web environments at scale for GUI agent training. While LLMs perform well on generating a single webpage, building a realistic and functional website with many interconnected pages faces challenges. We address these challenges through unified specification, task-centric test-driven development, and a combination of website seed with reference design image to ensure diversity. Our system also generates verifiable task evaluators enabling dense reward signals for reinforcement learning. Experiments show that InfiniteWeb surpasses commercial coding agents at realistic website construction, and GUI agents trained on our generated environments achieve significant performance improvements on OSWorld and Online-Mind2Web, demonstrating the effectiveness of proposed system.","authors":["Ziyun Zhang","Zezhou Wang","Xiaoyi Zhang","Zongyu Guo","Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2507.07947v3","updated":"2026-01-07T17:17:56Z","published":"2025-07-10T17:32:26Z","title":"Low Resource Reconstruction Attacks Through Benign Prompts","summary":"Recent advances in generative models, such as diffusion models, have raised concerns related to privacy, copyright infringement, and data stewardship. To better understand and control these risks, prior work has introduced techniques and attacks that reconstruct images, or parts of images, from training data. While these results demonstrate that training data can be recovered, existing methods often rely on high computational resources, partial access to the training set, or carefully engineered prompts.\n  In this work, we present a new attack that requires low resources, assumes little to no access to the training data, and identifies seemingly benign prompts that can lead to potentially risky image reconstruction. We further show that such reconstructions may occur unintentionally, even for users without specialized knowledge. For example, we observe that for one existing model, the prompt ``blue Unisex T-Shirt'' generates the face of a real individual. Moreover, by combining the identified vulnerabilities with real-world prompt data, we discover prompts that reproduce memorized visual elements.\n  Our approach builds on insights from prior work and leverages domain knowledge to expose a fundamental vulnerability arising from the use of scraped e-commerce data, where templated layouts and images are closely tied to pattern-like textual prompts.\n  The code for our attack is publicly available at https://github.com/TheSolY/lr-tmi.","authors":["Sol Yarkoni","Mahmood Sharif","Roi Livni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04100v1","updated":"2026-01-07T17:06:05Z","published":"2026-01-07T17:06:05Z","title":"Quantifying the Impact of Modules and Their Interactions in the PSO-X Framework","summary":"The PSO-X framework incorporates dozens of modules that have been proposed for solving single-objective continuous optimization problems using particle swarm optimization. While modular frameworks enable users to automatically generate and configure algorithms tailored to specific optimization problems, the complexity of this process increases with the number of modules in the framework and the degrees of freedom defined for their interaction. Understanding how modules affect the performance of algorithms for different problems is critical to making the process of finding effective implementations more efficient and identifying promising areas for further investigation. Despite their practical applications and scientific relevance, there is a lack of empirical studies investigating which modules matter most in modular optimization frameworks and how they interact. In this paper, we analyze the performance of 1424 particle swarm optimization algorithms instantiated from the PSO-X framework on the 25 functions in the CEC'05 benchmark suite with 10 and 30 dimensions. We use functional ANOVA to quantify the impact of modules and their combinations on performance in different problem classes. In practice, this allows us to identify which modules have greater influence on PSO-X performance depending on problem features such as multimodality, mathematical transformations and varying dimensionality. We then perform a cluster analysis to identify groups of problem classes that share similar module effect patterns. Our results show low variability in the importance of modules in all problem classes, suggesting that particle swarm optimization performance is driven by a few influential modules.","authors":["Christian L. Camacho-Villalón","Ana Nikolikj","Katharina Dost","Eva Tuba","Sašo Džeroski","Tome Eftimov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04098v1","updated":"2026-01-07T17:04:30Z","published":"2026-01-07T17:04:30Z","title":"Layer-wise Positional Bias in Short-Context Language Modeling","summary":"Language models often show a preference for using information from specific positions in the input regardless of semantic relevance. While positional bias has been studied in various contexts, from attention sinks to task performance degradation in long-context settings, prior work has not established how these biases evolve across individual layers and input positions, or how they vary independent of task complexity. We introduce an attribution-based framework to analyze positional effects in short-context language modeling. Using layer conductance with a sliding-window approach, we quantify how each layer distributes importance across input positions, yielding layer-wise positional importance profiles. We find that these profiles are architecture-specific, stable across inputs, and invariant to lexical scrambling. Characterizing these profiles, we find prominent recency bias that increases with depth and subtle primacy bias that diminishes through model depth. Beyond positional structure, we also show that early layers preferentially weight content words over function words across all positions, while later layers lose this word-type differentiation.","authors":["Maryam Rahimi","Mahdi Nouri","Yadollah Yaghoobzadeh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16942v2","updated":"2026-01-07T16:58:00Z","published":"2025-04-10T20:16:02Z","title":"S2Vec: Self-Supervised Geospatial Embeddings for the Built Environment","summary":"Scalable general-purpose representations of the built environment are crucial for geospatial artificial intelligence applications. This paper introduces S2Vec, a novel self-supervised framework for learning such geospatial embeddings. S2Vec uses the S2 Geometry library to partition large areas into discrete S2 cells, rasterizes built environment feature vectors within cells as images, and applies masked autoencoding on these rasterized images to encode the feature vectors. This approach yields task-agnostic embeddings that capture local feature characteristics and broader spatial relationships. We evaluate S2Vec on several large-scale geospatial prediction tasks, both random train/test splits (interpolation) and zero-shot geographic adaptation (extrapolation). Our experiments show S2Vec's competitive performance against several baselines on socioeconomic tasks, especially the geographic adaptation variant, with room for improvement on environmental tasks. We also explore combining S2Vec embeddings with image-based embeddings downstream, showing that such multimodal fusion can often improve performance. Our findings highlight how S2Vec can learn effective general-purpose geospatial representations of the built environment features it is provided, and how it can complement other data modalities in geospatial artificial intelligence.","authors":["Shushman Choudhury","Elad Aharoni","Chandrakumari Suvarna","Iveel Tsogsuren","Abdul Rahman Kreidieh","Chun-Ta Lu","Neha Arora"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04085v1","updated":"2026-01-07T16:54:02Z","published":"2026-01-07T16:54:02Z","title":"CSSG: Measuring Code Similarity with Semantic Graphs","summary":"Existing code similarity metrics, such as BLEU, CodeBLEU, and TSED, largely rely on surface-level string overlap or abstract syntax tree structures, and often fail to capture deeper semantic relationships between programs.We propose CSSG (Code Similarity using Semantic Graphs), a novel metric that leverages program dependence graphs to explicitly model control dependencies and variable interactions, providing a semantics-aware representation of code.Experiments on the CodeContests+ dataset show that CSSG consistently outperforms existing metrics in distinguishing more similar code from less similar code under both monolingual and cross-lingual settings, demonstrating that dependency-aware graph representations offer a more effective alternative to surface-level or syntax-based similarity measures.","authors":["Jingwen Xu","Yiyang Lu","Changze Lv","Zisu Huang","Zhengkang Guo","Zhengyuan Wang","Muzhao Tian","Xuanjing Huang","Xiaoqing Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20721v2","updated":"2026-01-07T16:46:55Z","published":"2025-10-23T16:38:26Z","title":"User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios","summary":"Large language models (LLMs) are rapidly being adopted for tasks like drafting emails, summarizing meetings, and answering health questions. In these settings, users may need to share private information (e.g., contact details, health records). To evaluate LLMs' ability to identify and redact such information, prior work introduced real-life, scenario-based benchmarks (e.g., ConfAIde, PrivacyLens) and found that LLMs can leak private information in complex scenarios. However, these evaluations relied on proxy LLMs to judge the helpfulness and privacy-preservation quality of LLM responses, rather than directly measuring users' perceptions. To understand how users perceive the helpfulness and privacy-preservation quality of LLM responses to privacy-sensitive scenarios, we conducted a user study ($n=94$) using 90 PrivacyLens scenarios. We found that users had low agreement with each other when evaluating identical LLM responses. In contrast, five proxy LLMs reached high agreement, yet each proxy LLM had low correlation with users' evaluations. These results indicate that proxy LLMs cannot accurately estimate users' wide range of perceptions of utility and privacy in privacy-sensitive scenarios. We discuss the need for more user-centered studies to measure LLMs' ability to help users while preserving privacy, and for improving alignment between LLMs and users in estimating perceived privacy and utility.","authors":["Xiaoyuan Wu","Roshni Kaushik","Wenkai Li","Lujo Bauer","Koichi Onoue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04073v1","updated":"2026-01-07T16:39:34Z","published":"2026-01-07T16:39:34Z","title":"Analyzing Reasoning Consistency in Large Multimodal Models under Cross-Modal Conflicts","summary":"Large Multimodal Models (LMMs) have demonstrated impressive capabilities in video reasoning via Chain-of-Thought (CoT). However, the robustness of their reasoning chains remains questionable. In this paper, we identify a critical failure mode termed textual inertia, where once a textual hallucination occurs in the thinking process, models tend to blindly adhere to the erroneous text while neglecting conflicting visual evidence. To systematically investigate this, we propose the LogicGraph Perturbation Protocol that structurally injects perturbations into the reasoning chains of diverse LMMs spanning both native reasoning architectures and prompt-driven paradigms to evaluate their self-reflection capabilities. The results reveal that models successfully self-correct in less than 10% of cases and predominantly succumb to blind textual error propagation. To mitigate this, we introduce Active Visual-Context Refinement, a training-free inference paradigm which orchestrates an active visual re-grounding mechanism to enforce fine-grained verification coupled with an adaptive context refinement strategy to summarize and denoise the reasoning history. Experiments demonstrate that our approach significantly stifles hallucination propagation and enhances reasoning robustness.","authors":["Zhihao Zhu","Jiafeng Liang","Shixin Jiang","Jinlan Fu","Ming Liu","Guanglu Sun","See-Kiong Ng","Bing Qin"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.04068v1","updated":"2026-01-07T16:32:17Z","published":"2026-01-07T16:32:17Z","title":"Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models","summary":"Aligning text-to-video diffusion models with human preferences is crucial for generating high-quality videos. Existing Direct Preference Otimization (DPO) methods rely on multi-sample ranking and task-specific critic models, which is inefficient and often yields ambiguous global supervision. To address these limitations, we propose LocalDPO, a novel post-training framework that constructs localized preference pairs from real videos and optimizes alignment at the spatio-temporal region level. We design an automated pipeline to efficiently collect preference pair data that generates preference pairs with a single inference per prompt, eliminating the need for external critic models or manual annotation. Specifically, we treat high-quality real videos as positive samples and generate corresponding negatives by locally corrupting them with random spatio-temporal masks and restoring only the masked regions using the frozen base model. During training, we introduce a region-aware DPO loss that restricts preference learning to corrupted areas for rapid convergence. Experiments on Wan2.1 and CogVideoX demonstrate that LocalDPO consistently improves video fidelity, temporal coherence and human preference scores over other post-training approaches, establishing a more efficient and fine-grained paradigm for video generator alignment.","authors":["Zitong Huang","Kaidong Zhang","Yukang Ding","Chao Gao","Rui Ding","Ying Chen","Wangmeng Zuo"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2512.07344v2","updated":"2026-01-07T16:24:34Z","published":"2025-12-08T09:32:47Z","title":"Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding","summary":"Vision-language models (VLMs) have demonstrated impressive multimodal comprehension capabilities and are being deployed in an increasing number of online video understanding applications. While recent efforts extensively explore advancing VLMs' reasoning power in these cases, deployment constraints are overlooked, leading to overwhelming system overhead in real-world deployments. To address that, we propose Venus, an on-device memory-and-retrieval system for efficient online video understanding. Venus proposes an edge-cloud disaggregated architecture that sinks memory construction and keyframe retrieval from cloud to edge, operating in two stages. In the ingestion stage, Venus continuously processes streaming edge videos via scene segmentation and clustering, where the selected keyframes are embedded with a multimodal embedding model to build a hierarchical memory for efficient storage and retrieval. In the querying stage, Venus indexes incoming queries from memory, and employs a threshold-based progressive sampling algorithm for keyframe selection that enhances diversity and adaptively balances system cost and reasoning accuracy. Our extensive evaluation shows that Venus achieves a 15x-131x speedup in total response latency compared to state-of-the-art methods, enabling real-time responses within seconds while maintaining comparable or even superior reasoning accuracy.","authors":["Shengyuan Ye","Bei Ouyang","Tianyi Qian","Liekang Zeng","Mu Yuan","Xiaowen Chu","Weijie Hong","Xu Chen"],"pdf_url":"","comment":"Accepted by IEEE International Conference on Computer Communications 2026"},{"id":"http://arxiv.org/abs/2601.04060v1","updated":"2026-01-07T16:24:01Z","published":"2026-01-07T16:24:01Z","title":"ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows","summary":"AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.","authors":["Jinwei Su","Qizhen Lan","Zeyu Wang","Yinghui Xia","Hairu Wen","Yiqun Duan","Xi Xiao","Tianyu Shi","Yang Jingsong","Lewei He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04035v1","updated":"2026-01-07T15:51:44Z","published":"2026-01-07T15:51:44Z","title":"MobileDreamer: Generative Sketch World Model for GUI Agent","summary":"Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.","authors":["Yilin Cao","Yufeng Zhong","Zhixiong Zeng","Liming Zheng","Jing Huang","Haibo Qiu","Peng Shi","Wenji Mao","Wan Guanglu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.06168v2","updated":"2026-01-07T15:50:40Z","published":"2025-11-09T00:27:38Z","title":"Chain-of-Thought as a Lens: Evaluating Structured Reasoning Alignment between Human Preferences and Large Language Models","summary":"This paper primarily demonstrate a method to quantitatively assess the alignment between multi-step, structured reasoning in large language models and human preferences. We introduce the Alignment Score, a semantic-level metric that compares a model-produced chain of thought traces with a human-preferred reference by constructing semantic-entropy-based matrices over intermediate steps and measuring their divergence. Our analysis shows that Alignment Score tracks task accuracy across models and hop depths, and peaks at 2-hop reasoning. Empirical results further indicates that misalignment at greater reasoning depths is driven mainly by alignment errors such as thematic shift and redundant reasoning. Viewing chain sampling as drawing from a distribution over reasoning paths, we empirically demonstrate a strong and consistent correlation between Alignment Score and accuracy performance, supporting its use as a meaningful diagnostic signal for structured reasoning.","authors":["Boxuan Wang","Zhuoyun Li","Xinmiao Huang","Xiaowei Huang","Yi Dong"],"pdf_url":"","comment":"Pre-print, 16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.04034v1","updated":"2026-01-07T15:47:28Z","published":"2026-01-07T15:47:28Z","title":"HoneyTrap: Deceiving Large Language Model Attackers to Honeypot Traps with Resilient Multi-Agent Defense","summary":"Jailbreak attacks pose significant threats to large language models (LLMs), enabling attackers to bypass safeguards. However, existing reactive defense approaches struggle to keep up with the rapidly evolving multi-turn jailbreaks, where attackers continuously deepen their attacks to exploit vulnerabilities. To address this critical challenge, we propose HoneyTrap, a novel deceptive LLM defense framework leveraging collaborative defenders to counter jailbreak attacks. It integrates four defensive agents, Threat Interceptor, Misdirection Controller, Forensic Tracker, and System Harmonizer, each performing a specialized security role and collaborating to complete a deceptive defense. To ensure a comprehensive evaluation, we introduce MTJ-Pro, a challenging multi-turn progressive jailbreak dataset that combines seven advanced jailbreak strategies designed to gradually deepen attack strategies across multi-turn attacks. Besides, we present two novel metrics: Mislead Success Rate (MSR) and Attack Resource Consumption (ARC), which provide more nuanced assessments of deceptive defense beyond conventional measures. Experimental results on GPT-4, GPT-3.5-turbo, Gemini-1.5-pro, and LLaMa-3.1 demonstrate that HoneyTrap achieves an average reduction of 68.77% in attack success rates compared to state-of-the-art baselines. Notably, even in a dedicated adaptive attacker setting with intensified conditions, HoneyTrap remains resilient, leveraging deceptive engagement to prolong interactions, significantly increasing the time and computational costs required for successful exploitation. Unlike simple rejection, HoneyTrap strategically wastes attacker resources without impacting benign queries, improving MSR and ARC by 118.11% and 149.16%, respectively.","authors":["Siyuan Li","Xi Lin","Jun Wu","Zehao Liu","Haoyu Li","Tianjie Ju","Xiang Chen","Jianhua Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.01650v2","updated":"2026-01-07T15:44:03Z","published":"2025-11-03T15:05:44Z","title":"EngTrace: A Symbolic Benchmark for Verifiable Process Supervision of Engineering Reasoning","summary":"Large Language Models (LLMs) are increasingly entering specialized, safety-critical engineering workflows governed by strict quantitative standards and immutable physical laws, making rigorous evaluation of their reasoning capabilities imperative. However, existing benchmarks such as MMLU, MATH, and HumanEval assess isolated cognitive skills, failing to capture the physically grounded reasoning central to engineering, where scientific principles, quantitative modeling, and practical constraints must converge. To enable verifiable process supervision in engineering, we introduce EngTrace, a symbolic benchmark comprising 90 templates across three major engineering branches, nine core domains and 20 distinct areas. Through domain-aware parameterization, we generate 1,350 unique, contamination-resistant test cases to stress-test generalization. Moving beyond outcome matching, we introduce a verifiable two-stage evaluation framework that uses a tiered protocol to validate intermediate reasoning traces alongside final answers through automated procedural checks and a heterogeneous AI Tribunal. Our evaluation of 24 leading LLMs reveals a distinct trade-off between numeric precision and trace fidelity, identifying a complexity cliff where abstract mathematical pre-training fails to translate into the integrative reasoning required for advanced engineering tasks.","authors":["Ayesha Gull","Muhammad Usman Safder","Rania Elbadry","Fan Zhang","Veselin Stoyanov","Preslav Nakov","Zhuohan Xie"],"pdf_url":"","comment":"22 pages, includes figures and tables; introduces the EngTrace benchmark"},{"id":"http://arxiv.org/abs/2504.16680v2","updated":"2026-01-07T15:37:21Z","published":"2025-04-23T12:58:15Z","title":"Uncertainty-Aware Robotic World Model Makes Offline Model-Based Reinforcement Learning Work on Real Robots","summary":"Reinforcement Learning (RL) has achieved impressive results in robotics, yet high-performing pipelines remain highly task-specific, with little reuse of prior data. Offline Model-based RL (MBRL) offers greater data efficiency by training policies entirely from existing datasets, but suffers from compounding errors and distribution shift in long-horizon rollouts. Although existing methods have shown success in controlled simulation benchmarks, robustly applying them to the noisy, biased, and partially observed datasets typical of real-world robotics remains challenging. We present a principled pipeline for making offline MBRL effective on physical robots. Our RWM-U extends autoregressive world models with epistemic uncertainty estimation, enabling temporally consistent multi-step rollouts with uncertainty effectively propagated over long horizons. We combine RWM-U with MOPO-PPO, which adapts uncertainty-penalized policy optimization to the stable, on-policy PPO framework for real-world control. We evaluate our approach on diverse manipulation and locomotion tasks in simulation and on real quadruped and humanoid, training policies entirely from offline datasets. The resulting policies consistently outperform model-free and uncertainty-unaware model-based baselines, and fusing real-world data in model learning further yields robust policies that surpass online model-free baselines trained solely in simulation.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01513v2","updated":"2026-01-07T15:36:31Z","published":"2026-01-04T12:46:35Z","title":"FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation","summary":"Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.","authors":["Gen Li","Peiyu Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.15577v2","updated":"2026-01-07T15:15:20Z","published":"2025-09-19T04:24:57Z","title":"Relevance to Utility: Process-Supervised Rewrite for RAG","summary":"Retrieval-augmented generation systems often suffer from a gap between optimizing retrieval relevance and generative utility. With such a gap, retrieved documents may be topically relevant but still lack the content needed for effective reasoning during generation. While existing bridge modules attempt to rewrite the retrieved text for better generation, we show how they fail by not capturing \"document utility\". In this work, we propose R2U, with a key distinction of approximating true utility through joint observation of rewriting and answering in the reasoning process. To distill, R2U scale such supervision to enhance reliability in distillation. We further construct utility-improvement supervision by measuring the generator's gain of the answer under the rewritten context, yielding signals for fine-tuning and preference optimization. We evaluate our method across multiple open-domain question-answering benchmarks. The empirical results demonstrate consistent improvements over strong bridging baselines","authors":["Jaeyoung Kim","Jongho Kim","Seung-won Hwang","Seoho Song","Young-In Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.05894v2","updated":"2026-01-07T15:11:39Z","published":"2024-11-08T14:23:02Z","title":"SSSD: Simply-Scalable Speculative Decoding","summary":"Speculative Decoding has emerged as a popular technique for accelerating inference in Large Language Models. However, most existing approaches yield only modest improvements in production serving systems. Methods that achieve substantial speedups typically rely on an additional trained draft model or auxiliary model components, increasing deployment and maintenance complexity. This added complexity reduces flexibility, particularly when serving workloads shift to tasks, domains, or languages that are not well represented in the draft model's training data.\n  We introduce Simply-Scalable Speculative Decoding (SSSD), a training-free method that combines lightweight n-gram matching with hardware-aware speculation. Relative to standard autoregressive decoding, SSSD reduces latency by up to 2.9x. It achieves performance on par with leading training-based approaches across a broad range of benchmarks, while requiring substantially lower adoption effort--no data preparation, training or tuning are needed--and exhibiting superior robustness under language and domain shift, as well as in long-context settings.","authors":["Michele Marzollo","Jiawei Zhuang","Niklas Roemer","Niklas Zwingenberger","Lorenz K. Müller","Lukas Cavigelli"],"pdf_url":"","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2601.03992v1","updated":"2026-01-07T15:02:57Z","published":"2026-01-07T15:02:57Z","title":"A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems","summary":"Mixture-of-Experts (MoE) models facilitate edge deployment by decoupling model capacity from active computation, yet their large memory footprint drives the need for GPU systems with near-data processing (NDP) capabilities that offload experts to dedicated processing units. However, deploying MoE models on such edge-based GPU-NDP systems faces three critical challenges: 1) severe load imbalance across NDP units due to non-uniform expert selection and expert parallelism, 2) insufficient GPU utilization during expert computation within NDP units, and 3) extensive data pre-profiling necessitated by unpredictable expert activation patterns for pre-fetching. To address these challenges, this paper proposes an efficient inference framework featuring three key optimizations. First, the underexplored tensor parallelism in MoE inference is exploited to partition and compute large expert parameters across multiple NDP units simultaneously towards edge low-batch scenarios. Second, a load-balancing-aware scheduling algorithm distributes expert computations across NDP units and GPU to maximize resource utilization. Third, a dataset-free pre-fetching strategy proactively loads frequently accessed experts to minimize activation delays. Experimental results show that our framework enables GPU-NDP systems to achieve 2.41x on average and up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches, significantly enhancing MoE inference efficiency in resource-constrained environments.","authors":["Qi Wu","Chao Fang","Jiayuan Chen","Ye Lin","Yueqi Zhang","Yichuan Bai","Yuan Du","Li Du"],"pdf_url":"","comment":"To appear in 2026 Design, Automation and Test in Europe Conference (DATE 2026)"},{"id":"http://arxiv.org/abs/2505.11830v3","updated":"2026-01-07T14:58:44Z","published":"2025-05-17T04:34:32Z","title":"VISTA: Mitigating Semantic Inertia in Video-LLMs via Training-Free Dynamic Chain-of-Thought Routing","summary":"Recent advancements in Large Language Models have successfully transitioned towards System 2 reasoning, yet applying these paradigms to video understanding remains challenging. While prevailing research attributes failures in Video-LLMs to perceptual limitations, our empirical analysis reveals a cognitive misalignment termed Semantic Inertia, where models suppress valid visual evidence in favor of dominant language priors. To rectify this, we propose VISTA, a training-free framework designed to align perception with logical deduction. By dynamically routing inference paths and materializing implicit visual features into explicit textual anchors, our approach effectively counterbalances the influence of parametric knowledge. Furthermore, we incorporate a Latent Reasoning Consensus mechanism to mitigate stochastic hallucinations. VISTA showed outstanding results on a wide range of benchmarks, and outperforms its base model by 9.3% on Egochema and 5.6% on VideoEspresso, rivalling or even surpassing larger and proprietary models. Our codebase will be publicly available soon.","authors":["Hongbo Jin","Jiayu Ding","Siyi Xie","Guibo Luo","Ge Li"],"pdf_url":"","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.03969v1","updated":"2026-01-07T14:31:07Z","published":"2026-01-07T14:31:07Z","title":"Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models","summary":"Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods.","authors":["Wei Wu","Liyi Chen","Congxi Xiao","Tianfu Wang","Qimeng Wang","Chengqiang Lu","Yan Gao","Yi Wu","Yao Hu","Hui Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.08925v4","updated":"2026-01-07T14:29:09Z","published":"2024-10-11T15:50:31Z","title":"An Overview of Prototype Formulations for Interpretable Deep Learning","summary":"Prototypical part networks offer interpretable alternatives to black-box deep learning models by learning visual prototypes for classification. This work provides a comprehensive analysis of prototype formulations, comparing point-based and probabilistic approaches in both Euclidean and hyperspherical latent spaces.\n  We introduce HyperPG, a probabilistic prototype representation using Gaussian distributions on hyperspheres. Experiments on CUB-200-2011, Stanford Cars, and Oxford Flowers datasets show that hyperspherical prototypes outperform standard Euclidean formulations. Critically, hyperspherical prototypes maintain competitive performance under simplified training schemes, while Euclidean prototypes require extensive hyperparameter tuning.","authors":["Maximilian Xiling Li","Korbinian Franz Rudolf","Paul Mattes","Nils Blank","Rudolf Lioutikov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13935v2","updated":"2026-01-07T14:13:11Z","published":"2025-10-15T15:51:13Z","title":"Big Reasoning with Small Models: Instruction Retrieval at Inference Time","summary":"Small language models (SLMs) enable low-cost, private, on-device inference, but they often fail on problems that require specialized domain knowledge or multi-step reasoning. Existing approaches for improving reasoning either rely on scale (e.g., chain-of-thought prompting), require task-specific training that limits reuse and generality (e.g., distillation), or retrieve unstructured information that still leaves the SLM to determine an appropriate reasoning strategy. We propose instruction retrieval, an inference-time intervention that augments an SLM with structured, reusable reasoning procedures rather than raw passages. We construct an Instruction Corpus by clustering similar training questions and using a teacher model to generate generalizable guides that pair domain background with explicit step-by-step procedures. At inference, the SLM retrieves the instructions most relevant to a given query and executes the associated procedures without any additional fine-tuning. Across three challenging domains: medicine, law, and mathematics, instruction retrieval yields consistent gains for models with at least 3B parameters, improving accuracy by 9.4%, 7.9%, and 5.1%, respectively, with the strongest 14B model surpassing GPT-4o's zero-shot performance on knowledge-intensive tasks.","authors":["Kenan Alkiek","David Jurgens","Vinod Vydiswaran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.02478v4","updated":"2026-01-07T14:09:58Z","published":"2024-11-04T18:10:10Z","title":"Imagining and building wise machines: The centrality of AI metacognition","summary":"Although AI has become increasingly smart, its wisdom has not kept pace. In this article, we examine what is known about human wisdom and sketch a vision of its AI counterpart. We analyze human wisdom as a set of strategies for solving intractable problems-those outside the scope of analytic techniques-including both object-level strategies like heuristics [for managing problems] and metacognitive strategies like intellectual humility, perspective-taking, or context-adaptability [for managing object-level strategies]. We argue that AI systems particularly struggle with metacognition; improved metacognition would lead to AI more robust to novel environments, explainable to users, cooperative with others, and safer in risking fewer misaligned goals with human users. We discuss how wise AI might be benchmarked, trained, and implemented.","authors":["Samuel G. B. Johnson","Amir-Hossein Karimi","Yoshua Bengio","Nick Chater","Tobias Gerstenberg","Kate Larson","Sydney Levine","Melanie Mitchell","Iyad Rahwan","Bernhard Schölkopf","Igor Grossmann"],"pdf_url":"","comment":"23 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2601.03948v1","updated":"2026-01-07T14:03:22Z","published":"2026-01-07T14:03:22Z","title":"Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification","summary":"Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards are verifiable but inherently noisy, causing standard RL to degenerate into reward hacking. To address this, we propose Trade-R1, a model training framework that bridges verifiable rewards to stochastic environments via process-level reasoning verification. Our key innovation is a verification method that transforms the problem of evaluating reasoning over lengthy financial documents into a structured Retrieval-Augmented Generation (RAG) task. We construct a triangular consistency metric, assessing pairwise alignment between retrieved evidence, reasoning chains, and decisions to serve as a validity filter for noisy market returns. We explore two reward integration strategies: Fixed-effect Semantic Reward (FSR) for stable alignment signals, and Dynamic-effect Semantic Reward (DSR) for coupled magnitude optimization. Experiments on different country asset selection demonstrate that our paradigm reduces reward hacking, with DSR achieving superior cross-market generalization while maintaining the highest reasoning consistency.","authors":["Rui Sun","Yifan Sun","Sheng Xu","Li Zhao","Jing Li","Daxin Jiang","Chen Hua","Zuo Bai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.24978v4","updated":"2026-01-07T13:59:59Z","published":"2025-09-29T16:07:05Z","title":"Agentic Exploration of Physics Models","summary":"The process of scientific discovery relies on an interplay of observations, analysis, and hypothesis generation. Machine learning is increasingly being adopted to address individual aspects of this process. However, it remains an open challenge to fully automate the heuristic, iterative loop required to discover the laws of an unknown system by exploring it through experiments and analysis, without tailoring the approach to the specifics of a given task. Here, we introduce SciExplorer, an agent that leverages large language model tool-use capabilities to enable exploration of systems without any domain-specific blueprints, and apply it to physical systems that are initially unknown to the agent. We test SciExplorer on a broad set of models spanning mechanical dynamical systems, wave evolution, and quantum many-body physics. Despite using a minimal set of tools, primarily based on code execution, we observe impressive performance on tasks such as recovering equations of motion from observed dynamics and inferring Hamiltonians from expectation values. The demonstrated effectiveness of this setup opens the door towards similar scientific exploration in other domains, without the need for finetuning or task-specific instructions.","authors":["Maximilian Nägele","Florian Marquardt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03940v1","updated":"2026-01-07T13:58:29Z","published":"2026-01-07T13:58:29Z","title":"Large-Scale Aspect-Based Sentiment Analysis with Reasoning-Infused LLMs","summary":"We introduce Arctic-ABSA, a collection of powerful models for real-life aspect-based sentiment analysis (ABSA). Our models are tailored to commercial needs, trained on a large corpus of public data alongside carefully generated synthetic data, resulting in a dataset 20 times larger than SemEval14. We extend typical ABSA models by expanding the number of sentiment classes from the standard three (positive, negative, neutral) to five, adding mixed and unknown classes, while also jointly predicting overall text sentiment and supporting multiple languages. We experiment with reasoning injection by fine-tuning on Chain-of-Thought (CoT) examples and introduce a novel reasoning pretraining technique for encoder-only models that significantly improves downstream fine-tuning and generalization. Our 395M-parameter encoder and 8B-parameter decoder achieve up to 10 percentage points higher accuracy than GPT-4o and Claude 3.5 Sonnet, while setting new state-of-the-art results on the SemEval14 benchmark. A single multilingual model maintains 87-91% accuracy across six languages without degrading English performance. We release ABSA-mix, a large-scale benchmark aggregating 17 public ABSA datasets across 92 domains.","authors":["Paweł Liskowski","Krzysztof Jankowski"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03938v1","updated":"2026-01-07T13:55:14Z","published":"2026-01-07T13:55:14Z","title":"FOREVER: Forgetting Curve-Inspired Memory Replay for Language Model Continual Learning","summary":"Continual learning (CL) for large language models (LLMs) aims to enable sequential knowledge acquisition without catastrophic forgetting. Memory replay methods are widely used for their practicality and effectiveness, but most rely on fixed, step-based heuristics that often misalign with the model's actual learning progress, since identical training steps can result in varying degrees of parameter change. Motivated by recent findings that LLM forgetting mirrors the Ebbinghaus human forgetting curve, we propose FOREVER (FORgEtting curVe-inspired mEmory Replay), a novel CL framework that aligns replay schedules with a model-centric notion of time. FOREVER defines model time using the magnitude of optimizer updates, allowing forgetting curve-inspired replay intervals to align with the model's internal evolution rather than raw training steps. Building on this approach, FOREVER incorporates a forgetting curve-based replay scheduler to determine when to replay and an intensity-aware regularization mechanism to adaptively control how to replay. Extensive experiments on three CL benchmarks and models ranging from 0.6B to 13B parameters demonstrate that FOREVER consistently mitigates catastrophic forgetting.","authors":["Yujie Feng","Hao Wang","Jian Li","Xu Chu","Zhaolu Kang","Yiran Liu","Yasha Wang","Philip S. Yu","Xiao-Ming Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03930v1","updated":"2026-01-07T13:49:57Z","published":"2026-01-07T13:49:57Z","title":"Bayes-PD: Exploring a Sequence to Binding Bayesian Neural Network model trained on Phage Display data","summary":"Phage display is a powerful laboratory technique used to study the interactions between proteins and other molecules, whether other proteins, peptides, DNA or RNA. The under-utilisation of this data in conjunction with deep learning models for protein design may be attributed to; high experimental noise levels; the complex nature of data pre-processing; and difficulty interpreting these experimental results. In this work, we propose a novel approach utilising a Bayesian Neural Network within a training loop, in order to simulate the phage display experiment and its associated noise. Our goal is to investigate how understanding the experimental noise and model uncertainty can enable the reliable application of such models to reliably interpret phage display experiments. We validate our approach using actual binding affinity measurements instead of relying solely on proxy values derived from 'held-out' phage display rounds.","authors":["Ilann Amiaud-Plachy","Michael Blank","Oliver Bent","Sebastien Boyer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03928v1","updated":"2026-01-07T13:48:12Z","published":"2026-01-07T13:48:12Z","title":"FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection","summary":"Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while preserving positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Preserving positional continuity during visual token selection. We find that general visual token pruning methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.","authors":["Mingyu Ouyang","Kevin Qinghong Lin","Mike Zheng Shou","Hwee Tou Ng"],"pdf_url":"","comment":"14 pages, 13 figures"},{"id":"http://arxiv.org/abs/2601.03919v1","updated":"2026-01-07T13:40:30Z","published":"2026-01-07T13:40:30Z","title":"A Gap Between Decision Trees and Neural Networks","summary":"We study when geometric simplicity of decision boundaries, used here as a notion of interpretability, can conflict with accurate approximation of axis-aligned decision trees by shallow neural networks. Decision trees induce rule-based, axis-aligned decision regions (finite unions of boxes), whereas shallow ReLU networks are typically trained as score models whose predictions are obtained by thresholding. We analyze the infinite-width, bounded-norm, single-hidden-layer ReLU class through the Radon total variation ($\\mathrm{R}\\mathrm{TV}$) seminorm, which controls the geometric complexity of level sets.\n  We first show that the hard tree indicator $1_A$ has infinite $\\mathrm{R}\\mathrm{TV}$. Moreover, two natural split-wise continuous surrogates--piecewise-linear ramp smoothing and sigmoidal (logistic) smoothing--also have infinite $\\mathrm{R}\\mathrm{TV}$ in dimensions $d>1$, while Gaussian convolution yields finite $\\mathrm{R}\\mathrm{TV}$ but with an explicit exponential dependence on $d$.\n  We then separate two goals that are often conflated: classification after thresholding (recovering the decision set) versus score learning (learning a calibrated score close to $1_A$). For classification, we construct a smooth barrier score $S_A$ with finite $\\mathrm{R}\\mathrm{TV}$ whose fixed threshold $τ=1$ exactly recovers the box. Under a mild tube-mass condition near $\\partial A$, we prove an $L_1(P)$ calibration bound that decays polynomially in a sharpness parameter, along with an explicit $\\mathrm{R}\\mathrm{TV}$ upper bound in terms of face measures. Experiments on synthetic unions of rectangles illustrate the resulting accuracy--complexity tradeoff and how threshold selection shifts where training lands along it.","authors":["Akash Kumar"],"pdf_url":"","comment":"45 pages"},{"id":"http://arxiv.org/abs/2506.19573v2","updated":"2026-01-07T13:39:17Z","published":"2025-06-24T12:37:17Z","title":"Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming","summary":"Machine learning (ML) techniques play a pivotal role in high-stakes domains such as healthcare, where accurate predictions can greatly enhance decision-making. However, most high-performing methods such as neural networks and ensemble methods are often opaque, limiting trust and broader adoption. In parallel, symbolic methods like Answer Set Programming (ASP) offer the possibility of interpretable logical rules but do not always match the predictive power of ML models. This paper proposes a hybrid approach that integrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML classifiers to selectively correct uncertain predictions and provide human-readable explanations. Experiments on five medical reveal statistically significant performance gains in accuracy and F1 score. This study underscores the potential of combining symbolic reasoning with conventional ML to achieve high interpretability without sacrificing accuracy\n","authors":["Sanne Wielinga","Jesse Heyninck"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03910v1","updated":"2026-01-07T13:21:44Z","published":"2026-01-07T13:21:44Z","title":"An Algebraic Representation Theorem for Linear GENEOs in Geometric Machine Learning","summary":"Geometric and Topological Deep Learning are rapidly growing research areas that enhance machine learning through the use of geometric and topological structures. Within this framework, Group Equivariant Non-Expansive Operators (GENEOs) have emerged as a powerful class of operators for encoding symmetries and designing efficient, interpretable neural architectures. Originally introduced in Topological Data Analysis, GENEOs have since found applications in Deep Learning as tools for constructing equivariant models with reduced parameter complexity. GENEOs provide a unifying framework bridging Geometric and Topological Deep Learning and include the operator computing persistence diagrams as a special case. Their theoretical foundations rely on group actions, equivariance, and compactness properties of operator spaces, grounding them in algebra and geometry while enabling both mathematical rigor and practical relevance. While a previous representation theorem characterized linear GENEOs acting on data of the same type, many real-world applications require operators between heterogeneous data spaces. In this work, we address this limitation by introducing a new representation theorem for linear GENEOs acting between different perception pairs, based on generalized T-permutant measures. Under mild assumptions on the data domains and group actions, our result provides a complete characterization of such operators. We also prove the compactness and convexity of the space of linear GENEOs. We further demonstrate the practical impact of this theory by applying the proposed framework to improve the performance of autoencoders, highlighting the relevance of GENEOs in modern machine learning applications.","authors":["Francesco Conti","Patrizio Frosini","Nicola Quercioli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03905v1","updated":"2026-01-07T13:15:23Z","published":"2026-01-07T13:15:23Z","title":"Current Agents Fail to Leverage World Model as Tool for Foresight","summary":"Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.","authors":["Cheng Qian","Emre Can Acikgoz","Bingxuan Li","Xiusi Chen","Yuji Zhang","Bingxiang He","Qinyu Luo","Dilek Hakkani-Tür","Gokhan Tur","Yunzhu Li","Heng Ji","Heng Ji"],"pdf_url":"","comment":"36 Pages, 13 Figures, 17 Tables"},{"id":"http://arxiv.org/abs/2601.03895v1","updated":"2026-01-07T13:04:52Z","published":"2026-01-07T13:04:52Z","title":"Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training","summary":"Group Relative Policy Optimization (GRPO) has emerged as a popular algorithm for reinforcement learning with large language models (LLMs). However, upon analyzing its clipping mechanism, we argue that it is suboptimal in certain scenarios. With appropriate modifications, GRPO can be significantly enhanced to improve both flexibility and generalization. To this end, we propose Adaptive-Boundary-Clipping GRPO (ABC-GRPO), an asymmetric and adaptive refinement of the original GRPO framework. We demonstrate that ABC-GRPO achieves superior performance over standard GRPO on mathematical reasoning tasks using the Qwen3 LLMs. Moreover, ABC-GRPO maintains substantially higher entropy throughout training, thereby preserving the model's exploration capacity and mitigating premature convergence. The implementation code is available online to ease reproducibility https://github.com/chi2liu/ABC-GRPO.","authors":["Chi Liu","Xin Chen"],"pdf_url":"","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.03889v1","updated":"2026-01-07T12:59:37Z","published":"2026-01-07T12:59:37Z","title":"Spectral Manifold Regularization for Stable and Modular Routing in Deep MoE Architectures","summary":"Mixture of Experts (MoE) architectures enable efficient scaling of neural networks but suffer from expert collapse, where routing converges to a few dominant experts. This reduces model capacity and causes catastrophic interference during adaptation. We propose the Spectrally-Regularized Mixture of Experts (SR-MoE), which imposes geometric constraints on the routing manifold to enforce structural modularity. Our method uses dual regularization: spectral norm constraints bound routing function Lipschitz continuity, while stable rank penalties preserve high-dimensional feature diversity in expert selection. We evaluate SR-MoE across architectural scales and dataset complexities using modular one-shot adaptation tasks. Results show that traditional linear gating fails with increasing depth (accuracy drops up to 4.72% due to expert entanglement), while SR-MoE maintains structural integrity (mean interference -0.32%). Our spectral constraints facilitate positive knowledge transfer, enabling localized expert updates without global performance decay. SR-MoE provides a general solution for building high-capacity, modular networks capable of stable lifelong learning.","authors":["Ibrahim Delibasoglu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03888v1","updated":"2026-01-07T12:58:16Z","published":"2026-01-07T12:58:16Z","title":"IndexTTS 2.5 Technical Report","summary":"In prior work, we introduced IndexTTS 2, a zero-shot neural text-to-speech foundation model comprising two core components: a transformer-based Text-to-Semantic (T2S) module and a non-autoregressive Semantic-to-Mel (S2M) module, which together enable faithful emotion replication and establish the first autoregressive duration-controllable generative paradigm. Building upon this, we present IndexTTS 2.5, which significantly enhances multilingual coverage, inference speed, and overall synthesis quality through four key improvements: 1) Semantic Codec Compression: we reduce the semantic codec frame rate from 50 Hz to 25 Hz, halving sequence length and substantially lowering both training and inference costs; 2) Architectural Upgrade: we replace the U-DiT-based backbone of the S2M module with a more efficient Zipformer-based modeling architecture, achieving notable parameter reduction and faster mel-spectrogram generation; 3) Multilingual Extension: We propose three explicit cross-lingual modeling strategies, boundary-aware alignment, token-level concatenation, and instruction-guided generation, establishing practical design principles for zero-shot multilingual emotional TTS that supports Chinese, English, Japanese, and Spanish, and enables robust emotion transfer even without target-language emotional training data; 4) Reinforcement Learning Optimization: we apply GRPO in post-training of the T2S module, improving pronunciation accuracy and natrualness. Experiments show that IndexTTS 2.5 not only supports broader language coverage but also replicates emotional prosody in unseen languages under the same zero-shot setting. IndexTTS 2.5 achieves a 2.28 times improvement in RTF while maintaining comparable WER and speaker similarity to IndexTTS 2.","authors":["Yunpei Li","Xun Zhou","Jinchao Wang","Lu Wang","Yong Wu","Siyi Zhou","Yiquan Zhou","Jingchen Shu"],"pdf_url":"","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.03884v1","updated":"2026-01-07T12:51:28Z","published":"2026-01-07T12:51:28Z","title":"FLNet: Flood-Induced Agriculture Damage Assessment using Super Resolution of Satellite Images","summary":"Distributing government relief efforts after a flood is challenging. In India, the crops are widely affected by floods; therefore, making rapid and accurate crop damage assessment is crucial for effective post-disaster agricultural management. Traditional manual surveys are slow and biased, while current satellite-based methods face challenges like cloud cover and low spatial resolution. Therefore, to bridge this gap, this paper introduced FLNet, a novel deep learning based architecture that used super-resolution to enhance the 10 m spatial resolution of Sentinel-2 satellite images into 3 m resolution before classifying damage. We tested our model on the Bihar Flood Impacted Croplands Dataset (BFCD-22), and the results showed an improved critical \"Full Damage\" F1-score from 0.83 to 0.89, nearly matching the 0.89 score of commercial high-resolution imagery. This work presented a cost-effective and scalable solution, paving the way for a nationwide shift from manual to automated, high-fidelity damage assessment.","authors":["Sanidhya Ghosal","Anurag Sharma","Sushil Ghildiyal","Mukesh Saini"],"pdf_url":"","comment":"Accepted for oral presentation at the 10th International Conference on Computer Vision and Image Processing (CVIP 2025)"},{"id":"http://arxiv.org/abs/2601.03880v1","updated":"2026-01-07T12:47:39Z","published":"2026-01-07T12:47:39Z","title":"Women Worry, Men Adopt: How Gendered Perceptions Shape the Use of Generative AI","summary":"Generative artificial intelligence (GenAI) is diffusing rapidly, yet its adoption is strikingly unequal. Using nationally representative UK survey data from 2023 to 2024, we show that women adopt GenAI substantially less often than men because they perceive its societal risks differently. We construct a composite index capturing concerns about mental health, privacy, climate impact, and labor market disruption. This index explains between 9 and 18 percent of the variation in GenAI adoption and ranks among the strongest predictors for women across all age groups, surpassing digital literacy and education for young women. Intersectional analyses show that the largest disparities arise among younger, digitally fluent individuals with high societal risk concerns, where gender gaps in personal use exceed 45 percentage points. Using a synthetic twin panel design, we show that increased optimism about AI's societal impact raises GenAI use among young women from 13 percent to 33 percent, substantially narrowing the gender divide. These findings indicate that gendered perceptions of AI's social and ethical consequences, rather than access or capability, are the primary drivers of unequal GenAI adoption, with implications for productivity, skill formation, and economic inequality in an AI enabled economy.","authors":["Fabian Stephany","Jedrzej Duszynski"],"pdf_url":"","comment":"16 pages, 6 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.03560v2","updated":"2026-01-07T12:35:21Z","published":"2024-10-04T16:07:36Z","title":"FÆRDXEL: An Expert System for Danish Traffic Law","summary":"We present FÆRDXEL, a tool for symbolic reasoning in the domain of Danish traffic law. FÆRDXEL combines techniques from logic programming with a novel interface that allows users to navigate through its reasoning process, thereby ensuring the system's explainability. Towards the goal of better understanding the value of FÆRDXEL, two evaluations of the system have been performed: (1) An empirical evaluation showing that for a selection of court cases, the conclusions of FÆRDXEL align with those of Danish judges. (2) A qualitative evaluation from legal experts indicating that this work has potential to become a foundation for real-world AI tools supporting professionals in the Danish legal sector.","authors":["Luís Cruz-Filipe","Jonas Vistrup"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2305.16203v4","updated":"2026-01-07T12:35:00Z","published":"2023-05-25T16:06:48Z","title":"Computing Universal Plans for Partially Observable Multi-Agent Routing Using Answer Set Programming","summary":"Multi-agent routing problems have gained significant attention recently due to their wide range of industrial applications, ranging from logistics warehouse automation to indoor service robots. Conventionally, they are modeled as classical planning problems. In this paper, we argue that it can be beneficial to formulate them as universal planning problems, particularly when the agents are autonomous entities and may encounter unforeseen situations. We therefore propose universal plans, also known as policies, as the solution concept, and implement a system based on Answer Set Programming (ASP) to compute them. Given an arbitrary two-dimensional map and a profile of goals for a group of partially observable agents, the system translates the problem configuration into logic programs and finds a feasible universal plan for each agent, mapping its observations to actions while ensuring that there are no collisions with other agents. We use the system to conduct experiments and obtain findings regarding the types of goal profiles and environments that lead to feasible policies, as well as how feasibility may depend on the agents' sensors. We also demonstrate how users can customize action preferences to compute more efficient policies, even (near-)optimal ones. The code is available at https://github.com/Fernadoo/MAPF_ASP.","authors":["Fengming Zhu","Fangzhen Lin"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03868v1","updated":"2026-01-07T12:31:52Z","published":"2026-01-07T12:31:52Z","title":"What Matters For Safety Alignment?","summary":"This paper presents a comprehensive empirical study on the safety alignment capabilities. We evaluate what matters for safety alignment in LLMs and LRMs to provide essential insights for developing more secure and reliable AI systems. We systematically investigate and compare the influence of six critical intrinsic model characteristics and three external attack techniques. Our large-scale evaluation is conducted using 32 recent, popular LLMs and LRMs across thirteen distinct model families, spanning a parameter scale from 3B to 235B. The assessment leverages five established safety datasets and probes model vulnerabilities with 56 jailbreak techniques and four CoT attack strategies, resulting in 4.6M API calls. Our key empirical findings are fourfold. First, we identify the LRMs GPT-OSS-20B, Qwen3-Next-80B-A3B-Thinking, and GPT-OSS-120B as the top-three safest models, which substantiates the significant advantage of integrated reasoning and self-reflection mechanisms for robust safety alignment. Second, post-training and knowledge distillation may lead to a systematic degradation of safety alignment. We thus argue that safety must be treated as an explicit constraint or a core optimization objective during these stages, not merely subordinated to the pursuit of general capability. Third, we reveal a pronounced vulnerability: employing a CoT attack via a response prefix can elevate the attack success rate by 3.34x on average and from 0.6% to 96.3% for Seed-OSS-36B-Instruct. This critical finding underscores the safety risks inherent in text-completion interfaces and features that allow user-defined response prefixes in LLM services, highlighting an urgent need for architectural and deployment safeguards. Fourth, roleplay, prompt injection, and gradient-based search for adversarial prompts are the predominant methodologies for eliciting unaligned behaviors in modern models.","authors":["Xing Li","Hui-Ling Zhen","Lihao Yin","Xianzhi Yu","Zhenhua Dong","Mingxuan Yuan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03850v1","updated":"2026-01-07T12:08:44Z","published":"2026-01-07T12:08:44Z","title":"Investigating the Grounding Bottleneck for a Large-Scale Configuration Problem: Existing Tools and Constraint-Aware Guessing","summary":"Answer set programming (ASP) aims to realize the AI vision: The user specifies the problem, and the computer solves it. Indeed, ASP has made this vision true in many application domains. However, will current ASP solving techniques scale up for large configuration problems? As a benchmark for such problems, we investigated the configuration of electronic systems, which may comprise more than 30,000 components. We show the potential and limits of current ASP technology, focusing on methods that address the so-called grounding bottleneck, i.e., the sharp increase of memory demands in the size of the problem instances. To push the limits, we investigated the incremental solving approach, which proved effective in practice. However, even in the incremental approach, memory demands impose significant limits. Based on an analysis of grounding, we developed the method constraint-aware guessing, which significantly reduced the memory need.","authors":["Veronika Semmelrock","Gerhard Friedrich"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03848v1","updated":"2026-01-07T12:08:15Z","published":"2026-01-07T12:08:15Z","title":"Implementing the First-Order Logic of Here and There","summary":"We present automated theorem provers for the first-order logic of here and there (HT). They are based on a native sequent calculus for the logic of HT and an axiomatic embedding of the logic of HT into intuitionistic logic. The analytic proof search in the sequent calculus is optimized by using free variables and skolemization. The embedding is used in combination with sequent, tableau and connection calculi for intuitionistic first-order logic. All provers are evaluated on a large benchmark set of first-order formulas, providing a foundation for the development of more efficient HT provers.\n","authors":["Jens Otten","Torsten Schaub"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2410.03296v3","updated":"2026-01-07T12:08:07Z","published":"2024-10-04T10:14:12Z","title":"A Systematic Comparison between Extractive Self-Explanations and Human Rationales in Text Classification","summary":"Instruction-tuned LLMs are able to provide \\textit{an} explanation about their output to users by generating self-explanations, without requiring the application of complex interpretability techniques. In this paper, we analyse whether this ability results in a \\textit{good} explanation. We evaluate self-explanations in the form of input rationales with respect to their plausibility to humans. We study three text classification tasks: sentiment classification, forced labour detection and claim verification. We include Danish and Italian translations of the sentiment classification task and compare self-explanations to human annotations. For this, we collected human rationale annotations for Climate-Fever, a claim verification dataset. We furthermore evaluate the faithfulness of human and self-explanation rationales with respect to correct model predictions, and extend the study by incorporating post-hoc attribution-based explanations. We analyse four open-weight LLMs and find that alignment between self-explanations and human rationales highly depends on text length and task complexity. Nevertheless, self-explanations yield faithful subsets of token-level rationales, whereas post-hoc attribution methods tend to emphasize structural and formatting tokens, reflecting fundamentally different explanation strategies.","authors":["Stephanie Brandl","Oliver Eberle"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2601.03847v1","updated":"2026-01-07T12:08:00Z","published":"2026-01-07T12:08:00Z","title":"xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming","summary":"Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their \"black-box\" nature. xAI approaches can be characterized along different dimensions such as their scope (global versus local explanations) or underlying methodologies (statistic-based versus rule-based strategies). Methods generating global explanations aim to provide reasoning process applicable to all possible output classes while local explanation methods focus only on a single, specific class. SHAP (SHapley Additive exPlanations), a well-known statistical technique, identifies important features of a network. Deep neural network rule extraction method constructs IF-THEN rules that link input conditions to a class. Another approach focuses on generating counterfactuals which help explain how small changes to an input can affect the model's predictions. However, these techniques primarily focus on the input-output relationship and thus neglect the structure of the network in explanation generation.   In this work, we propose xDNN(ASP), an explanation generation system for deep neural networks that provides global explanations. Given a neural network model and its training data, xDNN(ASP) extracts a logic program under answer set semantics that-in the ideal case-represents the trained model, i.e., answer sets of the extracted program correspond one-to-one to input-output pairs of the network. We demonstrate experimentally, using two synthetic datasets, that not only the extracted logic program maintains a high-level of accuracy in the prediction task, but it also provides valuable information for the understanding of the model such as the importance of features as well as the impact of hidden nodes on the prediction. The latter can be used as a guide for reducing the number of nodes used in hidden layers, i.e., providing a means for optimizing the network.","authors":["Ly Ly Trieu","Tran Cao Son"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03846v1","updated":"2026-01-07T12:07:48Z","published":"2026-01-07T12:07:48Z","title":"When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents","summary":"LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert communication in LLM-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different communication regimes, including explicit, restricted, and absent communication. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.","authors":["Alessio Buscemi","Daniele Proverbio","Alessandro Di Stefano","The Anh Han","German Castignani","Pietro Liò"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03845v1","updated":"2026-01-07T12:07:45Z","published":"2026-01-07T12:07:45Z","title":"Formally Explaining Decision Tree Models with Answer Set Programming","summary":"Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods.","authors":["Akihiro Takemura","Masayuki Otani","Katsumi Inoue"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03844v1","updated":"2026-01-07T12:07:30Z","published":"2026-01-07T12:07:30Z","title":"XAI-LAW: A Logic Programming Tool for Modeling, Explaining, and Learning Legal Decisions","summary":"We propose an approach to model articles of the Italian Criminal Code (ICC), using Answer Set Programming (ASP), and to semi-automatically learn legal rules from examples based on prior judicial decisions. The developed tool is intended to support legal experts during the criminal trial phase by providing reasoning and possible legal outcomes. The methodology involves analyzing and encoding articles of the ICC in ASP, including \"crimes against the person\" and property offenses. The resulting model is validated on a set of previous verdicts and refined as necessary. During the encoding process, contradictions may arise; these are properly handled by the system, which also generates possible decisions for new cases and provides explanations through a tool that leverages the \"supportedness\" of stable models. The automatic explainability offered by the tool can also be used to clarify the logic behind judicial decisions, making the decision-making process more interpretable. Furthermore, the tool integrates an inductive logic programming system for ASP, which is employed to generalize legal rules from case examples.","authors":["Agostino Dovier","Talissa Dreossi","Andrea Formisano","Benedetta Strizzolo"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2506.13600v2","updated":"2026-01-07T12:06:46Z","published":"2025-06-16T15:25:06Z","title":"The ASP-based Nurse Scheduling System at the University of Yamanashi Hospital","summary":"We present the design principles of a nurse scheduling system built using Answer Set Programming (ASP) and successfully deployed at the University of Yamanashi Hospital. Nurse scheduling is a complex optimization problem requiring the reconciliation of individual nurse preferences with hospital staffing needs across various wards. This involves balancing hard and soft constraints and the flexibility of interactive adjustments. While extensively studied in academia, real-world nurse scheduling presents unique challenges that go beyond typical benchmark problems and competitions. This paper details the practical application of ASP to address these challenges at the University of Yamanashi Hospital, focusing on the insights gained and the advancements in ASP technology necessary to effectively manage the complexities of real-world deployment.\n","authors":["Hidetomo Nabeshima","Mutsunori Banbara","Torsten Schaub","Takehide Soh"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03842v1","updated":"2026-01-07T12:06:26Z","published":"2026-01-07T12:06:26Z","title":"On the Trap Space Semantics of Normal Logic Programs","summary":"The logical semantics of normal logic programs has traditionally been based on the notions of Clark's completion and two-valued or three-valued canonical models, including supported, stable, regular, and well-founded models. Two-valued interpretations can also be seen as states evolving under a program's update operator, producing a transition graph whose fixed points and cycles capture stable and oscillatory behaviors, respectively. We refer to this view as dynamical semantics since it characterizes the program's meaning in terms of state-space trajectories, as first introduced in the stable (supported) class semantics. Recently, we have established a formal connection between Datalog^\\neg programs (i.e., normal logic programs without function symbols) and Boolean networks, leading to the introduction of the trap space concept for Datalog^\\neg programs. In this paper, we generalize the trap space concept to arbitrary normal logic programs, introducing trap space semantics as a new approach to their interpretation. This new semantics admits both model-theoretic and dynamical characterizations, providing a comprehensive approach to understanding program behavior. We establish the foundational properties of the trap space semantics and systematically relate it to the established model-theoretic semantics, including the stable (supported), stable (supported) partial, regular, and L-stable model semantics, as well as to the dynamical stable (supported) class semantics. Our results demonstrate that the trap space semantics offers a unified and precise framework for proving the existence of supported classes, strict stable (supported) classes, and regular models, in addition to uncovering and formalizing deeper relationships among the existing semantics of normal logic programs.","authors":["Van-Giang Trinh","Sylvain Soliman","François Fages","Belaid Benhamou"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03840v1","updated":"2026-01-07T12:05:41Z","published":"2026-01-07T12:05:41Z","title":"Defeasible Conditionals using Answer Set Programming","summary":"Defeasible entailment is concerned with drawing plausible conclusions from incomplete information. A foundational framework for modelling defeasible entailment is the KLM framework. Introduced by Kraus, Lehmann, and Magidor, the KLM framework outlines several key properties for defeasible entailment. One of the most prominent algorithms within this framework is Rational Closure (RC). This paper presents a declarative definition for computing RC using Answer Set Programming (ASP). Our approach enables the automatic construction of the minimal ranked model from a given knowledge base and supports entailment checking for specified queries. We formally prove the correctness of our ASP encoding and conduct empirical evaluations to compare the performance of our implementation with that of existing imperative implementations, specifically the InfOCF solver. The results demonstrate that our ASP-based approach adheres to RC's theoretical foundations and offers improved computational efficiency.","authors":["Racquel Dennison","Jesse Heyninck","Thomas Meyer"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2506.03997v3","updated":"2026-01-07T12:05:26Z","published":"2025-06-04T14:25:34Z","title":"A framework for Conditional Reasoning in Answer Set Programming","summary":"In this paper we introduce a Conditional Answer Set Programming framework (Conditional ASP) for the definition of conditional extensions of Answer Set Programming (ASP). The approach builds on a conditional logic with typicality, and on the combination of a conditional knowledge base with an ASP program, and allows for conditional reasoning over the answer sets of the program. The formalism relies on a multi-preferential semantics, and on the KLM preferential semantics, as a special case. Conditional entailment is encoded in ASP and a complexity upper-bound is provided.","authors":["Mario Alviano","Laura Giordano","Daniele Theseider Dupré"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03839v1","updated":"2026-01-07T12:04:49Z","published":"2026-01-07T12:04:49Z","title":"Logic Tensor Network-Enhanced Generative Adversarial Network","summary":"In this paper, we introduce Logic Tensor Network-Enhanced Generative Adversarial Network (LTN-GAN), a novel framework that enhances Generative Adversarial Networks (GANs) by incorporating Logic Tensor Networks (LTNs) to enforce domain-specific logical constraints during the sample generation process. Although GANs have shown remarkable success in generating realistic data, they often lack mechanisms to incorporate prior knowledge or enforce logical consistency, limiting their applicability in domains requiring rule adherence. LTNs provide a principled way to integrate first-order logic with neural networks, enabling models to reason over and satisfy logical constraints. By combining the strengths of GANs for realistic data synthesis with LTNs for logical reasoning, we gain valuable insights into how logical constraints influence the generative process while improving both the diversity and logical consistency of the generated samples. We evaluate LTN-GAN across multiple datasets, including synthetic datasets (gaussian, grid, rings) and the MNIST dataset, demonstrating that our model significantly outperforms traditional GANs in terms of adherence to predefined logical constraints while maintaining the quality and diversity of generated samples. This work highlights the potential of neuro-symbolic approaches to enhance generative modeling in knowledge-intensive domains.","authors":["Nijesh Upreti","Vaishak Belle"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2501.14540v3","updated":"2026-01-07T12:04:14Z","published":"2025-01-24T14:45:21Z","title":"VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning","summary":"A recent approach to neurosymbolic reasoning is to explicitly combine the strengths of large language models (LLMs) and symbolic solvers to tackle complex reasoning tasks. However, current approaches face significant limitations, including poor generalizability due to task-specific prompts, inefficiencies caused by the lack of separation between knowledge and queries, and restricted inferential capabilities. These shortcomings hinder their scalability and applicability across diverse domains. In this paper, we introduce VERUS-LM, a novel framework designed to address these challenges. VERUS-LM employs a generic prompting mechanism, clearly separates domain knowledge from queries, and supports a wide range of different logical reasoning tasks. This framework enhances adaptability, reduces computational cost, and allows for richer forms of reasoning, such as optimization and constraint satisfaction. We show that our approach succeeds in diverse reasoning on a novel dataset, markedly outperforming LLMs. Additionally, our system achieves competitive results on common reasoning benchmarks when compared to similar state-of-the-art approaches, and significantly surpasses them on the difficult AR-LSAT dataset. By pushing the boundaries of hybrid reasoning, VERUS-LM represents a significant step towards more versatile neurosymbolic AI systems.","authors":["Benjamin Callewaert","Simon Vandevelde","Joost Vennekens"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2506.17776v3","updated":"2026-01-07T12:03:57Z","published":"2025-06-21T18:13:13Z","title":"Machine Learning Model Integration with Open World Temporal Logic for Process Automation","summary":"Recent advances in Machine Learning (ML) have produced models that extract structured information from complex data. However, a significant challenge lies in translating these perceptual or extractive outputs into actionable and explainable decisions within complex operational workflows. To address these challenges, this paper introduces a novel approach that integrates the outputs of various machine learning models directly with the PyReason framework, an open-world temporal logic programming reasoning engine. PyReason's foundation in generalized annotated logic allows for the incorporation of real-valued outputs (e.g., probabilities, confidence scores) from a diverse set of ML models, treating them as truth intervals within its logical framework. Crucially, PyReason provides mechanisms, implemented in Python, to continuously poll ML model outputs, convert them into logical facts, and dynamically recompute the minimal model to enable decision-making in real-time. Furthermore, its native support for temporal reasoning, knowledge graph integration, and fully explainable interface traces enables an analysis of time-sensitive process data and existing organizational knowledge. By combining the strengths of perception and extraction from ML models with the logical deduction and transparency of PyReason, we aim to create a powerful system for automating complex processes. This integration is well suited for use cases in numerous domains, including manufacturing, healthcare, and business operations.","authors":["Dyuman Aditya","Colton Payne","Mario Leiva","Paulo Shakarian"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2507.03929v2","updated":"2026-01-07T12:03:42Z","published":"2025-07-05T07:23:24Z","title":"An ASP-Based Framework for MUSes","summary":"Given an unsatisfiable formula, understanding the core reason for unsatisfiability is crucial in several applications. One effective way to capture this is through the minimal unsatisfiable subset (MUS), the subset-minimal set of clauses that remains unsatisfiable. Current research broadly focuses on two directions: (i) enumerating as many MUSes as possible within a given time limit, and (ii) counting the total number of MUSes for a given unsatisfiable formula.\n  In this paper, we introduce an answer set programming-based framework, named MUS-ASP, designed for online enumeration of MUSes. ASP is a powerful tool for its strengths in knowledge representation and is particularly suitable for specifying complex combinatorial problems. By translating MUS enumeration into answer set solving, MUS-ASP leverages the computational efficiency of state-of-the-art ASP systems. Our extensive experimental evaluation demonstrates the effectiveness of MUS-ASP and highlights the acceleration in both MUS enumeration and counting tasks, particularly when integrated within hybrid solvers, including the framework proposed in this paper.","authors":["Mohimenul Kabir","Kuldeep S Meel"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2512.12069v2","updated":"2026-01-07T11:45:25Z","published":"2025-12-12T22:31:38Z","title":"Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring","summary":"Large Vision-Language Models (LVLMs) are vulnerable to a growing array of multimodal jailbreak attacks, necessitating defenses that are both generalizable to novel threats and efficient for practical deployment. Many current strategies fall short, either targeting specific attack patterns, which limits generalization, or imposing high computational overhead. While lightweight anomaly-detection methods offer a promising direction, we find that their common one-class design tends to confuse novel benign inputs with malicious ones, leading to unreliable over-rejection. To address this, we propose Representational Contrastive Scoring (RCS), a framework built on a key insight: the most potent safety signals reside within the LVLM's own internal representations. Our approach inspects the internal geometry of these representations, learning a lightweight projection to maximally separate benign and malicious inputs in safety-critical layers. This enables a simple yet powerful contrastive score that differentiates true malicious intent from mere novelty. Our instantiations, MCD (Mahalanobis Contrastive Detection) and KCD (K-nearest Contrastive Detection), achieve state-of-the-art performance on a challenging evaluation protocol designed to test generalization to unseen attack types. This work demonstrates that effective jailbreak detection can be achieved by applying simple, interpretable statistical methods to the appropriate internal representations, offering a practical path towards safer LVLM deployment. Our code is available on Github https://github.com/sarendis56/Jailbreak_Detection_RCS.","authors":["Peichun Hua","Hao Li","Shanghao Shi","Zhiyuan Yu","Ning Zhang"],"pdf_url":"","comment":"37 pages, 13 figures"},{"id":"http://arxiv.org/abs/2510.02370v2","updated":"2026-01-07T11:42:40Z","published":"2025-09-29T06:18:18Z","title":"How Training Data Shapes the Use of Parametric and In-Context Knowledge in Language Models","summary":"Large language models leverage not only parametric knowledge acquired during training but also in-context knowledge provided at inference time, despite the absence of explicit training objectives for using both sources. Prior work has further shown that when these knowledge sources conflict, models resolve the tension based on their internal confidence, preferring parametric knowledge for high-confidence facts while deferring to contextual information for less familiar ones. However, the training conditions that give rise to such knowledge utilization behaviors remain unclear. To address this gap, we conduct controlled experiments in which we train language models while systematically manipulating key properties of the training data. Our results reveal a counterintuitive finding: three properties commonly regarded as detrimental must co-occur for robust knowledge utilization and conflict resolution to emerge: (i) intra-document repetition of information, (ii) a moderate degree of within-document inconsistency, and (iii) a skewed knowledge frequency distribution. We further validate that the same training dynamics observed in our controlled setting also arise during real-world language model pretraining, and we analyze how post-training procedures can reshape models' knowledge preferences. Together, our findings provide concrete empirical guidance for training language models that harmoniously integrate parametric and in-context knowledge.","authors":["Minsung Kim","Dong-Kyum Kim","Jea Kwon","Nakyeong Yang","Kyomin Jung","Meeyoung Cha"],"pdf_url":"","comment":"16 pages"},{"id":"http://arxiv.org/abs/2601.03824v1","updated":"2026-01-07T11:37:57Z","published":"2026-01-07T11:37:57Z","title":"IDESplat: Iterative Depth Probability Estimation for Generalizable 3D Gaussian Splatting","summary":"Generalizable 3D Gaussian Splatting aims to directly predict Gaussian parameters using a feed-forward network for scene reconstruction. Among these parameters, Gaussian means are particularly difficult to predict, so depth is usually estimated first and then unprojected to obtain the Gaussian sphere centers. Existing methods typically rely solely on a single warp to estimate depth probability, which hinders their ability to fully leverage cross-view geometric cues, resulting in unstable and coarse depth maps. To address this limitation, we propose IDESplat, which iteratively applies warp operations to boost depth probability estimation for accurate Gaussian mean prediction. First, to eliminate the inherent instability of a single warp, we introduce a Depth Probability Boosting Unit (DPBU) that integrates epipolar attention maps produced by cascading warp operations in a multiplicative manner. Next, we construct an iterative depth estimation process by stacking multiple DPBUs, progressively identifying potential depth candidates with high likelihood. As IDESplat iteratively boosts depth probability estimates and updates the depth candidates, the depth map is gradually refined, resulting in accurate Gaussian means. We conduct experiments on RealEstate10K, ACID, and DL3DV. IDESplat achieves outstanding reconstruction quality and state-of-the-art performance with real-time efficiency. On RE10K, it outperforms DepthSplat by 0.33 dB in PSNR, using only 10.7% of the parameters and 70% of the memory. Additionally, our IDESplat improves PSNR by 2.95 dB over DepthSplat on the DTU dataset in cross-dataset experiments, demonstrating its strong generalization ability.","authors":["Wei Long","Haifeng Wu","Shiyin Jiang","Jinhua Zhang","Xinchun Ji","Shuhang Gu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03822v1","updated":"2026-01-07T11:30:55Z","published":"2026-01-07T11:30:55Z","title":"ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition","summary":"Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.","authors":["Muyang Zhao","Qi Qi","Hao Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03812v1","updated":"2026-01-07T11:18:10Z","published":"2026-01-07T11:18:10Z","title":"AI Generated Text Detection","summary":"The rapid development of large language models has led to an increase in AI-generated text, with students increasingly using LLM-generated content as their own work, which violates academic integrity. This paper presents an evaluation of AI text detection methods, including both traditional machine learning models and transformer-based architectures. We utilize two datasets, HC3 and DAIGT v2, to build a unified benchmark and apply a topic-based data split to prevent information leakage. This approach ensures robust generalization across unseen domains. Our experiments show that TF-IDF logistic regression achieves a reasonable baseline accuracy of 82.87%. However, deep learning models outperform it. The BiLSTM classifier achieves an accuracy of 88.86%, while DistilBERT achieves a similar accuracy of 88.11% with the highest ROC-AUC score of 0.96, demonstrating the strongest overall performance. The results indicate that contextual semantic modeling is significantly superior to lexical features and highlight the importance of mitigating topic memorization through appropriate evaluation protocols. The limitations of this work are primarily related to dataset diversity and computational constraints. In future work, we plan to expand dataset diversity and utilize parameter-efficient fine-tuning methods such as LoRA. We also plan to explore smaller or distilled models and employ more efficient batching strategies and hardware-aware optimization.","authors":["Adilkhan Alikhanov","Aidar Amangeldi","Diar Demeubay","Dilnaz Akhmetzhan","Nurbek Moldakhmetov","Omar Polat","Galymzhan Zharas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.15008v4","updated":"2026-01-07T11:09:58Z","published":"2025-08-20T18:56:26Z","title":"Neural Network Quantization for Microcontrollers: A Comprehensive Survey of Methods, Platforms, and Applications","summary":"The deployment of Quantized Neural Networks (QNNs) on resource-constrained edge devices, such as microcontrollers (MCUs), introduces fundamental challenges in balancing model performance, computational complexity, and memory constraints. Tiny Machine Learning (TinyML) addresses these issues by jointly advancing machine learning algorithms, hardware architectures, and software optimization techniques to enable deep neural network inference on embedded systems. This survey provides a hardware-oriented perspective on neural network quantization, systematically reviewing the quantization methods most relevant to MCUs and extreme-edge devices. Particular emphasis is placed on the critical trade-offs between model performance and the capabilities of MCU-class hardware, including memory hierarchies, numerical representations, and accelerator support. The survey further reviews contemporary MCU hardware platforms, including ARM-based and RISC-V-based designs, as well as MCUs integrating neural processing units (NPUs) for low-precision inference, together with the supporting software stacks. In addition, we analyze real-world deployments of quantized models on MCUs and consolidate the application domains in which such systems are used. Finally, we discuss open challenges and outline promising future directions toward scalable, energy-efficient, and sustainable AI deployment on edge devices.","authors":["Hamza A. Abushahla","Dara Varam","Ariel Justine N. Panopio","Mohamed I. AlHajri"],"pdf_url":"","comment":"40 pages, 16 figures, 8 Tables"},{"id":"http://arxiv.org/abs/2601.03798v1","updated":"2026-01-07T10:55:04Z","published":"2026-01-07T10:55:04Z","title":"Where meaning lives: Layer-wise accessibility of psycholinguistic features in encoder and decoder language models","summary":"Understanding where transformer language models encode psychologically meaningful aspects of meaning is essential for both theory and practice. We conduct a systematic layer-wise probing study of 58 psycholinguistic features across 10 transformer models, spanning encoder-only and decoder-only architectures, and compare three embedding extraction methods. We find that apparent localization of meaning is strongly method-dependent: contextualized embeddings yield higher feature-specific selectivity and different layer-wise profiles than isolated embeddings. Across models and methods, final-layer representations are rarely optimal for recovering psycholinguistic information with linear probes. Despite these differences, models exhibit a shared depth ordering of meaning dimensions, with lexical properties peaking earlier and experiential and affective dimensions peaking later. Together, these results show that where meaning \"lives\" in transformer models reflects an interaction between methodological choices and architectural constraints.","authors":["Taisiia Tikhomirova","Dirk U. Wulff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.19695v2","updated":"2026-01-07T10:51:43Z","published":"2025-09-24T02:06:26Z","title":"DyBBT: Dynamic Balance via Bandit inspired Targeting for Dialog Policy with Cognitive Dual-Systems","summary":"Task oriented dialog systems often rely on static exploration strategies that do not adapt to dynamic dialog contexts, leading to inefficient exploration and suboptimal performance. We propose DyBBT, a novel dialog policy learning framework that formalizes the exploration challenge through a structured cognitive state space capturing dialog progression, user uncertainty, and slot dependency. DyBBT proposes a bandit inspired meta-controller that dynamically switches between a fast intuitive inference (System 1) and a slow deliberative reasoner (System 2) based on real-time cognitive states and visitation counts. Extensive experiments on single- and multi-domain benchmarks show that DyBBT achieves state-of-the-art performance in success rate, efficiency, and generalization, with human evaluations confirming its decisions are well aligned with expert judgment. Code is available at https://github.com/carsonz/DyBBT.","authors":["Shuyu Zhang","Yifan Wei","Jialuo Yuan","Xinru Wang","Yanmin Zhu","Bin Li","Yujie Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.19742v3","updated":"2026-01-07T10:51:23Z","published":"2025-09-24T03:44:16Z","title":"HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST","summary":"Zero-shot Dialog State Tracking (zs-DST) is essential for enabling Task-Oriented Dialog Systems (TODs) to generalize to new domains without costly data annotation. A central challenge lies in the semantic misalignment between dynamic dialog contexts and static prompts, leading to inflexible cross-layer coordination, domain interference, and catastrophic forgetting. To tackle this, we propose Hierarchical Collaborative Low-Rank Adaptation (HiCoLoRA), a framework that enhances zero-shot slot inference through robust prompt alignment. It features a hierarchical LoRA architecture for dynamic layer-specific processing (combining lower-layer heuristic grouping and higher-layer full interaction), integrates Spectral Joint Domain-Slot Clustering to identify transferable associations (feeding an Adaptive Linear Fusion Mechanism), and employs Semantic-Enhanced SVD Initialization (SemSVD-Init) to preserve pre-trained knowledge. Experiments on multi-domain datasets MultiWOZ and SGD show that HiCoLoRA outperforms baselines, achieving SOTA in zs-DST. Code is available at https://github.com/carsonz/HiCoLoRA.","authors":["Shuyu Zhang","Yifan Wei","Xinru Wang","Yanmin Zhu","Yangfan He","Yixuan Weng","Bin Li","Yujie Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03794v1","updated":"2026-01-07T10:50:35Z","published":"2026-01-07T10:50:35Z","title":"An Algorithmic Framework for Systematic Literature Reviews: A Case Study for Financial Narratives","summary":"This paper introduces an algorithmic framework for conducting systematic literature reviews (SLRs), designed to improve efficiency, reproducibility, and selection quality assessment in the literature review process. The proposed method integrates Natural Language Processing (NLP) techniques, clustering algorithms, and interpretability tools to automate and structure the selection and analysis of academic publications. The framework is applied to a case study focused on financial narratives, an emerging area in financial economics that examines how structured accounts of economic events, formed by the convergence of individual interpretations, influence market dynamics and asset prices. Drawing from the Scopus database of peer-reviewed literature, the review highlights research efforts to model financial narratives using various NLP techniques. Results reveal that while advances have been made, the conceptualization of financial narratives remains fragmented, often reduced to sentiment analysis, topic modeling, or their combination, without a unified theoretical framework. The findings underscore the value of more rigorous and dynamic narrative modeling approaches and demonstrate the effectiveness of the proposed algorithmic SLR methodology.","authors":["Gabin Taibi","Joerg Osterrieder"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03791v1","updated":"2026-01-07T10:49:36Z","published":"2026-01-07T10:49:36Z","title":"Do LLMs Really Memorize Personally Identifiable Information? Revisiting PII Leakage with a Cue-Controlled Memorization Framework","summary":"Large Language Models (LLMs) have been reported to \"leak\" Personally Identifiable Information (PII), with successful PII reconstruction often interpreted as evidence of memorization. We propose a principled revision of memorization evaluation for LLMs, arguing that PII leakage should be evaluated under low lexical cue conditions, where target PII cannot be reconstructed through prompt-induced generalization or pattern completion. We formalize Cue-Resistant Memorization (CRM) as a cue-controlled evaluation framework and a necessary condition for valid memorization evaluation, explicitly conditioning on prompt-target overlap cues. Using CRM, we conduct a large-scale multilingual re-evaluation of PII leakage across 32 languages and multiple memorization paradigms. Revisiting reconstruction-based settings, including verbatim prefix-suffix completion and associative reconstruction, we find that their apparent effectiveness is driven primarily by direct surface-form cues rather than by true memorization. When such cues are controlled for, reconstruction success diminishes substantially. We further examine cue-free generation and membership inference, both of which exhibit extremely low true positive rates. Overall, our results suggest that previously reported PII leakage is better explained by cue-driven behavior than by genuine memorization, highlighting the importance of cue-controlled evaluation for reliably quantifying privacy-relevant memorization in LLMs.","authors":["Xiaoyu Luo","Yiyi Chen","Qiongxiu Li","Johannes Bjerva"],"pdf_url":"","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2601.03790v1","updated":"2026-01-07T10:49:00Z","published":"2026-01-07T10:49:00Z","title":"NeoAMT: Neologism-Aware Agentic Machine Translation with Reinforcement Learning","summary":"Neologism-aware machine translation aims to translate source sentences containing neologisms into target languages. This field remains underexplored compared with general machine translation (MT). In this paper, we propose an agentic framework, NeoAMT, for neologism-aware machine translation using a Wiktionary search tool. Specifically, we first create a new dataset for neologism-aware machine translation and develop a search tool based on Wiktionary. The new dataset covers 16 languages and 75 translation directions and is derived from approximately 10 million records of an English Wiktionary dump. The retrieval corpus of the search tool is also constructed from around 3 million cleaned records of the Wiktionary dump. We then use it for training the translation agent with reinforcement learning (RL) and evaluating the accuracy of neologism-aware machine translation. Based on this, we also propose an RL training framework that contains a novel reward design and an adaptive rollout generation approach by leveraging \"translation difficulty\" to further improve the translation quality of translation agents using our search tool.","authors":["Zhongtao Miao","Kaiyan Zhao","Masaaki Nagata","Yoshimasa Tsuruoka"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.15553v3","updated":"2026-01-07T10:48:53Z","published":"2025-05-21T14:14:47Z","title":"Social Bias in Popular Question-Answering Benchmarks","summary":"Question-answering (QA) and reading comprehension (RC) benchmarks are commonly used for assessing the capabilities of large language models (LLMs) to retrieve and reproduce knowledge. However, we demonstrate that popular QA and RC benchmarks do not cover questions about different demographics or regions in a representative way. We perform a content analysis of 30 benchmark papers and a quantitative analysis of 20 respective benchmark datasets to learn (1) who is involved in the benchmark creation, (2) whether the benchmarks exhibit social bias, or whether this is addressed or prevented, and (3) whether the demographics of the creators and annotators correspond to particular biases in the content. Most benchmark papers analyzed provide insufficient information about those involved in benchmark creation, particularly the annotators. Notably, just one (WinoGrande) explicitly reports measures taken to address social representation issues. Moreover, the data analysis revealed gender, religion, and geographic biases across a wide range of encyclopedic, commonsense, and scholarly benchmarks. Our work adds to the mounting criticism of AI evaluation practices and shines a light on biased benchmarks being a potential source of LLM bias by incentivizing biased inference heuristics.","authors":["Angelie Kraft","Judith Simon","Sonja Schimmler"],"pdf_url":"","comment":"Presented at the main track of the IJCNLP-AACL 2025 conference (Mumbai and Online)"},{"id":"http://arxiv.org/abs/2601.03788v1","updated":"2026-01-07T10:38:35Z","published":"2026-01-07T10:38:35Z","title":"Criminal Liability of Generative Artificial Intelligence Providers for User-Generated Child Sexual Abuse Material","summary":"The development of more powerful Generative Artificial Intelligence (GenAI) has expanded its capabilities and the variety of outputs. This has introduced significant legal challenges, including gray areas in various legal systems, such as the assessment of criminal liability for those responsible for these models. Therefore, we conducted a multidisciplinary study utilizing the statutory interpretation of relevant German laws, which, in conjunction with scenarios, provides a perspective on the different properties of GenAI in the context of Child Sexual Abuse Material (CSAM) generation. We found that generating CSAM with GenAI may have criminal and legal consequences not only for the user committing the primary offense but also for individuals responsible for the models, such as independent software developers, researchers, and company representatives. Additionally, the assessment of criminal liability may be affected by contextual and technical factors, including the type of generated image, content moderation policies, and the model's intended purpose. Based on our findings, we discussed the implications for different roles, as well as the requirements when developing such systems.","authors":["Anamaria Mojica-Hanke","Thomas Goger","Svenja Wölfel","Brian Valerius","Steffen Herbold"],"pdf_url":"","comment":"Accepted at the International Conference on AI Engineering"},{"id":"http://arxiv.org/abs/2601.03785v1","updated":"2026-01-07T10:36:29Z","published":"2026-01-07T10:36:29Z","title":"Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents","summary":"Human-agent dialogues often exhibit topic continuity-a stable thematic frame that evolves through temporally adjacent exchanges-yet most large language model (LLM) agent memory systems fail to preserve it. Existing designs follow a fragmentation-compensation paradigm: they first break dialogue streams into isolated utterances for storage, then attempt to restore coherence via embedding-based retrieval. This process irreversibly damages narrative and causal flow, while biasing retrieval towards lexical similarity. We introduce membox, a hierarchical memory architecture centered on a Topic Loom that continuously monitors dialogue in a sliding-window fashion, grouping consecutive same-topic turns into coherent \"memory boxes\" at storage time. Sealed boxes are then linked by a Trace Weaver into long-range event-timeline traces, recovering macro-topic recurrences across discontinuities. Experiments on LoCoMo demonstrate that Membox achieves up to 68% F1 improvement on temporal reasoning tasks, outperforming competitive baselines (e.g., Mem0, A-MEM). Notably, Membox attains these gains while using only a fraction of the context tokens required by existing methods, highlighting a superior balance between efficiency and effectiveness. By explicitly modeling topic continuity, Membox offers a cognitively motivated mechanism for enhancing both coherence and efficiency in LLM agents.","authors":["Dehao Tao","Guoliang Ma","Yongfeng Huang","Minghu Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.09668v2","updated":"2026-01-07T10:34:27Z","published":"2025-10-08T09:55:18Z","title":"A Hybrid Computational Intelligence Framework with Metaheuristic Optimization for Drug-Drug Interaction Prediction","summary":"Drug-drug interactions (DDIs) are a leading cause of preventable adverse events, often complicating treatment and increasing healthcare costs. At the same time, knowing which drugs do not interact is equally important, as such knowledge supports safer prescriptions and better patient outcomes. In this study, we propose an interpretable and efficient framework that blends modern machine learning with domain knowledge to improve DDI prediction. Our approach combines two complementary molecular embeddings - Mol2Vec, which captures fragment-level structural patterns, and SMILES-BERT, which learns contextual chemical features - together with a leakage-free, rule-based clinical score (RBScore) that injects pharmacological knowledge without relying on interaction labels. A lightweight neural classifier is then optimized using a novel three-stage metaheuristic strategy (RSmpl-ACO-PSO), which balances global exploration and local refinement for stable performance. Experiments on real-world datasets demonstrate that the model achieves high predictive accuracy (ROC-AUC 0.911, PR-AUC 0.867 on DrugBank) and generalizes well to a clinically relevant Type 2 Diabetes Mellitus cohort. Beyond raw performance, studies show how embedding fusion, RBScore, and the optimizer each contribute to precision and robustness. Together, these results highlight a practical pathway for building reliable, interpretable, and computationally efficient models that can support safer drug therapies and clinical decision-making.","authors":["Maryam Abdollahi Shamami","Babak Teimourpour","Farshad Sharifi"],"pdf_url":"","comment":"After further internal review, we identified that the methodological contribution claimed in Section 3 substantially overlaps with prior published work and lacks sufficient novel theoretical or empirical justification. As this affects the core contribution, the authors request withdrawal rather than replacement"},{"id":"http://arxiv.org/abs/2512.16953v2","updated":"2026-01-07T10:32:41Z","published":"2025-12-17T17:38:57Z","title":"Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases","summary":"Recognizing similarities among entities is central to both human cognition and computational intelligence. Within this broader landscape, Entity Set Expansion is one prominent task aimed at taking an initial set of (tuples of) entities and identifying additional ones that share relevant semantic properties with the former -- potentially repeating the process to form increasingly broader sets. However, this ``linear'' approach does not unveil the richer ``taxonomic'' structures present in knowledge resources. A recent logic-based framework introduces the notion of an expansion graph: a rooted directed acyclic graph where each node represents a semantic generalization labeled by a logical formula, and edges encode strict semantic inclusion. This structure supports taxonomic expansions of entity sets driven by knowledge bases. Yet, the potentially large size of such graphs may make full materialization impractical in real-world scenarios. To overcome this, we formalize reasoning tasks that check whether two tuples belong to comparable, incomparable, or the same nodes in the graph. Our results show that, under realistic assumptions -- such as bounding the input or limiting entity descriptions -- these tasks can be implemented efficiently. This enables local, incremental navigation of expansion graphs, supporting practical applications without requiring full graph construction.","authors":["Giovanni Amendola","Pietro Cofone","Marco Manna","Aldo Ricioppo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03782v1","updated":"2026-01-07T10:29:12Z","published":"2026-01-07T10:29:12Z","title":"PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation","summary":"Humans anticipate, from a glance and a contemplated action of their bodies, how the 3D world will respond, a capability that is equally vital for robotic manipulation. We introduce PointWorld, a large pre-trained 3D world model that unifies state and action in a shared 3D space as 3D point flows: given one or few RGB-D images and a sequence of low-level robot action commands, PointWorld forecasts per-pixel displacements in 3D that respond to the given actions. By representing actions as 3D point flows instead of embodiment-specific action spaces (e.g., joint positions), this formulation directly conditions on physical geometries of robots while seamlessly integrating learning across embodiments. To train our 3D world model, we curate a large-scale dataset spanning real and simulated robotic manipulation in open-world environments, enabled by recent advances in 3D vision and simulated environments, totaling about 2M trajectories and 500 hours across a single-arm Franka and a bimanual humanoid. Through rigorous, large-scale empirical studies of backbones, action representations, learning objectives, partial observability, data mixtures, domain transfers, and scaling, we distill design principles for large-scale 3D world modeling. With a real-time (0.1s) inference speed, PointWorld can be efficiently integrated in the model-predictive control (MPC) framework for manipulation. We demonstrate that a single pre-trained checkpoint enables a real-world Franka robot to perform rigid-body pushing, deformable and articulated object manipulation, and tool use, without requiring any demonstrations or post-training and all from a single image captured in-the-wild. Project website at https://point-world.github.io/.","authors":["Wenlong Huang","Yu-Wei Chao","Arsalan Mousavian","Ming-Yu Liu","Dieter Fox","Kaichun Mo","Li Fei-Fei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23412v2","updated":"2026-01-07T10:27:34Z","published":"2025-12-29T12:16:12Z","title":"MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning","summary":"Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks involving multi-step interactions with external environments. In this work, we introduce MindWatcher, a TIR agent integrating interleaved thinking and multimodal chain-of-thought (CoT) reasoning. MindWatcher can autonomously decide whether and how to invoke diverse tools and coordinate their use, without relying on human prompts or workflows. The interleaved thinking paradigm enables the model to switch between thinking and tool calling at any intermediate stage, while its multimodal CoT capability allows manipulation of images during reasoning to yield more precise search results. We implement automated data auditing and evaluation pipelines, complemented by manually curated high-quality datasets for training, and we construct a benchmark, called MindWatcher-Evaluate Bench (MWE-Bench), to evaluate its performance. MindWatcher is equipped with a comprehensive suite of auxiliary reasoning tools, enabling it to address broad-domain multimodal problems. A large-scale, high-quality local image retrieval database, covering eight categories including cars, animals, and plants, endows model with robust object recognition despite its small size. Finally, we design a more efficient training infrastructure for MindWatcher, enhancing training speed and hardware utilization. Experiments not only demonstrate that MindWatcher matches or exceeds the performance of larger or more recent models through superior tool invocation, but also uncover critical insights for agent training, such as the genetic inheritance phenomenon in agentic RL.","authors":["Jiawei Chen","Xintian Shen","Lihao Zheng","Zhenwei Shao","Handong Cui","Chaoqun Du","Li Gong","Feng Gu","Xuefeng Hao","Wei He","Jiabang He","Yi Hu","Bin Huang","Shanshan Li","Qizhen Li","Jing Luo","Zide Liu","Xiaobo Liu","Ning Mao","Lifu Mu","Xuhao Pan","Zhiheng Qu","Chang Ren","Xudong Rao","Haoyi Sun","Qian Wang","Shuai Wang","Zhichao Wang","Wei Wang","Lian Wen","Jiqing Zhan","Hongfu Yang","Sheng Yang","Jiajun Yang","Pengfei Yu","Hongyuan Zhang","Bin Zhang","Chunpeng Zhou","Zheng Zhou","Shucheng Zhou","Shuo Xie","Yun Zhu","Hao Ma","Tao Wei","Pan Zhou","Wei Chen"],"pdf_url":"","comment":"Technique Report"},{"id":"http://arxiv.org/abs/2511.12631v2","updated":"2026-01-07T10:24:02Z","published":"2025-11-16T14:52:54Z","title":"Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation","summary":"While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and text inputs, eliminating discrepancies between heterogeneous modality representations. The framework facilitates comprehensive multimodal feature interaction through stacked, newly designed multivariate transformer blocks that process all conditions synchronously. Additionally, we design a novel decoupled attention mechanism by dissociating implicit dependencies between mask tokens and temporal embeddings. This mechanism segregates internal computations into dynamic and static pathways, enabling caching and reuse of features computed in static pathways after initial calculation, thereby reducing additional computational overhead introduced by mask condition by over 94% while maintaining performance. Extensive experiments demonstrate that MDiTFace significantly outperforms other competing methods in terms of both facial fidelity and conditional consistency.","authors":["Yushe Cao","Dianxi Shi","Xing Fu","Xuechao Zou","Haikuo Peng","Xueqi Li","Chun Yu","Junliang Xing"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.06684v4","updated":"2026-01-07T10:17:03Z","published":"2025-02-10T17:11:20Z","title":"EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks","summary":"Recent foundational models for tabular data, such as TabPFN, excel at adapting to new tasks via in-context learning, but remain constrained to a fixed, pre-defined number of target dimensions-often necessitating costly ensembling strategies. We trace this constraint to a deeper architectural shortcoming: these models lack target equivariance, so that permuting target dimension orderings alters their predictions. This deficiency gives rise to an irreducible \"equivariance gap\", an error term that introduces instability in predictions. We eliminate this gap by designing a fully target-equivariant architecture-ensuring permutation invariance via equivariant encoders, decoders, and a bi-attention mechanism. Empirical evaluation on standard classification benchmarks shows that, on datasets with more classes than those seen during pre-training, our model matches or surpasses existing methods while incurring lower computational overhead.","authors":["Michael Arbel","David Salinas","Frank Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10549v2","updated":"2026-01-07T10:13:05Z","published":"2025-10-12T11:11:20Z","title":"ELAIPBench: A Benchmark for Expert-Level Artificial Intelligence Paper Understanding","summary":"While large language models (LLMs) excel at many domain-specific tasks, their ability to deeply comprehend and reason about full-length academic papers remains underexplored. Existing benchmarks often fall short of capturing such depth, either due to surface-level question design or unreliable evaluation metrics. To address this gap, we introduce ELAIPBench, a benchmark curated by domain experts to evaluate LLMs' comprehension of artificial intelligence (AI) research papers. Developed through an incentive-driven, adversarial annotation process, ELAIPBench features 403 multiple-choice questions from 137 papers. It spans three difficulty levels and emphasizes non-trivial reasoning rather than shallow retrieval. Our experiments show that the best-performing LLM achieves an accuracy of only 39.95%, far below human performance. Moreover, we observe that frontier LLMs equipped with a thinking mode or a retrieval-augmented generation (RAG) system fail to improve final results-even harming accuracy due to overthinking or noisy retrieval. These findings underscore the significant gap between current LLM capabilities and genuine comprehension of academic papers.","authors":["Xinbang Dai","Huikang Hu","Yongrui Chen","Jiaqi Li","Rihui Jin","Yuyang Zhang","Xiaoguang Li","Lifeng Shang","Guilin Qi"],"pdf_url":"","comment":"24 pages, 21 figures"},{"id":"http://arxiv.org/abs/2601.03774v1","updated":"2026-01-07T10:12:34Z","published":"2026-01-07T10:12:34Z","title":"Scalable Machine Learning Force Fields for Macromolecular Systems Through Long-Range Aware Message Passing","summary":"Machine learning force fields (MLFFs) have revolutionized molecular simulations by providing quantum mechanical accuracy at the speed of molecular mechanical computations. However, a fundamental reliance of these models on fixed-cutoff architectures limits their applicability to macromolecular systems where long-range interactions dominate. We demonstrate that this locality constraint causes force prediction errors to scale monotonically with system size, revealing a critical architectural bottleneck. To overcome this, we establish the systematically designed MolLR25 ({Mol}ecules with {L}ong-{R}ange effect) benchmark up to 1200 atoms, generated using high-fidelity DFT, and introduce E2Former-LSR, an equivariant transformer that explicitly integrates long-range attention blocks. E2Former-LSR exhibits stable error scaling, achieves superior fidelity in capturing non-covalent decay, and maintains precision on complex protein conformations. Crucially, its efficient design provides up to 30% speedup compared to purely local models. This work validates the necessity of non-local architectures for generalizable MLFFs, enabling high-fidelity molecular dynamics for large-scale chemical and biological systems.","authors":["Chu Wang","Lin Huang","Xinran Wei","Tao Qin","Arthur Jiang","Lixue Cheng","Jia Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02071v2","updated":"2026-01-07T10:02:54Z","published":"2026-01-05T12:50:50Z","title":"FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations","summary":"Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.","authors":["Adeshola Okubena","Yusuf Ali Mohammed","Moe Elbadawi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03769v1","updated":"2026-01-07T10:02:27Z","published":"2026-01-07T10:02:27Z","title":"EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation","summary":"Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality CoT supervision traces. EntroCoT first proposes an entropy-based mechanism to segment the reasoning trace into multiple steps at uncertain junctures, and then introduces a Monte Carlo rollout-based mechanism to evaluate the marginal contribution of each step. By accurately filtering deceptive reasoning samples, EntroCoT constructs a high-quality dataset where every intermediate step in each reasoning trace facilitates the final answer. Extensive experiments on mathematical benchmarks demonstrate that fine-tuning on the subset constructed by EntroCoT consistently outperforms the baseslines of full-dataset supervision.","authors":["Zihang Li","Yuhang Wang","Yikun Zong","Wenhan Yu","Xiaokun Yuan","Runhan Jiang","Zirui Liu","Tong Yang","Arthur Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03764v1","updated":"2026-01-07T10:00:17Z","published":"2026-01-07T10:00:17Z","title":"Learning Shrinks the Hard Tail: Training-Dependent Inference Scaling in a Solvable Linear Model","summary":"We analyze neural scaling laws in a solvable model of last-layer fine-tuning where targets have intrinsic, instance-heterogeneous difficulty. In our Latent Instance Difficulty (LID) model, each input's target variance is governed by a latent ``precision'' drawn from a heavy-tailed distribution. While generalization loss recovers standard scaling laws, our main contribution connects this to inference. The pass@$k$ failure rate exhibits a power-law decay, $k^{-β_\\text{eff}}$, but the observed exponent $β_\\text{eff}$ is training-dependent. It grows with sample size $N$ before saturating at an intrinsic limit $β$ set by the difficulty distribution's tail. This coupling reveals that learning shrinks the ``hard tail'' of the error distribution: improvements in the model's generalization error steepen the pass@$k$ curve until irreducible target variance dominates. The LID model yields testable, closed-form predictions for this behavior, including a compute-allocation rule that favors training before saturation and inference attempts after. We validate these predictions in simulations and in two real-data proxies: CIFAR-10H (human-label variance) and a maths teacher-student distillation task.","authors":["Noam Levi"],"pdf_url":"","comment":"10 pages"},{"id":"http://arxiv.org/abs/2601.03752v1","updated":"2026-01-07T09:43:13Z","published":"2026-01-07T09:43:13Z","title":"Evaluation of Multilingual LLMs Personalized Text Generation Capabilities Targeting Groups and Social-Media Platforms","summary":"Capabilities of large language models to generate multilingual coherent text have continuously enhanced in recent years, which opens concerns about their potential misuse. Previous research has shown that they can be misused for generation of personalized disinformation in multiple languages. It has also been observed that personalization negatively affects detectability of machine-generated texts; however, this has been studied in the English language only. In this work, we examine this phenomenon across 10 languages, while we focus not only on potential misuse of personalization capabilities, but also on potential benefits they offer. Overall, we cover 1080 combinations of various personalization aspects in the prompts, for which the texts are generated by 16 distinct language models (17,280 texts in total). Our results indicate that there are differences in personalization quality of the generated texts when targeting demographic groups and when targeting social-media platforms across languages. Personalization towards platforms affects detectability of the generated texts in a higher scale, especially in English, where the personalization quality is the highest.","authors":["Dominik Macko"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03748v1","updated":"2026-01-07T09:37:36Z","published":"2026-01-07T09:37:36Z","title":"Bridging OLAP and RAG: A Multidimensional Approach to the Design of Corpus Partitioning","summary":"Retrieval-Augmented Generation (RAG) systems are increasingly deployed on large-scale document collections, often comprising millions of documents and tens of millions of text chunks. In industrial-scale retrieval platforms, scalability is typically addressed through horizontal sharding and a combination of Approximate Nearest-Neighbor search, hybrid indexing, and optimized metadata filtering. Although effective from an efficiency perspective, these mechanisms rely on bottom-up, similarity-driven organization and lack a conceptual rationale for corpus partitioning. In this paper, we claim that the design of large-scale RAG systems may benefit from the combination of two orthogonal strategies: semantic clustering, which optimizes locality in embedding space, and multidimensional partitioning, which governs where retrieval should occur based on conceptual dimensions such as time and organizational context. Although such dimensions are already implicitly present in current systems, they are used in an ad hoc and poorly structured manner. We propose the Dimensional Fact Model (DFM) as a conceptual framework to guide the design of multidimensional partitions for RAG corpora. The DFM provides a principled way to reason about facts, dimensions, hierarchies, and granularity in retrieval-oriented settings. This framework naturally supports hierarchical routing and controlled fallback strategies, ensuring that retrieval remains robust even in the presence of incomplete metadata, while transforming the search process from a 'black-box' similarity matching into a governable and deterministic workflow. This work is intended as a position paper; its goal is to bridge the gap between OLAP-style multidimensional modeling and modern RAG architectures, and to stimulate further research on principled, explainable, and governable retrieval strategies at scale.","authors":["Dario Maio","Stefano Rizzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03743v1","updated":"2026-01-07T09:31:10Z","published":"2026-01-07T09:31:10Z","title":"O-Researcher: An Open Ended Deep Research Model via Multi-Agent Distillation and Agentic RL","summary":"The performance gap between closed-source and open-source large language models (LLMs) is largely attributed to disparities in access to high-quality training data. To bridge this gap, we introduce a novel framework for the automated synthesis of sophisticated, research-grade instructional data. Our approach centers on a multi-agent workflow where collaborative AI agents simulate complex tool-integrated reasoning to generate diverse and high-fidelity data end-to-end. Leveraging this synthesized data, we develop a two-stage training strategy that integrates supervised fine-tuning with a novel reinforcement learning method, designed to maximize model alignment and capability. Extensive experiments demonstrate that our framework empowers open-source models across multiple scales, enabling them to achieve new state-of-the-art performance on the major deep research benchmark. This work provides a scalable and effective pathway for advancing open-source LLMs without relying on proprietary data or models.","authors":["Yi Yao","He Zhu","Piaohong Wang","Jincheng Ren","Xinlong Yang","Qianben Chen","Xiaowan Li","Dingfeng Shi","Jiaxian Li","Qiexiang Wang","Sinuo Wang","Xinpeng Liu","Jiaqi Wu","Minghao Liu","Wangchunshu Zhou"],"pdf_url":"","comment":"22 pages"},{"id":"http://arxiv.org/abs/2407.19204v3","updated":"2026-01-07T09:30:15Z","published":"2024-07-27T08:14:18Z","title":"Towards the Terminator Economy: Assessing Job Exposure to AI through LLMs","summary":"AI and related technologies are reshaping jobs and tasks, either by automating or augmenting human skills in the workplace. Many researchers have been working on estimating if and to what extent jobs and tasks are exposed to the risk of being automatized by AI-related technologies. Our work tackles this issue through a data-driven approach by: (i) developing a reproducible framework that uses cutting-edge open-source large language models to assess the current capabilities of AI and robotics in performing job-related tasks; (ii) formalizing and computing a measure of AI exposure by occupation, the Task Exposure to AI (TEAI) index, and a measure of Task Replacement by AI (TRAI), both validated through a human user evaluation and compared with the state of the art.\n  Our results show that the TEAI index is positively correlated with cognitive, problem-solving and management skills, while it is negatively correlated with social skills. Applying the index to the US, we obtain that about one-third of US employment is highly exposed to AI, primarily in high-skill jobs requiring a graduate or postgraduate level of education. We also find that AI exposure is positively associated with both employment and wage growth in 2003-2023, suggesting that AI has an overall positive effect on productivity.\n  Considering specifically the TRAI index, we find that even in high-skill occupations, AI exhibits high variability in task substitution, suggesting that AI and humans complement each other within the same occupation, while the allocation of tasks within occupations is likely to change.\n  All results, models, and code are freely available online to allow the community to reproduce our results, compare outcomes, and use our work as a benchmark to monitor AI's progress over time.","authors":["Emilio Colombo","Fabio Mercorio","Mario Mezzanzanica","Antonio Serino"],"pdf_url":"","comment":"10 pages. Accepted for publication at IJCAI 2025. Final version available at https://doi.org/10.24963/ijcai.2025/1066"},{"id":"http://arxiv.org/abs/2601.03733v1","updated":"2026-01-07T09:25:04Z","published":"2026-01-07T09:25:04Z","title":"RadDiff: Describing Differences in Radiology Image Sets with Natural Language","summary":"Understanding how two radiology image sets differ is critical for generating clinical insights and for interpreting medical AI systems. We introduce RadDiff, a multimodal agentic system that performs radiologist-style comparative reasoning to describe clinically meaningful differences between paired radiology studies. RadDiff builds on a proposer-ranker framework from VisDiff, and incorporates four innovations inspired by real diagnostic workflows: (1) medical knowledge injection through domain-adapted vision-language models; (2) multimodal reasoning that integrates images with their clinical reports; (3) iterative hypothesis refinement across multiple reasoning rounds; and (4) targeted visual search that localizes and zooms in on salient regions to capture subtle findings. To evaluate RadDiff, we construct RadDiffBench, a challenging benchmark comprising 57 expert-validated radiology study pairs with ground-truth difference descriptions. On RadDiffBench, RadDiff achieves 47% accuracy, and 50% accuracy when guided by ground-truth reports, significantly outperforming the general-domain VisDiff baseline. We further demonstrate RadDiff's versatility across diverse clinical tasks, including COVID-19 phenotype comparison, racial subgroup analysis, and discovery of survival-related imaging features. Together, RadDiff and RadDiffBench provide the first method-and-benchmark foundation for systematically uncovering meaningful differences in radiological data.","authors":["Xiaoxian Shen","Yuhui Zhang","Sahithi Ankireddy","Xiaohan Wang","Maya Varma","Henry Guo","Curtis Langlotz","Serena Yeung-Levy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03731v1","updated":"2026-01-07T09:22:28Z","published":"2026-01-07T09:22:28Z","title":"From Laboratory to Real-World Applications: Benchmarking Agentic Code Reasoning at the Repository Level","summary":"As large language models (LLMs) evolve into autonomous agents, evaluating repository-level reasoning, the ability to maintain logical consistency across massive, real-world, interdependent file systems, has become critical. Current benchmarks typically fluctuate between isolated code snippets and black-box evaluations. We present RepoReason, a white-box diagnostic benchmark centered on abductive assertion verification. To eliminate memorization while preserving authentic logical depth, we implement an execution-driven mutation framework that utilizes the environment as a semantic oracle to regenerate ground-truth states. Furthermore, we establish a fine-grained diagnostic system using dynamic program slicing, quantifying reasoning via three orthogonal metrics: $ESV$ (reading load), $MCL$ (simulation depth), and $DFI$ (integration width). Comprehensive evaluations of frontier models (e.g., Claude-4.5-Sonnet, DeepSeek-v3.1-Terminus) reveal a prevalent aggregation deficit, where integration width serves as the primary cognitive bottleneck. Our findings provide granular white-box insights for optimizing the next generation of agentic software engineering.","authors":["Jia Li","Yuxin Su","Michael R. Lyu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03728v1","updated":"2026-01-07T09:21:38Z","published":"2026-01-07T09:21:38Z","title":"CSMCIR: CoT-Enhanced Symmetric Alignment with Memory Bank for Composed Image Retrieval","summary":"Composed Image Retrieval (CIR) enables users to search for target images using both a reference image and manipulation text, offering substantial advantages over single-modality retrieval systems. However, existing CIR methods suffer from representation space fragmentation: queries and targets comprise heterogeneous modalities and are processed by distinct encoders, forcing models to bridge misaligned representation spaces only through post-hoc alignment, which fundamentally limits retrieval performance. This architectural asymmetry manifests as three distinct, well-separated clusters in the feature space, directly demonstrating how heterogeneous modalities create fundamentally misaligned representation spaces from initialization. In this work, we propose CSMCIR, a unified representation framework that achieves efficient query-target alignment through three synergistic components. First, we introduce a Multi-level Chain-of-Thought (MCoT) prompting strategy that guides Multimodal Large Language Models to generate discriminative, semantically compatible captions for target images, establishing modal symmetry. Building upon this, we design a symmetric dual-tower architecture where both query and target sides utilize the identical shared-parameter Q-Former for cross-modal encoding, ensuring consistent feature representations and further reducing the alignment gap. Finally, this architectural symmetry enables an entropy-based, temporally dynamic Memory Bank strategy that provides high-quality negative samples while maintaining consistency with the evolving model state. Extensive experiments on four benchmark datasets demonstrate that our CSMCIR achieves state-of-the-art performance with superior training efficiency. Comprehensive ablation studies further validate the effectiveness of each proposed component.","authors":["Zhipeng Qian","Zihan Liang","Yufei Ma","Ben Chen","Huangyu Dai","Yiwei Ma","Jiayi Ji","Chenyi Lei","Han Li","Xiaoshuai Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.07828v2","updated":"2026-01-07T09:16:59Z","published":"2025-07-10T15:01:23Z","title":"Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles","summary":"Content-based puzzle solvers have been extensively studied, demonstrating significant progress in computational techniques. However, their evaluation often lacks realistic challenges crucial for real-world applications, such as the reassembly of fragmented artefacts or shredded documents. In this work, we investigate the robustness of State-Of-The-Art content-based puzzle solvers introducing three types of jigsaw puzzle corruptions: missing pieces, eroded edges, and eroded contents. Evaluating both heuristic and deep learning-based solvers, we analyse their ability to handle these corruptions and identify key limitations. Our results show that solvers developed for standard puzzles have a rapid decline in performance if more pieces are corrupted. However, deep learning models can significantly improve their robustness through fine-tuning with augmented data. Notably, the advanced Positional Diffusion model adapts particularly well, outperforming its competitors in most experiments. Based on our findings, we highlight promising research directions for enhancing the automated reconstruction of real-world artefacts.","authors":["Richard Dirauf","Florian Wolz","Dario Zanca","Björn Eskofier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.00088v2","updated":"2026-01-07T09:09:57Z","published":"2025-10-30T01:25:34Z","title":"Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail","summary":"End-to-end architectures trained via imitation learning have advanced autonomous driving by scaling model size and data, yet performance remains brittle in safety-critical long-tail scenarios where supervision is sparse and causal understanding is limited. We introduce Alpamayo-R1 (AR1), a vision-language-action model (VLA) that integrates Chain of Causation reasoning with trajectory planning for complex driving scenarios. Our approach features three key innovations: (1) the Chain of Causation (CoC) dataset, built through a hybrid auto-labeling and human-in-the-loop pipeline producing decision-grounded, causally linked reasoning traces aligned with driving behaviors; (2) a modular VLA architecture combining Cosmos-Reason, a vision-language model pre-trained for Physical AI, with a diffusion-based trajectory decoder that generates dynamically feasible trajectories in real time; (3) a multi-stage training strategy using supervised fine-tuning to elicit reasoning and reinforcement learning (RL) to enforce reasoning-action consistency and optimize reasoning quality. AR1 achieves up to a 12% improvement in planning accuracy on challenging cases compared to a trajectory-only baseline, with a 35% reduction in close encounter rate in closed-loop simulation. RL post-training improves reasoning quality by 45% and reasoning-action consistency by 37%. Model scaling from 0.5B to 7B parameters shows consistent improvements. On-vehicle road tests confirm real-time performance (99 ms latency) and successful urban deployment. By bridging interpretable reasoning with precise control, AR1 demonstrates a practical path towards Level 4 autonomous driving. Model weights are available at https://huggingface.co/nvidia/Alpamayo-R1-10B with inference code at https://github.com/NVlabs/alpamayo.","authors":[" NVIDIA"," :","Yan Wang","Wenjie Luo","Junjie Bai","Yulong Cao","Tong Che","Ke Chen","Yuxiao Chen","Jenna Diamond","Yifan Ding","Wenhao Ding","Liang Feng","Greg Heinrich","Jack Huang","Peter Karkus","Boyi Li","Pinyi Li","Tsung-Yi Lin","Dongran Liu","Ming-Yu Liu","Langechuan Liu","Zhijian Liu","Jason Lu","Yunxiang Mao","Pavlo Molchanov","Lindsey Pavao","Zhenghao Peng","Mike Ranzinger","Ed Schmerling","Shida Shen","Yunfei Shi","Sarah Tariq","Ran Tian","Tilman Wekel","Xinshuo Weng","Tianjun Xiao","Eric Yang","Xiaodong Yang","Yurong You","Xiaohui Zeng","Wenyuan Zhang","Boris Ivanovic","Marco Pavone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03715v1","updated":"2026-01-07T09:04:52Z","published":"2026-01-07T09:04:52Z","title":"R$^3$L: Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification","summary":"Reinforcement learning drives recent advances in LLM reasoning and agentic capabilities, yet current approaches struggle with both exploration and exploitation. Exploration suffers from low success rates on difficult tasks and high costs of repeated rollouts from scratch. Exploitation suffers from coarse credit assignment and training instability: Trajectory-level rewards penalize valid prefixes for later errors, and failure-dominated groups overwhelm the few positive signals, leaving optimization without constructive direction. To this end, we propose R$^3$L, Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification. To synthesize high-quality trajectories, R$^3$L shifts from stochastic sampling to active synthesis via reflect-then-retry, leveraging language feedback to diagnose errors, transform failed attempts into successful ones, and reduce rollout costs by restarting from identified failure points. With errors diagnosed and localized, Pivotal Credit Assignment updates only the diverging suffix where contrastive signals exist, excluding the shared prefix from gradient update. Since failures dominate on difficult tasks and reflect-then-retry produces off-policy data, risking training instability, Positive Amplification upweights successful trajectories to ensure positive signals guide the optimization process. Experiments on agentic and reasoning tasks demonstrate 5\\% to 52\\% relative improvements over baselines while maintaining training stability. Our code is released at https://github.com/shiweijiezero/R3L.","authors":["Weijie Shi","Yanxi Chen","Zexi Li","Xuchen Pan","Yuchang Sun","Jiajie Xu","Xiaofang Zhou","Yaliang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.04066v7","updated":"2026-01-07T09:02:39Z","published":"2025-02-06T13:23:53Z","title":"Beyond Scaling: Measuring and Predicting the Upper Bound of Knowledge Retention in Language Model Pre-Training","summary":"The GPT-4 technical report suggests that downstream performance can be predicted from pre-training signals, but offers little methodological detail on how to quantify this. This work address this gap by modeling knowledge retention, the capacity of a pre-trained language model to memorize factual information from its corpus, and introduce a principled method to estimate it prior to training. We propose Size-dependent Mutual Information (SMI), an information-theoretic predictor that integrates knowledge frequency, knowledge specificity, and model size to forecast closed-book question answering (QA) accuracy. SMI is validated through large-scale document retrieval over the disclosed pre-training corpora of 21 public and 3 custom models, combined with a robust multi-template QA evaluation. Experiments show that SMI significantly outperforms repetition-based baselines and achieves $R^2$ > 0.7 in predicting QA accuracy for models above 1B parameters, without additional training. The analysis further reveals diminishing returns from scaling data and model size and provides evidence for an intrinsic upper bound on knowledge retention achievable by pre-training alone, motivating retrieval and other augmentation strategies. The dataset and code are available at https://github.com/yuhui1038/SMI.","authors":["Changhao Jiang","Ming Zhang","Yifei Cao","Junjie Ye","Xiaoran Fan","Shihan Dou","Zhiheng Xi","Jiajun Sun","Yi Dong","Yujiong Shen","Jingqi Tong","Baoyu Fan","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.23163v3","updated":"2026-01-07T08:58:31Z","published":"2025-10-27T09:41:29Z","title":"Beyond Direct Generation: A Decomposed Approach to Well-Crafted Screenwriting with LLMs","summary":"The screenplay serves as the foundation for television production, defining narrative structure, character development, and dialogue. While Large Language Models (LLMs) show great potential in creative writing, direct end-to-end generation approaches often fail to produce well-crafted screenplays. We argue this failure stems from forcing a single model to simultaneously master two disparate capabilities: creative narrative construction and rigid format adherence. The resulting outputs may mimic superficial style but lack the deep structural integrity and storytelling substance required for professional use. To enable LLMs to generate high-quality screenplays, we introduce Dual-Stage Refinement (DSR), a decomposed framework that decouples creative narrative generation from format conversion. The first stage transforms a brief outline into rich, novel-style prose. The second stage refines this narrative into a professionally formatted screenplay. This separation enables the model to specialize in one distinct capability at each stage. A key challenge in implementing DSR is the scarcity of paired outline-to-novel training data. We address this through hybrid data synthesis: reverse synthesis deconstructs existing screenplays into structured inputs, while forward synthesis leverages these inputs to generate high-quality narrative texts as training targets. Blind evaluations by professional screenwriters show that DSR achieves a 75% win rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of human-level performance. Our work demonstrates that decomposed generation architecture with tailored data synthesis effectively specializes LLMs in complex creative domains.","authors":["Hang Lei","Shengyi Zong","Zhaoyan Li","Ziren Zhou","Hao Liu","Liang Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03709v1","updated":"2026-01-07T08:49:02Z","published":"2026-01-07T08:49:02Z","title":"The Power of 10: New Rules for the Digital World","summary":"As artificial intelligence rapidly advances, society is increasingly captivated by promises of superhuman machines and seamless digital futures. Yet these visions often obscure mounting social, ethical, and psychological concerns tied to pervasive digital technologies - from surveillance to mental health crises. This article argues that a guiding ethos is urgently needed to navigate these transformations. Inspired by the lasting influence of the biblical Ten Commandments, a European interdisciplinary group has proposed \"Ten Rules for the Digital World\" - a novel ethical framework to help individuals and societies make prudent, human-centered decisions in the age of \"supercharged\" technology.","authors":["Sarah Spiekermann-Hoff","Marc Langheinrich","Johannes Hoff","Christiane Wendehorst","Jürgen Pfeffer","Thomas Fuchs","Armin Grunwald"],"pdf_url":"","comment":"to be published in Communications of the ACM (submitted 26 June 2025, revised 29 August 2025, accepted 3 November 2025)"},{"id":"http://arxiv.org/abs/2601.03708v1","updated":"2026-01-07T08:46:10Z","published":"2026-01-07T08:46:10Z","title":"MHRC-Bench: A Multilingual Hardware Repository-Level Code Completion benchmark","summary":"Large language models (LLMs) have achieved strong performance on code completion tasks in general-purpose programming languages. However, existing repository-level code completion benchmarks focus almost exclusively on software code and largely overlook hardware description languages. In this work, we present \\textbf{MHRC-Bench}, consisting of \\textbf{MHRC-Bench-Train} and \\textbf{MHRC-Bench-Eval}, the first benchmark designed for multilingual hardware code completion at the repository level. Our benchmark targets completion tasks and covers three major hardware design coding styles. Each completion target is annotated with code-structure-level and hardware-oriented semantic labels derived from concrete syntax tree analysis. We conduct a comprehensive evaluation of models on MHRC-Bench-Eval. Comprehensive evaluation results and analysis demonstrate the effectiveness of MHRC-Bench.","authors":["Qingyun Zou","Jiahao Cui","Nuo Chen","Bingsheng He","Weng-Fai Wong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03704v1","updated":"2026-01-07T08:43:08Z","published":"2026-01-07T08:43:08Z","title":"Investigating Knowledge Distillation Through Neural Networks for Protein Binding Affinity Prediction","summary":"The trade-off between predictive accuracy and data availability makes it difficult to predict protein--protein binding affinity accurately. The lack of experimentally resolved protein structures limits the performance of structure-based machine learning models, which generally outperform sequence-based methods. In order to overcome this constraint, we suggest a regression framework based on knowledge distillation that uses protein structural data during training and only needs sequence data during inference. The suggested method uses binding affinity labels and intermediate feature representations to jointly supervise the training of a sequence-based student network under the guidance of a structure-informed teacher network. Leave-One-Complex-Out (LOCO) cross-validation was used to assess the framework on a non-redundant protein--protein binding affinity benchmark dataset. A maximum Pearson correlation coefficient (P_r) of 0.375 and an RMSE of 2.712 kcal/mol were obtained by sequence-only baseline models, whereas a P_r of 0.512 and an RMSE of 2.445 kcal/mol were obtained by structure-based models. With a P_r of 0.481 and an RMSE of 2.488 kcal/mol, the distillation-based student model greatly enhanced sequence-only performance. Improved agreement and decreased bias were further confirmed by thorough error analyses. With the potential to close the performance gap between sequence-based and structure-based models as larger datasets become available, these findings show that knowledge distillation is an efficient method for transferring structural knowledge to sequence-based predictors. The source code for running inference with the proposed distillation-based binding affinity predictor can be accessed at https://github.com/wajidarshad/ProteinAffinityKD.","authors":["Wajid Arshad Abbasi","Syed Ali Abbas","Maryum Bibi","Saiqa Andleeb","Muhammad Naveed Akhtar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03703v1","updated":"2026-01-07T08:42:14Z","published":"2026-01-07T08:42:14Z","title":"TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL","summary":"Reinforcement learning with group-based objectives, such as Group Relative Policy Optimization (GRPO), is a common framework for aligning large language models on complex reasoning tasks. However, standard GRPO treats each rollout trajectory as an independent flat sequence and assigns a single sequence-level advantage to all tokens, which leads to sample inefficiency and a length bias toward verbose, redundant chains of thought without improving logical depth. We introduce TreeAdv (Tree-Structured Advantage Redistribution for Group-Based RL), which makes the tree structure of group rollouts explicit for both exploration and advantage assignment. Specifically, TreeAdv builds a group of trees (a forest) based on an entropy-driven sampling method where each tree branches at high-uncertainty decisions while sharing low-uncertainty tokens across rollouts. Then, TreeAdv aggregates token-level advantages for internal tree segments by redistributing the advantages of complete rollouts (all leaf nodes), and TreeAdv can easily apply to group-based objectives such as GRPO or GSPO. Across 10 math reasoning benchmarks, TreeAdv consistently outperforms GRPO and GSPO, while using substantially fewer generated tokens under identical supervision, data, and decoding budgets.","authors":["Lang Cao","Hui Ruan","Yongqian Li","Peng Chao","Wu Ning","Haonan Song","Renhong Chen","Yitong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.14803v4","updated":"2026-01-07T08:39:36Z","published":"2025-09-18T09:56:45Z","title":"OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning","summary":"In online learning environments, students often lack personalized peer interactions, which are crucial for cognitive development and learning engagement. Although previous studies have employed large language models (LLMs) to simulate interactive learning environments, these interactions are limited to conversational exchanges, failing to adapt to learners' individualized cognitive and psychological states. As a result, students' engagement is low and they struggle to gain inspiration. To address this challenge, we propose OnlineMate, a multi-agent learning companion system driven by LLMs integrated with Theory of Mind (ToM). OnlineMate simulates peer-like roles, infers learners' psychological states such as misunderstandings and confusion during collaborative discussions, and dynamically adjusts interaction strategies to support higher-order thinking. Comprehensive evaluations, including simulation-based experiments, human assessments, and real classroom trials, demonstrate that OnlineMate significantly promotes deep learning and cognitive engagement by elevating students' average cognitive level while substantially improving emotional engagement scores.","authors":["Xian Gao","Zongyun Zhang","Ting Liu","Yuzhuo Fu"],"pdf_url":"","comment":"work in progress"},{"id":"http://arxiv.org/abs/2601.03701v1","updated":"2026-01-07T08:38:13Z","published":"2026-01-07T08:38:13Z","title":"Inference Attacks Against Graph Generative Diffusion Models","summary":"Graph generative diffusion models have recently emerged as a powerful paradigm for generating complex graph structures, effectively capturing intricate dependencies and relationships within graph data. However, the privacy risks associated with these models remain largely unexplored. In this paper, we investigate information leakage in such models through three types of black-box inference attacks. First, we design a graph reconstruction attack, which can reconstruct graphs structurally similar to those training graphs from the generated graphs. Second, we propose a property inference attack to infer the properties of the training graphs, such as the average graph density and the distribution of densities, from the generated graphs. Third, we develop two membership inference attacks to determine whether a given graph is present in the training set. Extensive experiments on three different types of graph generative diffusion models and six real-world graphs demonstrate the effectiveness of these attacks, significantly outperforming the baseline approaches. Finally, we propose two defense mechanisms that mitigate these inference attacks and achieve a better trade-off between defense strength and target model utility than existing methods. Our code is available at https://zenodo.org/records/17946102.","authors":["Xiuling Wang","Xin Huang","Guibo Luo","Jianliang Xu"],"pdf_url":"","comment":"This work has been accepted by USENIX Security 2026"},{"id":"http://arxiv.org/abs/2601.03700v1","updated":"2026-01-07T08:34:41Z","published":"2026-01-07T08:34:41Z","title":"ADEPT: Adaptive Dynamic Early-Exit Process for Transformers","summary":"The inference of large language models imposes significant computational workloads, often requiring the processing of billions of parameters. Although early-exit strategies have proven effective in reducing computational demands by halting inference earlier, they apply either to only the first token in the generation phase or at the prompt level in the prefill phase. Thus, the Key-Value (KV) cache for skipped layers remains a bottleneck for subsequent token generation, limiting the benefits of early exit. We introduce ADEPT (Adaptive Dynamic Early-exit Process for Transformers), a novel approach designed to overcome this issue and enable dynamic early exit in both the prefill and generation phases. The proposed adaptive token-level early-exit mechanism adjusts computation dynamically based on token complexity, optimizing efficiency without compromising performance. ADEPT further enhances KV generation procedure by decoupling sequential dependencies in skipped layers, making token-level early exit more practical. Experimental results demonstrate that ADEPT improves efficiency by up to 25% in language generation tasks and achieves a 4x speed-up in downstream classification tasks, with up to a 45% improvement in performance.","authors":["Sangmin Yoo","Srikanth Malla","Chiho Choi","Wei D. Lu","Joon Hee Choi"],"pdf_url":"","comment":"11 figures, 8 tables, 22 pages"},{"id":"http://arxiv.org/abs/2509.01211v2","updated":"2026-01-07T08:30:38Z","published":"2025-09-01T07:47:24Z","title":"Web Fraud Attacks Against LLM-Driven Multi-Agent Systems","summary":"With the proliferation of LLM-driven multi-agent systems (MAS), the security of Web links has become a critical concern. Once MAS is induced to trust a malicious link, attackers can use it as a springboard to expand the attack surface. In this paper, we propose Web Fraud Attacks, a novel type of attack manipulating unique structures of web links to deceive MAS. We design 12 representative attack variants that encompass various methods, such as homoglyph deception, sub-directory nesting, and parameter obfuscation. Through extensive experiments on these attack vectors, we demonstrate that Web fraud attacks not only exhibit significant destructive potential across different MAS architectures but also possess a distinct advantage in evasion: they circumvent the need for complex input design, lowering the threshold for attacks significantly. These results underscore the importance of addressing Web fraud attacks, providing new insights into MAS safety. Our code is available at https://github.com/JiangYingEr/Web-Fraud-Attack-in-MAS.","authors":["Dezhang Kong","Hujin Peng","Yilun Zhang","Lele Zhao","Zhenhua Xu","Shi Lin","Changting Lin","Meng Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03693v1","updated":"2026-01-07T08:28:47Z","published":"2026-01-07T08:28:47Z","title":"Can AI Chatbots Provide Coaching in Engineering? Beyond Information Processing Toward Mastery","summary":"Engineering education faces a double disruption: traditional apprenticeship models that cultivated judgment and tacit skill are eroding, just as generative AI emerges as an informal coaching partner. This convergence rekindles long-standing questions in the philosophy of AI and cognition about the limits of computation, the nature of embodied rationality, and the distinction between information processing and wisdom. Building on this rich intellectual tradition, this paper examines whether AI chatbots can provide coaching that fosters mastery rather than merely delivering information. We synthesize critical perspectives from decades of scholarship on expertise, tacit knowledge, and human-machine interaction, situating them within the context of contemporary AI-driven education. Empirically, we report findings from a mixed-methods study (N = 75 students, N = 7 faculty) exploring the use of a coaching chatbot in engineering education. Results reveal a consistent boundary: participants accept AI for technical problem solving (convergent tasks; M = 3.84 on a 1-5 Likert scale) but remain skeptical of its capacity for moral, emotional, and contextual judgment (divergent tasks). Faculty express stronger concerns over risk (M = 4.71 vs. M = 4.14, p = 0.003), and privacy emerges as a key requirement, with 64-71 percent of participants demanding strict confidentiality. Our findings suggest that while generative AI can democratize access to cognitive and procedural support, it cannot replicate the embodied, value-laden dimensions of human mentorship. We propose a multiplex coaching framework that integrates human wisdom within expert-in-the-loop models, preserving the depth of apprenticeship while leveraging AI scalability to enrich the next generation of engineering education.","authors":["Junaid Qadir","Muhammad Adil Attique","Saleha Shoaib","Syed Ibrahim Ghaznavi"],"pdf_url":"","comment":"accepted at IEEE EDUCON 2026"},{"id":"http://arxiv.org/abs/2508.05509v3","updated":"2026-01-07T08:27:26Z","published":"2025-08-07T15:42:00Z","title":"LAG: Logic-Augmented Generation from a Cartesian Perspective","summary":"Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet exhibit critical limitations in knowledge-intensive tasks, often generating hallucinations when faced with questions requiring specialized expertise. While retrieval-augmented generation (RAG) mitigates this by integrating external knowledge, it struggles with complex reasoning scenarios due to its reliance on direct semantic retrieval and lack of structured logical organization. Inspired by Cartesian principles from \\textit{Discours de la méthode}, this paper introduces Logic-Augmented Generation (LAG), a novel paradigm that reframes knowledge augmentation through systematic question decomposition, atomic memory bank and logic-aware reasoning. Specifically, LAG first decomposes complex questions into atomic sub-questions ordered by logical dependencies. It then resolves these sequentially, using prior answers to guide context retrieval for subsequent sub-questions, ensuring stepwise grounding in the logical chain. Experiments on four benchmarks demonstrate that LAG significantly improves accuracy and reduces hallucination over existing methods.","authors":["Yilin Xiao","Chuang Zhou","Yujing Zhang","Qinggang Zhang","Su Dong","Shengyuan Chen","Chang Yang","Xiao Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.08409v3","updated":"2026-01-07T08:26:58Z","published":"2025-11-11T16:22:49Z","title":"Faithful-First Reasoning, Planning, and Acting for Multimodal LLMs","summary":"Multimodal Large Language Models (MLLMs) frequently suffer from unfaithfulness, generating reasoning chains that drift from visual evidence or contradict final predictions. We propose Faithful-First Reasoning, Planning, and Acting (RPA) framework in which FaithEvi provides step-wise and chain-level supervision by evaluating the faithfulness of intermediate reasoning, and FaithAct uses these signals to plan and execute faithfulness-aware actions during inference. Experiments across multiple multimodal reasoning benchmarks show that faithful-first RPA improves perceptual faithfulness by up to 24% over prompt-based and tool-augmented reasoning frameworks, without degrading task accuracy. Our analysis shows that treating faithfulness as a guiding principle perceptually faithful reasoning trajectories and mitigates hallucination behavior. This work thereby establishes a unified framework for both evaluating and enforcing faithfulness in multimodal reasoning. Code will be released upon acceptance.","authors":["Junxian Li","Xinyue Xu","Sai Ma","Di Zhang","Sichao Li"],"pdf_url":"","comment":"16 pages, updated version"},{"id":"http://arxiv.org/abs/2504.05695v4","updated":"2026-01-07T08:26:24Z","published":"2025-04-08T05:37:38Z","title":"Architecture independent generalization bounds for overparametrized deep ReLU networks","summary":"We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove a uniform generalization bound that is independent of the network architecture. We perform computational experiments of our theoretical results with MNIST, and obtain agreement with the true test error within a 22 % margin on average.","authors":["Anandatheertha Bapu","Thomas Chen","Chun-Kai Kevin Chien","Patricia Muñoz Ewald","Andrew G. Moore"],"pdf_url":"","comment":"AMS Latex, 18 pages. Significantly updated, A. Bapu included as coauthor, Section 3 added"},{"id":"http://arxiv.org/abs/2601.03689v1","updated":"2026-01-07T08:24:08Z","published":"2026-01-07T08:24:08Z","title":"A Pre-trained Reaction Embedding Descriptor Capturing Bond Transformation Patterns","summary":"With the rise of data-driven reaction prediction models, effective reaction descriptors are crucial for bridging the gap between real-world chemistry and digital representations. However, general-purpose, reaction-wise descriptors remain scarce. This study introduces RXNEmb, a novel reaction-level descriptor derived from RXNGraphormer, a model pre-trained to distinguish real reactions from fictitious ones with erroneous bond changes, thereby learning intrinsic bond formation and cleavage patterns. We demonstrate its utility by data-driven re-clustering of the USPTO-50k dataset, yielding a classification that more directly reflects bond-change similarities than rule-based categories. Combined with dimensionality reduction, RXNEmb enables visualization of reaction space diversity. Furthermore, attention weight analysis reveals the model's focus on chemically critical sites, providing mechanistic insight. RXNEmb serves as a powerful, interpretable tool for reaction fingerprinting and analysis, paving the way for more data-centric approaches in reaction analysis and discovery.","authors":["Weiqi Liu","Fenglei Cao","Yuan Qi","Li-Cheng Xu"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.03687v1","updated":"2026-01-07T08:19:29Z","published":"2026-01-07T08:19:29Z","title":"Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics","summary":"Personalized medication planning involves selecting medications and determining a dosing schedule to achieve medical goals specific to each individual patient. Previous work successfully demonstrated that automated planners, using general domain-independent heuristics, are able to generate personalized treatments, when the domain and problems are modeled using a general domain description language (\\pddlp). Unfortunately, this process was limited in practice to consider no more than seven medications. In clinical terms, this is a non-starter. In this paper, we explore the use of automatically-generated domain- and problem-specific heuristics to be used with general search, as a method of scaling up medication planning to levels allowing closer work with clinicians. Specifically, we specify the domain programmatically (specifying an initial state and a successor generation procedure), and use an LLM to generate a problem specific heuristic that can be used by a fixed search algorithm (GBFS). The results indicate dramatic improvements in coverage and planning time, scaling up the number of medications to at least 28, and bringing medication planning one step closer to practical applications.","authors":["Yonatan Vernik","Alexander Tuisov","David Izhaki","Hana Weitman","Gal A. Kaminka","Alexander Shleyfman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23732v3","updated":"2026-01-07T08:16:32Z","published":"2025-12-21T05:48:57Z","title":"When in Doubt, Consult: Expert Debate for Sexism Detection via Confidence-Based Routing","summary":"Online sexism increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to overlook subtler, underrepresented forms of harm. To address these challenges, we propose a two-stage framework that unifies (i) targeted training procedures to better regularize supervision to scarce and noisy data with (ii) selective, reasoning-based inference to handle ambiguous or borderline cases. First, we stabilize the training combining class-balanced focal loss, class-aware batching, and post-hoc threshold calibration, strategies for the firs time adapted for this domain to mitigate label imbalance and noisy supervision. Second, we bridge the gap between efficiency and reasoning with a a dynamic routing mechanism that distinguishes between unambiguous instances and complex cases requiring a deliberative process. This reasoning process results in the novel Collaborative Expert Judgment (CEJ) module which prompts multiple personas and consolidates their reasoning through a judge model. Our approach outperforms existing approaches across several public benchmarks, with F1 gains of +4.48% and +1.30% on EDOS Tasks A and B, respectively, and a +2.79% improvement in ICM on EXIST 2025 Task 1.1.","authors":["Anwar Alajmi","Gabriele Pergola"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03682v1","updated":"2026-01-07T08:15:01Z","published":"2026-01-07T08:15:01Z","title":"From Implicit to Explicit: Token-Efficient Logical Supervision for Mathematical Reasoning in LLMs","summary":"Recent studies reveal that large language models (LLMs) exhibit limited logical reasoning abilities in mathematical problem-solving, instead often relying on pattern-matching and memorization. We systematically analyze this limitation, focusing on logical relationship understanding, which is a core capability underlying genuine logical reasoning, and reveal that errors related to this capability account for over 90\\% of incorrect predictions, with Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) failing to substantially reduce these errors. To address this bottleneck, we propose First-Step Logical Reasoning (FSLR), a lightweight training framework targeting logical relationship understanding. Our key insight is that the first planning step-identifying which variables to use and which operation to apply-encourages the model to derive logical relationships directly from the problem statement. By training models on this isolated step, FSLR provides explicit supervision for logical relationship understanding, unlike CoT-SFT which implicitly embeds such relationships within complete solution trajectories. Extensive experiments across multiple models and datasets demonstrate that FSLR consistently outperforms CoT-SFT under both in-distribution and out-of-distribution settings, with average improvements of 3.2\\% and 4.6\\%, respectively. Moreover, FSLR achieves 4-6x faster training and reduces training token consumption by over 80\\%.","authors":["Shaojie Wang","Liang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.20408v2","updated":"2026-01-07T08:08:55Z","published":"2025-02-13T04:42:39Z","title":"Brain-Inspired Exploration of Functional Networks and Key Neurons in Large Language Models","summary":"In recent years, the rapid advancement of large language models (LLMs) in natural language processing has sparked significant interest among researchers to understand their mechanisms and functional characteristics. Although prior studies have attempted to explain LLM functionalities by identifying and interpreting specific neurons, these efforts mostly focus on individual neuron contributions, neglecting the fact that human brain functions are realized through intricate interaction networks. Inspired by research on functional brain networks (FBNs) in the field of neuroscience, we utilize similar methodologies estabilished in FBN analysis to explore the \"functional networks\" within LLMs in this study. Experimental results highlight that, much like the human brain, LLMs exhibit certain functional networks that recur frequently during their operation. Further investigation reveals that these functional networks are indispensable for LLM performance. Inhibiting key functional networks severely impairs the model's capabilities. Conversely, amplifying the activity of neurons within these networks can enhance either the model's overall performance or its performance on specific tasks. This suggests that these functional networks are strongly associated with either specific tasks or the overall performance of the LLM. Code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.","authors":["Yiheng Liu","Zhengliang Liu","Zihao Wu","Junhao Ning","Haiyang Sun","Sichen Xia","Yang Yang","Xiaohui Gao","Ning Qiang","Bao Ge","Tianming Liu","Junwei Han","Xintao Hu"],"pdf_url":"","comment":"21 pages, 18 figures"},{"id":"http://arxiv.org/abs/2502.18851v3","updated":"2026-01-07T08:01:06Z","published":"2025-02-26T05:46:13Z","title":"Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code","summary":"Identifying LLM-generated code through watermarking poses a challenge in preserving functional correctness. Previous methods rely on the assumption that watermarking high-entropy tokens effectively maintains output quality. Our analysis reveals a fundamental limitation of this assumption: syntax-critical tokens such as keywords often exhibit the highest entropy, making existing approaches vulnerable to logic corruption. We present STONE, a syntax-aware watermarking method that embeds watermarks only in non-syntactic tokens and preserves code integrity. For its rigorous assessment, we also introduce STEM, a comprehensive framework that balances three critical dimensions: correctness, detectability, and imperceptibility. Across Python, C++, and Java, STONE preserves correctness, sustains strong detectability, and achieves balanced performance with minimal overhead. Our implementation is available at https://anonymous.4open.science/r/STONE-watermarking-AB4B/.","authors":["Jungin Kim","Shinwoo Park","Yo-Sub Han"],"pdf_url":"","comment":"Findings of EACL 2026"},{"id":"http://arxiv.org/abs/2601.03676v1","updated":"2026-01-07T07:58:51Z","published":"2026-01-07T07:58:51Z","title":"Towards Compositional Generalization of LLMs via Skill Taxonomy Guided Data Synthesis","summary":"Large Language Models (LLMs) and agent-based systems often struggle with compositional generalization due to a data bottleneck in which complex skill combinations follow a long-tailed, power-law distribution, limiting both instruction-following performance and generalization in agent-centric tasks. To address this challenge, we propose STEPS, a Skill Taxonomy guided Entropy-based Post-training data Synthesis framework for generating compositionally challenging data. STEPS explicitly targets compositional generalization by uncovering latent relationships among skills and organizing them into an interpretable, hierarchical skill taxonomy using structural information theory. Building on this taxonomy, we formulate data synthesis as a constrained information maximization problem, selecting skill combinations that maximize marginal structural information within the hierarchy while preserving semantic coherence. Experiments on challenging instruction-following benchmarks show that STEPS outperforms existing data synthesis baselines, while also yielding improved compositional generalization in downstream agent-based evaluations.","authors":["Yifan Wei","Li Du","Xiaoyan Yu","Yang Feng","Angsheng Li"],"pdf_url":"","comment":"The code and data for our methods and experiments are available at https://github.com/weiyifan1023/STEPS"},{"id":"http://arxiv.org/abs/2601.03673v1","updated":"2026-01-07T07:54:09Z","published":"2026-01-07T07:54:09Z","title":"Disentangling Aleatoric and Epistemic Uncertainty in Physics-Informed Neural Networks. Application to Insulation Material Degradation Prognostics","summary":"Physics-Informed Neural Networks (PINNs) provide a framework for integrating physical laws with data. However, their application to Prognostics and Health Management (PHM) remains constrained by the limited uncertainty quantification (UQ) capabilities. Most existing PINN-based prognostics approaches are deterministic or account only for epistemic uncertainty, limiting their suitability for risk-aware decision-making. This work introduces a heteroscedastic Bayesian Physics-Informed Neural Network (B-PINN) framework that jointly models epistemic and aleatoric uncertainty, yielding full predictive posteriors for spatiotemporal insulation material ageing estimation. The approach integrates Bayesian Neural Networks (BNNs) with physics-based residual enforcement and prior distributions, enabling probabilistic inference within a physics-informed learning architecture. The framework is evaluated on transformer insulation ageing application, validated with a finite-element thermal model and field measurements from a solar power plant, and benchmarked against deterministic PINNs, dropout-based PINNs (d-PINNs), and alternative B-PINN variants. Results show that the proposed B-PINN provides improved predictive accuracy and better-calibrated uncertainty estimates than competing approaches. A systematic sensitivity study further analyzes the impact of boundary-condition, initial-condition, and residual sampling strategies on accuracy, calibration, and generalization. Overall, the findings highlight the potential of Bayesian physics-informed learning to support uncertainty-aware prognostics and informed decision-making in transformer asset management.","authors":["Ibai Ramirez","Jokin Alcibar","Joel Pino","Mikel Sanz","Jose I. Aizpurua"],"pdf_url":"","comment":"24 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2601.03672v1","updated":"2026-01-07T07:52:30Z","published":"2026-01-07T07:52:30Z","title":"Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction","summary":"Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the model from leveraging its reasoning capability to improve accuracy. To address this issue, we propose Sandwich Reasoning (SandwichR), a novel approach that explicitly aligns a fast initial answer with post-hoc reasoning, enabling low-latency query correction without sacrificing reasoning-aware accuracy. SandwichR follows an Answer-Reasoning-Answer paradigm, producing an initial correction, an explicit reasoning process, and a final refined correction. To align the initial answer with post-reasoning insights, we design a consistency-aware reinforcement learning (RL) strategy: a dedicated consistency reward enforces alignment between the initial and final corrections, while margin-based rejection sampling prioritizes borderline samples where reasoning drives the most impactful corrective gains. Additionally, we construct a high-quality query correction dataset, addressing the lack of specialized benchmarks for complex query correction. Experimental results demonstrate that SandwichR achieves SOTA accuracy comparable to standard CoT while delivering a 40-70% latency reduction, resolving the latency-accuracy trade-off in online search.","authors":["Chen Zhang","Kepu Zhang","Jiatong Zhang","Xiao Zhang","Jun Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.08269v4","updated":"2026-01-07T07:50:30Z","published":"2025-09-10T04:05:54Z","title":"A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving","summary":"Large Language Models (LLMs) possess substantial reasoning capabilities and are increasingly applied to optimization tasks, particularly in synergy with evolutionary computation. However, while recent surveys have explored specific aspects of this domain, they lack an integrative perspective that connects problem modeling with solving workflows. To address this gap, we present a systematic review of recent developments and organize them within a structured framework. First, we classify existing research into two primary stages: LLMs for optimization modeling and LLMs for optimization solving. Second, we divide the latter into three paradigms based on the role of the LLM: stand-alone optimizers, low-level components embedded within algorithms, and high-level managers for algorithm selection and generation. Third, for each category, we analyze representative methods, distill technical challenges, and examine their interplay with traditional approaches. Finally, we review interdisciplinary applications across the natural sciences, engineering, and machine learning. Based on this analysis, we highlight key limitations and point toward future directions for developing self-evolving agentic ecosystems. An up-to-date collection of related literature is maintained at https://github.com/ishmael233/LLM4OPT.","authors":["Yisong Zhang","Ran Cheng","Guoxing Yi","Kay Chen Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08726v3","updated":"2026-01-07T07:50:27Z","published":"2025-06-10T12:22:57Z","title":"Improved LLM Agents for Financial Document Question Answering","summary":"Large language models (LLMs) have shown impressive capabilities on numerous natural language processing tasks. However, LLMs still struggle with numerical question answering for financial documents that include tabular and textual data. Recent works have showed the effectiveness of critic agents (i.e., self-correction) for this task given oracle labels. Building upon this framework, this paper examines the effectiveness of the traditional critic agent when oracle labels are not available, and show, through experiments, that this critic agent's performance deteriorates in this scenario. With this in mind, we present an improved critic agent, along with the calculator agent which outperforms the previous state-of-the-art approach (program-of-thought) and is safer. Furthermore, we investigate how our agents interact with each other, and how this interaction affects their performance.","authors":["Nelvin Tan","Zian Seng","Liang Zhang","Yu-Ching Shih","Dong Yang","Amol Salunkhe"],"pdf_url":"","comment":"13 pages, 6 figures. More analysis is added to Appendix C"},{"id":"http://arxiv.org/abs/2512.00947v2","updated":"2026-01-07T07:49:32Z","published":"2025-11-30T15:59:56Z","title":"Table as a Modality for Large Language Models","summary":"To migrate the remarkable successes of Large Language Models (LLMs), the community has made numerous efforts to generalize them to the table reasoning tasks for the widely deployed tabular data. Despite that, in this work, by showing a probing experiment on our proposed StructQA benchmark, we postulate that even the most advanced LLMs (such as GPTs) may still fall short of coping with tabular data. More specifically, the current scheme often simply relies on serializing the tabular data, together with the meta information, then inputting them through the LLMs. We argue that the loss of structural information is the root of this shortcoming. In this work, we further propose TAMO, which bears an ideology to treat the tables as an independent modality integrated with the text tokens. The resulting model in TAMO is a multimodal framework consisting of a hypergraph neural network as the global table encoder seamlessly integrated with the mainstream LLM. Empirical results on various benchmarking datasets, including HiTab, WikiTQ, WikiSQL, FeTaQA, and StructQA, have demonstrated significant improvements on generalization with an average relative gain of 42.65%.","authors":["Liyao Li","Chao Ye","Wentao Ye","Yifei Sun","Zhe Jiang","Haobo Wang","Jiaming Tian","Yiming Zhang","Ningtao Wang","Xing Fu","Gang Chen","Junbo Zhao"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2601.03668v1","updated":"2026-01-07T07:43:30Z","published":"2026-01-07T07:43:30Z","title":"Discontinuous Galerkin finite element operator network for solving non-smooth PDEs","summary":"We introduce Discontinuous Galerkin Finite Element Operator Network (DG--FEONet), a data-free operator learning framework that combines the strengths of the discontinuous Galerkin (DG) method with neural networks to solve parametric partial differential equations (PDEs) with discontinuous coefficients and non-smooth solutions. Unlike traditional operator learning models such as DeepONet and Fourier Neural Operator, which require large paired datasets and often struggle near sharp features, our approach minimizes the residual of a DG-based weak formulation using the Symmetric Interior Penalty Galerkin (SIPG) scheme. DG-FEONet predicts element-wise solution coefficients via a neural network, enabling data-free training without the need for precomputed input-output pairs. We provide theoretical justification through convergence analysis and validate the model's performance on a series of one- and two-dimensional PDE problems, demonstrating accurate recovery of discontinuities, strong generalization across parameter space, and reliable convergence rates. Our results highlight the potential of combining local discretization schemes with machine learning to achieve robust, singularity-aware operator approximation in challenging PDE settings.","authors":["Kapil Chawla","Youngjoon Hong","Jae Yong Lee","Sanghyun Lee"],"pdf_url":"","comment":"24 pages, 11 figures"},{"id":"http://arxiv.org/abs/2512.21578v3","updated":"2026-01-07T07:41:04Z","published":"2025-12-25T08:47:32Z","title":"NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent","summary":"We present the development and optimization of PayPal's Commerce Agent, powered by NEMO-4-PAYPAL, a multi-agent system designed to revolutionize agentic commerce on the PayPal platform. Through our strategic partnership with NVIDIA, we leveraged the NeMo Framework for LLM model fine-tuning to enhance agent performance. Specifically, we optimized the Search and Discovery agent by replacing our base model with a fine-tuned Nemotron small language model (SLM).\n  We conducted comprehensive experiments using the llama3.1-nemotron-nano-8B-v1 architecture, training LoRA-based models through systematic hyperparameter sweeps across learning rates, optimizers (Adam, AdamW), cosine annealing schedules, and LoRA ranks. Our contributions include: (1) the first application of NVIDIA's NeMo Framework to commerce-specific agent optimization, (2) LLM powered fine-tuning strategy for retrieval-focused commerce tasks, (3) demonstration of significant improvements in latency and cost while maintaining agent quality, and (4) a scalable framework for multi-agent system optimization in production e-commerce environments. Our results demonstrate that the fine-tuned Nemotron SLM effectively resolves the key performance issue in the retrieval component, which represents over 50\\% of total agent response time, while maintaining or enhancing overall system performance.","authors":["Sudhanshu Garg","Andrew Wang","Chaitanya Kulkarni","Ali Sahami","Farhad Farahani","Sean Yun-Shiuan Chuang","Jian Wan","Srinivasan Manoharan","Uma Kona","Nitin Sharma","Linsey Pang","Prakhar Mehrotra","Jessica Clark","Mark Moyou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03666v1","updated":"2026-01-07T07:39:40Z","published":"2026-01-07T07:39:40Z","title":"e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings","summary":"Modern information systems often involve different types of items, e.g., a text query, an image, a video clip, or an audio segment. This motivates omni-modal embedding models that map heterogeneous modalities into a shared space for direct comparison. However, most recent omni-modal embeddings still rely heavily on implicit alignment inherited from pretrained vision-language model (VLM) backbones. In practice, this causes three common issues: (i) similarity logits have modality-dependent sharpness, so scores are not on a consistent scale; (ii) in-batch negatives become less effective over time because mixed-modality batches create an imbalanced hardness distribution; as a result, many negatives quickly become trivial and contribute little gradient; and (iii) embeddings across modalities show mismatched first- and second-order statistics, which makes rankings less stable. To tackle these problems, we propose e5-omni, a lightweight explicit alignment recipe that adapts off-the-shelf VLMs into robust omni-modal embedding models. e5-omni combines three simple components: (1) modality-aware temperature calibration to align similarity scales, (2) a controllable negative curriculum with debiasing to focus on confusing negatives while reducing the impact of false negatives, and (3) batch whitening with covariance regularization to better match cross-modal geometry in the shared embedding space. Experiments on MMEB-V2 and AudioCaps show consistent gains over strong bi-modal and omni-modal baselines, and the same recipe also transfers well to other VLM backbones. We release our model checkpoint at https://huggingface.co/Haon-Chen/e5-omni-7B.","authors":["Haonan Chen","Sicheng Gao","Radu Timofte","Tetsuya Sakai","Zhicheng Dou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.02110v2","updated":"2026-01-07T07:28:14Z","published":"2025-08-04T06:38:59Z","title":"Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools","summary":"Large language model (LLM) agents have demonstrated remarkable capabilities in complex reasoning and decision-making by leveraging external tools. However, this tool-centric paradigm introduces a previously underexplored attack surface, where adversaries can manipulate tool metadata -- such as names, descriptions, and parameter schemas -- to influence agent behavior. We identify this as a new and stealthy threat surface that allows malicious tools to be preferentially selected by LLM agents, without requiring prompt injection or access to model internals. To demonstrate and exploit this vulnerability, we propose the Attractive Metadata Attack (AMA), a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization. The proposed attack integrates seamlessly into standard tool ecosystems and requires no modification to the agent's execution framework. Extensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\\%-95\\%) and significant privacy leakage, with negligible impact on primary task execution. Moreover, the attack remains effective even against prompt-level defenses, auditor-based detection, and structured tool-selection protocols such as the Model Context Protocol, revealing systemic vulnerabilities in current agent architectures. These findings reveal that metadata manipulation constitutes a potent and stealthy attack surface. Notably, AMA is orthogonal to injection attacks and can be combined with them to achieve stronger attack efficacy, highlighting the need for execution-level defenses beyond prompt-level and auditor-based mechanisms. Code is available at https://github.com/SEAIC-M/AMA.","authors":["Kanghua Mo","Li Hu","Yucheng Long","Zhihao Li"],"pdf_url":"","comment":"Accepted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2601.03662v1","updated":"2026-01-07T07:26:31Z","published":"2026-01-07T07:26:31Z","title":"How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs","summary":"Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Motivated by this finding, we propose SafeRemind, a decoding-time defense method that dynamically injects safe-reminding phrases into thinking steps. By leveraging entropy triggers to intervene at decision-locking points, SafeRemind redirects potentially harmful trajectories toward safer outcomes without requiring any parameter updates. Extensive evaluations across five LRMs and six benchmarks demonstrate that SafeRemind substantially enhances safety, achieving improvements of up to 45.5%p while preserving core reasoning utility.","authors":["Su-Hyeon Kim","Hyundong Jin","Yejin Lee","Yo-Sub Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.19614v3","updated":"2026-01-07T07:25:26Z","published":"2025-08-27T06:48:46Z","title":"LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation","summary":"Retrieval-augmented generation (RAG) incorporates external knowledge into large language models (LLMs), improving their adaptability to downstream tasks and enabling information updates. Surprisingly, recent empirical evidence demonstrates that injecting noise into retrieved relevant documents paradoxically facilitates exploitation of external knowledge and improves generation quality. Although counterintuitive and challenging to apply in practice, this phenomenon enables granular control and rigorous analysis of how LLMs integrate external knowledge. Therefore, in this paper, we intervene on noise injection and establish a layer-specific functional demarcation within the LLM: shallow layers specialize in local context modeling, intermediate layers focus on integrating long-range external factual knowledge, and deeper layers primarily rely on parametric internal knowledge. Building on this insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that directly combines representations from an intermediate layer with final-layer decoding outputs to fully exploit the external factual knowledge. To identify the optimal intermediate layer, we introduce an internal knowledge score (IKS) criterion that selects the layer with the lowest IKS value in the latter half of layers. Experimental results across multiple benchmarks demonstrate that LFD helps RAG systems more effectively surface retrieved context knowledge with minimal cost.","authors":["Yang Sun","Zhiyong Xie","Lixin Zou","Dan Luo","Min Tang","Xiangyu Zhao","Yunwei Zhao","Xixun Lin","Yanxiong Lu","Chenliang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03661v1","updated":"2026-01-07T07:22:58Z","published":"2026-01-07T07:22:58Z","title":"AMIR-GRPO: Inducing Implicit Preference Signals into GRPO","summary":"Reinforcement learning has become the primary paradigm for aligning large language models (LLMs) on complex reasoning tasks, with group relative policy optimization (GRPO) widely used in large-scale post-training. However, GRPO faces structural limitations in reasoning-heavy settings: sequence-level advantage normalization introduces systematic length bias, penalties for low-quality trajectories are diluted, and the scalar objective discards rich pairwise preference information embedded in within-group reward rankings. As a result, valuable supervision from costly rollouts remains underutilized.\n  We propose AMIR-GRPO, which augments GRPO with an implicit DPO-style contrastive regularizer constructed directly from intra-group reward rankings, requiring no additional annotations. This mechanism amplifies suppression of low-reward trajectories, attenuates response-level length bias, and transforms each rollout group into a denser set of supervision constraints. Across multiple mathematical reasoning benchmarks, AMIR-GRPO consistently outperforms strong GRPO baselines, yields clearer separation between correct and incorrect reasoning chains, and delivers broader coverage gains beyond the subset of instances solved by standard GRPO.","authors":["Amir Hossein Yari","Fajri Koto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.20382v2","updated":"2026-01-07T07:15:16Z","published":"2025-02-27T18:56:01Z","title":"Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization","summary":"We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks. Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinematic retargeting and trajectory optimization to adapt them across various robot embodiments and physical parameters. This process yields a diverse, physically consistent dataset that enables cross-embodiment data transfer, and offers the potential to reuse legacy datasets collected under different hardware configurations or physical parameters. We validate the pipeline's effectiveness by training diffusion policies from the generated datasets for challenging contact-rich manipulation tasks across multiple robot embodiments, including a floating Allegro hand and bimanual robot arms. The trained policies are deployed zero-shot on hardware for bimanual iiwa arms, achieving high success rates with minimal human input. Project website: https://lujieyang.github.io/physicsgen/.","authors":["Lujie Yang","H. J. Terry Suh","Tong Zhao","Bernhard Paus Graesdal","Tarik Kelestemur","Jiuguang Wang","Tao Pang","Russ Tedrake"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03658v1","updated":"2026-01-07T07:15:11Z","published":"2026-01-07T07:15:11Z","title":"Group and Exclusive Sparse Regularization-based Continual Learning of CNNs","summary":"We present a regularization-based approach for continual learning (CL) of fixed capacity convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when learning multiple tasks sequentially. This method referred to as Group and Exclusive Sparsity based Continual Learning (GESCL) avoids forgetting of previous tasks by ensuring the stability of the CNN via a stability regularization term, which prevents filters detected as important for past tasks to deviate too much when learning a new task. On top of that, GESCL makes the network plastic via a plasticity regularization term that leverage the over-parameterization of CNNs to efficiently sparsify the network and tunes unimportant filters making them relevant for future tasks. Doing so, GESCL deals with significantly less parameters and computation compared to CL approaches that either dynamically expand the network or memorize past tasks' data. Experiments on popular CL vision benchmarks show that GESCL leads to significant improvements over state-of-the-art method in terms of overall CL performance, as measured by classification accuracy as well as in terms of avoiding catastrophic forgetting.","authors":["Basile Tousside","Janis Mohr","Jörg Frochte"],"pdf_url":"","comment":"12 pages, Canadian Artificial Intelligence Association (CAIAC)"},{"id":"http://arxiv.org/abs/2601.03657v1","updated":"2026-01-07T07:13:01Z","published":"2026-01-07T07:13:01Z","title":"In Search of Grandmother Cells: Tracing Interpretable Neurons in Tabular Representations","summary":"Foundation models are powerful yet often opaque in their decision-making. A topic of continued interest in both neuroscience and artificial intelligence is whether some neurons behave like grandmother cells, i.e., neurons that are inherently interpretable because they exclusively respond to single concepts. In this work, we propose two information-theoretic measures that quantify the neuronal saliency and selectivity for single concepts. We apply these metrics to the representations of TabPFN, a tabular foundation model, and perform a simple search across neuron-concept pairs to find the most salient and selective pair. Our analysis provides the first evidence that some neurons in such models show moderate, statistically significant saliency and selectivity for high-level concepts. These findings suggest that interpretable neurons can emerge naturally and that they can, in some cases, be identified without resorting to more complex interpretability techniques.","authors":["Ricardo Knauer","Erik Rodner"],"pdf_url":"","comment":"EurIPS 2025 Workshop on AI for Tabular Data"},{"id":"http://arxiv.org/abs/2509.20823v3","updated":"2026-01-07T07:03:34Z","published":"2025-09-25T07:10:03Z","title":"CaTS-Bench: Can Language Models Describe Time Series?","summary":"Time series captioning, the task of describing time series in natural language, requires numeric and temporal reasoning, trend interpretation, and contextual understanding. Existing benchmarks, however, often rely on fully synthetic or generic captions, and typically neglect metadata and visual representations. We introduce \\textbf{CaTS-Bench}, a comprehensive benchmark for \\textbf{C}ontext-\\textbf{a}ware \\textbf{T}ime \\textbf{S}eries reasoning across $11$ diverse domains, centered on a gold-standard evaluation set of $1746$ human-rewritten captions that measure how effectively models translate numeric trends into immediately interpretable narratives. To address the scarcity of human-annotated data, we also propose a scalable pipeline for generating high-fidelity synthetic captions, the quality of which we validate. We evaluate leading Vision-Language Models on our benchmark, revealing that even proprietary models struggle to capture numeric nuances in temporal descriptions, while finetuning open-source models on synthetic data yields substantial performance gains. Finally, we release a diagnostic suite of $910$ multiple-choice questions and tailored numeric metrics to gauge time-series-specific reasoning capabilities, establishing CaTS-Bench as a reliable foundation for grounded, multimodal language generation in numeric domains.","authors":["Luca Zhou","Pratham Yashwante","Marshall Fisher","Alessio Sampieri","Zihao Zhou","Fabio Galasso","Rose Yu"],"pdf_url":"","comment":"8 pages, 6 figures, 3 tables in the main paper. Many more in the appendix"},{"id":"http://arxiv.org/abs/2503.23314v2","updated":"2026-01-07T06:55:19Z","published":"2025-03-30T04:45:32Z","title":"SPIO: Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science","summary":"Large Language Models (LLMs) have enabled dynamic reasoning in automated data analytics, yet recent multi-agent systems remain limited by rigid, single-path workflows that restrict strategic exploration and often lead to suboptimal outcomes. To overcome these limitations, we propose SPIO (Sequential Plan Integration and Optimization), a framework that replaces rigid workflows with adaptive, multi-path planning across four core modules: data preprocessing, feature engineering, model selection, and hyperparameter tuning. In each module, specialized agents generate diverse candidate strategies, which are cascaded and refined by an optimization agent. SPIO offers two operating modes: SPIO-S for selecting a single optimal pipeline, and SPIO-E for ensembling top-k pipelines to maximize robustness. Extensive evaluations on Kaggle and OpenML benchmarks show that SPIO consistently outperforms state-of-the-art baselines, achieving an average performance gain of 5.6%. By explicitly exploring and integrating multiple solution paths, SPIO delivers a more flexible, accurate, and reliable foundation for automated data science.","authors":["Wonduk Seo","Juhyeon Lee","Yanjun Shao","Qingshan Zhou","Seunghyun Lee","Yi Bu"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2601.03646v1","updated":"2026-01-07T06:50:56Z","published":"2026-01-07T06:50:56Z","title":"ReLA: Representation Learning and Aggregation for Job Scheduling with Reinforcement Learning","summary":"Job scheduling is widely used in real-world manufacturing systems to assign ordered job operations to machines under various constraints. Existing solutions remain limited by long running time or insufficient schedule quality, especially when problem scale increases. In this paper, we propose ReLA, a reinforcement-learning (RL) scheduler built on structured representation learning and aggregation. ReLA first learns diverse representations from scheduling entities, including job operations and machines, using two intra-entity learning modules with self-attention and convolution and one inter-entity learning module with cross-attention. These modules are applied in a multi-scale architecture, and their outputs are aggregated to support RL decision-making. Across experiments on small, medium, and large job instances, ReLA achieves the best makespan in most tested settings over the latest solutions. On non-large instances, ReLA reduces the optimality gap of the SOTA baseline by 13.0%, while on large-scale instances it reduces the gap by 78.6%, with the average optimality gaps lowered to 7.3% and 2.1%, respectively. These results confirm that ReLA's learned representations and aggregation provide strong decision support for RL scheduling, and enable fast job completion and decision-making for real-world applications.","authors":["Zhengyi Kwan","Zhang Wei","Aik Beng Ng","Zhengkui Wang","Simon See"],"pdf_url":"","comment":"15 pages"},{"id":"http://arxiv.org/abs/2601.02813v2","updated":"2026-01-07T06:28:16Z","published":"2026-01-06T08:40:55Z","title":"HAL: Inducing Human-likeness in LLMs with Alignment","summary":"Conversational human-likeness plays a central role in human-AI interaction, yet it has remained difficult to define, measure, and optimize. As a result, improvements in human-like behavior are largely driven by scale or broad supervised training, rather than targeted alignment. We introduce Human Aligning LLMs (HAL), a framework for aligning language models to conversational human-likeness using an interpretable, data-driven reward. HAL derives explicit conversational traits from contrastive dialogue data, combines them into a compact scalar score, and uses this score as a transparent reward signal for alignment with standard preference optimization methods. Using this approach, we align models of varying sizes without affecting their overall performance. In large-scale human evaluations, models aligned with HAL are more frequently perceived as human-like in conversation. Because HAL operates over explicit, interpretable traits, it enables inspection of alignment behavior and diagnosis of unintended effects. More broadly, HAL demonstrates how soft, qualitative properties of language--previously outside the scope for alignment--can be made measurable and aligned in an interpretable and explainable way.","authors":["Masum Hasan","Junjie Zhao","Ehsan Hoque"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03633v1","updated":"2026-01-07T06:24:26Z","published":"2026-01-07T06:24:26Z","title":"MFC-RFNet: A Multi-scale Guided Rectified Flow Network for Radar Sequence Prediction","summary":"Accurate and high-resolution precipitation nowcasting from radar echo sequences is crucial for disaster mitigation and economic planning, yet it remains a significant challenge. Key difficulties include modeling complex multi-scale evolution, correcting inter-frame feature misalignment caused by displacement, and efficiently capturing long-range spatiotemporal context without sacrificing spatial fidelity. To address these issues, we present the Multi-scale Feature Communication Rectified Flow (RF) Network (MFC-RFNet), a generative framework that integrates multi-scale communication with guided feature fusion. To enhance multi-scale fusion while retaining fine detail, a Wavelet-Guided Skip Connection (WGSC) preserves high-frequency components, and a Feature Communication Module (FCM) promotes bidirectional cross-scale interaction. To correct inter-frame displacement, a Condition-Guided Spatial Transform Fusion (CGSTF) learns spatial transforms from conditioning echoes to align shallow features. The backbone adopts rectified flow training to learn near-linear probability-flow trajectories, enabling few-step sampling with stable fidelity. Additionally, lightweight Vision-RWKV (RWKV) blocks are placed at the encoder tail, the bottleneck, and the first decoder layer to capture long-range spatiotemporal dependencies at low spatial resolutions with moderate compute. Evaluations on four public datasets (SEVIR, MeteoNet, Shanghai, and CIKM) demonstrate consistent improvements over strong baselines, yielding clearer echo morphology at higher rain-rate thresholds and sustained skill at longer lead times. These results suggest that the proposed synergy of RF training with scale-aware communication, spatial alignment, and frequency-aware fusion presents an effective and robust approach for radar-based nowcasting.","authors":["Wenjie Luo","Chuanhu Deng","Chaorong Li","Rongyao Deng","Qiang Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03632v1","updated":"2026-01-07T06:23:23Z","published":"2026-01-07T06:23:23Z","title":"ReStyle-TTS: Relative and Continuous Style Control for Zero-Shot Speech Synthesis","summary":"Zero-shot text-to-speech models can clone a speaker's timbre from a short reference audio, but they also strongly inherit the speaking style present in the reference. As a result, synthesizing speech with a desired style often requires carefully selecting reference audio, which is impractical when only limited or mismatched references are available. While recent controllable TTS methods attempt to address this issue, they typically rely on absolute style targets and discrete textual prompts, and therefore do not support continuous and reference-relative style control. We propose ReStyle-TTS, a framework that enables continuous and reference-relative style control in zero-shot TTS. Our key insight is that effective style control requires first reducing the model's implicit dependence on reference style before introducing explicit control mechanisms. To this end, we introduce Decoupled Classifier-Free Guidance (DCFG), which independently controls text and reference guidance, reducing reliance on reference style while preserving text fidelity. On top of this, we apply style-specific LoRAs together with Orthogonal LoRA Fusion to enable continuous and disentangled multi-attribute control, and introduce a Timbre Consistency Optimization module to mitigate timbre drift caused by weakened reference guidance. Experiments show that ReStyle-TTS enables user-friendly, continuous, and relative control over pitch, energy, and multiple emotions while maintaining intelligibility and speaker timbre, and performs robustly in challenging mismatched reference-target style scenarios.","authors":["Haitao Li","Chunxiang Jin","Chenglin Li","Wenhao Guan","Zhengxing Huang","Xie Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16925v2","updated":"2026-01-07T06:16:41Z","published":"2025-11-04T07:24:45Z","title":"V-Agent: An Interactive Video Search System Using Vision-Language Models","summary":"We introduce V-Agent, a novel multi-agent platform designed for advanced video search and interactive user-system conversations. By fine-tuning a vision-language model (VLM) with a small video preference dataset and enhancing it with a retrieval vector from an image-text retrieval model, we overcome the limitations of traditional text-based retrieval systems in multimodal scenarios. The VLM-based retrieval model independently embeds video frames and audio transcriptions from an automatic speech recognition (ASR) module into a shared multimodal representation space, enabling V-Agent to interpret both visual and spoken content for context-aware video search. This system consists of three agents-a routing agent, a search agent, and a chat agent-that work collaboratively to address user intents by refining search outputs and communicating with users. The search agent utilizes the VLM-based retrieval model together with an additional re-ranking module to further enhance video retrieval quality. Our proposed framework demonstrates state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark, highlighting its potential for both academic research and real-world applications. The retrieval model and demo videos are available at https://huggingface.co/NCSOFT/multimodal-embedding.","authors":["SunYoung Park","Jong-Hyeon Lee","Youngjune Kim","Daegyu Sung","Younghyun Yu","Young-rok Cha","Jeongho Ju"],"pdf_url":"","comment":"CIKM 2025 MMGENSR Workshop"},{"id":"http://arxiv.org/abs/2601.03627v1","updated":"2026-01-07T06:15:21Z","published":"2026-01-07T06:15:21Z","title":"Evaluating the Pre-Consultation Ability of LLMs using Diagnostic Guidelines","summary":"We introduce EPAG, a benchmark dataset and framework designed for Evaluating the Pre-consultation Ability of LLMs using diagnostic Guidelines. LLMs are evaluated directly through HPI-diagnostic guideline comparison and indirectly through disease diagnosis. In our experiments, we observe that small open-source models fine-tuned with a well-curated, task-specific dataset can outperform frontier LLMs in pre-consultation. Additionally, we find that increased amount of HPI (History of Present Illness) does not necessarily lead to improved diagnostic performance. Further experiments reveal that the language of pre-consultation influences the characteristics of the dialogue. By open-sourcing our dataset and evaluation pipeline on https://github.com/seemdog/EPAG, we aim to contribute to the evaluation and further development of LLM applications in real-world clinical settings.","authors":["Jean Seo","Gibaeg Kim","Kihun Shin","Seungseop Lim","Hyunkyung Lee","Wooseok Han","Jongwon Lee","Eunho Yang"],"pdf_url":"","comment":"EACL 2026 Industry"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2601.04190v1","updated":"2026-01-07T18:57:19Z","published":"2026-01-07T18:57:19Z","title":"Solar Panel-based Visible Light Communication for Batteryless Systems","summary":"This paper presents a batteryless wireless communication node for the Internet of Things, powered entirely by ambient light and capable of receiving data through visible light communication. A solar panel serves dual functions as an energy harvester and an optical antenna, capturing modulated signals from LED light sources. A lightweight analog front-end filters and digitizes the signals for an 8-bit low-power processor, which manages the system's operational states based on stored energy levels. The main processor is selectively activated to minimize energy consumption. Data reception is synchronized with the harvester's open-circuit phase, reducing interference and improving signal quality. The prototype reliably decodes 32-bit VLC frames at 800\\,Herz, consuming less than 2.8\\,mJ, and maintains sleep-mode power below 30\\,uW.","authors":["Juan F. Gutierrez","Nhung Nguyen","Jesus M. Quintero","Andres Gomez"],"pdf_url":"","comment":"This is an open-access, author-archived version of a manuscript published in ApplePies 2025 Conference"},{"id":"http://arxiv.org/abs/2601.04177v1","updated":"2026-01-07T18:43:18Z","published":"2026-01-07T18:43:18Z","title":"Hierarchical GNN-Based Multi-Agent Learning for Dynamic Queue-Jump Lane and Emergency Vehicle Corridor Formation","summary":"Emergency vehicles require rapid passage through congested traffic, yet existing strategies fail to adapt to dynamic conditions. We propose a novel hierarchical graph neural network (GNN)-based multi-agent reinforcement learning framework to coordinate connected vehicles for emergency corridor formation. Our approach uses a high-level planner for global strategy and low-level controllers for trajectory execution, utilizing graph attention networks to scale with variable agent counts. Trained via Multi-Agent Proximal Policy Optimization (MAPPO), the system reduces emergency vehicle travel time by 28.3% compared to baselines and 44.6% compared to uncoordinated traffic in simulations. The design achieves near-zero collision rates (0.3%) while maintaining 81% of background traffic efficiency. Ablation and generalization studies confirm the framework's robustness across diverse scenarios. These results demonstrate the effectiveness of combining GNNs with hierarchical learning for intelligent transportation systems.","authors":["Haoran Su"],"pdf_url":"","comment":"16 Pages, 5 Figures, 9 Tables, submitted to IEEE TITS"},{"id":"http://arxiv.org/abs/2505.23210v2","updated":"2026-01-07T18:35:23Z","published":"2025-05-29T07:52:40Z","title":"Latent Representations for Control Design with Provable Stability and Safety Guarantees","summary":"We initiate a formal study on the use of low-dimensional latent representations of dynamical systems for verifiable control synthesis. Our main goal is to enable the application of verification techniques -- such as Lyapunov or barrier functions -- that might otherwise be computationally prohibitive when applied directly to the full state representation. Towards this goal, we first provide dynamics-aware approximate conjugacy conditions which formalize the notion of reconstruction error necessary for systems analysis. We then utilize our conjugacy conditions to transfer the stability and invariance guarantees of a latent certificate function (e.g., a Lyapunov or barrier function) for a latent space controller back to the original system. Importantly, our analysis contains several important implications for learning latent spaces and dynamics, by highlighting the necessary geometric properties which need to be preserved by the latent space, in addition to providing concrete loss functions for dynamics reconstruction that are directly related to control design. We conclude by demonstrating the applicability of our theory to two case studies: (1) stabilization of a cartpole system, and (2) collision avoidance for a two vehicle system.","authors":["Paul Lutkus","Kaiyuan Wang","Lars Lindemann","Stephen Tu"],"pdf_url":"","comment":"14 pages, 3 figures. Presented at CDC 2025. Expanded version"},{"id":"http://arxiv.org/abs/2601.04136v1","updated":"2026-01-07T17:50:11Z","published":"2026-01-07T17:50:11Z","title":"A Load Impedance Emulation Active Interface for Piezoelectric Vibration Energy Harvesters","summary":"A single stage active AC/DC interface able to emulate the optimal load impedance of a Resonant Piezoelectric Vibration Energy Harvester (RPVEH) is proposed. As theoretically shown, unlike an electronic interface that emulates an optimal load generator, an interface that emulates an optimal load impedance does not require adaptation to the acceleration of input vibrations. This allows the use of a very simple control, avoiding the implementation of Maximum Power Point Tracking (MPPT) algorithms that require lossy microcontrollers. Thus, the proposed interface is equipped with a simple analog controller allowing the RPVEH to work in its Maximum Power Point (MPP) in both steady-state and variable conditions of vibrations, without recurring to multivariable perturbative approaches, as it happens for the most of single stage AC/DC interfaces proposed in the literature. The absence of perturbative techniques allows a significant improvement of both stationary and dynamic performances. Experimental tests of a prototype of the proposed interface confirm the theoretical findings and the predicted behavior.","authors":["Alessandro Lo Schiavo","Luigi Costanzo","Massimo Vitelli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.12279v4","updated":"2026-01-07T17:42:40Z","published":"2025-01-21T16:50:33Z","title":"Spatial exponential decay of perturbations in optimal control of general evolution equations","summary":"We analyze the robustness of optimally controlled evolution equations with respect to spatially localized perturbations. We prove that if the involved operators are domain-uniformly stabilizable and detectable, then these localized perturbations only have a local effect on the optimal solution. We characterize this domain-uniform stabilizability and detectability for the transport equation with constant transport velocity, showing that even for unitary semigroups, optimality implies exponential damping. We extend this result to the case of a space-dependent transport velocity. Finally we leverage the results for the transport equation to characterize domain-uniform stabilizability of the wave equation. Numerical examples in one space dimension complement the theoretical results.","authors":["Simone Göttlich","Benedikt Oppeneiger","Manuel Schaller","Karl Worthmann"],"pdf_url":"","comment":"53 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.04111v1","updated":"2026-01-07T17:17:32Z","published":"2026-01-07T17:17:32Z","title":"Stigmergic optimal transport","summary":"Efficient navigation in swarms often relies on the emergence of decentralized approaches that minimize traversal time or energy. Stigmergy, where agents modify a shared environment that then modifies their behavior, is a classic mechanism that can encode this strategy. We develop a theoretical framework for stigmergic transport by casting it as a stochastic optimal control problem: agents (collectively) lay and (individually) follow trails while minimizing expected traversal time. Simulations and analysis reveal two emergent behaviors: path straightening in homogeneous environments and path refraction at material interfaces, both consistent with experimental observations of insect trails. While reminiscent of Fermat's principle, our results show how local, noisy agent+field interactions can give rise to geodesic trajectories in heterogeneous environments, without centralized coordination or global knowledge, relying instead on an embodied slow fast dynamical mechanism.","authors":["Vishaal Krishnan","L. Mahadevan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.26428v2","updated":"2026-01-07T14:58:23Z","published":"2025-09-30T15:48:56Z","title":"Real-time Velocity Profile Optimization for Time-Optimal Maneuvering with Generic Acceleration Constraints","summary":"The computation of time-optimal velocity profiles along prescribed paths, subject to generic acceleration constraints, is a crucial problem in robot trajectory planning, with particular relevance to autonomous racing. However, the existing methods either support arbitrary acceleration constraints at high computational cost or use conservative box constraints for computational efficiency. We propose FBGA, a new \\underline{F}orward-\\underline{B}ackward algorithm with \\underline{G}eneric \\underline{A}cceleration constraints, which achieves both high accuracy and low computation time. FBGA operates forward and backward passes to maximize the velocity profile in short, discretized path segments, while satisfying user-defined performance limits. Tested on five racetracks and two vehicle classes, FBGA handles complex, non-convex acceleration constraints with custom formulations. Its maneuvers and lap times closely match optimal control baselines (within $0.11\\%$-$0.36\\%$), while being up to three orders of magnitude faster. FBGA maintains high accuracy even with coarse discretization, making it well-suited for online multi-query trajectory planning. Our open-source \\texttt{C++} implementation is available at: https://anonymous.4open.science/r/FB_public_RAL.","authors":["Mattia Piazza","Mattia Piccinini","Sebastiano Taddei","Francesco Biral","Enrico Bertolazzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03976v1","updated":"2026-01-07T14:43:35Z","published":"2026-01-07T14:43:35Z","title":"On-Device Deep Reinforcement Learning for Decentralized Task Offloading Performance trade-offs in the training process","summary":"Allowing less capable devices to offload computational tasks to more powerful devices or servers enables the development of new applications that may not run correctly on the device itself. Deciding where and why to run each of those applications is a complex task. Therefore, different approaches have been adopted to make offloading decisions. In this work, we propose a decentralized Deep Reinforcement Learning (DRL) agent to address the selection of computing locations. Unlike most existing work, we analyze it in a real testbed composed of various edge devices running the agent to determine where to execute each task. These devices are connected to a Multi-Access Edge Computing (MEC) server and a Cloud server through 5G communications. We evaluate not only the agent's performance in meeting task requirements but also the implications of running this type of agent locally, assessing the trade-offs of training locally versus remotely in terms of latency and energy consumption.","authors":["Gorka Nieto","Idoia de la Iglesia","Cristina Perfecto","Unai Lopez-Novoa"],"pdf_url":"","comment":"Submitted to IEEE Transactions on Cognitive Communications and Networking"},{"id":"http://arxiv.org/abs/2601.03971v1","updated":"2026-01-07T14:34:51Z","published":"2026-01-07T14:34:51Z","title":"Posterior error bounds for prior-driven balancing in linear Gaussian inverse problems","summary":"In large-scale Bayesian inverse problems, it is often necessary to apply approximate forward models to reduce the cost of forward model evaluations, while controlling approximation quality. In the context of Bayesian inverse problems with linear forward models, Gaussian priors, and Gaussian noise, we use perturbation theory for inverses to bound the error in the approximate posterior mean and posterior covariance resulting from a linear approximate forward model. We then focus on the smoothing problem of inferring the initial condition of linear time-invariant dynamical systems, using finitely many partial state observations. For such problems, and for a specific model order reduction method based on balanced truncation, we show that the impulse response of a certain prior-driven system is closely related to the prior-preconditioned Hessian of the inverse problem. This reveals a novel connection between systems theory and inverse problems. We exploit this connection to prove the first a priori error bounds for system-theoretic model order reduction methods applied to smoothing problems. The bounds control the approximation error of the posterior mean and covariance in terms of the truncated Hankel singular values of the underlying system.","authors":["Josie König","Han Cheng Lie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03906v1","updated":"2026-01-07T13:16:33Z","published":"2026-01-07T13:16:33Z","title":"Exact Continuous Reformulations of Logic Constraints in Nonlinear Optimization and Optimal Control Problems","summary":"Many nonlinear optimal control and optimization problems involve constraints that combine continuous dynamics with discrete logic conditions. Standard approaches typically rely on mixed-integer programming, which introduces scalability challenges and requires specialized solvers. This paper presents an exact reformulation of broad classes of logical constraints as binary-variable-free expressions whose differentiability properties coincide with those of the underlying predicates, enabling their direct integration into nonlinear programming models. Our approach rewrites arbitrary logical propositions into conjunctive normal form, converts them into equivalent max--min constraints, and applies a smoothing procedure that preserves the exact feasible set. The method is evaluated on two benchmark problems, a quadrotor trajectory optimization with obstacle avoidance and a hybrid two-tank system with temporal logic constraints, and is shown to obtain optimal solutions more consistently and efficiently than existing binary variable elimination techniques.","authors":["Jad Wehbeh","Eric C. Kerrigan"],"pdf_url":"","comment":"8 pages, 11 figures, submitted for publication to Automatica"},{"id":"http://arxiv.org/abs/2601.03893v1","updated":"2026-01-07T13:04:21Z","published":"2026-01-07T13:04:21Z","title":"Smooth Sampling-Based Model Predictive Control Using Deterministic Samples","summary":"Sampling-based model predictive control (MPC) is effective for nonlinear systems but often produces non-smooth control inputs due to random sampling. To address this issue, we extend the model predictive path integral (MPPI) framework with deterministic sampling and improvements from cross-entropy method (CEM)--MPC, such as iterative optimization, proposing deterministic sampling MPPI (dsMPPI). This combination leverages the exponential weighting of MPPI alongside the efficiency of deterministic samples. Experiments demonstrate that dsMPPI achieves smoother trajectories compared to state-of-the-art methods.","authors":["Markus Walker","Marcel Reith-Braun","Tai Hoang","Gerhard Neumann","Uwe D. Hanebeck"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03867v1","updated":"2026-01-07T12:31:04Z","published":"2026-01-07T12:31:04Z","title":"A Systems-Engineered ESP32 DAQ Architecture and FAIR Data Workflow for Small-Scale Wind Turbine Performance Measurement in Tropical Environments","summary":"Small-scale wind turbine research in resource-constrained academic settings frequently produces unreliable or unpublishable datasets due to ad-hoc instrumentation, inadequate time synchronization, storage failures, and weak data governance. This paper presents a systematic data acquisition (DAQ) methodology and ESP32-based reference implementation design for field characterization of small wind turbines (100~W--5~kW), emphasizing tropical/coastal deployment constraints typical of Low- and Middle-Income Countries (LMIC). We integrate (i)~a student-adapted V-model with requirements traceability, (ii)~hardware selection strategies for high-humidity and salt-spray environments, (iii)~an embedded firmware architecture featuring interrupt-driven rotor speed measurement, state-machine fault handling, and NTP-based time synchronization, (iv)~a local-first hybrid storage design combining SD-card persistence with optional MQTT cloud telemetry, and (v)~a data-management workflow adapting CRISP-DM and FAIR principles with explicit quality dimensions and publication templates. A detailed helical vertical-axis wind turbine (VAWT) design scenario for coastal Sri Lanka illustrates the complete methodology, targeting $>90\\%$ data completeness over six-month campaigns. The methodology is accompanied by open-source firmware, hardware templates, and data-publication workflow artifacts released via GitHub and Zenodo.","authors":["Asitha Lakruwan Kulasekera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03043v2","updated":"2026-01-07T11:50:37Z","published":"2025-10-03T14:25:49Z","title":"Economic zone data-enabled predictive control for connected open water systems","summary":"The real-time operation of open water systems is essential for ensuring operational safety, satisfying operational requirements, and optimizing energy usage. However, existing rule-based control strategies rely heavily on human experience, while model-based approaches depend on accurate hydrodynamic models, which limit their applicability to water systems with complex dynamics and uncertain disturbances. In this work, we develop a fully data-driven, zone-based control framework with adaptive control target zone selection for safe and energy-efficient operation of connected open water systems. Specifically, we propose a mixed-integer economic zone data-enabled predictive control (DeePC) approach that aims to maintain the water levels of the branches within the desired water-level zone while reducing real-time operational energy consumption. The DeePC-based approach enables direct use of input-output data for predictive control, eliminating the need for explicit dynamic modeling. To handle multiple control objectives with different priorities, we employ lexicographic optimization and reformulate the traditional DeePC cost function to incorporate zone tracking and energy consumption minimization objectives. Additionally, Bayesian optimization is utilized to determine the control target zone, which enables an effective trade-off between zone tracking and energy consumption in the presence of external disturbances. Comprehensive simulations and comparative analyses demonstrate the effectiveness of the proposed method. The proposed method maintains water levels within the desired water-level zone for 97.04% of the operating time, with an average energy consumption of 33.5 kWh per 0.5 hour. Compared to rule-based control method, the proposed method lowers zone-violation frequency by 74.96% and the average energy consumption by 22.44%.","authors":["Xiaoqiao Chen","Xuewen Zhang","Minghao Han","Adrian Wing-Keung Law","Xunyuan Yin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.01193v3","updated":"2026-01-07T11:36:34Z","published":"2024-08-02T11:22:57Z","title":"On Game based Distributed Approach for General Multi-agent Optimal Coverage with Application to UAV Networks","summary":"This paper focuses on the optimal coverage problem (OCP) for multi-agent systems with a decentralized optimization mechanism. A game based distributed decision-making method for the multi-agent OCP is proposed to address the high computational costs arising from the large scale of the multi-agent system and to ensure that the game's equilibrium achieves the global performance objective's maximum value. In particular, a distributed algorithm that needs only local information is developed and proved to converge to near-optimal global coverage. Finally, the proposed method is applied to maximize the coverage area of the UAV network for a target region. The simulation results show that our method can require much less computational time than other typical distributed algorithms in related work, while achieving a faster convergence rate. Comparison with centralized optimization also demonstrates that the proposed method has approximate optimization results and high computation efficiency.","authors":["Zixin Feng","Wenchao Xue","Yifen Mu","Ming Wei","Bin Meng","Wei Cui"],"pdf_url":"","comment":"11 pages,11 figures"},{"id":"http://arxiv.org/abs/2601.03819v1","updated":"2026-01-07T11:23:41Z","published":"2026-01-07T11:23:41Z","title":"Unified and Efficient Analysis of Machining Chatter and Surface Location Error","summary":"Although machining chatter can be suppressed by the choice of stable cutting parameters through means of stability lobe diagram (SLD), surface roughness still remains due to the forced vibration, which limits surface quality, especially in the surface finish. Better cutting parameters can be achieved considering surface location error (SLE) together with SLD. This paper proposes an innovative modeling framework of the machining dynamic system that enables efficient computation of the chatter stability and SLE. The framework mainly embodies two techniques, namely semi-discretization method (SDM) and lifting method. The machining dynamics system is mathematically expressed as an angle-varying delay differential equation (DDE). The SDM approximates the angle-varying and delayed terms to ordinary terms using zero-phase interpolations and governs the discrete angle-varying dynamics system. Then, the system is merged over the tooth passing angle using the lifted approach to establish an explicit dynamic system in the compact state-space form. Based on the compact state-space model, the chatter stability and SLE prediction are easily and efficiently conducted. Simulation results show the improved efficiency of the proposed method over other well-known methods.","authors":["Woraphrut Kornmaneesang","Tsu-Chin Tsao","Niloufar Esfandi","Shyh-Leh Chen"],"pdf_url":"","comment":"13 pages, 9 figures, and 1 table"},{"id":"http://arxiv.org/abs/2601.03777v1","updated":"2026-01-07T10:14:49Z","published":"2026-01-07T10:14:49Z","title":"Multi-agent Optimization of Non-cooperative Multimodal Mobility Systems","summary":"While multimodal mobility systems have the potential to bring many benefits to travelers, drivers, the environment, and traffic congestion, such systems typically involve multiple non-cooperative decision-makers who may selfishly optimize their own objectives without considering the overall system benefits. This paper aims to investigate market-based interactions of travelers and ride-sourcing drivers in the context of multimodal mobility systems. We propose a unified mathematical modeling framework to capture the decentralized travelers and drivers' decision-making process and balance the network's demand and supply by equilibrium pricing. Such a model allows analyses of the impact of decentralized decision-making on multimodal mobility efficiencies. The proposed formulation can be further convexified to efficiently compute the equilibrium ride-sourcing prices. We conduct numerical experiments on different settings of transportation networks to gain policy insights. We find that travelers prefer ride-sourcing and multimodal transportation more than the driving option when they are more sensitive to prices. We also find that travelers may need to be subsidized to use multimodal transportation when there is fewer transit hubs in the network or, ride-sourcing drivers become too sensitive to the prices. However, we find that more transit hubs in the network increases the total empty VMT of ride-sourcing drivers by increasing the total relocation time. The proposed model can be used by policymakers and platform operators to design pricing and subsidy schemes that align individual decision-making with system-level efficiency and evaluate the trade-offs between accessibility and environmental impacts in multimodal transportation networks.","authors":["Md Nafees Fuad Rafi","Zhaomiao Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03767v1","updated":"2026-01-07T10:00:55Z","published":"2026-01-07T10:00:55Z","title":"Output Consensus on Periodic References for Constrained Multi-agent Systems Under a Switching Network","summary":"This work addresses the output consensus problem of constrained heterogeneous multi-agent systems under a switching network with potential communication delay, where outputs are periodic and characterized by a linear exosystem. Since periodic references have more complex dynamics, it is more challenging to track periodic references and achieve consensus on them. In this paper, a model predictive control method incorporating an artificial reference and a modified cost is proposed to track periodic references, which maintains recursive feasibility even when reference switches. Moreover, consensus protocols are proposed to achieve consensus on periodic references in different scenarios, in which global information such as the set of globally admissible references and the global time index are not involved. Theoretical analysis proves that constrained output consensus is asymptotically achieved with the proposed algorithm as the references of each agent converge and agents track their references while maintaining constraint satisfaction. Finally, numerical examples are provided to verify the effectiveness of the proposed algorithm.","authors":["Shibo Han","Bonan Hou","Chong Jin Ong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03716v1","updated":"2026-01-07T09:08:17Z","published":"2026-01-07T09:08:17Z","title":"Derivation of the Thermal Conductivity in a Latent Thermal Energy Storage Unit for Use in Simplified System Models","summary":"Latent Thermal Energy Storages (LTES) can store thermal energy in a narrow temperature range. Therefore, they are favorable for integration into Rankine-based Carnot Batteries. For the design of such systems, simulations based on accurate models are desirable. However, physical phenomena such as natural convection in LTES units cannot be modeled directly in transient system models. Simplified models are required. Therefore, the objective of this work is to derive simplified LTES unit models for use in system models. In transient simulations the state of charge of the LTES influences its temperature profile. The temperature profile depends on the geometry of the LTES unit. Therefore, the geometry must be considered to model the transient behavior of an LTES unit. The LTES unit under investigation has a shell and tube heat exchanger structure. The phase change material (PCM) is located between the hexagonal fins and in the space between the finned tubes. Aluminum fins are used. They have a high thermal conductivity and thus compensate for the low thermal conductivity of the sodium nitrate used as PCM. The interaction between fins and PCM is complex. Therefore, a numerical approach can be used to gain insight into the behavior of the LTES unit. To transfer the results of a complex model to a simplified model where fins and PCM are not considered individually, the effective thermal conductivity of a single finned tube can be used to approximate the performance of the LTES unit. In this study, a model of a section with a single finned tube is developed using the COMSOL software. The effective thermal conductivity of the system is determined by varying the effective thermal conductivity in a simplified model and comparing the results with reference cases based on a complex modeling approach. The results can serve as model input for simplified system models of Carnot Batteries, among others.","authors":["Lauritz Zendel","Chiara Springer","Frank Dammel","Peter Stephan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03679v1","updated":"2026-01-07T08:00:43Z","published":"2026-01-07T08:00:43Z","title":"Accounting for Optimal Control in the Sizing of Isolated Hybrid Renewable Energy Systems Using Imitation Learning","summary":"Decarbonization of isolated or off-grid energy systems through phase-in of large shares of intermittent solar or wind generation requires co-installation of energy storage or continued use of existing fossil dispatchable power sources to balance supply and demand. The effective CO2 emission reduction depends on the relative capacity of the energy storage and renewable sources, the stochasticity of the renewable generation, and the optimal control or dispatch of the isolated energy system. While the operations of the energy storage and dispatchable sources may impact the optimal sizing of the system, it is challenging to account for the effect of finite horizon, optimal control at the stage of system sizing. Here, we present a flexible and computationally efficient sizing framework for energy storage and renewable capacity in isolated energy systems, accounting for uncertainty in the renewable generation and the optimal feedback control. To this end, we implement an imitation learning approach to stochastic neural model predictive control (MPC) which allows us to relate the battery storage and wind peak capacities to the emissions reduction and investment costs while accounting for finite horizon, optimal control. Through this approach, decision makers can evaluate the effective emission reduction and costs of different storage and wind capacities at any price point while accounting for uncertainty in the renewable generation with limited foresight. We evaluate the proposed sizing framework on a case study of an offshore energy system with a gas turbine, a wind farm and a battery energy storage system (BESS). In this case, we find a nonlinear, nontrivial relationship between the investment costs and reduction in gas usage relative to the wind and BESS capacities, emphasizing the complexity and importance of accounting for optimal control in the design of isolated energy systems.","authors":["Simon Halvdansson","Lucas Ferreira Bernardino","Brage Rugstad Knudsen"],"pdf_url":"","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2502.20382v2","updated":"2026-01-07T07:15:16Z","published":"2025-02-27T18:56:01Z","title":"Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization","summary":"We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks. Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinematic retargeting and trajectory optimization to adapt them across various robot embodiments and physical parameters. This process yields a diverse, physically consistent dataset that enables cross-embodiment data transfer, and offers the potential to reuse legacy datasets collected under different hardware configurations or physical parameters. We validate the pipeline's effectiveness by training diffusion policies from the generated datasets for challenging contact-rich manipulation tasks across multiple robot embodiments, including a floating Allegro hand and bimanual robot arms. The trained policies are deployed zero-shot on hardware for bimanual iiwa arms, achieving high success rates with minimal human input. Project website: https://lujieyang.github.io/physicsgen/.","authors":["Lujie Yang","H. J. Terry Suh","Tong Zhao","Bernhard Paus Graesdal","Tarik Kelestemur","Jiuguang Wang","Tao Pang","Russ Tedrake"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15119v3","updated":"2026-01-07T22:56:14Z","published":"2025-11-19T04:46:21Z","title":"Nonholonomic Robot Parking by Feedback -- Part I: Modular Strict CLF Designs","summary":"It has been known in the robotics literature since about 1995 that, in polar coordinates, the nonholonomic unicycle is asymptotically stabilizable by smooth feedback, even globally. We introduce a modular design framework that selects the forward velocity to decouple the radial coordinate, allowing the steering subsystem to be stabilized independently. Within this structure, we develop families of feedback laws using passivity, backstepping, and integrator forwarding. Each law is accompanied by a strict control Lyapunov function, including barrier variants that enforce angular constraints. These strict CLFs provide constructive class KL convergence estimates and enable eigenvalue assignment at the target equilibrium. The framework generalizes and extends prior modular and nonmodular approaches, while preparing the ground for inverse optimal and adaptive redesigns in the sequel paper.","authors":["Velimir Todorovski","Kwang Hak Kim","Alessandro Astolfi","Miroslav Krstic"],"pdf_url":"","comment":"arXiv admin note: text overlap with arXiv:2509.25575"},{"id":"http://arxiv.org/abs/2601.04392v1","updated":"2026-01-07T20:59:18Z","published":"2026-01-07T20:59:18Z","title":"Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay","summary":"This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.","authors":["Mohsen Jalaeian-Farimani"],"pdf_url":"","comment":"Submitted to ECC26 conference"},{"id":"http://arxiv.org/abs/2601.04354v1","updated":"2026-01-07T19:39:05Z","published":"2026-01-07T19:39:05Z","title":"Ultra-sensitive graphene-based electro-optic sensors for optically-multiplexed neural recording","summary":"Large-scale neural recording with high spatio-temporal resolution is essential for understanding information processing in brain, yet current neural interfaces fall far short of comprehensively capturing brain activity due to extremely high neuronal density and limited scalability. Although recent advances have miniaturized neural probes and increased channel density, fundamental design constraints still prevent dramatic scaling of simultaneously recorded channels. To address this limitation, we introduce a novel electro-optic sensor that directly converts ultra-low-amplitude neural electrical signals into optical signals with high signal-to-noise ratio. By leveraging the ultra-high bandwidth and intrinsic multiplexing capability of light, this approach offers a scalable path toward massively parallel neural recording beyond the limits of traditional electrical interfaces. The sensor integrates an on-chip photonic microresonator with a graphene layer, enabling direct detection of neural signals without genetically encoded optical indicators or tissue modification, making it suitable for human translation. Neural signals are locally transduced into amplified optical modulations and transmitted through on-chip waveguides, enabling interference-free recording without bulky electromagnetic shielding. Arrays of wavelength-selective sensors can be multiplexed on a single bus waveguide using wavelength-division multiplexing (WDM), greatly improving scalability while maintaining a minimal footprint to reduce tissue damage. We demonstrate detection of evoked neural signals as small as 25 $μ$V with 3 dB SNR from mouse brain tissue and show multiplexed recording from 10 sensors on a single waveguide. These results establish a proof-of-concept for optically multiplexed neural recording and point toward scalable, high-density neural interfaces for neurological research and clinical applications.","authors":["Zabir Ahmed","Xiang Li","Kanika Sarna","Harshvardhan Gupta","Vishal Jain","Maysamreza Chamanzar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.13529v3","updated":"2026-01-07T19:25:50Z","published":"2025-04-18T07:40:24Z","title":"Improving Bayesian Optimization for Portfolio Management with an Adaptive Scheduling","summary":"Existing black-box portfolio management systems are prevalent in the financial industry due to commercial and safety constraints, though their performance can fluctuate dramatically with changing market regimes. Evaluating these non-transparent systems is computationally expensive, as fixed budgets limit the number of possible observations. Therefore, achieving stable and sample-efficient optimization for these systems has become a critical challenge. This work presents a novel Bayesian optimization framework (TPE-AS) that improves search stability and efficiency for black-box portfolio models under these limited observation budgets. Standard Bayesian optimization, which solely maximizes expected return, can yield erratic search trajectories and misalign the surrogate model with the true objective, thereby wasting the limited evaluation budget. To mitigate these issues, we propose a weighted Lagrangian estimator that leverages an adaptive schedule and importance sampling. This estimator dynamically balances exploration and exploitation by incorporating both the maximization of model performance and the minimization of the variance of model observations. It guides the search from broad, performance-seeking exploration towards stable and desirable regions as the optimization progresses. Extensive experiments and ablation studies, which establish our proposed method as the primary approach and other configurations as baselines, demonstrate its effectiveness across four backtest settings with three distinct black-box portfolio management models.","authors":["Zinuo You","John Cartlidge","Karen Elliott","Menghan Ge","Daniel Gold"],"pdf_url":"","comment":"5 pages, 2 figures; version of record. ICAAI 2025, 9th International Conference on Advances in Artificial Intelligence (ICAAI 2025), November 14-16, 2025, Manchester, United Kingdom. ACM, New York, NY, USA, 5 pages"}],"Robotics":[{"id":"http://arxiv.org/abs/2601.04194v1","updated":"2026-01-07T18:59:40Z","published":"2026-01-07T18:59:40Z","title":"Choreographing a World of Dynamic Objects","summary":"Dynamic objects in our physical 4D (3D + time) world are constantly evolving, deforming, and interacting with other objects, leading to diverse 4D scene dynamics. In this paper, we present a universal generative pipeline, CHORD, for CHOReographing Dynamic objects and scenes and synthesizing this type of phenomena. Traditional rule-based graphics pipelines to create these dynamics are based on category-specific heuristics, yet are labor-intensive and not scalable. Recent learning-based methods typically demand large-scale datasets, which may not cover all object categories in interest. Our approach instead inherits the universality from the video generative models by proposing a distillation-based pipeline to extract the rich Lagrangian motion information hidden in the Eulerian representations of 2D videos. Our method is universal, versatile, and category-agnostic. We demonstrate its effectiveness by conducting experiments to generate a diverse range of multi-body 4D dynamics, show its advantage compared to existing methods, and demonstrate its applicability in generating robotics manipulation policies. Project page: https://yanzhelyu.github.io/chord","authors":["Yanzhe Lyu","Chen Geng","Karthik Dharmarajan","Yunzhi Zhang","Hadi Alzayer","Shangzhe Wu","Jiajun Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04191v1","updated":"2026-01-07T18:57:32Z","published":"2026-01-07T18:57:32Z","title":"Embedding Autonomous Agents in Resource-Constrained Robotic Platforms","summary":"Many embedded devices operate under resource constraints and in dynamic environments, requiring local decision-making capabilities. Enabling devices to make independent decisions in such environments can improve the responsiveness of the system and reduce the dependence on constant external control. In this work, we integrate an autonomous agent, programmed using AgentSpeak, with a small two-wheeled robot that explores a maze using its own decision-making and sensor data. Experimental results show that the agent successfully solved the maze in 59 seconds using 287 reasoning cycles, with decision phases taking less than one millisecond. These results indicate that the reasoning process is efficient enough for real-time execution on resource-constrained hardware. This integration demonstrates how high-level agent-based control can be applied to resource-constrained embedded systems for autonomous operation.","authors":["Negar Halakou","Juan F. Gutierrez","Ye Sun","Han Jiang","Xueming Wu","Yilun Song","Andres Gomez"],"pdf_url":"","comment":"This is an open-access, author-archived version of a manuscript published in European Conference on Multi-Agent Systems 2025"},{"id":"http://arxiv.org/abs/2601.04177v1","updated":"2026-01-07T18:43:18Z","published":"2026-01-07T18:43:18Z","title":"Hierarchical GNN-Based Multi-Agent Learning for Dynamic Queue-Jump Lane and Emergency Vehicle Corridor Formation","summary":"Emergency vehicles require rapid passage through congested traffic, yet existing strategies fail to adapt to dynamic conditions. We propose a novel hierarchical graph neural network (GNN)-based multi-agent reinforcement learning framework to coordinate connected vehicles for emergency corridor formation. Our approach uses a high-level planner for global strategy and low-level controllers for trajectory execution, utilizing graph attention networks to scale with variable agent counts. Trained via Multi-Agent Proximal Policy Optimization (MAPPO), the system reduces emergency vehicle travel time by 28.3% compared to baselines and 44.6% compared to uncoordinated traffic in simulations. The design achieves near-zero collision rates (0.3%) while maintaining 81% of background traffic efficiency. Ablation and generalization studies confirm the framework's robustness across diverse scenarios. These results demonstrate the effectiveness of combining GNNs with hierarchical learning for intelligent transportation systems.","authors":["Haoran Su"],"pdf_url":"","comment":"16 Pages, 5 Figures, 9 Tables, submitted to IEEE TITS"},{"id":"http://arxiv.org/abs/2601.04137v1","updated":"2026-01-07T17:50:37Z","published":"2026-01-07T17:50:37Z","title":"Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test","summary":"As world models gain momentum in Embodied AI, an increasing number of works explore using video foundation models as predictive world models for downstream embodied tasks like 3D prediction or interactive generation. However, before exploring these downstream tasks, video foundation models still have two critical questions unanswered: (1) whether their generative generalization is sufficient to maintain perceptual fidelity in the eyes of human observers, and (2) whether they are robust enough to serve as a universal prior for real-world embodied agents. To provide a standardized framework for answering these questions, we introduce the Embodied Turing Test benchmark: WoW-World-Eval (Wow,wo,val). Building upon 609 robot manipulation data, Wow-wo-val examines five core abilities, including perception, planning, prediction, generalization, and execution. We propose a comprehensive evaluation protocol with 22 metrics to assess the models' generation ability, which achieves a high Pearson Correlation between the overall score and human preference (>0.93) and establishes a reliable foundation for the Human Turing Test. On Wow-wo-val, models achieve only 17.27 on long-horizon planning and at best 68.02 on physical consistency, indicating limited spatiotemporal consistency and physical reasoning. For the Inverse Dynamic Model Turing Test, we first use an IDM to evaluate the video foundation models' execution accuracy in the real world. However, most models collapse to $\\approx$ 0% success, while WoW maintains a 40.74% success rate. These findings point to a noticeable gap between the generated videos and the real world, highlighting the urgency and necessity of benchmarking World Model in Embodied AI.","authors":["Chun-Kai Fan","Xiaowei Chi","Xiaozhu Ju","Hao Li","Yong Bao","Yu-Kai Wang","Lizhang Chen","Zhiyuan Jiang","Kuangzhi Ge","Ying Li","Weishi Mi","Qingpo Wuwu","Peidong Jia","Yulin Luo","Kevin Zhang","Zhiyuan Qin","Yong Dai","Sirui Han","Yike Guo","Shanghang Zhang","Jian Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.19486v3","updated":"2026-01-07T16:49:31Z","published":"2025-09-23T18:48:56Z","title":"Supercomputing for High-speed Avoidance and Reactive Planning in Robots","summary":"This paper presents SHARP (Supercomputing for High-speed Avoidance and Reactive Planning), a proof-of-concept study demonstrating how high-performance computing (HPC) can enable millisecond-scale responsiveness in robotic control. While modern robots face increasing demands for reactivity in human-robot shared workspaces, onboard processors are constrained by size, power, and cost. Offloading to HPC offers massive parallelism for trajectory planning, but its feasibility for real-time robotics remains uncertain due to network latency and jitter. We evaluate SHARP in a stress-test scenario where a 7-DOF manipulator must dodge high-speed foam projectiles. Using a hash-distributed multi-goal A* search implemented with MPI on both local and remote HPC clusters, the system achieves mean planning latencies of 22.9 ms (local) and 30.0 ms (remote, ~300 km away), with avoidance success rates of 84% and 88%, respectively. These results show that when round-trip latency remains within the tens-of-milliseconds regime, HPC-side computation is no longer the bottleneck, enabling avoidance well below human reaction times. The SHARP results motivate hybrid control architectures: low-level reflexes remain onboard for safety, while bursty, high-throughput planning tasks are offloaded to HPC for scalability. By reporting per-stage timing and success rates, this study provides a reproducible template for assessing real-time feasibility of HPC-driven robotics. Collectively, SHARP reframes HPC offloading as a viable pathway toward dependable, reactive robots in dynamic environments.","authors":["Kieran S. Lachmansingh","José R. González-Estrada","Jacob Chisholm","Ryan E. Grant","Matthew K. X. J. Pan"],"pdf_url":"","comment":"Error in the graph size calculation, recalculated and resubmitted"},{"id":"http://arxiv.org/abs/2601.04061v1","updated":"2026-01-07T16:26:33Z","published":"2026-01-07T16:26:33Z","title":"CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos","summary":"Generalist Vision-Language-Action models are currently hindered by the scarcity of robotic data compared to the abundance of human video demonstrations. Existing Latent Action Models attempt to leverage video data but often suffer from visual entanglement, capturing noise rather than manipulation skills. To address this, we propose Contrastive Latent Action Pretraining (CLAP), a framework that aligns the visual latent space from videos with a proprioceptive latent space from robot trajectories. By employing contrastive learning, CLAP maps video transitions onto a quantized, physically executable codebook. Building on this representation, we introduce a dual-formulation VLA framework offering both CLAP-NTP, an autoregressive model excelling at instruction following and object generalization, and CLAP-RF, a Rectified Flow-based policy designed for high-frequency, precise manipulation. Furthermore, we propose a Knowledge Matching (KM) regularization strategy to mitigate catastrophic forgetting during fine-tuning. Extensive experiments demonstrate that CLAP significantly outperforms strong baselines, enabling the effective transfer of skills from human videos to robotic execution. Project page: https://lin-shan.com/CLAP/.","authors":["Chubin Zhang","Jianan Wang","Zifeng Gao","Yue Su","Tianru Dai","Cai Zhou","Jiwen Lu","Yansong Tang"],"pdf_url":"","comment":"Project page: https://lin-shan.com/CLAP/"},{"id":"http://arxiv.org/abs/2601.04052v1","updated":"2026-01-07T16:16:10Z","published":"2026-01-07T16:16:10Z","title":"Stable Language Guidance for Vision-Language-Action Models","summary":"Vision-Language-Action (VLA) models have demonstrated impressive capabilities in generalized robotic control; however, they remain notoriously brittle to linguistic perturbations. We identify a critical ``modality collapse'' phenomenon where strong visual priors overwhelm sparse linguistic signals, causing agents to overfit to specific instruction phrasings while ignoring the underlying semantic intent. To address this, we propose \\textbf{Residual Semantic Steering (RSS)}, a probabilistic framework that disentangles physical affordance from semantic execution. RSS introduces two theoretical innovations: (1) \\textbf{Monte Carlo Syntactic Integration}, which approximates the true semantic posterior via dense, LLM-driven distributional expansion, and (2) \\textbf{Residual Affordance Steering}, a dual-stream decoding mechanism that explicitly isolates the causal influence of language by subtracting the visual affordance prior. Theoretical analysis suggests that RSS effectively maximizes the mutual information between action and intent while suppressing visual distractors. Empirical results across diverse manipulation benchmarks demonstrate that RSS achieves state-of-the-art robustness, maintaining performance even under adversarial linguistic perturbations.","authors":["Zhihao Zhan","Yuhao Chen","Jiaying Zhou","Qinhan Lv","Hao Liu","Keze Wang","Liang Lin","Guangrun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16680v2","updated":"2026-01-07T15:37:21Z","published":"2025-04-23T12:58:15Z","title":"Uncertainty-Aware Robotic World Model Makes Offline Model-Based Reinforcement Learning Work on Real Robots","summary":"Reinforcement Learning (RL) has achieved impressive results in robotics, yet high-performing pipelines remain highly task-specific, with little reuse of prior data. Offline Model-based RL (MBRL) offers greater data efficiency by training policies entirely from existing datasets, but suffers from compounding errors and distribution shift in long-horizon rollouts. Although existing methods have shown success in controlled simulation benchmarks, robustly applying them to the noisy, biased, and partially observed datasets typical of real-world robotics remains challenging. We present a principled pipeline for making offline MBRL effective on physical robots. Our RWM-U extends autoregressive world models with epistemic uncertainty estimation, enabling temporally consistent multi-step rollouts with uncertainty effectively propagated over long horizons. We combine RWM-U with MOPO-PPO, which adapts uncertainty-penalized policy optimization to the stable, on-policy PPO framework for real-world control. We evaluate our approach on diverse manipulation and locomotion tasks in simulation and on real quadruped and humanoid, training policies entirely from offline datasets. The resulting policies consistently outperform model-free and uncertainty-unaware model-based baselines, and fusing real-world data in model learning further yields robust policies that surpass online model-free baselines trained solely in simulation.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.26428v2","updated":"2026-01-07T14:58:23Z","published":"2025-09-30T15:48:56Z","title":"Real-time Velocity Profile Optimization for Time-Optimal Maneuvering with Generic Acceleration Constraints","summary":"The computation of time-optimal velocity profiles along prescribed paths, subject to generic acceleration constraints, is a crucial problem in robot trajectory planning, with particular relevance to autonomous racing. However, the existing methods either support arbitrary acceleration constraints at high computational cost or use conservative box constraints for computational efficiency. We propose FBGA, a new \\underline{F}orward-\\underline{B}ackward algorithm with \\underline{G}eneric \\underline{A}cceleration constraints, which achieves both high accuracy and low computation time. FBGA operates forward and backward passes to maximize the velocity profile in short, discretized path segments, while satisfying user-defined performance limits. Tested on five racetracks and two vehicle classes, FBGA handles complex, non-convex acceleration constraints with custom formulations. Its maneuvers and lap times closely match optimal control baselines (within $0.11\\%$-$0.36\\%$), while being up to three orders of magnitude faster. FBGA maintains high accuracy even with coarse discretization, making it well-suited for online multi-query trajectory planning. Our open-source \\texttt{C++} implementation is available at: https://anonymous.4open.science/r/FB_public_RAL.","authors":["Mattia Piazza","Mattia Piccinini","Sebastiano Taddei","Francesco Biral","Enrico Bertolazzi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03956v1","updated":"2026-01-07T14:10:46Z","published":"2026-01-07T14:10:46Z","title":"CoINS: Counterfactual Interactive Navigation via Skill-Aware VLM","summary":"Recent Vision-Language Models (VLMs) have demonstrated significant potential in robotic planning. However, they typically function as semantic reasoners, lacking an intrinsic understanding of the specific robot's physical capabilities. This limitation is particularly critical in interactive navigation, where robots must actively modify cluttered environments to create traversable paths. Existing VLM-based navigators are predominantly confined to passive obstacle avoidance, failing to reason about when and how to interact with objects to clear blocked paths. To bridge this gap, we propose Counterfactual Interactive Navigation via Skill-aware VLM (CoINS), a hierarchical framework that integrates skill-aware reasoning and robust low-level execution. Specifically, we fine-tune a VLM, named InterNav-VLM, which incorporates skill affordance and concrete constraint parameters into the input context and grounds them into a metric-scale environmental representation. By internalizing the logic of counterfactual reasoning through fine-tuning on the proposed InterNav dataset, the model learns to implicitly evaluate the causal effects of object removal on navigation connectivity, thereby determining interaction necessity and target selection. To execute the generated high-level plans, we develop a comprehensive skill library through reinforcement learning, specifically introducing traversability-oriented strategies to manipulate diverse objects for path clearance. A systematic benchmark in Isaac Sim is proposed to evaluate both the reasoning and execution aspects of interactive navigation. Extensive simulations and real-world experiments demonstrate that CoINS significantly outperforms representative baselines, achieving a 17\\% higher overall success rate and over 80\\% improvement in complex long-horizon scenarios compared to the best-performing baseline","authors":["Kangjie Zhou","Zhejia Wen","Zhiyong Zhuo","Zike Yan","Pengying Wu","Ieng Hou U","Shuaiyang Li","Han Gao","Kang Ding","Wenhan Cao","Wei Pan","Chang Liu"],"pdf_url":"","comment":"17 pages, 13 figures"},{"id":"http://arxiv.org/abs/2601.03907v1","updated":"2026-01-07T13:17:20Z","published":"2026-01-07T13:17:20Z","title":"An Event-Based Opto-Tactile Skin","summary":"This paper presents a neuromorphic, event-driven tactile sensing system for soft, large-area skin, based on the Dynamic Vision Sensors (DVS) integrated with a flexible silicone optical waveguide skin. Instead of repetitively scanning embedded photoreceivers, this design uses a stereo vision setup comprising two DVS cameras looking sideways through the skin. Such a design produces events as changes in brightness are detected, and estimates press positions on the 2D skin surface through triangulation, utilizing Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to find the center of mass of contact events resulting from pressing actions. The system is evaluated over a 4620 mm2 probed area of the skin using a meander raster scan. Across 95 % of the presses visible to both cameras, the press localization achieved a Root-Mean-Squared Error (RMSE) of 4.66 mm. The results highlight the potential of this approach for wide-area flexible and responsive tactile sensors in soft robotics and interactive environments. Moreover, we examined how the system performs when the amount of event data is strongly reduced. Using stochastic down-sampling, the event stream was reduced to 1/1024 of its original size. Under this extreme reduction, the average localization error increased only slightly (from 4.66 mm to 9.33 mm), and the system still produced valid press localizations for 85 % of the trials. This reduction in pass rate is expected, as some presses no longer produce enough events to form a reliable cluster for triangulation. These results show that the sensing approach remains functional even with very sparse event data, which is promising for reducing power consumption and computational load in future implementations. The system exhibits a detection latency distribution with a characteristic width of 31 ms.","authors":["Mohammadreza Koolani","Simeon Bamford","Petr Trunin","Simon F. Müller-Cleve","Matteo Lo Preti","Fulvio Mastrogiovanni","Lucia Beccai","Chiara Bartolozzi"],"pdf_url":"","comment":"Accepted for publication in Frontiers in Neuromorphic Engineering. 23 pages, 9 figures"},{"id":"http://arxiv.org/abs/2601.03904v1","updated":"2026-01-07T13:14:41Z","published":"2026-01-07T13:14:41Z","title":"Towards Safe Autonomous Driving: A Real-Time Motion Planning Algorithm on Embedded Hardware","summary":"Ensuring the functional safety of Autonomous Vehicles (AVs) requires motion planning modules that not only operate within strict real-time constraints but also maintain controllability in case of system faults. Existing safeguarding concepts, such as Online Verification (OV), provide safety layers that detect infeasible planning outputs. However, they lack an active mechanism to ensure safe operation in the event that the main planner fails. This paper presents a first step toward an active safety extension for fail-operational Autonomous Driving (AD). We deploy a lightweight sampling-based trajectory planner on an automotive-grade, embedded platform running a Real-Time Operating System (RTOS). The planner continuously computes trajectories under constrained computational resources, forming the foundation for future emergency planning architectures. Experimental results demonstrate deterministic timing behavior with bounded latency and minimal jitter, validating the feasibility of trajectory planning on safety-certifiable hardware. The study highlights both the potential and the remaining challenges of integrating active fallback mechanisms as an integral part of next-generation safeguarding frameworks. The code is available at: https://github.com/TUM-AVS/real-time-motion-planning","authors":["Korbinian Moller","Glenn Johannes Tungka","Lucas Jürgens","Johannes Betz"],"pdf_url":"","comment":"7 pages, submitted to the IEEE Intelligent Vehicles Symposium (IV 2026), Detroit, MI, United States"},{"id":"http://arxiv.org/abs/2601.03869v1","updated":"2026-01-07T12:32:39Z","published":"2026-01-07T12:32:39Z","title":"Bayesian Monocular Depth Refinement via Neural Radiance Fields","summary":"Monocular depth estimation has applications in many fields, such as autonomous navigation and extended reality, making it an essential computer vision task. However, current methods often produce smooth depth maps that lack the fine geometric detail needed for accurate scene understanding. We propose MDENeRF, an iterative framework that refines monocular depth estimates using depth information from Neural Radiance Fields (NeRFs). MDENeRF consists of three components: (1) an initial monocular estimate for global structure, (2) a NeRF trained on perturbed viewpoints, with per-pixel uncertainty, and (3) Bayesian fusion of the noisy monocular and NeRF depths. We derive NeRF uncertainty from the volume rendering process to iteratively inject high-frequency fine details. Meanwhile, our monocular prior maintains global structure. We demonstrate superior performance on key metrics and experiments using indoor scenes from the SUN RGB-D dataset.","authors":["Arun Muthukkumar"],"pdf_url":"","comment":"IEEE 8th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025). Oral presentation; Best Presenter Award"},{"id":"http://arxiv.org/abs/2502.07332v2","updated":"2026-01-07T12:05:11Z","published":"2025-02-11T07:51:20Z","title":"The Combined Problem of Online Task Assignment and Lifelong Path Finding in Logistics Warehouses: Rule-Based Systems Matter","summary":"We study the combined problem of online task assignment and lifelong path finding, which is crucial for the logistics industries. However, most literature either (1) focuses on lifelong path finding assuming a given task assigner, or (2) studies the offline version of this problem where tasks are known in advance. We argue that, to maximize the system throughput, the online version that integrates these two components should be tackled directly. To this end, we introduce a formal framework of the combined problem and its solution concept. Then, we design a rule-based lifelong planner under a practical robot model that works well even in environments with severe local congestion. Upon that, we automate the search for the task assigner with respect to the underlying path planner. Simulation experiments conducted in warehouse scenarios at Meituan, one of the largest shopping platforms in China, demonstrate that (a)in terms of time efficiency, our system requires only 83.77% of the execution time needed for the currently deployed system at Meituan, outperforming other SOTA algorithms by 8.09%; (b)in terms of economic efficiency, ours can achieve the same throughput with only 60% of the agents currently in use. The code and demos are available at https://github.com/Fernadoo/Online-TAPF.","authors":["Fengming Zhu","Weijia Xu","Yifei Guo","Fangzhen Lin"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03813v1","updated":"2026-01-07T11:18:29Z","published":"2026-01-07T11:18:29Z","title":"Integrating Sample Inheritance into Bayesian Optimization for Evolutionary Robotics","summary":"In evolutionary robotics, robot morphologies are designed automatically using evolutionary algorithms. This creates a body-brain optimization problem, where both morphology and control must be optimized together. A common approach is to include controller optimization for each morphology, but starting from scratch for every new body may require a high controller learning budget. We address this by using Bayesian optimization for controller optimization, exploiting its sample efficiency and strong exploration capabilities, and using sample inheritance as a form of Lamarckian inheritance. Under a deliberately low controller learning budget for each morphology, we investigate two types of sample inheritance: (1) transferring all the parent's samples to the offspring to be used as prior without evaluating them, and (2) reevaluating the parent's best samples on the offspring. Both are compared to a baseline without inheritance. Our results show that reevaluation performs best, with prior-based inheritance also outperforming no inheritance. Analysis reveals that while the learning budget is too low for a single morphology, generational inheritance compensates for this by accumulating learned adaptations across generations. Furthermore, inheritance mainly benefits offspring morphologies that are similar to their parents. Finally, we demonstrate the critical role of the environment, with more challenging environments resulting in more stable walking gaits. Our findings highlight that inheritance mechanisms can boost performance in evolutionary robotics without needing large learning budgets, offering an efficient path toward more capable robot design.","authors":["K. Ege de Bruin","Kyrre Glette","Kai Olav Ellefsen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03807v1","updated":"2026-01-07T11:11:57Z","published":"2026-01-07T11:11:57Z","title":"Generational Replacement and Learning for High-Performing and Diverse Populations in Evolvable Robots","summary":"Evolutionary Robotics offers the possibility to design robots to solve a specific task automatically by optimizing their morphology and control together. However, this co-optimization of body and control is challenging, because controllers need some time to adapt to the evolving morphology - which may make it difficult for new and promising designs to enter the evolving population. A solution to this is to add intra-life learning, defined as an additional controller optimization loop, to each individual in the evolving population. A related problem is the lack of diversity often seen in evolving populations as evolution narrows the search down to a few promising designs too quickly. This problem can be mitigated by implementing full generational replacement, where offspring robots replace the whole population. This solution for increasing diversity usually comes at the cost of lower performance compared to using elitism. In this work, we show that combining such generational replacement with intra-life learning can increase diversity while retaining performance. We also highlight the importance of performance metrics when studying learning in morphologically evolving robots, showing that evaluating according to function evaluations versus according to generations of evolution can give different conclusions.","authors":["K. Ege de Bruin","Kyrre Glette","Kai Olav Ellefsen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03782v1","updated":"2026-01-07T10:29:12Z","published":"2026-01-07T10:29:12Z","title":"PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation","summary":"Humans anticipate, from a glance and a contemplated action of their bodies, how the 3D world will respond, a capability that is equally vital for robotic manipulation. We introduce PointWorld, a large pre-trained 3D world model that unifies state and action in a shared 3D space as 3D point flows: given one or few RGB-D images and a sequence of low-level robot action commands, PointWorld forecasts per-pixel displacements in 3D that respond to the given actions. By representing actions as 3D point flows instead of embodiment-specific action spaces (e.g., joint positions), this formulation directly conditions on physical geometries of robots while seamlessly integrating learning across embodiments. To train our 3D world model, we curate a large-scale dataset spanning real and simulated robotic manipulation in open-world environments, enabled by recent advances in 3D vision and simulated environments, totaling about 2M trajectories and 500 hours across a single-arm Franka and a bimanual humanoid. Through rigorous, large-scale empirical studies of backbones, action representations, learning objectives, partial observability, data mixtures, domain transfers, and scaling, we distill design principles for large-scale 3D world modeling. With a real-time (0.1s) inference speed, PointWorld can be efficiently integrated in the model-predictive control (MPC) framework for manipulation. We demonstrate that a single pre-trained checkpoint enables a real-world Franka robot to perform rigid-body pushing, deformable and articulated object manipulation, and tool use, without requiring any demonstrations or post-training and all from a single image captured in-the-wild. Project website at https://point-world.github.io/.","authors":["Wenlong Huang","Yu-Wei Chao","Arsalan Mousavian","Ming-Yu Liu","Dieter Fox","Kaichun Mo","Li Fei-Fei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.01219v4","updated":"2026-01-07T09:23:17Z","published":"2025-11-03T04:30:49Z","title":"Tackling the Kidnapped Robot Problem via Sparse Feasible Hypothesis Sampling and Reliable Batched Multi-Stage Inference","summary":"This paper addresses the Kidnapped Robot Problem (KRP), a core localization challenge of relocalizing a robot in a known map without prior pose estimate when localization loss or at SLAM initialization. For this purpose, a passive 2-D global relocalization framework is proposed. It estimates the global pose efficiently and reliably from a single LiDAR scan and an occupancy grid map while the robot remains stationary, thereby enhancing the long-term autonomy of mobile robots. The proposed framework casts global relocalization as a non-convex problem and solves it via the multi-hypothesis scheme with batched multi-stage inference and early termination, balancing completeness and efficiency. The Rapidly-exploring Random Tree (RRT), under traversability constraints, asymptotically covers the reachable space to generate sparse, uniformly distributed feasible positional hypotheses, fundamentally reducing the sampling space. The hypotheses are preliminarily ordered by the proposed Scan Mean Absolute Difference (SMAD), a coarse beam-error level metric that facilitates the early termination by prioritizing high-likelihood candidates. The SMAD computation is optimized for non-panoramic scans. The Translation-Affinity Scan-to-Map Alignment Metric (TAM) is proposed for reliable orientation selection at hypothesized positions and accurate final pose evaluation to mitigate degradation in conventional likelihood-field metrics under translational uncertainty induced by sparse hypotheses, as well as non-panoramic LiDAR scan and environmental changes. Real-world experiments on a resource-constrained mobile robot with non-panoramic LiDAR scans show that the proposed framework achieves competitive performance in both global relocalization success rate and computational efficiency.","authors":["Muhua Zhang","Lei Ma","Ying Wu","Kai Shen","Deqing Huang","Henry Leung"],"pdf_url":"","comment":"10 pages, 8 figures. This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2511.00088v2","updated":"2026-01-07T09:09:57Z","published":"2025-10-30T01:25:34Z","title":"Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail","summary":"End-to-end architectures trained via imitation learning have advanced autonomous driving by scaling model size and data, yet performance remains brittle in safety-critical long-tail scenarios where supervision is sparse and causal understanding is limited. We introduce Alpamayo-R1 (AR1), a vision-language-action model (VLA) that integrates Chain of Causation reasoning with trajectory planning for complex driving scenarios. Our approach features three key innovations: (1) the Chain of Causation (CoC) dataset, built through a hybrid auto-labeling and human-in-the-loop pipeline producing decision-grounded, causally linked reasoning traces aligned with driving behaviors; (2) a modular VLA architecture combining Cosmos-Reason, a vision-language model pre-trained for Physical AI, with a diffusion-based trajectory decoder that generates dynamically feasible trajectories in real time; (3) a multi-stage training strategy using supervised fine-tuning to elicit reasoning and reinforcement learning (RL) to enforce reasoning-action consistency and optimize reasoning quality. AR1 achieves up to a 12% improvement in planning accuracy on challenging cases compared to a trajectory-only baseline, with a 35% reduction in close encounter rate in closed-loop simulation. RL post-training improves reasoning quality by 45% and reasoning-action consistency by 37%. Model scaling from 0.5B to 7B parameters shows consistent improvements. On-vehicle road tests confirm real-time performance (99 ms latency) and successful urban deployment. By bridging interpretable reasoning with precise control, AR1 demonstrates a practical path towards Level 4 autonomous driving. Model weights are available at https://huggingface.co/nvidia/Alpamayo-R1-10B with inference code at https://github.com/NVlabs/alpamayo.","authors":[" NVIDIA"," :","Yan Wang","Wenjie Luo","Junjie Bai","Yulong Cao","Tong Che","Ke Chen","Yuxiao Chen","Jenna Diamond","Yifan Ding","Wenhao Ding","Liang Feng","Greg Heinrich","Jack Huang","Peter Karkus","Boyi Li","Pinyi Li","Tsung-Yi Lin","Dongran Liu","Ming-Yu Liu","Langechuan Liu","Zhijian Liu","Jason Lu","Yunxiang Mao","Pavlo Molchanov","Lindsey Pavao","Zhenghao Peng","Mike Ranzinger","Ed Schmerling","Shida Shen","Yunfei Shi","Sarah Tariq","Ran Tian","Tilman Wekel","Xinshuo Weng","Tianjun Xiao","Eric Yang","Xiaodong Yang","Yurong You","Xiaohui Zeng","Wenyuan Zhang","Boris Ivanovic","Marco Pavone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12302v2","updated":"2026-01-07T08:27:06Z","published":"2025-12-13T11:59:51Z","title":"From Human Intention to Action Prediction: Intention-Driven End-to-End Autonomous Driving","summary":"While end-to-end autonomous driving has achieved remarkable progress in geometric control, current systems remain constrained by a command-following paradigm that relies on simple navigational instructions. Transitioning to genuinely intelligent agents requires the capability to interpret and fulfill high-level, abstract human intentions. However, this advancement is hindered by the lack of dedicated benchmarks and semantic-aware evaluation metrics. In this paper, we formally define the task of Intention-Driven End-to-End Autonomous Driving and present Intention-Drive, a comprehensive benchmark designed to bridge this gap. We construct a large-scale dataset featuring complex natural language intentions paired with high-fidelity sensor data. To overcome the limitations of conventional trajectory-based metrics, we introduce the Imagined Future Alignment (IFA), a novel evaluation protocol leveraging generative world models to assess the semantic fulfillment of human goals beyond mere geometric accuracy. Furthermore, we explore the solution space by proposing two distinct paradigms: an end-to-end vision-language planner and a hierarchical agent-based framework. The experiments reveal a critical dichotomy where existing models exhibit satisfactory driving stability but struggle significantly with intention fulfillment. Notably, the proposed frameworks demonstrate superior alignment with human intentions.","authors":["Huan Zheng","Yucheng Zhou","Tianyi Yan","Jiayi Su","Hongjun Chen","Dubing Chen","Xingtai Gui","Wencheng Han","Runzhou Tao","Zhongying Qiu","Jianfei Yang","Jianbing Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03686v1","updated":"2026-01-07T08:18:49Z","published":"2026-01-07T08:18:49Z","title":"Dual-Attention Heterogeneous GNN for Multi-robot Collaborative Area Search via Deep Reinforcement Learning","summary":"In multi-robot collaborative area search, a key challenge is to dynamically balance the two objectives of exploring unknown areas and covering specific targets to be rescued. Existing methods are often constrained by homogeneous graph representations, thus failing to model and balance these distinct tasks. To address this problem, we propose a Dual-Attention Heterogeneous Graph Neural Network (DA-HGNN) trained using deep reinforcement learning. Our method constructs a heterogeneous graph that incorporates three entity types: robot nodes, frontier nodes, and interesting nodes, as well as their historical states. The dual-attention mechanism comprises the relational-aware attention and type-aware attention operations. The relational-aware attention captures the complex spatio-temporal relationships among robots and candidate goals. Building on this relational-aware heterogeneous graph, the type-aware attention separately computes the relevance between robots and each goal type (frontiers vs. points of interest), thereby decoupling the exploration and coverage from the unified tasks. Extensive experiments conducted in interactive 3D scenarios within the iGibson simulator, leveraging the Gibson and MatterPort3D datasets, validate the superior scalability and generalization capability of the proposed approach.","authors":["Lina Zhu","Jiyu Cheng","Yuehu Liu","Wei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.20382v2","updated":"2026-01-07T07:15:16Z","published":"2025-02-27T18:56:01Z","title":"Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization","summary":"We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks. Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinematic retargeting and trajectory optimization to adapt them across various robot embodiments and physical parameters. This process yields a diverse, physically consistent dataset that enables cross-embodiment data transfer, and offers the potential to reuse legacy datasets collected under different hardware configurations or physical parameters. We validate the pipeline's effectiveness by training diffusion policies from the generated datasets for challenging contact-rich manipulation tasks across multiple robot embodiments, including a floating Allegro hand and bimanual robot arms. The trained policies are deployed zero-shot on hardware for bimanual iiwa arms, achieving high success rates with minimal human input. Project website: https://lujieyang.github.io/physicsgen/.","authors":["Lujie Yang","H. J. Terry Suh","Tong Zhao","Bernhard Paus Graesdal","Tarik Kelestemur","Jiuguang Wang","Tao Pang","Russ Tedrake"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25687v3","updated":"2026-01-07T05:59:43Z","published":"2025-09-30T02:44:28Z","title":"OmniNav: A Unified Framework for Prospective Exploration and Visual-Language Navigation","summary":"Embodied navigation presents a core challenge for intelligent robots, requiring the comprehension of visual environments, natural language instructions, and autonomous exploration. Existing models often fall short in offering a unified solution across diverse navigation paradigms, resulting in low success rates and limited generalization. We introduce OmniNav, a unified framework addressing instruct-goal, object-goal, point-goal navigation, and frontier-based exploration within a single architecture. Our approach features a lightweight, low-latency policy that accurately predicts continuous-space waypoints (coordinates and orientations). This policy surpasses action-chunk methods in precision and supports real-world deployment at control frequencies up to 5 Hz. Architecturally, OmniNav employs a fast-slow system design: a fast module generates waypoints using short-horizon visual context and subtasks, while a slow module performs deliberative planning with long-horizon observations and candidate frontiers to select subsequent subgoals and subtasks. This collaboration enhances path efficiency and maintains trajectory coherence, particularly in exploration and memory-intensive scenarios. Crucially, we identify that the primary bottleneck isn't merely navigation policy learning, but a robust understanding of general instructions and objects. To boost generalization, OmniNav integrates large-scale, general-purpose training datasets, including those for image captioning and visual recognition, into a joint multi-task regimen. This significantly improves success rates and robustness. Extensive experiments confirm OmniNav's state-of-the-art performance across various navigation benchmarks, with real-world deployment further validating its efficacy. OmniNav provides practical insights for embodied navigation, charting a scalable path towards versatile, highly generalizable robotic intelligence.","authors":["Xinda Xue","Junjun Hu","Minghua Luo","Shichao Xie","Jintao Chen","Zixun Xie","Kuichen Quan","Wei Guo","Mu Xu","Zedong Chu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03617v1","updated":"2026-01-07T05:57:19Z","published":"2026-01-07T05:57:19Z","title":"Systematic Evaluation of Depth Backbones and Semantic Cues for Monocular Pseudo-LiDAR 3D Detection","summary":"Monocular 3D object detection offers a low-cost alternative to LiDAR, yet remains less accurate due to the difficulty of estimating metric depth from a single image. We systematically evaluate how depth backbones and feature engineering affect a monocular Pseudo-LiDAR pipeline on the KITTI validation split. Specifically, we compare NeWCRFs (supervised metric depth) against Depth Anything V2 Metric-Outdoor (Base) under an identical pseudo-LiDAR generation and PointRCNN detection protocol. NeWCRFs yields stronger downstream 3D detection, achieving 10.50\\% AP$_{3D}$ at IoU$=0.7$ on the Moderate split using grayscale intensity (Exp~2). We further test point-cloud augmentations using appearance cues (grayscale intensity) and semantic cues (instance segmentation confidence). Contrary to the expectation that semantics would substantially close the gap, these features provide only marginal gains, and mask-based sampling can degrade performance by removing contextual geometry. Finally, we report a depth-accuracy-versus-distance diagnostic using ground-truth 2D boxes (including Ped/Cyc), highlighting that coarse depth correctness does not fully predict strict 3D IoU. Overall, under an off-the-shelf LiDAR detector, depth-backbone choice and geometric fidelity dominate performance, outweighing secondary feature injection.","authors":["Samson Oseiwe Ajadalu"],"pdf_url":"","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.03607v1","updated":"2026-01-07T05:36:39Z","published":"2026-01-07T05:36:39Z","title":"Locomotion Beyond Feet","summary":"Most locomotion methods for humanoid robots focus on leg-based gaits, yet natural bipeds frequently rely on hands, knees, and elbows to establish additional contacts for stability and support in complex environments. This paper introduces Locomotion Beyond Feet, a comprehensive system for whole-body humanoid locomotion across extremely challenging terrains, including low-clearance spaces under chairs, knee-high walls, knee-high platforms, and steep ascending and descending stairs. Our approach addresses two key challenges: contact-rich motion planning and generalization across diverse terrains. To this end, we combine physics-grounded keyframe animation with reinforcement learning. Keyframes encode human knowledge of motor skills, are embodiment-specific, and can be readily validated in simulation or on hardware, while reinforcement learning transforms these references into robust, physically accurate motions. We further employ a hierarchical framework consisting of terrain-specific motion-tracking policies, failure recovery mechanisms, and a vision-based skill planner. Real-world experiments demonstrate that Locomotion Beyond Feet achieves robust whole-body locomotion and generalizes across obstacle sizes, obstacle instances, and terrain sequences.","authors":["Tae Hoon Yang","Haochen Shi","Jiacheng Hu","Zhicong Zhang","Daniel Jiang","Weizhuo Wang","Yao He","Zhen Wu","Yuming Chen","Yifan Hou","Monroe Kennedy","Shuran Song","C. Karen Liu"],"pdf_url":"","comment":"Project website: https://locomotion-beyond-feet.github.io/"},{"id":"http://arxiv.org/abs/2212.04298v2","updated":"2026-01-07T04:58:13Z","published":"2022-12-08T14:39:20Z","title":"Real-time Sampling-based Model Predictive Control based on Reverse Kullback-Leibler Divergence and Its Adaptive Acceleration","summary":"Sampling-based model predictive control (MPC) has the potential for use in a wide variety of robotic systems. However, its unstable updates and poor convergence render it unsuitable for real-time control of robotic systems. This study addresses this challenge with a novel approach from reverse Kullback-Leibler divergence, which has a mode-seeking property and is likely to find one of the locally optimal solutions early. Using this approach, a weighted maximum likelihood estimation with positive and negative weights is obtained and solved using the mirror descent (MD) algorithm. Negative weights eliminate unnecessary actions, but a practical implementation needs to be designed to avoid interference with positive and negative updates based on rejection sampling. In addition, Nesterov's acceleration method for the proposed MD is modified to improve heuristic step size adaptive to the noise estimated in update amounts. Real-time simulations show that the proposed method can solve a wider variety of tasks statistically than the conventional method. In addition, higher degrees-of-freedom tasks can be solved by the improved acceleration even with a CPU only. The real-world applicability of the proposed method is also demonstrated by optimizing the operability in a variable impedance control of a force-driven mobile robot. https://youtu.be/D8bFMzct1XM","authors":["Taisuke Kobayashi","Kota Fukumoto"],"pdf_url":"","comment":"18 pages, 16 figures"},{"id":"http://arxiv.org/abs/2601.03562v1","updated":"2026-01-07T04:11:00Z","published":"2026-01-07T04:11:00Z","title":"From Score to Sound: An End-to-End MIDI-to-Motion Pipeline for Robotic Cello Performance","summary":"Robot musicians require precise control to obtain proper note accuracy, sound quality, and musical expression. Performance of string instruments, such as violin and cello, presents a significant challenge due to the precise control required over bow angle and pressure to produce the desired sound. While prior robotic cellists focus on accurate bowing trajectories, these works often rely on expensive motion capture techniques, and fail to sightread music in a human-like way.\n  We propose a novel end-to-end MIDI score to robotic motion pipeline which converts musical input directly into collision-aware bowing motions for a UR5e robot cellist. Through use of Universal Robot Freedrive feature, our robotic musician can achieve human-like sound without the need for motion capture. Additionally, this work records live joint data via Real-Time Data Exchange (RTDE) as the robot plays, providing labeled robotic playing data from a collection of five standard pieces to the research community. To demonstrate the effectiveness of our method in comparison to human performers, we introduce the Musical Turing Test, in which a collection of 132 human participants evaluate our robot's performance against a human baseline. Human reference recordings are also released, enabling direct comparison for future studies. This evaluation technique establishes the first benchmark for robotic cello performance. Finally, we outline a residual reinforcement learning methodology to improve upon baseline robotic controls, highlighting future opportunities for improved string-crossing efficiency and sound quality.","authors":["Samantha Sudhoff","Pranesh Velmurugan","Jiashu Liu","Vincent Zhao","Yung-Hsiang Lu","Kristen Yeon-Ji Yun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.09632v2","updated":"2026-01-07T02:46:01Z","published":"2025-03-11T20:52:01Z","title":"Adaptive Anomaly Recovery for Telemanipulation: A Diffusion Model Approach to Vision-Based Tracking","summary":"Dexterous telemanipulation critically relies on the continuous and stable tracking of the human operator's commands to ensure robust operation. Vison-based tracking methods are widely used but have low stability due to anomalies such as occlusions, inadequate lighting, and loss of sight. Traditional filtering, regression, and interpolation methods are commonly used to compensate for explicit information such as angles and positions. These approaches are restricted to low-dimensional data and often result in information loss compared to the original high-dimensional image and video data. Recent advances in diffusion-based approaches, which can operate on high-dimensional data, have achieved remarkable success in video reconstruction and generation. However, these methods have not been fully explored in continuous control tasks in robotics. This work introduces the Diffusion-Enhanced Telemanipulation (DET) framework, which incorporates the Frame-Difference Detection (FDD) technique to identify and segment anomalies in video streams. These anomalous clips are replaced after reconstruction using diffusion models, ensuring robust telemanipulation performance under challenging visual conditions. We validated this approach in various anomaly scenarios and compared it with the baseline methods. Experiments show that DET achieves an average RMSE reduction of 17.2% compared to the cubic spline and 51.1% compared to FFT-based interpolation for different occlusion durations.","authors":["Haoyang Wang","Haoran Guo","Lingfeng Tao","Zhengxiong Li"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2601.03520v1","updated":"2026-01-07T02:10:52Z","published":"2026-01-07T02:10:52Z","title":"A Reinforcement Learning-Based Model for Mapping and Goal-Directed Navigation Using Multiscale Place Fields","summary":"Autonomous navigation in complex and partially observable environments remains a central challenge in robotics. Several bio-inspired models of mapping and navigation based on place cells in the mammalian hippocampus have been proposed. This paper introduces a new robust model that employs parallel layers of place fields at multiple spatial scales, a replay-based reward mechanism, and dynamic scale fusion. Simulations show that the model improves path efficiency and accelerates learning compared to single-scale baselines, highlighting the value of multiscale spatial representations for adaptive robot navigation.","authors":["Bekarys Dukenbaev","Andrew Gerstenslager","Alexander Johnson","Ali A. Minai"],"pdf_url":"","comment":"11 pages, 8 figures. Submitted to IEEE Transactions on Cognitive and Developmental Systems"},{"id":"http://arxiv.org/abs/2601.03519v1","updated":"2026-01-07T02:08:18Z","published":"2026-01-07T02:08:18Z","title":"A Vision-Language-Action Model with Visual Prompt for OFF-Road Autonomous Driving","summary":"Efficient trajectory planning in off-road terrains presents a formidable challenge for autonomous vehicles, often necessitating complex multi-step pipelines. However, traditional approaches exhibit limited adaptability in dynamic environments. To address these limitations, this paper proposes OFF-EMMA, a novel end-to-end multimodal framework designed to overcome the deficiencies of insufficient spatial perception and unstable reasoning in visual-language-action (VLA) models for off-road autonomous driving scenarios. The framework explicitly annotates input images through the design of a visual prompt block and introduces a chain-of-thought with self-consistency (COT-SC) reasoning strategy to enhance the accuracy and robustness of trajectory planning. The visual prompt block utilizes semantic segmentation masks as visual prompts, enhancing the spatial understanding ability of pre-trained visual-language models for complex terrains. The COT- SC strategy effectively mitigates the error impact of outliers on planning performance through a multi-path reasoning mechanism. Experimental results on the RELLIS-3D off-road dataset demonstrate that OFF-EMMA significantly outperforms existing methods, reducing the average L2 error of the Qwen backbone model by 13.3% and decreasing the failure rate from 16.52% to 6.56%.","authors":["Liangdong Zhang","Yiming Nie","Haoyang Li","Fanjie Kong","Baobao Zhang","Shunxin Huang","Kai Fu","Chen Min","Liang Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.15119v3","updated":"2026-01-07T22:56:14Z","published":"2025-11-19T04:46:21Z","title":"Nonholonomic Robot Parking by Feedback -- Part I: Modular Strict CLF Designs","summary":"It has been known in the robotics literature since about 1995 that, in polar coordinates, the nonholonomic unicycle is asymptotically stabilizable by smooth feedback, even globally. We introduce a modular design framework that selects the forward velocity to decouple the radial coordinate, allowing the steering subsystem to be stabilized independently. Within this structure, we develop families of feedback laws using passivity, backstepping, and integrator forwarding. Each law is accompanied by a strict control Lyapunov function, including barrier variants that enforce angular constraints. These strict CLFs provide constructive class KL convergence estimates and enable eigenvalue assignment at the target equilibrium. The framework generalizes and extends prior modular and nonmodular approaches, while preparing the ground for inverse optimal and adaptive redesigns in the sequel paper.","authors":["Velimir Todorovski","Kwang Hak Kim","Alessandro Astolfi","Miroslav Krstic"],"pdf_url":"","comment":"arXiv admin note: text overlap with arXiv:2509.25575"},{"id":"http://arxiv.org/abs/2404.17070v7","updated":"2026-01-07T21:19:40Z","published":"2024-04-25T22:41:59Z","title":"Deep Reinforcement Learning for Bipedal Locomotion: A Brief Survey","summary":"Bipedal robots are gaining global recognition due to their potential applications and advancements in artificial intelligence, particularly through Deep Reinforcement Learning (DRL). While DRL has significantly advanced bipedal locomotion, the development of a unified framework capable of handling a wide range of tasks remains an ongoing challenge. This survey systematically categorises, compares, and analyses existing DRL frameworks for bipedal locomotion, organising them into end-to-end and hierarchical control schemes. End-to-end frameworks are evaluated based on their learning approaches, while hierarchical frameworks are examined in terms of layered structures that integrate learning-based or traditional model-based methods. We provide a detailed evaluation of the composition, strengths, limitations, and capabilities of each framework. Additionally, this survey identifies key research gaps and proposes future directions aimed at creating a more integrated and efficient framework for bipedal locomotion, with wide-ranging applications in real-world environments.","authors":["Lingfan Bao","Joseph Humphreys","Tianhu Peng","Chengxu Zhou"],"pdf_url":"","comment":"Published in Artificial Intelligence Review"},{"id":"http://arxiv.org/abs/2601.04401v1","updated":"2026-01-07T21:18:28Z","published":"2026-01-07T21:18:28Z","title":"Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces","summary":"Conventional optimization-based metering depends on strict adherence to precomputed schedules, which limits the flexibility required for the stochastic operations of Advanced Air Mobility (AAM). In contrast, multi-agent reinforcement learning (MARL) offers a decentralized, adaptive framework that can better handle uncertainty, required for safe aircraft separation assurance. Despite this advantage, current MARL approaches often overfit to specific airspace structures, limiting their adaptability to new configurations. To improve generalization, we recast the MARL problem in a relative polar state space and train a transformer encoder model across diverse traffic patterns and intersection angles. The learned model provides speed advisories to resolve conflicts while maintaining aircraft near their desired cruising speeds. In our experiments, we evaluated encoder depths of 1, 2, and 3 layers in both structured and unstructured airspaces, and found that a single encoder configuration outperformed deeper variants, yielding near-zero near mid-air collision rates and shorter loss-of-separation infringements than the deeper configurations. Additionally, we showed that the same configuration outperforms a baseline model designed purely with attention. Together, our results suggest that the newly formulated state representation, novel design of neural network architecture, and proposed training strategy provide an adaptable and scalable decentralized solution for aircraft separation assurance in both structured and unstructured airspaces.","authors":["Arsyi Aziz","Peng Wei"],"pdf_url":"","comment":"9 pages, 4 figures, 4 tables. Presented at SESAR Innovation Days 2025"},{"id":"http://arxiv.org/abs/2601.04392v1","updated":"2026-01-07T20:59:18Z","published":"2026-01-07T20:59:18Z","title":"Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay","summary":"This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.","authors":["Mohsen Jalaeian-Farimani"],"pdf_url":"","comment":"Submitted to ECC26 conference"},{"id":"http://arxiv.org/abs/2601.04356v1","updated":"2026-01-07T19:43:16Z","published":"2026-01-07T19:43:16Z","title":"UNIC: Learning Unified Multimodal Extrinsic Contact Estimation","summary":"Contact-rich manipulation requires reliable estimation of extrinsic contacts-the interactions between a grasped object and its environment which provide essential contextual information for planning, control, and policy learning. However, existing approaches often rely on restrictive assumptions, such as predefined contact types, fixed grasp configurations, or camera calibration, that hinder generalization to novel objects and deployment in unstructured environments. In this paper, we present UNIC, a unified multimodal framework for extrinsic contact estimation that operates without any prior knowledge or camera calibration. UNIC directly encodes visual observations in the camera frame and integrates them with proprioceptive and tactile modalities in a fully data-driven manner. It introduces a unified contact representation based on scene affordance maps that captures diverse contact formations and employs a multimodal fusion mechanism with random masking, enabling robust multimodal representation learning. Extensive experiments demonstrate that UNIC performs reliably. It achieves a 9.6 mm average Chamfer distance error on unseen contact locations, performs well on unseen objects, remains robust under missing modalities, and adapts to dynamic camera viewpoints. These results establish extrinsic contact estimation as a practical and versatile capability for contact-rich manipulation.","authors":["Zhengtong Xu","Yuki Shirai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.12962v2","updated":"2026-01-07T19:28:16Z","published":"2025-10-14T20:13:34Z","title":"Enhancing Sampling-based Planning with a Library of Paths","summary":"Path planning for 3D solid objects is a challenging problem, requiring a search in a six-dimensional configuration space, which is, nevertheless, essential in many robotic applications such as bin-picking and assembly. The commonly used sampling-based planners, such as Rapidly-exploring Random Trees, struggle with narrow passages where the sampling probability is low, increasing the time needed to find a solution. In scenarios like robotic bin-picking, various objects must be transported through the same environment. However, traditional planners start from scratch each time, losing valuable information gained during the planning process. We address this by using a library of past solutions, allowing the reuse of previous experiences even when planning for a new, previously unseen object. Paths for a set of objects are stored, and when planning for a new object, we find the most similar one in the library and use its paths as approximate solutions, adjusting for possible mutual transformations. The configuration space is then sampled along the approximate paths. Our method is tested in various narrow passage scenarios and compared with state-of-the-art methods from the OMPL library. Results show significant speed improvements (up to 85% decrease in the required time) of our method, often finding a solution in cases where the other planners fail. Our implementation of the proposed method is released as an open-source package.","authors":["Michal Minařík","Vojtěch Vonásek","Robert Pěnička"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04334v1","updated":"2026-01-07T19:13:22Z","published":"2026-01-07T19:13:22Z","title":"Autonomous Reasoning for Spacecraft Control: A Large Language Model Framework with Group Relative Policy Optimization","summary":"This paper presents a learning-based guidance-and-control approach that couples a reasoning-enabled Large Language Model (LLM) with Group Relative Policy Optimization (GRPO). A two-stage procedure consisting of Supervised Fine-Tuning (SFT) to learn formatting and control primitives, followed by GRPO for interaction-driven policy improvement, trains controllers for each environment. The framework is demonstrated on four control problems spanning a gradient of dynamical complexity, from canonical linear systems through nonlinear oscillatory dynamics to three-dimensional spacecraft attitude control with gyroscopic coupling and thrust constraints. Results demonstrate that an LLM with explicit reasoning, optimized via GRPO, can synthesize feasible stabilizing policies under consistent training settings across both linear and nonlinear systems. The two-stage training methodology enables models to generate control sequences while providing human-readable explanations of their decision-making process. This work establishes a foundation for applying GRPO-based reasoning to autonomous control systems, with potential applications in aerospace and other safety-critical domains.","authors":["Amit Jain","Richard Linares"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.14643v2","updated":"2026-01-07T19:12:10Z","published":"2025-10-16T12:55:28Z","title":"Generative Models From and For Sampling-Based MPC: A Bootstrapped Approach For Adaptive Contact-Rich Manipulation","summary":"We present a generative predictive control (GPC) framework that amortizes sampling-based Model Predictive Control (SPC) by bootstrapping it with conditional flow-matching models trained on SPC control sequences collected in simulation. Unlike prior work relying on iterative refinement or gradient-based solvers, we show that meaningful proposal distributions can be learned directly from noisy SPC data, enabling more efficient and informed sampling during online planning. We further demonstrate, for the first time, the application of this approach to real-world contact-rich loco-manipulation with a quadruped robot. Extensive experiments in simulation and on hardware show that our method improves sample efficiency, reduces planning horizon requirements, and generalizes robustly across task variations.","authors":["Lara Brudermüller","Brandon Hung","Xinghao Zhu","Jiuguang Wang","Nick Hawes","Preston Culbertson","Simon Le Cleac'h"],"pdf_url":"","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.04287v1","updated":"2026-01-07T14:28:37Z","published":"2026-01-07T14:28:37Z","title":"Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control","summary":"We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.","authors":["Ben Carvell","George De Ath","Eseoghene Benjamin","Richard Everson"],"pdf_url":"","comment":null}],"Analysis of PDEs":[{"id":"http://arxiv.org/abs/2601.04173v1","updated":"2026-01-07T18:42:01Z","published":"2026-01-07T18:42:01Z","title":"Trace regularity of solutions to the Navier equations","summary":"We present results on the trace regularity of the stress vector on the boundary of an elastic solid satisfying the time-dependent, displacement-traction problem for the Navier equations of linear elasticity in a bounded domain of $\\mathbb{R}^3$. Specifically, the solid's displacement is subject to Dirichlet- and Neumann-type conditions on different portions of its boundary and possibly non-zero body forces and initial data. Our regularity results are reminiscent of the so-called \"hidden trace regularity\" results for solutions to the scalar wave equation obtained in [12].","authors":["Jerin Tasnim Farin","Giusy Mazzone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.12279v4","updated":"2026-01-07T17:42:40Z","published":"2025-01-21T16:50:33Z","title":"Spatial exponential decay of perturbations in optimal control of general evolution equations","summary":"We analyze the robustness of optimally controlled evolution equations with respect to spatially localized perturbations. We prove that if the involved operators are domain-uniformly stabilizable and detectable, then these localized perturbations only have a local effect on the optimal solution. We characterize this domain-uniform stabilizability and detectability for the transport equation with constant transport velocity, showing that even for unitary semigroups, optimality implies exponential damping. We extend this result to the case of a space-dependent transport velocity. Finally we leverage the results for the transport equation to characterize domain-uniform stabilizability of the wave equation. Numerical examples in one space dimension complement the theoretical results.","authors":["Simone Göttlich","Benedikt Oppeneiger","Manuel Schaller","Karl Worthmann"],"pdf_url":"","comment":"53 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.04117v1","updated":"2026-01-07T17:26:19Z","published":"2026-01-07T17:26:19Z","title":"Teukolsky on slowly-rotating Kerr-de Sitter in the vanishing $Λ$ limit","summary":"We prove energy, Morawetz and $r^p$-weighted estimates for solutions to the Teukolsky equation set on a slowly-rotating Kerr-de Sitter background. The main feature of our estimates is their uniformity with respect to the cosmological constant $Λ>0$ (thus allowed to tend to $0$), while they hold on the whole domain of outer communications, extending up to $r\\sim Λ^{-\\frac{1}{2}}$. As an application of our result, we recover well-known corresponding estimates for solutions to Teukolsky on a slowly-rotating Kerr background in the limit $Λ\\to 0$.","authors":["Allen Juntao Fang","Jérémie Szeftel","Arthur Touati"],"pdf_url":"","comment":"193 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.04105v1","updated":"2026-01-07T17:11:23Z","published":"2026-01-07T17:11:23Z","title":"Time Reparametrization and Chaotic Dynamics in Conformable $C_0$-Semigroups","summary":"Conformable derivatives provide a fractional-looking calculus that remains local and admits a simple representation through classical derivatives with explicit weights. In this paper we develop a systematic operator-theoretic perspective showing that conformable time evolution is, in essence, a classical $C_0$-semigroup observed through a nonlinear clock. We introduce the conformable time map $ψ(t)=t^α/α$ and prove that every $C_0$--$α$-semigroup $\\{T_α(t)\\}_{t\\ge0}$ can be written as $T_α(t)=T(ψ(t))$ for a uniquely determined classical $C_0$-semigroup $\\{T(s)\\}_{s\\ge0}$, with generators agreeing on a common domain. This correspondence yields a one-to-one transfer of mild solutions and shows that orbit-based linear dynamics are invariant under conformable reparametrization. In particular, $α$-hypercyclicity and $α$--chaos coincide with the usual notions for the associated classical semigroup. As a consequence, we obtain a conformable version of the Desch--Schappacher--Webb spectral criterion for chaos. We also place the analysis in the natural functional setting provided by conformable Lebesgue spaces $L^{p,α}$ and their explicit isometric identification with standard $L^p$ spaces, which allows one to transport estimates and spectral arguments without loss. The results clarify which dynamical phenomena in conformable models are genuinely new and which are inherited from classical semigroup dynamics via a nonlinear change of time.","authors":["Mohamed Khoulane","Aziz El Ghazouani","M'hamed El Omari"],"pdf_url":"","comment":"17 pages"},{"id":"http://arxiv.org/abs/2508.18054v2","updated":"2026-01-07T17:06:44Z","published":"2025-08-25T14:13:07Z","title":"Hot spots on cones and warped product manifolds","summary":"We study extrema of solutions to the heat equation (i.e. hot spots) on a class of warped product manifolds of the form $([0,L]\\times M,dr^2+f(r)^2h)$ where $(M,h)$ is a closed Riemannian manifold. We prove that, under certain conditions on the warping function $f$, the statement of Rauch's hot spots conjecture holds for the corresponding warped product. We then go on to study the long-time behavior of hot spots on infinite cones over closed Riemannian manifolds. In this case, under appropriate hypotheses on the initial condition, there are four possible long-time behaviors depending only on the spectral gap of the fiber $(M,h)$.","authors":["Lawford Hatcher"],"pdf_url":"","comment":"Minor corrections and updates to the exposition; main results unchanged. 21 pages, 0 figures"},{"id":"http://arxiv.org/abs/2601.04088v1","updated":"2026-01-07T16:56:26Z","published":"2026-01-07T16:56:26Z","title":"Fractional heat content asymptotics for Carnot groups","summary":"We propose a novel approach for studying small-time asymptotics of the fractional heat content of $C^2$ non-characteristic domains in Carnot groups. Denoting the sub-Laplacian operator by $\\mathcal{L}$, the fractional heat content of a bounded domain $Ω$ is defined as $Q^{(α)}_Ω(t)=\\int_Ω u_α(t,x)dx$, where $u_α$ is the solution to the heat equation corresponding to the fractional sub-Laplacian $\\mathcal{L}_α:=\\mathcal{L}^{α/2}$ with Dirichlet boundary condition on $Ω$. We prove that for $1\\leα\\le 2$, there exists explict rate function $μ_α: (0,\\infty)\\to (0,\\infty)$ such that \\[ \\lim_{t\\to 0}\\frac{|Ω|-Q^{(α)}_Ω(t)}{μ_α(t)}=|\\partialΩ|_H, \\] where $|\\partialΩ|_H$ is the horizontal perimeter of $Ω$. Moreover, the rate function $μ_α$ coincides with the same for the Euclidean case.","authors":["Rohan Sarkar"],"pdf_url":"","comment":"21 pages"},{"id":"http://arxiv.org/abs/2601.04074v1","updated":"2026-01-07T16:39:47Z","published":"2026-01-07T16:39:47Z","title":"Multi-Dimensional Opinion Formation","summary":"In this paper we propose and investigate a multi-dimensional opinion dynamics model where people are characterised by both opinions and importance weights across these opinions. Opinion changes occur through binary interactions, with a novel coupling mechanism: the change in one topic depends on the weighted similarity across the full opinion vector. We state the kinetic equation for this process and derive its mean-field partial differential equation to describe the overall dynamics. Analytical computations and numerical simulations confirm that this model generates complex stationary states, and we demonstrate that the final opinion structures are critically determined by the peoples' opinion weights.","authors":["Hanna Bartel","Martin Burger","Marie-Therese Wolfram"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04018v1","updated":"2026-01-07T15:34:10Z","published":"2026-01-07T15:34:10Z","title":"Global stability of vacuum for the relativistic Vlasov-Maxwell-Boltzmann system","summary":"We consider the three-dimensional relativistic Vlasov-Maxwell-Boltzmann system, where the speed of light $c$ is an arbitrary constant no less than 1, and we establish global existence and nonlinear stability of the vacuum for small initial data, with bounds that are uniform in $c$. The analysis is based on the vector field method combined with the Glassey-Strauss decomposition of the electromagnetic field, and does not require any compact support assumption on the initial data. A key ingredient of the proof is the derivation of a chain rule for the relativistic Boltzmann collision operator that is compatible with the commutation properties of the vector fields. These tools allow us to control the coupled kinetic and electromagnetic equations and to obtain global stability near vacuum.","authors":["Chuqi Cao","Xingyu Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03968v1","updated":"2026-01-07T14:30:53Z","published":"2026-01-07T14:30:53Z","title":"The uniqueness and concentration behavior of solutions for a nonlinear fractional Schrödinger system","summary":"The paper is concerned with a nonlinear system of two coupled fractional Schrödinger equations with both attractive intraspecies and attractive interspecies interactions in $\\mathbb{R}$. By analyzing an associated $L^2$-constrained minimization problem, the uniqueness of solutions to this system is proved via the implicit function theorem. Under a certain type of trapping potential, by establishing some delicate energy estimates, we present a detailed analysis on the concentration behavior of the solutions as the total strength of intraspecies and interspecies interactions tends to a critical value, where each component of the solutions blows up and concentrates at a flattest common minimum point of the associated trapping potentials. An optimal blow-up rate of solutions to the system is also given.","authors":["Chungen Liu","Zhigao Zhang","Jiabin Zuo"],"pdf_url":"","comment":"26 pages"},{"id":"http://arxiv.org/abs/2412.08493v2","updated":"2026-01-07T13:43:12Z","published":"2024-12-11T15:57:41Z","title":"Dissipation for codimension 1 singular structures in the incompressible Euler equations","summary":"We consider weak solutions to the incompressible Euler equations. It is shown that energy conservation holds in any Onsager critical class in which smooth functions are dense. The argument is independent of the specific critical regularity and the underlying PDE. This groups several energy conservation results and it suggests that critical spaces where smooth functions are dense are not at all different from subcritical ones, although possessing the \"minimal\" regularity index. Then, we study properties of the dissipation $D$ in the case of bounded solutions that are allowed to jump on $H^d$-rectifiable space-time sets $Σ$, which are the natural dissipative regions in the compressible setting. As soon as both the velocity and the pressure posses traces on $Σ$, it is shown that $Σ$ is $D$-negligible. The argument makes the role of the incompressibility very apparent, and it prevents dissipation on codimension 1 sets even if they happen to be densely distributed. As a corollary, we deduce energy conservation for bounded solutions of \"special bounded deformation\", providing the first energy conservation criterion in a critical class where only an assumption on the \"longitudinal\" increment is made, while the energy flux does not vanish for kinematic reasons.","authors":["Luigi De Rosa","Marco Inversi","Matteo Nesi"],"pdf_url":"","comment":"Version accepted in Nonlinearity"},{"id":"http://arxiv.org/abs/2601.03865v1","updated":"2026-01-07T12:24:47Z","published":"2026-01-07T12:24:47Z","title":"On the Fučík spectrum of the Logarithmic Laplacian","summary":"In this paper, we investigate the Fučík spectrum $Σ_L$ associated with the logarithmic Laplacian. This spectrum is defined as the set of all pairs $(α,β) \\in \\mathbb{R}^2$ for which the problem \\[ L_Δu = αu^+-βu^- ~\\text{in} ~ Ω\\quad \\text{and} \\quad u=0 ~\\text{in} ~\\mathbb{R}^N\\setminus Ω\\] admits a nontrivial solution $u$. Here, $Ω\\subset \\mathbb{R}^N$ is a bounded domain with $C^{1,1}$ boundary, $u^\\pm = \\max\\{\\pm u,0\\}$, and $u = u^+ - u^-$. We show that the lines $λ_1^L \\times \\mathbb{R}$ and $\\mathbb{R} \\times λ_1^L$, where $λ_1^L$ denotes the first eigenvalue of $L_Δ$, lies in the spectrum $Σ_L$ and are isolated within the spectrum. Furthermore, we establish the existence of the first nontrivial curve in $Σ_L$ and analyze its qualitative properties, including Lipschitz continuity, strict monotonicity, and asymptotic behavior. In addition, we obtain a variational characterization of the second eigenvalue of the logarithmic Laplacian and show that all eigenfunctions corresponding to eigenvalues $λ> λ_1^L$ are sign-changing. Finally, we address a nonresonance problem with respect to the Fučík spectrum $Σ_L$, employing variational methods and carefully overcoming the difficulties arising from the contrasting features of the first eigenvalue $λ_1^L$.","authors":["Rakesh Arora","Tuhina Mukherjee"],"pdf_url":"","comment":"21 pages. Comments are welcome"},{"id":"http://arxiv.org/abs/2601.03833v1","updated":"2026-01-07T11:59:29Z","published":"2026-01-07T11:59:29Z","title":"On the existence of forward self-similar solutions to the two-dimensional Navier-Stokes equations","summary":"We establish the global existence of forward self-similar solutions to the two-dimensional incompressible Navier-Stokes equations for any divergence-free initial velocity $u_0$ that is homogeneous of degree $-1$ and locally Hölder continuous. This result requires no smallness assumption on the initial data. In sharp contrast to the three-dimensional case, where $(-1)$-homogeneous vector fields are locally square-integrable, the 2D problem is critical in the sense that the initial kinetic energy is locally infinite at the origin, and the initial vorticity fails to be locally integrable. Consequently, the classical local energy estimates are not available. To overcome this, we decompose the solution into a linear part solving the heat equation and a finite-energy perturbation part. By exploiting a kind of inherent cancellation relation between the linear part and the perturbation part, we can control interaction terms and establish the $H^1$-estimates for the perturbation part. Further investigating the corresponding Leray system in weighted Sobolev space, we can derive an optimal pointwise estimate. This gives the faster decay of the perturbation part at infinity and enables us to construct global-in-time self-similar solutions.","authors":["Changfeng Gui","Hao Liu","Chunjing Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.19386v2","updated":"2026-01-07T10:34:14Z","published":"2024-02-29T17:37:43Z","title":"The viscous variational wave equation with transport noise","summary":"This article considers the variational wave equation with viscosity and transport noise as a system of three coupled nonlinear stochastic partial differential equations. We prove pathwise global existence, uniqueness, and temporal continuity of solutions to this system in $L^2_x$. Martingale solutions are extracted from a two-level Galerkin approximation via the Skorokhod--Jakubowski theorem. We use the apparatus of Dudley maps to streamline this stochastic compactness method, bypassing the usual martingale identification argument. Pathwise uniqueness for the system is established through a renormalisation procedure that involves double commutator estimates and a delicate handling of noise and nonlinear terms. New model-specific commutator estimates are proven.","authors":["Peter H. C. Pang"],"pdf_url":"","comment":"41 pages; minor typos amended"},{"id":"http://arxiv.org/abs/2601.03773v1","updated":"2026-01-07T10:11:28Z","published":"2026-01-07T10:11:28Z","title":"Green function rigidity for two dimensional sphere","summary":"We verify a conjecture proposed by X. Chen and Y. Shi, which arises from their study of the Green function on spheres in Euclidean space. More precisely, let $M\\subset \\mathbb{R}^3$ be a closed $C^{2}$ embedded surface and suppose that there exists a point $p\\in M$ so that its Green function $G$ is of the form $G(p,q)=-\\frac{1}{2π} \\ln d_{\\mathbb{R}^3}(p,q)+c, \\forall q\\neq p$, then $M$ must be a round sphere.","authors":["Mijia Lai","Chilin Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03755v1","updated":"2026-01-07T09:45:32Z","published":"2026-01-07T09:45:32Z","title":"$BV$-Estimates for Non-Linear Parabolic PDE with Linear Drift","summary":"In the present work, we establish space Bounded Variation $(BV)$ regularity of the solution for a non-linear parabolic partial differential equations involving a linear drift term. We study the problem in a bounded domain with mixed Dirichlet-Neumann boundary conditions, a general non-linearity and reasonable assumptions on the data. Our results also cover, as a particular case, the linear transport equation in a bounded domain with an outward-pointing drift vector field on the boundary.","authors":["El Mahdi Erraji","Noureddine Igbida","Fahd Karami","Driss Meskine"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03742v1","updated":"2026-01-07T09:30:01Z","published":"2026-01-07T09:30:01Z","title":"Mean-field limits for interacting particles on general adaptive dynamical networks","summary":"We study the large-population limit of interacting particle systems evolving on adaptive dynamical networks, motivated in particular by models of opinion dynamics. In such systems, agents interact through weighted graphs whose structure evolves over time in a coupled manner with the agents' states, leading to non-exchangeable dynamics. In the dense-graph regime, we show that the asymptotic behavior is described by a Vlasov-type equation posed on an extended phase space that includes both the agents' states and identities and the evolving interaction weights. We establish this limiting equation through two complementary approaches. The first follows the mean-field methodology in the spirit of Sznitman [28]. In this framework, we impose the additional assumption that the weight dynamics is independent of one of the agent's states, an assumption that remains well motivated from a modeling perspective and allows for a direct derivation of the mean-field limit. The second approach is based on the graph limit framework and is formulated in a deterministic setting. This perspective makes it possible to remove the aforementioned restriction on the weight dynamics and to handle more general interaction structures. Our analysis includes wellposedness and stability results for the limiting Vlasov-type equation, as well as quantitative estimates ensuring the propagation of independence. We further clarify the relationship between the continuum (graph limit) formulation and the mean-field limit, thereby providing a unified description of the asymptotic dynamics of interacting particle systems on adaptive dynamical networks.","authors":["Nathalie Ayi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03739v1","updated":"2026-01-07T09:29:20Z","published":"2026-01-07T09:29:20Z","title":"On the structure of entropy dissipation and regularity for quasi-entropy solutions to 1d scalar conservation laws and to isentropic Euler system with $γ=3$","summary":"In this paper, we first investigate quasi-entropy solutions to scalar conservation laws in several space dimensions. In this setting, we introduce a suitable Lagrangian representation for such solutions. Next, we prove that, in one space dimension and for fluxes $f$ satisfying a general non-degeneracy condition, the entropy dissipation measures of quasi-entropy solutions are concentrated on a 1-rectifiable set. The same result is obtained for the isentropic Euler system with $γ= 3$, for which we also slightly improve the available fractional regularity by exploiting the sign of the kinetic measures.","authors":["Fabio Ancona","Elio Marconi","Luca Talamini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03721v1","updated":"2026-01-07T09:17:49Z","published":"2026-01-07T09:17:49Z","title":"Liouville theorems and gradient estimates of a nonlinear elliptic equation for the V-Laplacian","summary":"In this paper we establish gradient estimates for positive solutions to the nonlinear elliptic equation $$Δ_{V}u^{m}+μ(x)u+p(x)u^α=0 , \\quad m>1$$on any smooth metric measure space whose $k$-Bakry-Émery curvature is bounded from below by $-(k-1)K$ with $K \\geq 0$. Additionally, we obtain related Liouville theorems and Harnack inequalities. We partially extend conclusions of Wang, when $V=0$, $μ=0$ the equation becomes $Δu^{m}+p(x)u^α=0$. And $V=f$, $μ=c, p=0 $, the equation becomes $Δ_{f}u^{m}+cu=0 $.","authors":["Yike Jia"],"pdf_url":"","comment":"16 pages"},{"id":"http://arxiv.org/abs/2504.05695v4","updated":"2026-01-07T08:26:24Z","published":"2025-04-08T05:37:38Z","title":"Architecture independent generalization bounds for overparametrized deep ReLU networks","summary":"We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove a uniform generalization bound that is independent of the network architecture. We perform computational experiments of our theoretical results with MNIST, and obtain agreement with the true test error within a 22 % margin on average.","authors":["Anandatheertha Bapu","Thomas Chen","Chun-Kai Kevin Chien","Patricia Muñoz Ewald","Andrew G. Moore"],"pdf_url":"","comment":"AMS Latex, 18 pages. Significantly updated, A. Bapu included as coauthor, Section 3 added"},{"id":"http://arxiv.org/abs/2510.14728v2","updated":"2026-01-07T07:52:30Z","published":"2025-10-16T14:26:27Z","title":"The simultaneous effect of chemotaxis and alarm-taxis on the global existence and stability of a predator-prey system","summary":"This study examines a fully parabolic predator-prey chemo-alarm-taxis system under homogeneous Neumann boundary conditions in a bounded domain $Ω\\subset \\mathbb{R}^n$ with a smooth boundary $\\partialΩ$. Under specific parameter conditions, it is shown that the system admits a unique, globally bounded classical solution. The convergence of the solution is established through the construction of an appropriate Lyapunov functional. In addition, numerical simulations are presented to validate the asymptotic behaviour of the solution. The results highlight the significant role of chemotaxis and alarm-taxis coefficients in determining the existence and stability of predator-prey models, as discussed in the literature.","authors":["Gnanasekaran Shanmugasundaram","Jitraj Saha","Rafael Díaz Fuentes"],"pdf_url":"","comment":null}],"Dynamical Systems":[{"id":"http://arxiv.org/abs/2411.03413v3","updated":"2026-01-07T18:51:45Z","published":"2024-11-05T18:54:39Z","title":"Rapid Mixing at the Uniqueness Threshold","summary":"Over the past decades, a fascinating computational phase transition has been identified in sampling from Gibbs distributions. Though, the computational complexity at the critical point remains poorly understood, as previous algorithmic and hardness results all required a constant slack from this threshold.\n  In this paper, we resolve this open question at the critical phase transition threshold, thus completing the picture of the computational phase transition. We show that for the hardcore model on graphs with maximum degree $Δ\\ge 3$ at the uniqueness threshold $λ= λ_c(Δ)$, the mixing time of Glauber dynamics is upper bounded by a polynomial in $n$, but is not nearly linear in the worst case.\n  For the Ising model (either antiferromagnetic or ferromagnetic), we establish similar results. For the Ising model on graphs with maximum degree $Δ\\ge 3$ at the critical temperature $β$ where $|β| = β_c(Δ)$, with the tree-uniqueness threshold $β_c(Δ)$, we show that the mixing time of Glauber dynamics is upper bounded by $\\tilde{O}\\left(n^{3 + O(1/Δ)}\\right)$ and lower bounded by $Ω\\left(n^{3/2}\\right)$ in the worst case. For the Ising model specified by a critical interaction matrix $J$ with $\\left \\lVert J \\right \\rVert_2=1$, we obtain an upper bound $\\tilde{O}(n^{3/2})$ for the mixing time, matching the lower bound $Ω\\left(n^{3/2}\\right)$ on the complete graph up to a logarithmic factor.\n  Our mixing time upper bounds are derived from a new interpretation and analysis of the localization scheme method introduced by Chen and Eldan (2022), applied to the field dynamics for the hardcore model and the proximal sampler for the Ising model. As key steps in both our upper and lower bounds, we establish sub-linear upper and lower bounds for spectral independence at the critical point for worst-case instances.","authors":["Xiaoyu Chen","Zongchen Chen","Yitong Yin","Xinyuan Zhang"],"pdf_url":"","comment":"Remove the incorrectly claimed square-root spectral independence result for the critical graphical Ising model; see Remark 1.6 for details"},{"id":"http://arxiv.org/abs/2601.04169v1","updated":"2026-01-07T18:36:25Z","published":"2026-01-07T18:36:25Z","title":"A Polynomial Kernel for Face Cover on Non-Embedded Planar Graphs","summary":"Given a planar graph, a subset of its vertices called terminals, and $k \\in \\mathbb{N}$, the Face Cover Number problem asks whether the terminals lie on the boundaries of at most $k$ faces of some embedding of the input graph. When a plane graph is given in the input, the problem is known to have a polynomial kernel~\\cite{GarneroST17}. In this paper, we present the first polynomial kernel for Face Cover Number when the input is a planar graph (without a fixed embedding). Our approach overcomes the challenge of not having a predefined set of face boundaries by building a kernel bottom-up on an SPR-tree while preserving the essential properties of the face cover along the way.","authors":["Thekla Hamm","Sukanya Pandey","Krisztina Szilágyi"],"pdf_url":"","comment":"Accepted to STACS 2026"},{"id":"http://arxiv.org/abs/2601.02347v2","updated":"2026-01-07T15:53:40Z","published":"2026-01-05T18:44:27Z","title":"Solving Matrix Games with Near-Optimal Matvec Complexity","summary":"We study the problem of computing an $ε$-approximate Nash equilibrium of a two-player, bilinear game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(ε^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ (or zero-sum) games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games (encompassing hard-margin SVMs), where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(ε^{-8/9})$ for $\\ell_1$-$\\ell_1$ and $\\tilde{O}(ε^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In both settings our results are nearly-optimal as they match lower bounds of [KS '25] up to polylogarithmic factors.","authors":["Ishani Karmarkar","Liam O'Carroll","Aaron Sidford"],"pdf_url":"","comment":"v2: A few updates to the title, abstract, and intro to reflect the near optimality of our results for $\\ell_1$-$\\ell_1$ games in light of arXiv:2412.06990 v3"},{"id":"http://arxiv.org/abs/2507.17878v3","updated":"2026-01-07T14:47:09Z","published":"2025-07-23T19:11:32Z","title":"Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa","summary":"We introduce a new notion of sparsification, called \\emph{strong sparsification}, in which constraints are not removed but variables can be merged. As our main result, we present a strong sparsification algorithm for 1-in-3-SAT. The correctness of the algorithm relies on establishing a sub-quadratic bound on the size of certain sets of vectors in $\\mathbb{F}_2^d$. This result, obtained using the recent \\emph{Polynomial Freiman-Ruzsa Theorem} (Gowers, Green, Manners and Tao, Ann. Math. 2025), could be of independent interest. As an application, we improve the state-of-the-art algorithm for approximating linearly-ordered colourings of 3-uniform hypergraphs (Håstad, Martinsson, Nakajima and{Ž}ivn{ý}, APPROX 2024).","authors":["Benjamin Bedert","Tamio-Vesa Nakajima","Karolina Okrasa","Stanislav Živný"],"pdf_url":"","comment":"Full version of a FOCS'25 paper; v2 has more results; v3 proves Conjecture 33 from v2, giving a tight bound on strong sparsifiability of 1-in-k-SAT (in possibly exponential time)"},{"id":"http://arxiv.org/abs/2601.03934v1","updated":"2026-01-07T13:52:28Z","published":"2026-01-07T13:52:28Z","title":"Complexity of Perfect and Ideal Resilience Verification in Fast Re-Route Networks","summary":"To achieve fast recovery from link failures, most modern communication networks feature fully decentralized fast re-routing mechanisms. These re-routing mechanisms rely on pre-installed static re-routing rules at the nodes (the routers), which depend only on local failure information, namely on the failed links incident to the node. Ideally, a network is perfectly resilient: the re-routing rules ensure that packets are always successfully routed to their destinations as long as the source and the destination are still physically connected in the underlying network after the failures. Unfortunately, there are examples where achieving perfect resilience is not possible. Surprisingly, only very little is known about the algorithmic aspect of when and how perfect resilience can be achieved.\n  We investigate the computational complexity of analyzing such local fast re-routing mechanisms. Our main result is a negative one: we show that even checking whether a given set of static re-routing rules ensures perfect resilience is coNP-complete. We also show coNP-completeness of the so-called ideal resilience, a weaker notion of resilience often considered in the literature. Additionally, we investigate other fundamental variations of the problem. In particular, we show that our coNP-completeness proof also applies to scenarios where the re-routing rules have specific patterns (known as skipping in the literature).\n  On the positive side, for scenarios where nodes do not have information about the link from which a packet arrived (the so-called in-port), we present linear-time algorithms for both the verification and synthesis problem for perfect resilience.","authors":["Matthias Bentert","Esra Ceylan-Kettler","Valentin Hübner","Stefan Schmid","Jiří Srba"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03897v1","updated":"2026-01-07T13:06:07Z","published":"2026-01-07T13:06:07Z","title":"Implementing Binary Search Trees in GP 2 (Extended Abstract)","summary":"We present an approach to implement binary search trees in the rule-based graph programming language GP 2. Our implementation uses GP 2's rooted graph transformation rules to be fast and supports insertion, deletion and query operations. We argue that the worst-case runtime for each of the operations is O(n) for a tree with n nodes. In addition, we expect that, on average, the operations run in time O(log(n)). Hence the implementation would match the time complexity of binary search trees implementations in imperative languages.","authors":["Ziad Ismaili Alaoui","Detlef Plump"],"pdf_url":"","comment":"In Proceedings GCM 2025, arXiv:2601.03249"},{"id":"http://arxiv.org/abs/2109.02997v5","updated":"2026-01-07T11:49:02Z","published":"2021-09-07T11:17:59Z","title":"Worst-case optimal adaptive alphabetic prefix-free coding","summary":"We give the first algorithm for adaptive alphabetic prefix-free coding that is worst-case optimal in terms of time and compression when $σ\\in o \\left( \\frac{n^{1 / 2}}{\\log n} \\right)$, where $σ$ is the size of the alphabet and $n$ is the length of the input.","authors":["Travis Gagie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.15531v3","updated":"2026-01-07T07:59:36Z","published":"2025-09-19T02:31:17Z","title":"Sparse Neighborhood Graph-Based Approximate Nearest Neighbor Search Revisited: Theoretical Analysis and Optimization","summary":"Graph-based approaches to approximate nearest neighbor search (ANNS) enable fast, high-recall retrieval on billion-scale vector datasets. Among them, the Sparse Neighborhood Graph (SNG) is widely used due to its strong search performance. However, the lack of theoretical understanding of SNG leads to expensive tuning of the truncation parameter that controls graph sparsification. In this work, we present OPT-SNG, a principled framework for analyzing and optimizing SNG construction. We introduce a martingale-based model of the pruning process that characterizes the stochastic evolution of candidate sets during graph construction. Using this framework, we prove that SNG has a maximum out-degree of \\(O(n^{2/3+ε})\\), where \\(ε>0\\) is an arbitrarily small constant, and an expected search path length of \\(O(\\log n)\\). Building on these insights, we derive a closed-form rule for selecting the optimal truncation parameter \\(R\\), thereby eliminating the need for costly parameter sweeping. Extensive experiments on real-world datasets demonstrate that OPT-SNG achieves an average \\(5.9\\times\\) speedup in index construction time, with peak improvements reaching \\(15.4\\times\\), while consistently maintaining or improving search performance.","authors":["Xinran Ma","Zhaoqi Zhou","Chuan Zhou","Zaijiu Shang","Guoliang Li","Zhiming Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.05124v2","updated":"2026-01-07T07:58:46Z","published":"2025-08-07T08:01:59Z","title":"Text Indexing and Pattern Matching with Ephemeral Edits","summary":"A sequence $e_0,e_1,\\ldots$ of edit operations in a string $T$ is called ephemeral if operation $e_i$ constructing string $T^i$, for all $i=2k$ with $k\\in\\mathbb{N}$, is reverted by operation $e_{i+1}$ that reconstructs $T$. Such a sequence arises when processing a stream of independent edits or testing hypothetical edits.\n  We introduce text indexing with ephemeral substring edits, a new version of text indexing. Our goal is to design a data structure over a given text that supports subsequent pattern matching queries with ephemeral substring insertions, deletions, or substitutions in the text; we require insertions and substitutions to be of constant length. In particular, we preprocess a text $T=T[0\\mathinner{.\\,.} n)$ over an integer alphabet $Σ=[0,σ)$ with $σ=n^{\\mathcal{O}(1)}$ in $\\mathcal{O}(n)$ time. Then, we can preprocess any arbitrary pattern $P=P[0\\mathinner{.\\,.} m)$ given online in $\\mathcal{O}(m\\log\\log m)$ time and $\\mathcal{O}(m)$ space and allow any ephemeral sequence of edit operations in $T$. Before reverting the $i$th operation, we report all Occ occurrences of $P$ in $T^i$ in $\\mathcal{O}(\\log\\log n + \\text{Occ})$ time.\n  We also introduce pattern matching with ephemeral edits. In particular, we preprocess two strings $T$ and $P$, each of length at most $n$, over an integer alphabet $Σ=[0,σ)$ with $σ=n^{\\mathcal{O}(1)}$ in $\\mathcal{O}(n)$ time. Then, we allow any ephemeral sequence of edit operations in $T$. Before reverting the $i$th operation, we report all Occ occurrences of $P$ in $T^i$ in the optimal $\\mathcal{O}(\\text{Occ})$ time. Along our way to this result, we also give an optimal solution for pattern matching with ephemeral block deletions.","authors":["Solon P. Pissis"],"pdf_url":"","comment":"SOSA 2026 (abstract abridged to satisfy arXiv requirements)"},{"id":"http://arxiv.org/abs/2601.03643v1","updated":"2026-01-07T06:48:01Z","published":"2026-01-07T06:48:01Z","title":"On $k$-connectivity oracles in $k$-connected graphs","summary":"A $k$-connectivity oracle for a graph $G=(V,E)$ is a data structure that given $s,t \\in V$ determines whether there are at least $k+1$ internally disjoint $st$-paths in $G$. For undirected graphs, Pettie, Saranurak & Yin [STOC 2022, pp. 151-161] proved that any $k$-connectivity oracle requires $Ω(kn)$ bits of space. They asked whether $Ω(kn)$ bits are still necessary if $G$ is $k$-connected. We will show by a very simple proof that this is so even if $G$ is $k$-connected, answering this open question.","authors":["Zeev Nutov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.07515v2","updated":"2026-01-07T05:48:49Z","published":"2025-05-12T12:52:59Z","title":"Improved Mixing of Critical Hardcore Model","summary":"The hardcore model is one of the most classic and widely studied examples of undirected graphical models. Given a graph $G$, the hardcore model describes a Gibbs distribution of $λ$-weighted independent sets of $G$. In the last two decades, a beautiful computational phase transition has been established at a precise threshold $λ_c(Δ)$ where $Δ$ denotes the maximum degree, where the task of sampling independent sets transitions from polynomial-time solvable to computationally intractable. We study the critical hardcore model where $λ= λ_c(Δ)$ and show that the Glauber dynamics, a simple yet popular Markov chain algorithm, mixes in $\\tilde{O}(n^{4+O(1/Δ)})$ time on any $n$-vertex graph of maximum degree $Δ\\geq3$, significantly improving the previous upper bound $\\tilde{O}(n^{12.88+O(1/Δ)})$ by the recent work arXiv:2411.03413. Our improvement comes from an optimal bound on the $\\ell_\\infty$-spectral independence for the hardcore model at all subcritical fugacity $λ< λ_c(Δ)$.","authors":["Zongchen Chen","Tianhui Jiang"],"pdf_url":"","comment":"16 pages, addressed an error in the previous version involving $\\ell_\\infty$-spectral independence; see Remark 1.2 for details"},{"id":"http://arxiv.org/abs/2601.03573v1","updated":"2026-01-07T04:35:49Z","published":"2026-01-07T04:35:49Z","title":"Counting hypertriangles through hypergraph orientations","summary":"Counting the number of small patterns is a central task in network analysis. While this problem is well studied for graphs, many real-world datasets are naturally modeled as hypergraphs, motivating the need for efficient hypergraph motif counting algorithms. In particular, we study the problem of counting hypertriangles - collections of three pairwise-intersecting hyperedges. These hypergraph patterns have a rich structure with multiple distinct intersection patterns unlike graph triangles.\n  Inspired by classical graph algorithms based on orientations and degeneracy, we develop a theoretical framework that generalizes these concepts to hypergraphs and yields provable algorithms for hypertriangle counting. We implement these ideas in DITCH (Degeneracy Inspired Triangle Counter for Hypergraphs) and show experimentally that it is 10-100x faster and more memory efficient than existing state-of-the-art methods.","authors":["Daniel Paul-Pena","Vaishali Surianarayanan","Deeparnab Chakrabarty","C. Seshadhri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03533v1","updated":"2026-01-07T02:45:37Z","published":"2026-01-07T02:45:37Z","title":"Online Learning with Limited Information in the Sliding Window Model","summary":"Motivated by recent work on the experts problem in the streaming model, we consider the experts problem in the sliding window model. The sliding window model is a well-studied model that captures applications such as traffic monitoring, epidemic tracking, and automated trading, where recent information is more valuable than older data. Formally, we have $n$ experts, $T$ days, the ability to query the predictions of $q$ experts on each day, a limited amount of memory, and should achieve the (near-)optimal regret $\\sqrt{nW}\\text{polylog}(nT)$ regret over any window of the last $W$ days. While it is impossible to achieve such regret with $1$ query, we show that with $2$ queries we can achieve such regret and with only $\\text{polylog}(nT)$ bits of memory. Not only are our algorithms optimal for sliding windows, but we also show for every interval $\\mathcal{I}$ of days that we achieve $\\sqrt{n|\\mathcal{I}|}\\text{polylog}(nT)$ regret with $2$ queries and only $\\text{polylog}(nT)$ bits of memory, providing an exponential improvement on the memory of previous interval regret algorithms. Building upon these techniques, we address the bandit problem in data streams, where $q=1$, achieving $n T^{2/3}\\text{polylog}(T)$ regret with $\\text{polylog}(nT)$ memory, which is the first sublinear regret in the streaming model in the bandit setting with polylogarithmic memory; this can be further improved to the optimal $\\mathcal{O}(\\sqrt{nT})$ regret if the best expert's losses are in a random order.","authors":["Vladimir Braverman","Sumegha Garg","Chen Wang","David P. Woodruff","Samson Zhou"],"pdf_url":"","comment":"SODA 2026"},{"id":"http://arxiv.org/abs/2601.03523v1","updated":"2026-01-07T02:20:41Z","published":"2026-01-07T02:20:41Z","title":"Variance Computation for Weighted Model Counting with Knowledge Compilation Approach","summary":"One of the most important queries in knowledge compilation is weighted model counting (WMC), which has been applied to probabilistic inference on various models, such as Bayesian networks. In practical situations on inference tasks, the model's parameters have uncertainty because they are often learned from data, and thus we want to compute the degree of uncertainty in the inference outcome. One possible approach is to regard the inference outcome as a random variable by introducing distributions for the parameters and evaluate the variance of the outcome. Unfortunately, the tractability of computing such a variance is hardly known. Motivated by this, we consider the problem of computing the variance of WMC and investigate this problem's tractability. First, we derive a polynomial time algorithm to evaluate the WMC variance when the input is given as a structured d-DNNF. Second, we prove the hardness of this problem for structured DNNFs, d-DNNFs, and FBDDs, which is intriguing because the latter two allow polynomial time WMC algorithms. Finally, we show an application that measures the uncertainty in the inference of Bayesian networks. We empirically show that our algorithm can evaluate the variance of the marginal probability on real-world Bayesian networks and analyze the impact of the variances of parameters on the variance of the marginal.","authors":["Kengo Nakamura","Masaaki Nishino","Norihito Yasuda"],"pdf_url":"","comment":"25 pages; accepted for AAAI 2026 main track"},{"id":"http://arxiv.org/abs/2509.14144v3","updated":"2026-01-07T23:20:09Z","published":"2025-09-17T16:25:09Z","title":"Algorithms for Optimizing Acyclic Queries","summary":"Most research on query optimization has centered on binary join algorithms like hash join and sort-merge join. However, recent years have seen growing interest in theoretically optimal algorithms, notably Yannakakis' algorithm. These algorithms rely on join trees, which differ from the operator trees for binary joins and require new optimization techniques. We propose three approaches to constructing join trees for acyclic queries. First, we give an algorithm to enumerate all join trees of an alpha-acyclic query by edits with amortized constant delay, which forms the basis of a cost-based optimizer for acyclic joins. Second, we show that the Maximum Cardinality Search algorithm by Tarjan and Yannakakis constructs a unique shallowest join tree, rooted at any relation, for a Berge-acyclic query; this tree enables parallel execution of large join queries. Finally, we prove that any connected left-deep linear plan for a gamma-acyclic query can be converted into a join tree by a simple algorithm, allowing reuse of optimization infrastructure developed for binary joins.","authors":["Zheng Luo","Wim Van den Broeck","Guy Van den Broeck","Yisu Remy Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04423v1","updated":"2026-01-07T22:07:44Z","published":"2026-01-07T22:07:44Z","title":"Learning Multinomial Logits in $O(n \\log n)$ time","summary":"A Multinomial Logit (MNL) model is composed of a finite universe of items $[n]=\\{1,..., n\\}$, each assigned a positive weight. A query specifies an admissible subset -- called a slate -- and the model chooses one item from that slate with probability proportional to its weight. This query model is also known as the Plackett-Luce model or conditional sampling oracle in the literature. Although MNLs have been studied extensively, a basic computational question remains open: given query access to slates, how efficiently can we learn weights so that, for every slate, the induced choice distribution is within total variation distance $\\varepsilon$ of the ground truth? This question is central to MNL learning and has direct implications for modern recommender system interfaces.\n  We provide two algorithms for this task, one with adaptive queries and one with non-adaptive queries. Each algorithm outputs an MNL $M'$ that induces, for each slate $S$, a distribution $M'_S$ on $S$ that is within $\\varepsilon$ total variation distance of the true distribution. Our adaptive algorithm makes $O\\left(\\frac{n}{\\varepsilon^{3}}\\log n\\right)$ queries, while our non-adaptive algorithm makes $O\\left(\\frac{n^{2}}{\\varepsilon^{3}}\\log n \\log\\frac{n}{\\varepsilon}\\right)$ queries. Both algorithms query only slates of size two and run in time proportional to their query complexity.\n  We complement these upper bounds with lower bounds of $Ω\\left(\\frac{n}{\\varepsilon^{2}}\\log n\\right)$ for adaptive queries and $Ω\\left(\\frac{n^{2}}{\\varepsilon^{2}}\\log n\\right)$ for non-adaptive queries, thus proving that our adaptive algorithm is optimal in its dependence on the support size $n$, while the non-adaptive one is tight within a $\\log n$ factor.","authors":["Flavio Chierichetti","Mirko Giacchini","Ravi Kumar","Silvio Lattanzi","Alessandro Panconesi","Erasmo Tani","Andrew Tomkins"],"pdf_url":"","comment":null}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2508.15008v4","updated":"2026-01-07T11:09:58Z","published":"2025-08-20T18:56:26Z","title":"Neural Network Quantization for Microcontrollers: A Comprehensive Survey of Methods, Platforms, and Applications","summary":"The deployment of Quantized Neural Networks (QNNs) on resource-constrained edge devices, such as microcontrollers (MCUs), introduces fundamental challenges in balancing model performance, computational complexity, and memory constraints. Tiny Machine Learning (TinyML) addresses these issues by jointly advancing machine learning algorithms, hardware architectures, and software optimization techniques to enable deep neural network inference on embedded systems. This survey provides a hardware-oriented perspective on neural network quantization, systematically reviewing the quantization methods most relevant to MCUs and extreme-edge devices. Particular emphasis is placed on the critical trade-offs between model performance and the capabilities of MCU-class hardware, including memory hierarchies, numerical representations, and accelerator support. The survey further reviews contemporary MCU hardware platforms, including ARM-based and RISC-V-based designs, as well as MCUs integrating neural processing units (NPUs) for low-precision inference, together with the supporting software stacks. In addition, we analyze real-world deployments of quantized models on MCUs and consolidate the application domains in which such systems are used. Finally, we discuss open challenges and outline promising future directions toward scalable, energy-efficient, and sustainable AI deployment on edge devices.","authors":["Hamza A. Abushahla","Dara Varam","Ariel Justine N. Panopio","Mohamed I. AlHajri"],"pdf_url":"","comment":"40 pages, 16 figures, 8 Tables"},{"id":"http://arxiv.org/abs/2507.13375v2","updated":"2026-01-07T10:44:49Z","published":"2025-07-13T02:43:44Z","title":"GAP-LA: GPU-Accelerated Performance-Driven Layer Assignment","summary":"Layer assignment is critical for global routing of VLSI circuits. It converts 2D routing paths into 3D routing solutions by determining the proper metal layer for each routing segments to minimize congestion and via count. As different layers have different unit resistance and capacitance, layer assignment also has significant impacts to timing and power. With growing design complexity, it becomes increasingly challenging to simultaneously optimize timing, power, and congestion efficiently. Existing studies are mostly limited to a subset of objectives. In this paper, we propose a GPU-accelerated performance-driven layer assignment framework, GAP-LA, for holistic optimization the aforementioned objectives. Experimental results demonstrate that we can achieve 0.3%-9.9% better worst negative slack (WNS) and 2.0%-5.4% better total negative slack (TNS) while maintaining power and congestion with competitive runtime compared with ISPD 2025 contest winners, especially on designs with up to 12 millions of nets.","authors":["Chunyuan Zhao","Zizheng Guo","Zuodong Zhang","Yibo Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.04301v2","updated":"2026-01-07T00:48:17Z","published":"2025-06-04T14:37:54Z","title":"The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective","summary":"Large-language-model (LLM)-based AI agents have recently showcased impressive versatility by employing dynamic reasoning, an adaptive, multi-step process that coordinates with external tools. This shift from static, single-turn inference to agentic, multi-turn workflows broadens task generalization and behavioral flexibility, but it also introduces serious concerns about system-level cost, efficiency, and sustainability. This paper presents the first comprehensive system-level analysis of AI agents, quantifying their resource usage, latency behavior, energy consumption, and datacenter-wide power consumption demands across diverse agent designs and test-time scaling strategies. We further characterize how AI agent design choices, such as few-shot prompting, reflection depth, and parallel reasoning, impact accuracy-cost tradeoffs. Our findings reveal that while agents improve accuracy with increased compute, they suffer from rapidly diminishing returns, widening latency variance, and unsustainable infrastructure costs. Through detailed evaluation of representative agents, we highlight the profound computational demands introduced by AI agent workflows, uncovering a looming sustainability crisis. These results call for a paradigm shift in agent design toward compute-efficient reasoning, balancing performance with deployability under real-world constraints.","authors":["Jiin Kim","Byeongjun Shin","Jinha Chung","Minsoo Rhu"],"pdf_url":"","comment":"Accepted for publication at the 32nd IEEE International Symposium on High-Performance Computer Architecture (HPCA-32), 2026"},{"id":"http://arxiv.org/abs/2601.04358v1","updated":"2026-01-07T19:49:44Z","published":"2026-01-07T19:49:44Z","title":"Energy-Time-Accuracy Tradeoffs in Thermodynamic Computing","summary":"In the paradigm of thermodynamic computing, instead of behaving deterministically, hardware undergoes a stochastic process in order to sample from a distribution of interest. While it has been hypothesized that thermodynamic computers may achieve better energy efficiency and performance, a theoretical characterization of the resource cost of thermodynamic computations is still lacking. Here, we analyze the fundamental trade-offs between computational accuracy, energy dissipation, and time in thermodynamic computing. Using geometric bounds on entropy production, we derive general limits on the energy-delay-deficiency product (EDDP), a stochastic generalization of the traditional energy-delay product (EDP). While these limits can in principle be saturated, the corresponding optimal driving protocols require full knowledge of the final equilibrium distribution, i.e., the solution itself. To overcome this limitation, we develop quasi-optimal control schemes that require no prior information of the solution and demonstrate their performance for matrix inversion in overdamped quadratic systems. The derived bounds extend beyond this setting to more general potentials, being directly relevant to recent proposals based on non-equilibrium Langevin dynamics.","authors":["Alberto Rolandi","Paolo Abiuso","Patryk Lipka-Bartosik","Maxwell Aifer","Patrick J. Coles","Martí Perarnau-Llobet"],"pdf_url":"","comment":"10 pages (+ 6 pages of appendix), 7 figures"}],"Computational Finance":[{"id":"http://arxiv.org/abs/2601.04160v1","updated":"2026-01-07T18:18:28Z","published":"2026-01-07T18:18:28Z","title":"All That Glisters Is Not Gold: A Benchmark for Reference-Free Counterfactual Financial Misinformation Detection","summary":"We introduce RFC Bench, a benchmark for evaluating large language models on financial misinformation under realistic news. RFC Bench operates at the paragraph level and captures the contextual complexity of financial news where meaning emerges from dispersed cues. The benchmark defines two complementary tasks: reference free misinformation detection and comparison based diagnosis using paired original perturbed inputs. Experiments reveal a consistent pattern: performance is substantially stronger when comparative context is available, while reference free settings expose significant weaknesses, including unstable predictions and elevated invalid outputs. These results indicate that current models struggle to maintain coherent belief states without external grounding. By highlighting this gap, RFC Bench provides a structured testbed for studying reference free reasoning and advancing more reliable financial misinformation detection in real world settings.","authors":["Yuechen Jiang","Zhiwei Liu","Yupeng Cao","Yueru He","Ziyang Xu","Chen Xu","Zhiyang Deng","Prayag Tiwari","Xi Chen","Alejandro Lopez-Lira","Jimin Huang","Junichi Tsujii","Sophia Ananiadou"],"pdf_url":"","comment":"39 pages; 24 figures"},{"id":"http://arxiv.org/abs/2601.04049v1","updated":"2026-01-07T16:07:19Z","published":"2026-01-07T16:07:19Z","title":"Quantum computing for multidimensional option pricing: End-to-end pipeline","summary":"This work introduces an end-to-end framework for multi-asset option pricing that combines market-consistent risk-neutral density recovery with quantum-accelerated numerical integration. We first calibrate arbitrage-free marginal distributions from European option quotes using the Normal Inverse Gaussian (NIG) model, leveraging its analytical tractability and ability to capture skewness and fat tails. Marginals are coupled via a Gaussian copula to construct joint distributions. To address the computational bottleneck of the high-dimensional integration required to solve the option pricing formula, we employ Quantum Accelerated Monte Carlo (QAMC) techniques based on Quantum Amplitude Estimation (QAE), achieving quadratic convergence improvements over classical Monte Carlo (CMC) methods. Theoretical results establish accuracy bounds and query complexity for both marginal density estimation (via cosine-series expansions) and multidimensional pricing. Empirical tests on liquid equity entities (Credit Agricole, AXA, Michelin) confirm high calibration accuracy and demonstrate that QAMC requires 10-100 times fewer queries than classical methods for comparable precision. This study provides a practical route to integrate arbitrage-aware modelling with quantum computing, highlighting implications for scalability and future extensions to complex derivatives.","authors":["Julien Hok","Álvaro Leitao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18648v2","updated":"2026-01-07T07:58:57Z","published":"2025-12-21T08:50:11Z","title":"Optimal Signal Extraction from Order Flow: A Matched Filter Perspective on Normalization and Market Microstructure","summary":"We demonstrate that the choice of normalization for order flow intensity is fundamental to signal extraction in finance, not merely a technical detail. Through theoretical modeling, Monte Carlo simulation, and empirical validation using Korean market data, we prove that market capitalization normalization acts as a ``matched filter'' for informed trading signals, achieving 1.32--1.97$\\times$ higher correlation with future returns compared to traditional trading value normalization. The key insight is that informed traders scale positions by firm value (market capitalization), while noise traders respond to daily liquidity (trading volume), creating heteroskedastic corruption when normalizing by trading volume. By reframing the normalization problem using signal processing theory, we show that dividing order flow by market capitalization preserves the information signal while traditional volume normalization multiplies the signal by inverse turnover -- a highly volatile quantity. Our theoretical predictions are robust across parameter specifications and validated by empirical evidence showing 482\\% improvement in explanatory power. These findings have immediate implications for high-frequency trading algorithms, risk factor construction, and information-based trading strategies.","authors":["Sungwoo Kang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.13529v3","updated":"2026-01-07T19:25:50Z","published":"2025-04-18T07:40:24Z","title":"Improving Bayesian Optimization for Portfolio Management with an Adaptive Scheduling","summary":"Existing black-box portfolio management systems are prevalent in the financial industry due to commercial and safety constraints, though their performance can fluctuate dramatically with changing market regimes. Evaluating these non-transparent systems is computationally expensive, as fixed budgets limit the number of possible observations. Therefore, achieving stable and sample-efficient optimization for these systems has become a critical challenge. This work presents a novel Bayesian optimization framework (TPE-AS) that improves search stability and efficiency for black-box portfolio models under these limited observation budgets. Standard Bayesian optimization, which solely maximizes expected return, can yield erratic search trajectories and misalign the surrogate model with the true objective, thereby wasting the limited evaluation budget. To mitigate these issues, we propose a weighted Lagrangian estimator that leverages an adaptive schedule and importance sampling. This estimator dynamically balances exploration and exploitation by incorporating both the maximization of model performance and the minimization of the variance of model observations. It guides the search from broad, performance-seeking exploration towards stable and desirable regions as the optimization progresses. Extensive experiments and ablation studies, which establish our proposed method as the primary approach and other configurations as baselines, demonstrate its effectiveness across four backtest settings with three distinct black-box portfolio management models.","authors":["Zinuo You","John Cartlidge","Karen Elliott","Menghan Ge","Daniel Gold"],"pdf_url":"","comment":"5 pages, 2 figures; version of record. ICAAI 2025, 9th International Conference on Advances in Artificial Intelligence (ICAAI 2025), November 14-16, 2025, Manchester, United Kingdom. ACM, New York, NY, USA, 5 pages"}],"Mathematical Finance":[{"id":"http://arxiv.org/abs/2601.04096v1","updated":"2026-01-07T17:02:12Z","published":"2026-01-07T17:02:12Z","title":"Sharp Transitions and Systemic Risk in Sparse Financial Networks","summary":"We study contagion and systemic risk in sparse financial networks with balance-sheet interactions on a directed random graph. Each institution has homogeneous liabilities and equity, and exposures along outgoing edges are split equally across counterparties. A linear fraction of institutions have zero out-degree in sparse digraphs; we adopt an external-liability convention that makes the exposure mapping well-defined without altering propagation. We isolate a single-hit transmission mechanism and encode it by a sender-truncated subgraph G_sh. We define adversarial and random systemic events with shock size k_n = c log n and systemic fraction epsilon n. In the subcritical regime rho_out < 1, we prove that maximal forward reachability in G_sh is O(log n) with high probability, yielding O((log n)^2) cascades from shocks of size k_n. For random shocks, we give an explicit fan-in accumulation bound, showing that multi-hit defaults are negligible with high probability when the explored default set is polylogarithmic. In the supercritical regime, we give an exact distributional representation of G_sh as an i.i.d.-outdegree random digraph with uniform destinations, placing it within the scope of the strong-giant/bow-tie theorem of Penrose (2014). We derive the resulting implication for random-shock systemic events. Finally, we explain why sharp-threshold machinery does not directly apply: systemic-event properties need not be monotone in the edge set because adding outgoing edges reduces per-edge exposure.","authors":["Riley James Bendel"],"pdf_url":"","comment":"15 pages, 0 figures"},{"id":"http://arxiv.org/abs/2601.04067v1","updated":"2026-01-07T16:30:54Z","published":"2026-01-07T16:30:54Z","title":"Diversification Preferences and Risk Attitudes","summary":"Portfolio diversification is a cornerstone of modern finance, while risk aversion is central to decision theory; both concepts are long-standing and foundational. We investigate their connections by studying how different forms of diversification correspond to notions of risk aversion. We focus on the classical distinctions between weak and strong risk aversion, and consider diversification preferences for pairs of risks that are identically distributed, comonotonic, antimonotonic, independent, or exchangeable, as well as their intersections. Under a weak continuity condition and without assuming completeness of preferences, diversification for antimonotonic and identically distributed pairs implies weak risk aversion, and diversification for exchangeable pairs is equivalent to strong risk aversion. The implication from diversification for independent pairs to weak risk aversion requires a stronger continuity. We further provide results and examples that clarify the relationships between various diversification preferences and risk attitudes, in particular justifying the one-directional nature of many implications.","authors":["Xiangxin He","Fangda Liu","Ruodu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03799v1","updated":"2026-01-07T10:56:22Z","published":"2026-01-07T10:56:22Z","title":"Optimal execution on Uniswap v2/v3 under transient price impact","summary":"We study the optimal liquidation of a large position on Uniswap v2 and Uniswap v3 in discrete time. The instantaneous price impact is derived from the AMM pricing rule. Transient impact is modeled to capture either exponential or approximately power-law decay, together with a permanent component. In the Uniswap v2 setting, we obtain optimal strategies in closed-form under general price dynamics. For Uniswap v3, we consider a two-layer liquidity framework, which naturally extends to multiple layers. We address the problem using dynamic programming under geometric Brownian motion dynamics and approximate the solution numerically using a discretization scheme. We obtain optimal strategies akin to classical ones in the LOB literature, with features specific to Uniswap. In particular, we show how the liquidity profile influences them.","authors":["Bastien Baude","Damien Challet","Ioane Muni Toke"],"pdf_url":"","comment":"30 pages, 20 figures, 1 table"},{"id":"http://arxiv.org/abs/2312.01668v2","updated":"2026-01-07T05:37:34Z","published":"2023-12-04T06:36:27Z","title":"Optimal dividend payout with path-dependent drawdown constraint","summary":"This paper studies an optimal dividend problem with a drawdown constraint in a Brownian motion model, requiring the dividend payout rate to remain above a fixed proportion of its historical maximum. This leads to a path-dependent stochastic control problem, as the admissible control depends on its own past values. The associated Hamilton-Jacobi-Bellman (HJB) equation is a novel two-dimensional variational inequality with a gradient constraint, a type of problem previously only analyzed in the literature using viscosity solution techniques. In contrast, this paper employs delicate PDE methods to establish the existence of a strong solution. This stronger regularity allows us to explicitly characterize an optimal feedback control strategy, expressed in terms of two free boundaries and the running maximum surplus process. Furthermore, we derive key properties of the value function and the free boundaries, including boundedness and continuity. Numerical examples are provided to verify the theoretical results and to offer new financial insights.","authors":["Chonghu Guan","Jiacheng Fan","Zuo Quan Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23139v4","updated":"2026-01-07T02:15:01Z","published":"2025-12-29T02:00:35Z","title":"Lambda Expected Shortfall","summary":"The Lambda Value-at-Risk (Lambda-VaR) is a generalization of the Value-at-Risk (VaR), which has been actively studied in quantitative finance. Over the past two decades, the Expected Shortfall (ES) has become one of the most important risk measures alongside VaR because of its various desirable properties in the practice of optimization, risk management, and financial regulation. Analogously to the intimate relation between ES and VaR, we introduce the Lambda Expected Shortfall (Lambda-ES), as a generalization of ES and a counterpart to Lambda-VaR. Our definition of Lambda-ES has an explicit formula and many convenient properties, and we show that it is the smallest quasi-convex and law-invariant risk measure dominating Lambda-VaR under mild assumptions. We examine further properties of Lambda-ES, its dual representation, and related optimization problems.","authors":["Fabio Bellini","Muqiao Huang","Qiuqi Wang","Ruodu Wang"],"pdf_url":"","comment":null}],"Portfolio Management":[{"id":"http://arxiv.org/abs/2601.04062v1","updated":"2026-01-07T16:28:30Z","published":"2026-01-07T16:28:30Z","title":"Smart Predict--then--Optimize Paradigm for Portfolio Optimization in Real Markets","summary":"Improvements in return forecast accuracy do not always lead to proportional improvements in portfolio decision quality, especially under realistic trading frictions and constraints. This paper adopts the Smart Predict--then--Optimize (SPO) paradigm for portfolio optimization in real markets, which explicitly aligns the learning objective with downstream portfolio decision quality rather than pointwise prediction accuracy. Within this paradigm, predictive models are trained using an SPO-based surrogate loss that directly reflects the performance of the resulting investment decisions. To preserve interpretability and robustness, we employ linear predictors built on return-based and technical-indicator features and integrate them with portfolio optimization models that incorporate transaction costs, turnover control, and regularization. We evaluate the proposed approach on U.S. ETF data (2015--2025) using a rolling-window backtest with monthly rebalancing. Empirical results show that decision-focused training consistently improves risk-adjusted performance over predict--then--optimize baselines and classical optimization benchmarks, and yields strong robustness during adverse market regimes (e.g., the 2020 COVID-19). These findings highlight the practical value of the Smart Predict--then--Optimize paradigm for portfolio optimization in realistic and non-stationary financial environments.","authors":["Wang Yi","Takashi Hasuike"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03974v1","updated":"2026-01-07T14:41:51Z","published":"2026-01-07T14:41:51Z","title":"Class of topological portfolios: Are they better than classical portfolios?","summary":"Topological Data Analysis (TDA), an emerging field in investment sciences, harnesses mathematical methods to extract data features based on shape, offering a promising alternative to classical portfolio selection methodologies. We utilize persistence landscapes, a type of summary statistics for persistent homology, to capture the topological variation of returns, blossoming a novel concept of ``Topological Risk\". Our proposed topological risk then quantifies portfolio risk by tracking time-varying topological properties of assets through the $L_p$ norm of the persistence landscape. Through optimization, we derive an optimal portfolio that minimizes this topological risk. Numerical experiments conducted using nearly a decade long S\\&P 500 data demonstrate the superior performance of our TDA-based portfolios in comparison to the seven popular portfolio optimization models and two benchmark portfolio strategies, the naive $1/N$ portfolio and the S\\&P 500 market index, in terms of excess mean return, and several financial ratios. The outcome remains consistent through out the computational analysis conducted for the varying size of holding and investment time horizon. These results underscore the potential of our TDA-based topological risk metric in providing a more comprehensive understanding of portfolio dynamics than traditional statistical measures. As such, it holds significant relevance for modern portfolio management practices.","authors":["Anubha Goel","Amita Sharma","Juho Kanniainen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03927v1","updated":"2026-01-07T13:47:55Z","published":"2026-01-07T13:47:55Z","title":"A comprehensive review and analysis of different modeling approaches for financial index tracking problem","summary":"Index tracking, also known as passive investing, has gained significant traction in financial markets due to its cost-effective and efficient approach to replicating the performance of a specific market index. This review paper provides a comprehensive overview of the various modeling approaches and strategies developed for index tracking, highlighting the strengths and limitations of each approach. We categorize the index tracking models into three broad frameworks: optimization-based models, statistical-based models and machine learning based data-driven approach. A comprehensive empirical study conducted on the S\\&P 500 dataset demonstrates that the tracking error volatility model under the optimization-based framework delivers the most precise index tracking, the convex co-integration model, under the statistical-based framework achieves the strongest return-risk balance, and the deep neural network with fixed noise model within the data-driven framework provides a competitive performance with notably low turnover and high computational efficiency. By combining a critical review of the existing literature with comparative empirical analysis, this paper aims to provide insights into the evolving landscape of index tracking and its practical implications for investors and fund managers.","authors":["Vrinda Dhingra","Amita Sharma","Anubha Goel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2312.01668v2","updated":"2026-01-07T05:37:34Z","published":"2023-12-04T06:36:27Z","title":"Optimal dividend payout with path-dependent drawdown constraint","summary":"This paper studies an optimal dividend problem with a drawdown constraint in a Brownian motion model, requiring the dividend payout rate to remain above a fixed proportion of its historical maximum. This leads to a path-dependent stochastic control problem, as the admissible control depends on its own past values. The associated Hamilton-Jacobi-Bellman (HJB) equation is a novel two-dimensional variational inequality with a gradient constraint, a type of problem previously only analyzed in the literature using viscosity solution techniques. In contrast, this paper employs delicate PDE methods to establish the existence of a strong solution. This stronger regularity allows us to explicitly characterize an optimal feedback control strategy, expressed in terms of two free boundaries and the running maximum surplus process. Furthermore, we derive key properties of the value function and the free boundaries, including boundedness and continuity. Numerical examples are provided to verify the theoretical results and to offer new financial insights.","authors":["Chonghu Guan","Jiacheng Fan","Zuo Quan Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.13529v3","updated":"2026-01-07T19:25:50Z","published":"2025-04-18T07:40:24Z","title":"Improving Bayesian Optimization for Portfolio Management with an Adaptive Scheduling","summary":"Existing black-box portfolio management systems are prevalent in the financial industry due to commercial and safety constraints, though their performance can fluctuate dramatically with changing market regimes. Evaluating these non-transparent systems is computationally expensive, as fixed budgets limit the number of possible observations. Therefore, achieving stable and sample-efficient optimization for these systems has become a critical challenge. This work presents a novel Bayesian optimization framework (TPE-AS) that improves search stability and efficiency for black-box portfolio models under these limited observation budgets. Standard Bayesian optimization, which solely maximizes expected return, can yield erratic search trajectories and misalign the surrogate model with the true objective, thereby wasting the limited evaluation budget. To mitigate these issues, we propose a weighted Lagrangian estimator that leverages an adaptive schedule and importance sampling. This estimator dynamically balances exploration and exploitation by incorporating both the maximization of model performance and the minimization of the variance of model observations. It guides the search from broad, performance-seeking exploration towards stable and desirable regions as the optimization progresses. Extensive experiments and ablation studies, which establish our proposed method as the primary approach and other configurations as baselines, demonstrate its effectiveness across four backtest settings with three distinct black-box portfolio management models.","authors":["Zinuo You","John Cartlidge","Karen Elliott","Menghan Ge","Daniel Gold"],"pdf_url":"","comment":"5 pages, 2 figures; version of record. ICAAI 2025, 9th International Conference on Advances in Artificial Intelligence (ICAAI 2025), November 14-16, 2025, Manchester, United Kingdom. ACM, New York, NY, USA, 5 pages"}]},"2026-01-06T00:00:00Z":{"Optimization and Control":[{"id":"http://arxiv.org/abs/2503.22928v2","updated":"2026-01-06T23:08:19Z","published":"2025-03-29T01:21:16Z","title":"Optimal Control of an Epidemic with Intervention Design","summary":"This paper investigates the optimal control of an epidemic governed by a SEIR model with operational delays in vaccination and non pharmaceutical interventions. We address the mathematical challenge of imposing hard healthcare capacity constraints (e.g., ICU limits) over an infinite time horizon. To rigorously bridge the gap between theoretical constraints and numerical tractability, we employ a variational framework based on Moreau--Yosida regularization and establish the connection between finite- and infinite-horizon solutions via $Γ$-convergence. The necessary conditions for optimality are derived using the Pontryagin Maximum Principle, allowing for the characterization of singular regimes where the optimal strategy maintains the infection level precisely at the capacity boundary. Numerical simulations illustrate these theoretical findings, quantifying the shadow prices of infection and costs associated with intervention delays.","authors":["Behrooz Moosavi Ramezanzadeh"],"pdf_url":"","comment":"For code and computational details in Python, please refer to \\url{https://github.com/BehroozMoosavi/Codes/blob/main/Epidemic\\%20With\\%20Intervention/Epidemic.ipynb}"},{"id":"http://arxiv.org/abs/2601.01306v2","updated":"2026-01-06T22:53:02Z","published":"2026-01-04T00:04:05Z","title":"Towards a Principled Muon under $μ\\mathsf{P}$: Ensuring Spectral Conditions throughout Training","summary":"The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.","authors":["John Zhao"],"pdf_url":"","comment":"21 pages, 0 figures"},{"id":"http://arxiv.org/abs/2601.03445v1","updated":"2026-01-06T22:14:48Z","published":"2026-01-06T22:14:48Z","title":"Policy Synthesis for Interval MDPs via Polyhedral Lyapunov Functions","summary":"Decision-making under uncertainty is central to many safety-critical applications, where decisions must be guided by probabilistic modeling formalisms. This paper introduces a novel approach to policy synthesis in multi-objective interval Markov decision processes using polyhedral Lyapunov functions. Unlike previous Lyapunov-based methods that mainly rely on quadratic functions, our method utilizes polyhedral functions to enhance accuracy in managing uncertainties within value iteration of dynamic programming. We reformulate the value iteration algorithm as a switched affine system with interval uncertainties and apply control-theoretic stability principles to synthesize policies that guide the system toward a desired target set. By constructing an invariant set of attraction, we ensure that the synthesized policies provide convergence guarantees while minimizing the impact of transition uncertainty in the underlying model. Our methodology removes the need for computationally intensive Pareto curve computations by directly determining a policy that brings objectives within a specified range of their target values. We validate our approach through numerical case studies, including a recycling robot and an electric vehicle battery, demonstrating its effectiveness in achieving policy synthesis under uncertainty.","authors":["Negar Monir","Sadegh Soudjani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.07390v2","updated":"2026-01-06T20:06:48Z","published":"2025-02-11T09:19:44Z","title":"Nonlinear Open-Loop Mean field Stackelberg Stochastic Differential Game","summary":"This paper studies a nonlinear open-loop mean field Stackelberg stochastic differential game by using the probabilistic method through the FBSDE system and the idea of taking control as the fixed point. We successively construct the decentralized optimal control problems for the followers and the leader, among which the leader's decentralized optimal control problem is a partial information optimal control problem with the fully coupled conditional mean-field forward-backward stochastic differential equation (FBSDE, in short) as the state equation. We successively derive the maximum principles for the corresponding decentralized optimal control problems of the followers and the leader. To obtain the existence, uniqueness and estimations of solutions of the state equation, the variational equation and the adjoint equation for the leader's decentralized optimal control problem, we study the well-posedness of a new form of conditional mean-field FBSDE. And the decentralized optimal controls of the leader and followers are proved to be the approximate Stackelberg equilibrium of the nonlinear mean field Stackelberg game. Finally, we apply the theoretical results developed in this paper to solve a nonlinear mean field Stackelberg game problem between a robot control center and unicycle-type swarm robots.","authors":["Jianhui Huang","Qi Huang"],"pdf_url":"","comment":"Based on the original manuscript, we have added a new Section 7, in which the theoretical results developed in this paper are applied to study a nonlinear mean field Stackelberg game problem between a robot control center and unicycle-type swarm robots. In addition, minor revisions have been made to other parts of the paper"},{"id":"http://arxiv.org/abs/2601.03247v1","updated":"2026-01-06T18:43:49Z","published":"2026-01-06T18:43:49Z","title":"Nonlinear Spectral Modeling and Control of Soft-Robotic Muscles from Data","summary":"Artificial muscles are essential for compliant musculoskeletal robotics but complicate control due to nonlinear multiphysics dynamics. Hydraulically amplified electrostatic (HASEL) actuators, a class of soft artificial muscles, offer high performance but exhibit memory effects and hysteresis. Here we present a data-driven reduction and control strategy grounded in spectral submanifold (SSM) theory. In the adiabatic regime, where inputs vary slowly relative to intrinsic transients, trajectories rapidly converge to a low-dimensional slow manifold. We learn an explicit input-to-output map on this manifold from forced-response trajectories alone, avoiding decay experiments that can trigger hysteresis. We deploy the SSM-based model for real-time control of an antagonistic HASEL-clutch joint. This approach yields a substantial reduction in tracking error compared to feedback-only and feedforward-only baselines under identical settings. This record-and-control workflow enables rapid characterization and high-performance control of soft muscles and muscle-driven joints without detailed physics-based modeling.","authors":["Leonardo Bettini","Amirhossein Kazemipour","Robert K. Katzschmann","George Haller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03333v1","updated":"2026-01-06T18:28:01Z","published":"2026-01-06T18:28:01Z","title":"Optimal Quantization of Finite Uniform Data on the Sphere","summary":"This paper develops a systematic and geometric theory of optimal quantization on the unit sphere $\\mathbb S^2$, focusing on finite uniform probability distributions supported on the spherical surface - rather than on lower-dimensional geodesic subsets such as circles or arcs. We first establish the existence of optimal sets of $n$-means and characterize them through centroidal spherical Voronoi tessellations. Three fundamental structural results are obtained. First, a cluster - purity theorem shows that when the support consists of well-separated components, each optimal Voronoi region remains confined to a single component. Second, a ring - allocation (discrete water - filling) theorem provides an explicit rule describing how optimal representatives are distributed across multiple latitudinal rings, together with closed-form distortion formulas. Third, a Lipschitz - type stability theorem quantifies the robustness of optimal configurations under small geodesic perturbations of the support. In addition, a spherical analogue of Lloyd's algorithm is presented, in which intrinsic (Karcher) means replace Euclidean centroids for iterative refinement. These results collectively provide a unified and transparent framework for understanding the geometric and algorithmic structure of optimal quantization on $\\mathbb S^2$.","authors":["Mrinal Kanti Roychowdhury"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.16533v2","updated":"2026-01-06T17:51:17Z","published":"2025-12-18T13:43:02Z","title":"Continuized Nesterov Acceleration for Non-Convex Optimization","summary":"In convex optimization, continuous-time counterparts have been a fruitful tool for analyzing momentum algorithms. Fewer such examples are available when the function to minimize is non-convex. In several cases, discrepancies arise between the existing discrete-time results, namely those obtained for momentum algorithms, and their continuous-time counterparts, with the latter typically yielding stronger guarantees. We argue that the continuized framework (Even et al., 2021), mixing continuous and discrete components, can tighten the gap between known continuous and discrete results. This framework relies on computations akin to standard Lyapunov analyses, from which are deduced convergence bounds for an algorithm that can be written as a Nesterov momentum algorithm with stochastic parameters. In this work, we extend the range of applicability of the continuized framework, e.g. by allowing it to handle non-smooth Lyapunov functions. We then strengthen its trajectory-wise guarantees for linear convergence rate, deriving finite time bounds with high probability and asymptotic almost sure bounds. We apply this framework to the non-convex class of strongly quasar convex functions. Adapting continuous-time results that have weaker discrete equivalents to the continuized method, we improve by a constant factor the known convergence rate, and relax the existing assumptions on the set of minimizers.","authors":["Julien Hermant","Jean-François Aujol","Charles Dossal","Lorick Huang","Aude Rondepierre"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03182v1","updated":"2026-01-06T17:02:13Z","published":"2026-01-06T17:02:13Z","title":"Subjective-Objective Median-based Importance Technique (SOMIT) to Aid Multi-Criteria Renewable Energy Evaluation","summary":"Accelerating the renewable energy transition requires informed decision-making that accounts for the diverse financial, technical, environmental, and social trade-offs across different renewable energy technologies. A critical step in this multi-criteria decision-making (MCDM) process is the determination of appropriate criteria weights. However, deriving these weights often solely involves either subjective assessment from decision-makers or objective weighting methods, each of which has limitations in terms of cognitive burden, potential bias, and insufficient contextual relevance. This study proposes the subjective-objective median-based importance technique (SOMIT), a novel hybrid approach for determining criteria weights in MCDM. By tailoring SOMIT to renewable energy evaluation, the method directly supports applied energy system planning, policy analysis, and technology prioritization under carbon neutrality goals. The practical utility of SOMIT is demonstrated through two MCDM case studies on renewable energy decision-making in India and Saudi Arabia. Using the derived weights from SOMIT, the TOPSIS method ranks the renewable energy alternatives, with solar power achieving the highest performance scores in both cases. The main contributions of this work are five-fold: 1) the proposed SOMIT reduces the number of required subjective comparisons from the conventional quadratic order to a linear order; 2) SOMIT is more robust to outliers in the alternatives-criteria matrix (ACM); 3) SOMIT balances subjective expert knowledge with objective data-driven insights, thereby mitigating bias; 4) SOMIT is inherently modular, allowing both its individual parts and the complete approach to be seamlessly coupled with a wide range of MCDM methods commonly applied in energy systems and policy analysis; 5) a dedicated Python library, pysomit, is developed for SOMIT.","authors":["Ding Ding","Yang Li","Poh Ling Neo","Zhiyuan Wang","Chongwu Xia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16211v2","updated":"2026-01-06T15:52:50Z","published":"2025-11-20T10:27:58Z","title":"Weak optimal transport with moment constraints: constraint qualification, dual attainment and entropic regularization","summary":"We consider weak optimal problems (possibly entropically penalized) incorporating both soft and hard (including the case of the martingale condition) moment constraints. Even in the special case of the martingale optimal transport problem, existence of Lagrange multipliers corresponding to the martingale constraint is notoriously hard (and may fail unless some specific additional assumptions are made). We identify a condition of qualification of the hard moment constraints (which in the martingale case is implied by well-known conditions in the literature) under which general dual attainment results are established. We also analyze the convergence of entropically regularized schemes combined with penalization of the moment constraint and illustrate our theoretical findings by numerically solving in dimension one, the Brenier-Strassen problem of Gozlan and Juillet and a family of problems which interpolates between monotone transport and left-curtain martingale coupling of Beiglböck and Juillet.","authors":["Guillaume Carlier","Hugo Malamut","Maxime Sylvestre"],"pdf_url":"","comment":"37 pages, 2 figures"},{"id":"http://arxiv.org/abs/2601.03097v1","updated":"2026-01-06T15:30:02Z","published":"2026-01-06T15:30:02Z","title":"Dual-quaternion learning control for autonomous vehicle trajectory tracking with safety guarantees","summary":"We propose a learning-based trajectory tracking controller for autonomous robotic platforms whose motion can be described kinematically on $\\mathrm{SE}(3)$. The controller is formulated in the dual quaternion framework and operates at the velocity level, assuming direct command of angular and linear velocities, as is standard in many aerial vehicles and omnidirectional mobile robots. Gaussian Process (GP) regression is integrated into a geometric feedback law to learn and compensate online for unknown, state-dependent disturbances and modeling imperfections affecting both attitude and position, while preserving the algebraic structure and coupling properties inherent to rigid-body motion.\n  The proposed approach does not rely on explicit parametric models of the unknown effects, making it well-suited for robotic systems subject to sensor-induced disturbances, unmodeled actuation couplings, and environmental uncertainties. A Lyapunov-based analysis establishes probabilistic ultimate boundedness of the pose tracking error under bounded GP uncertainty, providing formal stability guarantees for the learning-based controller.\n  Simulation results demonstrate accurate and smooth trajectory tracking in the presence of realistic, localized disturbances, including correlated rotational and translational effects arising from magnetometer perturbations. These results illustrate the potential of combining geometric modeling and probabilistic learning to achieve robust, data-efficient pose control for autonomous robotic systems.","authors":["Omayra Yago Nieto","Alexandre Anahory Simoes","Juan I. Giribet","Leonardo Colombo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18998v2","updated":"2026-01-06T15:24:55Z","published":"2025-11-24T11:23:48Z","title":"A Trust-region Funnel Algorithm for Grey-Box Optimisation","summary":"Grey-box optimisation, where some parts of an optimisation problem are represented by explicit algebraic (glass-box) models while others are treated as black-box models lacking analytic derivatives, remains a challenge in process systems engineering. Trust-region (TR) methods provide a robust framework for grey-box problems by combining accurate glass-box derivatives with local reduced models (RMs) for black-box components. However, existing TR approaches often involve complex multi-layered formulations requiring extensive parameter tuning, or lack open-source implementations. Motivated by the recent advances in funnel-based convergence theory for nonlinear optimisation and the TR filter method, we propose a novel TR funnel algorithm for grey-box optimisation that replaces the filter acceptance criterion with a generalisable uni-dimensional funnel, maintaining a monotonically non-increasing upper bound on approximation error of the local black-box RMs. A global convergence proof to a first-order critical point is established. The algorithm, implemented in an open-source Pyomo framework, supports multiple RM forms and globalisation strategies (filter or funnel). Benchmark tests on seven numerical and engineering problems show that the TR funnel algorithm achieves comparable and often improved performance relative to the classical TR filter method. The TR funnel method thus provides a simpler, and extensible alternative for large-scale grey-box optimisation.","authors":["Gul Hameed","Tao Chen","Antonio del Rio Chanona","Lorenz T. Biegler","Michael Short"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2311.16086v2","updated":"2026-01-06T14:07:25Z","published":"2023-11-27T18:56:03Z","title":"MAST: Model-Agnostic Sparsified Training","summary":"We introduce a novel optimization problem formulation that departs from the conventional way of minimizing machine learning model loss as a black-box function. Unlike traditional formulations, the proposed approach explicitly incorporates an initially pre-trained model and random sketch operators, allowing for sparsification of both the model and gradient during training. We establish the insightful properties of the proposed objective function and highlight its connections to the standard formulation. Furthermore, we present several variants of the Stochastic Gradient Descent (SGD) method adapted to the new problem formulation, including SGD with general sampling, a distributed version, and SGD with variance reduction techniques. We achieve tighter convergence rates and relax assumptions, bridging the gap between theoretical principles and practical applications, covering several important techniques such as Dropout and Sparse training. This work presents promising opportunities to enhance the theoretical understanding of model training through a sparsification-aware optimization approach.","authors":["Yury Demidovich","Grigory Malinovsky","Egor Shulgin","Peter Richtárik"],"pdf_url":"","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2601.03016v1","updated":"2026-01-06T13:41:53Z","published":"2026-01-06T13:41:53Z","title":"Adaptive Control of Unknown Linear Switched Systems via Policy Gradient Methods","summary":"We consider the policy gradient adaptive control (PGAC) framework, which adaptively updates a control policy in real time, by performing data-based gradient descent steps on the linear quadratic regulator cost. This method has empirically shown to react to changing circumstances, such as model parameters, efficiently. To formalize this observation, we design a PGAC method which stabilizes linear switched systems, where both model parameters and switching time are unknown. We use sliding window data for the policy gradient estimate and show that under a dwell time condition and small dynamics variation, the policy can track the switching dynamics and ensure closed-loop stability. We perform simulations to validate our theoretical results.","authors":["Felix Laurent","Feiran Zhao","Jaap Eising","Florian Dörfler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03318v1","updated":"2026-01-06T13:39:07Z","published":"2026-01-06T13:39:07Z","title":"An overview of the fractional-order gradient descent method and its applications","summary":"Recent studies have shown that fractional calculus is an effective alternative mathematical tool in various scientific fields. However, some investigations indicate that results established in differential and integral calculus do not necessarily hold true in fractional calculus. In this work we will compare various methods presented in the literature to improve the Gradient Descent Method, in terms of convergence of the method, convergence to the extreme point, and convergence rate. In general, these methods that generalize the gradient descent algorithm by replacing the gradient with a fractional-order operator are inefficient in achieving convergence to the extremum point of the objective function. To avoid these difficulties, we proposed to choose the Fractional Continuous Time algorithm to generalize the gradient method. In this approach, the convergence of the method to the extreme point of the function is guaranteed by introducing the fractional order in the time derivative, rather than in of the gradient. In this case, the issue of finding the extreme point is resolved, while the issue of stability at the equilibrium point remains.\n  Fractional Continuous Time method converges to extreme point of cost function when fractional-order is between 0 and 1. The simulations shown in this work suggests that a similar result can be found when $1 \\leq α\\leq 2$. { This paper highlights the main advantages and disadvantages of generalizations of the gradient method using fractional derivatives, aiming to optimize convergence in complex problems. Some chemical problems, with n=11 and 24 optimization parameters, are employed as means of evaluating the efficacy of the propose algorithms. In general, previous studies are restricted to mathematical questions and simple illustrative examples.","authors":["Higor V. M. Ferreira","Camila A. Tavares","Nelson H. T. Lemes","José Claudinei Ferreira","José P. C. dos Santos"],"pdf_url":"","comment":"26 pages, 2 tables, 8 figures"},{"id":"http://arxiv.org/abs/2601.03008v1","updated":"2026-01-06T13:32:45Z","published":"2026-01-06T13:32:45Z","title":"A Relaxation Method for Nonsmooth Nonlinear Optimization with Binary Constraints","summary":"We study binary optimization problems of the form \\( \\min_{x\\in\\{-1,1\\}^n} f(Ax-b) \\) with possibly nonsmooth loss \\(f\\). Following the lifted rank-one semidefinite programming (SDP) approach\\cite{qian2023matrix}, we develop a majorization-minimization algorithm by using the difference-of-convexity (DC) reformuation for the rank-one constraint and the Moreau envelop for the nonsmooth loss. We provide global complexity guarantees for the proposed \\textbf{D}ifference of \\textbf{C}onvex \\textbf{R}elaxation \\textbf{A}lgorithm (DCRA) and show that it produces an approximately feasible binary solution with an explicit bound on the optimality gap. Numerical experiments on synthetic and real datasets confirm that our method achieves superior accuracy and scalability compared with existing approaches.","authors":["Lianghai Xiao","Yitian Qian","Shaohua Pan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.05187v3","updated":"2026-01-06T12:33:03Z","published":"2024-02-07T19:01:06Z","title":"Learning mirror maps in policy mirror descent","summary":"Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map -- namely, the negative entropy -- which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. Using evolutionary strategies, we identify more efficient mirror maps that enhance the performance of PMD. We first focus on a tabular environment, i.e. Grid-World, where we relate existing theoretical bounds with the performance of PMD for a few standard mirror maps and the learned one. We then show that it is possible to learn a mirror map that outperforms the negative entropy in more complex environments, such as the MinAtar suite. Additionally, we demonstrate that the learned mirror maps generalize effectively to different tasks by testing each map across various other environments.","authors":["Carlo Alfano","Sebastian Towers","Silvia Sapora","Chris Lu","Patrick Rebeschini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02951v1","updated":"2026-01-06T11:48:21Z","published":"2026-01-06T11:48:21Z","title":"Hopfield neural networks as port-Hamiltonian and gradient systems","summary":"The structure of continuous Hopfield networks is revisited from a system-theoretic point of view. After adopting a novel electrical network interpretation involving nonlinear capacitors, it is shown that Hopfield networks admit a port-Hamiltonian formulation provided an extra passivity condition is satisfied. Subsequently it is shown that any Hopfield network can be represented as a gradient system, with Riemannian metric given by the inverse of the Hessian matrix of the total energy stored in the nonlinear capacitors. On the other hand, the well-known 'energy' function employed by Hopfield turns out to be the dissipation potential of the gradient system, and this potential is shown to satisfy a dissipation inequality that can be used for analysis and interconnection.","authors":["Arjan van der Schaft"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2601.02899v1","updated":"2026-01-06T10:37:33Z","published":"2026-01-06T10:37:33Z","title":"Relating Checkpoint Update Probabilities to Momentum Parameters in Single-Loop Variance Reduction Methods","summary":"Variance reduction (VR) is a crucial tool for solving finite-sum optimization problems, including the composite general convex setting, which is the focus of this work. On the one hand, denoting the number of component functions as $n$ and the target accuracy as $ε$, some VR methods achieve the near-optimal complexity $\\widetilde{\\mathcal{O}}\\left(n+\\sqrt{n}/\\sqrtε\\right)$, but they all have nested structure and fail to provide convergence guarantee for the iterate sequence itself. On the other hand, single-loop VR methods, being free from the aforementioned disadvantages, have complexity no better than $\\mathcal{O}\\left(n+n/\\sqrtε\\right)$ which is the complexity of the deterministic method FISTA, thus leaving a critical gap unaddressed. In this work, we propose the \\textit{Harmonia} technique which relates checkpoint update probabilities to momentum parameters in single-loop VR methods. Based on this technique, we further propose to vary the growth rate of the momentum parameter, creating a novel continuous trade-off between acceleration and variance reduction, controlled by the key parameter $α\\in[0,1]$. The proposed techniques lead to following favourable consequences. First, several known complexity of quite different algorithms are re-discovered under the proposed unifying algorithmic framework Katyusha-H. Second, under an extra mild condition, Katyusha-H achieves the near-optimal complexity for $α$ belonging to a certain interval, highlighting the effectiveness of the acceleration-variance reduction trade-off. Last, without extra conditions, Katyusha-H achieves the complexity $\\widetilde{\\mathcal{O}}(n+\\sqrt{n}/\\sqrtε)$ with $α=1$ and proper mini-batch sizes. The proposed idea and techniques may be of general interest beyond the considered problem in this work.","authors":["Hai Liu","Tiande Guo","Congying Han"],"pdf_url":"","comment":null}],"Performance":[{"id":"http://arxiv.org/abs/2601.03159v1","updated":"2026-01-06T16:33:51Z","published":"2026-01-06T16:33:51Z","title":"Rapid Augmentations for Time Series (RATS): A High-Performance Library for Time Series Augmentation","summary":"Time series augmentation is critical for training robust deep learning models, particularly in domains where labelled data is scarce and expensive to obtain. However, existing augmentation libraries for time series, mainly written in Python, suffer from performance bottlenecks, where running time grows exponentially as dataset sizes increase -- an aspect limiting their applicability in large-scale, production-grade systems. We introduce RATS (Rapid Augmentations for Time Series), a high-performance library for time series augmentation written in Rust with Python bindings (RATSpy). RATS implements multiple augmentation methods spanning basic transformations, frequency-domain operations and time warping techniques, all accessible through a unified pipeline interface with built-in parallelisation. Comprehensive benchmarking of RATSpy versus a commonly used library (tasug) on 143 datasets demonstrates that RATSpy achieves an average speedup of 74.5\\% over tsaug (up to 94.8\\% on large datasets), with up to 47.9\\% less peak memory usage.","authors":["Wadie Skaf","Felix Kern","Aryamaan Basu Roy","Tejas Pradhan","Roman Kalkreuth","Holger Hoos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02735v1","updated":"2026-01-06T05:57:43Z","published":"2026-01-06T05:57:43Z","title":"Scalable Tree Ensemble Proximities in Python","summary":"Tree ensemble methods such as Random Forests naturally induce supervised similarity measures through their decision tree structure, but existing implementations of proximities derived from tree ensembles typically suffer from quadratic time or memory complexity, limiting their scalability. In this work, we introduce a general framework for efficient proximity computation by defining a family of Separable Weighted Leaf-Collision Proximities. We show that any proximity measure in this family admits an exact sparse matrix factorization, restricting computation to leaf-level collisions and avoiding explicit pairwise comparisons. This formulation enables low-memory, scalable proximity computation using sparse linear algebra in Python. Empirical benchmarks demonstrate substantial runtime and memory improvements over traditional approaches, allowing tree ensemble proximities to scale efficiently to datasets with hundreds of thousands of samples on standard CPU hardware.","authors":["Adrien Aumon","Guy Wolf","Kevin R. Moon","Jake S. Rhodes"],"pdf_url":"","comment":null}],"computadora Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2601.03468v1","updated":"2026-01-06T23:43:47Z","published":"2026-01-06T23:43:47Z","title":"Understanding Reward Hacking in Text-to-Image Reinforcement Learning","summary":"Reinforcement learning (RL) has become a standard approach for post-training large language models and, more recently, for improving image generation models, which uses reward functions to enhance generation quality and human preference alignment. However, existing reward designs are often imperfect proxies for true human judgment, making models prone to reward hacking--producing unrealistic or low-quality images that nevertheless achieve high reward scores. In this work, we systematically analyze reward hacking behaviors in text-to-image (T2I) RL post-training. We investigate how both aesthetic/human preference rewards and prompt-image consistency rewards individually contribute to reward hacking and further show that ensembling multiple rewards can only partially mitigate this issue. Across diverse reward models, we identify a common failure mode: the generation of artifact-prone images. To address this, we propose a lightweight and adaptive artifact reward model, trained on a small curated dataset of artifact-free and artifact-containing samples. This model can be integrated into existing RL pipelines as an effective regularizer for commonly used reward models. Experiments demonstrate that incorporating our artifact reward significantly improves visual realism and reduces reward hacking across multiple T2I RL setups, demonstrating the effectiveness of lightweight reward augment serving as a safeguard against reward hacking.","authors":["Yunqi Hong","Kuei-Chun Kao","Hengguang Zhou","Cho-Jui Hsieh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03467v1","updated":"2026-01-06T23:43:00Z","published":"2026-01-06T23:43:00Z","title":"ThinkRL-Edit: Thinking in Reinforcement Learning for Reasoning-Centric Image Editing","summary":"Instruction-driven image editing with unified multimodal generative models has advanced rapidly, yet their underlying visual reasoning remains limited, leading to suboptimal performance on reasoning-centric edits. Reinforcement learning (RL) has been investigated for improving the quality of image editing, but it faces three key challenges: (1) limited reasoning exploration confined to denoising stochasticity, (2) biased reward fusion, and (3) unstable VLM-based instruction rewards. In this work, we propose ThinkRL-Edit, a reasoning-centric RL framework that decouples visual reasoning from image synthesis and expands reasoning exploration beyond denoising. To the end, we introduce Chain-of-Thought (CoT)-based reasoning sampling with planning and reflection stages prior to generation in online sampling, compelling the model to explore multiple semantic hypotheses and validate their plausibility before committing to a visual outcome. To avoid the failures of weighted aggregation, we propose an unbiased chain preference grouping strategy across multiple reward dimensions. Moreover, we replace interval-based VLM scores with a binary checklist, yielding more precise, lower-variance, and interpretable rewards for complex reasoning. Experiments show our method significantly outperforms prior work on reasoning-centric image editing, producing instruction-faithful, visually coherent, and semantically grounded edits.","authors":["Hengjia Li","Liming Jiang","Qing Yan","Yizhi Song","Hao Kang","Zichuan Liu","Xin Lu","Boxi Wu","Deng Cai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03466v1","updated":"2026-01-06T23:42:40Z","published":"2026-01-06T23:42:40Z","title":"Latent Geometry of Taste: Scalable Low-Rank Matrix Factorization","summary":"Scalability and data sparsity remain critical bottlenecks for collaborative filtering on massive interaction datasets. This work investigates the latent geometry of user preferences using the MovieLens 32M dataset, implementing a high-performance, parallelized Alternating Least Squares (ALS) framework. Through extensive hyperparameter optimization, we demonstrate that constrained low-rank models significantly outperform higher dimensional counterparts in generalization, achieving an optimal balance between Root Mean Square Error (RMSE) and ranking precision. We visualize the learned embedding space to reveal the unsupervised emergence of semantic genre clusters, confirming that the model captures deep structural relationships solely from interaction data. Finally, we validate the system's practical utility in a cold-start scenario, introducing a tunable scoring parameter to manage the trade-off between popularity bias and personalized affinity effectively. The codebase for this research can be found here: https://github.com/joshsalako/recommender.git","authors":["Joshua Salako"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03463v1","updated":"2026-01-06T23:22:22Z","published":"2026-01-06T23:22:22Z","title":"Experimental Comparison of Light-Weight and Deep CNN Models Across Diverse Datasets","summary":"Our results reveal that a well-regularized shallow architecture can serve as a highly competitive baseline across heterogeneous domains - from smart-city surveillance to agricultural variety classification - without requiring large GPUs or specialized pre-trained models. This work establishes a unified, reproducible benchmark for multiple Bangladeshi vision datasets and highlights the practical value of lightweight CNNs for real-world deployment in low-resource settings.","authors":["Md. Hefzul Hossain Papon","Shadman Rabby"],"pdf_url":"","comment":"25 pages, 11 figures"},{"id":"http://arxiv.org/abs/2601.03460v1","updated":"2026-01-06T23:13:35Z","published":"2026-01-06T23:13:35Z","title":"FROST-Drive: Scalable and Efficient End-to-End Driving with a Frozen Vision Encoder","summary":"End-to-end (E2E) models in autonomous driving aim to directly map sensor inputs to control commands, but their ability to generalize to novel and complex scenarios remains a key challenge. The common practice of fully fine-tuning the vision encoder on driving datasets potentially limits its generalization by causing the model to specialize too heavily in the training data. This work challenges the necessity of this training paradigm. We propose FROST-Drive, a novel E2E architecture designed to preserve and leverage the powerful generalization capabilities of a pretrained vision encoder from a Vision-Language Model (VLM). By keeping the encoder's weights frozen, our approach directly transfers the rich, generalized world knowledge from the VLM to the driving task. Our model architecture combines this frozen encoder with a transformer-based adapter for multimodal fusion and a GRU-based decoder for smooth waypoint generation. Furthermore, we introduce a custom loss function designed to directly optimize for Rater Feedback Score (RFS), a metric that prioritizes robust trajectory planning. We conduct extensive experiments on Waymo Open E2E Dataset, a large-scale datasets deliberately curated to capture the long-tail scenarios, demonstrating that our frozen-encoder approach significantly outperforms models that employ full fine-tuning. Our results provide substantial evidence that preserving the broad knowledge of a capable VLM is a more effective strategy for achieving robust, generalizable driving performance than intensive domain-specific adaptation. This offers a new pathway for developing vision-based models that can better handle the complexities of real-world application domains.","authors":["Zeyu Dong","Yimin Zhu","Yu Wu","Yu Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.15438v4","updated":"2026-01-06T23:08:11Z","published":"2025-02-21T13:07:45Z","title":"Deflickering Vision-Based Occupancy Networks through Lightweight Spatio-Temporal Correlation","summary":"Vision-based occupancy networks (VONs) provide an end-to-end solution for reconstructing 3D environments in autonomous driving. However, existing methods often suffer from temporal inconsistencies, manifesting as flickering effects that degrade temporal coherence and adversely affect downstream decision-making. While recent approaches incorporate historical information to alleviate this issue, they often incur high computational costs and may introduce misaligned or redundant features that interfere with object detection. We propose OccLinker, a novel plugin framework that can be easily integrated into existing VONs to improve performance. Our method efficiently consolidates historical static and motion cues, learns sparse latent correlations with current features through a dual cross-attention mechanism, and generates correction occupancy components to refine the base network predictions. In addition, we introduce a new temporal consistency metric to quantitatively measure flickering effects. Extensive experiments on two benchmark datasets demonstrate that our method achieves superior performance with minimal computational overhead while effectively reducing flickering artifacts.","authors":["Fengcheng Yu","Haoran Xu","Canming Xia","Ziyang Zong","Guang Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22351v2","updated":"2026-01-06T22:16:58Z","published":"2025-12-26T19:22:39Z","title":"VULCAN: Tool-Augmented Multi Agents for Iterative 3D Object Arrangement","summary":"Despite the remarkable progress of Multimodal Large Language Models (MLLMs) in 2D vision-language tasks, their application to complex 3D scene manipulation remains underexplored. In this paper, we bridge this critical gap by tackling three key challenges in 3D object arrangement task using MLLMs. First, to address the weak visual grounding of MLLMs, which struggle to link programmatic edits with precise 3D outcomes, we introduce an MCP-based API. This shifts the interaction from brittle raw code manipulation to more robust, function-level updates. Second, we augment the MLLM's 3D scene understanding with a suite of specialized visual tools to analyze scene state, gather spatial information, and validate action outcomes. This perceptual feedback loop is critical for closing the gap between language-based updates and precise 3D-aware manipulation. Third, to manage the iterative, error-prone updates, we propose a collaborative multi-agent framework with designated roles for planning, execution, and verification. This decomposition allows the system to robustly handle multi-step instructions and recover from intermediate errors. We demonstrate the effectiveness of our approach on a diverse set of 25 complex object arrangement tasks, where it significantly outperforms existing baselines. Website: vulcan-3d.github.io","authors":["Zhengfei Kuang","Rui Lin","Long Zhao","Gordon Wetzstein","Saining Xie","Sanghyun Woo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03431v1","updated":"2026-01-06T21:41:11Z","published":"2026-01-06T21:41:11Z","title":"WeedRepFormer: Reparameterizable Vision Transformers for Real-Time Waterhemp Segmentation and Gender Classification","summary":"We present WeedRepFormer, a lightweight multi-task Vision Transformer designed for simultaneous waterhemp segmentation and gender classification. Existing agricultural models often struggle to balance the fine-grained feature extraction required for biological attribute classification with the efficiency needed for real-time deployment. To address this, WeedRepFormer systematically integrates structural reparameterization across the entire architecture - comprising a Vision Transformer backbone, a Lite R-ASPP decoder, and a novel reparameterizable classification head - to decouple training-time capacity from inference-time latency. We also introduce a comprehensive waterhemp dataset containing 10,264 annotated frames from 23 plants. On this benchmark, WeedRepFormer achieves 92.18% mIoU for segmentation and 81.91% accuracy for gender classification using only 3.59M parameters and 3.80 GFLOPs. At 108.95 FPS, our model outperforms the state-of-the-art iFormer-T by 4.40% in classification accuracy while maintaining competitive segmentation performance and significantly reducing parameter count by 1.9x.","authors":["Toqi Tahamid Sarker","Taminul Islam","Khaled R. Ahmed","Cristiana Bernardi Rankrape","Kaitlin E. Creager","Karla Gage"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.03416v1","updated":"2026-01-06T21:09:10Z","published":"2026-01-06T21:09:10Z","title":"GAMBIT: A Gamified Jailbreak Framework for Multimodal Large Language Models","summary":"Multimodal Large Language Models (MLLMs) have become widely deployed, yet their safety alignment remains fragile under adversarial inputs. Previous work has shown that increasing inference steps can disrupt safety mechanisms and lead MLLMs to generate attacker-desired harmful content. However, most existing attacks focus on increasing the complexity of the modified visual task itself and do not explicitly leverage the model's own reasoning incentives. This leads to them underperforming on reasoning models (Models with Chain-of-Thoughts) compared to non-reasoning ones (Models without Chain-of-Thoughts). If a model can think like a human, can we influence its cognitive-stage decisions so that it proactively completes a jailbreak? To validate this idea, we propose GAMBI} (Gamified Adversarial Multimodal Breakout via Instructional Traps), a novel multimodal jailbreak framework that decomposes and reassembles harmful visual semantics, then constructs a gamified scene that drives the model to explore, reconstruct intent, and answer as part of winning the game. The resulting structured reasoning chain increases task complexity in both vision and text, positioning the model as a participant whose goal pursuit reduces safety attention and induces it to answer the reconstructed malicious query. Extensive experiments on popular reasoning and non-reasoning MLLMs demonstrate that GAMBIT achieves high Attack Success Rates (ASR), reaching 92.13% on Gemini 2.5 Flash, 91.20% on QvQ-MAX, and 85.87% on GPT-4o, significantly outperforming baselines.","authors":["Xiangdong Hu","Yangyang Jiang","Qin Hu","Xiaojun Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.11260v2","updated":"2026-01-06T21:04:05Z","published":"2025-12-12T03:49:55Z","title":"Do We Need Reformer for Vision? An Experimental Comparison with Vision Transformers","summary":"Transformers have recently demonstrated strong performance in computer vision, with Vision Transformers (ViTs) leveraging self-attention to capture both low-level and high-level image features. However, standard ViTs remain computationally expensive, since global self-attention scales quadratically with the number of tokens, which limits their practicality for high-resolution inputs and resource-constrained settings.\n  In this work, we investigate the Reformer architecture as an alternative vision backbone. By combining patch-based tokenization with locality-sensitive hashing (LSH) attention, our model approximates global self-attention while reducing its theoretical time complexity from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n \\log n)$ in the sequence length $n$. We evaluate the proposed Reformer-based vision model on CIFAR-10 to assess its behavior on small-scale datasets, on ImageNet-100 to study its accuracy--efficiency trade-off in a more realistic setting, and on a high-resolution medical imaging dataset to evaluate the model under longer token sequences.\n  While the Reformer achieves higher accuracy on CIFAR-10 compared to our ViT-style baseline, the ViT model consistently outperforms the Reformer in our experiments in terms of practical efficiency and end-to-end computation time across the larger and higher-resolution settings. These results suggest that, despite the theoretical advantages of LSH-based attention, meaningful computation gains require sequence lengths substantially longer than those produced by typical high-resolution images.","authors":["Ali El Bellaj","Mohammed-Amine Cheddadi","Rhassan Berber"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03410v1","updated":"2026-01-06T20:52:12Z","published":"2026-01-06T20:52:12Z","title":"Inferring Clinically Relevant Molecular Subtypes of Pancreatic Cancer from Routine Histopathology Using Deep Learning","summary":"Molecular subtyping of PDAC into basal-like and classical has established prognostic and predictive value. However, its use in clinical practice is limited by cost, turnaround time, and tissue requirements, thereby restricting its application in the management of PDAC. We introduce PanSubNet, an interpretable deep learning framework that predicts therapy-relevant molecular subtypes directly from standard H&E-stained WSIs. PanSubNet was developed using data from 1,055 patients across two multi-institutional cohorts (PANCAN, n=846; TCGA, n=209) with paired histology and RNA-seq data. Ground-truth labels were derived using the validated Moffitt 50-gene signature refined by GATA6 expression. The model employs dual-scale architecture that fuses cellular-level morphology with tissue-level architecture, leveraging attention mechanisms for multi-scale representation learning and transparent feature attribution. On internal validation within PANCAN using five-fold cross-validation, PanSubNet achieved mean AUC of 88.5% with balanced sensitivity and specificity. External validation on the independent TCGA cohort without fine-tuning demonstrated robust generalizability (AUC 84.0%). PanSubNet preserved and, in metastatic disease, strengthened prognostic stratification compared to RNA-seq based labels. Prediction uncertainty linked to intermediate transcriptional states, not classification noise. Model predictions are aligned with established transcriptomic programs, differentiation markers, and DNA damage repair signatures. By enabling rapid, cost-effective molecular stratification from routine H&E-stained slides, PanSubNet offers a clinically deployable and interpretable tool for genetic subtyping. We are gathering data from two institutions to validate and assess real-world performance, supporting integration into digital pathology workflows and advancing precision oncology for PDAC.","authors":["Abdul Rehman Akbar","Alejandro Levya","Ashwini Esnakula","Elshad Hasanov","Anne Noonan","Upender Manne","Vaibhav Sahai","Lingbin Meng","Susan Tsai","Anil Parwani","Wei Chen","Ashish Manne","Muhammad Khalid Khan Niazi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03400v1","updated":"2026-01-06T20:27:29Z","published":"2026-01-06T20:27:29Z","title":"Eye-Q: A Multilingual Benchmark for Visual Word Puzzle Solving and Image-to-Phrase Reasoning","summary":"Vision-Language Models (VLMs) have achieved strong performance on standard vision-language benchmarks, yet often rely on surface-level recognition rather than deeper reasoning. We propose visual word puzzles as a challenging alternative, as they require discovering implicit visual cues, generating and revising hypotheses, and mapping perceptual evidence to non-literal concepts in ways that are difficult to solve via literal grounding, OCR-heavy shortcuts, or simple retrieval-style matching. We introduce Eye-Q, a multilingual benchmark designed to assess this form of complex visual understanding. Eye-Q contains 1,343 puzzles in which a model observes a conceptually dense scene with a brief description and must infer a specific target word or phrase. The puzzles are intentionally unstructured and cue-implicit, with distractors and contextual relationships that demand selective attention, abstraction, and associative inference. The benchmark spans English, Persian, Arabic, and cross-lingual puzzles. We evaluate state-of-the-art VLMs using an open-ended, human-aligned protocol that probes hypothesis formation and revision under lightweight assistance. Results reveal substantial performance gaps, especially on abstract and cross-lingual puzzles, highlighting limitations in current models' ability to construct and search over appropriate conceptual representations for flexible image-to-phrase inference; maximum accuracy reaches only 60.27%.","authors":["Ali Najar","Alireza Mirrokni","Arshia Izadyari","Sadegh Mohammadian","Amir Homayoon Sharifizade","Asal Meskin","Mobin Bagherian","Ehsaneddin Asgari"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2601.03392v1","updated":"2026-01-06T20:04:18Z","published":"2026-01-06T20:04:18Z","title":"Better, But Not Sufficient: Testing Video ANNs Against Macaque IT Dynamics","summary":"Feedforward artificial neural networks (ANNs) trained on static images remain the dominant models of the the primate ventral visual stream, yet they are intrinsically limited to static computations. The primate world is dynamic, and the macaque ventral visual pathways, specifically the inferior temporal (IT) cortex not only supports object recognition but also encodes object motion velocity during naturalistic video viewing. Does IT's temporal responses reflect nothing more than time-unfolded feedforward transformations, framewise features with shallow temporal pooling, or do they embody richer dynamic computations? We tested this by comparing macaque IT responses during naturalistic videos against static, recurrent, and video-based ANN models. Video models provided modest improvements in neural predictivity, particularly at later response stages, raising the question of what kind of dynamics they capture. To probe this, we applied a stress test: decoders trained on naturalistic videos were evaluated on \"appearance-free\" variants that preserve motion but remove shape and texture. IT population activity generalized across this manipulation, but all ANN classes failed. Thus, current video models better capture appearance-bound dynamics rather than the appearance-invariant temporal computations expressed in IT, underscoring the need for new objectives that encode biological temporal statistics and invariances.","authors":["Matteo Dunnhofer","Christian Micheloni","Kohitij Kar"],"pdf_url":"","comment":"Extended Abstract at the 2nd Human-inspired Computer Vision workshop at ICCV 2025"},{"id":"http://arxiv.org/abs/2601.03391v1","updated":"2026-01-06T19:56:16Z","published":"2026-01-06T19:56:16Z","title":"Edit2Restore:Few-Shot Image Restoration via Parameter-Efficient Adaptation of Pre-trained Editing Models","summary":"Image restoration has traditionally required training specialized models on thousands of paired examples per degradation type. We challenge this paradigm by demonstrating that powerful pre-trained text-conditioned image editing models can be efficiently adapted for multiple restoration tasks through parameter-efficient fine-tuning with remarkably few examples. Our approach fine-tunes LoRA adapters on FLUX.1 Kontext, a state-of-the-art 12B parameter flow matching model for image-to-image translation, using only 16-128 paired images per task, guided by simple text prompts that specify the restoration operation. Unlike existing methods that train specialized restoration networks from scratch with thousands of samples, we leverage the rich visual priors already encoded in large-scale pre-trained editing models, dramatically reducing data requirements while maintaining high perceptual quality. A single unified LoRA adapter, conditioned on task-specific text prompts, effectively handles multiple degradations including denoising, deraining, and dehazing. Through comprehensive ablation studies, we analyze: (i) the impact of training set size on restoration quality, (ii) trade-offs between task-specific versus unified multi-task adapters, (iii) the role of text encoder fine-tuning, and (iv) zero-shot baseline performance. While our method prioritizes perceptual quality over pixel-perfect reconstruction metrics like PSNR/SSIM, our results demonstrate that pre-trained image editing models, when properly adapted, offer a compelling and data-efficient alternative to traditional image restoration approaches, opening new avenues for few-shot, prompt-guided image enhancement. The code to reproduce our results are available at: https://github.com/makinyilmaz/Edit2Restore","authors":["M. Akın Yılmaz","Ahmet Bilican","Burak Can Biner","A. Murat Tekalp"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03382v1","updated":"2026-01-06T19:30:53Z","published":"2026-01-06T19:30:53Z","title":"A Novel Unified Approach to Deepfake Detection","summary":"The advancements in the field of AI is increasingly giving rise to various threats. One of the most prominent of them is the synthesis and misuse of Deepfakes. To sustain trust in this digital age, detection and tagging of deepfakes is very necessary. In this paper, a novel architecture for Deepfake detection in images and videos is presented. The architecture uses cross attention between spatial and frequency domain features along with a blood detection module to classify an image as real or fake. This paper aims to develop a unified architecture and provide insights into each step. Though this approach we achieve results better than SOTA, specifically 99.80%, 99.88% AUC on FF++ and Celeb-DF upon using Swin Transformer and BERT and 99.55, 99.38 while using EfficientNet-B4 and BERT. The approach also generalizes very well achieving great cross dataset results as well.","authors":["Lord Sen","Shyamapada Mukherjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03369v1","updated":"2026-01-06T19:14:49Z","published":"2026-01-06T19:14:49Z","title":"RiskCueBench: Benchmarking Anticipatory Reasoning from Early Risk Cues in Video-Language Models","summary":"With the rapid growth of video centered social media, the ability to anticipate risky events from visual data is a promising direction for ensuring public safety and preventing real world accidents. Prior work has extensively studied supervised video risk assessment across domains such as driving, protests, and natural disasters. However, many existing datasets provide models with access to the full video sequence, including the accident itself, which substantially reduces the difficulty of the task. To better reflect real world conditions, we introduce a new video understanding benchmark RiskCueBench in which videos are carefully annotated to identify a risk signal clip, defined as the earliest moment that indicates a potential safety concern. Experimental results reveal a significant gap in current systems ability to interpret evolving situations and anticipate future risky events from early visual signals, highlighting important challenges for deploying video risk prediction models in practice.","authors":["Sha Luo","Yogesh Prabhu","Tim Ossowski","Kaiping Chen","Junjie Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03362v1","updated":"2026-01-06T19:02:34Z","published":"2026-01-06T19:02:34Z","title":"Guardians of the Hair: Rescuing Soft Boundaries in Depth, Stereo, and Novel Views","summary":"Soft boundaries, like thin hairs, are commonly observed in natural and computer-generated imagery, but they remain challenging for 3D vision due to the ambiguous mixing of foreground and background cues. This paper introduces Guardians of the Hair (HairGuard), a framework designed to recover fine-grained soft boundary details in 3D vision tasks. Specifically, we first propose a novel data curation pipeline that leverages image matting datasets for training and design a depth fixer network to automatically identify soft boundary regions. With a gated residual module, the depth fixer refines depth precisely around soft boundaries while maintaining global depth quality, allowing plug-and-play integration with state-of-the-art depth models. For view synthesis, we perform depth-based forward warping to retain high-fidelity textures, followed by a generative scene painter that fills disoccluded regions and eliminates redundant background artifacts within soft boundaries. Finally, a color fuser adaptively combines warped and inpainted results to produce novel views with consistent geometry and fine-grained details. Extensive experiments demonstrate that HairGuard achieves state-of-the-art performance across monocular depth estimation, stereo image/video conversion, and novel view synthesis, with significant improvements in soft boundary regions.","authors":["Xiang Zhang","Yang Zhang","Lukas Mehl","Markus Gross","Christopher Schroers"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03357v1","updated":"2026-01-06T19:01:07Z","published":"2026-01-06T19:01:07Z","title":"RelightAnyone: A Generalized Relightable 3D Gaussian Head Model","summary":"3D Gaussian Splatting (3DGS) has become a standard approach to reconstruct and render photorealistic 3D head avatars. A major challenge is to relight the avatars to match any scene illumination. For high quality relighting, existing methods require subjects to be captured under complex time-multiplexed illumination, such as one-light-at-a-time (OLAT). We propose a new generalized relightable 3D Gaussian head model that can relight any subject observed in a single- or multi-view images without requiring OLAT data for that subject. Our core idea is to learn a mapping from flat-lit 3DGS avatars to corresponding relightable Gaussian parameters for that avatar. Our model consists of two stages: a first stage that models flat-lit 3DGS avatars without OLAT lighting, and a second stage that learns the mapping to physically-based reflectance parameters for high-quality relighting. This two-stage design allows us to train the first stage across diverse existing multi-view datasets without OLAT lighting ensuring cross-subject generalization, where we learn a dataset-specific lighting code for self-supervised lighting alignment. Subsequently, the second stage can be trained on a significantly smaller dataset of subjects captured under OLAT illumination. Together, this allows our method to generalize well and relight any subject from the first stage as if we had captured them under OLAT lighting. Furthermore, we can fit our model to unseen subjects from as little as a single image, allowing several applications in novel view synthesis and relighting for digital avatars.","authors":["Yingyan Xu","Pramod Rao","Sebastian Weiss","Gaspard Zoss","Markus Gross","Christian Theobalt","Marc Habermann","Derek Bradley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03256v1","updated":"2026-01-06T18:59:57Z","published":"2026-01-06T18:59:57Z","title":"Muses: Designing, Composing, Generating Nonexistent Fantasy 3D Creatures without Training","summary":"We present Muses, the first training-free method for fantastic 3D creature generation in a feed-forward paradigm. Previous methods, which rely on part-aware optimization, manual assembly, or 2D image generation, often produce unrealistic or incoherent 3D assets due to the challenges of intricate part-level manipulation and limited out-of-domain generation. In contrast, Muses leverages the 3D skeleton, a fundamental representation of biological forms, to explicitly and rationally compose diverse elements. This skeletal foundation formalizes 3D content creation as a structure-aware pipeline of design, composition, and generation. Muses begins by constructing a creatively composed 3D skeleton with coherent layout and scale through graph-constrained reasoning. This skeleton then guides a voxel-based assembly process within a structured latent space, integrating regions from different objects. Finally, image-guided appearance modeling under skeletal conditions is applied to generate a style-consistent and harmonious texture for the assembled shape. Extensive experiments establish Muses' state-of-the-art performance in terms of visual fidelity and alignment with textual descriptions, and potential on flexible 3D object editing. Project page: https://luhexiao.github.io/Muses.github.io/.","authors":["Hexiao Lu","Xiaokun Sun","Zeyu Cai","Hao Guo","Ying Tai","Jian Yang","Zhenyu Zhang"],"pdf_url":"","comment":"Project page: https://luhexiao.github.io/Muses.github.io/"},{"id":"http://arxiv.org/abs/2506.08002v2","updated":"2026-01-06T18:58:50Z","published":"2025-06-09T17:59:37Z","title":"Aligning Text, Images, and 3D Structure Token-by-Token","summary":"Creating machines capable of understanding the world in 3D is essential in assisting designers that build and edit 3D environments and robots navigating and interacting within a three-dimensional space. Inspired by advances in language and image modeling, we investigate the potential of autoregressive models for a new modality: structured 3D scenes. To this end, we propose a unified LLM framework that aligns language, images, and 3D scenes and provide a detailed ''cookbook'' outlining critical design choices for achieving optimal training and performance addressing key questions related to data representation, modality-specific objectives, and more. We show how to tokenize complex 3D objects to incorporate into our structured 3D scene modality. We evaluate performance across four core 3D tasks -- rendering, recognition, instruction-following, and question-answering -- and four 3D datasets, synthetic and real-world. We show our model's effectiveness on reconstructing complete 3D scenes consisting of complex objects from a single image and on real-world 3D object recognition tasks. Project webpage: https://glab-caltech.github.io/kyvo/","authors":["Aadarsh Sahoo","Vansh Tibrewal","Georgia Gkioxari"],"pdf_url":"","comment":"Project webpage: https://glab-caltech.github.io/kyvo/"},{"id":"http://arxiv.org/abs/2601.03252v1","updated":"2026-01-06T18:57:06Z","published":"2026-01-06T18:57:06Z","title":"InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields","summary":"Existing depth estimation methods are fundamentally limited to predicting depth on discrete image grids. Such representations restrict their scalability to arbitrary output resolutions and hinder the geometric detail recovery. This paper introduces InfiniDepth, which represents depth as neural implicit fields. Through a simple yet effective local implicit decoder, we can query depth at continuous 2D coordinates, enabling arbitrary-resolution and fine-grained depth estimation. To better assess our method's capabilities, we curate a high-quality 4K synthetic benchmark from five different games, spanning diverse scenes with rich geometric and appearance details. Extensive experiments demonstrate that InfiniDepth achieves state-of-the-art performance on both synthetic and real-world benchmarks across relative and metric depth estimation tasks, particularly excelling in fine-detail regions. It also benefits the task of novel view synthesis under large viewpoint shifts, producing high-quality results with fewer holes and artifacts.","authors":["Hao Yu","Haotong Lin","Jiawei Wang","Jiaxin Li","Yida Wang","Xueyang Zhang","Yue Wang","Xiaowei Zhou","Ruizhen Hu","Sida Peng"],"pdf_url":"","comment":"19 pages, 13 figures"},{"id":"http://arxiv.org/abs/2601.03250v1","updated":"2026-01-06T18:49:47Z","published":"2026-01-06T18:49:47Z","title":"A Versatile Multimodal Agent for Multimedia Content Generation","summary":"With the advancement of AIGC (AI-generated content) technologies, an increasing number of generative models are revolutionizing fields such as video editing, music generation, and even film production. However, due to the limitations of current AIGC models, most models can only serve as individual components within specific application scenarios and are not capable of completing tasks end-to-end in real-world applications. In real-world applications, editing experts often work with a wide variety of images and video inputs, producing multimodal outputs -- a video typically includes audio, text, and other elements. This level of integration across multiple modalities is something current models are unable to achieve effectively. However, the rise of agent-based systems has made it possible to use AI tools to tackle complex content generation tasks. To deal with the complex scenarios, in this paper, we propose a MultiMedia-Agent designed to automate complex content creation. Our agent system includes a data generation pipeline, a tool library for content creation, and a set of metrics for evaluating preference alignment. Notably, we introduce the skill acquisition theory to model the training data curation and agent training. We designed a two-stage correlation strategy for plan optimization, including self-correlation and model preference correlation. Additionally, we utilized the generated plans to train the MultiMedia-Agent via a three stage approach including base/success plan finetune and preference optimization. The comparison results demonstrate that the our approaches are effective and the MultiMedia-Agent can generate better multimedia content compared to novel models.","authors":["Daoan Zhang","Wenlin Yao","Xiaoyang Wang","Yebowen Hu","Jiebo Luo","Dong Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.20291v3","updated":"2026-01-06T18:46:16Z","published":"2025-05-26T17:59:33Z","title":"VisRet: Visualization Improves Knowledge-Intensive Text-to-Image Retrieval","summary":"Text-to-image retrieval (T2I retrieval) remains challenging because cross-modal embeddings often behave as bags of concepts, underrepresenting structured visual relationships such as pose and viewpoint. We propose Visualize-then-Retrieve (VisRet), a retrieval paradigm that mitigates this limitation of cross-modal similarity alignment. VisRet first projects textual queries into the image modality via T2I generation, then performs retrieval within the image modality to bypass the weaknesses of cross-modal retrievers in recognizing subtle visual-spatial features. Across four benchmarks (Visual-RAG, INQUIRE-Rerank, Microsoft COCO, and our new Visual-RAG-ME featuring multi-entity comparisons), VisRet substantially outperforms cross-modal similarity matching and baselines that recast T2I retrieval as text-to-text similarity matching, improving nDCG@30 by 0.125 on average with CLIP as the retriever and by 0.121 with E5-V. For downstream question answering, VisRet increases accuracy on Visual-RAG and Visual-RAG-ME by 3.8% and 15.7% in top-1 retrieval, and by 3.9% and 11.1% in top-10 retrieval. Ablation studies show compatibility with different T2I instruction LLMs, T2I generation models, and downstream LLMs. VisRet provides a simple yet effective perspective for advancing in text-image retrieval. Our code and the new benchmark are publicly available at https://github.com/xiaowu0162/Visualize-then-Retrieve.","authors":["Di Wu","Yixin Wan","Kai-Wei Chang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03233v1","updated":"2026-01-06T18:24:41Z","published":"2026-01-06T18:24:41Z","title":"LTX-2: Efficient Joint Audio-Visual Foundation Model","summary":"Recent text-to-video diffusion models can generate compelling video sequences, yet they remain silent -- missing the semantic, emotional, and atmospheric cues that audio provides. We introduce LTX-2, an open-source foundational model capable of generating high-quality, temporally synchronized audiovisual content in a unified manner. LTX-2 consists of an asymmetric dual-stream transformer with a 14B-parameter video stream and a 5B-parameter audio stream, coupled through bidirectional audio-video cross-attention layers with temporal positional embeddings and cross-modality AdaLN for shared timestep conditioning. This architecture enables efficient training and inference of a unified audiovisual model while allocating more capacity for video generation than audio generation. We employ a multilingual text encoder for broader prompt understanding and introduce a modality-aware classifier-free guidance (modality-CFG) mechanism for improved audiovisual alignment and controllability. Beyond generating speech, LTX-2 produces rich, coherent audio tracks that follow the characters, environment, style, and emotion of each scene -- complete with natural background and foley elements. In our evaluations, the model achieves state-of-the-art audiovisual quality and prompt adherence among open-source systems, while delivering results comparable to proprietary models at a fraction of their computational cost and inference time. All model weights and code are publicly released.","authors":["Yoav HaCohen","Benny Brazowski","Nisan Chiprut","Yaki Bitterman","Andrew Kvochko","Avishai Berkowitz","Daniel Shalem","Daphna Lifschitz","Dudu Moshe","Eitan Porat","Eitan Richardson","Guy Shiran","Itay Chachy","Jonathan Chetboun","Michael Finkelson","Michael Kupchick","Nir Zabari","Nitzan Guetta","Noa Kotler","Ofir Bibi","Ori Gordon","Poriya Panet","Roi Benita","Shahar Armon","Victor Kulikov","Yaron Inger","Yonatan Shiftan","Zeev Melumian","Zeev Farbman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.17394v4","updated":"2026-01-06T17:49:44Z","published":"2025-08-24T15:06:20Z","title":"LVLM-Aware Multimodal Retrieval for RAG-Based Medical Diagnosis with General-Purpose Models","summary":"Retrieving visual and textual information from medical literature and hospital records can enhance diagnostic accuracy for clinical image interpretation. However, multimodal retrieval-augmented diagnosis is highly challenging. We explore a lightweight mechanism for enhancing diagnostic performance of retrieval-augmented LVLMs. We train a lightweight LVLM-aware multimodal retriever, such that the retriever learns to return images and texts that guide the LVLM toward correct predictions. In our low-resource setting, we perform only lightweight fine-tuning with small amounts of data, and use only general-purpose backbone models, achieving competitive results in clinical classification and VQA tasks compared to medically pre-trained models with extensive training. In a novel analysis, we highlight a previously unexplored class of errors that we term inconsistent retrieval predictions: cases where different top-retrieved images yield different predictions for the same target. We find that these cases are challenging for all models, even for non-retrieval models, and that our retrieval optimization mechanism significantly improves these cases over standard RAG. However, our analysis also sheds light on gaps in the ability of LVLMs to utilize retrieved information for clinical predictions. Code and models available at: https://github.com/Nirmaz/JOMED.","authors":["Nir Mazor","Tom Hope"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03331v1","updated":"2026-01-06T17:45:26Z","published":"2026-01-06T17:45:26Z","title":"MMErroR: A Benchmark for Erroneous Reasoning in Vision-Language Models","summary":"Recent advances in Vision-Language Models (VLMs) have improved performance in multi-modal learning, raising the question of whether these models truly understand the content they process. Crucially, can VLMs detect when a reasoning process is wrong and identify its error type? To answer this, we present MMErroR, a multi-modal benchmark of 2,013 samples, each embedding a single coherent reasoning error. These samples span 24 subdomains across six top-level domains, ensuring broad coverage and taxonomic richness. Unlike existing benchmarks that focus on answer correctness, MMErroR targets a process-level, error-centric evaluation that requires models to detect incorrect reasoning and classify the error type within both visual and linguistic contexts. We evaluate 20 advanced VLMs, even the best model (Gemini-3.0-Pro) classifies the error in only 66.47\\% of cases, underscoring the challenge of identifying erroneous reasoning. Furthermore, the ability to accurately identify errors offers valuable insights into the capabilities of multi-modal reasoning models. Project Page: https://mmerror-benchmark.github.io","authors":["Yang Shi","Yifeng Xie","Minzhe Guo","Liangsi Lu","Mingxuan Huang","Jingchao Wang","Zhihong Zhu","Boyan Xu","Zhiqi Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11093v2","updated":"2026-01-06T17:32:00Z","published":"2025-11-14T09:11:41Z","title":"Machine-Learning Based Detection of Coronary Artery Calcification Using Synthetic Chest X-Rays","summary":"Coronary artery calcification (CAC) is a strong predictor of cardiovascular events, with CT-based Agatston scoring widely regarded as the clinical gold standard. However, CT is costly and impractical for large-scale screening, while chest X-rays (CXRs) are inexpensive but lack reliable ground truth labels, constraining deep learning development. Digitally reconstructed radiographs (DRRs) offer a scalable alternative by projecting CT volumes into CXR-like images while inheriting precise labels. In this work, we provide the first systematic evaluation of DRRs as a surrogate training domain for CAC detection. Using 667 CT scans from the COCA dataset, we generate synthetic DRRs and assess model capacity, super-resolution fidelity enhancement, preprocessing, and training strategies. Lightweight CNNs trained from scratch outperform large pretrained networks; pairing super-resolution with contrast enhancement yields significant gains; and curriculum learning stabilises training under weak supervision. Our best configuration achieves a mean AUC of 0.754, comparable to or exceeding prior CXR-based studies. These results establish DRRs as a scalable, label-rich foundation for CAC detection, while laying the foundation for future transfer learning and domain adaptation to real CXRs.","authors":["Dylan Saeed","Ramtin Gharleghi","Susann Beier","Sonit Singh"],"pdf_url":"","comment":"10 pages, 5 figures. Under review for MIDL 2026"},{"id":"http://arxiv.org/abs/2512.20260v2","updated":"2026-01-06T17:16:18Z","published":"2025-12-23T11:16:16Z","title":"D^3ETOR: Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations","summary":"Weakly-Supervised Camouflaged Object Detection (WSCOD) aims to locate and segment objects that are visually concealed within their surrounding scenes, relying solely on sparse supervision such as scribble annotations. Despite recent progress, existing WSCOD methods still lag far behind fully supervised ones due to two major limitations: (1) the pseudo masks generated by general-purpose segmentation models (e.g., SAM) and filtered via rules are often unreliable, as these models lack the task-specific semantic understanding required for effective pseudo labeling in COD; and (2) the neglect of inherent annotation bias in scribbles, which hinders the model from capturing the global structure of camouflaged objects. To overcome these challenges, we propose ${D}^{3}$ETOR, a two-stage WSCOD framework consisting of Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing. In the first stage, we introduce an adaptive entropy-driven point sampling method and a multi-agent debate mechanism to enhance the capability of SAM for COD, improving the interpretability and precision of pseudo masks. In the second stage, we design FADeNet, which progressively fuses multi-level frequency-aware features to balance global semantic understanding with local detail modeling, while dynamically reweighting supervision strength across regions to alleviate scribble bias. By jointly exploiting the supervision signals from both the pseudo masks and scribble semantics, ${D}^{3}$ETOR significantly narrows the gap between weakly and fully supervised COD, achieving state-of-the-art performance on multiple benchmarks.","authors":["Jiawei Ge","Jiuxin Cao","Xinyi Li","Xuelin Zhu","Chang Liu","Bo Liu","Chen Feng","Ioannis Patras"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.20234v4","updated":"2026-01-06T17:16:02Z","published":"2025-09-24T15:24:43Z","title":"ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression","summary":"The hypothesis that Convolutional Neural Networks (CNNs) are inherently texture-biased has shaped much of the discourse on feature use in deep learning. We revisit this hypothesis by examining limitations in the cue-conflict experiment by Geirhos et al. To address these limitations, we propose a domain-agnostic framework that quantifies feature reliance through systematic suppression of shape, texture, and color cues, avoiding the confounds of forced-choice conflicts. By evaluating humans and neural networks under controlled suppression conditions, we find that CNNs are not inherently texture-biased but predominantly rely on local shape features. Nonetheless, this reliance can be substantially mitigated through modern training strategies or architectures (ConvNeXt, ViTs). We further extend the analysis across computer vision, medical imaging, and remote sensing, revealing that reliance patterns differ systematically: computer vision models prioritize shape, medical imaging models emphasize color, and remote sensing models exhibit a stronger reliance on texture. Code is available at https://github.com/tomburgert/feature-reliance.","authors":["Tom Burgert","Oliver Stoll","Paolo Rota","Begüm Demir"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 (oral)"},{"id":"http://arxiv.org/abs/2601.03193v1","updated":"2026-01-06T17:15:50Z","published":"2026-01-06T17:15:50Z","title":"UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision","summary":"While Unified Multimodal Models (UMMs) have achieved remarkable success in cross-modal comprehension, a significant gap persists in their ability to leverage such internal knowledge for high-quality generation. We formalize this discrepancy as Conduction Aphasia, a phenomenon where models accurately interpret multimodal inputs but struggle to translate that understanding into faithful and controllable synthesis. To address this, we propose UniCorn, a simple yet elegant self-improvement framework that eliminates the need for external data or teacher supervision. By partitioning a single UMM into three collaborative roles: Proposer, Solver, and Judge, UniCorn generates high-quality interactions via self-play and employs cognitive pattern reconstruction to distill latent understanding into explicit generative signals. To validate the restoration of multimodal coherence, we introduce UniCycle, a cycle-consistency benchmark based on a Text to Image to Text reconstruction loop. Extensive experiments demonstrate that UniCorn achieves comprehensive and substantial improvements over the base model across six general image generation benchmarks. Notably, it achieves SOTA performance on TIIF(73.8), DPG(86.8), CompBench(88.5), and UniCycle while further delivering substantial gains of +5.0 on WISE and +6.5 on OneIG. These results highlight that our method significantly enhances T2I generation while maintaining robust comprehension, demonstrating the scalability of fully self-supervised refinement for unified multimodal intelligence.","authors":["Ruiyan Han","Zhen Fang","XinYu Sun","Yuchen Ma","Ziheng Wang","Yu Zeng","Zehui Chen","Lin Chen","Wenxuan Huang","Wei-Jie Xu","Yi Cao","Feng Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03191v1","updated":"2026-01-06T17:13:23Z","published":"2026-01-06T17:13:23Z","title":"AnatomiX, an Anatomy-Aware Grounded Multimodal Large Language Model for Chest X-Ray Interpretation","summary":"Multimodal medical large language models have shown impressive progress in chest X-ray interpretation but continue to face challenges in spatial reasoning and anatomical understanding. Although existing grounding techniques improve overall performance, they often fail to establish a true anatomical correspondence, resulting in incorrect anatomical understanding in the medical domain. To address this gap, we introduce AnatomiX, a multitask multimodal large language model explicitly designed for anatomically grounded chest X-ray interpretation. Inspired by the radiological workflow, AnatomiX adopts a two stage approach: first, it identifies anatomical structures and extracts their features, and then leverages a large language model to perform diverse downstream tasks such as phrase grounding, report generation, visual question answering, and image understanding. Extensive experiments across multiple benchmarks demonstrate that AnatomiX achieves superior anatomical reasoning and delivers over 25% improvement in performance on anatomy grounding, phrase grounding, grounded diagnosis and grounded captioning tasks compared to existing approaches. Code and pretrained model are available at https://github.com/aneesurhashmi/anatomix","authors":["Anees Ur Rehman Hashmi","Numan Saeed","Christoph Lippert"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03181v1","updated":"2026-01-06T16:59:29Z","published":"2026-01-06T16:59:29Z","title":"Multi-Modal Data-Enhanced Foundation Models for Prediction and Control in Wireless Networks: A Survey","summary":"Foundation models (FMs) are recognized as a transformative breakthrough that has started to reshape the future of artificial intelligence (AI) across both academia and industry. The integration of FMs into wireless networks is expected to enable the development of general-purpose AI agents capable of handling diverse network management requests and highly complex wireless-related tasks involving multi-modal data. Inspired by these ideas, this work discusses the utilization of FMs, especially multi-modal FMs in wireless networks. We focus on two important types of tasks in wireless network management: prediction tasks and control tasks. In particular, we first discuss FMs-enabled multi-modal contextual information understanding in wireless networks. Then, we explain how FMs can be applied to prediction and control tasks, respectively. Following this, we introduce the development of wireless-specific FMs from two perspectives: available datasets for development and the methodologies used. Finally, we conclude with a discussion of the challenges and future directions for FM-enhanced wireless networks.","authors":["Han Zhang","Mohammad Farzanullah","Mohammad Ghassemi","Akram Bin Sediq","Ali Afana","Melike Erol-Kantarci"],"pdf_url":"","comment":"5 figures, 7 tables, IEEE COMST"},{"id":"http://arxiv.org/abs/2601.03178v1","updated":"2026-01-06T16:55:55Z","published":"2026-01-06T16:55:55Z","title":"DiffBench Meets DiffAgent: End-to-End LLM-Driven Diffusion Acceleration Code Generation","summary":"Diffusion models have achieved remarkable success in image and video generation. However, their inherently multiple step inference process imposes substantial computational overhead, hindering real-world deployment. Accelerating diffusion models is therefore essential, yet determining how to combine multiple model acceleration techniques remains a significant challenge. To address this issue, we introduce a framework driven by large language models (LLMs) for automated acceleration code generation and evaluation. First, we present DiffBench, a comprehensive benchmark that implements a three stage automated evaluation pipeline across diverse diffusion architectures, optimization combinations and deployment scenarios. Second, we propose DiffAgent, an agent that generates optimal acceleration strategies and codes for arbitrary diffusion models. DiffAgent employs a closed-loop workflow in which a planning component and a debugging component iteratively refine the output of a code generation component, while a genetic algorithm extracts performance feedback from the execution environment to guide subsequent code refinements. We provide a detailed explanation of the DiffBench construction and the design principles underlying DiffAgent. Extensive experiments show that DiffBench offers a thorough evaluation of generated codes and that DiffAgent significantly outperforms existing LLMs in producing effective diffusion acceleration strategies.","authors":["Jiajun jiao","Haowei Zhu","Puyuan Yang","Jianghui Wang","Ji Liu","Ziqiong Liu","Dong Li","Yuejian Fang","Junhai Yong","Bin Wang","Emad Barsoum"],"pdf_url":"","comment":"Accepted to AAAI 2026"}],"Image and Video Processing":[{"id":"http://arxiv.org/abs/2601.03410v1","updated":"2026-01-06T20:52:12Z","published":"2026-01-06T20:52:12Z","title":"Inferring Clinically Relevant Molecular Subtypes of Pancreatic Cancer from Routine Histopathology Using Deep Learning","summary":"Molecular subtyping of PDAC into basal-like and classical has established prognostic and predictive value. However, its use in clinical practice is limited by cost, turnaround time, and tissue requirements, thereby restricting its application in the management of PDAC. We introduce PanSubNet, an interpretable deep learning framework that predicts therapy-relevant molecular subtypes directly from standard H&E-stained WSIs. PanSubNet was developed using data from 1,055 patients across two multi-institutional cohorts (PANCAN, n=846; TCGA, n=209) with paired histology and RNA-seq data. Ground-truth labels were derived using the validated Moffitt 50-gene signature refined by GATA6 expression. The model employs dual-scale architecture that fuses cellular-level morphology with tissue-level architecture, leveraging attention mechanisms for multi-scale representation learning and transparent feature attribution. On internal validation within PANCAN using five-fold cross-validation, PanSubNet achieved mean AUC of 88.5% with balanced sensitivity and specificity. External validation on the independent TCGA cohort without fine-tuning demonstrated robust generalizability (AUC 84.0%). PanSubNet preserved and, in metastatic disease, strengthened prognostic stratification compared to RNA-seq based labels. Prediction uncertainty linked to intermediate transcriptional states, not classification noise. Model predictions are aligned with established transcriptomic programs, differentiation markers, and DNA damage repair signatures. By enabling rapid, cost-effective molecular stratification from routine H&E-stained slides, PanSubNet offers a clinically deployable and interpretable tool for genetic subtyping. We are gathering data from two institutions to validate and assess real-world performance, supporting integration into digital pathology workflows and advancing precision oncology for PDAC.","authors":["Abdul Rehman Akbar","Alejandro Levya","Ashwini Esnakula","Elshad Hasanov","Anne Noonan","Upender Manne","Vaibhav Sahai","Lingbin Meng","Susan Tsai","Anil Parwani","Wei Chen","Ashish Manne","Muhammad Khalid Khan Niazi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03391v1","updated":"2026-01-06T19:56:16Z","published":"2026-01-06T19:56:16Z","title":"Edit2Restore:Few-Shot Image Restoration via Parameter-Efficient Adaptation of Pre-trained Editing Models","summary":"Image restoration has traditionally required training specialized models on thousands of paired examples per degradation type. We challenge this paradigm by demonstrating that powerful pre-trained text-conditioned image editing models can be efficiently adapted for multiple restoration tasks through parameter-efficient fine-tuning with remarkably few examples. Our approach fine-tunes LoRA adapters on FLUX.1 Kontext, a state-of-the-art 12B parameter flow matching model for image-to-image translation, using only 16-128 paired images per task, guided by simple text prompts that specify the restoration operation. Unlike existing methods that train specialized restoration networks from scratch with thousands of samples, we leverage the rich visual priors already encoded in large-scale pre-trained editing models, dramatically reducing data requirements while maintaining high perceptual quality. A single unified LoRA adapter, conditioned on task-specific text prompts, effectively handles multiple degradations including denoising, deraining, and dehazing. Through comprehensive ablation studies, we analyze: (i) the impact of training set size on restoration quality, (ii) trade-offs between task-specific versus unified multi-task adapters, (iii) the role of text encoder fine-tuning, and (iv) zero-shot baseline performance. While our method prioritizes perceptual quality over pixel-perfect reconstruction metrics like PSNR/SSIM, our results demonstrate that pre-trained image editing models, when properly adapted, offer a compelling and data-efficient alternative to traditional image restoration approaches, opening new avenues for few-shot, prompt-guided image enhancement. The code to reproduce our results are available at: https://github.com/makinyilmaz/Edit2Restore","authors":["M. Akın Yılmaz","Ahmet Bilican","Burak Can Biner","A. Murat Tekalp"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03244v1","updated":"2026-01-06T18:40:50Z","published":"2026-01-06T18:40:50Z","title":"Self-Supervised Learning from Noisy and Incomplete Data","summary":"Many important problems in science and engineering involve inferring a signal from noisy and/or incomplete observations, where the observation process is known. Historically, this problem has been tackled using hand-crafted regularization (e.g., sparsity, total-variation) to obtain meaningful estimates. Recent data-driven methods often offer better solutions by directly learning a solver from examples of ground-truth signals and associated observations. However, in many real-world applications, obtaining ground-truth references for training is expensive or impossible. Self-supervised learning methods offer a promising alternative by learning a solver from measurement data alone, bypassing the need for ground-truth references. This manuscript provides a comprehensive summary of different self-supervised methods for inverse problems, with a special emphasis on their theoretical underpinnings, and presents practical applications in imaging inverse problems.","authors":["Julián Tachella","Mike Davies"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03237v1","updated":"2026-01-06T18:30:25Z","published":"2026-01-06T18:30:25Z","title":"PET-TURTLE: Deep Unsupervised Support Vector Machines for Imbalanced Data Clusters","summary":"Foundation vision, audio, and language models enable zero-shot performance on downstream tasks via their latent representations. Recently, unsupervised learning of data group structure with deep learning methods has gained popularity. TURTLE, a state of the art deep clustering algorithm, uncovers data labeling without supervision by alternating label and hyperplane updates, maximizing the hyperplane margin, in a similar fashion to support vector machines (SVMs). However, TURTLE assumes clusters are balanced; when data is imbalanced, it yields non-ideal hyperplanes that cause higher clustering error. We propose PET-TURTLE, which generalizes the cost function to handle imbalanced data distributions by a power law prior. Additionally, by introducing sparse logits in the labeling process, PET-TURTLE optimizes a simpler search space that in turn improves accuracy for balanced datasets. Experiments on synthetic and real data show that PET-TURTLE improves accuracy for imbalanced sources, prevents over-prediction of minority clusters, and enhances overall clustering.","authors":["Javier Salazar Cavazos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03112v1","updated":"2026-01-06T15:42:45Z","published":"2026-01-06T15:42:45Z","title":"DiT-JSCC: Rethinking Deep JSCC with Diffusion Transformers and Semantic Representations","summary":"Generative joint source-channel coding (GJSCC) has emerged as a new Deep JSCC paradigm for achieving high-fidelity and robust image transmission under extreme wireless channel conditions, such as ultra-low bandwidth and low signal-to-noise ratio. Recent studies commonly adopt diffusion models as generative decoders, but they frequently produce visually realistic results with limited semantic consistency. This limitation stems from a fundamental mismatch between reconstruction-oriented JSCC encoders and generative decoders, as the former lack explicit semantic discriminability and fail to provide reliable conditional cues. In this paper, we propose DiT-JSCC, a novel GJSCC backbone that can jointly learn a semantics-prioritized representation encoder and a diffusion transformer (DiT) based generative decoder, our open-source project aims to promote the future research in GJSCC. Specifically, we design a semantics-detail dual-branch encoder that aligns naturally with a coarse-to-fine conditional DiT decoder, prioritizing semantic consistency under extreme channel conditions. Moreover, a training-free adaptive bandwidth allocation strategy inspired by Kolmogorov complexity is introduced to further improve the transmission efficiency, thereby indeed redefining the notion of information value in the era of generative decoding. Extensive experiments demonstrate that DiT-JSCC consistently outperforms existing JSCC methods in both semantic consistency and visual quality, particularly in extreme regimes.","authors":["Kailin Tan","Jincheng Dai","Sixian Wang","Guo Lu","Shuo Shao","Kai Niu","Wenjun Zhang","Ping Zhang"],"pdf_url":"","comment":"14pages, 14figures, 2tables"},{"id":"http://arxiv.org/abs/2601.02864v1","updated":"2026-01-06T09:52:00Z","published":"2026-01-06T09:52:00Z","title":"Lesion Segmentation in FDG-PET/CT Using Swin Transformer U-Net 3D: A Robust Deep Learning Framework","summary":"Accurate and automated lesion segmentation in Positron Emission Tomography / Computed Tomography (PET/CT) imaging is essential for cancer diagnosis and therapy planning. This paper presents a Swin Transformer UNet 3D (SwinUNet3D) framework for lesion segmentation in Fluorodeoxyglucose Positron Emission Tomography / Computed Tomography (FDG-PET/CT) scans. By combining shifted window self-attention with U-Net style skip connections, the model captures both global context and fine anatomical detail. We evaluate SwinUNet3D on the AutoPET III FDG dataset and compare it against a baseline 3D U-Net. Results show that SwinUNet3D achieves a Dice score of 0.88 and IoU of 0.78, surpassing 3D U-Net (Dice 0.48, IoU 0.32) while also delivering faster inference times. Qualitative analysis demonstrates improved detection of small and irregular lesions, reduced false positives, and more accurate PET/CT fusion. While the framework is currently limited to FDG scans and trained under modest GPU resources, it establishes a strong foundation for future multi-tracer, multi-center evaluations and benchmarking against other transformer-based architectures. Overall, SwinUNet3D represents an efficient and robust approach to PET/CT lesion segmentation, advancing the integration of transformer-based models into oncology imaging workflows.","authors":["Shovini Guha","Dwaipayan Nandi"],"pdf_url":"","comment":"8 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2512.21988v2","updated":"2026-01-06T09:38:37Z","published":"2025-12-26T11:19:25Z","title":"The Color-Clinical Decoupling: Why Perceptual Calibration Fails Clinical Biomarkers in Smartphone Dermatology","summary":"Smartphone-based tele-dermatology assumes that colorimetric calibration ensures clinical reliability, yet this remains untested for underrepresented skin phototypes. We investigated whether standard calibration translates to reliable clinical biomarkers using 43,425 images from 965 Korean subjects (Fitzpatrick III-IV) across DSLR, tablet, and smartphone devices. While Linear Color Correction Matrix (CCM) normalization reduced color error by 67-77% -- achieving near-clinical accuracy (Delta E < 2.3) -- this success did not translate to biomarker reliability.\n  We identify a phenomenon termed \"color-clinical decoupling\": despite perceptual accuracy, the Individual Typology Angle (ITA) showed poor inter-device agreement (ICC = 0.40), while the Melanin Index achieved good agreement (ICC = 0.77). This decoupling is driven by the ITA formula's sensitivity to b* channel noise and is further compounded by anatomical variance. Facial region accounts for 25.2% of color variance -- 3.6x greater than device effects (7.0%) -- challenging the efficacy of single-patch calibration. Our results demonstrate that current colorimetric standards are insufficient for clinical-grade biomarker extraction, necessitating region-aware protocols for mobile dermatology.","authors":["Sungwoo Kang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2102.02115v5","updated":"2026-01-06T09:29:33Z","published":"2021-02-03T15:48:22Z","title":"TEyeD: Over 20 million real-world eye images with Pupil, Eyelid, and Iris 2D and 3D Segmentations, 2D and 3D Landmarks, 3D Eyeball, Gaze Vector, and Eye Movement Types","summary":"We present TEyeD, the world's largest unified public data set of eye images taken with head-mounted devices. TEyeD was acquired with seven different head-mounted eye trackers. Among them, two eye trackers were integrated into virtual reality (VR) or augmented reality (AR) devices. The images in TEyeD were obtained from various tasks, including car rides, simulator rides, outdoor sports activities, and daily indoor activities. The data set includes 2D and 3D landmarks, semantic segmentation, 3D eyeball annotation and the gaze vector and eye movement types for all images. Landmarks and semantic segmentation are provided for the pupil, iris and eyelids. Video lengths vary from a few minutes to several hours. With more than 20 million carefully annotated images, TEyeD provides a unique, coherent resource and a valuable foundation for advancing research in the field of computer vision, eye tracking and gaze estimation in modern VR and AR applications. Download: https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FTEyeDS&mode=list Alternative Download: https://hctlsrva.edu.sot.tum.de/TEyeDS/","authors":["Wolfgang Fuhl","Gjergji Kasneci","Enkelejda Kasneci"],"pdf_url":"","comment":"Download: https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FTEyeDS&mode=list Alternative Download: https://hctlsrva.edu.sot.tum.de/TEyeDS/"},{"id":"http://arxiv.org/abs/2601.02712v1","updated":"2026-01-06T04:59:11Z","published":"2026-01-06T04:59:11Z","title":"Transform and Entropy Coding in AV2","summary":"AV2 is the successor to the AV1 royalty-free video coding standard developed by the Alliance for Open Media (AOMedia). Its primary objective is to deliver substantial compression gains and subjective quality improvements while maintaining low-complexity encoder and decoder operations. This paper describes the transform, quantization and entropy coding design in AV2, including redesigned transform kernels and data-driven transforms, expanded transform partitioning, and a mode & coefficient dependent transform signaling. AV2 introduces several new coding tools including Intra/Inter Secondary Transforms (IST), Trellis Coded Quantization (TCQ), Adaptive Transform Coding (ATC), Probability Adaptation Rate Adjustment (PARA), Forward Skip Coding (FSC), Cross Chroma Component Transforms (CCTX), Parity Hiding (PH) tools and improved lossless coding. These advances enable AV2 to deliver the highest quality video experience for video applications at a significantly reduced bitrate.","authors":["Alican Nalci","Hilmi E. Egilmez","Madhu P. Krishnan","Keng-Shih Lu","Joe Young","Debargha Mukherjee","Lin Zheng","Jingning Han","Joel Sole","Xin Zhao","Tianqi Liu","Liang Zhao","Todd Nguyen","Urvang Joshi","Kruthika Koratti Sivakumar","Luhang Xu","Zhijun Lei","Yue Yu","Aki Kuusela","Minhua Zhou","Andrey Norkin","Adrian Grange"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10196v3","updated":"2026-01-06T03:09:30Z","published":"2025-08-13T21:02:38Z","title":"Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks","summary":"Early detection of lung cancer is critical to improving survival outcomes. We present a deep learning framework for automated lung cancer screening from chest computed tomography (CT) images with integrated explainability. Using the IQ-OTH/NCCD dataset (1,197 scans across Normal, Benign, and Malignant classes), we evaluate a custom convolutional neural network (CNN) and three fine-tuned transfer learning backbones: DenseNet121, ResNet152, and VGG19. Models are trained with cost-sensitive learning to mitigate class imbalance and evaluated via accuracy, precision, recall, F1-score, and ROC-AUC. While ResNet152 achieved the highest accuracy (97.3%), DenseNet121 provided the best overall balance in precision, recall, and F1 (up to 92%, 90%, 91%, respectively). We further apply Shapley Additive Explanations (SHAP) to visualize evidence contributing to predictions, improving clinical transparency. Results indicate that CNN-based approaches augmented with explainability can provide fast, accurate, and interpretable support for lung cancer screening, particularly in resource-limited settings.","authors":["Nishan Rai","Sujan Khatri","Devendra Risal"],"pdf_url":"","comment":"11 pages, 9 figures, 4 tables. Undergraduate research project report"}],"Graphics":[{"id":"http://arxiv.org/abs/2601.03357v1","updated":"2026-01-06T19:01:07Z","published":"2026-01-06T19:01:07Z","title":"RelightAnyone: A Generalized Relightable 3D Gaussian Head Model","summary":"3D Gaussian Splatting (3DGS) has become a standard approach to reconstruct and render photorealistic 3D head avatars. A major challenge is to relight the avatars to match any scene illumination. For high quality relighting, existing methods require subjects to be captured under complex time-multiplexed illumination, such as one-light-at-a-time (OLAT). We propose a new generalized relightable 3D Gaussian head model that can relight any subject observed in a single- or multi-view images without requiring OLAT data for that subject. Our core idea is to learn a mapping from flat-lit 3DGS avatars to corresponding relightable Gaussian parameters for that avatar. Our model consists of two stages: a first stage that models flat-lit 3DGS avatars without OLAT lighting, and a second stage that learns the mapping to physically-based reflectance parameters for high-quality relighting. This two-stage design allows us to train the first stage across diverse existing multi-view datasets without OLAT lighting ensuring cross-subject generalization, where we learn a dataset-specific lighting code for self-supervised lighting alignment. Subsequently, the second stage can be trained on a significantly smaller dataset of subjects captured under OLAT illumination. Together, this allows our method to generalize well and relight any subject from the first stage as if we had captured them under OLAT lighting. Furthermore, we can fit our model to unseen subjects from as little as a single image, allowing several applications in novel view synthesis and relighting for digital avatars.","authors":["Yingyan Xu","Pramod Rao","Sebastian Weiss","Gaspard Zoss","Markus Gross","Christian Theobalt","Marc Habermann","Derek Bradley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03114v1","updated":"2026-01-06T15:44:18Z","published":"2026-01-06T15:44:18Z","title":"Stroke Patches: Customizable Artistic Image Styling Using Regression","summary":"We present a novel, regression-based method for artistically styling images. Unlike recent neural style transfer or diffusion-based approaches, our method allows for explicit control over the stroke composition and level of detail in the rendered image through the use of an extensible set of stroke patches. The stroke patch sets are procedurally generated by small programs that control the shape, size, orientation, density, color, and noise level of the strokes in the individual patches. Once trained on a set of stroke patches, a U-Net based regression model can render any input image in a variety of distinct, evocative and customizable styles.","authors":["Ian Jaffray","John Bronskill"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03319v1","updated":"2026-01-06T13:56:28Z","published":"2026-01-06T13:56:28Z","title":"CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature","summary":"A photorealistic and controllable 3D caricaturization framework for faces is introduced. We start with an intrinsic Gaussian curvature-based surface exaggeration technique, which, when coupled with texture, tends to produce over-smoothed renders. To address this, we resort to 3D Gaussian Splatting (3DGS), which has recently been shown to produce realistic free-viewpoint avatars. Given a multiview sequence, we extract a FLAME mesh, solve a curvature-weighted Poisson equation, and obtain its exaggerated form. However, directly deforming the Gaussians yields poor results, necessitating the synthesis of pseudo-ground-truth caricature images by warping each frame to its exaggerated 2D representation using local affine transformations. We then devise a training scheme that alternates real and synthesized supervision, enabling a single Gaussian collection to represent both natural and exaggerated avatars. This scheme improves fidelity, supports local edits, and allows continuous control over the intensity of the caricature. In order to achieve real-time deformations, an efficient interpolation between the original and exaggerated surfaces is introduced. We further analyze and show that it has a bounded deviation from closed-form solutions. In both quantitative and qualitative evaluations, our results outperform prior work, delivering photorealistic, geometry-controlled caricature avatars.","authors":["Eldad Matmon","Amit Bracha","Noam Rotstein","Ron Kimmel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02829v1","updated":"2026-01-06T09:01:16Z","published":"2026-01-06T09:01:16Z","title":"Resolution deficits drive simulator sickness and compromise reading performance in virtual environments","summary":"Extended reality (XR) is evolving into a general-purpose computing platform, yet its adoption for productivity is hindered by visual fatigue and simulator sickness. While these symptoms are often attributed to latency or motion conflicts, the precise impact of textual clarity on physiological comfort remains undefined. Here we show that sub-optimal effective resolution, the clarity that reaches the eye after the full display-optics-rendering pipeline, is a primary driver of simulator sickness during reading tasks in both virtual reality and video see-through environments. By systematically manipulating end-to-end effective resolution on a unified logMAR scale, we measured reading psychophysics and sickness symptoms in a controlled within-subjects study. We find that reading performance and user comfort degrade exponentially as resolution drops below 0 logMAR (normal visual acuity). Notably, our results reveal 0 logMAR as a key physiological tipping point: resolutions better than this threshold yield naked-eye-level performance with minimal sickness, whereas poorer resolutions trigger rapid, non-linear increases in nausea and oculomotor strain. These findings suggest that the cognitive and perceptual effort required to resolve blurry text directly compromises user comfort, establishing human-eye resolution as a critical baseline for the design of future ergonomic XR systems.","authors":["Jialin Wang","Xinru Cheng","Boyong Hou","Hai-Ning Liang"],"pdf_url":"","comment":"18 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2601.02805v1","updated":"2026-01-06T08:28:23Z","published":"2026-01-06T08:28:23Z","title":"The perceptual gap between video see-through displays and natural human vision","summary":"Video see-through (VST) technology aims to seamlessly blend virtual and physical worlds by reconstructing reality through cameras. While manufacturers promise perceptual fidelity, it remains unclear how close these systems are to replicating natural human vision across varying environmental conditions. In this work, we quantify the perceptual gap between the human eye and different popular VST headsets (Apple Vision Pro, Meta Quest 3, Quest Pro) using psychophysical measures of visual acuity, contrast sensitivity, and color vision. We show that despite hardware advancements, all tested VST systems fail to match the dynamic range and adaptability of the naked eye. While high-end devices approach human performance in ideal lighting, they exhibit significant degradation in low-light conditions, particularly in contrast sensitivity and acuity. Our results map the physiological limitations of digital reality reconstruction, establishing a specific perceptual gap that defines the roadmap for achieving indistinguishable VST experiences.","authors":["Jialin Wang","Songming Ping","Kemu Xu","Yue Li","Hai-Ning Liang"],"pdf_url":"","comment":"19 pages, 9 figures, 4 tables"},{"id":"http://arxiv.org/abs/2601.03323v1","updated":"2026-01-06T14:59:22Z","published":"2026-01-06T14:59:22Z","title":"Listen to Rhythm, Choose Movements: Autoregressive Multimodal Dance Generation via Diffusion and Mamba with Decoupled Dance Dataset","summary":"Advances in generative models and sequence learning have greatly promoted research in dance motion generation, yet current methods still suffer from coarse semantic control and poor coherence in long sequences. In this work, we present Listen to Rhythm, Choose Movements (LRCM), a multimodal-guided diffusion framework supporting both diverse input modalities and autoregressive dance motion generation. We explore a feature decoupling paradigm for dance datasets and generalize it to the Motorica Dance dataset, separating motion capture data, audio rhythm, and professionally annotated global and local text descriptions. Our diffusion architecture integrates an audio-latent Conformer and a text-latent Cross-Conformer, and incorporates a Motion Temporal Mamba Module (MTMM) to enable smooth, long-duration autoregressive synthesis. Experimental results indicate that LRCM delivers strong performance in both functional capability and quantitative metrics, demonstrating notable potential in multimodal input scenarios and extended sequence generation. We will release the full codebase, dataset, and pretrained models publicly upon acceptance.","authors":["Oran Duan","Yinghua Shen","Yingzhu Lv","Luyang Jie","Yaxin Liu","Qiong Wu"],"pdf_url":"","comment":"12 pages, 13 figures"}],"Signal Processing":[{"id":"http://arxiv.org/abs/2501.13339v3","updated":"2026-01-06T23:26:54Z","published":"2025-01-23T02:39:34Z","title":"Joint Beamforming and Position Optimization for Fluid RIS-aided ISAC Systems","summary":"A fluid reconfigurable intelligent surface (fRIS)-aided integrated sensing and communication (ISAC) system is proposed to enhance multi-target sensing and multi-user communication. Unlike the conventional RIS, the fRIS employs movable elements with adjustable positions, offering additional spatial degrees of freedom. In this system, a joint optimization problem is formulated to minimize sensing beampattern mismatch and symbol estimation error. An algorithm based on alternating minimization is devised to handle the resultant non-convex problem, where the subproblems are solved via augmented Lagrangian method, quadratic programming, semidefinite relaxation, and majorization-minimization. A key challenge is that the element positions affect both incident and reflective channels, leading to the high-order composite objective functions. As a remedy, the high-order terms are transformed into linear and linear-difference forms by exploiting the structural characteristics of fRIS and the channels. Numerical results demonstrate the superiority of the proposed scheme over conventional RIS-aided ISAC and other benchmarks.","authors":["Junjie Ye","Peichang Zhang","Xiao-Peng Li","Lei Huang","Yuanwei Liu"],"pdf_url":"","comment":"13 pages, has submitted to an IEEE journal for possible publication"},{"id":"http://arxiv.org/abs/2601.03446v1","updated":"2026-01-06T22:18:17Z","published":"2026-01-06T22:18:17Z","title":"Energy Harvesting in High Altitude Platform Station Enabled Sensor Networks","summary":"High altitude platform station (HAPS) systems are becoming crucial facilitators for future wireless communication networks, enhancing connectivity across all vertical communication layers, including small Internet of Things (IoT) sensors and devices, terrestrial users, and aerial devices. In the context of the widely recognized vertical heterogeneous network (VHetNet) architecture, HAPS systems can provide service to both aerial and ground users. However, integrating HAPS systems as a core element in the VHetNet architecture presents a considerable energy challenge, marking a prominent constraint for their operation. Driven by this challenge, we introduce an energy harvesting (EH) strategy tailored for HAPS systems, enabling a HAPS system to gather energy from another HAPS system, which is not constrained by energy limitations. To assess the performance capabilities of the proposed model, we derive outage probability (OP), ergodic capacity (EC) and verify them by using Monte Carlo (MC) simulations. Moreover, we explore the system in terms of throughput. The findings reveal that harnessing full potential of EH stands as a viable approach to meet the energy demands of HAPS systems.","authors":["Melek Tuylu","Eylem Erdogan"],"pdf_url":"","comment":"PDF-only submission approved by arXiv support due to unresolved TeX compilation issues"},{"id":"http://arxiv.org/abs/2601.03443v1","updated":"2026-01-06T22:10:45Z","published":"2026-01-06T22:10:45Z","title":"Discriminating real and synthetic super-resolved audio samples using embedding-based classifiers","summary":"Generative adversarial networks (GANs) and diffusion models have recently achieved state-of-the-art performance in audio super-resolution (ADSR), producing perceptually convincing wideband audio from narrowband inputs. However, existing evaluations primarily rely on signal-level or perceptual metrics, leaving open the question of how closely the distributions of synthetic super-resolved and real wideband audio match. Here we address this problem by analyzing the separability of real and super-resolved audio in various embedding spaces. We consider both middle-band ($4\\to 16$~kHz) and full-band ($16\\to 48$~kHz) upsampling tasks for speech and music, training linear classifiers to distinguish real from synthetic samples based on multiple types of audio embeddings. Comparisons with objective metrics and subjective listening tests reveal that embedding-based classifiers achieve near-perfect separation, even when the generated audio attains high perceptual quality and state-of-the-art metric scores. This behavior is consistent across datasets and models, including recent diffusion-based approaches, highlighting a persistent gap between perceptual quality and true distributional fidelity in ADSR models.","authors":["Mikhail Silaev","Konstantinos Drossos","Tuomas Virtanen"],"pdf_url":"","comment":"Accepted for publication in Workshop Proceedingsof the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing"},{"id":"http://arxiv.org/abs/2601.03427v1","updated":"2026-01-06T21:32:16Z","published":"2026-01-06T21:32:16Z","title":"Foundation Model-Aided Hierarchical Control for Robust RIS-Assisted Near-Field Communications","summary":"The deployment of extremely large aperture arrays (ELAAs) in sixth-generation (6G) networks could shift communication into the near-field communication (NFC) regime. In this regime, signals exhibit spherical wave propagation, unlike the planar waves in conventional far-field systems. Reconfigurable intelligent surfaces (RISs) can dynamically adjust phase shifts to support NFC beamfocusing, concentrating signal energy at specific spatial coordinates. However, effective RIS utilization depends on both rapid channel state information (CSI) estimation and proactive blockage mitigation, which occur on inherently different timescales. CSI varies at millisecond intervals due to small-scale fading, while blockage events evolve over seconds, posing challenges for conventional single-level control algorithms. To address this issue, we propose a dual-transformer (DT) hierarchical framework that integrates two specialized transformer models within a hierarchical deep reinforcement learning (HDRL) architecture, referred to as the DT-HDRL framework. A fast-timescale transformer processes ray-tracing data for rapid CSI estimation, while a vision transformer (ViT) analyzes visual data to predict impending blockages. In HDRL, the high-level controller selects line-of-sight (LoS) or RIS-assisted non-line-of-sight (NLoS) transmission paths and sets goals, while the low-level controller optimizes base station (BS) beamfocusing and RIS phase shifts using instantaneous CSI. This dual-timescale coordination maximizes spectral efficiency (SE) while ensuring robust performance under dynamic conditions. Simulation results demonstrate that our approach improves SE by approximately 18% compared to single-timescale baselines, while the proposed blockage predictor achieves an F1-score of 0.92, providing a 769 ms advance warning window in dynamic scenarios.","authors":["Mohammad Ghassemi","Han Zhang","Ali Afana","Akram Bin Sediq","Melike Erol-Kantarci"],"pdf_url":"","comment":"12 pages, 8 figures,"},{"id":"http://arxiv.org/abs/2512.24583v2","updated":"2026-01-06T21:12:49Z","published":"2025-12-31T03:22:19Z","title":"Resource Allocation via Backscatter-Aware Transmit Antenna Selection for Low-PAPR and Ultra-Reliable WSNs","summary":"This paper addresses a fundamental physical layer conflict in hybrid Wireless Sensor Networks (WSNs) between high-throughput primary communication and the stringent power envelope requirements of passive backscatter sensors. We propose a Backscatter-Constrained Transmit Antenna Selection (BC-TAS) framework, a per-subcarrier selection strategy for multi-antenna illuminators operating within a Multi-Dimensional Orthogonal Frequency Division Multiplexing (MD-OFDM) architecture. Unlike conventional signal-to-noise ratio (SNR) centric selection schemes, BC-TAS employs a multi-objective cost function that jointly maximizes desired link reliability, stabilizes the incident RF energy envelope at passive Surface Acoustic Wave (SAW) sensors, and suppresses interference toward coexisting victim receivers. By exploiting the inherent sparsity of MD-OFDM, the proposed framework enables dual-envelope regulation, simultaneously reducing the transmitter Peak-to-Average Power Ratio (PAPR) and the Backscatter Crest Factor (BCF) observed at the tag. To enhance robustness under imperfect Channel State Information (CSI), a Kalman-based channel smoothing mechanism is incorporated to maintain selection stability in low-SNR regimes. Numerical results using IEEE 802.11be dispersive channel models and a nonlinear Rapp power amplifier demonstrate that BC-TAS achieves orders-of-magnitude improvement in outage probability and significant gains in energy efficiency compared to conventional MU-MIMO baselines, while ensuring spectral mask compliance under reduced power amplifier back-off. These results establish BC-TAS as an effective illuminator-side control mechanism for enabling reliable and energy-stable sensing and communication coexistence in dense, power-constrained wireless environments.","authors":["Rahul Gulia","Ashish Sheikh","Feyisayo Favour Popoola","Serisha Vadlamudi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03387v1","updated":"2026-01-06T19:48:34Z","published":"2026-01-06T19:48:34Z","title":"SEP Analysis of a Low-Resolution SIMO System with M-PSK over Fading Channels","summary":"In this paper, the average symbol error probability (SEP) of a phase-quantized single-input multiple-output (SIMO) system with M-ary phase-shift keying (PSK) modulation is analyzed under Rayleigh fading and additive white Gaussian noise. By leveraging a novel method, we derive exact SEP expressions for a quadrature PSK (QPSK)-modulated n-bit phase-quantized SIMO system with maximum ratio combining (SIMO-MRC), along with the corresponding high signal-to-noise ratio (SNR) characterizations in terms of diversity and coding gains. For a QPSK-modulated 2-bit phase-quantized SIMO system with selection combining, the diversity and coding gains are further obtained for an arbitrary number of receive antennas, complementing existing results. Interestingly, the proposed method also reveals a duality between a SIMO-MRC system and a phase-quantized multiple-input single-output (MISO) system with maximum ratio transmission, when the modulation order, phase-quantization resolution, antenna configuration, and the channel state information (CSI) conditions are reciprocal. This duality enables direct inference to obtain the diversity of a general M-PSK-modulated n-bit phase-quantized SIMO-MRC system, and extends the results to its MISO counterpart. All the above results have been obtained assuming perfect CSI at the receiver (CSIR). Finally, the SEP analysis of a QPSK-modulated 2-bit phase-quantized SIMO system is extended to the limited CSIR case, where the CSI at each receive antenna is represented by only 2 bits of channel phase information. In this scenario, the diversity gain is shown to be further halved in general.","authors":["Amila Ravinath","Minhua Ding","Bikshapathi Gouda","Italo Atzeni","Antti Tölli"],"pdf_url":"","comment":"13 pages, 8 figures, Submitted to IEEE Transactions on Communications"},{"id":"http://arxiv.org/abs/2510.04924v2","updated":"2026-01-06T19:36:18Z","published":"2025-10-06T15:35:18Z","title":"Steady-State Spread Bounds for Graph Diffusion via Laplacian Regularisation in Networked Systems","summary":"We study how far a diffusion process on a graph can deviate from a designed starting pattern when the pattern is generated via Laplacian regularisation. Under standard stability conditions for undirected, entrywise nonnegative graphs, we give a closed-form, instance-specific upper bound on the steady-state spread, measured as the relative change between the final and initial profiles. The bound separates two effects: (i) an irreducible term determined by the graph's maximum node degree, and (ii) a design-controlled term that shrinks as the regularisation strength increases (with an inverse square-root law). This leads to a design rule: given any target limit on spread, one can choose a sufficient regularisation strength in closed form. Although one motivating application is array beamforming -- where the initial pattern is the squared magnitude of the beamformer weights -- the result applies to any scenario that first enforces Laplacian smoothness and then evolves by linear diffusion on a graph. Overall, the guarantee is non-asymptotic, easy to compute, and certifies the maximum steady-state deviation.","authors":["Ardavan Rahimian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01776v2","updated":"2026-01-06T19:16:20Z","published":"2025-08-03T14:28:23Z","title":"Statistical Multiport-Network Modeling and Efficient Discrete Optimization of RIS","summary":"This Letter addresses the physics-consistent optimization of reconfigurable intelligent surfaces (RISs) with mutual coupling (MC) and 1-bit-programmable RIS elements. This combination of constraints is typical of current prototypes but unexplored in theoretical work. First, we present a simple statistical generator for multiport-network-theory (MNT) parameters of rich-scattering, RIS-parametrized channels. We account for reciprocity, passivity, and coherent backscattering; then, we add a simple hyper-parameter to control the MC strength. Second, we benchmark model-agnostic (dictionary search, coordinate descent, genetic algorithm) and model-based (temperature-annealed back-propagation) strategies under varying MC, with and without intelligent initialization. Except when MC is negligible, coordinate descent with random initialization offers the best trade-off in performance, runtime, and memory. Our insights can guide wireless practitioners who optimize RIS prototypes and other reconfigurable wave systems.","authors":["Cheima Hammami","Luc Le Magoarou","Philipp del Hougne"],"pdf_url":"","comment":"5 pages including 3 figures"},{"id":"http://arxiv.org/abs/2601.03241v1","updated":"2026-01-06T18:34:07Z","published":"2026-01-06T18:34:07Z","title":"On the Capacity Region of Individual Key Rates in Vector Linear Secure Aggregation","summary":"We provide new insights into an open problem recently posed by Yuan-Sun [ISIT 2025], concerning the minimum individual key rate required in the vector linear secure aggregation problem. Consider a distributed system with $K$ users, where each user $k\\in [K]$ holds a data stream $W_k$ and an individual key $Z_k$. A server aims to compute a linear function $\\mathbf{F}[W_1;\\ldots;W_K]$ without learning any information about another linear function $\\mathbf{G}[W_1;\\ldots;W_K]$, where $[W_1;\\ldots;W_K]$ denotes the row stack of $W_1,\\ldots,W_K$. The open problem is to determine the minimum required length of $Z_k$, denoted as $R_k$, $k\\in [K]$. In this paper, we characterize a new achievable region for the rate tuple $(R_1,\\ldots,R_K)$. The region is polyhedral, with vertices characterized by a binary rate assignment $(R_1,\\ldots,R_K) = (\\mathbf{1}(1 \\in \\mathcal{I}),\\ldots,\\mathbf{1}(K\\in \\mathcal{I}))$, where $\\mathcal{I}\\subseteq [K]$ satisfies the \\textit{rank-increment condition}: $\\mathrm{rank}\\left(\\bigl[\\mathbf{F}_{\\mathcal{I}};\\mathbf{G}_{\\mathcal{I}}\\bigr]\\right) =\\mathrm{rank}\\bigl(\\mathbf{F}_{\\mathcal{I}}\\bigr)+N$. Here, $\\mathbf{F}_\\mathcal{I}$ and $\\mathbf{G}_\\mathcal{I}$ are the submatrices formed by the columns indexed by $\\mathcal{I}$. Our results uncover the novel fact that it is not necessary for every user to hold a key, thereby strictly enlarging the best-known achievable region in the literature. Furthermore, we provide a converse analysis to demonstrate its optimality when minimizing the number of users that hold keys.","authors":["Lei Hu","Sennur Ulukus"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03234v1","updated":"2026-01-06T18:26:37Z","published":"2026-01-06T18:26:37Z","title":"Inter-Year Transfer of Altitude-Dependent Spectrum Activity Models Using Minimal Calibration","summary":"This paper studies the transferability of altitude-dependent spectrum activity models and measurements across years. We introduce a physics-informed, mean-only stochastic-geometry model of aggregate interference to altitude-binned received power, yielding three interpretable parameters for a given band and campaign: 1) line-of-sight transition slope, 2) transition altitude, and 3) effective activity constant. Analysis of aerial spectrum measurements collected from 2023 to 2025 across multiple sub-6 GHz bands reveals that downlink (DL) and shared-access bands preserve a persistent geometry-driven altitude structure that is stable across years. In contrast, uplink (UL) bands exhibit weak altitude dependence with no identifiable transition, indicating that interference is dominated by activity dynamics rather than propagation geometry. To quantify the practical limits of model reuse, we evaluate a minimal-calibration method in which the transition altitude is fixed from a reference year and the remaining parameters are estimated from only two altitude bins in the target year. The results further indicate that the proposed approach provides accurate predictions for DL and CBRS bands, suggesting the feasibility of low-cost model transfer in stable environments, while highlighting the reduced applicability of mean-field models for UL scenarios.","authors":["Amir Hossein Fahim Raouf","İsmail Güvenc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03171v1","updated":"2026-01-06T16:51:34Z","published":"2026-01-06T16:51:34Z","title":"Eco-WakeLoc: An Energy-Neutral and Cooperative UWB Real-Time Locating System","summary":"Indoor localization systems face a fundamental trade-off between efficiency and responsiveness, which is especially important for emerging use cases such as mobile robots operating in GPS-denied environments. Traditional RTLS either require continuously powered infrastructure, limiting their scalability, or are limited by their responsiveness. This work presents Eco-WakeLoc, designed to achieve centimeter-level UWB localization while remaining energy-neutral by combining ultra-low power wake-up radios (WuRs) with solar energy harvesting. By activating anchor nodes only on demand, the proposed system eliminates constant energy consumption while achieving centimeter-level positioning accuracy. To reduce coordination overhead and improve scalability, Eco-WakeLoc employs cooperative localization where active tags initiate ranging exchanges (trilateration), while passive tags opportunistically reuse these messages for TDOA positioning. An additive-increase/multiplicative-decrease (AIMD)-based energy-aware scheduler adapts localization rates according to the harvested energy, thereby maximizing the overall performance of the sensor network while ensuring long-term energy neutrality. The measured energy consumption is only 3.22mJ per localization for active tags, 951uJ for passive tags, and 353uJ for anchors. Real-world deployment on a quadruped robot with nine anchors confirms the practical feasibility, achieving an average accuracy of 43cm in dynamic indoor environments. Year-long simulations show that tags achieve an average of 2031 localizations per day, retaining over 7% battery capacity after one year -- demonstrating that the RTLS achieves sustained energy-neutral operation. Eco-WakeLoc demonstrates that high-accuracy indoor localization can be achieved at scale without continuous infrastructure operation, combining energy neutrality, cooperative positioning, and adaptive scheduling.","authors":["Silvano Cortesi","Lukas Schulthess","Davide Plozza","Christian Vogt","Michele Magno"],"pdf_url":"","comment":"This work has been accepted for publication in the IEEE Sensors Journal, specifically the Special Issue on \"Special Issue on Advances in Resource-Efficient Sensors and Interfaces Fostered by Artificial Intelligence\""},{"id":"http://arxiv.org/abs/2601.03148v1","updated":"2026-01-06T16:18:46Z","published":"2026-01-06T16:18:46Z","title":"Spectral-Efficient LoRa with Low Complexity Detection","summary":"In this paper, we propose a spectral-efficient LoRa (SE-LoRa) modulation scheme with a low complexity successive interference cancellation (SIC)-based detector. The proposed communication scheme significantly improves the spectral efficiency of LoRa modulation, while achieving an acceptable error performance compared to conventional LoRa modulation, especially in higher spreading factor (SF) settings. We derive the joint maximum likelihood (ML) detection rule for the SE-LoRa transmission scheme that turns out to be of high computational complexity. To overcome this issue, and by exploiting the frequency-domain characteristics of the dechirped SE-LoRa signal, we propose a low complexity SIC-based detector with a computation complexity at the order of conventional LoRa detection. By computer simulations, we show that the proposed SE-LoRa with low complexity SIC-based detector can improve the spectral efficiency of LoRa modulation up to $445.45\\%$, $1011.11\\%$, and $1071.88\\%$ for SF values of $7$, $9$, and $11$, respectively, while maintaining the error performance within less than $3$ dB of conventional LoRa at symbol error rate (SER) of $10^{-3}$ in Rician channel conditions.","authors":["Alireza Maleki","Ebrahim Bedeer","Robert Barton"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.05017v2","updated":"2026-01-06T15:59:43Z","published":"2025-04-07T12:41:08Z","title":"Joint BS Deployment and Power Optimization for Minimum EMF Exposure with RL in Real-World Based Urban Scenario","summary":"Base station (BS) deployment remains a critical task with successive wireless communication generations and increasing data rates demands, while the electromagnetic field (EMF) exposure is often underrated, yielding potential health implications. Therefore, this paper proposes a workflow that adjusts BS deployment and radiated power in a 3D urban scenario to jointly consider EMF exposure and coverage. To achieve this ambition, firstly, a novel least-time shoot-and-bounce ray (SBR) ray-launching (RL) tool is developed to improve computational efficiency, and simultaneously enhance diffraction modeling} for accurate EMF exposure calculation, validated with real-world measurements. To efficiently extend the computation across the target urban area, the adaptive grid refinement (AGR) algorithm is designed based on the spatial stability of the effective channel while accounting for BS beamforming, enabling global estimation of EMF exposure and signal coverage. Subsequently, to better represent real-world communication network behaviors, the actual maximum transmit power, intercell interference, and channel state information imperfection are incorporated on the BS side, while mobility over the EMF exposure averaging interval is captured on the user equipment side. Upon the aforementioned aspects, the coverage-guaranteed EMF exposure minimization problem is formulated in a realistic and accurate manner, and solved by a geometry-aware algorithm adapted to deterministic channel models, yielding the optimal BS deployment and power configuration. In comparison to a baseline that relies on an empirical channel model, the proposed workflow delivers more reliable estimation of EMF exposure and provides practical guidance for BS construction and operations.","authors":["Xueyun Long","Yueheng Li","Mario Pauli","Benjamin Nuss","Thomas Zwick"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20942v2","updated":"2026-01-06T15:51:59Z","published":"2025-12-24T04:56:28Z","title":"BenchLink: An SoC-Based Benchmark for Resilient Communication Links in GPS-Denied Environments","summary":"Accurate timing and synchronization, typically enabled by GPS, are essential for modern wireless communication systems. However, many emerging applications must operate in GPS-denied environments where signals are unreliable or disrupted, resulting in oscillator drift and carrier frequency impairments. To address these challenges, we present BenchLink, a System-on-Chip (SoC)-based benchmark for resilient communication links that functions without GPS and supports adaptive pilot density and modulation. Unlike traditional General Purpose Processor (GPP)-based software-defined radios (e.g. USRPs), the SoC-based design allows for more precise latency control. We implement and evaluate BenchLink on Zynq UltraScale+ MPSoCs, and demonstrate its effectiveness in both ground and aerial environments. A comprehensive dataset has also been collected under various conditions. We will make both the SoC-based link design and dataset available to the wireless community. BenchLink is expected to facilitate future research on data-driven link adaptation, resilient synchronization in GPS-denied scenarios, and emerging applications that require precise latency control, such as integrated radar sensing and communication.","authors":["Sidharth Santhi Nivas","Prem Sagar Pattanshetty Vasanth Kumar","Zhaoxi Zhang","Chenzhi Zhao","Maxwell McManus","Nicholas Mastronarde","Elizabeth Serena Bentley","George Sklivanitis","Dimitris A. Pados","Zhangyu Guan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03108v1","updated":"2026-01-06T15:38:13Z","published":"2026-01-06T15:38:13Z","title":"Post-Decision State-Based Online Learning for Delay-Energy-Aware Flow Allocation in Wireless Systems","summary":"We develop a structure-aware reinforcement learning (RL) approach for delay- and energy-aware flow allocation in 5G User Plane Functions (UPFs). We consider a dynamic system with $K$ heterogeneous UPFs of varying capacities that handle stochastic arrivals of $M$ flow types, each with distinct rate requirements. We model the system as a Markov decision process (MDP) to capture the stochastic nature of flow arrivals and departures (possibly unknown), as well as the impact of flow allocation in the system. To solve this problem, we propose a post-decision state (PDS) based value iteration algorithm that exploits the underlying structure of the MDP. By separating action-controlled dynamics from exogenous factors, PDS enables faster convergence and efficient adaptive flow allocation, even in the absence of statistical knowledge about exogenous variables. Simulation results demonstrate that the proposed method converges faster and achieves lower long-term cost than standard Q-learning, highlighting the effectiveness of PDS-based RL for resource allocation in wireless networks.","authors":["Mahesh Ganesh Bhat","Shana Moothedath","Prasanna Chaporkar"],"pdf_url":"","comment":"This work has been submitted to IEEE ICC 2026 for possible publication"},{"id":"http://arxiv.org/abs/2601.03084v1","updated":"2026-01-06T15:15:58Z","published":"2026-01-06T15:15:58Z","title":"A Conditional Variational Framework for Channel Prediction in High-Mobility 6G OTFS Networks","summary":"This paper proposes a machine learning (ML) based method for channel prediction in high mobility orthogonal time frequency space (OTFS) channels. In these scenarios, rapid variations caused by Doppler spread and time varying multipath propagation lead to fast channel decorrelation, making conventional pilot based channel estimation methods prone to outdated channel state information (CSI) and excessive overhead. Therefore, reliable channel prediction methods become essential to support robust detection and decoding in OTFS systems. In this paper, we propose conditional variational autoencoder for channel prediction (CVAE4CP) method, which learns the conditional distribution of OTFS delay Doppler channel coefficients given physical system and mobility parameters. By incorporating these parameters as conditioning information, the proposed method enables the prediction of future channel coefficients before their actual realization, while accounting for inherent channel uncertainty through a low dimensional latent representation. The proposed framework is evaluated through extensive simulations under high mobility conditions. Numerical results demonstrate that CVAE4CP consistently outperforms a competing learning based baseline in terms of normalized mean squared error (NMSE), particularly at high Doppler frequencies and extended prediction horizons. These results confirm the effectiveness and robustness of the proposed approach for channel prediction in rapidly time varying OTFS systems.","authors":["Mohsen Kazemian","Jürgen Jasperneite"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03063v1","updated":"2026-01-06T14:46:36Z","published":"2026-01-06T14:46:36Z","title":"Study of Class-Incremental Radio Frequency Fingerprint Recognition Without Storing Exemplars","summary":"The rapid proliferation of wireless devices makes robust identity authentication essential. Radio Frequency Fingerprinting (RFF) exploits device-specific, hard-to-forge physical-layer impairments for identification, and is promising for IoT and unmanned systems. In practice, however, new devices continuously join deployed systems while per-class training data are limited. Conventional static training and naive replay of stored exemplars are impractical due to growing class cardinality, storage cost, and privacy concerns.\n  We propose an exemplar-free class-incremental learning framework tailored to RFF recognition. Starting from a pretrained feature extractor, we freeze the backbone during incremental stages and train only a classifier together with lightweight Adapter modules that perform small task-specific feature adjustments. For each class we fit a diagonal Gaussian Mixture Model (GMM) to the backbone features and sample pseudo-features from these fitted distributions to rehearse past classes without storing raw signals. To improve robustness under few-shot conditions we introduce a time-domain random-masking augmentation and adopt a multi-teacher distillation scheme to compress stage-wise Adapters into a single inference Adapter, trading off accuracy and runtime efficiency.\n  We evaluate the method on large, self-collected ADS-B datasets: the backbone is pretrained on 2,175 classes and incremental experiments are run on a disjoint set of 669 classes with multiple rounds and step sizes. Against several representative baselines, our approach consistently yields higher average accuracy and lower forgetting, while using substantially less storage and avoiding raw-data retention.\n  The proposed pipeline is reproducible and provides a practical, low-storage solution for RFF deployment in resource- and privacy-constrained environments.","authors":["Rundong Jiang","Jun Hu","Yunqi Song","Zhiyuan Xie","Shiyou Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.10219v2","updated":"2026-01-06T14:15:37Z","published":"2025-01-17T14:33:05Z","title":"Robust Egoistic Rigid Body Localization","summary":"We consider a robust and self-reliant (or \"egoistic\") variation of the rigid body localization (RBL) problem, in which a primary rigid body seeks to estimate the pose (i.e., location and orientation) of another rigid body (or \"target\"), relative to its own, without the assistance of external infrastructure, without prior knowledge of the shape of the target, and taking into account the possibility that the available observations are incomplete. Three complementary contributions are then offered for such a scenario. The first is a method to estimate the translation vector between the center point of both rigid bodies, which unlike existing techniques does not require that both objects have the same shape or even the same number of landmark points. This technique is shown to significantly outperform the state-of-the-art (SotA) under complete information, but to be sensitive to data erasures, even when enhanced by matrix completion methods. The second contribution, designed to offer improved performance in the presence of incomplete information, offers a robust alternative to the latter, at the expense of a slight relative loss under complete information. Finally, the third contribution is a scheme for the estimation of the rotation matrix describing the relative orientation of the target rigid body with respect to the primary. Comparisons of the proposed schemes and SotA techniques demonstrate the advantage of the contributed methods in terms of root mean square error (RMSE) performance under fully complete information and incomplete conditions.","authors":["Niclas Führling","Giuseppe Thadeu Freitas de Abreu","David González G.","Osvaldo Gonsa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02874v1","updated":"2026-01-06T10:02:55Z","published":"2026-01-06T10:02:55Z","title":"Transparent and Resilient Activity Recognition via Attention-Based Distributed Radar Sensing","summary":"Distributed radar sensors enable robust human activity recognition. However, scaling the number of coordinated nodes introduces challenges in feature extraction from large datasets, and transparent data fusion. We propose an end-to-end framework that operates directly on raw radar data. Each radar node employs a lightweight 2D Convolutional Neural Network (CNN) to extract local features. A self-attention fusion block then models inter-node relationships and performs adaptive information fusion. Local feature extraction reduces the input dimensionality by up to 480x. This significantly lowers communication overhead and latency. The attention mechanism provides inherent interpretability by quantifying the contribution of each radar node. A hybrid supervised contrastive loss further improves feature separability, especially for fine-grained and imbalanced activity classes. Experiments on real-world distributed Ultra Wide Band (UWB) radar data demonstrate that the proposed method reduces model complexity by 70.8\\%, while achieving higher average accuracy than baseline approaches. Overall, the framework enables transparent, efficient, and low-overhead distributed radar sensing.","authors":["Mina Shahbazifar","Zolfa Zeinalpour-Yazdi","Matthias Hollick","Arash Asadi","Vahid Jamali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01791v2","updated":"2026-01-06T08:31:40Z","published":"2026-01-05T05:05:15Z","title":"Rethinking Secure Semantic Communications in the Age of Generative and Agentic AI: Threats and Opportunities","summary":"Semantic communication (SemCom) improves communication efficiency by transmitting task-relevant information instead of raw bits and is expected to be a key technology for 6G networks. Recent advances in generative AI (GenAI) further enhance SemCom by enabling robust semantic encoding and decoding under limited channel conditions. However, these efficiency gains also introduce new security and privacy vulnerabilities. Due to the broadcast nature of wireless channels, eavesdroppers can also use powerful GenAI-based semantic decoders to recover private information from intercepted signals. Moreover, rapid advances in agentic AI enable eavesdroppers to perform long-term and adaptive inference through the integration of memory, external knowledge, and reasoning capabilities. This allows eavesdroppers to further infer user private behavior and intent beyond the transmitted content. Motivated by these emerging challenges, this paper comprehensively rethinks the security and privacy of SemCom systems in the age of generative and agentic AI. We first present a systematic taxonomy of eavesdropping threat models in SemCom systems. Then, we provide insights into how GenAI and agentic AI can enhance eavesdropping threats. Meanwhile, we also highlight potential opportunities for leveraging GenAI and agentic AI to design privacy-preserving SemCom systems.","authors":["Shunpu Tang","Yuanyuan Jia","Zijiu Yang","Qianqian Yang","Ruichen Zhang","Jun Du","Jihong Park","Zhiguo Shi","Jiming Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02790v1","updated":"2026-01-06T07:57:27Z","published":"2026-01-06T07:57:27Z","title":"RadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse","summary":"Accurate radio map (RM) construction is essential to enabling environment-aware and adaptive wireless communication. However, in future 6G scenarios characterized by high-speed network entities and fast-changing environments, it is very challenging to meet real-time requirements. Although generative diffusion models (DMs) can achieve state-of-the-art accuracy with second-level delay, their iterative nature leads to prohibitive inference latency in delay-sensitive scenarios. In this paper, by uncovering a key structural property of diffusion processes: the latent midpoints remain highly consistent across semantically similar scenes, we propose RadioDiff-Flux, a novel two-stage latent diffusion framework that decouples static environmental modeling from dynamic refinement, enabling the reuse of precomputed midpoints to bypass redundant denoising. In particular, the first stage generates a coarse latent representation using only static scene features, which can be cached and shared across similar scenarios. The second stage adapts this representation to dynamic conditions and transmitter locations using a pre-trained model, thereby avoiding repeated early-stage computation. The proposed RadioDiff-Flux significantly reduces inference time while preserving fidelity. Experiment results show that RadioDiff-Flux can achieve up to 50 acceleration with less than 0.15% accuracy loss, demonstrating its practical utility for fast, scalable RM generation in future 6G networks.","authors":["Xiucheng Wang","Peilin Zheng","Honggang Jia","Nan Cheng","Ruijin Sun","Conghao Zhou","Xuemin Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06572v2","updated":"2026-01-06T00:04:18Z","published":"2025-06-06T22:51:44Z","title":"Cyber Security of Sensor Systems for State Sequence Estimation: an AI Approach","summary":"Sensor systems are extremely popular today and vulnerable to sensor data attacks. Due to possible devastating consequences, counteracting sensor data attacks is an extremely important topic, which has not seen sufficient study. This paper develops the first methods that accurately identify/eliminate only the problematic attacked sensor data presented to a sequence estimation/regression algorithm under a powerful attack model constructed based on known/observed attacks. The approach does not assume a known form for the statistical model of the sensor data, allowing data-driven and machine learning sequence estimation/regression algorithms to be protected. A simple protection approach for attackers not endowed with knowledge of the details of our protection approach is first developed, followed by additional processing for attacks based on protection system knowledge. In the cases tested for which it was designed, experimental results show that the simple approach achieves performance indistinguishable, to two decimal places, from that for an approach which knows which sensors are attacked. For cases where the attacker has knowledge of the protection approach, experimental results indicate the additional processing can be configured so that the worst-case degradation under the additional processing and a large number of sensors attacked can be made significantly smaller than the worst-case degradation of the simple approach, and close to an approach which knows which sensors are attacked, for the same number of attacked sensors with just a slight degradation under no attacks. Mathematical descriptions of the worst-case attacks are used to demonstrate the additional processing will provide similar advantages for cases for which we do not have numerical results. All the data-driven processing used in our approaches employ only unattacked training data.","authors":["Xubin Fang","Rick S. Blum","Ramesh Bharadwaj","Brian M. Sadler"],"pdf_url":"","comment":null}],"Computational Geometry":[{"id":"http://arxiv.org/abs/2508.18222v7","updated":"2026-01-06T15:41:28Z","published":"2025-08-25T17:21:13Z","title":"Symbolic Constraints in Polyhedral Enclosure and Tetrahedral Decomposition in Genus-0 Polyhedra","summary":"I present a coordinate-free, symbolic framework for determining whether a given set of polygonal faces can form a closed, genus-zero polyhedral surface and for predicting admissible internal tetrahedral decompositions consistent with incidence constraints. The method uses only discrete combinatorial variables, such as the number of tetrahedra T, internal gluing triangles Ni, and internal triangulation segments Si, and applies feasibility checks prior to any geometric embedding. For polyhedra in normal form, I record exact incidence identities linking V, E, and F to a flatness parameter S defined as the sum over faces of (degree minus three), and identify parity-sensitive extremal behavior in E, F, and S arising from minimal vertex-degree constraints. These external identities and parity-dependent bounds hold for genus-zero polyhedral graphs under standard simplicity and connectivity assumptions. For internal quantities, I prove exact relations Ni = 2T - V + 2 and T - Ni + Si = 1, and derive restricted linear ranges for tetrahedral decompositions in normal form with no interior vertices. Together, these results yield a symbolic workflow for rapid pre-screening of combinatorially impossible configurations, reducing reliance on costly geometric validation in computational geometry, graphics, and automated modeling.","authors":["Moustapha Itani"],"pdf_url":"","comment":"An open-source R implementation of the symbolic framework is available at https://github.com/MoustaphaItani/polyenclose"},{"id":"http://arxiv.org/abs/2511.02064v4","updated":"2026-01-06T11:43:52Z","published":"2025-11-03T21:00:14Z","title":"MCHex: Marching Cubes Based Adaptive Hexahedral Mesh Generation with Guaranteed Positive Jacobian","summary":"Constructing an adaptive hexahedral tessellation to fit an input triangle boundary is a key challenge in grid-based methods. The conventional method first removes outside elements (RO) and then projects the axis-aligned boundary onto the input triangle boundary, which has no guarantee on improving the initial Intersection over Union (IoU) and Hausdorff distance ratio (HR, w.r.t bounding box diagonal). The proposed MCHex approach replaces RO with a Marching Cubes method MCHex. Given the same computational budget (benchmarked using an identical precomputed Signed Distance Field, which dominates the runtime), MCHex provides better boundary approximation (higher IoU and lower HR) while guaranteeing a lower, yet still positive, minimum scaled Jacobian (>0 vs. RO's >0.48).","authors":["Hua Tong","Yongjie Jessica Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14862v4","updated":"2026-01-06T11:39:44Z","published":"2025-12-16T19:23:16Z","title":"Element-Saving Hexahedral 3-Refinement Templates","summary":"Conforming hexahedral (hex) meshes are favored in simulation for their superior numerical properties, yet automatically decomposing a general 3D volume into a conforming hex mesh remains a formidable challenge. Among existing approaches, methods that construct an adaptive Cartesian grid and subsequently convert it into a conforming mesh stand out for their robustness. However, the topological schemes enabling this conversion require strict compatibility conditions among grid elements, which inevitably refine the initial grid and increase element count. Developing more relaxed conditions to minimize this overhead has been a persistent research focus. State-of-the-art 2-refinement octree methods employ a weakly-balanced condition combined with a generalized pairing condition, using a dual transformation to yield exceptionally low element counts. Yet this approach suffers from critical limitations: information stored on primal cells, such as signed distance fields or triangle index sets, is lost after dualization, and the resulting dual cells often exhibit poor minimum scaled Jacobian (min SJ) with non-planar quadrilateral (quad) faces. Alternatively, 3-refinement 27-tree methods can directly generate conforming hex meshes through template-based replacement of primal cells, producing higher-quality elements with planar quad faces. However, previous 3-refinement techniques impose conditions far more strict than 2-refinement counterparts, severely over-refining grids by factors of ten to one hundred, creating a major bottleneck in simulation pipelines. This article introduces a novel 3-refinement approach that transforms an adaptive 3-refinement grid into a conforming grid using a moderately-balanced condition, slightly stronger than the weakly-balanced condition but substantially more relaxed than prior 3-refinement requirements...... (check PDF for the full abstract)","authors":["Hua Tong","Yongjie Jessica Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02920v1","updated":"2026-01-06T11:01:57Z","published":"2026-01-06T11:01:57Z","title":"Intersection patterns of set systems on manifolds with slowly growing homological shatter functions","summary":"A theorem of Matoušek asserts that for any $k \\ge 2$, any set system whose shatter function is $o(n^k)$ enjoys a fractional Helly theorem: in the $k$-wise intersection hypergraph, positive density implies a linear-size clique. Kalai and Meshulam conjectured a generalization of that phenomenon to homological shatter functions. It was verified for set systems with bounded homological shatter functions and ground set with a forbidden homological minor (which includes $\\mathbb{R}^d$ by a homological analogue of the van Kampen-Flores theorem). We present two contributions to this line of research:\n  - We study homological minors in certain manifolds (possibly with boundary), for which we prove analogues of the van Kampen-Flores theorem and of the Hanani-Tutte theorem.\n  - We introduce graded analogues of the Radon and Helly numbers of set systems and relate their growth rate to the original parameters. This allows to extend the verification of the Kalai-Meshulam conjecture for sufficiently slowly growing homological shatter functions.","authors":["Sergey Avvakumov","Marguerite Bin","Xavier Goaoc"],"pdf_url":"","comment":null}],"Game Theory":[{"id":"http://arxiv.org/abs/2601.03438v1","updated":"2026-01-06T21:57:22Z","published":"2026-01-06T21:57:22Z","title":"EFX and PO Allocation Exists for Two Types of Goods","summary":"We study the problem of fairly and efficiently allocating indivisible goods among agents with additive valuations. We focus on envy-freeness up to any good (EFX) -- an important fairness notion in fair division of indivisible goods. A central open question in this field is whether EFX allocations always exist for any number of agents. While prior work has established EFX existence for settings with at most three distinct valuations (Prakash HV et al. 2025) and for two types of goods (Gorantla, Marwaha, and Velusamy 2023), the general case remains unresolved.\n  In this paper, we extend the existent knowledge by proving that EFX allocations satisfying Pareto optimality (PO) always exist and can be computed in quasiliniear time when there are two types of goods, given that the valuations are positive. This result strengthens the existing work of (Gorantla, Marwaha, and Velusamy 2023), which only guarantees the existence of EFX allocations without ensuring Pareto optimality. Our findings demonstrate a fairly simple and efficient algorithm constructing an EFX+PO allocation.","authors":["Vladimir Davidiuk","Yuriy Dementiev","Artur Ignatiev","Danil Sagunov"],"pdf_url":"","comment":"Accepted at AAAI 2026"},{"id":"http://arxiv.org/abs/2601.03381v1","updated":"2026-01-06T19:30:00Z","published":"2026-01-06T19:30:00Z","title":"Algorithm and Strategy Construction for Sure-Almost-Sure Stochastic Parity Games","summary":"We consider turn-based stochastic two-player games with a combination of a parity condition that must hold surely, that is in all possible outcomes, and of a parity condition that must hold almost-surely, that is with probability 1. The problem of deciding the existence of a winning strategy in such games is central in the framework of synthesis beyond worst-case where a hard requirement that must hold surely is combined with a softer requirement. Recent works showed that the problem is coNP-complete, and infinite-memory strategies are necessary in general, even in one-player games (i.e., Markov decision processes). However, memoryless strategies are sufficient for the opponent player. Despite these comprehensive results, the known algorithmic solution enumerates all memoryless strategies of the opponent, which is exponential in all cases, and does not construct a winning strategy when one exists.\n  We present a recursive algorithm, based on a characterisation of the winning region, that gives a deeper insight into the problem. In particular, we show how to construct a winning strategy to achieve the combination of sure and almost-sure parity, and we derive new complexity and memory bounds for special classes of the problem, defined by fixing the index of either of the two parity conditions.","authors":["Laurent Doyen","Shibashis Guha"],"pdf_url":"","comment":"Extended version of STACS 2026 paper"},{"id":"http://arxiv.org/abs/2511.00835v3","updated":"2026-01-06T16:45:27Z","published":"2025-11-02T07:19:10Z","title":"Optimal Allocations under Strongly Pigou-Dalton Criteria: Hidden Layer Structure & Efficient Combinatorial Approach","summary":"We investigate optimal social welfare allocations of $m$ items to $n$ agents with binary additive or submodular valuations. For binary additive valuations, we prove that the set of optimal allocations coincides with the set of so-called \\emph{stable allocations}, as long as the employed criterion for evaluating social welfare is strongly Pigou-Dalton (SPD) and symmetric. Many common criteria are SPD and symmetric, such as Nash social welfare, leximax, leximin, Gini index, entropy, and envy sum. We also design efficient algorithms for finding a stable allocation, including an $O(m^2n)$ time algorithm for the case of indivisible items, and an $O(m^2n^5)$ time one for the case of divisible items. The first is faster than the existing algorithms or has a simpler analysis. The latter is the first combinatorial algorithm for that problem. It utilizes a hidden layer partition of items and agents admitted by all stable allocations, and cleverly reduces the case of divisible items to the case of indivisible items.In addition, we show that the profiles of different optimal allocations have a small Chebyshev distance, which is 0 for the case of divisible items under binary additive valuations, and is at most 1 for the case of indivisible items under binary submodular valuations.","authors":["Taikun Zhu","Kai Jin","Ruixi Luo","Song Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.18805v3","updated":"2026-01-06T13:34:41Z","published":"2025-02-26T04:19:48Z","title":"It's Not All Black and White: Degree of Truthfulness for Risk-Avoiding Agents","summary":"The classic notion of \\emph{truthfulness} requires that no agent has a profitable manipulation -- an untruthful report that, for \\emph{some} combination of reports of the other agents, increases her utility. This strong notion implicitly assumes that the manipulating agent either knows what all other agents are going to report, or is willing to take the risk and act as-if she knows their reports.\n  Without knowledge of the others' reports, most manipulations are \\emph{risky} -- they might decrease the manipulator's utility for some other combinations of reports by the other agents. Accordingly, a recent paper (Bu, Song and Tao, ``On the existence of truthful fair cake cutting mechanisms'', Artificial Intelligence 319 (2023), 103904) suggests a relaxed notion, which we refer to as \\emph{risk-avoiding truthfulness (RAT)}, which requires only that no agent can gain from a \\emph{safe} manipulation -- one that is sometimes beneficial and never harmful.\n  Truthfulness and RAT are two extremes: the former considers manipulators with complete knowledge of others, whereas the latter considers manipulators with no knowledge at all. In reality, agents often know about some -- but not all -- of the other agents. This paper introduces the \\emph{RAT-degree} of a mechanism, defined as the smallest number of agents whose reports, if known, may allow another agent to safely manipulate, or $n$ if there is no such number. This notion interpolates between classic truthfulness (degree $n$) and RAT (degree at least $1$): a mechanism with a higher RAT-degree is harder to manipulate safely.\n  To illustrate the generality and applicability of this concept, we analyze the RAT-degree of prominent mechanisms across various social choice settings, including auctions, indivisible goods allocations, cake-cutting, voting, and two-sided matching.","authors":["Eden Hartman","Erel Segal-Halevi","Biaoshuai Tao"],"pdf_url":"","comment":"Accepted to EC 2025"},{"id":"http://arxiv.org/abs/2508.08772v2","updated":"2026-01-06T08:08:37Z","published":"2025-08-12T09:20:12Z","title":"Optimal Boost Design for Auto-bidding Mechanism with Publisher Quality Constraints","summary":"Online bidding serves as a fundamental information system in mobile ecosystems, facilitating real-time ad allocation across billions of devices while optimizing both platform performance and user experience through data-driven decision making. Improving ad allocation efficiency is a long-standing research problem, as it directly enhances the economic outcomes for all participants in advertising platforms. This paper investigates the design of optimal boost factors in online bidding while incorporating quality value (the impact of displayed ads on publishers' long-term benefits). To address the divergent interests on quality, we establish a three-party auction framework with a unified welfare metric of advertiser and publisher. Within this framework, we derive the theoretical efficiency lower bound for C-competitive boost in second-price single-slot auctions, then design a novel quality-involved Boosting (q-Boost) algorithm for computing the optimal boost factor. Experimental validation on Alibaba's public dataset (AuctionNet) demonstrates 2%-6% welfare improvements over conventional approaches, proving our method's effectiveness in real-world settings.","authors":["Huanyu Yan","Yu Huo","Min Lu","Weitong Ou","Xingyan Shi","Ruihe Shi","Xiaoying Tang"],"pdf_url":"","comment":"31 pages, 23 figures, journal"},{"id":"http://arxiv.org/abs/2209.14468v2","updated":"2026-01-06T07:18:03Z","published":"2022-09-28T23:13:06Z","title":"Auditing for Core Stability in Participatory Budgeting","summary":"We consider the participatory budgeting problem where each of $n$ voters specifies additive utilities over $m$ candidate projects with given sizes, and the goal is to choose a subset of projects (i.e., a committee) with total size at most $k$. Participatory budgeting mathematically generalizes multiwinner elections, and both have received great attention in computational social choice recently. A well-studied notion of group fairness in this setting is core stability: Each voter is assigned an \"entitlement\" of $\\frac{k}{n}$, so that a subset $S$ of voters can pay for a committee of size at most $|S| \\cdot \\frac{k}{n}$. A given committee is in the core if no subset of voters can pay for another committee that provides each of them strictly larger utility. This provides proportional representation to all voters in a strong sense.\n  In this paper, we study the following auditing question: Given a committee computed by some preference aggregation method, how close is it to the core? Concretely, how much does the entitlement of each voter need to be scaled down by, so that the core property subsequently holds? As our main contribution, we present computational hardness results for this problem, as well as a logarithmic approximation algorithm via linear program rounding. We show that our analysis is tight against the linear programming bound. Additionally, we consider two related notions of group fairness that have similar audit properties. The first is Lindahl priceability, which audits the closeness of a committee to a market clearing solution. We show that this is related to the linear programming relaxation of auditing the core, leading to efficient exact and approximation algorithms for auditing. The second is a novel weakening of the core that we term the sub-core, and we present computational results for auditing this notion as well.","authors":["Kamesh Munagala","Yiheng Shen","Kangning Wang"],"pdf_url":"","comment":"Corrected an incorrect equivalence claim in Section 7; clarified that Weak Priceability is weaker than priceability. Added acknowledgement. Accepted by the 18th Conference on Web and Internet Economics (WINE 2022)"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2506.20854v4","updated":"2026-01-06T19:26:28Z","published":"2025-06-25T22:00:12Z","title":"Towards Two-Stage Counterfactual Learning to Rank","summary":"Counterfactual learning to rank (CLTR) aims to learn a ranking policy from user interactions while correcting for the inherent biases in interaction data, such as position bias. Existing CLTR methods assume a single ranking policy that selects top-K ranking from the entire document candidate set. In real-world applications, the candidate document set is on the order of millions, making a single-stage ranking policy impractical. In order to scale to millions of documents, real-world ranking systems are designed in a two-stage fashion, with a candidate generator followed by a ranker. The existing CLTR method for a two-stage offline ranking system only considers the top-1 ranking set-up and only focuses on training the candidate generator, with the ranker fixed. A CLTR method for training both the ranker and candidate generator jointly is missing from the existing literature. In this paper, we propose a two-stage CLTR estimator that considers the interaction between the two stages and estimates the joint value of the two policies offline. In addition, we propose a novel joint optimization method to train the candidate and ranker policies, respectively. To the best of our knowledge, we are the first to propose a CLTR estimator and learning method for two-stage ranking. Experimental results on a semi-synthetic benchmark demonstrate the effectiveness of the proposed joint CLTR method over baselines.","authors":["Shashank Gupta","Yiming Liao","Maarten de Rijke"],"pdf_url":"","comment":"Accepted at ICTIR 2025 (co-located with SIGIR 2025)"},{"id":"http://arxiv.org/abs/2601.03211v1","updated":"2026-01-06T17:48:40Z","published":"2026-01-06T17:48:40Z","title":"Fine-tuning Small Language Models as Efficient Enterprise Search Relevance Labelers","summary":"In enterprise search, building high-quality datasets at scale remains a central challenge due to the difficulty of acquiring labeled data. To resolve this challenge, we propose an efficient approach to fine-tune small language models (SLMs) for accurate relevance labeling, enabling high-throughput, domain-specific labeling comparable or even better in quality to that of state-of-the-art large language models (LLMs). To overcome the lack of high-quality and accessible datasets in the enterprise domain, our method leverages on synthetic data generation. Specifically, we employ an LLM to synthesize realistic enterprise queries from a seed document, apply BM25 to retrieve hard negatives, and use a teacher LLM to assign relevance scores. The resulting dataset is then distilled into an SLM, producing a compact relevance labeler. We evaluate our approach on a high-quality benchmark consisting of 923 enterprise query-document pairs annotated by trained human annotators, and show that the distilled SLM achieves agreement with human judgments on par with or better than the teacher LLM. Furthermore, our fine-tuned labeler substantially improves throughput, achieving 17 times increase while also being 19 times more cost-effective. This approach enables scalable and cost-effective relevance labeling for enterprise-scale retrieval applications, supporting rapid offline evaluation and iteration in real-world settings.","authors":["Yue Kang","Zhuoyi Huang","Benji Schussheim","Diana Licon","Dina Atia","Shixing Cao","Jacob Danovitch","Kunho Kim","Billy Norcilien","Jonah Karpman","Mahmound Sayed","Mike Taylor","Tao Sun","Pavel Metrikov","Vipul Agarwal","Chris Quirk","Ye-Yi Wang","Nick Craswell","Irene Shaffer","Tianwei Chen","Sulaiman Vesal","Soundar Srinivasan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03153v1","updated":"2026-01-06T16:25:48Z","published":"2026-01-06T16:25:48Z","title":"Parallel Latent Reasoning for Sequential Recommendation","summary":"Capturing complex user preferences from sparse behavioral sequences remains a fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along a single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose \\textbf{Parallel Latent Reasoning (PLR)}, a novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixture-of-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling.","authors":["Jiakai Tang","Xu Chen","Wen Chen","Jian Wu","Yuning Jiang","Bo Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.06254v5","updated":"2026-01-06T16:20:31Z","published":"2024-11-09T19:03:56Z","title":"EviRerank: Adaptive Evidence Construction for Long-Document LLM Reranking","summary":"Decoder-only LLM rerankers struggle with long documents: inference is costly and relevance signals can be diluted by irrelevant context. Motivated by an attention analysis indicating a consistent degradation trend when non-relevant text is appended, we propose EviRerank, an evidence-based long-document reranking framework for decoder-only LLMs. EviRerank (i) scores document blocks with a lightweight selector (BM25, bi-encoder, or cross-encoder), (ii) constructs a compact reranking context under a hard token cap by dynamically budgeting evidence blocks with Adaptive Evidence Budgeting (AEB) and adding a global summary cue via Summary Augmentation (SA), and (iii) reranks with a decoder-only LLM. Across TREC DL'19, DL'23, and MLDR-zh, EviRerank consistently outperforms full-document LLM reranking and strong block-selection baselines while substantially reducing the required input length. On TREC DL'19, EviRerank achieves 0.743 nDCG@10 and 0.307 MAP, establishing a new best result and improving over RankLLaMA (0.701/0.288) by +0.042 nDCG@10 (+6.0%) and +0.019 MAP (+6.6%).","authors":["Minghan Li","Eric Gaussier","Juntao Li","Guodong Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.03025v3","updated":"2026-01-06T15:14:48Z","published":"2025-12-02T18:50:42Z","title":"LORE: A Large Generative Model for Search Relevance","summary":"Achievement. We introduce LORE, a systematic framework for Large Generative Model-based relevance in e-commerce search. Deployed and iterated over three years, LORE achieves a cumulative +27\\% improvement in online GoodRate metrics. This report shares the valuable experience gained throughout its development lifecycle, spanning data, features, training, evaluation, and deployment. Insight. While existing works apply Chain-of-Thought (CoT) to enhance relevance, they often hit a performance ceiling. We argue this stems from treating relevance as a monolithic task, lacking principled deconstruction. Our key insight is that relevance comprises distinct capabilities: knowledge and reasoning, multi-modal matching, and rule adherence. We contend that a qualitative-driven decomposition is essential for breaking through current performance bottlenecks. Contributions. LORE provides a complete blueprint for the LLM relevance lifecycle. Key contributions include: (1) A two-stage training paradigm combining progressive CoT synthesis via SFT with human preference alignment via RL. (2) A comprehensive benchmark, RAIR, designed to evaluate these core capabilities. (3) A query frequency-stratified deployment strategy that efficiently transfers offline LLM capabilities to the online system. LORE serves as both a practical solution and a methodological reference for other vertical domains.","authors":["Chenji Lu","Zhuo Chen","Hui Zhao","Zhiyuan Zeng","Gang Zhao","Junjie Ren","Ruicong Xu","Haoran Li","Songyan Liu","Pengjie Wang","Jian Xu","Bo Zheng"],"pdf_url":"","comment":null}],"Discrete Mathematics":[{"id":"http://arxiv.org/abs/2601.03129v1","updated":"2026-01-06T16:02:08Z","published":"2026-01-06T16:02:08Z","title":"Density Matters: A Complexity Dichotomy of Deleting Edges to Bound Subgraph Density","summary":"We study $τ$-Bounded-Density Edge Deletion ($τ$-BDED), where given an undirected graph $G$, the task is to remove as few edges as possible to obtain a graph $G'$ where no subgraph of $G'$ has density more than $τ$. The density of a (sub)graph is the number of edges divided by the number of vertices. This problem was recently introduced and shown to be NP-hard for $τ\\in \\{2/3, 3/4, 1 + 1/25\\}$, but polynomial-time solvable for $τ\\in \\{0,1/2,1\\}$ [Bazgan et al., JCSS 2025]. We provide a complete dichotomy with respect to the target density $τ$:\n  1. If $2τ\\in \\mathbb{N}$ (half-integral target density) or $τ< 2/3$, then $τ$-BDED is polynomial-time solvable.\n  2. Otherwise, $τ$-BDED is NP-hard.\n  We complement the NP-hardness with fixed-parameter tractability with respect to the treewidth of $G$. Moreover, for integral target density $τ\\in \\mathbb{N}$, we show $τ$-BDED to be solvable in randomized $O(m^{1 + o(1)})$ time. Our algorithmic results are based on a reduction to a new general flow problem on restricted networks that, depending on $τ$, can be solved via Maximum s-t-Flow or General Factors. We believe this connection between these variants of flow and matching to be of independent interest.","authors":["Matthias Bentert","Tom-Lukas Breitkopf","Vincent Froese","Anton Herrmann","André Nichterlein"],"pdf_url":"","comment":"to appear at STACS 2026"},{"id":"http://arxiv.org/abs/2601.02999v1","updated":"2026-01-06T13:23:56Z","published":"2026-01-06T13:23:56Z","title":"Transducing Linear Decompositions of Tournaments","summary":"Bojańczyk, Pilipczuk, and Grohe [LICS '18] proved that for graphs of bounded linear clique-width, clique-decompositions of bounded width can be produced by a CMSO transduction. We show that in the case of tournaments, a first-order transduction suffices. This implies that the logics CMSO and existential MSO are equivalent over bounded linear clique-width tournaments.","authors":["Colin Geniet","Fatemeh Ghasemi","Mamadou Moustapha Kanté"],"pdf_url":"","comment":"30 pages, 4 figures"},{"id":"http://arxiv.org/abs/2501.15515v5","updated":"2026-01-06T11:24:20Z","published":"2025-01-26T13:15:04Z","title":"Degree Realization by Bipartite Multigraphs","summary":"The problem of realizing a given degree sequence by a multigraph can be thought of as a relaxation of the classical degree realization problem (where the realizing graph is simple). This paper concerns the case where the realizing multigraph is required to be bipartite.\n  The problem of characterizing sequences that can be realized by a bipartite graph has two variants. In the simpler one, termed BDR$^P$, the partition of the sequence into two sides is given as part of the input. A complete characterization for realizability in this variant was given by Gale and Ryser over sixty years ago. However, the variant where the partition is not given, termed BDR, is still open.\n  For bipartite multigraph realizations, there are also two variants. For BDR$^P$, where the partition is given as part of the input, a characterization was known for determining whether there is a multigraph realization whose underlying graph is bipartite, such that the maximum number of copies of an edge is at most $r$. We present a characterization for determining if there is a bipartite multigraph realization such that the total number of excess edges is at most $t$. We show that optimizing these two measures may lead to different realizations, and that optimizing by one measure may increase the other substantially. As for the variant BDR, where the partition is not given, we show that determining whether a given (single) sequence admits a bipartite multigraph realization is NP-hard. Moreover, we show that this hardness result extends to any graph family which is a sub-family of bipartite graphs and a super-family of paths. On the positive side, we provide an algorithm that computes optimal realizations for the case where the number of balanced partitions is polynomial, and present sufficient conditions for the existence of bipartite multigraph realizations that depend only on the largest degree of the sequence.","authors":["Amotz Bar-Noy","Toni Bohnlein","David Peleg","Dror Rawitz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02920v1","updated":"2026-01-06T11:01:57Z","published":"2026-01-06T11:01:57Z","title":"Intersection patterns of set systems on manifolds with slowly growing homological shatter functions","summary":"A theorem of Matoušek asserts that for any $k \\ge 2$, any set system whose shatter function is $o(n^k)$ enjoys a fractional Helly theorem: in the $k$-wise intersection hypergraph, positive density implies a linear-size clique. Kalai and Meshulam conjectured a generalization of that phenomenon to homological shatter functions. It was verified for set systems with bounded homological shatter functions and ground set with a forbidden homological minor (which includes $\\mathbb{R}^d$ by a homological analogue of the van Kampen-Flores theorem). We present two contributions to this line of research:\n  - We study homological minors in certain manifolds (possibly with boundary), for which we prove analogues of the van Kampen-Flores theorem and of the Hanani-Tutte theorem.\n  - We introduce graded analogues of the Radon and Helly numbers of set systems and relate their growth rate to the original parameters. This allows to extend the verification of the Kalai-Meshulam conjecture for sufficiently slowly growing homological shatter functions.","authors":["Sergey Avvakumov","Marguerite Bin","Xavier Goaoc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02685v1","updated":"2026-01-06T03:37:25Z","published":"2026-01-06T03:37:25Z","title":"Branching $k$-path vertex cover of forests","summary":"We define a set $P$ to be a branching $k$-path vertex cover of an undirected forest $F$ if all leaves and isolated vertices (vertices of degree at most $1$) of $F$ belong to $P$ and every path on $k$ vertices (of length $k-1$) contains either a branching vertex (a vertex of degree at least $3$) or a vertex belonging to $P$. We define the branching $k$-path vertex cover number of an undirected forest $F$, denoted by $ψ_b(F,k)$, to be the number of vertices in the smallest branching $k$-path vertex cover of $F$. These notions for a rooted directed forest are defined similarly, with natural adjustments. We prove the lower bound $ψ_b(F,k) \\geq \\frac{n+3k-1}{2k}$ for undirected forests, the lower bound $ψ_b(F,k) \\geq \\frac{n+k}{2k}$ for rooted directed forests, and that both of them are tight.","authors":["Mikhail Makarov"],"pdf_url":"","comment":"6 pages"},{"id":"http://arxiv.org/abs/2504.17286v2","updated":"2026-01-06T01:09:36Z","published":"2025-04-24T06:28:14Z","title":"Vertex evaluation of multiplex graphs using Forman Curvature","summary":"The identification of vertices that play a central role in network analysis is a fundamental challenge. Although traditional centrality measures have been extensively employed for this purpose, the increasing complexity of modern networks necessitates the use of sophisticated metrics. The concept of Forman curvature has recently garnered significant attention as a promising approach. We define the Forman curvature for multiplex graphs, which are a category of complex networks characterized by multiple layers of connections between nodes. We then prove the key properties of the Forman curvature in the context of multiplex graphs and show its usefulness in identifying vertices occupying central positions within these networks. Moreover, through a series of comparative experiments with traditional graph features and graph kernels, we demonstrate that the Forman curvature can function as an effective metric for classifying the overall structure of networks.","authors":["Taiki Yamada"],"pdf_url":"","comment":"26 pages, 9 figures, 3 tables"}],"Symbolic Computation":[{"id":"http://arxiv.org/abs/2601.02703v1","updated":"2026-01-06T04:29:30Z","published":"2026-01-06T04:29:30Z","title":"Exact Constructive Digit-by-Digit Algorithms for Integer $e$-th Root Extraction","summary":"We present a unified constructive digit-by-digit framework for exact root extraction using only integer arithmetic. The core contribution is a complete correctness theory for the fractional square root algorithm, proving that each computed decimal digit is exact and final, together with a sharp truncation error bound of $10^{-k}$ after $k$ digits. We further develop an invariant-based framework for computing the integer $e$-th root $\\lfloor N^{1/e} \\rfloor$ of a non-negative integer $N$ for arbitrary fixed exponents $e \\ge 2$, derived directly from the binomial theorem. This method generalizes the classical long-division square root algorithm, preserves a constructive remainder invariant throughout the computation, and provides an exact decision procedure for perfect $e$-th power detection. We also explain why exact digit-by-digit fractional extraction with non-revisable digits is structurally possible only for square roots ($e=2$), whereas higher-order roots ($e \\ge 3$) exhibit nonlinear coupling that prevents digit stability under scaling. All proofs are carried out in a constructive, algorithmic manner consistent with Bishop-style constructive mathematics, yielding explicit algorithmic witnesses, decidable predicates, and guaranteed termination. The resulting algorithms require no division or floating-point operations and are well suited to symbolic computation, verified exact arithmetic, educational exposition, and digital hardware implementation.","authors":["Suresan Pareth"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03298v1","updated":"2026-01-06T01:01:04Z","published":"2026-01-06T01:01:04Z","title":"130k Lines of Formal Topology in Two Weeks: Simple and Cheap Autoformalization for Everyone?","summary":"This is a brief description of a project that has already autoformalized a large portion of the general topology from the Munkres textbook (which has in total 241 pages in 7 chapters and 39 sections). The project has been running since November 21, 2025 and has as of January 4, 2026, produced 160k lines of formalized topology. Most of it (about 130k lines) have been done in two weeks,from December 22 to January 4, for an LLM subscription cost of about \\$100. This includes a 3k-line proof of Urysohn's lemma, a 2k-line proof of Urysohn's Metrization theorem, over 10k-line proof of the Tietze extension theorem, and many more (in total over 1.5k lemmas/theorems). The approach is quite simple and cheap: build a long-running feedback loop between an LLM and a reasonably fast proof checker equipped with a core foundational library. The LLM is now instantiated as ChatGPT (mostly 5.2) or Claude Sonnet (4.5) run through the respective Codex or Claude Code command line interfaces. The proof checker is Chad Brown's higher-order set theory system Megalodon, and the core library is Brown's formalization of basic set theory and surreal numbers (including reals, etc). The rest is some prompt engineering and technical choices which we describe here. Based on the fast progress, low cost, virtually unknown ITP/library, and the simple setup available to everyone, we believe that (auto)formalization may become quite easy and ubiquitous in 2026, regardless of which proof assistant is used.","authors":["Josef Urban"],"pdf_url":"","comment":null}],"Robotics":[{"id":"http://arxiv.org/abs/2601.03449v1","updated":"2026-01-06T22:31:57Z","published":"2026-01-06T22:31:57Z","title":"FIRE-VLM: A Vision-Language-Driven Reinforcement Learning Framework for UAV Wildfire Tracking in a Physics-Grounded Fire Digital Twin","summary":"Wildfire monitoring demands autonomous systems capable of reasoning under extreme visual degradation, rapidly evolving physical dynamics, and scarce real-world training data. Existing UAV navigation approaches rely on simplified simulators and supervised perception pipelines, and lack embodied agents interacting with physically realistic fire environments. We introduce FIRE-VLM, the first end-to-end vision-language model (VLM) guided reinforcement learning (RL) framework trained entirely within a high-fidelity, physics-grounded wildfire digital twin. Built from USGS Digital Elevation Model (DEM) terrain, LANDFIRE fuel inventories, and semi-physical fire-spread solvers, this twin captures terrain-induced runs, wind-driven acceleration, smoke plume occlusion, and dynamic fuel consumption. Within this environment, a PPO agent with dual-view UAV sensing is guided by a CLIP-style VLM. Wildfire-specific semantic alignment scores, derived from a single prompt describing active fire and smoke plumes, are integrated as potential-based reward shaping signals. Our contributions are: (1) a GIS-to-simulation pipeline for constructing wildfire digital twins; (2) a VLM-guided RL agent for UAV firefront tracking; and (3) a wildfire-aware reward design that combines physical terms with VLM semantics. Across five digital-twin evaluation tasks, our VLM-guided policy reduces time-to-detection by up to 6 times, increases time-in-FOV, and is, to our knowledge, the first RL-based UAV wildfire monitoring system demonstrated in kilometer-scale, physics-grounded digital-twin fires.","authors":["Chris Webb","Mobin Habibpour","Mayamin Hamid Raha","Ali Reza Tavakkoli","Janice Coen","Fatemeh Afghah"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03447v1","updated":"2026-01-06T22:25:19Z","published":"2026-01-06T22:25:19Z","title":"Cost-Effective Radar Sensors for Field-Based Water Level Monitoring with Sub-Centimeter Accuracy","summary":"Water level monitoring is critical for flood management, water resource allocation, and ecological assessment, yet traditional methods remain costly and limited in coverage. This work explores radar-based sensing as a low-cost alternative for water level estimation, leveraging its non-contact nature and robustness to environmental conditions. Commercial radar sensors are evaluated in real-world field tests, applying statistical filtering techniques to improve accuracy. Results show that a single radar sensor can achieve centimeter-scale precision with minimal calibration, making it a practical solution for autonomous water monitoring using drones and robotic platforms.","authors":["Anna Zavei-Boroda","J. Toby Minear","Kyle Harlow","Dusty Woods","Christoffer Heckman"],"pdf_url":"","comment":"10 pages, 6 figures. Preliminary results presented as a poster at an academic conference"},{"id":"http://arxiv.org/abs/2601.03398v1","updated":"2026-01-06T20:18:15Z","published":"2026-01-06T20:18:15Z","title":"Towards Zero-Knowledge Task Planning via a Language-based Approach","summary":"In this work, we introduce and formalize the Zero-Knowledge Task Planning (ZKTP) problem, i.e., formulating a sequence of actions to achieve some goal without task-specific knowledge. Additionally, we present a first investigation and approach for ZKTP that leverages a large language model (LLM) to decompose natural language instructions into subtasks and generate behavior trees (BTs) for execution. If errors arise during task execution, the approach also uses an LLM to adjust the BTs on-the-fly in a refinement loop. Experimental validation in the AI2-THOR simulator demonstrate our approach's effectiveness in improving overall task performance compared to alternative approaches that leverage task-specific knowledge. Our work demonstrates the potential of LLMs to effectively address several aspects of the ZKTP problem, providing a robust framework for automated behavior generation with no task-specific setup.","authors":["Liam Merz Hoffmeister","Brian Scassellati","Daniel Rakita"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03386v1","updated":"2026-01-06T19:48:15Z","published":"2026-01-06T19:48:15Z","title":"Modeling and Control for UAV with Off-center Slung Load","summary":"Unmanned aerial vehicle (UAV) with slung load system is a classic air transportation system. In practical applications, the suspension point of the slung load does not always align with the center of mass (CoM) of the UAV due to mission requirements or mechanical interference. This offset creates coupling in the system's nonlinear dynamics which leads to a complicated motion control problem. In existing research, modeling of the system are performed about the UAV's CoM. In this work we use the point of suspension instead. Based on the new model, a cascade control strategy is developed. In the middle-loop controller, the acceleration of the suspension point is used to regulate the swing angle of the slung load without the need for considering the coupling between the slung load and the UAV. Using the off-center reference frame, an inner-loop controller is designed to track the UAV's attitude without the need of simplification on the coupling effects. We prove local exponential stability of the closed-loop using Lyapunov approach. Finally, simulations and experiments are conducted to validate the proposed control system.","authors":["Zongyang Lv","Yanmei Jia","Yongqing Liu","Alan F. Lynch","Qing Zhao","Yuhu Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03371v1","updated":"2026-01-06T19:16:55Z","published":"2026-01-06T19:16:55Z","title":"Lunar Rover Cargo Transport: Mission Concept and Field Test","summary":"In future operations on the lunar surface, automated vehicles will be required to transport cargo between known locations. Such vehicles must be able to navigate precisely in safe regions to avoid natural hazards, human-constructed infrastructure, and dangerous dark shadows. Rovers must be able to park their cargo autonomously within a small tolerance to achieve a successful pickup and delivery. In this field test, Lidar Teach and Repeat provides an ideal autonomy solution for transporting cargo in this way. A one-tonne path-to-flight rover was driven in a semi-autonomous remote-control mode to create a network of safe paths. Once the route was taught, the rover immediately repeated the entire network of paths autonomously while carrying cargo. The closed-loop performance is accurate enough to align the vehicle to the cargo and pick it up. This field report describes a two-week deployment at the Canadian Space Agency's Analogue Terrain, culminating in a simulated lunar operation to evaluate the system's capabilities. Successful cargo collection and delivery were demonstrated in harsh environmental conditions.","authors":["Alexander Krawciw","Nicolas Olmedo","Faizan Rehmatullah","Maxime Desjardins-Goulet","Pascal Toupin","Timothy D. Barfoot"],"pdf_url":"","comment":"15 Pages, 13 Figures, to appear in IEEE Transactions on Field Robotics"},{"id":"http://arxiv.org/abs/2601.03360v1","updated":"2026-01-06T19:02:19Z","published":"2026-01-06T19:02:19Z","title":"Revisiting Continuous-Time Trajectory Estimation via Gaussian Processes and the Magnus Expansion","summary":"Continuous-time state estimation has been shown to be an effective means of (i) handling asynchronous and high-rate measurements, (ii) introducing smoothness to the estimate, (iii) post hoc querying the estimate at times other than those of the measurements, and (iv) addressing certain observability issues related to scanning-while-moving sensors. A popular means of representing the trajectory in continuous time is via a Gaussian process (GP) prior, with the prior's mean and covariance functions generated by a linear time-varying (LTV) stochastic differential equation (SDE) driven by white noise. When the state comprises elements of Lie groups, previous works have resorted to a patchwork of local GPs each with a linear time-invariant SDE kernel, which while effective in practice, lacks theoretical elegance. Here we revisit the full LTV GP approach to continuous-time trajectory estimation, deriving a global GP prior on Lie groups via the Magnus expansion, which offers a more elegant and general solution. We provide a numerical comparison between the two approaches and discuss their relative merits.","authors":["Timothy Barfoot","Cedric Le Gentil","Sven Lilge"],"pdf_url":"","comment":"21 pages, 12 figures"},{"id":"http://arxiv.org/abs/2505.05665v3","updated":"2026-01-06T18:46:38Z","published":"2025-05-08T21:50:43Z","title":"Characterizing the Robustness of Black-Box LLM Planners Under Perturbed Observations with Adaptive Stress Testing","summary":"Large language models (LLMs) have recently demonstrated success in decision-making tasks including planning, control, and prediction, but their tendency to hallucinate unsafe and undesired outputs poses risks. This unwanted behavior is further exacerbated in environments where sensors are noisy or unreliable. Characterizing the behavior of LLM planners to varied observations is necessary to proactively avoid failures in safety-critical scenarios. We specifically investigate the response of LLMs along two different perturbation dimensions. Like prior works, one dimension generates semantically similar prompts with varied phrasing by randomizing order of details, modifying access to few-shot examples, etc. Unique to our work, the second dimension simulates access to varied sensors and noise to mimic raw sensor or detection algorithm failures. An initial case study in which perturbations are manually applied show that both dimensions lead LLMs to hallucinate in a multi-agent driving environment. However, manually covering the entire perturbation space for several scenarios is infeasible. As such, we propose a novel method for efficiently searching the space of prompt perturbations using adaptive stress testing (AST) with Monte-Carlo tree search (MCTS). Our AST formulation enables discovery of scenarios, sensor configurations, and prompt phrasing that cause language models to act with high uncertainty or even crash. By generating MCTS prompt perturbation trees across diverse scenarios, we show through extensive experiments that offline analyses can be used to proactively understand potential failures that may arise at runtime.","authors":["Neeloy Chakraborty","John Pohovey","Melkior Ornik","Katherine Driggs-Campbell"],"pdf_url":"","comment":"30 pages, 24 figures, 6 tables"},{"id":"http://arxiv.org/abs/2601.03247v1","updated":"2026-01-06T18:43:49Z","published":"2026-01-06T18:43:49Z","title":"Nonlinear Spectral Modeling and Control of Soft-Robotic Muscles from Data","summary":"Artificial muscles are essential for compliant musculoskeletal robotics but complicate control due to nonlinear multiphysics dynamics. Hydraulically amplified electrostatic (HASEL) actuators, a class of soft artificial muscles, offer high performance but exhibit memory effects and hysteresis. Here we present a data-driven reduction and control strategy grounded in spectral submanifold (SSM) theory. In the adiabatic regime, where inputs vary slowly relative to intrinsic transients, trajectories rapidly converge to a low-dimensional slow manifold. We learn an explicit input-to-output map on this manifold from forced-response trajectories alone, avoiding decay experiments that can trigger hysteresis. We deploy the SSM-based model for real-time control of an antagonistic HASEL-clutch joint. This approach yields a substantial reduction in tracking error compared to feedback-only and feedforward-only baselines under identical settings. This record-and-control workflow enables rapid characterization and high-performance control of soft muscles and muscle-driven joints without detailed physics-based modeling.","authors":["Leonardo Bettini","Amirhossein Kazemipour","Robert K. Katzschmann","George Haller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.03550v2","updated":"2026-01-06T18:19:15Z","published":"2025-11-05T15:31:47Z","title":"Indicating Robot Vision Capabilities with Augmented Reality","summary":"Research indicates that humans can mistakenly assume that robots and humans have the same field of view, possessing an inaccurate mental model of robots. This misperception may lead to failures during human-robot collaboration tasks where robots might be asked to complete impossible tasks about out-of-view objects. The issue is more severe when robots do not have a chance to scan the scene to update their world model while focusing on assigned tasks.\n  To help align humans' mental models of robots' vision capabilities, we propose four field-of-view indicators in augmented reality and conducted a human-subjects experiment (N=41) to evaluate them in a collaborative assembly task regarding accuracy, confidence, task efficiency, and workload. These indicators span a spectrum of positions: two at robot's eye and head space -- deepening eye socket and adding blocks to two sides of the eyes (i.e., egocentric), and two anchoring in the robot's task space -- adding extended blocks from the sides of eyes to the table and placing blocks directly on the tables (i.e., allocentric).\n  Results showed that, when placed directly in the task space, the allocentric indicator yields the highest accuracy, although with a delay in interpreting the robot's field of view. When placed at the robot's eyes, the egocentric indicator of deeper eye sockets, possible for physical alteration, also increased accuracy. In all indicators, participants' confidence was high while cognitive load remained low. Finally, we contribute six guidelines for practitioners to apply our augmented reality indicators or physical alterations to align humans' mental models with robots' vision capabilities.","authors":["Hong Wang","Ridhima Phatak","James Ocampo","Zhao Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03200v1","updated":"2026-01-06T17:29:10Z","published":"2026-01-06T17:29:10Z","title":"A High-Fidelity Digital Twin for Robotic Manipulation Based on 3D Gaussian Splatting","summary":"Developing high-fidelity, interactive digital twins is crucial for enabling closed-loop motion planning and reliable real-world robot execution, which are essential to advancing sim-to-real transfer. However, existing approaches often suffer from slow reconstruction, limited visual fidelity, and difficulties in converting photorealistic models into planning-ready collision geometry. We present a practical framework that constructs high-quality digital twins within minutes from sparse RGB inputs. Our system employs 3D Gaussian Splatting (3DGS) for fast, photorealistic reconstruction as a unified scene representation. We enhance 3DGS with visibility-aware semantic fusion for accurate 3D labelling and introduce an efficient, filter-based geometry conversion method to produce collision-ready models seamlessly integrated with a Unity-ROS2-MoveIt physics engine. In experiments with a Franka Emika Panda robot performing pick-and-place tasks, we demonstrate that this enhanced geometric accuracy effectively supports robust manipulation in real-world trials. These results demonstrate that 3DGS-based digital twins, enriched with semantic and geometric consistency, offer a fast, reliable, and scalable path from perception to manipulation in unstructured environments.","authors":["Ziyang Sun","Lingfan Bao","Tianhu Peng","Jingcheng Sun","Chengxu Zhou"],"pdf_url":"","comment":"Under review of Journal of Robot Learning"},{"id":"http://arxiv.org/abs/2601.03136v1","updated":"2026-01-06T16:06:47Z","published":"2026-01-06T16:06:47Z","title":"Limited Linguistic Diversity in Embodied AI Datasets","summary":"Language plays a critical role in Vision-Language-Action (VLA) models, yet the linguistic characteristics of the datasets used to train and evaluate these systems remain poorly documented. In this work, we present a systematic dataset audit of several widely used VLA corpora, aiming to characterize what kinds of instructions these datasets actually contain and how much linguistic variety they provide. We quantify instruction language along complementary dimensions-including lexical variety, duplication and overlap, semantic similarity, and syntactic complexity. Our analysis shows that many datasets rely on highly repetitive, template-like commands with limited structural variation, yielding a narrow distribution of instruction forms. We position these findings as descriptive documentation of the language signal available in current VLA training and evaluation data, intended to support more detailed dataset reporting, more principled dataset selection, and targeted curation or augmentation strategies that broaden language coverage.","authors":["Selma Wanna","Agnes Luhtaru","Jonathan Salfity","Ryan Barron","Juston Moore","Cynthia Matuszek","Mitch Pryor"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13961v3","updated":"2026-01-06T15:57:48Z","published":"2025-11-17T22:36:17Z","title":"FICO: Finite-Horizon Closed-Loop Factorization for Unified Multi-Agent Path Finding","summary":"Multi-Agent Path Finding is a fundamental problem in robotics and AI, yet most existing formulations treat planning and execution separately and address variants of the problem in an ad hoc manner. This paper presents a system-level framework for MAPF that integrates planning and execution, generalizes across variants, and explicitly models uncertainties. At its core is the MAPF system, a formal model that casts MAPF as a control design problem encompassing classical and uncertainty-aware formulations. To solve it, we introduce Finite-Horizon Closed-Loop Factorization (FICO), a factorization-based algorithm inspired by receding-horizon control that exploits compositional structure for efficient closed-loop operation. FICO enables real-time responses -- commencing execution within milliseconds -- while scaling to thousands of agents and adapting seamlessly to execution-time uncertainties. Extensive case studies demonstrate that it reduces computation time by up to two orders of magnitude compared with open-loop baselines, while delivering significantly higher throughput under stochastic delays and agent arrivals. These results establish a principled foundation for analyzing and advancing MAPF through system-level modeling, factorization, and closed-loop design.","authors":["Jiarui Li","Alessandro Zanardi","Federico Pecora","Runyu Zhang","Gioele Zardini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03097v1","updated":"2026-01-06T15:30:02Z","published":"2026-01-06T15:30:02Z","title":"Dual-quaternion learning control for autonomous vehicle trajectory tracking with safety guarantees","summary":"We propose a learning-based trajectory tracking controller for autonomous robotic platforms whose motion can be described kinematically on $\\mathrm{SE}(3)$. The controller is formulated in the dual quaternion framework and operates at the velocity level, assuming direct command of angular and linear velocities, as is standard in many aerial vehicles and omnidirectional mobile robots. Gaussian Process (GP) regression is integrated into a geometric feedback law to learn and compensate online for unknown, state-dependent disturbances and modeling imperfections affecting both attitude and position, while preserving the algebraic structure and coupling properties inherent to rigid-body motion.\n  The proposed approach does not rely on explicit parametric models of the unknown effects, making it well-suited for robotic systems subject to sensor-induced disturbances, unmodeled actuation couplings, and environmental uncertainties. A Lyapunov-based analysis establishes probabilistic ultimate boundedness of the pose tracking error under bounded GP uncertainty, providing formal stability guarantees for the learning-based controller.\n  Simulation results demonstrate accurate and smooth trajectory tracking in the presence of realistic, localized disturbances, including correlated rotational and translational effects arising from magnetometer perturbations. These results illustrate the potential of combining geometric modeling and probabilistic learning to achieve robust, data-efficient pose control for autonomous robotic systems.","authors":["Omayra Yago Nieto","Alexandre Anahory Simoes","Juan I. Giribet","Leonardo Colombo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03070v1","updated":"2026-01-06T14:55:16Z","published":"2026-01-06T14:55:16Z","title":"HEXAR: a Hierarchical Explainability Architecture for Robots","summary":"As robotic systems become increasingly complex, the need for explainable decision-making becomes critical. Existing explainability approaches in robotics typically either focus on individual modules, which can be difficult to query from the perspective of high-level behaviour, or employ monolithic approaches, which do not exploit the modularity of robotic architectures. We present HEXAR (Hierarchical EXplainability Architecture for Robots), a novel framework that provides a plug-in, hierarchical approach to generate explanations about robotic systems. HEXAR consists of specialised component explainers using diverse explanation techniques (e.g., LLM-based reasoning, causal models, feature importance, etc) tailored to specific robot modules, orchestrated by an explainer selector that chooses the most appropriate one for a given query. We implement and evaluate HEXAR on a TIAGo robot performing assistive tasks in a home environment, comparing it against end-to-end and aggregated baseline approaches across 180 scenario-query variations. We observe that HEXAR significantly outperforms baselines in root cause identification, incorrect information exclusion, and runtime, offering a promising direction for transparent autonomous systems.","authors":["Tamlin Love","Ferran Gebellí","Pradip Pramanick","Antonio Andriella","Guillem Alenyà","Anais Garrell","Raquel Ros","Silvia Rossi"],"pdf_url":"","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2601.03055v1","updated":"2026-01-06T14:38:19Z","published":"2026-01-06T14:38:19Z","title":"A Fast Semidefinite Convex Relaxation for Optimal Control Problems With Spatio-Temporal Constraints","summary":"Solving optimal control problems (OCPs) of autonomous agents operating under spatial and temporal constraints fast and accurately is essential in applications ranging from eco-driving of autonomous vehicles to quadrotor navigation. However, the nonlinear programs approximating the OCPs are inherently nonconvex due to the coupling between the dynamics and the event timing, and therefore, they are challenging to solve. Most approaches address this challenge by predefining waypoint times or just using nonconvex trajectory optimization, which simplifies the problem but often yields suboptimal solutions. To significantly improve the numerical properties, we propose a formulation with a time-scaling direct multiple shooting scheme that partitions the prediction horizon into segments aligned with characteristic time constraints. Moreover, we develop a fast semidefinite-programming-based convex relaxation that exploits the sparsity pattern of the lifted formulation. Comprehensive simulation studies demonstrate the solution optimality and computational efficiency. Furthermore, real-world experiments on a quadrotor waypoint flight task with constrained open time windows validate the practical applicability of the approach in complex environments.","authors":["Shiying Dong","Zhipeng Shen","Rudolf Reiter","Hailong Huang","Bingzhao Gao","Hong Chen","Wen-Hua Chen"],"pdf_url":"","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2601.03044v1","updated":"2026-01-06T14:25:11Z","published":"2026-01-06T14:25:11Z","title":"SOP: A Scalable Online Post-Training System for Vision-Language-Action Models","summary":"Vision-language-action (VLA) models achieve strong generalization through large-scale pre-training, but real-world deployment requires expert-level task proficiency in addition to broad generality. Existing post-training approaches for VLA models are typically offline, single-robot, or task-specific, limiting effective on-policy adaptation and scalable learning from real-world interaction. We introduce a Scalable Online Post-training (SOP) system that enables online, distributed, multi-task post-training of generalist VLA models directly in the physical world. SOP tightly couples execution and learning through a closed-loop architecture in which a fleet of robots continuously streams on-policy experience and human intervention signals to a centralized cloud learner, and asynchronously receives updated policies. This design supports prompt on-policy correction, scales experience collection through parallel deployment, and preserves generality during adaptation. SOP is agnostic to the choice of post-training algorithm; we instantiate it with both interactive imitation learning (HG-DAgger) and reinforcement learning (RECAP). Across a range of real-world manipulation tasks including cloth folding, box assembly, and grocery restocking, we show that SOP substantially improves the performance of large pretrained VLA models while maintaining a single shared policy across tasks. Effective post-training can be achieved within hours of real-world interaction, and performance scales near-linearly with the number of robots in the fleet. These results suggest that tightly coupling online learning with fleet-scale deployment is instrumental to enabling efficient, reliable, and scalable post-training of generalist robot policies in the physical world.","authors":["Mingjie Pan","Siyuan Feng","Qinglin Zhang","Xinchen Li","Jianheng Song","Chendi Qu","Yi Wang","Chuankang Li","Ziyu Xiong","Zhi Chen","Yi Liu","Jianlan Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03040v1","updated":"2026-01-06T14:19:50Z","published":"2026-01-06T14:19:50Z","title":"PiDR: Physics-Informed Inertial Dead Reckoning for Autonomous Platforms","summary":"A fundamental requirement for full autonomy is the ability to sustain accurate navigation in the absence of external data, such as GNSS signals or visual information. In these challenging environments, the platform must rely exclusively on inertial sensors, leading to pure inertial navigation. However, the inherent noise and other error terms of the inertial sensors in such real-world scenarios will cause the navigation solution to drift over time. Although conventional deep-learning models have emerged as a possible approach to inertial navigation, they are inherently black-box in nature. Furthermore, they struggle to learn effectively with limited supervised sensor data and often fail to preserve physical principles. To address these limitations, we propose PiDR, a physics-informed inertial dead-reckoning framework for autonomous platforms in situations of pure inertial navigation. PiDR offers transparency by explicitly integrating inertial navigation principles into the network training process through the physics-informed residual component. PiDR plays a crucial role in mitigating abrupt trajectory deviations even under limited or sparse supervision. We evaluated PiDR on real-world datasets collected by a mobile robot and an autonomous underwater vehicle. We obtained more than 29% positioning improvement in both datasets, demonstrating the ability of PiDR to generalize different platforms operating in various environments and dynamics. Thus, PiDR offers a robust, lightweight, yet effective architecture and can be deployed on resource-constrained platforms, enabling real-time pure inertial navigation in adverse scenarios.","authors":["Arup Kumar Sahoo","Itzik Klein"],"pdf_url":"","comment":"11 pages and 7 figures"},{"id":"http://arxiv.org/abs/2601.03038v1","updated":"2026-01-06T14:13:33Z","published":"2026-01-06T14:13:33Z","title":"Validating Generalist Robots with Situation Calculus and STL Falsification","summary":"Generalist robots are becoming a reality, capable of interpreting natural language instructions and executing diverse operations. However, their validation remains challenging because each task induces its own operational context and correctness specification, exceeding the assumptions of traditional validation methods. We propose a two-layer validation framework that combines abstract reasoning with concrete system falsification. At the abstract layer, situation calculus models the world and derives weakest preconditions, enabling constraint-aware combinatorial testing to systematically generate diverse, semantically valid world-task configurations with controllable coverage strength. At the concrete layer, these configurations are instantiated for simulation-based falsification with STL monitoring. Experiments on tabletop manipulation tasks show that our framework effectively uncovers failure cases in the NVIDIA GR00T controller, demonstrating its promise for validating general-purpose robot autonomy.","authors":["Changwen Li","Rongjie Yan","Chih-Hong Cheng","Jian Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03037v1","updated":"2026-01-06T14:10:06Z","published":"2026-01-06T14:10:06Z","title":"A Bi-directional Adaptive Framework for Agile UAV Landing","summary":"Autonomous landing on mobile platforms is crucial for extending quadcopter operational flexibility, yet conventional methods are often too inefficient for highly dynamic scenarios. The core limitation lies in the prevalent ``track-then-descend'' paradigm, which treats the platform as a passive target and forces the quadcopter to perform complex, sequential maneuvers. This paper challenges that paradigm by introducing a bi-directional cooperative landing framework that redefines the roles of the vehicle and the platform. The essential innovation is transforming the problem from a single-agent tracking challenge into a coupled system optimization. Our key insight is that the mobile platform is not merely a target, but an active agent in the landing process. It proactively tilts its surface to create an optimal, stable terminal attitude for the approaching quadcopter. This active cooperation fundamentally breaks the sequential model by parallelizing the alignment and descent phases. Concurrently, the quadcopter's planning pipeline focuses on generating a time-optimal and dynamically feasible trajectory that minimizes energy consumption. This bi-directional coordination allows the system to execute the recovery in an agile manner, characterized by aggressive trajectory tracking and rapid state synchronization within transient windows. The framework's effectiveness, validated in dynamic scenarios, significantly improves the efficiency, precision, and robustness of autonomous quadrotor recovery in complex and time-constrained missions.","authors":["Chunhui Zhao","Xirui Kao","Yilin Lu","Yang Lyu"],"pdf_url":"","comment":"This work has been submitted to the IEEE Robotics and Automation Letters (RA-L) for possible publication"},{"id":"http://arxiv.org/abs/2512.10675v2","updated":"2026-01-06T13:53:20Z","published":"2025-12-11T14:22:14Z","title":"Evaluating Gemini Robotics Policies in a Veo World Simulator","summary":"Generative world models hold significant potential for simulating interactions with visuomotor policies in varied environments. Frontier video models can enable generation of realistic observations and environment interactions in a scalable and general manner. However, the use of video models in robotics has been limited primarily to in-distribution evaluations, i.e., scenarios that are similar to ones used to train the policy or fine-tune the base video model. In this report, we demonstrate that video models can be used for the entire spectrum of policy evaluation use cases in robotics: from assessing nominal performance to out-of-distribution (OOD) generalization, and probing physical and semantic safety. We introduce a generative evaluation system built upon a frontier video foundation model (Veo). The system is optimized to support robot action conditioning and multi-view consistency, while integrating generative image-editing and multi-view completion to synthesize realistic variations of real-world scenes along multiple axes of generalization. We demonstrate that the system preserves the base capabilities of the video model to enable accurate simulation of scenes that have been edited to include novel interaction objects, novel visual backgrounds, and novel distractor objects. This fidelity enables accurately predicting the relative performance of different policies in both nominal and OOD conditions, determining the relative impact of different axes of generalization on policy performance, and performing red teaming of policies to expose behaviors that violate physical or semantic safety constraints. We validate these capabilities through 1600+ real-world evaluations of eight Gemini Robotics policy checkpoints and five tasks for a bimanual manipulator.","authors":[" Gemini Robotics Team","Krzysztof Choromanski","Coline Devin","Yilun Du","Debidatta Dwibedi","Ruiqi Gao","Abhishek Jindal","Thomas Kipf","Sean Kirmani","Isabel Leal","Fangchen Liu","Anirudha Majumdar","Andrew Marmon","Carolina Parada","Yulia Rubanova","Dhruv Shah","Vikas Sindhwani","Jie Tan","Fei Xia","Ted Xiao","Sherry Yang","Wenhao Yu","Allan Zhou"],"pdf_url":"","comment":null}],"Dynamical Systems":[{"id":"http://arxiv.org/abs/2512.16875v3","updated":"2026-01-06T23:05:21Z","published":"2025-12-18T18:42:20Z","title":"Learning Confidence Ellipsoids and Applications to Robust Subspace Recovery","summary":"We study the problem of finding confidence ellipsoids for an arbitrary distribution in high dimensions. Given samples from a distribution $\\mathcal{D}$ and a confidence parameter $α$, the goal is to find the smallest volume ellipsoid $E$ which has probability mass $\\Pr_{\\mathcal{D}}[E] \\ge 1-α$. Ellipsoids are a highly expressive class of confidence sets as they can capture correlations in the distribution, and can approximate any convex set. This problem has been studied in many different communities. In statistics, this is the classic minimum volume estimator introduced by Rousseeuw as a robust non-parametric estimator of location and scatter. However in high dimensions, it becomes NP-hard to obtain any non-trivial approximation factor in volume when the condition number $β$ of the ellipsoid (ratio of the largest to the smallest axis length) goes to $\\infty$. This motivates the focus of our paper: can we efficiently find confidence ellipsoids with volume approximation guarantees when compared to ellipsoids of bounded condition number $β$?\n  Our main result is a polynomial time algorithm that finds an ellipsoid $E$ whose volume is within a $O(β)^{γd}$ multiplicative factor of the volume of best $β$-conditioned ellipsoid while covering at least $1-O(α/γ)$ probability mass for any $γ\\in (0,1)$. We complement this with a computational hardness result that shows that such a dependence seems necessary up to constants in the exponent. The algorithm and analysis uses the rich primal-dual structure of the minimum volume enclosing ellipsoid and the geometric Brascamp-Lieb inequality. As a consequence, we obtain the first polynomial time algorithm with approximation guarantees on worst-case instances of the robust subspace recovery problem.","authors":["Chao Gao","Liren Shan","Vaidehi Srinivas","Aravindan Vijayaraghavan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03129v1","updated":"2026-01-06T16:02:08Z","published":"2026-01-06T16:02:08Z","title":"Density Matters: A Complexity Dichotomy of Deleting Edges to Bound Subgraph Density","summary":"We study $τ$-Bounded-Density Edge Deletion ($τ$-BDED), where given an undirected graph $G$, the task is to remove as few edges as possible to obtain a graph $G'$ where no subgraph of $G'$ has density more than $τ$. The density of a (sub)graph is the number of edges divided by the number of vertices. This problem was recently introduced and shown to be NP-hard for $τ\\in \\{2/3, 3/4, 1 + 1/25\\}$, but polynomial-time solvable for $τ\\in \\{0,1/2,1\\}$ [Bazgan et al., JCSS 2025]. We provide a complete dichotomy with respect to the target density $τ$:\n  1. If $2τ\\in \\mathbb{N}$ (half-integral target density) or $τ< 2/3$, then $τ$-BDED is polynomial-time solvable.\n  2. Otherwise, $τ$-BDED is NP-hard.\n  We complement the NP-hardness with fixed-parameter tractability with respect to the treewidth of $G$. Moreover, for integral target density $τ\\in \\mathbb{N}$, we show $τ$-BDED to be solvable in randomized $O(m^{1 + o(1)})$ time. Our algorithmic results are based on a reduction to a new general flow problem on restricted networks that, depending on $τ$, can be solved via Maximum s-t-Flow or General Factors. We believe this connection between these variants of flow and matching to be of independent interest.","authors":["Matthias Bentert","Tom-Lukas Breitkopf","Vincent Froese","Anton Herrmann","André Nichterlein"],"pdf_url":"","comment":"to appear at STACS 2026"},{"id":"http://arxiv.org/abs/2601.03020v1","updated":"2026-01-06T13:47:13Z","published":"2026-01-06T13:47:13Z","title":"Hardness of Regular Expression Matching with Extensions","summary":"The regular expression matching problem asks whether a given regular expression of length $m$ matches a given string of length $n$. As is well known, the problem can be solved in $O(nm)$ time using Thompson's algorithm. Moreover, recent studies have shown that the matching problem for regular expressions extended with a practical extension called lookaround can be solved in the same time complexity. In this work, we consider three well-known extensions to regular expressions called backreference, intersection and complement, and we show that, unlike in the case of lookaround, the matching problem for regular expressions extended with any of the three (for backreference, even when restricted to one capturing group) cannot be solved in $O(n^{2-\\varepsilon} \\mathrm{poly}(m))$ time for any constant $\\varepsilon > 0$ under the Orthogonal Vectors Conjecture. Moreover, we study the matching problem for regular expressions extended with complement in more detail, which is also known as extended regular expression (ERE) matching. We show that there is no ERE matching algorithm that runs in $O(n^{ω-\\varepsilon} \\mathrm{poly}(m))$ time ($2 \\le ω< 2.3716$ is the exponent of square matrix multiplication) for any constant $\\varepsilon > 0$ under the $k$-Clique Hypothesis, and there is no combinatorial ERE matching algorithm that runs in $O(n^{3-\\varepsilon} \\mathrm{poly}(m))$ time for any constant $\\varepsilon > 0$ under the Combinatorial $k$-Clique Hypothesis. This shows that the $O(n^3 m)$-time algorithm introduced by Hopcroft and Ullman in 1979 and recently improved by Bille et al. to run in $O(n^ωm)$ time using fast matrix multiplication was already optimal in a sense, and sheds light on why the theoretical computer science community has struggled to improve the time complexity of ERE matching with respect to $n$ and $m$ for more than 45 years.","authors":["Taisei Nogami","Tachio Terauchi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02836v1","updated":"2026-01-06T09:12:51Z","published":"2026-01-06T09:12:51Z","title":"A Practical 73/50 Approximation for Contiguous Monotone Moldable Job Scheduling","summary":"In moldable job scheduling, we are provided $m$ identical machines and $n$ jobs that can be executed on a variable number of machines. The execution time of each job depends on the number of machines assigned to execute that job. For the specific problem of monotone moldable job scheduling, jobs are assumed to have a processing time that is non-increasing in the number of machines.\n  The previous best-known algorithms are: (1) a polynomial-time approximation scheme with time complexity $Ω(n^{g(1/\\varepsilon)})$, where $g(\\cdot)$ is a super-exponential function [Jansen and Thöle '08; Jansen and Land '18], (2) a fully polynomial approximation scheme for the case of $m \\geq 8\\frac{n}{\\varepsilon}$ [Jansen and Land '18], and (3) a $\\frac{3}{2}$ approximation with time complexity $O(nm\\log(mn))$ [Wu, Zhang, and Chen '23].\n  We present a new practically efficient algorithm with an approximation ratio of $\\approx (1.4593 + \\varepsilon)$ and a time complexity of $O(nm \\log \\frac{1}{\\varepsilon})$. Our result also applies to the contiguous variant of the problem. In addition to our theoretical results, we implement the presented algorithm and show that the practical performance is significantly better than the theoretical worst-case approximation ratio.","authors":["Klaus Jansen","Felix Ohnesorge"],"pdf_url":"","comment":"to appear in STACS 2026"},{"id":"http://arxiv.org/abs/2601.02735v1","updated":"2026-01-06T05:57:43Z","published":"2026-01-06T05:57:43Z","title":"Scalable Tree Ensemble Proximities in Python","summary":"Tree ensemble methods such as Random Forests naturally induce supervised similarity measures through their decision tree structure, but existing implementations of proximities derived from tree ensembles typically suffer from quadratic time or memory complexity, limiting their scalability. In this work, we introduce a general framework for efficient proximity computation by defining a family of Separable Weighted Leaf-Collision Proximities. We show that any proximity measure in this family admits an exact sparse matrix factorization, restricting computation to leaf-level collisions and avoiding explicit pairwise comparisons. This formulation enables low-memory, scalable proximity computation using sparse linear algebra in Python. Empirical benchmarks demonstrate substantial runtime and memory improvements over traditional approaches, allowing tree ensemble proximities to scale efficiently to datasets with hundreds of thousands of samples on standard CPU hardware.","authors":["Adrien Aumon","Guy Wolf","Kevin R. Moon","Jake S. Rhodes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.08148v13","updated":"2026-01-06T03:05:00Z","published":"2025-09-09T21:10:15Z","title":"A Dynamic, Self-balancing k-d Tree","summary":"The original description of the k-d tree recognized that rebalancing techniques, used for building an AVL or red-black tree, are not applicable to a k-d tree, because these techniques involve cyclic exchange of tree nodes that violates the invariant of the k-d tree. For this reason, a static, balanced k-d tree is often built from all of the k-dimensional data en masse. However, it is possible to build a dynamic k-d tree that self-balances when necessary after insertion or deletion of each k-dimensional datum. This article describes insertion, deletion, and rebalancing algorithms for a dynamic, self-balancing k-d tree, and measures their performance.","authors":["Russell A. Brown"],"pdf_url":"","comment":"19 pages, 9 figures, 5 tables"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2601.03229v1","updated":"2026-01-06T18:15:53Z","published":"2026-01-06T18:15:53Z","title":"SpANNS: Optimizing Approximate Nearest Neighbor Search for Sparse Vectors Using Near Memory Processing","summary":"Approximate Nearest Neighbor Search (ANNS) is a fundamental operation in vector databases, enabling efficient similarity search in high-dimensional spaces. While dense ANNS has been optimized using specialized hardware accelerators, sparse ANNS remains limited by CPU-based implementations, hindering scalability. This limitation is increasingly critical as hybrid retrieval systems, combining sparse and dense embeddings, become standard in Information Retrieval (IR) pipelines. We propose SpANNS, a near-memory processing architecture for sparse ANNS. SpANNS combines a hybrid inverted index with efficient query management and runtime optimizations. The architecture is built on a CXL Type-2 near-memory platform, where a specialized controller manages query parsing and cluster filtering, while compute-enabled DIMMs perform index traversal and distance computations close to the data. It achieves 15.2x to 21.6x faster execution over the state-of-the-art CPU baselines, offering scalable and efficient solutions for sparse vector search.","authors":["Tianqi Zhang","Flavio Ponzina","Tajana Rosing"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03324v1","updated":"2026-01-06T15:00:40Z","published":"2026-01-06T15:00:40Z","title":"Bare-Metal Tensor Virtualization: Overcoming the Memory Wall in Edge-AI Inference on ARM64","summary":"The deployment of Large Language Models (LLMs) on edge devices is fundamentally constrained by the \"Memory Wall\" the bottleneck where data movement latency outstrips arithmetic throughput. Standard inference runtimes often incur significant overhead through high-level abstractions, dynamic dispatch, and unaligned memory access patterns. In this work, we present a novel \"Virtual Tensor Core\" architecture implemented in software, optimized specifically for ARM64 microarchitectures (Apple Silicon). By bypassing standard library containers in favor of direct memory mapping (mmap) and implementing hand-tuned NEON SIMD kernels, we achieve a form of \"Software-Defined Direct Memory Access (DMA).\" Our proposed Tensor Virtualization Layout (TVL) guarantees 100% cache line utilization for weight matrices, while our zero-copy loader eliminates initialization latency. Experimental results on a 110M parameter model demonstrate a stable throughput of >60 tokens/second on M2 hardware. While proprietary hardware accelerators (e.g., Apple AMX) can achieve higher peak throughput, our architecture provides a fully open, portable, and deterministic reference implementation for studying the memory bottleneck on general-purpose ARM silicon, meeting the 200ms psycholinguistic latency threshold without opaque dependencies.","authors":["Bugra Kilictas","Faruk Alpay"],"pdf_url":"","comment":"14 pages, 2 figures. Code and data available at https://github.com/farukalpay/stories100m"},{"id":"http://arxiv.org/abs/2601.02766v1","updated":"2026-01-06T06:58:26Z","published":"2026-01-06T06:58:26Z","title":"Advancing Assistive Robotics: Multi-Modal Navigation and Biophysical Monitoring for Next-Generation Wheelchairs","summary":"Assistive electric-powered wheelchairs (EPWs) have become essential mobility aids for people with disabilities such as amyotrophic lateral sclerosis (ALS), post-stroke hemiplegia, and dementia-related mobility impairment. This work presents a novel multi-modal EPW control system designed to prioritize patient needs while allowing seamless switching between control modes. Four complementary interfaces, namely joystick, speech, hand gesture, and electrooculography (EOG), are integrated with a continuous vital sign monitoring framework measuring heart rate variability, oxygen saturation (SpO2), and skin temperature. This combination enables greater patient independence while allowing caregivers to maintain real-time supervision and early intervention capability.\n  Two-point calibration of the biophysical sensors against clinical reference devices resulted in root mean square errors of at most 2 bpm for heart rate, 0.5 degree Celsius for skin temperature, and 1 percent for SpO2. Experimental evaluation involved twenty participants with mobility impairments executing a total of 500 indoor navigation commands. The achieved command recognition accuracies were 99 percent for joystick control, 97 percent plus or minus 2 percent for speech, and 95 percent plus or minus 3 percent for hand gesture, with an average closed-loop latency of 20 plus or minus 0.5 milliseconds. Caregivers receive real-time alerts through an Android application following encrypted cloud transmission of physiological data. By integrating multi-modal mobility control with cloud-enabled health monitoring and reporting latency and energy budgets, the proposed prototype addresses key challenges in assistive robotics, contributes toward compliance with ISO 7176-31 and IEC 80601-2-78 safety standards, and establishes a foundation for future adaptive machine learning enhancements.","authors":["Md. Anowar Hossain","Mohd. Ehsanul Hoque"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02613v1","updated":"2026-01-06T00:15:38Z","published":"2026-01-06T00:15:38Z","title":"Sparsity-Aware Streaming SNN Accelerator with Output-Channel Dataflow for Automatic Modulation Classification","summary":"The rapid advancement of wireless communication technologies, including 5G, emerging 6G networks, and the large-scale deployment of the Internet of Things (IoT), has intensified the need for efficient spectrum utilization. Automatic modulation classification (AMC) plays a vital role in cognitive radio systems by enabling real-time identification of modulation schemes for dynamic spectrum access and interference mitigation. While deep neural networks (DNNs) offer high classification accuracy, their computational and energy demands pose challenges for real-time edge deployment. Spiking neural networks (SNNs), with their event-driven nature, offer inherent energy efficiency, but achieving both high throughput and low power under constrained hardware resources remains challenging. This work proposes a sparsity-aware SNN streaming accelerator optimized for AMC tasks. Unlike traditional systolic arrays that exploit sparsity but suffer from low throughput, or streaming architectures that achieve high throughput but cannot fully utilize input and weight sparsity, our design integrates both advantages. By leveraging the fixed nature of kernels during inference, we apply the gated one-to-all product (GOAP) algorithm to compute only on non-zero input-weight intersections. Extra or empty iterations are precomputed and embedded into the inference dataflow, eliminating dynamic data fetches and enabling fully pipelined, control-free inter-layer execution. Implemented on an FPGA, our sparsity-aware output-channel dataflow streaming (SAOCDS) accelerator achieves 23.5 MS/s (approximately double the baseline throughput) on the RadioML 2016 dataset, while reducing dynamic power and maintaining comparable classification accuracy. These results demonstrate strong potential for real-time, low-power deployment in edge cognitive radio systems.","authors":["Kuilian Yang","Li Zhang","Ahmed M. Eltawil","Khaled Nabil Salama"],"pdf_url":"","comment":null}],"Computational Finance":[{"id":"http://arxiv.org/abs/2601.03175v1","updated":"2026-01-06T16:52:35Z","published":"2026-01-06T16:52:35Z","title":"Breaking the Dimensional Barrier: Dynamic Portfolio Choice with Parameter Uncertainty via Pontryagin Projection","summary":"We study continuous-time portfolio choice in diffusion markets with parameter $θ\\in Θ$ and uncertainty law $q(dθ)$. Nature draws latent $θ\\sim q$ at time 0; the investor cannot observe it and must deploy a single $θ$-blind feedback policy maximizing an ex-ante CRRA objective averaged over diffusion noise and $θ$. Our methods access $q$ only by sampling and assume no parametric form. We extend Pontryagin-Guided Direct Policy Optimization (PG-DPO) by sampling $θ$ inside the simulator and computing discrete-time gradients via backpropagation through time (BPTT), and we propose projected PG-DPO (P-PGDPO) that projects costate estimates to satisfy the $q$-aggregated Pontryagin first-order condition, yielding a deployable rule. We prove a BPTT-PMP correspondence uniform on compacts and a residual-based $θ$-blind policy-gap bound under local stability with explicit discretization/Monte Carlo errors; experiments show projection-driven stability and accurate decision-time benchmark recovery in high dimensions.","authors":["Jeonggyu Huh","Hyeng Keun Koo"],"pdf_url":"","comment":null}]},"2026-01-08T00:00:00Z":{"Optimization and Control":[{"id":"http://arxiv.org/abs/2503.23564v2","updated":"2026-01-08T18:48:14Z","published":"2025-03-30T19:06:27Z","title":"A Class of Optimal Directed Graphs for Network Synchronization","summary":"In a paper by Nishikawa and Motter, a quantity called the normalized spread of the Laplacian eigenvalues is used to measure the synchronizability of certain network dynamics. Through simulations, and without theoretical validation, it is conjectured that among all simple directed graphs with a fixed number of vertices and arcs, the optimal value of this quantity is achieved if the Laplacian spectrum satisfies a specific pattern. This paper proves this conjecture and further shows that the conjectured spectral condition is not only sufficient but also necessary. Moreover, the paper proves that the optimal Laplacian spectrum is always achievable by a class of almost regular directed graphs, which can be constructed through an inductive algorithm.","authors":["Susie Lu","John Urschel","Ji Liu"],"pdf_url":"","comment":"This version proves the conjecture and establishes a stronger statement"},{"id":"http://arxiv.org/abs/2601.05207v1","updated":"2026-01-08T18:33:07Z","published":"2026-01-08T18:33:07Z","title":"On the Value Function of Convex Bolza Problems Governed by Stochastic Difference Equations","summary":"In this paper we study the value function of Bolza problems governed by stochastic difference equations, with particular emphasis on the convex non-anticipative case. Our goal is to provide some insights on the structure of the subdiferential of the value function. In particular, we establish a connection between the evolution of the subgradients of the value function and a stochastic difference equation of Hamiltonian type. This result can be seen as a transposition of the method of characteristics, introduced by Rockafellar and Wolenski in the 2000s, to the stochastic discrete-time setting. Similarly as done in the literature for the deterministic case, the analysis is based on a duality approach. For this reason we study first a dual representation for the value function in terms of the value function of a dual problem, which is a pseudo Bolza problem. The main difference with the deterministic case is that (due to the non-anticipativity) the symmetry between the Bolza problem and its dual is no longer valid. This in turn implies that ensuring the existence of minimizers for the Bolza problem (which is a key point for establishing the method of characteristics) is not as simple as in the deterministic case, and it should be addressed differently. To complete the exposition, we study the existence of minimizers for a particular class of Bolza problems governed by linear stochastic difference equations, the so-called linear-convex optimal control problems.","authors":["Sebastián Álvarez","Julio Deride","Cristopher Hermosilla"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.09812v2","updated":"2026-01-08T17:43:20Z","published":"2025-06-11T14:52:09Z","title":"Balanced quasistatic evolutions of critical points in metric spaces","summary":"Quasistatic evolutions of critical points of time-dependent energies exhibit piecewise smooth behavior, making them useful for modeling continuum mechanics phenomena like elastic-plasticity and fracture. Traditionally, such evolutions have been derived as vanishing viscosity and inertia limits, leading to balanced viscosity solutions. However, for nonconvex energies, these constructions have been realized in Euclidean spaces and assume non-degenerate critical points. In this paper, we take a different approach by decoupling the time scales of the energy evolution and of the transition to equilibria. Namely, starting from an equilibrium configuration, we let the energy evolve, while keeping frozen the system state; then, we update the state by freezing the energy, while letting the system transit via gradient flow or an approximation of it (e.g., minimizing movement or backward differentiation schemes). This approach has several advantages. It aligns with the physical principle that systems transit through energy-minimizing steady states. It is also fully constructive and computationally implementable, with physical and computational costs governed by appropriate action functionals. Additionally, our analysis is simpler and more general than previous formulations in the literature, as it does not require non-degenerate critical points. Finally, this approach extends to evolutions in locally compact metric path spaces, and our axiomatic presentation allows for various realizations.","authors":["Stefano Almi","Massimo Fornasier","Jona Klemenc","Alessandro Scagliotti"],"pdf_url":"","comment":"66 pages, 6 figures. Minor adjustments and corrections"},{"id":"http://arxiv.org/abs/2601.05056v1","updated":"2026-01-08T15:58:16Z","published":"2026-01-08T15:58:16Z","title":"ZIVR: An Incremental Variance Reduction Technique For Zeroth-Order Composite Problems","summary":"This paper investigates zeroth-order (ZO) finite-sum composite optimization. Recently, variance reduction techniques have been applied to ZO methods to mitigate the non-vanishing variance of 2-point estimators in constrained/composite optimization, yielding improved convergence rates. However, existing ZO variance reduction methods typically involve batch sampling of size at least $Θ(n)$ or $Θ(d)$, which can be computationally prohibitive for large-scale problems. In this work, we propose a general variance reduction framework, Zeroth-Order Incremental Variance Reduction (ZIVR), which supports flexible implementations$\\unicode{x2014}$including a pure 2-point zeroth-order algorithm that eliminates the need for large batch sampling. Furthermore, we establish comprehensive convergence guarantees for ZIVR across strongly-convex, convex, and non-convex settings that match their first-order counterparts. Numerical experiments validate the effectiveness of our proposed algorithm.","authors":["Silan Zhang","Yujie Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05029v1","updated":"2026-01-08T15:38:33Z","published":"2026-01-08T15:38:33Z","title":"Stochastic convergence of a class of greedy-type algorithms for Configuration Optimization Problems","summary":"Greedy Sampling Methods (GSMs) are widely used to construct approximate solutions of Configuration Optimization Problems (COPs), where a loss functional is minimized over finite configurations of points in a compact domain. While effective in practice, deterministic convergence analyses of greedy-type algorithms are often restrictive and difficult to verify. We propose a stochastic framework in which greedy-type methods are formulated as continuous-time Markov processes on the space of configurations. This viewpoint enables convergence analysis in expectation and in probability under mild structural assumptions on the error functional and the transition kernel. For global error functionals, we derive explicit convergence rates, including logarithmic, polynomial, and exponential decay, depending on an abstract improvement condition. As a pedagogical example, we study stochastic greedy sampling for one-dimensional piecewise linear interpolation and prove exponential convergence of the $L^1$-interpolation error for $C^2$-functions. Motivated by this analysis, we introduce the Randomized Polytope Division Method (R-PDM), a randomized variant of the classical Polytope Division Method, and demonstrate its effectiveness and variance reduction in numerical experiments","authors":["Evie Nielen","Oliver Tse"],"pdf_url":"","comment":"32 pages, 9 figures"},{"id":"http://arxiv.org/abs/2409.10295v2","updated":"2026-01-08T14:17:55Z","published":"2024-09-16T14:01:28Z","title":"A Note on Piecewise Affine Decision Rules for Robust, Stochastic, and Data-Driven Optimization","summary":"Multi-stage decision-making under uncertainty, where decisions are taken under sequentially revealing uncertain problem parameters, is often essential to faithfully model managerial problems. Given the significant computational challenges involved, these problems are typically solved approximately. This short note introduces an algorithmic framework that revisits a popular approximation scheme for multi-stage stochastic programs by Georghiou et al. (2015) and improves upon it to deliver superior policies in the stochastic setting, as well as extend its applicability to robust optimization and a contemporary Wasserstein-based data-driven setting. We demonstrate how the policies of our framework can be computed efficiently, and we present numerical experiments that highlight the benefits of our method.","authors":["Simon Thomä","Maximilian Schiffer","Wolfram Wiesemann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04965v1","updated":"2026-01-08T14:14:12Z","published":"2026-01-08T14:14:12Z","title":"Sum of Squares Decompositions and Rank Bounds for Biquadratic Forms","summary":"We study positive semi-definite (PSD) biquadratic forms and their sum-of-squares (SOS) representations. For the class of partially symmetric biquadratic forms, we establish necessary and sufficient conditions for positive semi-definiteness and prove that every PSD partially symmetric biquadratic form is a sum of squares of bilinear forms. This extends the known result for fully symmetric biquadratic forms. We describe an efficient computational procedure for constructing SOS decompositions, exploiting the Kronecker-product structure of the associated matrix representation. We present a $2 \\times 2$ PSD biquadratic form, and show that it can be expressed as the sum of three squares, but cannot be expressed as the sum of two squares. Furthermore, we present a $3 \\times 2$ PSD biquadratic form, and show that it can be expressed as the sum of four squares, but cannot be expressed as the sum of three squares. These show that previously proved results that a $2 \\times 2$ PSD biquadratic form can be expressed as the sum of three squares, and a $3 \\times 2$ PSD biquadratic form can be expressed as the sum of four squares, are tight.","authors":["Liqun Qi","Chunfeng Cui","Yi Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.15338v2","updated":"2026-01-08T14:06:28Z","published":"2024-06-21T17:51:58Z","title":"Network-Based Optimal Control of Pollution Growth","summary":"This paper studies a model for the optimal control (by a centralized economic agent which we call the planner) of pollution diffusion over time and space. The controls are the investments in production and depollution and the goal is to maximize an intertemporal utility function. The main novelty is the fact that the spatial component has a network structure. Moreover, in such a time-space setting we also analyze the trade-off between the use of green or non-green technologies: this also seems to be a novelty in such a setting. Extending methods of previous papers, we can solve explicitly the problem in the case of linear costs of pollution.","authors":["Fausto Gozzi","Marta Leocata","Giulia Pucci"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.04739v2","updated":"2026-01-08T13:45:05Z","published":"2025-07-07T08:11:00Z","title":"Optimization of Transfers linking Ballistic Captures to Earth-Moon Periodic Orbit Families","summary":"The design of transfers to periodic orbits in the Earth-Moon system has regained prominence with NASA's Artemis and CNSA's Chang'e programs. This work addresses the problem of linking ballistic capture trajectories - exploiting multi-body dynamics for temporary lunar orbit insertion - with bounded periodic motion described in the circular restricted three-body problem (CR3BP). A unified framework is developed for optimizing bi-impulsive transfers to families of periodic orbits via a high-order polynomial expansion of the CR3BP dynamics. That same expansion underlies a continuous parameterization of periodic orbit families, enabling rapid targeting and analytic sensitivity. Transfers to planar periodic orbit families - such as Lyapunov L1/L2 and distant retrograde orbits (DROs) - are addressed first, followed by extension to spatial families - such as butterfly and halo L1/L2 orbits - with an emphasis towards near-rectilinear halo orbits (NRHOs). Numerical results demonstrate low-Δv solutions and validate the method's adaptability for designing lunar missions. The optimized trajectories can inform an established low-energy transfer database, enriching it with detailed cost profiles that reflect both transfer feasibility and underlying dynamical relationships to specific periodic orbit families. Finally, the proposed transfers provide reliable estimates for rapid refinement, making them readily adaptable for further optimization across mission-specific needs.","authors":["Lorenzo Anoè","Roberto Armellin","Jack Yarndley","Thomas Caleb","Stéphanie Lizy-Destrez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03318v2","updated":"2026-01-08T12:43:47Z","published":"2026-01-06T13:39:07Z","title":"An overview of the fractional-order gradient descent method and its applications","summary":"Recent studies have shown that fractional calculus is an effective alternative mathematical tool in various scientific fields. However, some investigations indicate that results established in differential and integral calculus do not necessarily hold true in fractional calculus. In this work we will compare various methods presented in the literature to improve the Gradient Descent Method, in terms of convergence of the method, convergence to the extreme point, and convergence rate. In general, these methods that generalize the gradient descent algorithm by replacing the gradient with a fractional-order operator are inefficient in achieving convergence to the extremum point of the objective function. To avoid these difficulties, we proposed to choose the Fractional Continuous Time algorithm to generalize the gradient method. In this approach, the convergence of the method to the extreme point of the function is guaranteed by introducing the fractional order in the time derivative, rather than in of the gradient. In this case, the issue of finding the extreme point is resolved, while the issue of stability at the equilibrium point remains.\n  Fractional Continuous Time method converges to extreme point of cost function when fractional-order is between 0 and 1. The simulations shown in this work suggests that a similar result can be found when $1 \\leq α\\leq 2$. { This paper highlights the main advantages and disadvantages of generalizations of the gradient method using fractional derivatives, aiming to optimize convergence in complex problems. Some chemical problems, with n=11 and 24 optimization parameters, are employed as means of evaluating the efficacy of the propose algorithms. In general, previous studies are restricted to mathematical questions and simple illustrative examples.","authors":["Higor V. M. Ferreira","Camila A. Tavares","Nelson H. T. Lemes","José P. C. dos Santos"],"pdf_url":"","comment":"26 pages, 2 tables, 8 figures"},{"id":"http://arxiv.org/abs/2511.17130v3","updated":"2026-01-08T12:31:36Z","published":"2025-11-21T10:46:06Z","title":"Asymptotics of motion planning complexity for control-affine systems","summary":"In this paper, we study the complexity of the approximation of nonadmissible curves for nonlinear control-affine systems satisfying the strong H{ö}rmander condition. Focusing on tubular approximation complexities, we provide asymptotic equivalences, with explicit constants, for all generic situations where the distribution, i.e., the linear part of the control system, is of co-rank one. Namely, we consider curves in step 2 distributions and any dimension. In the 3 dimensional case, we also consider the case of distributions with Martinet-type singularities that are crossed by the curve at isolated points.","authors":["Michele Motta","Dario Prandi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.02357v3","updated":"2026-01-08T11:50:16Z","published":"2024-10-03T10:11:44Z","title":"A universal example for quantitative semi-uniform stability","summary":"We characterise quantitative semi-uniform stability for $C_0$-semigroups arising from port-Hamiltonian systems, complementing recent works on exponential and strong stability. With the result, we present a simple universal example class of port-Hamiltonian $C_0$-semigroups exhibiting arbitrary decay rates slower than $t^{-1/2}$.\n  The latter is based on results from the theory of Diophantine approximation, as the decay rates will be strongly related to the approximation properties of irrational numbers by rationals obtained from cut-offs of continued fraction expansions.","authors":["Sahiba Arora","Felix Schwenninger","Ingrid Vukusic","Marcus Waurick"],"pdf_url":"","comment":"24 pages; this is version 3, included the proof of Theorem A.5 and fixed an error in proof of Theorem A.6"},{"id":"http://arxiv.org/abs/2601.04652v1","updated":"2026-01-08T06:58:47Z","published":"2026-01-08T06:58:47Z","title":"Stochastic Linear-Quadratic Optimal Control Problems with Markovian Regime Switching and $H_\\infty$ Constraint under Partial Information","summary":"This paper is concerned with a stochastic linear-quadratic optimal control problem of Markovian regime switching system with model uncertainty and partial information, where the information available to the control is based on a sub-$σ$-algebra of the filtration generated by the underlying Brownian motion and the Markov chain. Based on $H_\\infty$ control theory, we turn to deal with a soft-constrained zero-sum linear-quadratic stochastic differential game with Markov chain and partial information. By virtue of the filtering technique, the Riccati equation approach, the method of orthogonal decomposition, and the completion-of-squares method, we obtain the closed-loop saddle point of the zero-sum game via the optimal feedback control-strategy pair. Subsequently, we prove that the corresponding outcome of the closed-loop saddle point satisfies the $H_\\infty$ performance criterion. Finally, the obtained theoretical results are applied to a stock market investment problem to further illustrate the practical significance and effectiveness.","authors":["Na Xiang","Jingtao Shi"],"pdf_url":"","comment":"46 pages, 10 figures"},{"id":"http://arxiv.org/abs/2402.04281v2","updated":"2026-01-08T06:35:46Z","published":"2024-02-05T21:23:51Z","title":"Global minimisation of nonconvex functions by generalising the mirror descent method","summary":"In this paper we introduce two conceptual algorithms for minimising abstract convex functions. Both algorithms rely on solving a proximal-type subproblem with an abstract Bregman distance based proximal term. We prove their convergence when the set of abstract linear functions forms a linear space. This latter assumption can be relaxed to only require the set of abstract linear functions to be closed under the sum, which is a classical assumption in abstract convexity. We provide numerical examples on the minimisation of nonconvex functions with the presented algorithms.","authors":["Reinier Díaz Millán","Julien Ugon"],"pdf_url":"","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2509.19629v2","updated":"2026-01-08T06:14:58Z","published":"2025-09-23T22:42:22Z","title":"A Multiobjective Mathematical Model for Optimal Irrigation Water Allocation","summary":"Sustainable irrigation and food security increasingly depend on efficient water resource management in the face of growing climatic and economic constraints. In this study, we develop two single objective optimization models for irrigation planning, one that maximizes net benefit and the other that minimizes environmental flow deficiency, and compare their performance with established models reported in previous studies. We then extend the analysis to a multiobjective programming formulation solved through scalarization and genetic approaches to evaluate trade-offs. Numerical experiments on the Muhuri Irrigation Project reveal three outcomes: (i) a complete scenario view with profits ranging from $ \\$ 0.2 \\times 10^9$ to $ \\$ 1.497\\times 10^9$ and environmental flow deficits between 0 and 1200 GL, where the 1200 GL represents the theoretical annual maximum under a 100 GL uniform monthly target; (ii) explicit trade-offs showing higher profits correspond to greater ecological shortfalls; and (iii) an integration based approach producing nearly 1000 Pareto optimal solutions within seconds, greatly outperforming earlier studies.","authors":["Nahid Sultana","M. M. Rizvi","G. M. Wali Ullah"],"pdf_url":"","comment":"25 pages, 1 figure"},{"id":"http://arxiv.org/abs/2310.15976v3","updated":"2026-01-08T02:59:38Z","published":"2023-10-24T16:25:13Z","title":"Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex Optimization","summary":"signSGD is popular in nonconvex optimization due to its communication efficiency. Yet, existing analyses typically assume data are sampled with replacement in each iteration, contradicting a common practical implementation where data are randomly reshuffled and sequentially fed into the algorithm. This gap leaves the theoretical understanding of the more practical algorithm, signSGD with random reshuffling (SignRR), largely unexplored. We develop the first analysis of SignRR to identify the core technical challenge that prevents a thorough convergence analysis of this method. In particular, given a dataset of size $n$ and $T$ epochs, we show that the expected gradient norm of SignRR is upper bounded by $O(\\log(nT)/\\sqrt{nT} + σ)$, where $σ$ is the averaged conditional mean square error that may not vanish. To tackle this limitation, we develop two new sign-based algorithms under random reshuffling: SignRVR, which incorporates variance-reduced gradients, and SignRVM, which integrates momentum-based updates. Both algorithms achieve a faster convergence rate of ${O}(\\log(nT)/\\sqrt{nT} +\\log(nT)\\sqrt{n}/\\sqrt{T})$. We further extend our algorithms to a distributed setting, with a convergence rate of ${O}(\\log(n_0T)/\\sqrt{n_0T} +\\log (n_0T)\\sqrt{n_0}/\\sqrt{T})$, where $n_0$ is the size of the dataset of a single machine. These results mark the first step towards the theoretical understanding of practical implementation of sign-based optimization algorithms. Finally, we back up our theoretical findings through experiments on simulated and real-world problems, verifying that randomly reshuffled sign methods match or surpass existing baselines.","authors":["Zhen Qin","Zhishuai Liu","Pan Xu"],"pdf_url":"","comment":"37 pages, 5 figures"}],"Performance":[{"id":"http://arxiv.org/abs/2601.05205v1","updated":"2026-01-08T18:31:11Z","published":"2026-01-08T18:31:11Z","title":"EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI","summary":"Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.","authors":["Zain Iqbal","Lorenzo Valerio"],"pdf_url":"","comment":"6 pages, 9 figures, 2 Tables, conference [Submitted in PerConAI-2026]"},{"id":"http://arxiv.org/abs/2601.04904v1","updated":"2026-01-08T13:03:56Z","published":"2026-01-08T13:03:56Z","title":"Parallel Quadratic Selected Inversion in Quantum Transport Simulation","summary":"Driven by Moore's Law, the dimensions of transistors have been pushed down to the nanometer scale. Advanced quantum transport (QT) solvers are required to accurately simulate such nano-devices. The non-equilibrium Green's function (NEGF) formalism lends itself optimally to these tasks, but it is computationally very intensive, involving the selected inversion (SI) of matrices and the selected solution of quadratic matrix (SQ) equations. Existing algorithms to tackle these numerical problems are ideally suited to GPU acceleration, e.g., the so-called recursive Green's function (RGF) technique, but they are typically sequential, require block-tridiagonal (BT) matrices as inputs, and their implementation has been so far restricted to shared memory parallelism, thus limiting the achievable device sizes. To address these shortcomings, we introduce distributed methods that build on RGF and enable parallel selected inversion and selected solution of the quadratic matrix equation. We further extend them to handle BT matrices with arrowhead, which allows for the investigation of multi-terminal transistor structures. We evaluate the performance of our approach on a real dataset from the QT simulation of a nano-ribbon transistor and compare it with the sparse direct package PARDISO. When scaling to 16 GPUs, our fused SI and SQ solver is 5.2x faster than the SI module of PARDISO applied to a device 16x shorter. These results highlight the potential of our method to accelerate NEGF-based nano-device simulations.","authors":["Vincent Maillou","Matthias Bollhofer","Olaf Schenk","Alexandros Nikolaos Ziogas","Mathieu Luisier"],"pdf_url":"","comment":"12 pages, 9 figures"},{"id":"http://arxiv.org/abs/2507.10367v4","updated":"2026-01-08T09:19:47Z","published":"2025-07-14T15:09:01Z","title":"FalconFS: Distributed File System for Large-Scale Deep Learning Pipeline","summary":"Client-side metadata caching has long been considered an effective method for accelerating metadata operations in distributed file systems (DFSs). However, we have found that client-side state (e.g., caching) is not only ineffective but also consumes valuable memory resources in the deep learning pipelines. We thus propose FalconFS, a DFS optimized for deep learning pipelines with the stateless-client architecture. Specifically, instead of performing client-side path resolution and caching, FalconFS efficiently resolves paths on the server side using hybrid metadata indexing and lazy namespace replication. FalconFS also boosts server concurrency with concurrent request merging and provides easy deployment with VFS shortcut. Evaluations against CephFS and Lustre show that FalconFS achieves up to 5.72$\\times$ throughput for small file read/write and up to 12.81$\\times$ throughput for deep learning model training. FalconFS has been running in Huawei autonomous driving system's production environment with 10,000 NPUs for one year and has been open-sourced.","authors":["Jingwei Xu","Junbin Kang","Mingkai Dong","Mingyu Liu","Lu Zhang","Shaohong Guo","Ziyan Qiu","Mingzhen You","Ziyi Tian","Anqi Yu","Tianhong Ding","Xinwei Hu","Haibo Chen"],"pdf_url":"","comment":"Accepted by NSDI'26"},{"id":"http://arxiv.org/abs/2601.04719v1","updated":"2026-01-08T08:35:56Z","published":"2026-01-08T08:35:56Z","title":"GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models","summary":"The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior","authors":["Maanas Taneja","Purab Shingvi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04707v1","updated":"2026-01-08T08:19:47Z","published":"2026-01-08T08:19:47Z","title":"MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training","summary":"Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \\boldmath $\\bm{4.6\\,\\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.","authors":["Irfan Ullah","Young-Koo Lee"],"pdf_url":"","comment":"IEEE Access 2025"},{"id":"http://arxiv.org/abs/2601.04545v1","updated":"2026-01-08T03:17:59Z","published":"2026-01-08T03:17:59Z","title":"Personalized Model-Based Design of Human Centric AI enabled CPS for Long term usage","summary":"Human centric critical systems are increasingly involving artificial intelligence to enable knowledge extraction from sensor collected data. Examples include medical monitoring and control systems, gesture based human computer interaction systems, and autonomous cars. Such systems are intended to operate for a long term potentially for a lifetime in many scenarios such as closed loop blood glucose control for Type 1 diabetics, self-driving cars, and monitoting systems for stroke diagnosis, and rehabilitation. Long term operation of such AI enabled human centric applications can expose them to corner cases for which their operation is may be uncertain. This can be due to many reasons such as inherent flaws in the design, limited resources for testing, inherent computational limitations of the testing methodology, or unknown use cases resulting from human interaction with the system. Such untested corner cases or cases for which the system performance is uncertain can lead to violations in the safety, sustainability, and security requirements of the system. In this paper, we analyze the existing techniques for safety, sustainability, and security analysis of an AI enabled human centric control system and discuss their limitations for testing the system for long term use in practice. We then propose personalized model based solutions for potentially eliminating such limitations.","authors":["Bernard Ngabonziza","Ayan Banerjee","Sandeep K. S. Gupta"],"pdf_url":"","comment":null}],"Computation and Language":[{"id":"http://arxiv.org/abs/2601.05242v1","updated":"2026-01-08T18:59:24Z","published":"2026-01-08T18:59:24Z","title":"GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization","summary":"As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.","authors":["Shih-Yang Liu","Xin Dong","Ximing Lu","Shizhe Diao","Peter Belcak","Mingjie Liu","Min-Hung Chen","Hongxu Yin","Yu-Chiang Frank Wang","Kwang-Ting Cheng","Yejin Choi","Jan Kautz","Pavlo Molchanov"],"pdf_url":"","comment":"NVIDIA-Tech Report"},{"id":"http://arxiv.org/abs/2601.05232v1","updated":"2026-01-08T18:57:01Z","published":"2026-01-08T18:57:01Z","title":"Measuring and Fostering Peace through Machine Learning and Artificial Intelligence","summary":"We used machine learning and artificial intelligence: 1) to measure levels of peace in countries from news and social media and 2) to develop on-line tools that promote peace by helping users better understand their own media diet. For news media, we used neural networks to measure levels of peace from text embeddings of on-line news sources. The model, trained on one news media dataset also showed high accuracy when used to analyze a different news dataset. For social media, such as YouTube, we developed other models to measure levels of social dimensions important in peace using word level (GoEmotions) and context level (Large Language Model) methods. To promote peace, we note that 71% of people 20-40 years old daily view most of their news through short videos on social media. Content creators of these videos are biased towards creating videos with emotional activation, making you angry to engage you, to increase clicks. We developed and tested a Chrome extension, MirrorMirror, which provides real-time feedback to YouTube viewers about the peacefulness of the media they are watching. Our long term goal is for MirrorMirror to evolve into an open-source tool for content creators, journalists, researchers, platforms, and individual users to better understand the tone of their media creation and consumption and its effects on viewers. Moving beyond simple engagement metrics, we hope to encourage more respectful, nuanced, and informative communication.","authors":["P. Gilda","P. Dungarwal","A. Thongkham","E. T. Ajayi","S. Choudhary","T. M. Terol","C. Lam","J. P. Araujo","M. McFadyen-Mungalln","L. S. Liebovitch","P. T. Coleman","H. West","K. Sieck","S. Carter"],"pdf_url":"","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.13467v3","updated":"2026-01-08T18:51:57Z","published":"2025-11-17T15:09:22Z","title":"Non-Linear Scoring Model for Translation Quality Evaluation","summary":"Analytic Translation Quality Evaluation (TQE), based on Multidimensional Quality Metrics (MQM), traditionally uses a linear error-to-penalty scale calibrated to a reference sample of 1000-2000 words. However, linear extrapolation biases judgment on samples of different sizes, over-penalizing short samples and under-penalizing long ones, producing misalignment with expert intuition.\n  Building on the Multi-Range framework, this paper presents a calibrated, non-linear scoring model that better reflects how human content consumers perceive translation quality across samples of varying length. Empirical data from three large-scale enterprise environments shows that acceptable error counts grow logarithmically, not linearly, with sample size.\n  Psychophysical and cognitive evidence, including the Weber-Fechner law and Cognitive Load Theory, supports this premise by explaining why the perceptual impact of additional errors diminishes while the cognitive burden grows with scale. We propose a two-parameter model\n  E(x) = a * ln(1 + b * x), a, b > 0,\n  anchored to a reference tolerance and calibrated from two tolerance points using a one-dimensional root-finding step. The model yields an explicit interval within which the linear approximation stays within +/-20 percent relative error and integrates into existing evaluation workflows with only a dynamic tolerance function added.\n  The approach improves interpretability, fairness, and inter-rater reliability across both human and AI-generated translations. By operationalizing a perceptually valid scoring paradigm, it advances translation quality evaluation toward more accurate and scalable assessment. The model also provides a stronger basis for AI-based document-level evaluation aligned with human judgment. Implementation considerations for CAT/LQA systems and implications for human and AI-generated text evaluation are discussed.","authors":["Serge Gladkoff","Lifeng Han","Katerina Gasova"],"pdf_url":"","comment":"ongoing work, 32 pages"},{"id":"http://arxiv.org/abs/2601.01266v2","updated":"2026-01-08T18:28:40Z","published":"2026-01-03T19:24:51Z","title":"From Policy to Logic for Efficient and Interpretable Coverage Assessment","summary":"Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.","authors":["Rhitabrat Pokharel","Hamid Reza Hassanzadeh","Ameeta Agrawal"],"pdf_url":"","comment":"Accepted at AIMedHealth @ AAAI 2026"},{"id":"http://arxiv.org/abs/2601.02015v2","updated":"2026-01-08T18:27:27Z","published":"2026-01-05T11:24:33Z","title":"Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects","summary":"Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.","authors":["Omar Momen","Emilie Sitter","Berenike Herrmann","Sina Zarrieß"],"pdf_url":"","comment":"to be published at EACL 2026 main conference"},{"id":"http://arxiv.org/abs/2601.05201v1","updated":"2026-01-08T18:23:03Z","published":"2026-01-08T18:23:03Z","title":"Mechanisms of Prompt-Induced Hallucination in Vision-Language Models","summary":"Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy. Through mechanistic analysis of three VLMs, we identify a small set of attention heads whose ablation substantially reduces prompt-induced hallucinations (PIH) by at least 40% without additional training. Across models, PIH-heads mediate prompt copying in model-specific ways. We characterize these differences and show that PIH ablation increases correction toward visual evidence. Our findings offer insights into the internal mechanisms driving prompt-induced hallucinations, revealing model-specific differences in how these behaviors are implemented.","authors":["William Rudman","Michal Golovanevsky","Dana Arad","Yonatan Belinkov","Ritambhara Singh","Carsten Eickhoff","Kyle Mahowald"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05192v1","updated":"2026-01-08T18:15:34Z","published":"2026-01-08T18:15:34Z","title":"LELA: an LLM-based Entity Linking Approach with Zero-Shot Domain Adaptation","summary":"Entity linking (mapping ambiguous mentions in text to entities in a knowledge base) is a foundational step in tasks such as knowledge graph construction, question-answering, and information extraction. Our method, LELA, is a modular coarse-to-fine approach that leverages the capabilities of large language models (LLMs), and works with different target domains, knowledge bases and LLMs, without any fine-tuning phase. Our experiments across various entity linking settings show that LELA is highly competitive with fine-tuned approaches, and substantially outperforms the non-fine-tuned ones.","authors":["Samy Haffoudhi","Fabian M. Suchanek","Nils Holzenberger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05184v1","updated":"2026-01-08T18:08:15Z","published":"2026-01-08T18:08:15Z","title":"Observations and Remedies for Large Language Model Bias in Self-Consuming Performative Loop","summary":"The rapid advancement of large language models (LLMs) has led to growing interest in using synthetic data to train future models. However, this creates a self-consuming retraining loop, where models are trained on their own outputs and may cause performance drops and induce emerging biases. In real-world applications, previously deployed LLMs may influence the data they generate, leading to a dynamic system driven by user feedback. For example, if a model continues to underserve users from a group, less query data will be collected from this particular demographic of users. In this study, we introduce the concept of \\textbf{S}elf-\\textbf{C}onsuming \\textbf{P}erformative \\textbf{L}oop (\\textbf{SCPL}) and investigate the role of synthetic data in shaping bias during these dynamic iterative training processes under controlled performative feedback. This controlled setting is motivated by the inaccessibility of real-world user preference data from dynamic production systems, and enables us to isolate and analyze feedback-driven bias evolution in a principled manner. We focus on two types of loops, including the typical retraining setting and the incremental fine-tuning setting, which is largely underexplored. Through experiments on three real-world tasks, we find that the performative loop increases preference bias and decreases disparate bias. We design a reward-based rejection sampling strategy to mitigate the bias, moving towards more trustworthy self-improving systems.","authors":["Yaxuan Wang","Zhongteng Cai","Yujia Bao","Xueru Zhang","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.21072v3","updated":"2026-01-08T18:06:58Z","published":"2025-05-27T11:56:59Z","title":"Faithfulness-Aware Uncertainty Quantification for Fact-Checking the Output of Retrieval Augmented Generation","summary":"Large Language Models (LLMs) enhanced with retrieval, an approach known as Retrieval-Augmented Generation (RAG), have achieved strong performance in open-domain question answering. However, RAG remains prone to hallucinations: factually incorrect outputs may arise from inaccuracies in the model's internal knowledge and the retrieved context. Existing approaches to mitigating hallucinations often conflate factuality with faithfulness to the retrieved evidence, incorrectly labeling factually correct statements as hallucinations if they are not explicitly supported by the retrieval. In this paper, we introduce FRANQ, a new method for hallucination detection in RAG outputs. FRANQ applies distinct uncertainty quantification (UQ) techniques to estimate factuality, conditioning on whether a statement is faithful to the retrieved context. To evaluate FRANQ and competing UQ methods, we construct a new long-form question answering dataset annotated for both factuality and faithfulness, combining automated labeling with manual validation of challenging cases. Extensive experiments across multiple datasets, tasks, and LLMs show that FRANQ achieves more accurate detection of factual errors in RAG-generated responses compared to existing approaches.","authors":["Ekaterina Fadeeva","Aleksandr Rubashevskii","Dzianis Piatrashyn","Roman Vashurin","Shehzaad Dhuliawala","Artem Shelmanov","Timothy Baldwin","Preslav Nakov","Mrinmaya Sachan","Maxim Panov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05171v1","updated":"2026-01-08T17:59:11Z","published":"2026-01-08T17:59:11Z","title":"Inside Out: Evolving User-Centric Core Memory Trees for Long-Term Personalized Dialogue Systems","summary":"Existing long-term personalized dialogue systems struggle to reconcile unbounded interaction streams with finite context constraints, often succumbing to memory noise accumulation, reasoning degradation, and persona inconsistency. To address these challenges, this paper proposes Inside Out, a framework that utilizes a globally maintained PersonaTree as the carrier of long-term user profiling. By constraining the trunk with an initial schema and updating the branches and leaves, PersonaTree enables controllable growth, achieving memory compression while preserving consistency. Moreover, we train a lightweight MemListener via reinforcement learning with process-based rewards to produce structured, executable, and interpretable {ADD, UPDATE, DELETE, NO_OP} operations, thereby supporting the dynamic evolution of the personalized tree. During response generation, PersonaTree is directly leveraged to enhance outputs in latency-sensitive scenarios; when users require more details, the agentic mode is triggered to introduce details on-demand under the constraints of the PersonaTree. Experiments show that PersonaTree outperforms full-text concatenation and various personalized memory systems in suppressing contextual noise and maintaining persona consistency. Notably, the small MemListener model achieves memory-operation decision performance comparable to, or even surpassing, powerful reasoning models such as DeepSeek-R1-0528 and Gemini-3-Pro.","authors":["Jihao Zhao","Ding Chen","Zhaoxin Fan","Kerun Xu","Mengting Hu","Bo Tang","Feiyu Xiong","Zhiyu li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05170v1","updated":"2026-01-08T17:58:52Z","published":"2026-01-08T17:58:52Z","title":"Reverse-engineering NLI: A study of the meta-inferential properties of Natural Language Inference","summary":"Natural Language Inference (NLI) has been an important task for evaluating language models for Natural Language Understanding, but the logical properties of the task are poorly understood and often mischaracterized. Understanding the notion of inference captured by NLI is key to interpreting model performance on the task. In this paper we formulate three possible readings of the NLI label set and perform a comprehensive analysis of the meta-inferential properties they entail. Focusing on the SNLI dataset, we exploit (1) NLI items with shared premises and (2) items generated by LLMs to evaluate models trained on SNLI for meta-inferential consistency and derive insights into which reading of the logical relations is encoded by the dataset.","authors":["Rasmus Blanck","Bill Noble","Stergios Chatzikyriakidis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05167v1","updated":"2026-01-08T17:56:16Z","published":"2026-01-08T17:56:16Z","title":"RelayLLM: Efficient Reasoning via Collaborative Decoding","summary":"Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.","authors":["Chengsong Huang","Tong Zheng","Langlin Huang","Jinyuan Li","Haolin Liu","Jiaxin Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05163v1","updated":"2026-01-08T17:54:32Z","published":"2026-01-08T17:54:32Z","title":"DocDancer: Towards Agentic Document-Grounded Information Seeking","summary":"Document Question Answering (DocQA) focuses on answering questions grounded in given documents, yet existing DocQA agents lack effective tool utilization and largely rely on closed-source models. In this work, we introduce DocDancer, an end-to-end trained open-source Doc agent. We formulate DocQA as an information-seeking problem and propose a tool-driven agent framework that explicitly models document exploration and comprehension. To enable end-to-end training of such agents, we introduce an Exploration-then-Synthesis data synthesis pipeline that addresses the scarcity of high-quality training data for DocQA. Training on the synthesized data, the trained models on two long-context document understanding benchmarks, MMLongBench-Doc and DocBench, show their effectiveness. Further analysis provides valuable insights for the agentic tool design and synthetic data.","authors":["Qintong Zhang","Xinjie Lv","Jialong Wu","Baixuan Li","Zhengwei Tao","Guochen Yan","Huanyao Zhang","Bin Wang","Jiahao Xu","Haitao Mi","Wentao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05143v1","updated":"2026-01-08T17:31:09Z","published":"2026-01-08T17:31:09Z","title":"A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering","summary":"Visual question answering for crop disease analysis requires accurate visual understanding and reliable language generation. This work presents a lightweight vision-language framework for crop and disease identification from leaf images. The proposed approach combines a Swin Transformer vision encoder with sequence-to-sequence language decoders. A two-stage training strategy is adopted to improve visual representation learning and cross-modal alignment. The model is evaluated on a large-scale crop disease dataset using classification and natural language generation metrics. Experimental results show high accuracy for both crop and disease identification. The framework also achieves strong performance on BLEU, ROUGE and BERTScore. Our proposed models outperform large-scale vision-language baselines while using significantly fewer parameters. Explainability is assessed using Grad-CAM and token-level attribution. Qualitative results demonstrate robust performance under diverse user-driven queries. These findings highlight the effectiveness of task-specific visual pretraining for crop disease visual question answering.","authors":["Md. Zahid Hossain","Most. Sharmin Sultana Samu","Md. Rakibul Islam","Md. Siam Ansary"],"pdf_url":"","comment":"Preprint, manuscript is under review"},{"id":"http://arxiv.org/abs/2503.18526v2","updated":"2026-01-08T17:04:29Z","published":"2025-03-24T10:31:31Z","title":"SciClaims: An End-to-End Generative System for Biomedical Claim Analysis","summary":"We present SciClaims, an interactive web-based system for end-to-end scientific claim analysis in the biomedical domain. Designed for high-stakes use cases such as systematic literature reviews and patent validation, SciClaims extracts claims from text, retrieves relevant evidence from PubMed, and verifies their veracity. The system features a user-friendly interface where users can input scientific text and view extracted claims, predictions, supporting or refuting evidence, and justifications in natural language. Unlike prior approaches, SciClaims seamlessly integrates the entire scientific claim analysis process using a single large language model, without requiring additional fine-tuning. SciClaims is optimized to run efficiently on a single GPU and is publicly available for live interaction.","authors":["Raúl Ortega","José Manuel Gómez-Pérez"],"pdf_url":"","comment":"In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: System Demonstrations"},{"id":"http://arxiv.org/abs/2507.11939v2","updated":"2026-01-08T17:00:25Z","published":"2025-07-16T06:09:02Z","title":"POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering","summary":"Charts are a universally adopted medium for data communication, yet existing chart understanding benchmarks are overwhelmingly English-centric, limiting their accessibility and relevance to global audiences. To address this limitation, we introduce PolyChartQA, the first large-scale multilingual benchmark for chart question answering, comprising 22,606 charts and 26,151 QA pairs across 10 diverse languages. PolyChartQA is constructed through a scalable pipeline that enables efficient multilingual chart generation via data translation and code reuse, supported by LLM-based translation and rigorous quality control. We systematically evaluate multilingual chart understanding with PolyChartQA on state-of-the-art LVLMs and reveal a significant performance gap between English and other languages, particularly low-resource ones. Additionally, we introduce a companion multilingual chart question answering training set, PolyChartQA-Train, on which fine-tuning LVLMs yields substantial gains in multilingual chart understanding across diverse model sizes and architectures. Together, our benchmark provides a foundation for developing globally inclusive vision-language models capable of understanding charts across diverse linguistic contexts.","authors":["Yichen Xu","Liangyu Chen","Liang Zhang","Jianzhe Ma","Wenxuan Wang","Qin Jin"],"pdf_url":"","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2505.23923v2","updated":"2026-01-08T16:58:59Z","published":"2025-05-29T18:15:18Z","title":"Act-Adaptive Margin: Dynamically Calibrating Reward Models for Subjective Ambiguity","summary":"Currently, most reinforcement learning tasks focus on domains like mathematics and programming, where verification is relatively straightforward. However, in subjective tasks such as role-playing, alignment techniques struggle to make progress, primarily because subjective reward modeling using the Bradley-Terry model faces significant challenges when dealing with ambiguous preferences. To improve reward modeling in subjective tasks, this paper proposes AAM (\\textbf{\\underline{A}}ct-\\textbf{\\underline{A}}daptive \\textbf{\\underline{M}}argin), which enhances reward modeling by dynamically calibrating preference margins using the model's internal parameter knowledge. We design two versions of AAM that efficiently generate contextually-appropriate preference gaps without additional human annotation. This approach fundamentally improves how reward models handle subjective rewards by better integrating generative understanding with preference scoring. To validate AAM's effectiveness in subjective reward modeling, we conduct evaluations on RewardBench, JudgeBench, and challenging role-playing tasks. Results show that AAM significantly improves subjective reward modeling performance, enhancing Bradley-Terry reward models by 2.95\\% in general tasks and 4.85\\% in subjective role-playing tasks. Furthermore, reward models trained with AAM can help downstream alignment tasks achieve better results. Our test results show that applying rewards generated by AAM-Augmented RM to preference learning techniques (e.g., GRPO) achieves state-of-the-art results on CharacterEval and Charm. Code and dataset are available at https://github.com/calubkk/AAM.","authors":["Feiteng Fang","Dingwei Chen","Xiang Huang","Ting-En Lin","Yuchuan Wu","Xiong Liu","Xinge Ye","Ziqiang Liu","Haonan Zhang","Liang Zhu","Hamid Alinejad-Rokny","Min Yang","Yongbin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05111v1","updated":"2026-01-08T16:58:10Z","published":"2026-01-08T16:58:10Z","title":"Agent-as-a-Judge","summary":"LLM-as-a-Judge has revolutionized AI evaluation by leveraging large language models for scalable assessments. However, as evaluands become increasingly complex, specialized, and multi-step, the reliability of LLM-as-a-Judge has become constrained by inherent biases, shallow single-pass reasoning, and the inability to verify assessments against real-world observations. This has catalyzed the transition to Agent-as-a-Judge, where agentic judges employ planning, tool-augmented verification, multi-agent collaboration, and persistent memory to enable more robust, verifiable, and nuanced evaluations. Despite the rapid proliferation of agentic evaluation systems, the field lacks a unified framework to navigate this shifting landscape. To bridge this gap, we present the first comprehensive survey tracing this evolution. Specifically, we identify key dimensions that characterize this paradigm shift and establish a developmental taxonomy. We organize core methodologies and survey applications across general and professional domains. Furthermore, we analyze frontier challenges and identify promising research directions, ultimately providing a clear roadmap for the next generation of agentic evaluation.","authors":["Runyang You","Hongru Cai","Caiqi Zhang","Qiancheng Xu","Meng Liu","Tiezheng Yu","Yongqi Li","Wenjie Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05106v1","updated":"2026-01-08T16:53:16Z","published":"2026-01-08T16:53:16Z","title":"Token-Level LLM Collaboration via FusionRoute","summary":"Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.","authors":["Nuoya Xiong","Yuhang Zhou","Hanqing Zeng","Zhaorun Chen","Furong Huang","Shuchao Bi","Lizhu Zhang","Zhuokai Zhao"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2601.05104v1","updated":"2026-01-08T16:50:00Z","published":"2026-01-08T16:50:00Z","title":"How Human is AI? Examining the Impact of Emotional Prompts on Artificial and Human and Responsiveness","summary":"This research examines how the emotional tone of human-AI interactions shapes ChatGPT and human behavior. In a between-subject experiment, we asked participants to express a specific emotion while working with ChatGPT (GPT-4.0) on two tasks, including writing a public response and addressing an ethical dilemma. We found that compared to interactions where participants maintained a neutral tone, ChatGPT showed greater improvement in its answers when participants praised ChatGPT for its responses. Expressing anger towards ChatGPT also led to a higher albeit smaller improvement relative to the neutral condition, whereas blaming ChatGPT did not improve its answers. When addressing an ethical dilemma, ChatGPT prioritized corporate interests less when participants expressed anger towards it, while blaming increases its emphasis on protecting the public interest. Additionally, we found that people used more negative, hostile, and disappointing expressions in human-human communication after interactions during which participants blamed rather than praised for their responses. Together, our findings demonstrate that the emotional tone people apply in human-AI interactions not only shape ChatGPT's outputs but also carry over into subsequent human-human communication.","authors":["Florence Bernays","Marco Henriques Pereira","Jochen Menges"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05103v1","updated":"2026-01-08T16:48:36Z","published":"2026-01-08T16:48:36Z","title":"Semantically Orthogonal Framework for Citation Classification: Disentangling Intent and Content","summary":"Understanding the role of citations is essential for research assessment and citation-aware digital libraries. However, existing citation classification frameworks often conflate citation intent (why a work is cited) with cited content type (what part is cited), limiting their effectiveness in auto classification due to a dilemma between fine-grained type distinctions and practical classification reliability. We introduce SOFT, a Semantically Orthogonal Framework with Two dimensions that explicitly separates citation intent from cited content type, drawing inspiration from semantic role theory. We systematically re-annotate the ACL-ARC dataset using SOFT and release a cross-disciplinary test set sampled from ACT2. Evaluation with both zero-shot and fine-tuned Large Language Models demonstrates that SOFT enables higher agreement between human annotators and LLMs, and supports stronger classification performance and robust cross-domain generalization compared to ACL-ARC and SciCite annotation frameworks. These results confirm SOFT's value as a clear, reusable annotation standard, improving clarity, consistency, and generalizability for digital libraries and scholarly communication infrastructures. All code and data are publicly available on GitHub https://github.com/zhiyintan/SOFT.","authors":["Changxu Duan","Zhiyin Tan"],"pdf_url":"","comment":"Accepted at the 29th International Conference on Theory and Practice of Digital Libraries (TPDL 2025)"},{"id":"http://arxiv.org/abs/2601.05099v1","updated":"2026-01-08T16:46:06Z","published":"2026-01-08T16:46:06Z","title":"Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts","summary":"Identifying suitable datasets for a research question remains challenging because existing dataset search engines rely heavily on metadata quality and keyword overlap, which often fail to capture the semantic intent of scientific investigation. We introduce a literature-driven framework that discovers datasets from citation contexts in scientific papers, enabling retrieval grounded in actual research use rather than metadata availability. Our approach combines large-scale citation-context extraction, schema-guided dataset recognition with Large Language Models, and provenance-preserving entity resolution. We evaluate the system on eight survey-derived computer science queries and find that it achieves substantially higher recall than Google Dataset Search and DataCite Commons, with normalized recall ranging from an average of 47.47% to a highest value of 81.82%. Beyond recovering gold-standard datasets, the method also surfaces additional datasets not documented in the surveys. Expert assessments across five top-level Fields of Science indicate that a substantial portion of the additional datasets are considered high utility, and some are regarded as novel for the specific topics chosen by the experts. These findings establish citation-context mining as an effective and generalizable paradigm for dataset discovery, particularly in settings where datasets lack sufficient or reliable metadata. To support reproducibility and future extensions, we release our code, evaluation datasets, and results on GitHub (https://github.com/Fireblossom/citation-context-dataset-discovery).","authors":["Zhiyin Tan","Changxu Duan"],"pdf_url":"","comment":"Accepted at the 25th ACM/IEEE Joint Conference on Digital Libraries (JCDL 2025)"},{"id":"http://arxiv.org/abs/2601.05091v1","updated":"2026-01-08T16:39:26Z","published":"2026-01-08T16:39:26Z","title":"Code-Mix Sentiment Analysis on Hinglish Tweets","summary":"The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.","authors":["Aashi Garg","Aneshya Das","Arshi Arya","Anushka Goyal"," Aditi"],"pdf_url":"","comment":"Accepted at the 9th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2025), Fukuoka, Japan"},{"id":"http://arxiv.org/abs/2506.15480v2","updated":"2026-01-08T16:32:25Z","published":"2025-06-18T14:13:56Z","title":"Instruction Tuning with and without Context: Behavioral Shifts and Downstream Impact","summary":"Instruction tuning is a widely used approach to improve the instruction-following ability of large language models (LLMs). Instruction-tuning datasets typically include a mixture of context-augmented and context-free examples, yet prior work has largely combined these data types without examining their distinct effects. In this paper, we investigate how training LLMs with or without context affects model behavior and downstream performance. First, in the text domain, we show that LLMs trained with context attend more strongly to the provided knowledge, achieving better grounding. We also observe that context-augmented training shifts how LLMs use knowledge: models store and leverage less on parametric knowledge and instead depend more on the provided context. Second, we observe that using LLM trained with context-augmented data as the backbone for vision-language models reduces hallucination and improves grounding in the visual domain. Finally, we explore practical strategies for real-world deployments where context availability varies. We show that maintaining separate context-augmented and context-free models and routing inputs between them yields more robust overall performance than training a single mixed model, as it better preserves their complementary strengths.","authors":["Hyunji Lee","Seunghyun Yoon","Yunjae Won","Hanseok Oh","Geewook Kim","Trung Bui","Franck Dernoncourt","Elias Stengel-Eskin","Mohit Bansal","Minjoon Seo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.03259v2","updated":"2026-01-08T16:22:24Z","published":"2025-06-03T18:00:08Z","title":"Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems","summary":"Purpose: This study aims to evaluate the effectiveness of large language models (LLMs) in automating disease annotation of CT radiology reports. We compare a rule-based algorithm (RBA), RadBERT, and three lightweight open-weight LLMs for multi-disease labeling of chest, abdomen, and pelvis (CAP) CT reports.\n  Materials and Methods: This retrospective study analyzed 40,833 chest-abdomen-pelvis (CAP) CT reports from 29,540 patients, with 1,789 reports manually annotated across three organ systems. External validation was conducted using the CT RATE dataset. Three open-weight LLMs were tested with zero-shot prompting. Performance was evaluated using Cohen's Kappa ($κ$) and micro/macro-averaged F1 scores.\n  Results: In the internal test set of 12,197 CAP reports from 8,854 patients, Llama-3.1 8B and Gemma-3 27B showed the highest agreement ($κ$ median: 0.87). On the manually annotated set, Gemma-3 27B achieved the top macro-F1 (0.82), followed by Llama-3.1 8B (0.79), while the RBA scored lowest (0.64). On the CT RATE dataset (lungs/pleura labels only), Llama-3.1 8B performed best (0.91), with Gemma-3 27B close behind (0.89). Performance differences were mainly due to differing labeling practices, especially for labels with high subjectivity such as atelectasis.\n  Conclusion: Lightweight LLMs outperform rule-based methods for CT report annotation and generalize across organ systems with zero-shot prompting. However, binary labels alone cannot capture the full nuance of report language. LLMs can provide a flexible, efficient solution aligned with clinical judgment and user needs.","authors":["Michael E. Garcia-Alcoser","Mobina GhojoghNejad","Fakrul Islam Tushar","David Kim","Kyle J. Lafata","Geoffrey D. Rubin","Joseph Y. Lo"],"pdf_url":"","comment":"18 pages, 9 figures, to be submitted in Radiology: Artificial Intelligence"},{"id":"http://arxiv.org/abs/2601.05075v1","updated":"2026-01-08T16:19:24Z","published":"2026-01-08T16:19:24Z","title":"SemPA: Improving Sentence Embeddings of Large Language Models through Semantic Preference Alignment","summary":"Traditional sentence embedding methods employ token-level contrastive learning on non-generative pre-trained models. Recently, there have emerged embedding methods based on generative large language models (LLMs). These methods either rely on fixed prompt templates or involve modifications to the model architecture. The former lacks further optimization of the model and results in limited performance, while the latter alters the internal computational mechanisms of the model, thereby compromising its generative capabilities. We propose SemPA, a novel approach that boosts the sentence representations while preserving the generative ability of LLMs via semantic preference alignment. We leverage sentence-level Direct Preference Optimization (DPO) to efficiently optimize LLMs on a paraphrase generation task, where the model learns to discriminate semantically equivalent sentences while preserving inherent generative capacity. Theoretically, we establish a formal connection between DPO and contrastive learning under the Plackett-Luce model framework. Empirically, experimental results on both semantic textual similarity tasks and various benchmarks for LLMs show that SemPA achieves better semantic representations without sacrificing the inherent generation capability of LLMs.","authors":["Ziyang Chen","Zhenxuan Huang","Yile Wang","Weiqin Wang","Lu Yin","Hui Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05062v1","updated":"2026-01-08T16:08:44Z","published":"2026-01-08T16:08:44Z","title":"Compositional Steering of Large Language Models with Steering Tokens","summary":"Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.","authors":["Gorjan Radevski","Kiril Gashteovski","Giwon Hong","Carolin Lawrence","Goran Glavaš"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.21007v3","updated":"2026-01-08T16:05:16Z","published":"2025-10-23T21:33:28Z","title":"Can Confidence Estimates Decide When Chain-of-Thought Is Necessary for LLMs?","summary":"Chain-of-thought (CoT) prompting is a common technique for improving the reasoning abilities of large language models (LLMs). However, extended reasoning is often unnecessary and substantially increases token usage. As such, a key question becomes how to optimally allocate compute to when reasoning is actually needed. We study this through confidence-gated CoT, where a model produces a direct answer and a confidence estimate to decide whether to invoke CoT. We present an evaluation framework together with the first systematic study of confidence signals for this decision. We evaluate four representative confidence measures and compare them with random gating and an oracle upper bound. Experiments across two model families and diverse reasoning tasks show that existing training-free confidence measures can reduce redundant reasoning. However, we also find that the utility of individual confidence measures is inconsistent across settings. Through our evaluation framework and analysis, our study provides practical guidance toward developing and evaluating models that selectively use CoT.","authors":["Samuel Lewis-Lim","Xingwei Tan","Zhixue Zhao","Nikolaos Aletras"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2601.05053v1","updated":"2026-01-08T15:56:44Z","published":"2026-01-08T15:56:44Z","title":"Reinforced Efficient Reasoning via Semantically Diverse Exploration","summary":"Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.","authors":["Ziqi Zhao","Zhaochun Ren","Jiahong Zou","Liu Yang","Zhiwei Xu","Xuri Ge","Zhumin Chen","Xinyu Ma","Daiting Shi","Shuaiqiang Wang","Dawei Yin","Xin Xin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05051v1","updated":"2026-01-08T15:56:17Z","published":"2026-01-08T15:56:17Z","title":"Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence","summary":"Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.","authors":["Jennifer D'Souza","Soren Auer","Eleni Poupaki","Alex Watkins","Anjana Devi","Riikka L. Puurunen","Bora Karasulu","Adrie Mackus","Erwin Kessels"],"pdf_url":"","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2502.13691v3","updated":"2026-01-08T15:44:53Z","published":"2025-02-19T13:03:06Z","title":"Is This Collection Worth My LLM's Time? Automatically Measuring Information Potential in Text Corpora","summary":"As large language models (LLMs) converge towards similar capabilities, the key to advancing their performance lies in identifying and incorporating valuable new information sources. However, evaluating which text collections are worth the substantial investment required for digitization, preprocessing, and integration into LLM systems remains a significant challenge. We present a novel approach to this challenge: an automated pipeline that evaluates the potential information gain from text collections without requiring model training or fine-tuning. Our method generates multiple choice questions (MCQs) from texts and measures an LLM's performance both with and without access to the source material. The performance gap between these conditions serves as a proxy for the collection's information potential. We validate our approach using five strategically selected datasets: EPFL PhD manuscripts, a private collection of Venetian historical records, two sets of Wikipedia articles on related topics, and a synthetic baseline dataset. Our results demonstrate that this method effectively identifies collections containing valuable novel information, providing a practical tool for prioritizing data acquisition and integration efforts.","authors":["Tristan Karch","Luca Engel","Philippe Schwaller","Frédéric Kaplan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05038v1","updated":"2026-01-08T15:44:52Z","published":"2026-01-08T15:44:52Z","title":"ArcAligner: Adaptive Recursive Aligner for Compressed Context Embeddings in RAG","summary":"Retrieval-Augmented Generation (RAG) helps LLMs stay accurate, but feeding long documents into a prompt makes the model slow and expensive. This has motivated context compression, ranging from token pruning and summarization to embedding-based compression. While researchers have tried ''compressing'' these documents into smaller summaries or mathematical embeddings, there is a catch: the more you compress the data, the more the LLM struggles to understand it. To address this challenge, we propose ArcAligner (Adaptive recursive context *Aligner*), a lightweight module integrated into the language model layers to help the model better utilize highly compressed context representations for downstream generation. It uses an adaptive ''gating'' system that only adds extra processing power when the information is complex, keeping the system fast. Across knowledge-intensive QA benchmarks, ArcAligner consistently beats compression baselines at comparable compression rates, especially on multi-hop and long-tail settings. The source code is publicly available.","authors":["Jianbo Li","Yi Jiang","Sendong Zhao","Bairui Hu","Haochun Wang","Bing Qin"],"pdf_url":"","comment":"Code is available at https://github.com/liunian-Jay/ArcAligner.git"},{"id":"http://arxiv.org/abs/2601.05019v1","updated":"2026-01-08T15:27:03Z","published":"2026-01-08T15:27:03Z","title":"Hán Dān Xué Bù (Mimicry) or Qīng Chū Yú Lán (Mastery)? A Cognitive Perspective on Reasoning Distillation in Large Language Models","summary":"Recent Large Reasoning Models trained via reinforcement learning exhibit a \"natural\" alignment with human cognitive costs. However, we show that the prevailing paradigm of reasoning distillation -- training student models to mimic these traces via Supervised Fine-Tuning (SFT) -- fails to transmit this cognitive structure. Testing the \"Hán Dān Xué Bù\" (Superficial Mimicry) hypothesis across 14 models, we find that distillation induces a \"Functional Alignment Collapse\": while teacher models mirror human difficulty scaling ($\\bar{r}=0.64$), distilled students significantly degrade this alignment ($\\bar{r}=0.34$), often underperforming their own pre-distillation baselines (\"Negative Transfer\"). Our analysis suggests that SFT induces a \"Cargo Cult\" effect, where students ritualistically replicate the linguistic form of reasoning (verbosity) without internalizing the teacher's dynamic resource allocation policy. Consequently, reasoning distillation decouples computational cost from cognitive demand, revealing that human-like cognition is an emergent property of active reinforcement, not passive imitation.","authors":["Yueqing Hu","Xinyang Peng","Shuting Peng","Hanqi Wang","Tianhong Wang"],"pdf_url":"","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.13368v2","updated":"2026-01-08T15:10:27Z","published":"2025-11-17T13:41:31Z","title":"Donors and Recipients: On Asymmetric Transfer Across Tasks and Languages with Parameter-Efficient Fine-Tuning","summary":"Large language models (LLMs) perform strongly across tasks and languages, yet how improvements in one task or language affect other tasks and languages remains poorly understood. We conduct a controlled LoRA fine-tuning study across multiple open-weight LLM families and scales, using a standardised grid of 11 languages and four benchmarks. We fine-tune each model on a single task-language source and measure transfer when evaluated on all other task-language target pairs. We decompose transfer into three regimes: (i) Matched-Task (Cross-Language), (ii) Matched-Language (Cross-Task), and (iii) Cross-Task (Cross-Language). Single-source fine-tuning yields a net positive uplift across regimes, but the gains are strongly asymmetric. Matched-Task (Cross-Language) transfer emerges as the most effective and predictable regime, driven principally by the identity of the target language rather than model architecture. We identify a stable hierarchy where high-resource languages and broad semantic tasks act as efficient recipients that absorb gains from diverse sources, while specialised tasks and lower-resource languages are more isolated. These results imply that effective fine-tuning requires navigating donor-recipient roles to maximise downstream gains.","authors":["Kajetan Dymkiewicz","Ivan Vulic","Helen Yannakoudakis","Eilam Shapira","Roi Reichart","Anna Korhonen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05004v1","updated":"2026-01-08T15:02:41Z","published":"2026-01-08T15:02:41Z","title":"Can Large Language Models Resolve Semantic Discrepancy in Self-Destructive Subcultures? Evidence from Jirai Kei","summary":"Self-destructive behaviors are linked to complex psychological states and can be challenging to diagnose. These behaviors may be even harder to identify within subcultural groups due to their unique expressions. As large language models (LLMs) are applied across various fields, some researchers have begun exploring their application for detecting self-destructive behaviors. Motivated by this, we investigate self-destructive behavior detection within subcultures using current LLM-based methods. However, these methods have two main challenges: (1) Knowledge Lag: Subcultural slang evolves rapidly, faster than LLMs' training cycles; and (2) Semantic Misalignment: it is challenging to grasp the specific and nuanced expressions unique to subcultures. To address these issues, we proposed Subcultural Alignment Solver (SAS), a multi-agent framework that incorporates automatic retrieval and subculture alignment, significantly enhancing the performance of LLMs in detecting self-destructive behavior. Our experimental results show that SAS outperforms the current advanced multi-agent framework OWL. Notably, it competes well with fine-tuned LLMs. We hope that SAS will advance the field of self-destructive behavior detection in subcultural contexts and serve as a valuable resource for future researchers.","authors":["Peng Wang","Xilin Tao","Siyi Yao","Jiageng Wu","Yuntao Zou","Zhuotao Tian","Libo Qin","Dagang Li"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2601.05002v1","updated":"2026-01-08T15:00:35Z","published":"2026-01-08T15:00:35Z","title":"On the Hidden Objective Biases of Group-based Reinforcement Learning","summary":"Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.","authors":["Aleksandar Fontana","Marco Simoni","Giulio Rossolini","Andrea Saracino","Paolo Mori"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.10424v2","updated":"2026-01-08T14:58:52Z","published":"2024-02-16T03:20:14Z","title":"Pelican Soup Framework: A Theoretical Framework for Language Model Capabilities","summary":"In this work, we propose a simple theoretical framework, Pelican Soup, aiming to better understand how pretraining allows LLMs to (1) generalize to unseen instructions and (2) perform in-context learning, even when the verbalizers are irrelevant to the task. To this end, in our framework, we introduce the notion of \"knowledge base\" and \"reference-sense association\" and a simple formalism for natural language processing tasks. Our framework demonstrates how linguistic, psychology, and philosophy studies can inform our understanding of the language model and is connected to several other existing theoretical results. As an illustration of the usage of our framework, we derive a bound on in-context learning loss with our framework. Finally, we support our framework with empirical experiments and provide possible future research directions.","authors":["Ting-Rui Chiang","Dani Yogatama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03042v2","updated":"2026-01-08T14:57:18Z","published":"2026-01-06T14:22:21Z","title":"BaseCal: Unsupervised Confidence Calibration via Base Model Signals","summary":"Reliable confidence is essential for trusting the outputs of LLMs, yet widely deployed post-trained LLMs (PoLLMs) typically compromise this trust with severe overconfidence. In contrast, we observe that their corresponding base LLMs often remain well-calibrated. This naturally motivates us to calibrate PoLLM confidence using the base LLM as a reference. This work proposes two ways to achieve this. A straightforward solution, BaseCal-ReEval, evaluates PoLLM's responses by feeding them into the base LLM to get average probabilities as confidence. While effective, this approach introduces additional inference overhead. To address this, we propose BaseCal-Proj, which trains a lightweight projection to map the final-layer hidden states of PoLLMs back to those of their base LLMs. These projected states are then processed by the base LLM's output layer to derive base-calibrated confidence for PoLLM's responses. Notably, BaseCal is an unsupervised, plug-and-play solution that operates without human labels or LLM modifications. Experiments across five datasets and three LLM families demonstrate the effectiveness of BaseCal, reducing Expected Calibration Error (ECE) by an average of 42.90\\% compared to the best unsupervised baselines.","authors":["Hexiang Tan","Wanli Yang","Junwei Zhang","Xin Chen","Rui Tang","Du Su","Jingang Wang","Yuanzhuo Wang","Fei Sun","Xueqi Cheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19455v3","updated":"2026-01-08T14:54:45Z","published":"2025-12-22T15:00:25Z","title":"SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation","summary":"Open-weights large language models remain difficult to deploy for Thai due to unstable generation under complex instructions, despite strong English performance. To mitigate these limitations, We present SiamGPT-32B, an open-weights model based on Qwen3-32B, fine-tuned with a Quality-First strategy emphasizing curated supervision over data scale. The fine-tuning pipeline combines high-complexity English instruction data with a Thai-adapted AutoIF framework for instruction and linguistic constraints. Using supervised fine-tuning only, without continual pretraining or corpus expansion, SiamGPT-32B improves instruction adherence, multi-turn robustness, and linguistic stability. Evaluations on the SEA-HELM benchmark show that SiamGPT-32B achieves the strongest overall performance among similar-scale open-weights Thai models, with consistent gains in instruction following, multi-turn dialogue, and natural language understanding.","authors":["Thittipat Pairatsuppawat","Abhibhu Tachaapornchai","Paweekorn Kusolsomboon","Chutikan Chaiwong","Thodsaporn Chay-intr","Kobkrit Viriyayudhakorn","Nongnuch Ketui","Aslan B. Wong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04992v1","updated":"2026-01-08T14:49:10Z","published":"2026-01-08T14:49:10Z","title":"Learning from Mistakes: Negative Reasoning Samples Enhance Out-of-Domain Generalization","summary":"Supervised fine-tuning (SFT) on chain-of-thought (CoT) trajectories demonstrations is a common approach for enabling reasoning in large language models. Standard practices typically only retain trajectories with correct final answers (positives) while ignoring the rest (negatives). We argue that this paradigm discards substantial supervision and exacerbates overfitting, limiting out-of-domain (OOD) generalization. Specifically, we surprisingly find that incorporating negative trajectories into SFT yields substantial OOD generalization gains over positive-only training, as these trajectories often retain valid intermediate reasoning despite incorrect final answers. To understand this effect in depth, we systematically analyze data, training dynamics, and inference behavior, identifying 22 recurring patterns in negative chains that serve a dual role: they moderate loss descent to mitigate overfitting during training and boost policy entropy by 35.67% during inference to facilitate exploration. Motivated by these observations, we further propose Gain-based LOss Weighting (GLOW), an adaptive, sample-aware scheme that exploits such distinctive training dynamics by rescaling per-sample loss based on inter-epoch progress. Empirically, GLOW efficiently leverages unfiltered trajectories, yielding a 5.51% OOD gain over positive-only SFT on Qwen2.5-7B and boosting MMLU from 72.82% to 76.47% as an RL initialization.","authors":["Xueyun Tian","Minghua Ma","Bingbing Xu","Nuoyan Lyu","Wei Li","Heng Dong","Zheng Chu","Yuanzhuo Wang","Huawei Shen"],"pdf_url":"","comment":"Code and data are available at https://github.com/Eureka-Maggie/GLOW"},{"id":"http://arxiv.org/abs/2601.04160v2","updated":"2026-01-08T14:39:03Z","published":"2026-01-07T18:18:28Z","title":"All That Glisters Is Not Gold: A Benchmark for Reference-Free Counterfactual Financial Misinformation Detection","summary":"We introduce RFC Bench, a benchmark for evaluating large language models on financial misinformation under realistic news. RFC Bench operates at the paragraph level and captures the contextual complexity of financial news where meaning emerges from dispersed cues. The benchmark defines two complementary tasks: reference free misinformation detection and comparison based diagnosis using paired original perturbed inputs. Experiments reveal a consistent pattern: performance is substantially stronger when comparative context is available, while reference free settings expose significant weaknesses, including unstable predictions and elevated invalid outputs. These results indicate that current models struggle to maintain coherent belief states without external grounding. By highlighting this gap, RFC Bench provides a structured testbed for studying reference free reasoning and advancing more reliable financial misinformation detection in real world settings.","authors":["Yuechen Jiang","Zhiwei Liu","Yupeng Cao","Yueru He","Chen Xu","Ziyang Xu","Zhiyang Deng","Prayag Tiwari","Xi Chen","Alejandro Lopez-Lira","Jimin Huang","Junichi Tsujii","Sophia Ananiadou"],"pdf_url":"","comment":"49 pages; 24 figures"},{"id":"http://arxiv.org/abs/2502.18770v4","updated":"2026-01-08T14:33:47Z","published":"2025-02-26T02:57:59Z","title":"Reward Shaping to Mitigate Reward Hacking in RLHF","summary":"Reinforcement Learning from Human Feedback (RLHF) is essential for aligning large language models (LLMs) with human values. However, RLHF is susceptible to \\emph{reward hacking}, where the agent exploits flaws in the reward function rather than learning the intended behavior, thus degrading alignment. Although reward shaping helps stabilize RLHF and partially mitigate reward hacking, a systematic investigation into shaping techniques and their underlying principles remains lacking. To bridge this gap, we present a comprehensive study of the prevalent reward shaping methods. Our analysis suggests two key design principles: (1) the RL reward should be bounded, and (2) the RL reward benefits from rapid initial growth followed by gradual convergence. Guided by these insights, we propose Preference As Reward (PAR), a novel approach that leverages the latent preferences embedded within the reward model as the signal for reinforcement learning. Moreover, PAR exhibits two critical variance-reduction properties that contribute to stabilizing the RLHF training process and effectively extending the tolerance window for early stopping. We evaluated PAR on the base model Gemma2-2B using two datasets, Ultrafeedback-Binarized and HH-RLHF. Experimental results demonstrate PAR's superior performance over other reward shaping methods. On the AlpacaEval 2.0 benchmark, PAR achieves a win rate of at least 5 percentage points higher than competing approaches. Furthermore, PAR exhibits remarkable data efficiency, requiring only a single reference reward for optimal performance, and maintains robustness against reward hacking even after two full epochs of training. The code is available at https://github.com/PorUna-byte/PAR.","authors":["Jiayi Fu","Xuandong Zhao","Chengyuan Yao","Heng Wang","Qi Han","Yanghua Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03973v2","updated":"2026-01-08T14:25:41Z","published":"2026-01-07T14:40:48Z","title":"Muse: Towards Reproducible Long-Form Song Generation with Fine-Grained Style Control","summary":"Recent commercial systems such as Suno demonstrate strong capabilities in long-form song generation, while academic research remains largely non-reproducible due to the lack of publicly available training data, hindering fair comparison and progress. To this end, we release a fully open-source system for long-form song generation with fine-grained style conditioning, including a licensed synthetic dataset, training and evaluation pipelines, and Muse, an easy-to-deploy song generation model. The dataset consists of 116k fully licensed synthetic songs with automatically generated lyrics and style descriptions paired with audio synthesized by SunoV5. We train Muse via single-stage supervised finetuning of a Qwen-based language model extended with discrete audio tokens using MuCodec, without task-specific losses, auxiliary objectives, or additional architectural components. Our evaluations find that although Muse is trained with a modest data scale and model size, it achieves competitive performance on phoneme error rate, text--music style similarity, and audio aesthetic quality, while enabling controllable segment-level generation across different musical structures. All data, model weights, and training and evaluation pipelines will be publicly released, paving the way for continued progress in controllable long-form song generation research. The project repository is available at https://github.com/yuhui1038/Muse.","authors":["Changhao Jiang","Jiahao Chen","Zhenghao Xiang","Zhixiong Yang","Hanchen Wang","Jiabao Zhuang","Xinmeng Che","Jiajun Sun","Hui Li","Yifei Cao","Shihan Dou","Ming Zhang","Junjie Ye","Tao Ji","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04973v1","updated":"2026-01-08T14:22:58Z","published":"2026-01-08T14:22:58Z","title":"ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning","summary":"Recent breakthroughs in Large Reasoning Models (LRMs) have demonstrated that extensive Chain-of-Thought (CoT) generation is critical for enabling intricate cognitive behaviors, such as self-verification and backtracking, to solve complex tasks. However, this capability often leads to ``overthinking'', where models generate redundant reasoning paths that inflate computational costs without improving accuracy. While Supervised Fine-Tuning (SFT) on reasoning traces is a standard paradigm for the 'cold start' phase, applying existing compression techniques to these traces often compromises logical coherence or incurs prohibitive sampling costs. In this paper, we introduce ConMax (Confidence-Maximizing Compression), a novel reinforcement learning framework designed to automatically compress reasoning traces while preserving essential reasoning patterns. ConMax formulates compression as a reward-driven optimization problem, training a policy to prune redundancy by maximizing a weighted combination of answer confidence for predictive fidelity and thinking confidence for reasoning validity through a frozen auxiliary LRM. Extensive experiments across five reasoning datasets demonstrate that ConMax achieves a superior efficiency-performance trade-off. Specifically, it reduces inference length by 43% over strong baselines at the cost of a mere 0.7% dip in accuracy, proving its effectiveness in generating high-quality, efficient training data for LRMs.","authors":["Minda Hu","Zexuan Qiu","Zenan Xu","Kun Li","Bo Zhou","Irwin King"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04963v1","updated":"2026-01-08T14:09:17Z","published":"2026-01-08T14:09:17Z","title":"Text as a Universal Interface for Transferable Personalization","summary":"We study the problem of personalization in large language models (LLMs). Prior work predominantly represents user preferences as implicit, model-specific vectors or parameters, yielding opaque ``black-box'' profiles that are difficult to interpret and transfer across models and tasks. In contrast, we advocate natural language as a universal, model- and task-agnostic interface for preference representation. The formulation leads to interpretable and reusable preference descriptions, while naturally supporting continual evolution as new interactions are observed. To learn such representations, we introduce a two-stage training framework that combines supervised fine-tuning on high-quality synthesized data with reinforcement learning to optimize long-term utility and cross-task transferability. Based on this framework, we develop AlignXplore+, a universal preference reasoning model that generates textual preference summaries. Experiments on nine benchmarks show that our 8B model achieves state-of-the-art performanc -- outperforming substantially larger open-source models -- while exhibiting strong transferability across tasks, model families, and interaction formats.","authors":["Yuting Liu","Jian Guan","Jia-Nan Li","Wei Wu","Jiang-Ming Yang","Jianzhe Zhao","Guibing Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04960v1","updated":"2026-01-08T14:07:30Z","published":"2026-01-08T14:07:30Z","title":"A Unified Spoken Language Model with Injected Emotional-Attribution Thinking for Human-like Interaction","summary":"This paper presents a unified spoken language model for emotional intelligence, enhanced by a novel data construction strategy termed Injected Emotional-Attribution Thinking (IEAT). IEAT incorporates user emotional states and their underlying causes into the model's internal reasoning process, enabling emotion-aware reasoning to be internalized rather than treated as explicit supervision. The model is trained with a two-stage progressive strategy. The first stage performs speech-text alignment and emotional attribute modeling via self-distillation, while the second stage conducts end-to-end cross-modal joint optimization to ensure consistency between textual and spoken emotional expressions. Experiments on the Human-like Spoken Dialogue Systems Challenge (HumDial) Emotional Intelligence benchmark demonstrate that the proposed approach achieves top-ranked performance across emotional trajectory modeling, emotional reasoning, and empathetic response generation under both LLM-based and human evaluations.","authors":["Qing Wang","Zehan Li","Yaodong Song","Hongjie Chen","Jian Kang","Jie Lian","Jie Li","Yongxiang Li","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.12089v5","updated":"2026-01-08T13:35:28Z","published":"2025-09-15T16:16:57Z","title":"RadarPLM: Adapting Pre-trained Language Models for Marine Radar Target Detection by Selective Fine-tuning","summary":"Recent advances in pre-trained language models (PLMs) have demonstrated their capabilities in capturing universal knowledge, making them promising for radar signal processing applications. Nevertheless, directly fine-tuning PLMs on radar signals is both computationally expensive and prone to overfitting, particularly in low signal-to-clutter ratio (SCR) environments. In this paper, we propose a fine-tuning framework for PLM-based marine radar target detection. First, we design a lightweight adaptation module, enabling computationally efficient fine-tuning while preserving the pre-trained model's general knowledge. Second, a novel preference-aware loss is developed to selectively optimize different feature patches based on their online-evaluated learning values, guiding the model to concentrate on those generalizable feature patterns during optimization. Finally, a binary classification head is retrained based on autoencoder network to further enhance detection performance. Experiments on real-world radar data show that the proposed RadarPLM framework yields at least a 6.35% improvement in detection performance over the existing networks under low SCR conditions. Especially, in the small-sample training cases, the proposed RadarPLM also achieves a significant advantage over existing networks owing to the incorporation of the PLM.","authors":["Qiying Hu","Yaowen Li","Shengyi Zhang","Chuan Huang","Yu Liu","You He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04932v1","updated":"2026-01-08T13:30:30Z","published":"2026-01-08T13:30:30Z","title":"GenProve: Learning to Generate Text with Fine-Grained Provenance","summary":"Large language models (LLM) often hallucinate, and while adding citations is a common solution, it is frequently insufficient for accountability as users struggle to verify how a cited source supports a generated claim. Existing methods are typically coarse-grained and fail to distinguish between direct quotes and complex reasoning. In this paper, we introduce Generation-time Fine-grained Provenance, a task where models must generate fluent answers while simultaneously producing structured, sentence-level provenance triples. To enable this, we present ReFInE (Relation-aware Fine-grained Interpretability & Evidence), a dataset featuring expert verified annotations that distinguish between Quotation, Compression, and Inference. Building on ReFInE, we propose GenProve, a framework that combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO). By optimizing a composite reward for answer fidelity and provenance correctness, GenProve significantly outperforms 14 strong LLMs in joint evaluation. Crucially, our analysis uncovers a reasoning gap where models excel at surface-level quotation but struggle significantly with inference-based provenance, suggesting that verifiable reasoning remains a frontier challenge distinct from surface-level citation.","authors":["Jingxuan Wei","Xingyue Wang","Yanghaoyu Liao","Jie Dong","Yuchen Liu","Caijun Jia","Bihui Yu","Junnan Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06842v2","updated":"2026-01-08T13:25:34Z","published":"2025-06-07T15:46:02Z","title":"PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation","summary":"Disinformation detection is a key aspect of media literacy. Psychological studies have shown that knowledge of persuasive fallacies helps individuals detect disinformation. Inspired by these findings, we experimented with large language models (LLMs) to test whether infusing persuasion knowledge enhances disinformation detection. As a result, we introduce the Persuasion-Augmented Chain of Thought (PCoT), a novel approach that leverages persuasion to improve disinformation detection in zero-shot classification. We extensively evaluate PCoT on online news and social media posts. Moreover, we publish two novel, up-to-date disinformation datasets: EUDisinfo and MultiDis. These datasets enable the evaluation of PCoT on content entirely unseen by the LLMs used in our experiments, as the content was published after the models' knowledge cutoffs. We show that, on average, PCoT outperforms competitive methods by 15% across five LLMs and five datasets. These findings highlight the value of persuasion in strengthening zero-shot disinformation detection.","authors":["Arkadiusz Modzelewski","Witold Sosnowski","Tiziano Labruna","Adam Wierzbicki","Giovanni Da San Martino"],"pdf_url":"","comment":"Accepted to ACL 2025 Main Conference"},{"id":"http://arxiv.org/abs/2601.03997v2","updated":"2026-01-08T13:24:16Z","published":"2026-01-07T15:06:53Z","title":"VotIE: Information Extraction from Meeting Minutes","summary":"Municipal meeting minutes record key decisions in local democratic processes. Unlike parliamentary proceedings, which typically adhere to standardized formats, they encode voting outcomes in highly heterogeneous, free-form narrative text that varies widely across municipalities, posing significant challenges for automated extraction. In this paper, we introduce VotIE (Voting Information Extraction), a new information extraction task aimed at identifying structured voting events in narrative deliberative records, and establish the first benchmark for this task using Portuguese municipal minutes, building on the recently introduced CitiLink corpus. Our experiments yield two key findings. First, under standard in-domain evaluation, fine-tuned encoders, specifically XLM-R-CRF, achieve the strongest performance, reaching 93.2\\% macro F1, outperforming generative approaches. Second, in a cross-municipality setting that evaluates transfer to unseen administrative contexts, these models suffer substantial performance degradation, whereas few-shot LLMs demonstrate greater robustness, with significantly smaller declines in performance. Despite this generalization advantage, the high computational cost of generative models currently constrains their practicality. As a result, lightweight fine-tuned encoders remain a more practical option for large-scale, real-world deployment. To support reproducible research in administrative NLP, we publicly release our benchmark, trained models, and evaluation framework.","authors":["José Pedro Evans","Luís Filipe Cunha","Purificação Silvano","Alípio Jorge","Nuno Guimarães","Sérgio Nunes","Ricardo Campos"],"pdf_url":"","comment":null}],"computadora Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2601.05251v1","updated":"2026-01-08T18:59:56Z","published":"2026-01-08T18:59:56Z","title":"Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video","summary":"We propose Mesh4D, a feed-forward model for monocular 4D mesh reconstruction. Given a monocular video of a dynamic object, our model reconstructs the object's complete 3D shape and motion, represented as a deformation field. Our key contribution is a compact latent space that encodes the entire animation sequence in a single pass. This latent space is learned by an autoencoder that, during training, is guided by the skeletal structure of the training objects, providing strong priors on plausible deformations. Crucially, skeletal information is not required at inference time. The encoder employs spatio-temporal attention, yielding a more stable representation of the object's overall deformation. Building on this representation, we train a latent diffusion model that, conditioned on the input video and the mesh reconstructed from the first frame, predicts the full animation in one shot. We evaluate Mesh4D on reconstruction and novel view synthesis benchmarks, outperforming prior methods in recovering accurate 3D shape and deformation.","authors":["Zeren Jiang","Chuanxia Zheng","Iro Laina","Diane Larlus","Andrea Vedaldi"],"pdf_url":"","comment":"15 pages, 8 figures, project page: https://mesh-4d.github.io/"},{"id":"http://arxiv.org/abs/2601.05249v1","updated":"2026-01-08T18:59:55Z","published":"2026-01-08T18:59:55Z","title":"RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes","summary":"Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime dataset. Experiment results demonstrate that our method achieves superior generalization capability across low-light and well-illuminated images. Project page: https://ntuneillee.github.io/research/rl-awb/","authors":["Yuan-Kang Lee","Kuan-Lin Chen","Chia-Che Chang","Yu-Lun Liu"],"pdf_url":"","comment":"Project page: https://ntuneillee.github.io/research/rl-awb/"},{"id":"http://arxiv.org/abs/2601.05250v1","updated":"2026-01-08T18:59:55Z","published":"2026-01-08T18:59:55Z","title":"QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer","summary":"Recently, Quantum Visual Fields (QVFs) have shown promising improvements in model compactness and convergence speed for learning the provided 2D or 3D signals. Meanwhile, novel-view synthesis has seen major advances with Neural Radiance Fields (NeRFs), where models learn a compact representation from 2D images to render 3D scenes, albeit at the cost of larger models and intensive training. In this work, we extend the approach of QVFs by introducing QNeRF, the first hybrid quantum-classical model designed for novel-view synthesis from 2D images. QNeRF leverages parameterised quantum circuits to encode spatial and view-dependent information via quantum superposition and entanglement, resulting in more compact models compared to the classical counterpart. We present two architectural variants. Full QNeRF maximally exploits all quantum amplitudes to enhance representational capabilities. In contrast, Dual-Branch QNeRF introduces a task-informed inductive bias by branching spatial and view-dependent quantum state preparations, drastically reducing the complexity of this operation and ensuring scalability and potential hardware compatibility. Our experiments demonstrate that -- when trained on images of moderate resolution -- QNeRF matches or outperforms classical NeRF baselines while using less than half the number of parameters. These results suggest that quantum machine learning can serve as a competitive alternative for continuous signal representation in mid-level tasks in computer vision, such as 3D representation learning from 2D observations.","authors":["Daniele Lizzio Bosco","Shuteng Wang","Giuseppe Serra","Vladislav Golyanik"],"pdf_url":"","comment":"30 pages, 15 figures, 11 tables; project page: https://4dqv.mpi-inf.mpg.de/QNeRF/"},{"id":"http://arxiv.org/abs/2601.05246v1","updated":"2026-01-08T18:59:49Z","published":"2026-01-08T18:59:49Z","title":"Pixel-Perfect Visual Geometry Estimation","summary":"Recovering clean and accurate geometry from images is essential for robotics and augmented reality. However, existing geometry foundation models still suffer severely from flying pixels and the loss of fine details. In this paper, we present pixel-perfect visual geometry models that can predict high-quality, flying-pixel-free point clouds by leveraging generative modeling in the pixel space. We first introduce Pixel-Perfect Depth (PPD), a monocular depth foundation model built upon pixel-space diffusion transformers (DiT). To address the high computational complexity associated with pixel-space diffusion, we propose two key designs: 1) Semantics-Prompted DiT, which incorporates semantic representations from vision foundation models to prompt the diffusion process, preserving global semantics while enhancing fine-grained visual details; and 2) Cascade DiT architecture that progressively increases the number of image tokens, improving both efficiency and accuracy. To further extend PPD to video (PPVD), we introduce a new Semantics-Consistent DiT, which extracts temporally consistent semantics from a multi-view geometry foundation model. We then perform reference-guided token propagation within the DiT to maintain temporal coherence with minimal computational and memory overhead. Our models achieve the best performance among all generative monocular and video depth estimation models and produce significantly cleaner point clouds than all other models.","authors":["Gangwei Xu","Haotong Lin","Hongcheng Luo","Haiyang Sun","Bing Wang","Guang Chen","Sida Peng","Hangjun Ye","Xin Yang"],"pdf_url":"","comment":"Code: https://github.com/gangweix/pixel-perfect-depth"},{"id":"http://arxiv.org/abs/2601.05244v1","updated":"2026-01-08T18:59:30Z","published":"2026-01-08T18:59:30Z","title":"GREx: Generalized Referring Expression Segmentation, Comprehension, and Generation","summary":"Referring Expression Segmentation (RES) and Comprehension (REC) respectively segment and detect the object described by an expression, while Referring Expression Generation (REG) generates an expression for the selected object. Existing datasets and methods commonly support single-target expressions only, i.e., one expression refers to one object, not considering multi-target and no-target expressions. This greatly limits the real applications of REx (RES/REC/REG). This paper introduces three new benchmarks called Generalized Referring Expression Segmentation (GRES), Comprehension (GREC), and Generation (GREG), collectively denoted as GREx, which extend the classic REx to allow expressions to identify an arbitrary number of objects. We construct the first large-scale GREx dataset gRefCOCO that contains multi-target, no-target, and single-target expressions and their corresponding images with labeled targets. GREx and gRefCOCO are designed to be backward-compatible with REx, facilitating extensive experiments to study the performance gap of the existing REx methods on GREx tasks. One of the challenges of GRES/GREC is complex relationship modeling, for which we propose a baseline ReLA that adaptively divides the image into regions with sub-instance clues and explicitly models the region-region and region-language dependencies. The proposed ReLA achieves the state-of-the-art results on the both GRES and GREC tasks. The proposed gRefCOCO dataset and method are available at https://henghuiding.github.io/GREx.","authors":["Henghui Ding","Chang Liu","Shuting He","Xudong Jiang","Yu-Gang Jiang"],"pdf_url":"","comment":"IJCV, Project Page: https://henghuiding.com/GREx/"},{"id":"http://arxiv.org/abs/2601.05243v1","updated":"2026-01-08T18:59:30Z","published":"2026-01-08T18:59:30Z","title":"Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration","summary":"Functional grasping with dexterous robotic hands is a key capability for enabling tool use and complex manipulation, yet progress has been constrained by two persistent bottlenecks: the scarcity of large-scale datasets and the absence of integrated semantic and geometric reasoning in learned models. In this work, we present CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration. At the core of our approach is a correspondence-based data engine that generates diverse, high-quality training data in simulation. Based on the human demonstration, our data engine generates diverse object instances of the same category, transfers the expert grasp to the generated objects through correspondence estimation, and adapts the grasp through optimization. Building on the generated data, we introduce a multimodal prediction network that integrates visual and geometric information. By devising a local-global fusion module and an importance-aware sampling mechanism, we enable robust and computationally efficient prediction of functional dexterous grasps. Through extensive experiments across various object categories, we demonstrate that CorDex generalizes well to unseen object instances and significantly outperforms state-of-the-art baselines.","authors":["Xingyi He","Adhitya Polavaram","Yunhao Cao","Om Deshmukh","Tianrui Wang","Xiaowei Zhou","Kuan Fang"],"pdf_url":"","comment":"Project Page: https://cordex-manipulation.github.io/"},{"id":"http://arxiv.org/abs/2506.10230v3","updated":"2026-01-08T18:59:27Z","published":"2025-06-11T23:12:48Z","title":"Leveraging Clinical Text and Class Conditioning for 3D Prostate MRI Generation","summary":"Objective: Latent diffusion models (LDM) could alleviate data scarcity challenges affecting machine learning development for medical imaging. However, medical LDM strategies typically rely on short-prompt text encoders, nonmedical LDMs, or large data volumes. These strategies can limit performance and scientific accessibility. We propose a novel LDM conditioning approach to address these limitations. Methods: We propose Class-Conditioned Efficient Large Language model Adapter (CCELLA), a novel dual-head conditioning approach that simultaneously conditions the LDM U-Net with free-text clinical reports and radiology classification. We also propose a data-efficient LDM pipeline centered around CCELLA and a proposed joint loss function. We first evaluate our method on 3D prostate MRI against state-of-the-art. We then augment a downstream classifier model training dataset with synthetic images from our method. Results: Our method achieves a 3D FID score of 0.025 on a size-limited 3D prostate MRI dataset, significantly outperforming a recent foundation model with FID 0.070. When training a classifier for prostate cancer prediction, adding synthetic images generated by our method during training improves classifier accuracy from 69% to 74% and outperforms classifiers trained on images generated by prior state-of-the-art. Classifier training solely on our method's synthetic images achieved comparable performance to real image training. Conclusion: We show that our method improved both synthetic image quality and downstream classifier performance using limited data and minimal human annotation. Significance: The proposed CCELLA-centric pipeline enables radiology report and class-conditioned LDM training for high-quality medical image synthesis given limited data volume and human data annotation, improving LDM performance and scientific accessibility.","authors":["Emerson P. Grabke","Babak Taati","Masoom A. Haider"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Biomedical Engineering, 2025. This is the accepted author version. The final published version is available at https://doi.org/10.1109/TBME.2025.3648426"},{"id":"http://arxiv.org/abs/2601.05241v1","updated":"2026-01-08T18:59:22Z","published":"2026-01-08T18:59:22Z","title":"RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation","summary":"The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.","authors":["Boyang Wang","Haoran Zhang","Shujie Zhang","Jinkun Hao","Mingda Jia","Qi Lv","Yucheng Mao","Zhaoyang Lyu","Jia Zeng","Xudong Xu","Jiangmiao Pang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05239v1","updated":"2026-01-08T18:58:32Z","published":"2026-01-08T18:58:32Z","title":"Plenoptic Video Generation","summary":"Camera-controlled generative video re-rendering methods, such as ReCamMaster, have achieved remarkable progress. However, despite their success in single-view setting, these works often struggle to maintain consistency across multi-view scenarios. Ensuring spatio-temporal coherence in hallucinated regions remains challenging due to the inherent stochasticity of generative models. To address it, we introduce PlenopticDreamer, a framework that synchronizes generative hallucinations to maintain spatio-temporal memory. The core idea is to train a multi-in-single-out video-conditioned model in an autoregressive manner, aided by a camera-guided video retrieval strategy that adaptively selects salient videos from previous generations as conditional inputs. In addition, Our training incorporates progressive context-scaling to improve convergence, self-conditioning to enhance robustness against long-range visual degradation caused by error accumulation, and a long-video conditioning mechanism to support extended video generation. Extensive experiments on the Basic and Agibot benchmarks demonstrate that PlenopticDreamer achieves state-of-the-art video re-rendering, delivering superior view synchronization, high-fidelity visuals, accurate camera control, and diverse view transformations (e.g., third-person to third-person, and head-view to gripper-view in robotic manipulation). Project page: https://research.nvidia.com/labs/dir/plenopticdreamer/","authors":["Xiao Fu","Shitao Tang","Min Shi","Xian Liu","Jinwei Gu","Ming-Yu Liu","Dahua Lin","Chen-Hsuan Lin"],"pdf_url":"","comment":"Project Page: https://research.nvidia.com/labs/dir/plenopticdreamer/"},{"id":"http://arxiv.org/abs/2601.05237v1","updated":"2026-01-08T18:58:08Z","published":"2026-01-08T18:58:08Z","title":"ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos","summary":"Humans can effortlessly anticipate how objects might move or change through interaction--imagining a cup being lifted, a knife slicing, or a lid being closed. We aim to endow computational systems with a similar ability to predict plausible future object motions directly from passive visual observation. We introduce ObjectForesight, a 3D object-centric dynamics model that predicts future 6-DoF poses and trajectories of rigid objects from short egocentric video sequences. Unlike conventional world or dynamics models that operate in pixel or latent space, ObjectForesight represents the world explicitly in 3D at the object level, enabling geometrically grounded and temporally coherent predictions that capture object affordances and trajectories. To train such a model at scale, we leverage recent advances in segmentation, mesh reconstruction, and 3D pose estimation to curate a dataset of 2 million plus short clips with pseudo-ground-truth 3D object trajectories. Through extensive experiments, we show that ObjectForesight achieves significant gains in accuracy, geometric consistency, and generalization to unseen objects and scenes, establishing a scalable framework for learning physically grounded, object-centric dynamics models directly from observation. objectforesight.github.io","authors":["Rustin Soraki","Homanga Bharadhwaj","Ali Farhadi","Roozbeh Mottaghi"],"pdf_url":"","comment":"Preprint. Project Website: objectforesight.github.io"},{"id":"http://arxiv.org/abs/2601.05230v1","updated":"2026-01-08T18:55:39Z","published":"2026-01-08T18:55:39Z","title":"Learning Latent Action World Models In The Wild","summary":"Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require action labels, that can be complex to obtain at scale. This motivates the learning of latent action models, that can learn an action space from videos alone. Our work addresses the problem of learning latent actions world models on in-the-wild videos, expanding the scope of existing works that focus on simple robotics simulations, video games, or manipulation data. While this allows us to capture richer actions, it also introduces challenges stemming from the video diversity, such as environmental noise, or the lack of a common embodiment across videos. To address some of the challenges, we discuss properties that actions should follow as well as relevant architectural choices and evaluations. We find that continuous, but constrained, latent actions are able to capture the complexity of actions from in-the-wild videos, something that the common vector quantization does not. We for example find that changes in the environment coming from agents, such as humans entering the room, can be transferred across videos. This highlights the capability of learning actions that are specific to in-the-wild videos. In the absence of a common embodiment across videos, we are mainly able to learn latent actions that become localized in space, relative to the camera. Nonetheless, we are able to train a controller that maps known actions to latent ones, allowing us to use latent actions as a universal interface and solve planning tasks with our world model with similar performance as action-conditioned baselines. Our analyses and experiments provide a step towards scaling latent action models to the real world.","authors":["Quentin Garrido","Tushar Nagarajan","Basile Terver","Nicolas Ballas","Yann LeCun","Michael Rabbat"],"pdf_url":"","comment":"37 pages, 25 figures"},{"id":"http://arxiv.org/abs/2512.19327v2","updated":"2026-01-08T18:45:51Z","published":"2025-12-22T12:25:50Z","title":"Extended OpenTT Games Dataset: A table tennis dataset for fine-grained shot type and point outcome","summary":"Automatically detecting and classifying strokes in table tennis video can streamline training workflows, enrich broadcast overlays, and enable fine-grained performance analytics. For this to be possible, annotated video data of table tennis is needed. We extend the public OpenTTGames dataset with highly detailed, frame-accurate shot type annotations (forehand, backhand with subtypes), player posture labels (body lean and leg stance), and rally outcome tags at point end. OpenTTGames is a set of recordings from the side of the table with official labels for bounces, when the ball is above the net, or hitting the net. The dataset already contains ball coordinates near events, which are either \"bounce\", \"net\", or \"empty_event\" in the original OpenTTGames dataset, and semantic masks (humans, table, scoreboard). Our extension adds the types of stroke to the events and a per-player taxonomy so models can move beyond event spotting toward tactical understanding (e.g., whether a stroke is likely to win the point or set up an advantage). We provide a compact coding scheme and code-assisted labeling procedure to support reproducible annotations and baselines for fine-grained stroke understanding in racket sports. This fills a practical gap in the community, where many prior video resources are either not publicly released or carry restrictive/unclear licenses that hinder reuse and benchmarking. Our annotations are released under the same CC BY-NC-SA 4.0 license as OpenTTGames, allowing free non-commercial use, modification, and redistribution, with appropriate attribution.","authors":["Moamal Fadhil Abdul-Mahdi","Jonas Bruun Hubrechts","Thomas Martini Jørgensen","Emil Hovad"],"pdf_url":"","comment":"Thomas Martini Jørgensen and Emil Hovad contributed equally and share last authorship"},{"id":"http://arxiv.org/abs/2601.05212v1","updated":"2026-01-08T18:36:29Z","published":"2026-01-08T18:36:29Z","title":"FlowLet: Conditional 3D Brain MRI Synthesis using Wavelet Flow Matching","summary":"Brain Magnetic Resonance Imaging (MRI) plays a central role in studying neurological development, aging, and diseases. One key application is Brain Age Prediction (BAP), which estimates an individual's biological brain age from MRI data. Effective BAP models require large, diverse, and age-balanced datasets, whereas existing 3D MRI datasets are demographically skewed, limiting fairness and generalizability. Acquiring new data is costly and ethically constrained, motivating generative data augmentation. Current generative methods are often based on latent diffusion models, which operate in learned low dimensional latent spaces to address the memory demands of volumetric MRI data. However, these methods are typically slow at inference, may introduce artifacts due to latent compression, and are rarely conditioned on age, thereby affecting the BAP performance. In this work, we propose FlowLet, a conditional generative framework that synthesizes age-conditioned 3D MRIs by leveraging flow matching within an invertible 3D wavelet domain, helping to avoid reconstruction artifacts and reducing computational demands. Experiments show that FlowLet generates high-fidelity volumes with few sampling steps. Training BAP models with data generated by FlowLet improves performance for underrepresented age groups, and region-based analysis confirms preservation of anatomical structures.","authors":["Danilo Danese","Angela Lombardi","Matteo Attimonelli","Giuseppe Fasano","Tommaso Di Noia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05208v1","updated":"2026-01-08T18:33:52Z","published":"2026-01-08T18:33:52Z","title":"MoE3D: A Mixture-of-Experts Module for 3D Reconstruction","summary":"MoE3D is a mixture-of-experts module designed to sharpen depth boundaries and mitigate flying-point artifacts (highlighted in red) of existing feed-forward 3D reconstruction models (left side). MoE3D predicts multiple candidate depth maps and fuses them via dynamic weighting (visualized by MoE weights on the right side). When integrated with a pre-trained 3D reconstruction backbone such as VGGT, it substantially enhances reconstruction quality with minimal additional computational overhead. Best viewed digitally.","authors":["Zichen Wang","Ang Cao","Liam J. Wang","Jeong Joon Park"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05201v1","updated":"2026-01-08T18:23:03Z","published":"2026-01-08T18:23:03Z","title":"Mechanisms of Prompt-Induced Hallucination in Vision-Language Models","summary":"Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy. Through mechanistic analysis of three VLMs, we identify a small set of attention heads whose ablation substantially reduces prompt-induced hallucinations (PIH) by at least 40% without additional training. Across models, PIH-heads mediate prompt copying in model-specific ways. We characterize these differences and show that PIH ablation increases correction toward visual evidence. Our findings offer insights into the internal mechanisms driving prompt-induced hallucinations, revealing model-specific differences in how these behaviors are implemented.","authors":["William Rudman","Michal Golovanevsky","Dana Arad","Yonatan Belinkov","Ritambhara Singh","Carsten Eickhoff","Kyle Mahowald"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05191v1","updated":"2026-01-08T18:13:46Z","published":"2026-01-08T18:13:46Z","title":"Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable","summary":"When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines","authors":["Zuhair Ahmed Khan Taha","Mohammed Mudassir Uddin","Shahnawaz Alam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05175v1","updated":"2026-01-08T18:00:59Z","published":"2026-01-08T18:00:59Z","title":"VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice","summary":"Chain-of-thought (CoT) reasoning has emerged as a powerful tool for multimodal large language models on video understanding tasks. However, its necessity and advantages over direct answering remain underexplored. In this paper, we first demonstrate that for RL-trained video models, direct answering often matches or even surpasses CoT performance, despite CoT producing step-by-step analyses at a higher computational cost. Motivated by this, we propose VideoAuto-R1, a video understanding framework that adopts a reason-when-necessary strategy. During training, our approach follows a Thinking Once, Answering Twice paradigm: the model first generates an initial answer, then performs reasoning, and finally outputs a reviewed answer. Both answers are supervised via verifiable rewards. During inference, the model uses the confidence score of the initial answer to determine whether to proceed with reasoning. Across video QA and grounding benchmarks, VideoAuto-R1 achieves state-of-the-art accuracy with significantly improved efficiency, reducing the average response length by ~3.3x, e.g., from 149 to just 44 tokens. Moreover, we observe a low rate of thinking-mode activation on perception-oriented tasks, but a higher rate on reasoning-intensive tasks. This suggests that explicit language-based reasoning is generally beneficial but not always necessary.","authors":["Shuming Liu","Mingchen Zhuge","Changsheng Zhao","Jun Chen","Lemeng Wu","Zechun Liu","Chenchen Zhu","Zhipeng Cai","Chong Zhou","Haozhe Liu","Ernie Chang","Saksham Suri","Hongyu Xu","Qi Qian","Wei Wen","Balakrishnan Varadarajan","Zhuang Liu","Hu Xu","Florian Bordes","Raghuraman Krishnamoorthi","Bernard Ghanem","Vikas Chandra","Yunyang Xiong"],"pdf_url":"","comment":"Project page: https://ivul-kaust.github.io/projects/videoauto-r1/"},{"id":"http://arxiv.org/abs/2601.05172v1","updated":"2026-01-08T17:59:42Z","published":"2026-01-08T17:59:42Z","title":"CoV: Chain-of-View Prompting for Spatial Reasoning","summary":"Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process. CoV first employs a View Selection agent to filter redundant frames and identify question-aligned anchor views. It then performs fine-grained view adjustment by interleaving iterative reasoning with discrete camera actions, obtaining new observations from the underlying 3D scene representation until sufficient context is gathered or a step budget is reached.\n  We evaluate CoV on OpenEQA across four mainstream VLMs and obtain an average +11.56\\% improvement in LLM-Match, with a maximum gain of +13.62\\% on Qwen3-VL-Flash. CoV further exhibits test-time scaling: increasing the minimum action budget yields an additional +2.51\\% average improvement, peaking at +3.73\\% on Gemini-2.5-Flash. On ScanQA and SQA3D, CoV delivers strong performance (e.g., 116 CIDEr / 31.9 EM@1 on ScanQA and 51.1 EM@1 on SQA3D). Overall, these results suggest that question-aligned view selection coupled with open-view search is an effective, model-agnostic strategy for improving spatial reasoning in 3D EQA without additional training.","authors":["Haoyu Zhao","Akide Liu","Zeyu Zhang","Weijie Wang","Feng Chen","Ruihan Zhu","Gholamreza Haffari","Bohan Zhuang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.18693v3","updated":"2026-01-08T17:56:05Z","published":"2025-09-23T06:23:56Z","title":"MVT: Mask-Grounded Vision-Language Models for Taxonomy-Aligned Land-Cover Tagging","summary":"Land-cover understanding in remote sensing increasingly demands class-agnostic systems that generalize across datasets while remaining spatially precise and interpretable. We study a geometry-first discovery-and-interpretation setting under domain shift, where candidate regions are delineated class-agnostically and supervision avoids lexical class names via anonymized identifiers. Complementary to open-set recognition and open-world learning, we focus on coupling class-agnostic mask evidence with taxonomy-grounded scene interpretation, rather than unknown rejection or continual class expansion. We propose MVT, a three-stage framework that (i) extracts boundary-faithful region masks using SAM2 with domain adaptation, (ii) performs mask-grounded semantic tagging and scene description generation via dual-step LoRA fine-tuning of multimodal LLMs, and (iii) evaluates outputs with LLM-as-judge scoring calibrated by stratified expert ratings. On cross-dataset segmentation transfer (train on OpenEarthMap, evaluate on LoveDA), domain-adapted SAM2 improves mask quality; meanwhile, dual-step MLLM fine-tuning yields more accurate taxonomy-aligned tags and more informative mask-grounded scene descriptions.","authors":["Siyi Chen","Kai Wang","Weicong Pang","Ruiming Yang","Ziru Chen","Renjun Gao","Alexis Kai Hon Lau","Dasa Gu","Chenchen Zhang","Cheng Li"],"pdf_url":"","comment":"The project is available at https://charlescsyyy.github.io/MVT"},{"id":"http://arxiv.org/abs/2601.05162v1","updated":"2026-01-08T17:51:35Z","published":"2026-01-08T17:51:35Z","title":"GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation","summary":"Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.","authors":["Jinze Yu","Dayuan Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05159v1","updated":"2026-01-08T17:49:13Z","published":"2026-01-08T17:49:13Z","title":"Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering","summary":"Object hallucination critically undermines the reliability of Multimodal Large Language Models, often stemming from a fundamental failure in cognitive introspection, where models blindly trust linguistic priors over specific visual evidence. Existing mitigations remain limited: contrastive decoding approaches operate superficially without rectifying internal semantic misalignments, while current latent steering methods rely on static vectors that lack instance-specific precision. We introduce Vision-Language Introspection (VLI), a training-free inference framework that simulates a metacognitive self-correction process. VLI first performs Attributive Introspection to diagnose hallucination risks via probabilistic conflict detection and localize the causal visual anchors. It then employs Interpretable Bi-Causal Steering to actively modulate the inference process, dynamically isolating visual evidence from background noise while neutralizing blind confidence through adaptive calibration. VLI achieves state-of-the-art performance on advanced models, reducing object hallucination rates by 12.67% on MMHal-Bench and improving accuracy by 5.8% on POPE.","authors":["Shuliang Liu","Songbo Yang","Dong Fang","Sihang Jia","Yuqi Tang","Lingfeng Su","Ruoshui Peng","Yibo Yan","Xin Zou","Xuming Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.18620v2","updated":"2026-01-08T17:46:03Z","published":"2025-01-26T16:26:32Z","title":"Spontaneous emergence of linguistic statistical laws in images via artificial neural networks","summary":"As a core element of culture, images transform perception into structured representations and undergo evolution similar to natural languages. Given that visual input accounts for 60% of human sensory experience, it is natural to ask whether images follow statistical regularities similar to those in linguistic systems. Guided by symbol-grounding theory, which posits that meaningful symbols originate from perception, we treat images as vision-centric artifacts and employ pre-trained neural networks to model visual processing. By detecting kernel activations and extracting pixels, we obtain text-like units, which reveal that these image-derived representations adhere to statistical laws such as Zipf's, Heaps', and Benford's laws, analogous to linguistic data. Notably, these statistical regularities emerge spontaneously, without the need for explicit symbols or hybrid architectures. Our results indicate that connectionist networks can automatically develop structured, quasi-symbolic units through perceptual processing alone, suggesting that text- and symbol-like properties can naturally emerge from neural networks and providing a novel perspective for interpretation.","authors":["Ping-Rui Tsai","Chi-hsiang Wang","Yu-Cheng Liao","Hong-Yue Huang","Tzay-Ming Hong"],"pdf_url":"","comment":"10 figures"},{"id":"http://arxiv.org/abs/2601.05149v1","updated":"2026-01-08T17:39:35Z","published":"2026-01-08T17:39:35Z","title":"Multi-Scale Local Speculative Decoding for Image Generation","summary":"Autoregressive (AR) models have achieved remarkable success in image synthesis, yet their sequential nature imposes significant latency constraints. Speculative Decoding offers a promising avenue for acceleration, but existing approaches are limited by token-level ambiguity and lack of spatial awareness. In this work, we introduce Multi-Scale Local Speculative Decoding (MuLo-SD), a novel framework that combines multi-resolution drafting with spatially informed verification to accelerate AR image generation. Our method leverages a low-resolution drafter paired with learned up-samplers to propose candidate image tokens, which are then verified in parallel by a high-resolution target model. Crucially, we incorporate a local rejection and resampling mechanism, enabling efficient correction of draft errors by focusing on spatial neighborhoods rather than raster-scan resampling after the first rejection. We demonstrate that MuLo-SD achieves substantial speedups - up to $\\mathbf{1.7\\times}$ - outperforming strong speculative decoding baselines such as EAGLE-2 and LANTERN in terms of acceleration, while maintaining comparable semantic alignment and perceptual quality. These results are validated using GenEval, DPG-Bench, and FID/HPSv2 on the MS-COCO 5k validation split. Extensive ablations highlight the impact of up-sampling design, probability pooling, and local rejection and resampling with neighborhood expansion. Our approach sets a new state-of-the-art in speculative decoding for image synthesis, bridging the gap between efficiency and fidelity.","authors":["Elia Peruzzo","Guillaume Sautière","Amirhossein Habibian"],"pdf_url":"","comment":"Project page is available at https://qualcomm-ai-research.github.io/mulo-sd-webpage"},{"id":"http://arxiv.org/abs/2601.05148v1","updated":"2026-01-08T17:37:00Z","published":"2026-01-08T17:37:00Z","title":"Atlas 2 -- Foundation models for clinical deployment","summary":"Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model dataset to date comprising 5.5 million histopathology whole slide images, collected from three medical institutions Charité - Universtätsmedizin Berlin, LMU Munich, and Mayo Clinic.","authors":["Maximilian Alber","Timo Milbich","Alexandra Carpen-Amarie","Stephan Tietz","Jonas Dippel","Lukas Muttenthaler","Beatriz Perez Cancer","Alessandro Benetti","Panos Korfiatis","Elias Eulig","Jérôme Lüscher","Jiasen Wu","Sayed Abid Hashimi","Gabriel Dernbach","Simon Schallenberg","Neelay Shah","Moritz Krügener","Aniruddh Jammoria","Jake Matras","Patrick Duffy","Matt Redlon","Philipp Jurmeister","David Horst","Lukas Ruff","Klaus-Robert Müller","Frederick Klauschen","Andrew Norgan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05143v1","updated":"2026-01-08T17:31:09Z","published":"2026-01-08T17:31:09Z","title":"A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering","summary":"Visual question answering for crop disease analysis requires accurate visual understanding and reliable language generation. This work presents a lightweight vision-language framework for crop and disease identification from leaf images. The proposed approach combines a Swin Transformer vision encoder with sequence-to-sequence language decoders. A two-stage training strategy is adopted to improve visual representation learning and cross-modal alignment. The model is evaluated on a large-scale crop disease dataset using classification and natural language generation metrics. Experimental results show high accuracy for both crop and disease identification. The framework also achieves strong performance on BLEU, ROUGE and BERTScore. Our proposed models outperform large-scale vision-language baselines while using significantly fewer parameters. Explainability is assessed using Grad-CAM and token-level attribution. Qualitative results demonstrate robust performance under diverse user-driven queries. These findings highlight the effectiveness of task-specific visual pretraining for crop disease visual question answering.","authors":["Md. Zahid Hossain","Most. Sharmin Sultana Samu","Md. Rakibul Islam","Md. Siam Ansary"],"pdf_url":"","comment":"Preprint, manuscript is under review"},{"id":"http://arxiv.org/abs/2601.05138v1","updated":"2026-01-08T17:28:52Z","published":"2026-01-08T17:28:52Z","title":"VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control","summary":"Video world models aim to simulate dynamic, real-world environments, yet existing methods struggle to provide unified and precise control over camera and multi-object motion, as videos inherently operate dynamics in the projected 2D image plane. To bridge this gap, we introduce VerseCrafter, a 4D-aware video world model that enables explicit and coherent control over both camera and object dynamics within a unified 4D geometric world state. Our approach is centered on a novel 4D Geometric Control representation, which encodes the world state through a static background point cloud and per-object 3D Gaussian trajectories. This representation captures not only an object's path but also its probabilistic 3D occupancy over time, offering a flexible, category-agnostic alternative to rigid bounding boxes or parametric models. These 4D controls are rendered into conditioning signals for a pretrained video diffusion model, enabling the generation of high-fidelity, view-consistent videos that precisely adhere to the specified dynamics. Unfortunately, another major challenge lies in the scarcity of large-scale training data with explicit 4D annotations. We address this by developing an automatic data engine that extracts the required 4D controls from in-the-wild videos, allowing us to train our model on a massive and diverse dataset.","authors":["Sixiao Zheng","Minghao Yin","Wenbo Hu","Xiaoyu Li","Ying Shan","Yanwei Fu"],"pdf_url":"","comment":"Project Page: https://sixiaozheng.github.io/VerseCrafter_page/"},{"id":"http://arxiv.org/abs/2503.19850v3","updated":"2026-01-08T17:17:54Z","published":"2025-03-25T17:17:19Z","title":"FALCONEye: Finding Answers and Localizing Content in ONE-hour-long videos with multi-modal LLMs","summary":"Finding information in hour-long videos is a challenging task even for top-performing Vision Language Models (VLMs), as encoding visual content quickly exceeds available context windows. To tackle this challenge, we present FALCONEye, a novel video agent based on a training-free, model-agnostic meta-architecture composed of a VLM and a Large Language Model (LLM). FALCONEye answers open-ended questions using an exploration-based search algorithm guided by calibrated confidence from the VLM's answers. We also introduce the FALCON-Bench benchmark, extending Question Answering problem to Video Answer Search-requiring models to return both the answer and its supporting temporal window for open-ended questions in hour-long videos. With just a 7B VLM and a lightweight LLM, FALCONEye outscores all open-source 7B VLMs and comparable agents in FALCON-Bench. It further demonstrates its generalization capability in MLVU benchmark with shorter videos and different tasks, surpassing GPT-4o on single-detail tasks while slashing inference cost by roughly an order of magnitude.","authors":["Carlos Plou","Cesar Borja","Ruben Martinez-Cantin","Ana C. Murillo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05125v1","updated":"2026-01-08T17:15:15Z","published":"2026-01-08T17:15:15Z","title":"VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding","summary":"This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters. We validate the methodology by training on the synthetic MERIT Dataset and evaluating on its real-world counterpart, MERIT Secret. Results show that VERSE helps uncover the visual features associated with error-prone clusters, and that retraining with samples containing these features substantially boosts F1 performance without degrading generalization. Furthermore, we demonstrate that on-premise models such as Donut and Idefics2, when optimized with VERSE, match or even surpass the performance of SaaS solutions like GPT-4 and Pixtral.","authors":["Ignacio de Rodrigo","Alvaro J. Lopez-Lopez","Jaime Boal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05124v1","updated":"2026-01-08T17:13:00Z","published":"2026-01-08T17:13:00Z","title":"Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing","summary":"In-context image generation and editing (ICGE) enables users to specify visual concepts through interleaved image-text prompts, demanding precise understanding and faithful execution of user intent. Although recent unified multimodal models exhibit promising understanding capabilities, these strengths often fail to transfer effectively to image generation. We introduce Re-Align, a unified framework that bridges the gap between understanding and generation through structured reasoning-guided alignment. At its core lies the In-Context Chain-of-Thought (IC-CoT), a structured reasoning paradigm that decouples semantic guidance and reference association, providing clear textual target and mitigating confusion among reference images. Furthermore, Re-Align introduces an effective RL training scheme that leverages a surrogate reward to measure the alignment between structured reasoning text and the generated image, thereby improving the model's overall performance on ICGE tasks. Extensive experiments verify that Re-Align outperforms competitive methods of comparable model scale and resources on both in-context image generation and editing tasks.","authors":["Runze He","Yiji Cheng","Tiankai Hang","Zhimin Li","Yu Xu","Zijin Yin","Shiyi Zhang","Wenxun Dai","Penghui Du","Ao Ma","Chunyu Wang","Qinglin Lu","Jizhong Han","Jiao Dai"],"pdf_url":"","comment":"13 pages, 9 figures, project page: https://github.com/hrz2000/realign"},{"id":"http://arxiv.org/abs/2601.05116v1","updated":"2026-01-08T17:03:44Z","published":"2026-01-08T17:03:44Z","title":"From Rays to Projections: Better Inputs for Feed-Forward View Synthesis","summary":"Feed-forward view synthesis models predict a novel view in a single pass with minimal 3D inductive bias. Existing works encode cameras as Plücker ray maps, which tie predictions to the arbitrary world coordinate gauge and make them sensitive to small camera transformations, thereby undermining geometric consistency. In this paper, we ask what inputs best condition a model for robust and consistent view synthesis. We propose projective conditioning, which replaces raw camera parameters with a target-view projective cue that provides a stable 2D input. This reframes the task from a brittle geometric regression problem in ray space to a well-conditioned target-view image-to-image translation problem. Additionally, we introduce a masked autoencoding pretraining strategy tailored to this cue, enabling the use of large-scale uncalibrated data for pretraining. Our method shows improved fidelity and stronger cross-view consistency compared to ray-conditioned baselines on our view-consistency benchmark. It also achieves state-of-the-art quality on standard novel view synthesis benchmarks.","authors":["Zirui Wu","Zeren Jiang","Martin R. Oswald","Jie Song"],"pdf_url":"","comment":"Project Page: https://wuzirui.github.io/pvsm-web"},{"id":"http://arxiv.org/abs/2507.11939v2","updated":"2026-01-08T17:00:25Z","published":"2025-07-16T06:09:02Z","title":"POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering","summary":"Charts are a universally adopted medium for data communication, yet existing chart understanding benchmarks are overwhelmingly English-centric, limiting their accessibility and relevance to global audiences. To address this limitation, we introduce PolyChartQA, the first large-scale multilingual benchmark for chart question answering, comprising 22,606 charts and 26,151 QA pairs across 10 diverse languages. PolyChartQA is constructed through a scalable pipeline that enables efficient multilingual chart generation via data translation and code reuse, supported by LLM-based translation and rigorous quality control. We systematically evaluate multilingual chart understanding with PolyChartQA on state-of-the-art LVLMs and reveal a significant performance gap between English and other languages, particularly low-resource ones. Additionally, we introduce a companion multilingual chart question answering training set, PolyChartQA-Train, on which fine-tuning LVLMs yields substantial gains in multilingual chart understanding across diverse model sizes and architectures. Together, our benchmark provides a foundation for developing globally inclusive vision-language models capable of understanding charts across diverse linguistic contexts.","authors":["Yichen Xu","Liangyu Chen","Liang Zhang","Jianzhe Ma","Wenxuan Wang","Qin Jin"],"pdf_url":"","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2601.05105v1","updated":"2026-01-08T16:52:28Z","published":"2026-01-08T16:52:28Z","title":"UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition","summary":"Unlabeled LiDAR logs, in autonomous driving applications, are inherently a gold mine of dense 3D geometry hiding in plain sight - yet they are almost useless without human labels, highlighting a dominant cost barrier for autonomous-perception research. In this work we tackle this bottleneck by leveraging temporal-geometric consistency across LiDAR sweeps to lift and fuse cues from text and 2D vision foundation models directly into 3D, without any manual input. We introduce an unsupervised multi-modal pseudo-labeling method relying on strong geometric priors learned from temporally accumulated LiDAR maps, alongside with a novel iterative update rule that enforces joint geometric-semantic consistency, and vice-versa detecting moving objects from inconsistencies. Our method simultaneously produces 3D semantic labels, 3D bounding boxes, and dense LiDAR scans, demonstrating robust generalization across three datasets. We experimentally validate that our method compares favorably to existing semantic segmentation and object detection pseudo-labeling methods, which often require additional manual supervision. We confirm that even a small fraction of our geometrically consistent, densified LiDAR improves depth prediction by 51.5% and 22.0% MAE in the 80-150 and 150-250 meters range, respectively.","authors":["Filippo Ghilotti","Samuel Brucker","Nahku Saidy","Matteo Matteucci","Mario Bijelic","Felix Heide"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.17297v4","updated":"2026-01-08T16:42:43Z","published":"2024-08-30T13:52:26Z","title":"BOP-Distrib: Revisiting 6D Pose Estimation Benchmarks for Better Evaluation under Visual Ambiguities","summary":"6D pose estimation aims at determining the object pose that best explains the camera observation. The unique solution for non-ambiguous objects can turn into a multi-modal pose distribution for symmetrical objects or when occlusions of symmetry-breaking elements happen, depending on the viewpoint. Currently, 6D pose estimation methods are benchmarked on datasets that consider, for their ground truth annotations, visual ambiguities as only related to global object symmetries, whereas they should be defined per-image to account for the camera viewpoint. We thus first propose an automatic method to re-annotate those datasets with a 6D pose distribution specific to each image, taking into account the object surface visibility in the image to correctly determine the visual ambiguities. Second, given this improved ground truth, we re-evaluate the state-of-the-art single pose methods and show that this greatly modifies the ranking of these methods. Third, as some recent works focus on estimating the complete set of solutions, we derive a precision/recall formulation to evaluate them against our image-wise distribution ground truth, making it the first benchmark for pose distribution methods on real images.","authors":["Boris Meden","Asma Brazi","Fabrice Mayran de Chamisso","Steve Bourgeois","Vincent Lepetit"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05083v1","updated":"2026-01-08T16:28:24Z","published":"2026-01-08T16:28:24Z","title":"Driving on Registers","summary":"We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.","authors":["Ellington Kirby","Alexandre Boulch","Yihong Xu","Yuan Yin","Gilles Puy","Éloi Zablocki","Andrei Bursuc","Spyros Gidaris","Renaud Marlet","Florent Bartoccioni","Anh-Quan Cao","Nermin Samet","Tuan-Hung VU","Matthieu Cord"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.17722v2","updated":"2026-01-08T16:16:20Z","published":"2025-10-20T16:38:40Z","title":"MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues","summary":"The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AI's ability to understand visual modalities. However, existing evaluation benchmarks remain limited to single-turn question answering, overlooking the complexity of multi-turn dialogues in real-world scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video understanding benchmark for evaluating MLLMs in multi-turn dialogues. Specifically, our MT-Video-Bench mainly assesses 6 core competencies that focus on perceptivity and interactivity, encompassing 1,000 meticulously curated multi-turn dialogues from diverse domains. These capabilities are rigorously aligned with real-world applications, such as interactive sports analysis and multi-turn video-based intelligent tutoring. With MT-Video-Bench, we extensively evaluate various state-of-the-art open-source and closed-source MLLMs, revealing their significant performance discrepancies and limitations in handling multi-turn video dialogues. The benchmark will be publicly available to foster future research.","authors":["Yaning Pan","Qianqian Xie","Guohui Zhang","Zekun Wang","Yongqian Wen","Yuanxing Zhang","Haoxuan Hu","Zhiyu Pan","Yibing Huang","Zhidong Gan","Yonghong Lin","An Ping","Shihao Li","Yanghai Wang","Tianhao Peng","Jiaheng Liu"],"pdf_url":"","comment":"Project Website: https://github.com/NJU-LINK/MT-Video-Bench"},{"id":"http://arxiv.org/abs/2601.05063v1","updated":"2026-01-08T16:08:58Z","published":"2026-01-08T16:08:58Z","title":"Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset","summary":"Magnetic resonance imaging (MRI) is a cornerstone of clinical neuroimaging, yet conventional MRIs provide qualitative information heavily dependent on scanner hardware and acquisition settings. While quantitative MRI (qMRI) offers intrinsic tissue parameters, the requirement for specialized acquisition protocols and reconstruction algorithms restricts its availability and impedes large-scale biomarker research. This study presents a self-supervised physics-guided deep learning framework to infer quantitative T1, T2, and proton-density (PD) maps directly from widely available clinical conventional T1-weighted, T2-weighted, and FLAIR MRIs. The framework was trained and evaluated on a large-scale, clinically heterogeneous dataset comprising 4,121 scan sessions acquired at our institution over six years on four different 3 T MRI scanner systems, capturing real-world clinical variability. The framework integrates Bloch-based signal models directly into the training objective. Across more than 600 test sessions, the generated maps exhibited white matter and gray matter values consistent with literature ranges. Additionally, the generated maps showed invariance to scanner hardware and acquisition protocol groups, with inter-group coefficients of variation $\\leq$ 1.1%. Subject-specific analyses demonstrated excellent voxel-wise reproducibility across scanner systems and sequence parameters, with Pearson $r$ and concordance correlation coefficients exceeding 0.82 for T1 and T2. Mean relative voxel-wise differences were low across all quantitative parameters, especially for T2 ($<$ 6%). These results indicate that the proposed framework can robustly transform diverse clinical conventional MRI data into quantitative maps, potentially paving the way for large-scale quantitative biomarker research.","authors":["Jelmer van Lune","Stefano Mandija","Oscar van der Heide","Matteo Maspero","Martin B. Schilder","Jan Willem Dankbaar","Cornelis A. T. van den Berg","Alessandro Sbrizzi"],"pdf_url":"","comment":"30 pages, 13 figures, full paper"},{"id":"http://arxiv.org/abs/2510.10797v2","updated":"2026-01-08T16:08:46Z","published":"2025-10-12T20:31:40Z","title":"Full segmentation annotations of 3D time-lapse microscopy images of MDA231 cells","summary":"High-quality, publicly available segmentation annotations of image and video datasets are critical for advancing the field of image processing. In particular, annotations of volumetric images of a large number of targets are time-consuming and challenging. In (Melnikova, A., & Matula, P., 2025), we presented the first publicly available full 3D time-lapse segmentation annotations of migrating cells with complex dynamic shapes. Concretely, three distinct humans annotated two sequences of MDA231 human breast carcinoma cells (Fluo-C3DL-MDA231) from the Cell Tracking Challenge (CTC).\n  This paper aims to provide a comprehensive description of the dataset and accompanying experiments that were not included in (Melnikova, A., & Matula, P., 2025) due to limitations in publication space. Namely, we show that the created annotations are consistent with the previously published tracking markers provided by the CTC organizers and the segmentation accuracy measured based on the 2D gold truth of CTC is within the inter-annotator variability margins. We compared the created 3D annotations with automatically created silver truth provided by CTC. We have found the proposed annotations better represent the complexity of the input images. The presented annotations can be used for testing and training cell segmentation, or analyzing 3D shapes of highly dynamic objects.","authors":["Aleksandra Melnikova","Petr Matula"],"pdf_url":"","comment":"6 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2601.05059v1","updated":"2026-01-08T16:02:56Z","published":"2026-01-08T16:02:56Z","title":"From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)","summary":"Vision Language Models (VLMs) are poised to revolutionize the digital transformation of pharmacyceutical industry by enabling intelligent, scalable, and automated multi-modality content processing. Traditional manual annotation of heterogeneous data modalities (text, images, video, audio, and web links), is prone to inconsistencies, quality degradation, and inefficiencies in content utilization. The sheer volume of long video and audio data further exacerbates these challenges, (e.g. long clinical trial interviews and educational seminars).\n  Here, we introduce a domain adapted Video to Video Clip Generation framework that integrates Audio Language Models (ALMs) and Vision Language Models (VLMs) to produce highlight clips. Our contributions are threefold: (i) a reproducible Cut & Merge algorithm with fade in/out and timestamp normalization, ensuring smooth transitions and audio/visual alignment; (ii) a personalization mechanism based on role definition and prompt injection for tailored outputs (marketing, training, regulatory); (iii) a cost efficient e2e pipeline strategy balancing ALM/VLM enhanced processing. Evaluations on Video MME benchmark (900) and our proprietary dataset of 16,159 pharmacy videos across 14 disease areas demonstrate 3 to 4 times speedup, 4 times cost reduction, and competitive clip quality. Beyond efficiency gains, we also report our methods improved clip coherence scores (0.348) and informativeness scores (0.721) over state of the art VLM baselines (e.g., Gemini 2.5 Pro), highlighting the potential of transparent, custom extractive, and compliance supporting video summarization for life sciences.","authors":["Suyash Mishra","Qiang Li","Srikanth Patil","Anubhav Girdhar"],"pdf_url":"","comment":"Contributed original research to top tier conference in VLM; currently undergoing peer review"},{"id":"http://arxiv.org/abs/2601.05035v1","updated":"2026-01-08T15:43:57Z","published":"2026-01-08T15:43:57Z","title":"Patch-based Representation and Learning for Efficient Deformation Modeling","summary":"In this paper, we present a patch-based representation of surfaces, PolyFit, which is obtained by fitting jet functions locally on surface patches. Such a representation can be learned efficiently in a supervised fashion from both analytic functions and real data. Once learned, it can be generalized to various types of surfaces. Using PolyFit, the surfaces can be efficiently deformed by updating a compact set of jet coefficients rather than optimizing per-vertex degrees of freedom for many downstream tasks in computer vision and graphics. We demonstrate the capabilities of our proposed methodologies with two applications: 1) Shape-from-template (SfT): where the goal is to deform the input 3D template of an object as seen in image/video. Using PolyFit, we adopt test-time optimization that delivers competitive accuracy while being markedly faster than offline physics-based solvers, and outperforms recent physics-guided neural simulators in accuracy at modest additional runtime. 2) Garment draping. We train a self-supervised, mesh- and garment-agnostic model that generalizes across resolutions and garment types, delivering up to an order-of-magnitude faster inference than strong baselines.","authors":["Ruochen Chen","Thuy Tran","Shaifali Parashar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05020v1","updated":"2026-01-08T15:28:39Z","published":"2026-01-08T15:28:39Z","title":"Scalable neural pushbroom architectures for real-time denoising of hyperspectral images onboard satellites","summary":"The next generation of Earth observation satellites will seek to deploy intelligent models directly onboard the payload in order to minimize the latency incurred by the transmission and processing chain of the ground segment, for time-critical applications. Designing neural architectures for onboard execution, particularly for satellite-based hyperspectral imagers, poses novel challenges due to the unique constraints of this environment and imaging system that are largely unexplored by the traditional computer vision literature. In this paper, we show that this setting requires addressing three competing objectives, namely high-quality inference with low complexity, dynamic power scalability and fault tolerance. We focus on the problem of hyperspectral image denoising, which is a critical task to enable effective downstream inference, and highlights the constraints of the onboard processing scenario. We propose a neural network design that addresses the three aforementioned objectives with several novel contributions. In particular, we propose a mixture of denoisers that can be resilient to radiation-induced faults as well as allowing for time-varying power scaling. Moreover, each denoiser employs an innovative architecture where an image is processed line-by-line in a causal way, with a memory of past lines, in order to match the acquisition process of pushbroom hyperspectral sensors and greatly limit memory requirements. We show that the proposed architecture can run in real-time, i.e., process one line in the time it takes to acquire the next one, on low-power hardware and provide competitive denoising quality with respect to significantly more complex state-of-the-art models. We also show that the power scalability and fault tolerance objectives provide a design space with multiple tradeoffs between those properties and denoising quality.","authors":["Ziyao Yi","Davide Piccinini","Diego Valsesia","Tiziano Bianchi","Enrico Magli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04991v1","updated":"2026-01-08T14:48:50Z","published":"2026-01-08T14:48:50Z","title":"Higher-Order Adversarial Patches for Real-Time Object Detectors","summary":"Higher-order adversarial attacks can directly be considered the result of a cat-and-mouse game -- an elaborate action involving constant pursuit, near captures, and repeated escapes. This idiom describes the enduring circular training of adversarial attack patterns and adversarial training the best. The following work investigates the impact of higher-order adversarial attacks on object detectors by successively training attack patterns and hardening object detectors with adversarial training. The YOLOv10 object detector is chosen as a representative, and adversarial patches are used in an evasion attack manner. Our results indicate that higher-order adversarial patches are not only affecting the object detector directly trained on but rather provide a stronger generalization capacity compared to lower-order adversarial patches. Moreover, the results highlight that solely adversarial training is not sufficient to harden an object detector efficiently against this kind of adversarial attack. Code: https://github.com/JensBayer/HigherOrder","authors":["Jens Bayer","Stefan Becker","David Münch","Michael Arens","Jürgen Beyerer"],"pdf_url":"","comment":"Under review (ICPR2026)"},{"id":"http://arxiv.org/abs/2601.04984v1","updated":"2026-01-08T14:38:39Z","published":"2026-01-08T14:38:39Z","title":"OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction","summary":"We introduce OceanSplat, a novel 3D Gaussian Splatting-based approach for accurately representing 3D geometry in underwater scenes. To overcome multi-view inconsistencies caused by underwater optical degradation, our method enforces trinocular view consistency by rendering horizontally and vertically translated camera views relative to each input view and aligning them via inverse warping. Furthermore, these translated camera views are used to derive a synthetic epipolar depth prior through triangulation, which serves as a self-supervised depth regularizer. These geometric constraints facilitate the spatial optimization of 3D Gaussians and preserve scene structure in underwater environments. We also propose a depth-aware alpha adjustment that modulates the opacity of 3D Gaussians during early training based on their $z$-component and viewing direction, deterring the formation of medium-induced primitives. With our contributions, 3D Gaussians are disentangled from the scattering medium, enabling robust representation of object geometry and significantly reducing floating artifacts in reconstructed underwater scenes. Experiments on real-world underwater and simulated scenes demonstrate that OceanSplat substantially outperforms existing methods for both scene reconstruction and restoration in scattering media.","authors":["Minseong Kweon","Jinsun Park"],"pdf_url":"","comment":"Accepted to AAAI 2026. Project page: https://oceansplat.github.io"},{"id":"http://arxiv.org/abs/2511.14361v2","updated":"2026-01-08T14:35:09Z","published":"2025-11-18T11:07:31Z","title":"Clinically-Validated Innovative Mobile Application for Assessing Blinking and Eyelid Movements","summary":"Blinking is a vital physiological process that protects and maintains the health of the ocular surface. Objective assessment of eyelid movements remains challenging due to the complexity, cost, and limited clinical applicability of existing tools. This study presents the Bapp (Blink Application), a mobile application developed using the Flutter framework and integrated with Google ML Kit for on-device, real-time analysis of eyelid movements, and its clinical validation. The validation was performed using 45 videos from patients, whose blinks were manually annotated by an ophthalmology specialist as the ground truth. The Bapp's performance was evaluated using standard metrics, with results demonstrating 98.4% precision, 96.9% recall, and an overall accuracy of 98.3%. These outcomes confirm the reliability of the Bapp as a portable, accessible, and objective tool for monitoring eyelid movements. The application offers a promising alternative to traditional manual blink counting, supporting continuous ocular health monitoring and postoperative evaluation in clinical environments.","authors":["Gustavo Adolpho Bonesso","Carlos Marcelo Gurjão de Godoy","Tammy Hentona Osaki","Midori Hentona Osaki","Bárbara Moreira Ribeiro Trindade dos Santos","Juliana Yuka Washiya","Regina Célia Coelho"],"pdf_url":"","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2512.18503v2","updated":"2026-01-08T14:23:21Z","published":"2025-12-20T20:42:30Z","title":"NASTaR: NovaSAR Automated Ship Target Recognition Dataset","summary":"Synthetic Aperture Radar (SAR) offers a unique capability for all-weather, space-based maritime activity monitoring by capturing and imaging strong reflections from ships at sea. A well-defined challenge in this domain is ship type classification. Due to the high diversity and complexity of ship types, accurate recognition is difficult and typically requires specialized deep learning models. These models, however, depend on large, high-quality ground-truth datasets to achieve robust performance and generalization. Furthermore, the growing variety of SAR satellites operating at different frequencies and spatial resolutions has amplified the need for more annotated datasets to enhance model accuracy. To address this, we present the NovaSAR Automated Ship Target Recognition (NASTaR) dataset. This dataset comprises of 3415 ship patches extracted from NovaSAR S-band imagery, with labels matched to AIS data. It includes distinctive features such as 23 unique classes, inshore/offshore separation, and an auxiliary wake dataset for patches where ship wakes are visible. We validated the dataset applicability across prominent ship-type classification scenarios using benchmark deep learning models. Results demonstrate over 60% accuracy for classifying four major ship types, over 70% for a three-class scenario, more than 75% for distinguishing cargo from tanker ships, and over 87% for identifying fishing vessels. The NASTaR dataset is available at https://doi.org/10.5523/bris.2tfa6x37oerz2lyiw6hp47058, while relevant codes for benchmarking and analysis are available at https://github.com/benyaminhosseiny/nastar.","authors":["Benyamin Hosseiny","Kamirul Kamirul","Odysseas Pappas","Alin Achim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04968v1","updated":"2026-01-08T14:16:11Z","published":"2026-01-08T14:16:11Z","title":"SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection","summary":"3D lane detection has emerged as a critical challenge in autonomous driving, encompassing identification and localization of lane markings and the 3D road surface. Conventional 3D methods detect lanes from dense birds-eye-viewed (BEV) features, though erroneous transformations often result in a poor feature representation misaligned with the true 3D road surface. While recent sparse lane detectors have surpassed dense BEV approaches, they completely disregard valuable lane-specific priors. Furthermore, existing methods fail to utilize historic lane observations, which yield the potential to resolve ambiguities in situations of poor visibility. To address these challenges, we present SparseLaneSTP, a novel method that integrates both geometric properties of the lane structure and temporal information into a sparse lane transformer. It introduces a new lane-specific spatio-temporal attention mechanism, a continuous lane representation tailored for sparse architectures as well as temporal regularization. Identifying weaknesses of existing 3D lane datasets, we also introduce a precise and consistent 3D lane dataset using a simple yet effective auto-labeling strategy. Our experimental section proves the benefits of our contributions and demonstrates state-of-the-art performance across all detection and error metrics on existing 3D lane detection benchmarks as well as on our novel dataset.","authors":["Maximilian Pittner","Joel Janai","Mario Faigle","Alexandru Paul Condurache"],"pdf_url":"","comment":"Published at IEEE/CVF International Conference on Computer Vision (ICCV) 2025"},{"id":"http://arxiv.org/abs/2601.04956v1","updated":"2026-01-08T14:02:28Z","published":"2026-01-08T14:02:28Z","title":"TEA: Temporal Adaptive Satellite Image Semantic Segmentation","summary":"Crop mapping based on satellite images time-series (SITS) holds substantial economic value in agricultural production settings, in which parcel segmentation is an essential step. Existing approaches have achieved notable advancements in SITS segmentation with predetermined sequence lengths. However, we found that these approaches overlooked the generalization capability of models across scenarios with varying temporal length, leading to markedly poor segmentation results in such cases. To address this issue, we propose TEA, a TEmporal Adaptive SITS semantic segmentation method to enhance the model's resilience under varying sequence lengths. We introduce a teacher model that encapsulates the global sequence knowledge to guide a student model with adaptive temporal input lengths. Specifically, teacher shapes the student's feature space via intermediate embedding, prototypes and soft label perspectives to realize knowledge transfer, while dynamically aggregating student model to mitigate knowledge forgetting. Finally, we introduce full-sequence reconstruction as an auxiliary task to further enhance the quality of representations across inputs of varying temporal lengths. Through extensive experiments, we demonstrate that our method brings remarkable improvements across inputs of different temporal lengths on common benchmarks. Our code will be publicly available.","authors":["Juyuan Kang","Hao Zhu","Yan Zhu","Wei Zhang","Jianing Chen","Tianxiang Xiao","Yike Ma","Hao Jiang","Feng Dai"],"pdf_url":"","comment":"Under review. Code will be available at \\href{https://github.com/KeplerKang/TEA}{this https URL}"},{"id":"http://arxiv.org/abs/2601.04946v1","updated":"2026-01-08T13:49:14Z","published":"2026-01-08T13:49:14Z","title":"Prototypicality Bias Reveals Blindspots in Multimodal Evaluation Metrics","summary":"Automatic metrics are now central to evaluating text-to-image models, often substituting for human judgment in benchmarking and large-scale filtering. However, it remains unclear whether these metrics truly prioritize semantic correctness or instead favor visually and socially prototypical images learned from biased data distributions. We identify and study \\emph{prototypicality bias} as a systematic failure mode in multimodal evaluation. We introduce a controlled contrastive benchmark \\textsc{\\textbf{ProtoBias}} (\\textit{\\textbf{Proto}typical \\textbf{Bias}}), spanning Animals, Objects, and Demography images, where semantically correct but non-prototypical images are paired with subtly incorrect yet prototypical adversarial counterparts. This setup enables a directional evaluation of whether metrics follow textual semantics or default to prototypes. Our results show that widely used metrics, including CLIPScore, PickScore, and VQA-based scores, frequently misrank these pairs, while even LLM-as-Judge systems exhibit uneven robustness in socially grounded cases. Human evaluations consistently favour semantic correctness with larger decision margins. Motivated by these findings, we propose \\textbf{\\textsc{ProtoScore}}, a robust 7B-parameter metric that substantially reduces failure rates and suppresses misranking, while running at orders of magnitude faster than the inference time of GPT-5, approaching the robustness of much larger closed-source judges.","authors":["Subhadeep Roy","Gagan Bhatia","Steffen Eger"],"pdf_url":"","comment":"First version"},{"id":"http://arxiv.org/abs/2601.04912v1","updated":"2026-01-08T13:10:33Z","published":"2026-01-08T13:10:33Z","title":"Decentralized Privacy-Preserving Federal Learning of Computer Vision Models on Edge Devices","summary":"Collaborative training of a machine learning model comes with a risk of sharing sensitive or private data. Federated learning offers a way of collectively training a single global model without the need to share client data, by sharing only the updated parameters from each client's local model. A central server is then used to aggregate parameters from all clients and redistribute the aggregated model back to the clients. Recent findings have shown that even in this scenario, private data can be reconstructed only using information about model parameters. Current efforts to mitigate this are mainly focused on reducing privacy risks on the server side, assuming that other clients will not act maliciously. In this work, we analyzed various methods for improving the privacy of client data concerning both the server and other clients for neural networks. Some of these methods include homomorphic encryption, gradient compression, gradient noising, and discussion on possible usage of modified federated learning systems such as split learning, swarm learning or fully encrypted models. We have analyzed the negative effects of gradient compression and gradient noising on the accuracy of convolutional neural networks used for classification. We have shown the difficulty of data reconstruction in the case of segmentation networks. We have also implemented a proof of concept on the NVIDIA Jetson TX2 module used in edge devices and simulated a federated learning process.","authors":["Damian Harenčák","Lukáš Gajdošech","Martin Madaras"],"pdf_url":"","comment":"Accepted to VISAPP 2026 as Position Paper"},{"id":"http://arxiv.org/abs/2412.08973v3","updated":"2026-01-08T13:08:33Z","published":"2024-12-12T06:09:49Z","title":"Is Contrastive Distillation Enough for Learning Comprehensive 3D Representations?","summary":"Cross-modal contrastive distillation has recently been explored for learning effective 3D representations. However, existing methods focus primarily on modality-shared features, neglecting the modality-specific features during the pre-training process, which leads to suboptimal representations. In this paper, we theoretically analyze the limitations of current contrastive methods for 3D representation learning and propose a new framework, namely CMCR (Cross-Modal Comprehensive Representation Learning), to address these shortcomings. Our approach improves upon traditional methods by better integrating both modality-shared and modality-specific features. Specifically, we introduce masked image modeling and occupancy estimation tasks to guide the network in learning more comprehensive modality-specific features. Furthermore, we propose a novel multi-modal unified codebook that learns an embedding space shared across different modalities. Besides, we introduce geometry-enhanced masked image modeling to further boost 3D representation learning. Extensive experiments demonstrate that our method mitigates the challenges faced by traditional approaches and consistently outperforms existing image-to-LiDAR contrastive distillation methods in downstream tasks. Code will be available at https://github.com/Eaphan/CMCR.","authors":["Yifan Zhang","Junhui Hou"],"pdf_url":"","comment":"22 pages, 10 figures"},{"id":"http://arxiv.org/abs/2601.04899v1","updated":"2026-01-08T12:53:33Z","published":"2026-01-08T12:53:33Z","title":"Rotation-Robust Regression with Convolutional Model Trees","summary":"We study rotation-robust learning for image inputs using Convolutional Model Trees (CMTs) [1], whose split and leaf coefficients can be structured on the image grid and transformed geometrically at deployment time. In a controlled MNIST setting with a rotation-invariant regression target, we introduce three geometry-aware inductive biases for split directions -- convolutional smoothing, a tilt dominance constraint, and importance-based pruning -- and quantify their impact on robustness under in-plane rotations. We further evaluate a deployment-time orientation search that selects a discrete rotation maximizing a forest-level confidence proxy without updating model parameters. Orientation search improves robustness under severe rotations but can be harmful near the canonical orientation when confidence is misaligned with correctness. Finally, we observe consistent trends on MNIST digit recognition implemented as one-vs-rest regression, highlighting both the promise and limitations of confidence-based orientation selection for model-tree ensembles.","authors":["Hongyi Li","William Ward Armstrong","Jun Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04897v1","updated":"2026-01-08T12:50:14Z","published":"2026-01-08T12:50:14Z","title":"V-FAT: Benchmarking Visual Fidelity Against Text-bias","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated impressive performance on standard visual reasoning benchmarks. However, there is growing concern that these models rely excessively on linguistic shortcuts rather than genuine visual grounding, a phenomenon we term Text Bias. In this paper, we investigate the fundamental tension between visual perception and linguistic priors. We decouple the sources of this bias into two dimensions: Internal Corpus Bias, stemming from statistical correlations in pretraining, and External Instruction Bias, arising from the alignment-induced tendency toward sycophancy. To quantify this effect, we introduce V-FAT (Visual Fidelity Against Text-bias), a diagnostic benchmark comprising 4,026 VQA instances across six semantic domains. V-FAT employs a Three-Level Evaluation Framework that systematically increases the conflict between visual evidence and textual information: (L1) internal bias from atypical images, (L2) external bias from misleading instructions, and (L3) synergistic bias where both coincide. We introduce the Visual Robustness Score (VRS), a metric designed to penalize \"lucky\" linguistic guesses and reward true visual fidelity. Our evaluation of 12 frontier MLLMs reveals that while models excel in existing benchmarks, they experience significant visual collapse under high linguistic dominance.","authors":["Ziteng Wang","Yujie He","Guanliang Li","Siqi Yang","Jiaqi Xiong","Songxiang Liu"],"pdf_url":"","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2601.04891v1","updated":"2026-01-08T12:42:17Z","published":"2026-01-08T12:42:17Z","title":"Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform","summary":"Vision Language Models (VLMs) have shown strong performance on multimodal reasoning tasks, yet most evaluations focus on short videos and assume unconstrained computational resources. In industrial settings such as pharmaceutical content understanding, practitioners must process long-form videos under strict GPU, latency, and cost constraints, where many existing approaches fail to scale. In this work, we present an industrial GenAI framework that processes over 200,000 PDFs, 25,326 videos across eight formats (e.g., MP4, M4V, etc.), and 888 multilingual audio files in more than 20 languages. Our study makes three contributions: (i) an industrial large-scale architecture for multimodal reasoning in pharmaceutical domains; (ii) empirical analysis of over 40 VLMs on two leading benchmarks (Video-MME and MMBench) and proprietary dataset of 25,326 videos across 14 disease areas; and (iii) four findings relevant to long-form video reasoning: the role of multimodality, attention mechanism trade-offs, temporal reasoning limits, and challenges of video splitting under GPU constraints. Results show 3-8 times efficiency gains with SDPA attention on commodity GPUs, multimodality improving up to 8/12 task domains (especially length-dependent tasks), and clear bottlenecks in temporal alignment and keyframe detection across open- and closed-source VLMs. Rather than proposing a new \"A+B\" model, this paper characterizes practical limits, trade-offs, and failure patterns of current VLMs under realistic deployment constraints, and provide actionable guidance for both researchers and practitioners designing scalable multimodal systems for long-form video understanding in industrial domains.","authors":["Suyash Mishra","Qiang Li","Srikanth Patil","Satyanarayan Pati","Baddu Narendra"],"pdf_url":"","comment":"Submitted to the Industry Track of Top Tier Conference; currently under peer review"},{"id":"http://arxiv.org/abs/2512.03979v3","updated":"2026-01-08T12:28:51Z","published":"2025-12-03T17:10:44Z","title":"BlurDM: A Blur Diffusion Model for Image Deblurring","summary":"Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The project page is available at https://jin-ting-he.github.io/BlurDM/.","authors":["Jin-Ting He","Fu-Jen Tsai","Yan-Tsung Peng","Min-Hung Chen","Chia-Wen Lin","Yen-Yu Lin"],"pdf_url":"","comment":"NeurIPS 2025. Project Page: https://jin-ting-he.github.io/BlurDM/"},{"id":"http://arxiv.org/abs/2508.10688v2","updated":"2026-01-08T11:56:13Z","published":"2025-08-14T14:32:52Z","title":"Novel View Synthesis using DDIM Inversion","summary":"Synthesizing novel views from a single input image is a challenging task. It requires extrapolating the 3D structure of a scene while inferring details in occluded regions, and maintaining geometric consistency across viewpoints. Many existing methods must fine-tune large diffusion backbones using multiple views or train a diffusion model from scratch, which is extremely expensive. Additionally, they suffer from blurry reconstruction and poor generalization. This gap presents the opportunity to explore an explicit lightweight view translation framework that can directly utilize the high-fidelity generative capabilities of a pretrained diffusion model while reconstructing a scene from a novel view. Given the DDIM-inverted latent of a single input image, we employ a camera pose-conditioned translation U-Net, TUNet, to predict the inverted latent corresponding to the desired target view. However, the image sampled using the predicted latent may result in a blurry reconstruction. To this end, we propose a novel fusion strategy that exploits the inherent noise correlation structure observed in DDIM inversion. The proposed fusion strategy helps preserve the texture and fine-grained details. To synthesize the novel view, we use the fused latent as the initial condition for DDIM sampling, leveraging the generative prior of the pretrained diffusion model. Extensive experiments on MVImgNet demonstrate that our method outperforms existing methods.","authors":["Sehajdeep Singh","A V Subramanyam","Aditya Gupta","Sahil Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.12641v2","updated":"2026-01-08T11:53:15Z","published":"2025-05-19T02:50:15Z","title":"Single Image Reflection Separation via Dual Prior Interaction Transformer","summary":"Single image reflection separation aims to separate the transmission and reflection layers from a mixed image. Existing methods typically combine general priors from pre-trained models with task-specific priors such as text prompts and reflection detection. However, the transmission prior, as the most direct task-specific prior for the target transmission layer, has not been effectively modeled or fully utilized, limiting performance in complex scenarios. To address this issue, we propose a dual-prior interaction framework based on lightweight transmission prior generation and effective prior fusion. First, we design a Local Linear Correction Network (LLCN) that finetunes pre-trained models based on the physical constraint T=SI+B, where S and B represent pixel-wise and channel-wise scaling and bias transformations. LLCN efficiently generates high-quality transmission priors with minimal parameters. Second, we construct a Dual-Prior Interaction Transformer (DPIT) that employs a dual-stream channel reorganization attention mechanism. By reorganizing features from general and transmission priors for attention computation, DPIT achieves deep fusion of both priors, fully exploiting their complementary information. Experimental results on multiple benchmark datasets demonstrate that the proposed method achieves state-of-the-art performance.","authors":["Yue Huang","Zi'ang Li","Tianle Hu","Jie Wen","Guanbin Li","Jinglin Zhang","Guoxu Zhou","Xiaozhao Fang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04860v1","updated":"2026-01-08T11:53:04Z","published":"2026-01-08T11:53:04Z","title":"DivAS: Interactive 3D Segmentation of NeRFs via Depth-Weighted Voxel Aggregation","summary":"Existing methods for segmenting Neural Radiance Fields (NeRFs) are often optimization-based, requiring slow per-scene training that sacrifices the zero-shot capabilities of 2D foundation models. We introduce DivAS (Depth-interactive Voxel Aggregation Segmentation), an optimization-free, fully interactive framework that addresses these limitations. Our method operates via a fast GUI-based workflow where 2D SAM masks, generated from user point prompts, are refined using NeRF-derived depth priors to improve geometric accuracy and foreground-background separation. The core of our contribution is a custom CUDA kernel that aggregates these refined multi-view masks into a unified 3D voxel grid in under 200ms, enabling real-time visual feedback. This optimization-free design eliminates the need for per-scene training. Experiments on Mip-NeRF 360° and LLFF show that DivAS achieves segmentation quality comparable to optimization-based methods, while being 2-2.5x faster end-to-end, and up to an order of magnitude faster when excluding user prompting time.","authors":["Ayush Pande"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.21581v3","updated":"2026-01-08T11:48:39Z","published":"2025-05-27T09:58:43Z","title":"Cognitive-Hierarchy Guided End-to-End Planning for Autonomous Driving","summary":"While end-to-end autonomous driving has advanced significantly, prevailing methods remain fundamentally misaligned with human cognitive principles in both perception and planning. In this paper, we propose CogAD, a novel end-to-end autonomous driving model that emulates the hierarchical cognition mechanisms of human drivers. CogAD implements dual hierarchical mechanisms: global-to-local context processing for human-like perception and intent-conditioned multi-mode trajectory generation for cognitively-inspired planning. The proposed method demonstrates three principal advantages: comprehensive environmental understanding through hierarchical perception, robust planning exploration enabled by multi-level planning, and diverse yet reasonable multi-modal trajectory generation facilitated by dual-level uncertainty modeling. Extensive experiments on nuScenes and Bench2Drive demonstrate that CogAD achieves state-of-the-art performance in end-to-end planning, exhibiting particular superiority in long-tail scenarios and robust generalization to complex real-world driving conditions.","authors":["Zhennan Wang","Jianing Teng","Canqun Xiang","Kangliang Chen","Xing Pan","Lu Deng","Weihao Gu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.03244v2","updated":"2026-01-08T11:16:21Z","published":"2025-03-05T07:52:52Z","title":"Two-Stream Thermal Imaging Fusion for Enhanced Time of Birth Detection in Neonatal Care","summary":"Around 10% of newborns require some help to initiate breathing, and 5\\% need ventilation assistance. Accurate Time of Birth (ToB) documentation is essential for optimizing neonatal care, as timely interventions are vital for proper resuscitation. However, current clinical methods for recording ToB often rely on manual processes, which can be prone to inaccuracies. In this study, we present a novel two-stream fusion system that combines the power of image and video analysis to accurately detect the ToB from thermal recordings in the delivery room and operating theater. By integrating static and dynamic streams, our approach captures richer birth-related spatiotemporal features, leading to more robust and precise ToB estimation. We demonstrate that this synergy between data modalities enhances performance over single-stream approaches. Our system achieves 95.7% precision and 84.8% recall in detecting birth within short video clips. Additionally, with the help of a score aggregation module, it successfully identifies ToB in 100% of test cases, with a median absolute error of 2 seconds and an absolute mean deviation of 4.5 seconds compared to manual annotations.","authors":["Jorge García-Torres","Øyvind Meinich-Bache","Sara Brunner","Siren Rettedal","Vilde Kolstad","Kjersti Engan"],"pdf_url":"","comment":"This work has been accepted at IEEE 25th International Conference on Digital Signal Processing"},{"id":"http://arxiv.org/abs/2601.04834v1","updated":"2026-01-08T11:11:24Z","published":"2026-01-08T11:11:24Z","title":"Character Detection using YOLO for Writer Identification in multiple Medieval books","summary":"Paleography is the study of ancient and historical handwriting, its key objectives include the dating of manuscripts and understanding the evolution of writing. Estimating when a document was written and tracing the development of scripts and writing styles can be aided by identifying the individual scribes who contributed to a medieval manuscript. Although digital technologies have made significant progress in this field, the general problem remains unsolved and continues to pose open challenges. ... We previously proposed an approach focused on identifying specific letters or abbreviations that characterize each writer. In that study, we considered the letter \"a\", as it was widely present on all pages of text and highly distinctive, according to the suggestions of expert paleographers. We used template matching techniques to detect the occurrences of the character \"a\" on each page and the convolutional neural network (CNN) to attribute each instance to the correct scribe. Moving from the interesting results achieved from this previous system and being aware of the limitations of the template matching technique, which requires an appropriate threshold to work, we decided to experiment in the same framework with the use of the YOLO object detection model to identify the scribe who contributed to the writing of different medieval books. We considered the fifth version of YOLO to implement the YOLO object detection model, which completely substituted the template matching and CNN used in the previous work. The experimental results demonstrate that YOLO effectively extracts a greater number of letters considered, leading to a more accurate second-stage classification. Furthermore, the YOLO confidence score provides a foundation for developing a system that applies a rejection threshold, enabling reliable writer identification even in unseen manuscripts.","authors":["Alessandra Scotto di Freca","Tiziana D Alessandro","Francesco Fontanella","Filippo Sarria","Claudio De Stefano"],"pdf_url":"","comment":"7 pages, 2 figures, 1 table. Accepted at IEEE-CH 2025"},{"id":"http://arxiv.org/abs/2601.03193v2","updated":"2026-01-08T11:08:10Z","published":"2026-01-06T17:15:50Z","title":"UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision","summary":"While Unified Multimodal Models (UMMs) have achieved remarkable success in cross-modal comprehension, a significant gap persists in their ability to leverage such internal knowledge for high-quality generation. We formalize this discrepancy as Conduction Aphasia, a phenomenon where models accurately interpret multimodal inputs but struggle to translate that understanding into faithful and controllable synthesis. To address this, we propose UniCorn, a simple yet elegant self-improvement framework that eliminates the need for external data or teacher supervision. By partitioning a single UMM into three collaborative roles: Proposer, Solver, and Judge, UniCorn generates high-quality interactions via self-play and employs cognitive pattern reconstruction to distill latent understanding into explicit generative signals. To validate the restoration of multimodal coherence, we introduce UniCycle, a cycle-consistency benchmark based on a Text to Image to Text reconstruction loop. Extensive experiments demonstrate that UniCorn achieves comprehensive and substantial improvements over the base model across six general image generation benchmarks. Notably, it achieves SOTA performance on TIIF(73.8), DPG(86.8), CompBench(88.5), and UniCycle while further delivering substantial gains of +5.0 on WISE and +6.5 on OneIG. These results highlight that our method significantly enhances T2I generation while maintaining robust comprehension, demonstrating the scalability of fully self-supervised refinement for unified multimodal intelligence.","authors":["Ruiyan Han","Zhen Fang","XinYu Sun","Yuchen Ma","Ziheng Wang","Yu Zeng","Zehui Chen","Lin Chen","Wenxuan Huang","Wei-Jie Xu","Yi Cao","Feng Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04825v1","updated":"2026-01-08T11:00:40Z","published":"2026-01-08T11:00:40Z","title":"Illumination Angular Spectrum Encoding for Controlling the Functionality of Diffractive Networks","summary":"Diffractive neural networks have recently emerged as a promising framework for all-optical computing. However, these networks are typically trained for a single task, limiting their potential adoption in systems requiring multiple functionalities. Existing approaches to achieving multi-task functionality either modify the mechanical configuration of the network per task or use a different illumination wavelength or polarization state for each task. In this work, we propose a new control mechanism, which is based on the illumination's angular spectrum. Specifically, we shape the illumination using an amplitude mask that selectively controls its angular spectrum. We employ different illumination masks for achieving different network functionalities, so that the mask serves as a unique task encoder. Interestingly, we show that effective control can be achieved over a very narrow angular range, within the paraxial regime. We numerically illustrate the proposed approach by training a single diffractive network to perform multiple image-to-image translation tasks. In particular, we demonstrate translating handwritten digits into typeset digits of different values, and translating handwritten English letters into typeset numbers and typeset Greek letters, where the type of the output is determined by the illumination's angular components. As we show, the proposed framework can work under different coherence conditions, and can be combined with existing control strategies, such as different wavelengths. Our results establish the illumination angular spectrum as a powerful degree of freedom for controlling diffractive networks, enabling a scalable and versatile framework for multi-task all-optical computing.","authors":["Matan Kleiner","Lior Michaeli","Tomer Michaeli"],"pdf_url":"","comment":"Project's code https://github.com/matankleiner/Angular-Spectrum-Encoding"},{"id":"http://arxiv.org/abs/2601.04824v1","updated":"2026-01-08T10:58:59Z","published":"2026-01-08T10:58:59Z","title":"SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models","summary":"Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.\n  Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.","authors":["Oriol Rabasseda","Zenjie Li","Kamal Nasrollahi","Sergio Escalera"],"pdf_url":"","comment":"This work has been accepted at Real World Surveillance: Applications and Challenges, 6th (in WACV Workshops)"},{"id":"http://arxiv.org/abs/2601.02046v2","updated":"2026-01-08T10:57:37Z","published":"2026-01-05T12:06:43Z","title":"Agentic Retoucher for Text-To-Image Generation","summary":"Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.","authors":["Shaocheng Shen","Jianfeng Liang","Chunlei Cai","Cong Geng","Huiyu Duan","Xiaoyun Zhang","Qiang Hu","Guangtao Zhai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01747v2","updated":"2026-01-08T10:46:04Z","published":"2026-01-05T02:49:33Z","title":"Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization","summary":"Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs","authors":["Jiwei Guan","Haibo Jin","Haohan Wang"],"pdf_url":"","comment":"EACL"},{"id":"http://arxiv.org/abs/2601.04800v1","updated":"2026-01-08T10:30:59Z","published":"2026-01-08T10:30:59Z","title":"Integrated Framework for Selecting and Enhancing Ancient Marathi Inscription Images from Stone, Metal Plate, and Paper Documents","summary":"Ancient script images often suffer from severe background noise, low contrast, and degradation caused by aging and environmental effects. In many cases, the foreground text and background exhibit similar visual characteristics, making the inscriptions difficult to read. The primary objective of image enhancement is to improve the readability of such degraded ancient images. This paper presents an image enhancement approach based on binarization and complementary preprocessing techniques for removing stains and enhancing unclear ancient text. The proposed methods are evaluated on different types of ancient scripts, including inscriptions on stone, metal plates, and historical documents. Experimental results show that the proposed approach achieves classification accuracies of 55.7%, 62%, and 65.6% for stone, metal plate, and document scripts, respectively, using the K-Nearest Neighbor (K-NN) classifier. Using the Support Vector Machine (SVM) classifier, accuracies of 53.2%, 59.5%, and 67.8% are obtained. The results demonstrate the effectiveness of the proposed enhancement method in improving the readability of ancient Marathi inscription images.","authors":["Bapu D. Chendage","Rajivkumar S. Mente"],"pdf_url":"","comment":"9 Pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.07155v4","updated":"2026-01-08T10:29:58Z","published":"2025-12-08T04:39:12Z","title":"CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics","summary":"Diffusion models exhibit remarkable generative ability, yet achieving smooth and semantically consistent image morphing remains a challenge. Existing approaches often yield abrupt transitions or over-saturated appearances due to the lack of adaptive structural and semantic alignments. We propose CHIMERA, a zero-shot diffusion-based framework that formulates morphing as a cached inversion-guided denoising process. To handle large semantic and appearance disparities, we propose Adaptive Cache Injection and Semantic Anchor Prompting. Adaptive Cache Injection (ACI) caches down, mid, and up blocks features from both inputs during DDIM inversion and re-injects them adaptively during denoising, enabling spatial and semantic alignment in depth- and time-adaptive manners and enabling natural feature fusion and smooth transitions. Semantic Anchor Prompting (SAP) leverages a vision-language model to generate a shared anchor prompt that serves as a semantic anchor, bridging dissimilar inputs and guiding the denoising process toward coherent results. Finally, we introduce the Global-Local Consistency Score (GLCS), a morphing-oriented metric that simultaneously evaluates the global harmonization of the two inputs and the smoothness of the local morphing transition. Extensive experiments and user studies show that CHIMERA achieves smoother and more semantically aligned transitions than existing methods, establishing a new state of the art in image morphing. The code and project page will be publicly released.","authors":["Dahyeon Kye","Jeahun Sung","Minkyu Jeon","Jihyong Oh"],"pdf_url":"","comment":"Please visit our project page at https://cmlab-korea.github.io/CHIMERA/"},{"id":"http://arxiv.org/abs/2601.04798v1","updated":"2026-01-08T10:27:05Z","published":"2026-01-08T10:27:05Z","title":"Detector-Augmented SAMURAI for Long-Duration Drone Tracking","summary":"Robust long-term tracking of drone is a critical requirement for modern surveillance systems, given their increasing threat potential. While detector-based approaches typically achieve strong frame-level accuracy, they often suffer from temporal inconsistencies caused by frequent detection dropouts. Despite its practical relevance, research on RGB-based drone tracking is still limited and largely reliant on conventional motion models. Meanwhile, foundation models like SAMURAI have established their effectiveness across other domains, exhibiting strong category-agnostic tracking performance. However, their applicability in drone-specific scenarios has not been investigated yet. Motivated by this gap, we present the first systematic evaluation of SAMURAI's potential for robust drone tracking in urban surveillance settings. Furthermore, we introduce a detector-augmented extension of SAMURAI to mitigate sensitivity to bounding-box initialization and sequence length. Our findings demonstrate that the proposed extension significantly improves robustness in complex urban environments, with pronounced benefits in long-duration sequences - especially under drone exit-re-entry events. The incorporation of detector cues yields consistent gains over SAMURAI's zero-shot performance across datasets and metrics, with success rate improvements of up to +0.393 and FNR reductions of up to -0.475.","authors":["Tamara R. Lenhard","Andreas Weinmann","Hichem Snoussi","Tobias Koch"],"pdf_url":"","comment":"Accepted at the WACV 2026 Workshop on \"Real World Surveillance: Applications and Challenges\""},{"id":"http://arxiv.org/abs/2511.05547v2","updated":"2026-01-08T10:24:34Z","published":"2025-11-01T19:05:09Z","title":"Automated Invoice Data Extraction: Using LLM and OCR","summary":"Conventional Optical Character Recognition (OCR) systems are challenged by variant invoice layouts, handwritten text, and low-quality scans, which are often caused by strong template dependencies that restrict their flexibility across different document structures and layouts. Newer solutions utilize advanced deep learning models such as Convolutional Neural Networks (CNN) as well as Transformers, and domain-specific models for better layout analysis and accuracy across various sections over varied document types. Large Language Models (LLMs) have revolutionized extraction pipelines at their core with sophisticated entity recognition and semantic comprehension to support complex contextual relationship mapping without direct programming specification. Visual Named Entity Recognition (NER) capabilities permit extraction from invoice images with greater contextual sensitivity and much higher accuracy rates than older approaches. Existing industry best practices utilize hybrid architectures that blend OCR technology and LLM for maximum scalability and minimal human intervention. This work introduces a holistic Artificial Intelligence (AI) platform combining OCR, deep learning, LLMs, and graph analytics to achieve unprecedented extraction quality and consistency.","authors":["Khushi Khanchandani","Advait Thakur","Akshita Shetty","Chaitravi Reddy","Ritisa Behera"],"pdf_url":"","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2601.04792v1","updated":"2026-01-08T10:16:06Z","published":"2026-01-08T10:16:06Z","title":"PyramidalWan: On Making Pretrained Video Model Pyramidal for Efficient Inference","summary":"Recently proposed pyramidal models decompose the conventional forward and backward diffusion processes into multiple stages operating at varying resolutions. These models handle inputs with higher noise levels at lower resolutions, while less noisy inputs are processed at higher resolutions. This hierarchical approach significantly reduces the computational cost of inference in multi-step denoising models. However, existing open-source pyramidal video models have been trained from scratch and tend to underperform compared to state-of-the-art systems in terms of visual plausibility. In this work, we present a pipeline that converts a pretrained diffusion model into a pyramidal one through low-cost finetuning, achieving this transformation without degradation in quality of output videos. Furthermore, we investigate and compare various strategies for step distillation within pyramidal models, aiming to further enhance the inference efficiency. Our results are available at https://qualcomm-ai-research.github.io/PyramidalWan.","authors":["Denis Korzhenkov","Adil Karjauv","Animesh Karnewar","Mohsen Ghafoorian","Amirhossein Habibian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04791v1","updated":"2026-01-08T10:15:35Z","published":"2026-01-08T10:15:35Z","title":"Measurement-Consistent Langevin Corrector: A Remedy for Latent Diffusion Inverse Solvers","summary":"With recent advances in generative models, diffusion models have emerged as powerful priors for solving inverse problems in each domain. Since Latent Diffusion Models (LDMs) provide generic priors, several studies have explored their potential as domain-agnostic zero-shot inverse solvers. Despite these efforts, existing latent diffusion inverse solvers suffer from their instability, exhibiting undesirable artifacts and degraded quality. In this work, we first identify the instability as a discrepancy between the solver's and true reverse diffusion dynamics, and show that reducing this gap stabilizes the solver. Building on this, we introduce Measurement-Consistent Langevin Corrector (MCLC), a theoretically grounded plug-and-play correction module that remedies the LDM-based inverse solvers through measurement-consistent Langevin updates. Compared to prior approaches that rely on linear manifold assumptions, which often do not hold in latent space, MCLC operates without this assumption, leading to more stable and reliable behavior. We experimentally demonstrate the effectiveness of MCLC and its compatibility with existing solvers across diverse image restoration tasks. Additionally, we analyze blob artifacts and offer insights into their underlying causes. We highlight that MCLC is a key step toward more robust zero-shot inverse problem solvers.","authors":["Lee Hyoseok","Sohwi Lim","Eunju Cha","Tae-Hyun Oh"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2601.04785v1","updated":"2026-01-08T10:10:03Z","published":"2026-01-08T10:10:03Z","title":"SRU-Pix2Pix: A Fusion-Driven Generator Network for Medical Image Translation with Few-Shot Learning","summary":"Magnetic Resonance Imaging (MRI) provides detailed tissue information, but its clinical application is limited by long acquisition time, high cost, and restricted resolution. Image translation has recently gained attention as a strategy to address these limitations. Although Pix2Pix has been widely applied in medical image translation, its potential has not been fully explored. In this study, we propose an enhanced Pix2Pix framework that integrates Squeeze-and-Excitation Residual Networks (SEResNet) and U-Net++ to improve image generation quality and structural fidelity. SEResNet strengthens critical feature representation through channel attention, while U-Net++ enhances multi-scale feature fusion. A simplified PatchGAN discriminator further stabilizes training and refines local anatomical realism. Experimental results demonstrate that under few-shot conditions with fewer than 500 images, the proposed method achieves consistent structural fidelity and superior image quality across multiple intra-modality MRI translation tasks, showing strong generalization ability. These results suggest an effective extension of Pix2Pix for medical image translation.","authors":["Xihe Qiu","Yang Dai","Xiaoyu Tan","Sijia Li","Fenghao Sun","Lu Gan","Liang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04779v1","updated":"2026-01-08T10:03:13Z","published":"2026-01-08T10:03:13Z","title":"Defocus Aberration Theory Confirms Gaussian Model in Most Imaging Devices","summary":"Over the past three decades, defocus has consistently provided groundbreaking depth information in scene images. However, accurately estimating depth from 2D images continues to be a persistent and fundamental challenge in the field of 3D recovery. Heuristic approaches involve with the ill-posed problem for inferring the spatial variant defocusing blur, as the desired blur cannot be distinguished from the inherent blur. Given a prior knowledge of the defocus model, the problem become well-posed with an analytic solution for the relative blur between two images, taken at the same viewpoint with different camera settings for the focus. The Gaussian model stands out as an optimal choice for real-time applications, due to its mathematical simplicity and computational efficiency. And theoretically, it is the only model can be applied at the same time to both the absolute blur caused by depth in a single image and the relative blur resulting from depth differences between two images. This paper introduces the settings, for conventional imaging devices, to ensure that the defocusing operator adheres to the Gaussian model. Defocus analysis begins within the framework of geometric optics and is conducted by defocus aberration theory in diffraction-limited optics to obtain the accuracy of fitting the actual model to its Gaussian approximation. The results for a typical set of focused depths between $1$ and $100$ meters, with a maximum depth variation of $10\\%$ at the focused depth, confirm the Gaussian model's applicability for defocus operators in most imaging devices. The findings demonstrate a maximum Mean Absolute Error $(\\!M\\!A\\!E)$ of less than $1\\%$, underscoring the model's accuracy and reliability.","authors":["Akbar Saadat"],"pdf_url":"","comment":"13 pages, 9 figures, 11 .jpg files"},{"id":"http://arxiv.org/abs/2601.04778v1","updated":"2026-01-08T10:03:07Z","published":"2026-01-08T10:03:07Z","title":"CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models","summary":"Video-language models (VLMs) achieve strong multimodal understanding but remain prone to hallucinations, especially when reasoning about actions and temporal order. Existing mitigation strategies, such as textual filtering or random video perturbations, often fail to address the root cause: over-reliance on language priors rather than fine-grained visual dynamics. We propose a scalable framework for counterfactual video generation that synthesizes videos differing only in actions or temporal structure while preserving scene context. Our pipeline combines multimodal LLMs for action proposal and editing guidance with diffusion-based image and video models to generate semantic hard negatives at scale. Using this framework, we build CounterVid, a synthetic dataset of ~26k preference pairs targeting action recognition and temporal reasoning. We further introduce MixDPO, a unified Direct Preference Optimization approach that jointly leverages textual and visual preferences. Fine-tuning Qwen2.5-VL with MixDPO yields consistent improvements, notably in temporal ordering, and transfers effectively to standard video hallucination benchmarks. Code and models will be made publicly available.","authors":["Tobia Poppi","Burak Uzkent","Amanmeet Garg","Lucas Porto","Garin Kessler","Yezhou Yang","Marcella Cornia","Lorenzo Baraldi","Rita Cucchiara","Florian Schiffers"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.15361v2","updated":"2026-01-08T10:00:24Z","published":"2025-03-19T16:01:27Z","title":"Boosting HDR Image Reconstruction via Semantic Knowledge Transfer","summary":"Recovering High Dynamic Range (HDR) images from multiple Standard Dynamic Range (SDR) images become challenging when the SDR images exhibit noticeable degradation and missing content. Leveraging scene-specific semantic priors offers a promising solution for restoring heavily degraded regions. However, these priors are typically extracted from sRGB SDR images, the domain/format gap poses a significant challenge when applying it to HDR imaging. To address this issue, we propose a general framework that transfers semantic knowledge derived from SDR domain via self-distillation to boost existing HDR reconstruction. Specifically, the proposed framework first introduces the Semantic Priors Guided Reconstruction Model (SPGRM), which leverages SDR image semantic knowledge to address ill-posed problems in the initial HDR reconstruction results. Subsequently, we leverage a self-distillation mechanism that constrains the color and content information with semantic knowledge, aligning the external outputs between the baseline and SPGRM. Furthermore, to transfer the semantic knowledge of the internal features, we utilize a Semantic Knowledge Alignment Module (SKAM) to fill the missing semantic contents with the complementary masks. Extensive experiments demonstrate that our framework significantly boosts HDR imaging quality for existing methods without altering the network architecture.","authors":["Tao Hu","Longyao Wu","Wei Dong","Peng Wu","Jinqiu Sun","Xiaogang Xu","Qingsen Yan","Yanning Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04777v1","updated":"2026-01-08T09:58:35Z","published":"2026-01-08T09:58:35Z","title":"GeM-VG: Towards Generalized Multi-image Visual Grounding with Multimodal Large Language Models","summary":"Multimodal Large Language Models (MLLMs) have demonstrated impressive progress in single-image grounding and general multi-image understanding. Recently, some methods begin to address multi-image grounding. However, they are constrained by single-target localization and limited types of practical tasks, due to the lack of unified modeling for generalized grounding tasks. Therefore, we propose GeM-VG, an MLLM capable of Generalized Multi-image Visual Grounding. To support this, we systematically categorize and organize existing multi-image grounding tasks according to their reliance of cross-image cues and reasoning, and introduce the MG-Data-240K dataset, addressing the limitations of existing datasets regarding target quantity and image relation. To tackle the challenges of robustly handling diverse multi-image grounding tasks, we further propose a hybrid reinforcement finetuning strategy that integrates chain-of-thought (CoT) reasoning and direct answering, considering their complementary strengths. This strategy adopts an R1-like algorithm guided by a carefully designed rule-based reward, effectively enhancing the model's overall perception and reasoning capabilities. Extensive experiments demonstrate the superior generalized grounding capabilities of our model. For multi-image grounding, it outperforms the previous leading MLLMs by 2.0% and 9.7% on MIG-Bench and MC-Bench, respectively. In single-image grounding, it achieves a 9.1% improvement over the base model on ODINW. Furthermore, our model retains strong capabilities in general multi-image understanding.","authors":["Shurong Zheng","Yousong Zhu","Hongyin Zhao","Fan Yang","Yufei Zhan","Ming Tang","Jinqiao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04776v1","updated":"2026-01-08T09:57:47Z","published":"2026-01-08T09:57:47Z","title":"Segmentation-Driven Monocular Shape from Polarization based on Physical Model","summary":"Monocular shape-from-polarization (SfP) leverages the intrinsic relationship between light polarization properties and surface geometry to recover surface normals from single-view polarized images, providing a compact and robust approach for three-dimensional (3D) reconstruction. Despite its potential, existing monocular SfP methods suffer from azimuth angle ambiguity, an inherent limitation of polarization analysis, that severely compromises reconstruction accuracy and stability. This paper introduces a novel segmentation-driven monocular SfP (SMSfP) framework that reformulates global shape recovery into a set of local reconstructions over adaptively segmented convex sub-regions. Specifically, a polarization-aided adaptive region growing (PARG) segmentation strategy is proposed to decompose the global convexity assumption into locally convex regions, effectively suppressing azimuth ambiguities and preserving surface continuity. Furthermore, a multi-scale fusion convexity prior (MFCP) constraint is developed to ensure local surface consistency and enhance the recovery of fine textural and structural details. Extensive experiments on both synthetic and real-world datasets validate the proposed approach, showing significant improvements in disambiguation accuracy and geometric fidelity compared with existing physics-based monocular SfP techniques.","authors":["Jinyu Zhang","Xu Ma","Weili Chen","Gonzalo R. Arce"],"pdf_url":"","comment":"11 pages, 10 figures, submittd to IEEE Transactions on Image Processing"},{"id":"http://arxiv.org/abs/2507.13425v2","updated":"2026-01-08T09:25:09Z","published":"2025-07-17T17:10:37Z","title":"CaTFormer: Causal Temporal Transformer with Dynamic Contextual Fusion for Driving Intention Prediction","summary":"Accurate prediction of driving intention is key to enhancing the safety and interactive efficiency of human-machine co-driving systems. It serves as a cornerstone for achieving high-level autonomous driving. However, current approaches remain inadequate for accurately modeling the complex spatiotemporal interdependencies and the unpredictable variability of human driving behavior. To address these challenges, we propose CaTFormer, a causal Temporal Transformer that explicitly models causal interactions between driver behavior and environmental context for robust intention prediction. Specifically, CaTFormer introduces a novel Reciprocal Delayed Fusion (RDF) mechanism for precise temporal alignment of interior and exterior feature streams, a Counterfactual Residual Encoding (CRE) module that systematically eliminates spurious correlations to reveal authentic causal dependencies, and an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these purified representations into coherent temporal representations. Experimental results demonstrate that CaTFormer attains state-of-the-art performance on the Brain4Cars dataset. It effectively captures complex causal temporal dependencies and enhances both the accuracy and transparency of driving intention prediction.","authors":["Sirui Wang","Zhou Guan","Bingxi Zhao","Tongjia Gu","Jie Liu"],"pdf_url":"","comment":"Accepted at AAAI 2026"},{"id":"http://arxiv.org/abs/2601.04754v1","updated":"2026-01-08T09:20:46Z","published":"2026-01-08T09:20:46Z","title":"ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting","summary":"We present ProFuse, an efficient context-aware framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting (3DGS). The pipeline enhances cross-view consistency and intra-mask cohesion within a direct registration setup, adding minimal overhead and requiring no render-supervised fine-tuning. Instead of relying on a pretrained 3DGS scene, we introduce a dense correspondence-guided pre-registration phase that initializes Gaussians with accurate geometry while jointly constructing 3D Context Proposals via cross-view clustering. Each proposal carries a global feature obtained through weighted aggregation of member embeddings, and this feature is fused onto Gaussians during direct registration to maintain per-primitive language coherence across views. With associations established in advance, semantic fusion requires no additional optimization beyond standard reconstruction, and the model retains geometric refinement without densification. ProFuse achieves strong open-vocabulary 3DGS understanding while completing semantic attachment in about five minutes per scene, which is two times faster than SOTA.","authors":["Yen-Jen Chiou","Wei-Tse Cheng","Yuan-Fu Yang"],"pdf_url":"","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.04752v1","updated":"2026-01-08T09:15:27Z","published":"2026-01-08T09:15:27Z","title":"Skeletonization-Based Adversarial Perturbations on Large Vision Language Model's Mathematical Text Recognition","summary":"This work explores the visual capabilities and limitations of foundation models by introducing a novel adversarial attack method utilizing skeletonization to reduce the search space effectively. Our approach specifically targets images containing text, particularly mathematical formula images, which are more challenging due to their LaTeX conversion and intricate structure. We conduct a detailed evaluation of both character and semantic changes between original and adversarially perturbed outputs to provide insights into the models' visual interpretation and reasoning abilities. The effectiveness of our method is further demonstrated through its application to ChatGPT, which shows its practical implications in real-world scenarios.","authors":["Masatomo Yoshida","Haruto Namura","Nicola Adami","Masahiro Okuda"],"pdf_url":"","comment":"accepted to ITC-CSCC 2025"},{"id":"http://arxiv.org/abs/2411.05633v2","updated":"2026-01-08T09:08:41Z","published":"2024-11-08T15:22:49Z","title":"SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection","summary":"Developing robust drone detection systems is often constrained by the limited availability of large-scale annotated training data and the high costs associated with real-world data collection. However, leveraging synthetic data generated via game engine-based simulations provides a promising and cost-effective solution to overcome this issue. Therefore, we present SynDroneVision, a synthetic dataset specifically designed for RGB-based drone detection in surveillance applications. Featuring diverse backgrounds, lighting conditions, and drone models, SynDroneVision offers a comprehensive training foundation for deep learning algorithms. To evaluate the dataset's effectiveness, we perform a comparative analysis across a selection of recent YOLO detection models. Our findings demonstrate that SynDroneVision is a valuable resource for real-world data enrichment, achieving notable enhancements in model performance and robustness, while significantly reducing the time and costs of real-world data acquisition. SynDroneVision will be publicly released upon paper acceptance.","authors":["Tamara R. Lenhard","Andreas Weinmann","Kai Franke","Tobias Koch"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04734v1","updated":"2026-01-08T08:56:07Z","published":"2026-01-08T08:56:07Z","title":"AIVD: Adaptive Edge-Cloud Collaboration for Accurate and Efficient Industrial Visual Detection","summary":"Multimodal large language models (MLLMs) demonstrate exceptional capabilities in semantic understanding and visual reasoning, yet they still face challenges in precise object localization and resource-constrained edge-cloud deployment. To address this, this paper proposes the AIVD framework, which achieves unified precise localization and high-quality semantic generation through the collaboration between lightweight edge detectors and cloud-based MLLMs. To enhance the cloud MLLM's robustness against edge cropped-box noise and scenario variations, we design an efficient fine-tuning strategy with visual-semantic collaborative augmentation, significantly improving classification accuracy and semantic consistency. Furthermore, to maintain high throughput and low latency across heterogeneous edge devices and dynamic network conditions, we propose a heterogeneous resource-aware dynamic scheduling algorithm. Experimental results demonstrate that AIVD substantially reduces resource consumption while improving MLLM classification performance and semantic generation quality. The proposed scheduling strategy also achieves higher throughput and lower latency across diverse scenarios.","authors":["Yunqing Hu","Zheming Yang","Chang Zhao","Qi Guo","Meng Gao","Pengcheng Li","Wen Ji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04727v1","updated":"2026-01-08T08:44:17Z","published":"2026-01-08T08:44:17Z","title":"Training a Custom CNN on Five Heterogeneous Image Datasets","summary":"Deep learning has transformed visual data analysis, with Convolutional Neural Networks (CNNs) becoming highly effective in learning meaningful feature representations directly from images. Unlike traditional manual feature engineering methods, CNNs automatically extract hierarchical visual patterns, enabling strong performance across diverse real-world contexts. This study investigates the effectiveness of CNN-based architectures across five heterogeneous datasets spanning agricultural and urban domains: mango variety classification, paddy variety identification, road surface condition assessment, auto-rickshaw detection, and footpath encroachment monitoring. These datasets introduce varying challenges, including differences in illumination, resolution, environmental complexity, and class imbalance, necessitating adaptable and robust learning models.\n  We evaluate a lightweight, task-specific custom CNN alongside established deep architectures, including ResNet-18 and VGG-16, trained both from scratch and using transfer learning. Through systematic preprocessing, augmentation, and controlled experimentation, we analyze how architectural complexity, model depth, and pre-training influence convergence, generalization, and performance across datasets of differing scale and difficulty. The key contributions of this work are: (1) the development of an efficient custom CNN that achieves competitive performance across multiple application domains, and (2) a comprehensive comparative analysis highlighting when transfer learning and deep architectures provide substantial advantages, particularly in data-constrained environments. These findings offer practical insights for deploying deep learning models in resource-limited yet high-impact real-world visual classification tasks.","authors":["Anika Tabassum","Tasnuva Mahazabin Tuba","Nafisa Naznin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01568v2","updated":"2026-01-08T08:43:41Z","published":"2026-01-04T15:26:15Z","title":"MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning","summary":"Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.","authors":["Chunyu Qiang","Jun Wang","Xiaopeng Wang","Kang Yin","Yuxin Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03714v2","updated":"2026-01-08T08:37:59Z","published":"2026-01-07T09:01:23Z","title":"Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR","summary":"DeepSeek-OCR utilizes an optical 2D mapping approach to achieve high-ratio vision-text compression, claiming to decode text tokens exceeding ten times the input visual tokens. While this suggests a promising solution for the LLM long-context bottleneck, we investigate a critical question: \"Visual merit or linguistic crutch - which drives DeepSeek-OCR's performance?\" By employing sentence-level and word-level semantic corruption, we isolate the model's intrinsic OCR capabilities from its language priors. Results demonstrate that without linguistic support, DeepSeek-OCR's performance plummets from approximately 90% to 20%. Comparative benchmarking against 13 baseline models reveals that traditional pipeline OCR methods exhibit significantly higher robustness to such semantic perturbations than end-to-end methods. Furthermore, we find that lower visual token counts correlate with increased reliance on priors, exacerbating hallucination risks. Context stress testing also reveals a total model collapse around 10,000 text tokens, suggesting that current optical compression techniques may paradoxically aggravate the long-context bottleneck. This study empirically defines DeepSeek-OCR's capability boundaries and offers essential insights for future optimizations of the vision-text compression paradigm. We release all data, results and scripts used in this study at https://github.com/dududuck00/DeepSeekOCR.","authors":["Yunhao Liang","Ruixuan Ying","Bo Li","Hong Li","Kai Yan","Qingwen Li","Min Yang","Okamoto Satoshi","Zhe Cui","Shiwen Ni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04715v1","updated":"2026-01-08T08:33:22Z","published":"2026-01-08T08:33:22Z","title":"On the Holistic Approach for Detecting Human Image Forgery","summary":"The rapid advancement of AI-generated content (AIGC) has escalated the threat of deepfakes, from facial manipulations to the synthesis of entire photorealistic human bodies. However, existing detection methods remain fragmented, specializing either in facial-region forgeries or full-body synthetic images, and consequently fail to generalize across the full spectrum of human image manipulations. We introduce HuForDet, a holistic framework for human image forgery detection, which features a dual-branch architecture comprising: (1) a face forgery detection branch that employs heterogeneous experts operating in both RGB and frequency domains, including an adaptive Laplacian-of-Gaussian (LoG) module designed to capture artifacts ranging from fine-grained blending boundaries to coarse-scale texture irregularities; and (2) a contextualized forgery detection branch that leverages a Multi-Modal Large Language Model (MLLM) to analyze full-body semantic consistency, enhanced with a confidence estimation mechanism that dynamically weights its contribution during feature fusion. We curate a human image forgery (HuFor) dataset that unifies existing face forgery data with a new corpus of full-body synthetic humans. Extensive experiments show that our HuForDet achieves state-of-the-art forgery detection performance and superior robustness across diverse human image forgeries.","authors":["Xiao Guo","Jie Zhu","Anil Jain","Xiaoming Liu"],"pdf_url":"","comment":"6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2601.04706v1","updated":"2026-01-08T08:18:44Z","published":"2026-01-08T08:18:44Z","title":"Forge-and-Quench: Enhancing Image Generation for Higher Fidelity in Unified Multimodal Models","summary":"Integrating image generation and understanding into a single framework has become a pivotal goal in the multimodal domain. However, how understanding can effectively assist generation has not been fully explored. Unlike previous works that focus on leveraging reasoning abilities and world knowledge from understanding models, this paper introduces a novel perspective: leveraging understanding to enhance the fidelity and detail richness of generated images. To this end, we propose Forge-and-Quench, a new unified framework that puts this principle into practice. In the generation process of our framework, an MLLM first reasons over the entire conversational context, including text instructions, to produce an enhanced text instruction. This refined instruction is then mapped to a virtual visual representation, termed the Bridge Feature, via a novel Bridge Adapter. This feature acts as a crucial link, forging insights from the understanding model to quench and refine the generation process. It is subsequently injected into the T2I backbone as a visual guidance signal, alongside the enhanced text instruction that replaces the original input. To validate this paradigm, we conduct comprehensive studies on the design of the Bridge Feature and Bridge Adapter. Our framework demonstrates exceptional extensibility and flexibility, enabling efficient migration across different MLLM and T2I models with significant savings in training overhead, all without compromising the MLLM's inherent multimodal understanding capabilities. Experiments show that Forge-and-Quench significantly improves image fidelity and detail across multiple models, while also maintaining instruction-following accuracy and enhancing world knowledge application. Models and codes are available at https://github.com/YanbingZeng/Forge-and-Quench.","authors":["Yanbing Zeng","Jia Wang","Hanghang Ma","Junqiang Wu","Jie Zhu","Xiaoming Wei","Jie Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04692v1","updated":"2026-01-08T08:02:48Z","published":"2026-01-08T08:02:48Z","title":"See, Explain, and Intervene: A Few-Shot Multimodal Agent Framework for Hateful Meme Moderation","summary":"In this work, we examine hateful memes from three complementary angles - how to detect them, how to explain their content and how to intervene them prior to being posted - by applying a range of strategies built on top of generative AI models. To the best of our knowledge, explanation and intervention have typically been studied separately from detection, which does not reflect real-world conditions. Further, since curating large annotated datasets for meme moderation is prohibitively expensive, we propose a novel framework that leverages task-specific generative multimodal agents and the few-shot adaptability of large multimodal models to cater to different types of memes. We believe this is the first work focused on generalizable hateful meme moderation under limited data conditions, and has strong potential for deployment in real-world production scenarios. Warning: Contains potentially toxic contents.","authors":["Naquee Rizwan","Subhankar Swain","Paramananda Bhaskar","Gagan Aryan","Shehryaar Shah Khan","Animesh Mukherjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04687v1","updated":"2026-01-08T07:55:10Z","published":"2026-01-08T07:55:10Z","title":"WebCryptoAgent: Agentic Crypto Trading with Web Informatics","summary":"Cryptocurrency trading increasingly depends on timely integration of heterogeneous web information and market microstructure signals to support short-horizon decision making under extreme volatility. However, existing trading systems struggle to jointly reason over noisy multi-source web evidence while maintaining robustness to rapid price shocks at sub-second timescales. The first challenge lies in synthesizing unstructured web content, social sentiment, and structured OHLCV signals into coherent and interpretable trading decisions without amplifying spurious correlations, while the second challenge concerns risk control, as slow deliberative reasoning pipelines are ill-suited for handling abrupt market shocks that require immediate defensive responses. To address these challenges, we propose WebCryptoAgent, an agentic trading framework that decomposes web-informed decision making into modality-specific agents and consolidates their outputs into a unified evidence document for confidence-calibrated reasoning. We further introduce a decoupled control architecture that separates strategic hourly reasoning from a real-time second-level risk model, enabling fast shock detection and protective intervention independent of the trading loop. Extensive experiments on real-world cryptocurrency markets demonstrate that WebCryptoAgent improves trading stability, reduces spurious activity, and enhances tail-risk handling compared to existing baselines. Code will be available at https://github.com/AIGeeksGroup/WebCryptoAgent.","authors":["Ali Kurban","Wei Luo","Liangyu Zuo","Zeyu Zhang","Renda Han","Zhaolu Kang","Hao Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04682v1","updated":"2026-01-08T07:49:02Z","published":"2026-01-08T07:49:02Z","title":"HATIR: Heat-Aware Diffusion for Turbulent Infrared Video Super-Resolution","summary":"Infrared video has been of great interest in visual tasks under challenging environments, but often suffers from severe atmospheric turbulence and compression degradation. Existing video super-resolution (VSR) methods either neglect the inherent modality gap between infrared and visible images or fail to restore turbulence-induced distortions. Directly cascading turbulence mitigation (TM) algorithms with VSR methods leads to error propagation and accumulation due to the decoupled modeling of degradation between turbulence and resolution. We introduce HATIR, a Heat-Aware Diffusion for Turbulent InfraRed Video Super-Resolution, which injects heat-aware deformation priors into the diffusion sampling path to jointly model the inverse process of turbulent degradation and structural detail loss. Specifically, HATIR constructs a Phasor-Guided Flow Estimator, rooted in the physical principle that thermally active regions exhibit consistent phasor responses over time, enabling reliable turbulence-aware flow to guide the reverse diffusion process. To ensure the fidelity of structural recovery under nonuniform distortions, a Turbulence-Aware Decoder is proposed to selectively suppress unstable temporal cues and enhance edge-aware feature aggregation via turbulence gating and structure-aware attention. We built FLIR-IVSR, the first dataset for turbulent infrared VSR, comprising paired LR-HR sequences from a FLIR T1050sc camera (1024 X 768) spanning 640 diverse scenes with varying camera and object motion conditions. This encourages future research in infrared VSR. Project page: https://github.com/JZ0606/HATIR","authors":["Yang Zou","Xingyue Zhu","Kaiqi Han","Jun Ma","Xingyuan Li","Zhiying Jiang","Jinyuan Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04676v1","updated":"2026-01-08T07:41:37Z","published":"2026-01-08T07:41:37Z","title":"DB-MSMUNet:Dual Branch Multi-scale Mamba UNet for Pancreatic CT Scans Segmentation","summary":"Accurate segmentation of the pancreas and its lesions in CT scans is crucial for the precise diagnosis and treatment of pancreatic cancer. However, it remains a highly challenging task due to several factors such as low tissue contrast with surrounding organs, blurry anatomical boundaries, irregular organ shapes, and the small size of lesions. To tackle these issues, we propose DB-MSMUNet (Dual-Branch Multi-scale Mamba UNet), a novel encoder-decoder architecture designed specifically for robust pancreatic segmentation. The encoder is constructed using a Multi-scale Mamba Module (MSMM), which combines deformable convolutions and multi-scale state space modeling to enhance both global context modeling and local deformation adaptation. The network employs a dual-decoder design: the edge decoder introduces an Edge Enhancement Path (EEP) to explicitly capture boundary cues and refine fuzzy contours, while the area decoder incorporates a Multi-layer Decoder (MLD) to preserve fine-grained details and accurately reconstruct small lesions by leveraging multi-scale deep semantic features. Furthermore, Auxiliary Deep Supervision (ADS) heads are added at multiple scales to both decoders, providing more accurate gradient feedback and further enhancing the discriminative capability of multi-scale features. We conduct extensive experiments on three datasets: the NIH Pancreas dataset, the MSD dataset, and a clinical pancreatic tumor dataset provided by collaborating hospitals. DB-MSMUNet achieves Dice Similarity Coefficients of 89.47%, 87.59%, and 89.02%, respectively, outperforming most existing state-of-the-art methods in terms of segmentation accuracy, edge preservation, and robustness across different datasets. These results demonstrate the effectiveness and generalizability of the proposed method for real-world pancreatic CT segmentation tasks.","authors":["Qiu Guan","Zhiqiang Yang","Dezhang Ye","Yang Chen","Xinli Xu","Ying Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04672v1","updated":"2026-01-08T07:34:37Z","published":"2026-01-08T07:34:37Z","title":"Agri-R1: Empowering Generalizable Agricultural Reasoning in Vision-Language Models with Reinforcement Learning","summary":"Agricultural disease diagnosis challenges VLMs, as conventional fine-tuning requires extensive labels, lacks interpretability, and generalizes poorly. While reasoning improves model robustness, existing methods rely on costly expert annotations and rarely address the open-ended, diverse nature of agricultural queries. To address these limitations, we propose \\textbf{Agri-R1}, a reasoning-enhanced large model for agriculture. Our framework automates high-quality reasoning data generation via vision-language synthesis and LLM-based filtering, using only 19\\% of available samples. Training employs Group Relative Policy Optimization (GRPO) with a novel proposed reward function that integrates domain-specific lexicons and fuzzy matching to assess both correctness and linguistic flexibility in open-ended responses. Evaluated on CDDMBench, our resulting 3B-parameter model achieves performance competitive with 7B- to 13B-parameter baselines, showing a +23.2\\% relative gain in disease recognition accuracy, +33.3\\% in agricultural knowledge QA, and a +26.10-point improvement in cross-domain generalization over standard fine-tuning. Ablation studies confirm that the synergy between structured reasoning data and GRPO-driven exploration underpins these gains, with benefits scaling as question complexity increases.","authors":["Wentao Zhang","Lifei Wang","Lina Lu","MingKun Xu","Shangyang Li","Yanchao Yang","Tao Fang"],"pdf_url":"","comment":"This paper is submitted for review to ACL 2026. It is 17 pages long and includes 5 figures. The corresponding authors are Tao Fang and Lina Lu"},{"id":"http://arxiv.org/abs/2512.17226v2","updated":"2026-01-08T07:00:53Z","published":"2025-12-19T04:24:03Z","title":"Robust Scene Coordinate Regression via Geometrically-Consistent Global Descriptors","summary":"Recent learning-based visual localization methods use global descriptors to disambiguate visually similar places, but existing approaches often derive these descriptors from geometric cues alone (e.g., covisibility graphs), limiting their discriminative power and reducing robustness in the presence of noisy geometric constraints. We propose an aggregator module that learns global descriptors consistent with both geometrical structure and visual similarity, ensuring that images are close in descriptor space only when they are visually similar and spatially connected. This corrects erroneous associations caused by unreliable overlap scores. Using a batch-mining strategy based solely on the overlap scores and a modified contrastive loss, our method trains without manual place labels and generalizes across diverse environments. Experiments on challenging benchmarks show substantial localization gains in large-scale environments while preserving computational and memory efficiency. Code is available at https://github.com/sontung/robust_scr.","authors":["Son Tung Nguyen","Alejandro Fontan","Michael Milford","Tobias Fischer"],"pdf_url":"","comment":"Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026"},{"id":"http://arxiv.org/abs/2512.05665v2","updated":"2026-01-08T06:50:09Z","published":"2025-12-05T12:09:39Z","title":"Interleaved Latent Visual Reasoning with Selective Perceptual Modeling","summary":"Interleaved reasoning paradigms enhance Multimodal Large Language Models (MLLMs) with visual feedback but are hindered by the prohibitive computational cost of re-encoding pixel-dense images. A promising alternative, latent visual reasoning, circumvents this bottleneck yet faces limitations: methods either fail to capture intermediate state evolution due to single-step, non-interleaved structures, or sacrifice precise perceptual modeling by over-compressing features. We introduce Interleaved Latent Visual Reasoning (ILVR), a framework that unifies dynamic state evolution with precise perceptual modeling. ILVR interleaves textual generation with latent visual representations that act as specific, evolving cues for subsequent reasoning. Specifically, we employ a self-supervision strategy where a momentum teacher model selectively distills relevant features from ground-truth intermediate images into sparse supervision targets. This adaptive selection mechanism guides the model to autonomously generate context-aware visual signals. Extensive experiments on multimodal reasoning benchmarks demonstrate that ILVR outperforms existing approaches, effectively bridging the gap between fine-grained perception and sequential multimodal reasoning.","authors":["Shuai Dong","Siyuan Wang","Xingyu Liu","Chenglin Li","Haowen Hou","Zhongyu Wei"],"pdf_url":"","comment":"18 pages, 11 figures. Code available at https://github.com/XD111ds/ILVR"},{"id":"http://arxiv.org/abs/2601.04126v2","updated":"2026-01-08T06:37:47Z","published":"2026-01-07T17:40:08Z","title":"InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training","summary":"GUI agents that interact with graphical interfaces on behalf of users represent a promising direction for practical AI assistants. However, training such agents is hindered by the scarcity of suitable environments. We present InfiniteWeb, a system that automatically generates functional web environments at scale for GUI agent training. While LLMs perform well on generating a single webpage, building a realistic and functional website with many interconnected pages faces challenges. We address these challenges through unified specification, task-centric test-driven development, and a combination of website seed with reference design image to ensure diversity. Our system also generates verifiable task evaluators enabling dense reward signals for reinforcement learning. Experiments show that InfiniteWeb surpasses commercial coding agents at realistic website construction, and GUI agents trained on our generated environments achieve significant performance improvements on OSWorld and Online-Mind2Web, demonstrating the effectiveness of proposed system.","authors":["Ziyun Zhang","Zezhou Wang","Xiaoyi Zhang","Zongyu Guo","Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2601.03667v2","updated":"2026-01-08T06:30:42Z","published":"2026-01-07T07:41:57Z","title":"TRec: Egocentric Action Recognition using 2D Point Tracks","summary":"We present a novel approach for egocentric action recognition that leverages 2D point tracks as an additional motion cue. While most existing methods rely on RGB appearance, human pose estimation, or their combination, our work demonstrates that tracking randomly sampled image points across video frames can substantially improve recognition accuracy. Unlike prior approaches, we do not detect hands, objects, or interaction regions. Instead, we employ CoTracker to follow a set of randomly initialized points through each video and use the resulting trajectories, together with the corresponding image frames, as input to a Transformer-based recognition model. Surprisingly, our method achieves notable gains even when only the initial frame and its associated point tracks are provided, without incorporating the full video sequence. Experimental results confirm that integrating 2D point tracks consistently enhances performance compared to the same model trained without motion information, highlighting their potential as a lightweight yet effective representation for egocentric action understanding.","authors":["Dennis Holzmann","Sven Wachsmuth"],"pdf_url":"","comment":"submitted to ICPR 2026"},{"id":"http://arxiv.org/abs/2601.04118v2","updated":"2026-01-08T06:19:12Z","published":"2026-01-07T17:26:41Z","title":"GeoReason: Aligning Thinking And Answering In Remote Sensing Vision-Language Models Via Logical Consistency Reinforcement Learning","summary":"The evolution of Remote Sensing Vision-Language Models(RS-VLMs) emphasizes the importance of transitioning from perception-centric recognition toward high-level deductive reasoning to enhance cognitive reliability in complex spatial tasks. However, current models often suffer from logical hallucinations, where correct answers are derived from flawed reasoning chains or rely on positional shortcuts rather than spatial logic. This decoupling undermines reliability in strategic spatial decision-making. To address this, we present GeoReason, a framework designed to synchronize internal thinking with final decisions. We first construct GeoReason-Bench, a logic-driven dataset containing 4,000 reasoning trajectories synthesized from geometric primitives and expert knowledge. We then formulate a two-stage training strategy: (1) Supervised Knowledge Initialization to equip the model with reasoning syntax and domain expertise, and (2) Consistency-Aware Reinforcement Learning to refine deductive reliability. This second stage integrates a novel Logical Consistency Reward, which penalizes logical drift via an option permutation strategy to anchor decisions in verifiable reasoning traces. Experimental results demonstrate that our framework significantly enhances the cognitive reliability and interpretability of RS-VLMs, achieving state-of-the-art performance compared to other advanced methods.","authors":["Wenshuai Li","Xiantai Xiang","Zixiao Wen","Guangyao Zhou","Ben Niu","Feng Wang","Lijia Huang","Qiantong Wang","Yuxin Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.09779v2","updated":"2026-01-08T05:44:40Z","published":"2025-08-13T13:00:05Z","title":"MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models","summary":"Large Vision-Language Models (LVLMs) have demonstrated remarkable performance across multi-modal tasks by scaling model size and training data. However, these dense LVLMs incur significant computational costs and motivate the exploration of sparse Mixture of Experts (MoE) architectures. While MoE improve parameter efficiency, effectively applying MoE to simultaneously model modality-specific features and cross-modal associations in LVLMs remains challenging. In this work, we propose to incorporate Mixture of Intra- and Inter-Modality Experts (MoIIE) to LVLMs. For each token, expert routing is guided by its modality, directing tokens to their respective intra-modality experts as well as a shared pool of inter-modality experts, enabling the model to jointly learn rich intra-modal features and cross-modal interactions. We further introduce an effective and straightforward two-stage training strategy, which facilitates the direct activation of both MoE and multi-modal capabilities. Extensive experiments across different data scales and LLM backbone demonstrate the effectiveness, efficiency and generality of our approach. Notably, our MoIIE models with 5.5B and 11.3B activated parameters match or even surpass the performance of existing advanced open-source MoE-LLMs based multi-modal models that involve more activated parameters. The code is available at https://github.com/AlenjandroWang/MoIIE.","authors":["Dianyi Wang","Siyuan Wang","Zejun Li","Yikun Wang","Yitong Li","Duyu Tang","Xiaoyu Shen","Xuanjing Huang","Zhongyu Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04614v1","updated":"2026-01-08T05:41:06Z","published":"2026-01-08T05:41:06Z","title":"HyperAlign: Hyperbolic Entailment Cones for Adaptive Text-to-Image Alignment Assessment","summary":"With the rapid development of text-to-image generation technology, accurately assessing the alignment between generated images and text prompts has become a critical challenge. Existing methods rely on Euclidean space metrics, neglecting the structured nature of semantic alignment, while lacking adaptive capabilities for different samples. To address these limitations, we propose HyperAlign, an adaptive text-to-image alignment assessment framework based on hyperbolic entailment geometry. First, we extract Euclidean features using CLIP and map them to hyperbolic space. Second, we design a dynamic-supervision entailment modeling mechanism that transforms discrete entailment logic into continuous geometric structure supervision. Finally, we propose an adaptive modulation regressor that utilizes hyperbolic geometric features to generate sample-level modulation parameters, adaptively calibrating Euclidean cosine similarity to predict the final score. HyperAlign achieves highly competitive performance on both single database evaluation and cross-database generalization tasks, fully validating the effectiveness of hyperbolic geometric modeling for image-text alignment assessment.","authors":["Wenzhi Chen","Bo Hu","Leida Li","Lihuo He","Wen Lu","Xinbo Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03637v2","updated":"2026-01-08T05:35:39Z","published":"2026-01-07T06:28:16Z","title":"CrackSegFlow: Controllable Flow Matching Synthesis for Generalizable Crack Segmentation with a 50K Image-Mask Benchmark","summary":"Automated crack segmentation is essential for condition assessment, yet deployment is limited by scarce pixel-level labels and domain shift. We present CrackSegFlow, a controllable flow-matching synthesis framework that generates crack images conditioned on binary masks with mask-image alignment. The renderer combines topology-preserving mask injection with edge gating to maintain thin-structure continuity and suppress false positives. A class-conditional flow-matching mask model synthesizes masks with control over crack coverage, enabling balanced, topology-diverse data without manual annotation. We inject masks into crack-free backgrounds to diversify illumination and reduce false positives. On five datasets with a CNN-Transformer backbone, incorporating synthesized pairs improves in-domain performance by 5.37 mIoU and 5.13 F1, and target-guided cross-domain synthesis yields gains of 13.12 mIoU and 14.82 F1 using target mask statistics. We also release CSF-50K, 50,000 image-mask pairs for benchmarking.","authors":["Babak Asadi","Peiyang Wu","Mani Golparvar-Fard","Ramez Hajj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04607v1","updated":"2026-01-08T05:25:05Z","published":"2026-01-08T05:25:05Z","title":"HUR-MACL: High-Uncertainty Region-Guided Multi-Architecture Collaborative Learning for Head and Neck Multi-Organ Segmentation","summary":"Accurate segmentation of organs at risk in the head and neck is essential for radiation therapy, yet deep learning models often fail on small, complexly shaped organs. While hybrid architectures that combine different models show promise, they typically just concatenate features without exploiting the unique strengths of each component. This results in functional overlap and limited segmentation accuracy. To address these issues, we propose a high uncertainty region-guided multi-architecture collaborative learning (HUR-MACL) model for multi-organ segmentation in the head and neck. This model adaptively identifies high uncertainty regions using a convolutional neural network, and for these regions, Vision Mamba as well as Deformable CNN are utilized to jointly improve their segmentation accuracy. Additionally, a heterogeneous feature distillation loss was proposed to promote collaborative learning between the two architectures in high uncertainty regions to further enhance performance. Our method achieves SOTA results on two public datasets and one private dataset.","authors":["Xiaoyu Liu","Siwen Wei","Linhao Qu","Mingyuan Pan","Chengsheng Zhang","Yonghong Shi","Zhijian Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04605v1","updated":"2026-01-08T05:23:58Z","published":"2026-01-08T05:23:58Z","title":"Detection of Deployment Operational Deviations for Safety and Security of AI-Enabled Human-Centric Cyber Physical Systems","summary":"In recent years, Human-centric cyber-physical systems have increasingly involved artificial intelligence to enable knowledge extraction from sensor-collected data. Examples include medical monitoring and control systems, as well as autonomous cars. Such systems are intended to operate according to the protocols and guidelines for regular system operations. However, in many scenarios, such as closed-loop blood glucose control for Type 1 diabetics, self-driving cars, and monitoring systems for stroke diagnosis. The operations of such AI-enabled human-centric applications can expose them to cases for which their operational mode may be uncertain, for instance, resulting from the interactions with a human with the system. Such cases, in which the system is in uncertain conditions, can violate the system's safety and security requirements. \n  This paper will discuss operational deviations that can lead these systems to operate in unknown conditions. We will then create a framework to evaluate different strategies for ensuring the safety and security of AI-enabled human-centric cyber-physical systems in operation deployment. Then, as an example, we show a personalized image-based novel technique for detecting the non-announcement of meals in closed-loop blood glucose control for Type 1 diabetics.","authors":["Bernard Ngabonziza","Ayan Banerjee","Sandeep K. S. Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.11399v2","updated":"2026-01-08T05:10:53Z","published":"2025-12-12T09:19:45Z","title":"Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction","summary":"Vision-Language Models (VLMs) are able to process increasingly longer videos. Yet, important visual information is easily lost throughout the entire context and missed by VLMs. Also, it is important to design tools that enable cost-effective analysis of lengthy video content. In this paper, we propose a clip selection method that targets key video moments to be included in a multimodal summary. We divide the video into short clips and generate compact visual descriptions of each using a lightweight video captioning model. These are then passed to a large language model (LLM), which selects the K clips containing the most relevant visual information for a multimodal summary. We evaluate our approach on reference clips for the task, automatically derived from full human-annotated screenplays and summaries in the MovieSum dataset. We further show that these reference clips (less than 6% of the movie) are sufficient to build a complete multimodal summary of the movies in MovieSum. Using our clip selection method, we achieve a summarization performance close to that of these reference clips while capturing substantially more relevant video information than random clip selection. Importantly, we maintain low computational cost by relying on a lightweight captioning model.","authors":["Galann Pennec","Zhengyuan Liu","Nicholas Asher","Philippe Muller","Nancy F. Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.12766v2","updated":"2026-01-08T04:46:43Z","published":"2025-06-15T08:19:32Z","title":"Probing Deep into Temporal Profile Makes the Infrared Small Target Detector Much Better","summary":"Infrared small target (IRST) detection is challenging in simultaneously achieving precise, robust, and efficient performance due to extremely dim targets and strong interference. Current learning-based methods attempt to leverage ``more\" information from both the spatial and the short-term temporal domains, but suffer from unreliable performance under complex conditions while incurring computational redundancy. In this paper, we explore the ``more essential\" information from a more crucial domain for the detection. Through theoretical analysis, we reveal that the global temporal saliency and correlation information in the temporal profile demonstrate significant superiority in distinguishing target signals from other signals. To investigate whether such superiority is preferentially leveraged by well-trained networks, we built the first prediction attribution tool in this field and verified the importance of the temporal profile information. Inspired by the above conclusions, we remodel the IRST detection task as a one-dimensional signal anomaly detection task, and propose an efficient deep temporal probe network (DeepPro) that only performs calculations in the time dimension for IRST detection. We conducted extensive experiments to fully validate the effectiveness of our method. The experimental results are exciting, as our DeepPro outperforms existing state-of-the-art IRST detection methods on widely-used benchmarks with extremely high efficiency, and achieves a significant improvement on dim targets and in complex scenarios. We provide a new modeling domain, a new insight, a new method, and a new performance, which can promote the development of IRST detection. Codes are available at https://github.com/TinaLRJ/DeepPro.","authors":["Ruojing Li","Wei An","Yingqian Wang","Xinyi Ying","Yimian Dai","Longguang Wang","Miao Li","Yulan Guo","Li Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.04358v2","updated":"2026-01-08T04:38:47Z","published":"2025-12-04T01:08:38Z","title":"MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching","summary":"Existing stereo matching networks typically rely on either cost-volume construction based on 3D convolutions or deformation methods based on iterative optimization. The former incurs significant computational overhead during cost aggregation, whereas the latter often lacks the ability to model non-local contextual information. These methods exhibit poor compatibility on resource-constrained mobile devices, limiting their deployment in real-time applications. To address this, we propose a Multi-frequency Adaptive Fusion Network (MAFNet), which can produce high-quality disparity maps using only efficient 2D convolutions. Specifically, we design an adaptive frequency-domain filtering attention module that decomposes the full cost volume into high-frequency and low-frequency volumes, performing frequency-aware feature aggregation separately. Subsequently, we introduce a Linformer-based low-rank attention mechanism to adaptively fuse high- and low-frequency information, yielding more robust disparity estimation. Extensive experiments demonstrate that the proposed MAFNet significantly outperforms existing real-time methods on public datasets such as Scene Flow and KITTI 2015, showing a favorable balance between accuracy and real-time performance.","authors":["Ao Xu","Rujin Zhao","Xiong Xu","Boceng Huang","Yujia Jia","Hongfeng Long","Fuxuan Chen","Zilong Cao","Fangyuan Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04589v1","updated":"2026-01-08T04:38:07Z","published":"2026-01-08T04:38:07Z","title":"MiLDEdit: Reasoning-Based Multi-Layer Design Document Editing","summary":"Real-world design documents (e.g., posters) are inherently multi-layered, combining decoration, text, and images. Editing them from natural-language instructions requires fine-grained, layer-aware reasoning to identify relevant layers and coordinate modifications. Prior work largely overlooks multi-layer design document editing, focusing instead on single-layer image editing or multi-layer generation, which assume a flat canvas and lack the reasoning needed to determine what and where to modify. To address this gap, we introduce the Multi-Layer Document Editing Agent (MiLDEAgent), a reasoning-based framework that combines an RL-trained multimodal reasoner for layer-wise understanding with an image editor for targeted modifications. To systematically benchmark this setting, we introduce the MiLDEBench, a human-in-the-loop corpus of over 20K design documents paired with diverse editing instructions. The benchmark is complemented by a task-specific evaluation protocol, MiLDEEval, which spans four dimensions including instruction following, layout consistency, aesthetics, and text rendering. Extensive experiments on 14 open-source and 2 closed-source models reveal that existing approaches fail to generalize: open-source models often cannot complete multi-layer document editing tasks, while closed-source models suffer from format violations. In contrast, MiLDEAgent achieves strong layer-aware reasoning and precise editing, significantly outperforming all open-source baselines and attaining performance comparable to closed-source models, thereby establishing the first strong baseline for multi-layer document editing.","authors":["Zihao Lin","Wanrong Zhu","Jiuxiang Gu","Jihyung Kil","Christopher Tensmeyer","Lin Zhang","Shilong Liu","Ruiyi Zhang","Lifu Huang","Vlad I. Morariu","Tong Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04588v1","updated":"2026-01-08T04:35:40Z","published":"2026-01-08T04:35:40Z","title":"3D Conditional Image Synthesis of Left Atrial LGE MRI from Composite Semantic Masks","summary":"Segmentation of the left atrial (LA) wall and endocardium from late gadolinium-enhanced (LGE) MRI is essential for quantifying atrial fibrosis in patients with atrial fibrillation. The development of accurate machine learning-based segmentation models remains challenging due to the limited availability of data and the complexity of anatomical structures. In this work, we investigate 3D conditional generative models as potential solution for augmenting scarce LGE training data and improving LA segmentation performance. We develop a pipeline to synthesize high-fidelity 3D LGE MRI volumes from composite semantic label maps combining anatomical expert annotations with unsupervised tissue clusters, using three 3D conditional generators (Pix2Pix GAN, SPADE-GAN, and SPADE-LDM). The synthetic images are evaluated for realism and their impact on downstream LA segmentation. SPADE-LDM generates the most realistic and structurally accurate images, achieving an FID of 4.063 and surpassing GAN models, which have FIDs of 40.821 and 7.652 for Pix2Pix and SPADE-GAN, respectively. When augmented with synthetic LGE images, the Dice score for LA cavity segmentation with a 3D U-Net model improved from 0.908 to 0.936, showing a statistically significant improvement (p < 0.05) over the baseline.These findings demonstrate the potential of label-conditioned 3D synthesis to enhance the segmentation of under-represented cardiac structures.","authors":["Yusri Al-Sanaani","Rebecca Thornhill","Sreeraman Rajan"],"pdf_url":"","comment":"This work has been published in the Proceedings of the 2025 IEEE International Conference on Imaging Systems and Techniques (IST). The final published version is available via IEEE Xplore"},{"id":"http://arxiv.org/abs/2601.01856v2","updated":"2026-01-08T04:18:30Z","published":"2026-01-05T07:33:50Z","title":"GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection","summary":"Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.\n  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.\n  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR","authors":["Joongwon Chae","Lihui Luo","Yang Liu","Runming Wang","Dongmei Yu","Zeming Liang","Xi Yuan","Dayan Zhang","Zhenglin Chen","Peiwu Qin","Ilmoon Chae"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.05759v4","updated":"2026-01-08T04:15:41Z","published":"2025-10-07T10:25:21Z","title":"OneVision: An End-to-End Generative Framework for Multi-view E-commerce Vision Search","summary":"Traditional vision search, similar to search and recommendation systems, follows the multi-stage cascading architecture (MCA) paradigm to balance efficiency and conversion. Specifically, the query image undergoes feature extraction, recall, pre-ranking, and ranking stages, ultimately presenting the user with semantically similar products that meet their preferences. This multi-view representation discrepancy of the same object in the query and the optimization objective collide across these stages, making it difficult to achieve Pareto optimality in both user experience and conversion. In this paper, an end-to-end generative framework, OneVision, is proposed to address these problems. OneVision builds on VRQ, a vision-aligned residual quantization encoding, which can align the vastly different representations of an object across multiple viewpoints while preserving the distinctive features of each product as much as possible. Then a multi-stage semantic alignment scheme is adopted to maintain strong visual similarity priors while effectively incorporating user-specific information for personalized preference generation. In offline evaluations, OneVision performs on par with online MCA, while improving inference efficiency by 21% through dynamic pruning. In A/B tests, it achieves significant online improvements: +2.15% item CTR, +2.27% CVR, and +3.12% order volume. These results demonstrate that a semantic ID centric, generative architecture can unify retrieval and personalization while simplifying the serving pathway.","authors":["Zexin Zheng","Huangyu Dai","Lingtao Mao","Xinyu Sun","Zihan Liang","Ben Chen","Yuqing Ding","Chenyi Lei","Wenwu Ou","Han Li","Kun Gai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.12994v2","updated":"2026-01-08T04:10:56Z","published":"2024-10-16T19:42:47Z","title":"Explainable Binary Classification of Separable Shape Ensembles","summary":"Scientists, engineers, biologists, and technology specialists universally leverage image segmentation to extract shape ensembles containing many thousands of curves representing patterns in observations and measurements. These large curve ensembles facilitate inferences about important changes when comparing and contrasting images. We introduce novel pattern recognition formalisms combined with inference methods over large ensembles of segmented curves. Our formalism involves accurately approximating eigenspaces of composite integral operators to motivate discrete, dual representations of curves collocated at quadrature nodes. Approximations are projected onto underlying matrix manifolds and the resulting separable shape tensors constitute rigid-invariant decompositions of curves into generalized (linear) scale variations and complementary (nonlinear) undulations. With thousands of curves segmented from pairs of images, we demonstrate how data-driven features of separable shape tensors inform explainable binary classification utilizing a product maximum mean discrepancy; absent labeled data, building interpretable feature spaces in seconds without high performance computation, and detecting discrepancies below cursory visual inspections.","authors":["Zachary Grey","Nicholas Fisher","Andrew Glaws"],"pdf_url":"","comment":"32 pages, 16 figures"},{"id":"http://arxiv.org/abs/2601.02356v2","updated":"2026-01-08T03:56:27Z","published":"2026-01-05T18:55:32Z","title":"Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes","summary":"We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.","authors":["Jing Tan","Zhaoyang Zhang","Yantao Shen","Jiarui Cai","Shuo Yang","Jiajun Wu","Wei Xia","Zhuowen Tu","Stefano Soatto"],"pdf_url":"","comment":"Project page: https://sparkstj.github.io/talk2move"},{"id":"http://arxiv.org/abs/2601.04567v1","updated":"2026-01-08T03:49:49Z","published":"2026-01-08T03:49:49Z","title":"All Changes May Have Invariant Principles: Improving Ever-Shifting Harmful Meme Detection via Design Concept Reproduction","summary":"Harmful memes are ever-shifting in the Internet communities, which are difficult to analyze due to their type-shifting and temporal-evolving nature. Although these memes are shifting, we find that different memes may share invariant principles, i.e., the underlying design concept of malicious users, which can help us analyze why these memes are harmful. In this paper, we propose RepMD, an ever-shifting harmful meme detection method based on the design concept reproduction. We first refer to the attack tree to define the Design Concept Graph (DCG), which describes steps that people may take to design a harmful meme. Then, we derive the DCG from historical memes with design step reproduction and graph pruning. Finally, we use DCG to guide the Multimodal Large Language Model (MLLM) to detect harmful memes. The evaluation results show that RepMD achieves the highest accuracy with 81.1% and has slight accuracy decreases when generalized to type-shifting and temporal-evolving memes. Human evaluation shows that RepMD can improve the efficiency of human discovery on harmful memes, with 15$\\sim$30 seconds per meme.","authors":["Ziyou Jiang","Mingyang Li","Junjie Wang","Yuekai Huang","Jie Huang","Zhiyuan Chang","Zhaoyang Li","Qing Wang"],"pdf_url":"","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2506.06099v2","updated":"2026-01-08T03:48:52Z","published":"2025-06-06T13:59:08Z","title":"DermaCon-IN: A Multi-concept Annotated Dermatological Image Dataset of Indian Skin Disorders for Clinical AI Research","summary":"Artificial intelligence is poised to augment dermatological care by enabling scalable image-based diagnostics. Yet, the development of robust and equitable models remains hindered by datasets that fail to capture the clinical and demographic complexity of real-world practice. This complexity stems from region-specific disease distributions, wide variation in skin tones, and the underrepresentation of outpatient scenarios from non-Western populations. We introduce DermaCon-IN, a prospectively curated dermatology dataset comprising 5,450 clinical images from 3,002 patients across outpatient clinics in South India. Each image is annotated by board-certified dermatologists with 245 distinct diagnoses, structured under a hierarchical, aetiology-based taxonomy adapted from Rook's classification. The dataset captures a wide spectrum of dermatologic conditions and tonal variation commonly seen in Indian outpatient care. We benchmark a range of architectures, including convolutional models (ResNet, DenseNet, EfficientNet), transformer-based models (ViT, MaxViT, Swin), and Concept Bottleneck Models to establish baseline performance and explore how anatomical and concept-level cues may be integrated. These results are intended to guide future efforts toward interpretable and clinically realistic models. DermaCon-IN provides a scalable and representative foundation for advancing dermatology AI.","authors":["Shanawaj S Madarkar","Mahajabeen Madarkar","Madhumitha Venkatesh","Deepanshu Bansal","Teli Prakash","Konda Reddy Mopuri","Vinaykumar MV","KVL Sathwika","Adarsh Kasturi","Gandla Dilip Raj","PVN Supranitha","Harsh Udai"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 (D&B Track)"},{"id":"http://arxiv.org/abs/2507.09792v3","updated":"2026-01-08T03:47:27Z","published":"2025-07-13T21:11:53Z","title":"CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design","summary":"Computer-aided design (CAD) is the digital construction of 2D and 3D objects, and is central to a wide range of engineering and manufacturing applications like automobile and aviation. Despite its importance, CAD modeling remains largely a time-intensive, manual task. Recent works have attempted to automate this process with small transformer-based models and handcrafted CAD sequence representations. However, there has been little effort to leverage the potential of large language models (LLMs) for sequential CAD design. In this work, we introduce a new large-scale dataset of more than 170k CAD models annotated with high-quality, human-like descriptions generated with our pipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs to generate CAD sequences represented in a JSON-based format from natural language descriptions, demonstrating the viability and effectiveness of this approach for text-conditioned CAD generation. Because simple metrics often fail to reflect the quality of generated objects, we introduce geometric and topological metrics based on sphericity, mean curvature, and Euler characteristic to provide richer structural insights. Our experiments and ablation studies on both synthetic and human-annotated data demonstrate that CADmium is able to automate CAD design, drastically speeding up the design of new objects. The dataset, code, and fine-tuned models are available online.","authors":["Prashant Govindarajan","Davide Baldelli","Jay Pathak","Quentin Fournier","Sarath Chandar"],"pdf_url":"","comment":"Published in Transactions on Machine Learning Research (TMLR) 01/2026"},{"id":"http://arxiv.org/abs/2601.04563v1","updated":"2026-01-08T03:46:20Z","published":"2026-01-08T03:46:20Z","title":"A Vision for Multisensory Intelligence: Sensing, Synergy, and Science","summary":"Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological and tactile cues on the body, to physical and social signals in homes, cities, and the environment. We outline how this field must advance through three interrelated themes of sensing, science, and synergy. Firstly, research in sensing should extend how AI captures the world in richer ways beyond the digital medium. Secondly, developing a principled science for quantifying multimodal heterogeneity and interactions, developing unified modeling architectures and representations, and understanding cross-modal transfer. Finally, we present new technical challenges to learn synergy between modalities and between humans and AI, covering multisensory integration, alignment, reasoning, generation, generalization, and experience. Accompanying this vision paper are a series of projects, resources, and demos of latest advances from the Multisensory Intelligence group at the MIT Media Lab, see https://mit-mi.github.io/.","authors":["Paul Pu Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24385v2","updated":"2026-01-08T02:52:40Z","published":"2025-12-30T17:58:01Z","title":"Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems","summary":"The rapid advancement of autonomous systems, including self-driving vehicles and drones, has intensified the need to forge true Spatial Intelligence from multi-modal onboard sensor data. While foundation models excel in single-modal contexts, integrating their capabilities across diverse sensors like cameras and LiDAR to create a unified understanding remains a formidable challenge. This paper presents a comprehensive framework for multi-modal pre-training, identifying the core set of techniques driving progress toward this goal. We dissect the interplay between foundational sensor characteristics and learning strategies, evaluating the role of platform-specific datasets in enabling these advancements. Our central contribution is the formulation of a unified taxonomy for pre-training paradigms: ranging from single-modality baselines to sophisticated unified frameworks that learn holistic representations for advanced tasks like 3D object detection and semantic occupancy prediction. Furthermore, we investigate the integration of textual inputs and occupancy representations to facilitate open-world perception and planning. Finally, we identify critical bottlenecks, such as computational efficiency and model scalability, and propose a roadmap toward general-purpose multi-modal foundation models capable of achieving robust Spatial Intelligence for real-world deployment.","authors":["Song Wang","Lingdong Kong","Xiaolu Liu","Hao Shi","Wentong Li","Jianke Zhu","Steven C. H. Hoi"],"pdf_url":"","comment":"Survey; 40 pages, 7 figures, 9 tables; GitHub Repo at https://github.com/worldbench/awesome-spatial-intelligence"},{"id":"http://arxiv.org/abs/2601.04068v2","updated":"2026-01-08T02:51:26Z","published":"2026-01-07T16:32:17Z","title":"Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models","summary":"Aligning text-to-video diffusion models with human preferences is crucial for generating high-quality videos. Existing Direct Preference Otimization (DPO) methods rely on multi-sample ranking and task-specific critic models, which is inefficient and often yields ambiguous global supervision. To address these limitations, we propose LocalDPO, a novel post-training framework that constructs localized preference pairs from real videos and optimizes alignment at the spatio-temporal region level. We design an automated pipeline to efficiently collect preference pair data that generates preference pairs with a single inference per prompt, eliminating the need for external critic models or manual annotation. Specifically, we treat high-quality real videos as positive samples and generate corresponding negatives by locally corrupting them with random spatio-temporal masks and restoring only the masked regions using the frozen base model. During training, we introduce a region-aware DPO loss that restricts preference learning to corrupted areas for rapid convergence. Experiments on Wan2.1 and CogVideoX demonstrate that LocalDPO consistently improves video fidelity, temporal coherence and human preference scores over other post-training approaches, establishing a more efficient and fine-grained paradigm for video generator alignment.","authors":["Zitong Huang","Kaidong Zhang","Yukang Ding","Chao Gao","Rui Ding","Ying Chen","Wangmeng Zuo"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2510.22582v3","updated":"2026-01-08T02:40:07Z","published":"2025-10-26T08:47:20Z","title":"MobileGeo: Exploring Hierarchical Knowledge Distillation for Resource-Efficient Cross-view Drone Geo-Localization","summary":"Cross-view geo-localization (CVGL) plays a vital role in drone-based multimedia applications, enabling precise localization by matching drone-captured aerial images against geo-tagged satellite databases in GNSS-denied environments. However, existing methods rely on resource-intensive feature alignment and multi-branch architectures, incurring high inference costs that limit their deployment on edge devices. We propose MobileGeo, a mobile-friendly framework designed for efficient on-device CVGL: 1) During training, a Hierarchical Distillation (HD-CVGL) paradigm, coupled with Uncertainty-Aware Prediction Alignment (UAPA), distills essential information into a compact model without incurring inference overhead. 2) During inference, an efficient Multi-view Selection Refinement Module (MSRM) leverages mutual information to filter redundant views and reduce computational load. Extensive experiments demonstrate that MobileGeo outperforms previous state-of-the-art methods, achieving a 4.19% improvement in AP on University1652 dataset while being over 5 times efficient in FLOPs and 3 times faster. Crucially, MobileGeo runs at 251.5 FPS on an NVIDIA AGX Orin edge device, demonstrating its practical viability for real-time on-device drone geo-localization. The code is available at https://github.com/SkyEyeLoc/MobileGeo.","authors":["Jian Sun","Kangdao Liu","Chi Zhang","Chuangquan Chen","Junge Shen","C. L. Philip Chen","Chi-Man Vong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04520v1","updated":"2026-01-08T02:34:29Z","published":"2026-01-08T02:34:29Z","title":"FaceRefiner: High-Fidelity Facial Texture Refinement with Differentiable Rendering-based Style Transfer","summary":"Recent facial texture generation methods prefer to use deep networks to synthesize image content and then fill in the UV map, thus generating a compelling full texture from a single image. Nevertheless, the synthesized texture UV map usually comes from a space constructed by the training data or the 2D face generator, which limits the methods' generalization ability for in-the-wild input images. Consequently, their facial details, structures and identity may not be consistent with the input. In this paper, we address this issue by proposing a style transfer-based facial texture refinement method named FaceRefiner. FaceRefiner treats the 3D sampled texture as style and the output of a texture generation method as content. The photo-realistic style is then expected to be transferred from the style image to the content image. Different from current style transfer methods that only transfer high and middle level information to the result, our style transfer method integrates differentiable rendering to also transfer low level (or pixel level) information in the visible face regions. The main benefit of such multi-level information transfer is that, the details, structures and semantics in the input can thus be well preserved. The extensive experiments on Multi-PIE, CelebA and FFHQ datasets demonstrate that our refinement method can improve the texture quality and the face identity preserving ability, compared with state-of-the-arts.","authors":["Chengyang Li","Baoping Cheng","Yao Cheng","Haocheng Zhang","Renshuai Liu","Yinglin Zheng","Jing Liao","Xuan Cheng"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2601.04519v1","updated":"2026-01-08T02:32:48Z","published":"2026-01-08T02:32:48Z","title":"TokenSeg: Efficient 3D Medical Image Segmentation via Hierarchical Visual Token Compression","summary":"Three-dimensional medical image segmentation is a fundamental yet computationally demanding task due to the cubic growth of voxel processing and the redundant computation on homogeneous regions. To address these limitations, we propose \\textbf{TokenSeg}, a boundary-aware sparse token representation framework for efficient 3D medical volume segmentation. Specifically, (1) we design a \\emph{multi-scale hierarchical encoder} that extracts 400 candidate tokens across four resolution levels to capture both global anatomical context and fine boundary details; (2) we introduce a \\emph{boundary-aware tokenizer} that combines VQ-VAE quantization with importance scoring to select 100 salient tokens, over 60\\% of which lie near tumor boundaries; and (3) we develop a \\emph{sparse-to-dense decoder} that reconstructs full-resolution masks through token reprojection, progressive upsampling, and skip connections. Extensive experiments on a 3D breast DCE-MRI dataset comprising 960 cases demonstrate that TokenSeg achieves state-of-the-art performance with 94.49\\% Dice and 89.61\\% IoU, while reducing GPU memory and inference latency by 64\\% and 68\\%, respectively. To verify the generalization capability, our evaluations on MSD cardiac and brain MRI benchmark datasets demonstrate that TokenSeg consistently delivers optimal performance across heterogeneous anatomical structures. These results highlight the effectiveness of anatomically informed sparse representation for accurate and efficient 3D medical image segmentation.","authors":["Sen Zeng","Hong Zhou","Zheng Zhu","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04510v1","updated":"2026-01-08T02:25:14Z","published":"2026-01-08T02:25:14Z","title":"Towards Spatio-Temporal Extrapolation of Phase-Field Simulations with Convolution-Only Neural Networks","summary":"Phase-field simulations of liquid metal dealloying (LMD) can capture complex microstructural evolutions but can be prohibitively expensive for large domains and long time horizons. In this paper, we introduce a fully convolutional, conditionally parameterized U-Net surrogate designed to extrapolate far beyond its training data in both space and time. The architecture integrates convolutional self-attention, physically informed padding, and a flood-fill corrector method to maintain accuracy under extreme extrapolation, while conditioning on simulation parameters allows for flexible time-step skipping and adaptation to varying alloy compositions. To remove the need for costly solver-based initialization, we couple the surrogate with a conditional diffusion model that generates synthetic, physically consistent initial conditions. We train our surrogate on simulations generated over small domain sizes and short time spans, but, by taking advantage of the convolutional nature of U-Nets, we are able to run and extrapolate surrogate simulations for longer time horizons than what would be achievable with classic numerical solvers. Across multiple alloy compositions, the framework is able to reproduce the LMD physics accurately. It predicts key quantities of interest and spatial statistics with relative errors typically below 5% in the training regime and under 15% during large-scale, long time-horizon extrapolations. Our framework can also deliver speed-ups of up to 36,000 times, bringing the time to run weeks-long simulations down to a few seconds. This work is a first stepping stone towards high-fidelity extrapolation in both space and time of phase-field simulation for LMD.","authors":["Christophe Bonneville","Nathan Bieberdorf","Pieterjan Robbe","Mark Asta","Habib Najm","Laurent Capolungo","Cosmin Safta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03718v2","updated":"2026-01-08T02:11:05Z","published":"2026-01-07T09:13:20Z","title":"Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation","summary":"Active Alignment (AA) is a key technology for the large-scale automated assembly of high-precision optical systems. Compared with labor-intensive per-model on-device calibration, a digital-twin pipeline built on optical simulation offers a substantial advantage in generating large-scale labeled data. However, complex imaging conditions induce a domain gap between simulation and real-world images, limiting the generalization of simulation-trained models. To address this, we propose augmenting a simulation baseline with minimal unlabeled real-world images captured at random misalignment positions, mitigating the gap from a domain adaptation perspective. We introduce Domain Adaptive Active Alignment (DA3), which utilizes an autoregressive domain transformation generator and an adversarial-based feature alignment strategy to distill real-world domain information via self-supervised learning. This enables the extraction of domain-invariant image degradation features to facilitate robust misalignment prediction. Experiments on two lens types reveal that DA3 improves accuracy by 46% over a purely simulation pipeline. Notably, it approaches the performance achieved with precisely labeled real-world data collected on 3 lens samples, while reducing on-device data collection time by 98.7%. The results demonstrate that domain adaptation effectively endows simulation-trained models with robust real-world performance, validating the digital-twin pipeline as a practical solution to significantly enhance the efficiency of large-scale optical assembly.","authors":["Wenyong Li","Qi Jiang","Weijian Hu","Kailun Yang","Zhanjun Zhang","Wenjun Tian","Kaiwei Wang","Jian Bai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04498v1","updated":"2026-01-08T02:06:53Z","published":"2026-01-08T02:06:53Z","title":"IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation","summary":"Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.","authors":["Yinghao Tang","Xueding Liu","Boyuan Zhang","Tingfeng Lan","Yupeng Xie","Jiale Lao","Yiyao Wang","Haoxuan Li","Tingting Gao","Bo Pan","Luoxuan Weng","Xiuqi Huang","Minfeng Zhu","Yingchaojie Feng","Yuyu Luo","Wei Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04497v1","updated":"2026-01-08T02:02:36Z","published":"2026-01-08T02:02:36Z","title":"Vision-Language Agents for Interactive Forest Change Analysis","summary":"Modern forest monitoring workflows increasingly benefit from the growing availability of high-resolution satellite imagery and advances in deep learning. Two persistent challenges in this context are accurate pixel-level change detection and meaningful semantic change captioning for complex forest dynamics. While large language models (LLMs) are being adapted for interactive data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored. To address this gap, we introduce an LLM-driven agent for integrated forest change analysis that supports natural language querying across multiple RSICI tasks. The proposed system builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration. To facilitate adaptation and evaluation in forest environments, we further introduce the Forest-Change dataset, which comprises bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated using a combination of human annotation and rule-based methods. Experimental results show that the proposed system achieves mIoU and BLEU-4 scores of 67.10% and 40.17% on the Forest-Change dataset, and 88.13% and 34.41% on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI benchmark for joint change detection and captioning. These results highlight the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and efficiency of forest change analysis. All data and code are publicly available at https://github.com/JamesBrockUoB/ForestChat.","authors":["James Brock","Ce Zhang","Nantheera Anantrasirichai"],"pdf_url":"","comment":"5 pages, 4 figures, Submitted to IGARSS 2026"},{"id":"http://arxiv.org/abs/2512.21015v2","updated":"2026-01-08T01:57:34Z","published":"2025-12-24T07:21:59Z","title":"FluencyVE: Marrying Temporal-Aware Mamba with Bypass Attention for Video Editing","summary":"Large-scale text-to-image diffusion models have achieved unprecedented success in image generation and editing. However, extending this success to video editing remains challenging. Recent video editing efforts have adapted pretrained text-to-image models by adding temporal attention mechanisms to handle video tasks. Unfortunately, these methods continue to suffer from temporal inconsistency issues and high computational overheads. In this study, we propose FluencyVE, which is a simple yet effective one-shot video editing approach. FluencyVE integrates the linear time-series module, Mamba, into a video editing model based on pretrained Stable Diffusion models, replacing the temporal attention layer. This enables global frame-level attention while reducing the computational costs. In addition, we employ low-rank approximation matrices to replace the query and key weight matrices in the causal attention, and use a weighted averaging technique during training to update the attention scores. This approach significantly preserves the generative power of the text-to-image model while effectively reducing the computational burden. Experiments and analyses demonstrate promising results in editing various attributes, subjects, and locations in real-world videos.","authors":["Mingshu Cai","Yixuan Li","Osamu Yoshie","Yuya Ieiri"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Multimedia (TMM)"},{"id":"http://arxiv.org/abs/2505.09109v2","updated":"2026-01-08T01:52:57Z","published":"2025-05-14T03:34:30Z","title":"FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis","summary":"Due to the deformability of garments, generating a large amount of high-quality data for robotic garment manipulation tasks is highly challenging. In this paper, we present a synthetic garment dataset that can be used for robotic garment folding. We begin by constructing geometric garment templates based on keypoints and applying generative models to generate realistic texture patterns. Leveraging these keypoint annotations, we generate folding demonstrations in simulation and train folding policies via closed-loop imitation learning. To improve robustness, we propose KG-DAgger, which uses a keypoint-based strategy to generate demonstration data for recovering from failures. KG-DAgger significantly improves the model performance, boosting the real-world success rate by 25\\%. After training with 15K trajectories (about 2M image-action pairs), the model achieves a 75\\% success rate in the real world. Experiments in both simulation and real-world settings validate the effectiveness of our proposed framework.","authors":["Yuxing Chen","Bowen Xiao","He Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.06282v2","updated":"2026-01-08T01:19:36Z","published":"2025-03-08T17:05:21Z","title":"From Dataset to Real-world: General 3D Object Detection via Generalized Cross-domain Few-shot Learning","summary":"LiDAR-based 3D object detection models often struggle to generalize to real-world environments due to limited object diversity in existing datasets. To tackle it, we introduce the first generalized cross-domain few-shot (GCFS) task in 3D object detection, aiming to adapt a source-pretrained model to both common and novel classes in a new domain with only few-shot annotations. We propose a unified framework that learns stable target semantics under limited supervision by bridging 2D open-set semantics with 3D spatial reasoning. Specifically, an image-guided multi-modal fusion injects transferable 2D semantic cues into the 3D pipeline via vision-language models, while a physically-aware box search enhances 2D-to-3D alignment via LiDAR priors. To capture class-specific semantics from sparse data, we further introduce contrastive-enhanced prototype learning, which encodes few-shot instances into discriminative semantic anchors and stabilizes representation learning. Extensive experiments on GCFS benchmarks demonstrate the effectiveness and generality of our approach in realistic deployment settings.","authors":["Shuangzhi Li","Junlong Shen","Lei Ma","Xingyu Li"],"pdf_url":"","comment":"The latest version refines the few-shot setting on common classes, enforcing a stricter object-level definition"},{"id":"http://arxiv.org/abs/2503.11677v3","updated":"2026-01-08T00:29:55Z","published":"2025-03-01T17:54:31Z","title":"Simulation of prosthetic vision with PRIMA system and enhancement of face representation","summary":"Objective. Patients implanted with the PRIMA photovoltaic subretinal prosthesis in geographic atrophy report form vision with the average acuity matching the 100um pixel size. Although this remarkable outcome enables them to read and write, they report difficulty with perceiving faces. Despite the pixelated stimulation, patients see smooth patterns rather than dots. We present a novel, non-pixelated algorithm for simulating prosthetic vision, compare its predictions to clinical outcomes, and describe computer vision and machine learning (ML) methods to improve face representation. Approach. Our simulation algorithm (ProViSim) integrates a spatial resolution filter based on sampling density limited by the pixel pitch and a contrast filter representing reduced contrast sensitivity of prosthetic vision. Patterns of Landolt C and human faces created using this simulator are compared to reports from actual PRIMA users. To recover the facial features lost in prosthetic vision due to limited resolution or contrast, we apply an ML facial landmarking model, as well as contrast-adjusting tone curves to the image prior to its projection onto the photovoltaic retinal implant. Main results. Prosthetic vision simulated using the above algorithm matches the letter acuity observed in clinical studies, as well as the patients' descriptions of perceived facial features. Applying the inversed contrast filter to images prior to projection onto the implant and accentuating the facial features using an ML facial landmarking model helps preserve the contrast in prosthetic vision, improves emotion recognition and reduces the response time. Significance. Spatial and contrast constraints of prosthetic vision limit the resolvable features and degrade natural images. ML based methods and contrast adjustments prior to image projection onto the implant mitigate some limitations and improve face representation.","authors":["Anna Kochnev Goldstein","Jungyeon Park","Yueming Zhuo","Nathan Jensen","Daniel Palanker"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.08759v2","updated":"2026-01-08T00:18:07Z","published":"2025-03-11T16:06:16Z","title":"QUIET-SR: Quantum Image Enhancement Transformer for Single Image Super-Resolution","summary":"Recent advancements in Single-Image Super-Resolution (SISR) using deep learning have significantly improved image restoration quality. However, the high computational cost of processing high-resolution images due to the large number of parameters in classical models, along with the scalability challenges of quantum algorithms for image processing, remains a major obstacle. In this paper, we propose the Quantum Image Enhancement Transformer for Super-Resolution (QUIET-SR), a hybrid framework that extends the Swin transformer architecture with a novel shifted quantum window attention mechanism, built upon variational quantum neural networks. QUIET-SR effectively captures complex residual mappings between low-resolution and high-resolution images, leveraging quantum attention mechanisms to enhance feature extraction and image restoration while requiring a minimal number of qubits, making it suitable for the Noisy Intermediate-Scale Quantum (NISQ) era. We evaluate our framework in MNIST (30.24 PSNR, 0.989 SSIM), FashionMNIST (29.76 PSNR, 0.976 SSIM) and the MedMNIST dataset collection, demonstrating that QUIET-SR achieves PSNR and SSIM scores comparable to state-of-the-art methods while using fewer parameters. Our efficient batching strategy directly enables massive parallelization on multiple QPU's paving the way for practical quantum-enhanced image super-resolution through coordinated QPU-GPU quantum supercomputing.","authors":["Siddhant Dutta","Nouhaila Innan","Khadijeh Najafi","Sadok Ben Yahia","Muhammad Shafique"],"pdf_url":"","comment":"13 Pages, 7 Figures (5 Main figures, 2 Sub-figures), 2 Tables, Under Review"}],"Image and Video Processing":[{"id":"http://arxiv.org/abs/2506.10230v3","updated":"2026-01-08T18:59:27Z","published":"2025-06-11T23:12:48Z","title":"Leveraging Clinical Text and Class Conditioning for 3D Prostate MRI Generation","summary":"Objective: Latent diffusion models (LDM) could alleviate data scarcity challenges affecting machine learning development for medical imaging. However, medical LDM strategies typically rely on short-prompt text encoders, nonmedical LDMs, or large data volumes. These strategies can limit performance and scientific accessibility. We propose a novel LDM conditioning approach to address these limitations. Methods: We propose Class-Conditioned Efficient Large Language model Adapter (CCELLA), a novel dual-head conditioning approach that simultaneously conditions the LDM U-Net with free-text clinical reports and radiology classification. We also propose a data-efficient LDM pipeline centered around CCELLA and a proposed joint loss function. We first evaluate our method on 3D prostate MRI against state-of-the-art. We then augment a downstream classifier model training dataset with synthetic images from our method. Results: Our method achieves a 3D FID score of 0.025 on a size-limited 3D prostate MRI dataset, significantly outperforming a recent foundation model with FID 0.070. When training a classifier for prostate cancer prediction, adding synthetic images generated by our method during training improves classifier accuracy from 69% to 74% and outperforms classifiers trained on images generated by prior state-of-the-art. Classifier training solely on our method's synthetic images achieved comparable performance to real image training. Conclusion: We show that our method improved both synthetic image quality and downstream classifier performance using limited data and minimal human annotation. Significance: The proposed CCELLA-centric pipeline enables radiology report and class-conditioned LDM training for high-quality medical image synthesis given limited data volume and human data annotation, improving LDM performance and scientific accessibility.","authors":["Emerson P. Grabke","Babak Taati","Masoom A. Haider"],"pdf_url":"","comment":"Accepted for publication in IEEE Transactions on Biomedical Engineering, 2025. This is the accepted author version. The final published version is available at https://doi.org/10.1109/TBME.2025.3648426"},{"id":"http://arxiv.org/abs/2601.05181v1","updated":"2026-01-08T18:04:09Z","published":"2026-01-08T18:04:09Z","title":"Spacecube: A fast inverse hyperspectral georectification system","summary":"Hyperspectral cameras provide numerous advantages in terms of the utility of the data captured. They capture hundreds of data points per sample (pixel) instead of only the few of RGB or multispectral camera systems. Aerial systems sense such data remotely, but the data must be georectified to produce consistent images before analysis. We find the traditional direct georectification method to be slow, and it is prone to artifacts. To address its downsides, we propose Spacecube, a program that implements a complete hyperspectral georectification pipeline, including our own fast inverse georectification technique, using OpenGL graphics programming technologies. Spacecube operates substantially faster than real-time and eliminates pixel coverage artifacts. It facilitates high quality interactive viewing, data exploration, and export of final products. We release Spacecube's source code publicly for the community to use.","authors":["Thomas P. Watson","Eddie L. Jacobs"],"pdf_url":"","comment":"9 pages, 16 figures. source code available after peer-reviewed publication"},{"id":"http://arxiv.org/abs/2601.05020v1","updated":"2026-01-08T15:28:39Z","published":"2026-01-08T15:28:39Z","title":"Scalable neural pushbroom architectures for real-time denoising of hyperspectral images onboard satellites","summary":"The next generation of Earth observation satellites will seek to deploy intelligent models directly onboard the payload in order to minimize the latency incurred by the transmission and processing chain of the ground segment, for time-critical applications. Designing neural architectures for onboard execution, particularly for satellite-based hyperspectral imagers, poses novel challenges due to the unique constraints of this environment and imaging system that are largely unexplored by the traditional computer vision literature. In this paper, we show that this setting requires addressing three competing objectives, namely high-quality inference with low complexity, dynamic power scalability and fault tolerance. We focus on the problem of hyperspectral image denoising, which is a critical task to enable effective downstream inference, and highlights the constraints of the onboard processing scenario. We propose a neural network design that addresses the three aforementioned objectives with several novel contributions. In particular, we propose a mixture of denoisers that can be resilient to radiation-induced faults as well as allowing for time-varying power scaling. Moreover, each denoiser employs an innovative architecture where an image is processed line-by-line in a causal way, with a memory of past lines, in order to match the acquisition process of pushbroom hyperspectral sensors and greatly limit memory requirements. We show that the proposed architecture can run in real-time, i.e., process one line in the time it takes to acquire the next one, on low-power hardware and provide competitive denoising quality with respect to significantly more complex state-of-the-art models. We also show that the power scalability and fault tolerance objectives provide a design space with multiple tradeoffs between those properties and denoising quality.","authors":["Ziyao Yi","Davide Piccinini","Diego Valsesia","Tiziano Bianchi","Enrico Magli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04775v1","updated":"2026-01-08T09:57:39Z","published":"2026-01-08T09:57:39Z","title":"Towards a Unified Theoretical Framework for Self-Supervised MRI Reconstruction","summary":"The demand for high-resolution, non-invasive imaging continues to drive innovation in magnetic resonance imaging (MRI), yet prolonged acquisition times hinder accessibility and real-time applications. While deep learning-based reconstruction methods have accelerated MRI, their predominant supervised paradigm depends on fully-sampled reference data that are challenging to acquire. Recently, self-supervised learning (SSL) approaches have emerged as promising alternatives, but most are empirically designed and fragmented. Therefore, we introduce UNITS (Unified Theory for Self-supervision), a general framework for self-supervised MRI reconstruction. UNITS unifies prior SSL strategies within a common formalism, enabling consistent interpretation and systematic benchmarking. We prove that SSL can achieve the same expected performance as supervised learning. Under this theoretical guarantee, we introduce sampling stochasticity and flexible data utilization, which improve network generalization under out-of-domain distributions and stabilize training. Together, these contributions establish UNITS as a theoretical foundation and a practical paradigm for interpretable, generalizable, and clinically applicable self-supervised MRI reconstruction.","authors":["Siying Xu","Kerstin Hammernik","Daniel Rueckert","Sergios Gatidis","Thomas Küstner"],"pdf_url":"","comment":"Under review at IEEE Transactions on Computational Imaging. Supplementary material is included"},{"id":"http://arxiv.org/abs/2506.06099v2","updated":"2026-01-08T03:48:52Z","published":"2025-06-06T13:59:08Z","title":"DermaCon-IN: A Multi-concept Annotated Dermatological Image Dataset of Indian Skin Disorders for Clinical AI Research","summary":"Artificial intelligence is poised to augment dermatological care by enabling scalable image-based diagnostics. Yet, the development of robust and equitable models remains hindered by datasets that fail to capture the clinical and demographic complexity of real-world practice. This complexity stems from region-specific disease distributions, wide variation in skin tones, and the underrepresentation of outpatient scenarios from non-Western populations. We introduce DermaCon-IN, a prospectively curated dermatology dataset comprising 5,450 clinical images from 3,002 patients across outpatient clinics in South India. Each image is annotated by board-certified dermatologists with 245 distinct diagnoses, structured under a hierarchical, aetiology-based taxonomy adapted from Rook's classification. The dataset captures a wide spectrum of dermatologic conditions and tonal variation commonly seen in Indian outpatient care. We benchmark a range of architectures, including convolutional models (ResNet, DenseNet, EfficientNet), transformer-based models (ViT, MaxViT, Swin), and Concept Bottleneck Models to establish baseline performance and explore how anatomical and concept-level cues may be integrated. These results are intended to guide future efforts toward interpretable and clinically realistic models. DermaCon-IN provides a scalable and representative foundation for advancing dermatology AI.","authors":["Shanawaj S Madarkar","Mahajabeen Madarkar","Madhumitha Venkatesh","Deepanshu Bansal","Teli Prakash","Konda Reddy Mopuri","Vinaykumar MV","KVL Sathwika","Adarsh Kasturi","Gandla Dilip Raj","PVN Supranitha","Harsh Udai"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 (D&B Track)"},{"id":"http://arxiv.org/abs/2601.03718v2","updated":"2026-01-08T02:11:05Z","published":"2026-01-07T09:13:20Z","title":"Towards Real-world Lens Active Alignment with Unlabeled Data via Domain Adaptation","summary":"Active Alignment (AA) is a key technology for the large-scale automated assembly of high-precision optical systems. Compared with labor-intensive per-model on-device calibration, a digital-twin pipeline built on optical simulation offers a substantial advantage in generating large-scale labeled data. However, complex imaging conditions induce a domain gap between simulation and real-world images, limiting the generalization of simulation-trained models. To address this, we propose augmenting a simulation baseline with minimal unlabeled real-world images captured at random misalignment positions, mitigating the gap from a domain adaptation perspective. We introduce Domain Adaptive Active Alignment (DA3), which utilizes an autoregressive domain transformation generator and an adversarial-based feature alignment strategy to distill real-world domain information via self-supervised learning. This enables the extraction of domain-invariant image degradation features to facilitate robust misalignment prediction. Experiments on two lens types reveal that DA3 improves accuracy by 46% over a purely simulation pipeline. Notably, it approaches the performance achieved with precisely labeled real-world data collected on 3 lens samples, while reducing on-device data collection time by 98.7%. The results demonstrate that domain adaptation effectively endows simulation-trained models with robust real-world performance, validating the digital-twin pipeline as a practical solution to significantly enhance the efficiency of large-scale optical assembly.","authors":["Wenyong Li","Qi Jiang","Weijian Hu","Kailun Yang","Zhanjun Zhang","Wenjun Tian","Kaiwei Wang","Jian Bai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.08759v2","updated":"2026-01-08T00:18:07Z","published":"2025-03-11T16:06:16Z","title":"QUIET-SR: Quantum Image Enhancement Transformer for Single Image Super-Resolution","summary":"Recent advancements in Single-Image Super-Resolution (SISR) using deep learning have significantly improved image restoration quality. However, the high computational cost of processing high-resolution images due to the large number of parameters in classical models, along with the scalability challenges of quantum algorithms for image processing, remains a major obstacle. In this paper, we propose the Quantum Image Enhancement Transformer for Super-Resolution (QUIET-SR), a hybrid framework that extends the Swin transformer architecture with a novel shifted quantum window attention mechanism, built upon variational quantum neural networks. QUIET-SR effectively captures complex residual mappings between low-resolution and high-resolution images, leveraging quantum attention mechanisms to enhance feature extraction and image restoration while requiring a minimal number of qubits, making it suitable for the Noisy Intermediate-Scale Quantum (NISQ) era. We evaluate our framework in MNIST (30.24 PSNR, 0.989 SSIM), FashionMNIST (29.76 PSNR, 0.976 SSIM) and the MedMNIST dataset collection, demonstrating that QUIET-SR achieves PSNR and SSIM scores comparable to state-of-the-art methods while using fewer parameters. Our efficient batching strategy directly enables massive parallelization on multiple QPU's paving the way for practical quantum-enhanced image super-resolution through coordinated QPU-GPU quantum supercomputing.","authors":["Siddhant Dutta","Nouhaila Innan","Khadijeh Najafi","Sadok Ben Yahia","Muhammad Shafique"],"pdf_url":"","comment":"13 Pages, 7 Figures (5 Main figures, 2 Sub-figures), 2 Tables, Under Review"}],"Graphics":[{"id":"http://arxiv.org/abs/2601.05181v1","updated":"2026-01-08T18:04:09Z","published":"2026-01-08T18:04:09Z","title":"Spacecube: A fast inverse hyperspectral georectification system","summary":"Hyperspectral cameras provide numerous advantages in terms of the utility of the data captured. They capture hundreds of data points per sample (pixel) instead of only the few of RGB or multispectral camera systems. Aerial systems sense such data remotely, but the data must be georectified to produce consistent images before analysis. We find the traditional direct georectification method to be slow, and it is prone to artifacts. To address its downsides, we propose Spacecube, a program that implements a complete hyperspectral georectification pipeline, including our own fast inverse georectification technique, using OpenGL graphics programming technologies. Spacecube operates substantially faster than real-time and eliminates pixel coverage artifacts. It facilitates high quality interactive viewing, data exploration, and export of final products. We release Spacecube's source code publicly for the community to use.","authors":["Thomas P. Watson","Eddie L. Jacobs"],"pdf_url":"","comment":"9 pages, 16 figures. source code available after peer-reviewed publication"},{"id":"http://arxiv.org/abs/2601.05162v1","updated":"2026-01-08T17:51:35Z","published":"2026-01-08T17:51:35Z","title":"GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation","summary":"Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.","authors":["Jinze Yu","Dayuan Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05127v1","updated":"2026-01-08T17:17:47Z","published":"2026-01-08T17:17:47Z","title":"LooseRoPE: Content-aware Attention Manipulation for Semantic Harmonization","summary":"Recent diffusion-based image editing methods commonly rely on text or high-level instructions to guide the generation process, offering intuitive but coarse control. In contrast, we focus on explicit, prompt-free editing, where the user directly specifies the modification by cropping and pasting an object or sub-object into a chosen location within an image. This operation affords precise spatial and visual control, yet it introduces a fundamental challenge: preserving the identity of the pasted object while harmonizing it with its new context. We observe that attention maps in diffusion-based editing models inherently govern whether image regions are preserved or adapted for coherence. Building on this insight, we introduce LooseRoPE, a saliency-guided modulation of rotational positional encoding (RoPE) that loosens the positional constraints to continuously control the attention field of view. By relaxing RoPE in this manner, our method smoothly steers the model's focus between faithful preservation of the input image and coherent harmonization of the inserted object, enabling a balanced trade-off between identity retention and contextual blending. Our approach provides a flexible and intuitive framework for image editing, achieving seamless compositional results without textual descriptions or complex user input.","authors":["Etai Sella","Yoav Baron","Hadar Averbuch-Elor","Daniel Cohen-Or","Or Patashnik"],"pdf_url":"","comment":"Project Page: https://snap-research.github.io/LooseRoPE/"},{"id":"http://arxiv.org/abs/2601.05016v1","updated":"2026-01-08T15:18:12Z","published":"2026-01-08T15:18:12Z","title":"From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling","summary":"We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.","authors":["Jin Gao","Saichandu Juluri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/1001.4002v3","updated":"2026-01-08T12:36:04Z","published":"2010-01-22T18:23:27Z","title":"Aplicación Gráfica para el estudio de un Modelo de Celda Electrolítica usando Técnicas de Visualización de Campos Vectoriales","summary":"The use of floating bipolar electrodes in copper electro-winning cells represents an emerging technology that promises economic and operational impacts. This thesis presents EWCellCAD, a computational tool designed for the simulation and analysis of these electrochemical systems. Based on the generalization and optimization of an existing 2D finite difference model for calculating electrical variables in rectangular cells, EWCellCAD implements a new 3D model capable of processing complex geometries, not necessarily rectangular, which also accelerates calculations by several orders of magnitude. At the same time, a new analytical method for estimating potentials in floating electrodes is introduced, overcoming the inaccuracies of previous heuristic approaches. The analysis of the results is supported by an interactive visualization technique of three-dimensional vector fields as flow lines.","authors":["César Mena"],"pdf_url":"","comment":"BSc Thesis in Electronic Engineering (part of the research project FONDECYT 1970955), Universidad de Concepción, 2000, 105 pages, 22 figures, in Spanish. Related publication: arXiv:1001.3974 [cs.GR]. Metadata-only update: Author name standardized (maternal surname removed; paternal surname as sole last name). Title orthography corrected with TeX accents. Abstract refined"},{"id":"http://arxiv.org/abs/2507.09792v3","updated":"2026-01-08T03:47:27Z","published":"2025-07-13T21:11:53Z","title":"CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design","summary":"Computer-aided design (CAD) is the digital construction of 2D and 3D objects, and is central to a wide range of engineering and manufacturing applications like automobile and aviation. Despite its importance, CAD modeling remains largely a time-intensive, manual task. Recent works have attempted to automate this process with small transformer-based models and handcrafted CAD sequence representations. However, there has been little effort to leverage the potential of large language models (LLMs) for sequential CAD design. In this work, we introduce a new large-scale dataset of more than 170k CAD models annotated with high-quality, human-like descriptions generated with our pipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs to generate CAD sequences represented in a JSON-based format from natural language descriptions, demonstrating the viability and effectiveness of this approach for text-conditioned CAD generation. Because simple metrics often fail to reflect the quality of generated objects, we introduce geometric and topological metrics based on sphericity, mean curvature, and Euler characteristic to provide richer structural insights. Our experiments and ablation studies on both synthetic and human-annotated data demonstrate that CADmium is able to automate CAD design, drastically speeding up the design of new objects. The dataset, code, and fine-tuned models are available online.","authors":["Prashant Govindarajan","Davide Baldelli","Jay Pathak","Quentin Fournier","Sarath Chandar"],"pdf_url":"","comment":"Published in Transactions on Machine Learning Research (TMLR) 01/2026"},{"id":"http://arxiv.org/abs/2601.04494v1","updated":"2026-01-08T01:58:20Z","published":"2026-01-08T01:58:20Z","title":"Differential Locally Injective Grid Deformation and Optimization","summary":"Grids are a general representation for capturing regularly-spaced information, but since they are uniform in space, they cannot dynamically allocate resolution to regions with varying levels of detail. There has been some exploration of indirect grid adaptivity by replacing uniform grids with tetrahedral meshes or locally subdivided grids, as inversion-free deformation of grids is difficult. This work develops an inversion-free grid deformation method that optimizes differential weight to adaptively compress space. The method is the first to optimize grid vertices as differential elements using vertex-colorings, decomposing a dense input linear system into many independent sets of vertices which can be optimized concurrently. This method is then also extended to optimize UV meshes with convex boundaries. Experimentally, this differential representation leads to a smoother optimization manifold than updating extrinsic vertex coordinates. By optimizing each sets of vertices in a coloring separately, local injectivity checks are straightforward since the valid region for each vertex is fixed. This enables the use of optimizers such as Adam, as each vertex can be optimized independently of other vertices. We demonstrate the generality and efficacy of this approach through applications in isosurface extraction for inverse rendering, image compaction, and mesh parameterization.","authors":["Julian Knodt","Seung-Hwan Baek"],"pdf_url":"","comment":null}],"Signal Processing":[{"id":"http://arxiv.org/abs/2506.23525v2","updated":"2026-01-08T18:11:38Z","published":"2025-06-30T05:21:11Z","title":"Sensing for Free: Learn to Localize More Sources than Antennas without Pilots","summary":"Integrated sensing and communication (ISAC) represents a key paradigm for future wireless networks. However, existing approaches require waveform modifications, dedicated pilots, or overhead that complicates standards integration. We propose sensing for free - performing multi-source localization without pilots by reusing uplink data symbols, making sensing occur during transmission and directly compatible with 3GPP 5G NR and 6G specifications. With ever-increasing devices in dense 6G networks, this approach is particularly compelling when combined with sparse arrays, which can localize more sources than uniform arrays via an enlarged virtual array. Existing pilot-free multi-source localization algorithms first reconstruct an extended covariance matrix and apply subspace methods, incurring cubic complexity and limited to second-order statistics. Performance degrades under non-Gaussian data symbols and few snapshots, and higher-order statistics remain unexploited. We address these challenges with an attention-only transformer that directly processes raw signal snapshots for grid-less end-to-end direction-of-arrival (DOA) estimation. The model efficiently captures higher-order statistics while being permutation-invariant and adaptive to varying snapshot counts. Our algorithm greatly outperforms state-of-the-art AI-based benchmarks with over 30x reduction in parameters and runtime, and enjoys excellent generalization under practical mismatches. Applied to multi-user MIMO beam training, our algorithm can localize uplink DOAs of multiple users during data transmission. Through angular reciprocity, estimated uplink DOAs prune downlink beam sweeping candidates and improve throughput via sensing-assisted beam management. This work shows how reusing existing data transmission for sensing can enhance both multi-source localization and beam management in 3GPP efforts towards 6G.","authors":["Wentao Yu","Khaled B. Letaief","Lizhong Zheng"],"pdf_url":"","comment":"17 pages, 14 figures, 1 table. This paper was accepted by the IEEE Journal on Selected Areas in Communications (JSAC) on Jan. 5, 2026"},{"id":"http://arxiv.org/abs/2601.05178v1","updated":"2026-01-08T18:03:28Z","published":"2026-01-08T18:03:28Z","title":"Multi-band Carrier Phase Positioning toward 6G: Performance Bounds and Efficient Estimators","summary":"In addition to satellite systems, carrier phase positioning (CPP) is gaining attraction also in terrestrial mobile networks, particularly in 5G New Radio evolution toward 6G. One key challenge is to resolve the integer ambiguity problem, as the carrier phase provides only relative position information. This work introduces and studies a multi-band CPP scenario with intra- and inter-band carrier aggregation (CA) opportunities across FR1, mmWave-FR2, and emerging 6G FR3 bands. Specifically, we derive multi-band CPP performance bounds, showcasing the superiority of multi-band CPP for high-precision localization in current and future mobile networks, while noting also practical imperfections such as clock offsets between the user equipment (UE) and the network as well as mutual clock imperfections between the network nodes. A wide collection of numerical results is provided, covering the impacts of the available carrier bandwidth, number of aggregated carriers, transmit power, and the number of network nodes or base stations. The offered results highlight that only two carriers suffice to substantially facilitate resolving the integer ambiguity problem while also largely enhancing the robustness of positioning against imperfections imposed by the network-side clocks and multi-path propagation. In addition, we also propose a two-stage practical estimator that achieves the derived bounds under all realistic bandwidth and transmit power conditions. Furthermore, we show that with an additional search-based refinement step, the proposed estimator becomes particularly suitable for narrowband Internet of Things applications operating efficiently even under narrow carrier bandwidths. Finally, both the derived bounds and the proposed estimators are extended to scenarios where the bands assigned to each base station are nonuniform or fully disjoint, enhancing the practical deployment flexibility.","authors":["Ehsan Shourezari","Ossi Kaltiokallio","Mehmet C. Ilter","Jukka Talvitie","Gonzalo Seco-Granados","Henk Wymeersch","Mikko Valkama"],"pdf_url":"","comment":"13 pages, 10 figures, under review in IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2506.23410v3","updated":"2026-01-08T17:55:22Z","published":"2025-06-29T22:10:54Z","title":"Integrated Polarimetric Sensing and Communication with Polarization-Reconfigurable Arrays","summary":"Polarization diversity offers a cost- and space-efficient solution to enhance the performance of integrated sensing and communication systems. Polarimetric sensing exploits the signal's polarity to extract details about the target such as shape, pose, and material composition. From a communication perspective, polarization diversity can enhance the reliability and throughput of communication channels. This paper proposes an integrated polarimetric sensing and communication (IPSAC) system that jointly conducts polarimetric sensing and communications. We study the use of single-port polarization-reconfigurable antennas to adapt to channel depolarization effects, without the need for separate RF chains for each polarization. We address two core sensing tasks in IPSAC systems, target parameter estimation and target detection. For parameter estimation, we consider the problem of minimizing the mean-squared error (MSE) of the target depolarization parameter estimate, which is a critical task for various polarimetric radar applications such as rainfall forecasting, vegetation identification, and target classification. To address this nonconvex problem, we apply semi-definite relaxation (SDR) and majorization-minimization (MM) optimization techniques. Next, we consider a design that maximizes the target SINR leveraging prior knowledge of the target and clutter depolarization statistics to enhance the target detection performance. To tackle this problem, we modify the solution developed for MSE minimization subject to the same quality-of-service (QoS) constraints. Extensive simulations show that the proposed polarization reconfiguration method substantially improves the depolarization parameter MSE. Furthermore, the proposed method considerably boosts the target SINR due to polarization diversity, particularly in cluttered environments.","authors":["Byunghyun Lee","Rang Liu","David J. Love","James V. Krogmeier","A. Lee Swindlehurst"],"pdf_url":"","comment":"Accepted to IEEE Transactions on Wireless Communications for publication"},{"id":"http://arxiv.org/abs/2601.05084v1","updated":"2026-01-08T16:29:08Z","published":"2026-01-08T16:29:08Z","title":"Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication","summary":"Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.","authors":["Niloufar Alavi","Swati Shah","Rezvan Alamian","Stefan Goetz"],"pdf_url":"","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.05032v1","updated":"2026-01-08T15:43:12Z","published":"2026-01-08T15:43:12Z","title":"On the Impact of Channel Aging and Doppler-Affected Clutter on OFDM ISAC Systems","summary":"The temporal evolution of the propagation environment plays a central role in integrated sensing and communication (ISAC) systems. A slow-time evolution manifests as channel aging in communication links, while a fast-time one is associated with structured clutter with non-zero Doppler. Nevertheless, the joint impact of these two phenomena on ISAC performance has been largely overlooked. This addresses this research gap in a network utilizing orthogonal frequency division multiplexing waveforms. Here, a base station simultaneously serves multiple user equipment (UE) devices and performs monostatic sensing. Channel aging is captured through an autoregressive model with exponential correlation decay. In contrast, clutter is modeled as a collection of uncorrelated, coherent patches with non-zero Doppler, resulting in a Kronecker-separable covariance structure. We propose an aging-aware channel estimator that uses prior pilot observations to estimate the time-varying UE channels, characterized by a non-isotropic multipath fading structure. The clutter's structure enables a novel low-complexity sensing pipeline: clutter statistics are estimated from raw data and subsequently used to suppress the clutter's action, after which target parameters are extracted through range-angle and range-velocity maps. We evaluate the influence of frame length and pilot history on channel estimation accuracy and demonstrate substantial performance gains over block fading in low-to-moderate mobility regimes. The sensing pipeline is implemented in a clutter-dominated environment, demonstrating that effective clutter suppression can be achieved under practical configurations. Furthermore, our results show that dedicated sensing streams are required, as communication beams provide insufficient range resolution.","authors":["Steven Rivetti","Gabor Fodor","Emil Björnson","Mikael Skoglund"],"pdf_url":"","comment":"13 pages, 21 pictures, submitted to IEEE TWC"},{"id":"http://arxiv.org/abs/2412.12751v4","updated":"2026-01-08T15:43:04Z","published":"2024-12-17T10:15:46Z","title":"Experimental Study of Low-Latency Video Streaming in an ORAN Setup with Generative AI","summary":"Current Adaptive Bit Rate (ABR) methods react to network congestion after it occurs, causing application layer buffering and latency spikes in live video streaming. We introduce a proactive semantic control channel that enables coordination between Open Radio Access Network (ORAN) xApp, Mobile Edge computing (MEC), and User Equipment (UE) components for seamless live video streaming between mobile devices. When the transmitting UE experiences poor Uplink (UL) conditions, the MEC proactively instructs downscaling based on low-level RAN metrics, including channel SNR updated every millisecond, preventing buffering before it occurs. A Generative AI (GAI) module at the MEC reconstructs high-quality frames from downscaled video before forwarding to the receiving UE via the typically more robust Downlink (DL). Experimental validation on a live ORAN testbed with 50 video streams shows that our approach reduces latency tail behavior while achieving up to 4 dB improvement in PSNR and 15 points in VMAF compared to reactive ABR methods. The proactive control eliminates latency spikes exceeding 600 ms, demonstrating effective cross-layer coordination for latency-critical live video streaming.","authors":["Andreas Casparsen","Van-Phuc Bui","Shashi Raj Pandey","Jimmy Jessen Nielsen","Petar Popovski"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.19209v3","updated":"2026-01-08T15:05:49Z","published":"2025-10-22T03:38:52Z","title":"AI Signal Processing Paradigm for Movable Antenna: From Spatial Position Optimization to Electromagnetic Reconfigurability","summary":"As 6G wireless communication systems evolve toward intelligence, high reconfigurability, and space-air-ground integration \\cite{liu2025toward, liu2024near}, the limitations of traditional fixed antenna (TFA) have become increasingly prominent. As a remedy, spatially movable antenna (SMA) and electromagnetically reconfigurable antenna (ERA) have respectively emerged as key technologies to break through this bottleneck. SMA activates spatial degree of freedom (DoF) by dynamically adjusting antenna positions, ERA regulates radiation characteristics using tunable metamaterials, thereby introducing DoF in the electromagnetic domain. However, the ``spatial-electromagnetic dual reconfiguration\" paradigm formed by their integration poses severe challenges of high-dimensional hybrid optimization to signal processing. To address this issue, we integrate the spatial optimization of SMA and the electromagnetic reconfiguration of ERA, propose a unified modeling framework termed movable and reconfigurable antenna (MARA) and investigate the channel modeling and spectral efficiency (SE) optimization for MARA. Besides, we systematically review artificial intelligence (AI)-based solutions, focusing on analyzing the advantages of AI over traditional algorithms in solving high-dimensional non-convex optimization problems. This paper fills the gap in existing literature regarding the lack of a comprehensive review on the AI-driven signal processing paradigm under spatial-electromagnetic dual reconfiguration and provides theoretical guidance for the design and optimization of 6G wireless systems with advanced MARA.","authors":["Yining Li","Ziwei Wan","Chongjia Sun","Kaijun Feng","Keke Ying","Wenyan Ma","Lipeng Zhu","Xiaodan Shao","Weidong Mei","Wenqian Shen","Zhenyu Xiao","Zhen Gao","Rui Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05000v1","updated":"2026-01-08T14:59:18Z","published":"2026-01-08T14:59:18Z","title":"Ultra-Wideband Transmission Systems From an Energy Perspective: Which Band is Next?","summary":"Measuring the power efficiency of the state-of-the-art OESCL-band amplifiers, we show that 1000 km OESCL-band systems can achieve 2.98x greater throughput for +48% higher energy-per-bit compared to CL-band transmission only.","authors":["Ronit Sohanpal","Mindaugus Jarmolovicius","Jiaqian Yang","Eric Sillekens","Romulo Aparecido","Vitaly Mikhailov","Jiawei Luo","David J. DiGiovanni","Ruben S. Luis","Hideaki Furukawa","Robert I. Killey","Polina Bayvel"],"pdf_url":"","comment":"Optical Fiber Communications Conference (OFC) 2026"},{"id":"http://arxiv.org/abs/2601.04980v1","updated":"2026-01-08T14:33:04Z","published":"2026-01-08T14:33:04Z","title":"Learning Sparsifying Transforms for mmWave Communication via $\\ell^4$-Norm Maximization","summary":"The high directionality of wave propagation at millimeter-wave (mmWave) carrier frequencies results in only a small number of significant transmission paths between user equipments and the basestation (BS). This sparse nature of wave propagation is revealed in the beamspace domain, which is traditionally obtained by taking the spatial discrete Fourier transform (DFT) across a uniform linear antenna array at the BS, where each DFT output is associated with a distinct beam. In recent years, beamspace processing has emerged as a promising technique to reduce baseband complexity and power consumption in all-digital massive multiuser (MU) multiple-input multiple-output (MIMO) systems operating at mmWave frequencies. However, it remains unclear whether the DFT is the optimal sparsifying transform for finite-dimensional antenna arrays. In this paper, we extend the framework of Zhai et al. for complete dictionary learning via $\\ell^4$-norm maximization to the complex case in order to learn new sparsifying transforms. We provide a theoretical foundation for $\\ell^4$-norm maximization and propose two suitable learning algorithms. We then utilize these algorithms (i) to assess the optimality of the DFT for sparsifying channel vectors theoretically and via simulations and (ii) to learn improved sparsifying transforms for real-world and synthetically generated channel vectors.","authors":["Sueda Taner","Christoph Studer"],"pdf_url":"","comment":"Submitted to a journal"},{"id":"http://arxiv.org/abs/2601.04969v1","updated":"2026-01-08T14:19:30Z","published":"2026-01-08T14:19:30Z","title":"6D Movable Antenna Enhanced Cell-free MIMO: Two-timescale Decentralized Beamforming and Antenna Movement Optimization","summary":"This paper investigates a six-dimensional movable antenna (6DMA)-aided cell-free multi-user multiple-input multiple-output (MIMO) communication system. In this system, each distributed access point (AP) can flexibly adjust its array orientation and antenna positions to adapt to spatial channel variations and enhance communication performance. However, frequent antenna movements and centralized beamforming based on global instantaneous channel state information (CSI) sharing among APs entail extremely high signal processing delay and system overhead, which is difficult to be practically implemented in high-mobility scenarios with short channel coherence time. To address these practical implementation challenges and improve scalability, a two-timescale decentralized optimization framework is proposed in this paper to jointly design the beamformer, antenna positions, and array orientations. In the short timescale, each AP updates its receive beamformer based on local instantaneous CSI and global statistical CSI. In the long timescale, the central processing unit optimizes the antenna positions and array orientations at all APs based on global statistical CSI to maximize the ergodic sum rate of all users. The resulting optimization problem is non-convex and involves highly coupled variables, thus posing significant challenges for obtaining efficient solutions. To address this problem, a constrained stochastic successive convex approximation algorithm is developed. Numerical results demonstrate that the proposed 6DMA-aided cell-free system with decentralized beamforming significantly outperforms other antenna movement schemes with less flexibility and even achieves a performance comparable to that of the centralized beamforming benchmark.","authors":["Yichi Zhang","Yuchen Zhang","Wenyan Ma","Lipeng Zhu","Jianquan Wang","Wanbin Tang","Rui Zhang"],"pdf_url":"","comment":"13 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2509.12089v5","updated":"2026-01-08T13:35:28Z","published":"2025-09-15T16:16:57Z","title":"RadarPLM: Adapting Pre-trained Language Models for Marine Radar Target Detection by Selective Fine-tuning","summary":"Recent advances in pre-trained language models (PLMs) have demonstrated their capabilities in capturing universal knowledge, making them promising for radar signal processing applications. Nevertheless, directly fine-tuning PLMs on radar signals is both computationally expensive and prone to overfitting, particularly in low signal-to-clutter ratio (SCR) environments. In this paper, we propose a fine-tuning framework for PLM-based marine radar target detection. First, we design a lightweight adaptation module, enabling computationally efficient fine-tuning while preserving the pre-trained model's general knowledge. Second, a novel preference-aware loss is developed to selectively optimize different feature patches based on their online-evaluated learning values, guiding the model to concentrate on those generalizable feature patterns during optimization. Finally, a binary classification head is retrained based on autoencoder network to further enhance detection performance. Experiments on real-world radar data show that the proposed RadarPLM framework yields at least a 6.35% improvement in detection performance over the existing networks under low SCR conditions. Especially, in the small-sample training cases, the proposed RadarPLM also achieves a significant advantage over existing networks owing to the incorporation of the PLM.","authors":["Qiying Hu","Yaowen Li","Shengyi Zhang","Chuan Huang","Yu Liu","You He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04844v1","updated":"2026-01-08T11:30:18Z","published":"2026-01-08T11:30:18Z","title":"SE-EE Tradeoff in Pinching-Antenna Systems: Waveguide Multiplexing or Waveguide Switching?","summary":"The spectral and energy efficiency (SE-EE) trade-off in pinching-antenna systems (PASS) is investigated in this paper. In particular, two practical operating protocols, namely waveguide multiplexing (WM) and waveguide switching (WS), are considered. A multi-objective optimization problem (MOOP) is formulated to jointly optimize the baseband and pinching beamforming for maximizing the achievable SE and EE, which is then converted into a single-objective problem via the ε-constraint method. For WM, the problem is decomposed within the alternating-optimization framework, where the baseband beamforming is optimized using the successive convex approximation, and the pinching beamforming is updated through the particle swarm optimization. For WS, due to the time-division transmission and interference-free nature, the pinching beamforming in each time slot is first adjusted to maximize the served user channel gain, followed by the baseband power allocation. Simulation results demonstrate that 1) PASS outperforms conventional antennas by mitigating large-scale path losses; 2) WS leads to a higher maximum achievable EE by activating a single RF chain, whereas WM yields a higher SE upper bound by serving all users concurrently; and 3) increasing the number of users substantially enhances SE under WM, whereas WS shows more pronounced benefits in low-signal-to-noise ratio regimes.","authors":["Guangyu Zhu","Xidong Mu","Li Guo","Shibiao Xu","Yuanwei Liu","Naofal Al-Dhahir"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04831v1","updated":"2026-01-08T11:10:53Z","published":"2026-01-08T11:10:53Z","title":"An Ultra-Fast MLE for Low SNR Multi-Reference Alignment","summary":"Motivated by single-particle cryo-electron microscopy, multi-reference alignment (MRA) models the task of recovering an unknown signal from multiple noisy observations corrupted by random rotations. The standard approach, expectation-maximization (EM), often becomes computationally prohibitive, particularly in low signal-to-noise ratio (SNR) settings. We introduce an alternative, ultra-fast algorithm for MRA over the special orthogonal group $\\mathrm{SO}(2)$. By performing a Taylor expansion of the log-likelihood in the low-SNR regime, we estimate the signal by sequentially computing data-driven averages of observations. Our method requires only one pass over the data, dramatically reducing computational cost compared to EM. Numerical experiments show that the proposed approach achieves high accuracy in low-SNR environments and provides an excellent initialization for subsequent EM refinement.","authors":["Shay Kreymer","Amnon Balanov","Tamir Bendory"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24334v2","updated":"2026-01-08T10:31:52Z","published":"2025-12-30T16:40:02Z","title":"OptiVote: Non-Coherent FSO Over-the-Air Majority Vote for Communication-Efficient Distributed Federated Learning in Space Data Centers","summary":"The rapid deployment of mega-constellations is driving the long-term vision of space data centers (SDCs), where interconnected satellites form in-orbit distributed computing and learning infrastructures. Enabling distributed federated learning in such systems is challenging because iterative training requires frequent aggregation over inter-satellite links that are bandwidth- and energy-constrained, and the link conditions can be highly dynamic. In this work, we exploit over-the-air computation (AirComp) as an in-network aggregation primitive. However, conventional coherent AirComp relies on stringent phase alignment, which is difficult to maintain in space environments due to satellite jitter and Doppler effects. To overcome this limitation, we propose OptiVote, a robust and communication-efficient non-coherent free-space optical (FSO) AirComp framework for federated learning toward Space Data Centers. OptiVote integrates sign stochastic gradient descent (signSGD) with a majority-vote (MV) aggregation principle and pulse-position modulation (PPM), where each satellite conveys local gradient signs by activating orthogonal PPM time slots. The aggregation node performs MV detection via non-coherent energy accumulation, transforming phase-sensitive field superposition into phase-agnostic optical intensity combining, thereby eliminating the need for precise phase synchronization and improving resilience under dynamic impairments. To mitigate aggregation bias induced by heterogeneous FSO channels, we further develop an importance-aware, channel state information (CSI)-free dynamic power control scheme that balances received energies without additional signaling. We provide theoretical analysis by characterizing the aggregate error probability under statistical FSO channels and establishing convergence guarantees for non-convex objectives.","authors":["Anbang Zhang","Chenyuan Feng","Wai Ho Mow","Jia Ye","Shuaishuai Guo","Geyong Min","Tony Q. S. Quek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.18465v3","updated":"2026-01-08T09:33:54Z","published":"2025-06-23T10:06:24Z","title":"Sizing Antenna Arrays for Near-field Communication and Sensing","summary":"This paper presents key performance metrics for near-field communication and sensing systems and their scaling behavior as a function of the antenna array aperture. Analytical expressions are derived for several standard array geometries to ease the design of the large antenna arrays under given system requirements. First, the near-field beam focusing is analyzed and the minimum beamdepth is observed to rapidly saturate to a low asymptotic limit as the array aperture increases. In contrast, the near-field region span is shown to scale quadratically with the array aperture. Based on these two metrics, the maximum number of resolvable beamspots at 3 dB separation is derived analytically, exhibiting a linear dependence on the array aperture. Moreover, when considering a region where the beamfocusing resolution does not exceed a specified threshold, the extent of the region is also shown to scale linearly with the array size. Finally, the number of significant singular values of a channel observed at the array's broadside is estimated, showing a power-law dependence on the aperture. The resulting expressions provide practical design guidelines for evaluating aperture requirements in near-field communication and sensing applications.","authors":["Marcin Wachowiak","André Bourdoux","Sofie Pollin"],"pdf_url":"","comment":"Accepted to IEEE Wireless Communications Letters"},{"id":"http://arxiv.org/abs/2601.04723v1","updated":"2026-01-08T08:37:33Z","published":"2026-01-08T08:37:33Z","title":"Feasibility Study Regarding Self-sustainable Reconfigurable Intelligent Surfaces","summary":"Without requiring operational costs such as cabling and powering while maintaining reconfigurable phase-shift capability, self-sustainable reconfigurable intelligent surfaces (ssRISs) can be deployed in locations inaccessible to conventional relays or base stations, offering a novel approach to enhance wireless coverage. This study assesses the feasibility of ssRIS deployment by analyzing two harvest-and-reflect (HaR) schemes: element-splitting (ES) and time-splitting (TS). We examine how element requirements scale with key system parameters, transmit power, data rate demands, and outage constraints under both line-of-sight (LOS) and non-line-of-sight (NLOS) ssRIS-to-user equipment (UE) channels. Analytical and numerical results reveal distinct feasibility characteristics. The TS scheme demonstrates better channel hardening gain, maintaining stable element requirements across varying outage margins, making it advantageous for indoor deployments with favorable harvesting conditions and moderate data rates. However, TS exhibits an element requirement that exponentially scales to harvesting difficulty and data rate. Conversely, the ES scheme shows only linear growth with harvesting difficulty, providing better feasibility under challenging outdoor scenarios. These findings establish that TS excels in benign environments, prioritizing reliability, while ES is preferable for demanding conditions requiring operational robustness.","authors":["Zhenyu Li","Ozan Alp Topal","Özlem Tuğfe Demir","Emil Björnson","Cicek Cavdar"],"pdf_url":"","comment":"5pages, 3 figures, submitted and accepted by IEEE Wireless Communication Letter"},{"id":"http://arxiv.org/abs/2509.15993v2","updated":"2026-01-08T06:44:09Z","published":"2025-09-19T14:07:07Z","title":"Filter-and-Attend: Wireless Channel Foundation Model with Noise-Plus-Interference Suppression Structure","summary":"Wireless channel foundation model (WCFM) is a task-agnostic AI model that is pre-trained to learn a universal channel representation for a wide range of communications and sensing tasks. While existing works on WCFM have demonstrated its great potentials in various downstream tasks, the models are all trained using perfect (i.e., error-free and complete) channel information state (CSI) data. In practical systems, however, only degraded CSI obtained from pilot-based channel estimation is accessible, leading to distorted channel representations and performance degradation in downstream tasks for some real-world environments with severe noise and interference. To address this issue, this paper proposes a new paradigm for WCFM, termed as Filter-and-Attend. In this paradigm, Filter refers to explicitly suppressing noise-plus-interference (NPI) in the received signals, while Attend means performing correlation-aware CSI completion and feature extraction using attention mechanism. Specifically, an enhanced WCFM architecture is developed. In this architecture, coarse estimates of the CSIs are first obtained and exploited to construct two projection matrices that extract NPI components in the received signals, which are further processed and removed by a subtraction module. The filtered signal is subsequently passed through a CSI completion network to get a clean CSI for feature extraction. Simulation results demonstrated that compared to the state-of-the-art solutions, WCFM with NPI suppression structure achieves improved performance on various downstream tasks including time-domain channel prediction, frequency-domain channel prediction, and localization.","authors":["Yuwei Wang","Li Sun","Tingting Yang","Yuxuan Shi","Maged Elkashlan","Xiao Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04599v1","updated":"2026-01-08T05:03:03Z","published":"2026-01-08T05:03:03Z","title":"MIMO Beam Map Reconstruction via Toeplitz-Structured Matrix-Vector Tensor Decomposition","summary":"As wireless networks progress toward sixthgeneration (6G), understanding the spatial distribution of directional beam coverage becomes increasingly important for beam management and link optimization. Multiple-input multipleoutput (MIMO) beam map provides such spatial awareness, yet accurate construction under sparse measurements remains difficult due to incomplete spatial coverage and strong angular variations. This paper presents a tensor decomposition approach for reconstructing MIMO beam map from limited measurements. By transforming measurements from a Cartesian coordinate system into a polar coordinate system, we uncover a matrix-vector outer-product structure associated with different propagation conditions. Specifically, we mathematically demonstrate that the matrix factor, representing beam-space gain, exhibits an intrinsic Toeplitz structure due to the shift-invariant nature of array responses, and the vector factor captures distance-dependent attenuation. Leveraging these structural priors, we formulate a regularized tensor decomposition problem to jointly reconstruct line-of-sight (LOS), reflection, and obstruction propagation conditions. Simulation results confirm that the proposed method significantly enhances data efficiency, achieving a normalized mean square error (NMSE) reduction of over 20% compared to state-of-the-art baselines, even under sparse sampling regimes.","authors":["Hao Sun","Junting Chen","Xianghao Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04581v1","updated":"2026-01-08T04:26:19Z","published":"2026-01-08T04:26:19Z","title":"Spectral point transformer for significant wave height estimation from sea clutter","summary":"This paper presents a method for estimating significant wave height (Hs) from sparse S_pectral P_oint using a T_ransformer-based approach (SPT). Based on empirical observations that only a minority of spectral points with strong power contribute to wave energy, the proposed SPT effectively integrates geometric and spectral characteristics of ocean surface waves to estimate Hs through multi-dimensional feature representation. The experiment reveals an intriguing phenomenon: the learned features of SPT align well with physical dispersion relations, where the contribution-score map of selected points is concentrated along dispersion curves. Compared to conventional vision networks that process image sequences and full spectra, SPT demonstrates superior performance in Hs regression while consuming significantly fewer computational resources. On a consumer-grade GPU, SPT completes the training of regression model for 1080 sea clutter image sequences within 4 minutes, showcasing its potential to reduce deployment costs for radar wave-measuring systems. The open-source implementation of SPT will be available at https://github.com/joeyee/spt","authors":["Yi Zhou","Li Wang","Hang Su","Tian Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04488v1","updated":"2026-01-08T01:47:51Z","published":"2026-01-08T01:47:51Z","title":"Invisible Walls: Privacy-Preserving ISAC Empowered by Reconfigurable Intelligent Surfaces","summary":"The environmental and target-related information inherently carried in wireless signals, such as channel state information (CSI), has brought increasing attention to integrated sensing and communication (ISAC). However, it also raises pressing concerns about privacy leakage through eavesdropping. While existing efforts have attempted to mitigate this issue, they either fail to account for the needs of legitimate communication and sensing users or rely on hardware with high complexity and cost. To overcome these limitations, we propose PrivISAC, a plug-and-play, low-cost solution that leverages RIS to protect user privacy while preserving ISAC performance. At the core of PrivISAC is a novel strategy in which each RIS row is assigned two distinct beamforming vectors, from which we deliberately construct a limited set of RIS configurations. During operation, exactly one configuration is randomly activated at each time slot to introduce additional perturbations, effectively masking sensitive sensing information from unauthorized eavesdroppers. To jointly ensure privacy protection and communication performance, we design the two vectors such that their responses remain nearly identical in the communication direction, thereby preserving stable, high-throughput transmission, while exhibiting pronounced differences in the sensing direction, which introduces sufficient perturbations to thwart eavesdroppers. Additionally, to enable legitimate sensing under such randomized configurations, we introduce a time-domain masking and demasking method that allows the authorized receiver to associate each CSI sample with its underlying configuration and eliminate configuration-induced discrepancies, thereby recovering valid CSI. We implement PrivISAC on commodity wireless devices and experiment results show that PrivISAC provides strong privacy protection while preserving high-quality legitimate ISAC.","authors":["Yinghui He","Long Fan","Lei Xie","Dusit Niyato","Chau Yuen","Jun Luo"],"pdf_url":"","comment":"This paper has been submitted to IEEE"},{"id":"http://arxiv.org/abs/2601.04483v1","updated":"2026-01-08T01:34:51Z","published":"2026-01-08T01:34:51Z","title":"Hybrid Federated Learning for Noise-Robust Training","summary":"Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.","authors":["Yongjun Kim","Hyeongjun Park","Hwanjin Kim","Junil Choi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04478v1","updated":"2026-01-08T01:30:52Z","published":"2026-01-08T01:30:52Z","title":"Prediction of Cellular Malignancy Using Electrical Impedance Signatures and Supervised Machine Learning","summary":"Bioelectrical properties of cells such as relative permittivity, conductivity, and characteristic time constants vary significantly between healthy and malignant cells across different frequencies. These distinctions provide a promising foundation for diagnostic and classification applications. This study systematically reviewed 33 scholarly articles to compile datasets of quantitative bioelectric parameters and evaluated their utility in predictive modeling. Three supervised machine learning algorithms- Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) were implemented and tuned using key hyperparameters to assess classification performance. Model effectiveness was evaluated using accuracy and F1 score as performance metrics. Results demonstrate that Random Forest achieved the highest predictive accuracy of ~ 90% when configured with a maximum depth of 4 and 100 estimators. These findings highlight the potential of integrating bioelectrical property analysis with machine learning for improved diagnostic decision-making. Similarly, for KNN and SVM, the F1 score peaked at approximately 78% and 76.5%, respectively. Future work will explore incorporating additional discriminative features, leveraging stimulated datasets, and optimizing hyperparameter through advanced search strategies. Ultimately, hardware prototype with embedded micro-electrodes and real-time control systems could pave the path for practical diagnostic tools capable of in-situ cell classification.","authors":["Shadeeb Hossain"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2207.03427v2","updated":"2026-01-08T00:28:17Z","published":"2022-07-07T16:52:50Z","title":"Binary Iterative Hard Thresholding Converges with Optimal Number of Measurements for 1-Bit Compressed Sensing","summary":"Compressed sensing has been a very successful high-dimensional signal acquisition and recovery technique that relies on linear operations. However, the actual measurements of signals have to be quantized before storing or processing. 1(One)-bit compressed sensing is a heavily quantized version of compressed sensing, where each linear measurement of a signal is reduced to just one bit: the sign of the measurement. Once enough of such measurements are collected, the recovery problem in 1-bit compressed sensing aims to find the original signal with as much accuracy as possible. The recovery problem is related to the traditional \"halfspace-learning\" problem in learning theory.\n  For recovery of sparse vectors, a popular reconstruction method from 1-bit measurements is the binary iterative hard thresholding (BIHT) algorithm. The algorithm is a simple projected sub-gradient descent method, and is known to converge well empirically, despite the nonconvexity of the problem. The convergence property of BIHT was not theoretically justified, except with an exorbitantly large number of measurements (i.e., a number of measurement greater than $\\max\\{k^{10}, 24^{48}, k^{3.5}/ε\\}$, where $k$ is the sparsity, $ε$ denotes the approximation error, and even this expression hides other factors). In this paper we show that the BIHT algorithm converges with only $\\tilde{O}(\\frac{k}ε)$ measurements. Note that, this dependence on $k$ and $ε$ is optimal for any recovery method in 1-bit compressed sensing. With this result, to the best of our knowledge, BIHT is the only practical and efficient (polynomial time) algorithm that requires the optimal number of measurements in all parameters (both $k$ and $ε$). This is also an example of a gradient descent algorithm converging to the correct solution for a nonconvex problem, under suitable structural conditions.","authors":["Namiko Matsumoto","Arya Mazumdar"],"pdf_url":"","comment":"Published in Journal of the ACM, 2024; conference version published in FOCS 2022"}],"Computational Geometry":[{"id":"http://arxiv.org/abs/2407.07749v4","updated":"2026-01-08T16:15:45Z","published":"2024-07-10T15:20:21Z","title":"Fast Approximation Algorithms for Euclidean Minimum Weight Perfect Matching","summary":"We study the Euclidean minimum weight perfect matching problem for $n$ points in the plane. It is known that any deterministic approximation algorithm whose approximation ratio depends only on $n$ requires at least $Ω(n \\log n)$ time. We propose such an algorithm for the Euclidean minimum weight perfect matching problem with runtime $O(n\\log n)$ and show that it has approximation ratio $O(n^{0.206})$. This improves the so far best known approximation ratio of $n/2$. We also develop an $O(n \\log n)$ algorithm for the Euclidean minimum weight perfect matching problem in higher dimensions and show it has approximation ratio $O(n^{0.412})$ in all fixed dimensions.","authors":["Stefan Hougardy","Karolina Tammemaa"],"pdf_url":"","comment":"revised, 22 pages"},{"id":"http://arxiv.org/abs/2601.04626v1","updated":"2026-01-08T05:55:26Z","published":"2026-01-08T05:55:26Z","title":"Using Ray-shooting Queries for Sublinear Algorithms for Dominating Sets in RDV Graphs","summary":"In this paper, we study the dominating set problem in \\emph{RDV graphs}, a graph class that lies between interval graphs and chordal graphs and is defined as the \\textbf{v}ertex-intersection graphs of \\textbf{d}ownward paths in a \\textbf{r}ooted tree. It was shown in a previous paper that adjacency queries in an RDV graph can be reduced to the question whether a horizontal segment intersects a vertical segment. This was then used to find a maximum matching in an $n$-vertex RDV graph, using priority search trees, in $O(n\\log n)$ time, i.e., without even looking at all edges. In this paper, we show that if additionally we also use a ray shooting data structure, we can also find a minimum dominating set in an RDV graph $O(n\\log n)$ time (presuming a linear-sized representation of the graph is given). The same idea can also be used for a new proof to find a minimum dominating set in an interval graph in $O(n)$ time.","authors":["Therese Biedl","Prashant Gokhale"],"pdf_url":"","comment":"To appear at SOFSEM'26"}],"Data Structure and Algorithm":[{"id":"http://arxiv.org/abs/2601.05225v1","updated":"2026-01-08T18:53:52Z","published":"2026-01-08T18:53:52Z","title":"Concurrent Balanced Augmented Trees","summary":"Augmentation makes search trees tremendously more versatile, allowing them to support efficient aggregation queries, order-statistic queries, and range queries in addition to insertion, deletion, and lookup. In this paper, we present the first lock-free augmented balanced search tree. Our algorithmic ideas build upon a recent augmented unbalanced search tree presented by Fatourou and Ruppert [DISC, 2024]. We implement both data structures, solving some memory reclamation challenges in the process, and provide an experimental performance analysis of them. We also present optimized versions of our balanced tree that use delegation to achieve better scalability and performance (by more than 2x in some workloads). Our experiments show that our augmented balanced tree is 2.2 to 30 times faster than the unbalanced augmented tree, and up to several orders of magnitude faster than unaugmented trees on 120 threads.","authors":["Evan Wrench","Ajay Singh","Younghun Roh","Panagiota Fatourou","Siddhartha Jayanti","Eric Ruppert","Yuanhao Wei"],"pdf_url":"","comment":"To appear in PPoPP 2026"},{"id":"http://arxiv.org/abs/2601.05166v1","updated":"2026-01-08T17:55:57Z","published":"2026-01-08T17:55:57Z","title":"Inapproximability of Counting Permutation Patterns","summary":"Detecting and counting copies of permutation patterns are fundamental algorithmic problems, with applications in the analysis of rankings, nonparametric statistics, and property testing tasks such as independence and quasirandomness testing. From an algorithmic perspective, there is a sharp difference in complexity between detecting and counting the copies of a given length-$k$ pattern in a length-$n$ permutation. The former admits a $2^{\\mathcal{O}(k^2)} \\cdot n$ time algorithm (Guillemot and Marx, 2014) while the latter cannot be solved in time $f(k)\\cdot n^{o(k/\\log k)}$ unless the Exponential Time Hypothesis (ETH) fails (Berendsohn, Kozma, and Marx, 2021). In fact already for patterns of length 4, exact counting is unlikely to admit near-linear time algorithms under standard fine-grained complexity assumptions (Dudek and Gawrychowski, 2020).\n  Recently, Ben-Eliezer, Mitrović and Sristava (2026) showed that for patterns of length up to 5, a $(1+\\varepsilon)$-approximation of the pattern count can be computed in near-linear time, yielding a separation between exact and approximate counting for small patterns, and conjectured that approximate counting is asymptotically easier than exact counting in general. We strongly refute their conjecture by showing that, under ETH, no algorithm running in time $f(k)\\cdot n^{o(k/\\log k)}$ can approximate the number of copies of a length-$k$ pattern within a multiplicative factor $n^{(1/2-\\varepsilon)k}$. The lower bound on runtime matches the conditional lower bound for exact pattern counting, and the obtained bound on the multiplicative error factor is essentially tight, as an $n^{k/2}$-approximation can be computed in $2^{\\mathcal{O}(k^2)}\\cdot n$ time using an algorithm for pattern detection.","authors":["Michal Opler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05157v1","updated":"2026-01-08T17:47:58Z","published":"2026-01-08T17:47:58Z","title":"Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms","summary":"In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians.\n  All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments.\n  Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function.\n  Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.","authors":["Alkis Kalavasis","Pravesh K. Kothari","Shuchen Li","Manolis Zampetakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.07749v4","updated":"2026-01-08T16:15:45Z","published":"2024-07-10T15:20:21Z","title":"Fast Approximation Algorithms for Euclidean Minimum Weight Perfect Matching","summary":"We study the Euclidean minimum weight perfect matching problem for $n$ points in the plane. It is known that any deterministic approximation algorithm whose approximation ratio depends only on $n$ requires at least $Ω(n \\log n)$ time. We propose such an algorithm for the Euclidean minimum weight perfect matching problem with runtime $O(n\\log n)$ and show that it has approximation ratio $O(n^{0.206})$. This improves the so far best known approximation ratio of $n/2$. We also develop an $O(n \\log n)$ algorithm for the Euclidean minimum weight perfect matching problem in higher dimensions and show it has approximation ratio $O(n^{0.412})$ in all fixed dimensions.","authors":["Stefan Hougardy","Karolina Tammemaa"],"pdf_url":"","comment":"revised, 22 pages"},{"id":"http://arxiv.org/abs/2601.05044v1","updated":"2026-01-08T15:49:39Z","published":"2026-01-08T15:49:39Z","title":"An Invitation to \"Fine-grained Complexity of NP-Complete Problems\"","summary":"Assuming that P is not equal to NP, the worst-case run time of any algorithm solving an NP-complete problem must be super-polynomial. But what is the fastest run time we can get? Before one can even hope to approach this question, a more provocative question presents itself: Since for many problems the naive brute-force baseline algorithms are still the fastest ones, maybe their run times are already optimal?\n  The area that we call in this survey \"fine-grained complexity of NP-complete problems\" studies exactly this question. We invite the reader to catch up on selected classic results as well as delve into exciting recent developments in a riveting tour through the area passing by (among others) algebra, complexity theory, extremal and additive combinatorics, cryptography, and, of course, last but not least, algorithm design.","authors":["Jesper Nederlof"],"pdf_url":"","comment":"40 pages. Invited survey (currently under review, remarks are welcome)"},{"id":"http://arxiv.org/abs/2601.05026v1","updated":"2026-01-08T15:33:58Z","published":"2026-01-08T15:33:58Z","title":"A data structure for monomial ideals with applications to signature Gröbner bases","summary":"We introduce monomial divisibility diagrams (MDDs), a data structure for monomial ideals that supports insertion of new generators and fast membership tests. MDDs stem from a canonical tree representation by maximally sharing equal subtrees, yielding a directed acyclic graph. We establish basic complexity bounds for membership and insertion, and study empirically the size of MDDs. As an application, we integrate MDDs into the signature Gröbner basis implementation of the Julia package AlgebraicSolving.jl. Membership tests in monomial ideals are used to detect some reductions to zero, and the use of MDDs leads to substantial speed-ups.","authors":["Pierre Lairez","Rafael Mohr","Théo Ternier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2301.12783v4","updated":"2026-01-08T13:05:49Z","published":"2023-01-30T11:03:54Z","title":"The Leafed Induced Subtree in chordal and bounded treewidth graphs","summary":"In the Fully Leafed Induced Subtrees, one is given a graph $G$ and two integers $a$ and $b$ and the question is to find an induced subtree of $G$ with $a$ vertices and at least $b$ leaves. This problem is known to be NP-complete even when the input graph is $4$-regular. Polynomial algorithms are known when the input graph is restricted to be a tree or series-parallel. In this paper we generalize these results by providing an FPT algorithm parameterized by treewidth. We also provide a polynomial algorithm when the input graph is restricted to be a chordal graph.","authors":["Julien Baste"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:1704.07284, arXiv:2103.06536"},{"id":"http://arxiv.org/abs/2305.11352v3","updated":"2026-01-08T10:09:21Z","published":"2023-05-19T00:07:32Z","title":"Randomized adiabatic quantum linear solver algorithm with optimal complexity scaling and detailed running costs","summary":"Solving linear systems of equations is a fundamental problem with a wide variety of applications across many fields of science, and there is increasing effort to develop quantum linear solver algorithms. [Subaşi et al., Phys. Rev. Lett. (2019)] proposed a randomized algorithm inspired by adiabatic quantum computing, based on a sequence of random Hamiltonian simulation steps, with suboptimal scaling in the condition number $κ$ of the linear system and the target error $ε$. Here we go beyond these results in several ways. Firstly, using filtering~[Lin et al., Quantum (2019)] and Poissonization techniques [Cunningham et al., arXiv:2406.03972 (2024)], the algorithm complexity is improved to the optimal scaling $O(κ\\log(1/ε))$ -- an exponential improvement in $ε$, and a shaving of a $\\log κ$ scaling factor in $κ$. Secondly, the algorithm is further modified to achieve constant factor improvements, which are vital as we progress towards hardware implementations on fault-tolerant devices. We introduce a cheaper randomized walk operator method replacing Hamiltonian simulation -- which also removes the need for potentially challenging classical precomputations; randomized routines are sampled over optimized random variables; circuit constructions are improved. We obtain a closed formula rigorously upper bounding the expected number of times one needs to apply a block-encoding of the linear system matrix to output a quantum state encoding the solution to the linear system. The upper bound is $837 κ$ at $ε=10^{-10}$ for Hermitian matrices.","authors":["David Jennings","Matteo Lostaglio","Sam Pallister","Andrew T Sornborger","Yiğit Subaşı"],"pdf_url":"","comment":"19 pages. Published version"},{"id":"http://arxiv.org/abs/2601.04756v1","updated":"2026-01-08T09:22:22Z","published":"2026-01-08T09:22:22Z","title":"Branch-width of connectivity functions is fixed-parameter tractable","summary":"A connectivity function on a finite set $V$ is a symmetric submodular function $f \\colon 2^V \\to \\mathbb{Z}$ with $f(\\emptyset)=0$. We prove that finding a branch-decomposition of width at most $k$ for a connectivity function given by an oracle is fixed-parameter tractable (FPT), by providing an algorithm of running time $2^{O(k^2)} γn^6 \\log n$, where $γ$ is the time to compute $f(X)$ for any set $X$, and $n = |V|$. This improves the previous algorithm by Oum and Seymour [J. Combin. Theory Ser.~B, 2007], which runs in time $γn^{O(k)}$. Our algorithm can be applied to rank-width of graphs, branch-width of matroids, branch-width of (hyper)graphs, and carving-width of graphs. This resolves an open problem asked by Hliněný [SIAM J. Comput., 2005], who asked whether branch-width of matroids given by the rank oracle is fixed-parameter tractable. Furthermore, our algorithm improves the best known dependency on $k$ in the running times of FPT algorithms for graph branch-width, rank-width, and carving-width.","authors":["Tuukka Korhonen","Sang-il Oum"],"pdf_url":"","comment":"13 pages"},{"id":"http://arxiv.org/abs/2601.04626v1","updated":"2026-01-08T05:55:26Z","published":"2026-01-08T05:55:26Z","title":"Using Ray-shooting Queries for Sublinear Algorithms for Dominating Sets in RDV Graphs","summary":"In this paper, we study the dominating set problem in \\emph{RDV graphs}, a graph class that lies between interval graphs and chordal graphs and is defined as the \\textbf{v}ertex-intersection graphs of \\textbf{d}ownward paths in a \\textbf{r}ooted tree. It was shown in a previous paper that adjacency queries in an RDV graph can be reduced to the question whether a horizontal segment intersects a vertical segment. This was then used to find a maximum matching in an $n$-vertex RDV graph, using priority search trees, in $O(n\\log n)$ time, i.e., without even looking at all edges. In this paper, we show that if additionally we also use a ray shooting data structure, we can also find a minimum dominating set in an RDV graph $O(n\\log n)$ time (presuming a linear-sized representation of the graph is given). The same idea can also be used for a new proof to find a minimum dominating set in an interval graph in $O(n)$ time.","authors":["Therese Biedl","Prashant Gokhale"],"pdf_url":"","comment":"To appear at SOFSEM'26"}],"Game Theory":[{"id":"http://arxiv.org/abs/2509.24849v3","updated":"2026-01-08T16:41:22Z","published":"2025-09-29T14:34:19Z","title":"The Free Option Problem of ePBS","summary":"Ethereum's upcoming Glamsterdam upgrade introduces EIP-7732 enshrined Proposer--Builder Separation (ePBS), which improves the block production pipeline by addressing trust and scalability challenges. Yet it also creates a new liveness risk: builders gain a short-dated ``free'' option to prevent the execution payload they committed to from becoming canonical, without incurring an additional penalty. Exercising this option renders an empty block for the slot in question, thereby degrading network liveness.\n  We present the first systematic study of the free option problem. Our theoretical results predict that option value and exercise probability grow with market volatility, the length of the option window, and the share of block value derived from external signals such as external market prices. The availability of a free option will lead to mispricing and LP losses. The problem would be exacerbated if Ethereum further scales and attracts more liquidity. Empirical estimates of values and exercise probabilities on historical blocks largely confirm our theoretical predictions. While the option is rarely profitable to exercise on average (0.82\\% of blocks assuming an 8-second option time window), it becomes significant in volatile periods, reaching up to 6\\% of blocks on high-volatility days -- precisely when users most require timely execution.\n  Moreover, builders whose block value relies heavily on CEX-DEX arbitrage are more likely to exercise the option. We demonstrate that mitigation strategies -- shortening the option window or penalizing exercised options -- effectively reduce liveness risk.","authors":["Bruno Mazorra","Burak Öz","Christoph Schlegel","Fei Wu"],"pdf_url":"","comment":"In Financial Cryptography and Data Security 2026"},{"id":"http://arxiv.org/abs/2601.04648v1","updated":"2026-01-08T06:45:22Z","published":"2026-01-08T06:45:22Z","title":"Mechanism Design for Federated Learning with Non-Monotonic Network Effects","summary":"Mechanism design is pivotal to federated learning (FL) for maximizing social welfare by coordinating self-interested clients. Existing mechanisms, however, often overlook the network effects of client participation and the diverse model performance requirements (i.e., generalization error) across applications, leading to suboptimal incentives and social welfare, or even inapplicability in real deployments. To address this gap, we explore incentive mechanism design for FL with network effects and application-specific requirements of model performance. We develop a theoretical model to quantify the impact of network effects on heterogeneous client participation, revealing the non-monotonic nature of such effects. Based on these insights, we propose a Model Trading and Sharing (MoTS) framework, which enables clients to obtain FL models through either participation or purchase. To further address clients' strategic behaviors, we design a Social Welfare maximization with Application-aware and Network effects (SWAN) mechanism, exploiting model customer payments for incentivization. Experimental results on a hardware prototype demonstrate that our SWAN mechanism outperforms existing FL mechanisms, improving social welfare by up to $352.42\\%$ and reducing extra incentive costs by $93.07\\%$.","authors":["Xiang Li","Bing Luo","Jianwei Huang","Yuan Luo"],"pdf_url":"","comment":"Journal extension of Mobihoc conference version, under review of IEEE TMC"}],"Information Theory":[{"id":"http://arxiv.org/abs/2601.05217v1","updated":"2026-01-08T18:42:26Z","published":"2026-01-08T18:42:26Z","title":"A complete characterization of testable hypotheses","summary":"We revisit a fundamental question in hypothesis testing: given two sets of probability measures $\\mathcal{P}$ and $\\mathcal{Q}$, when does a nontrivial (i.e.\\ strictly unbiased) test for $\\mathcal{P}$ against $\\mathcal{Q}$ exist? Le~Cam showed that, when $\\mathcal{P}$ and $\\mathcal{Q}$ have a common dominating measure, a test that has power exceeding its level by more than $\\varepsilon$ exists if and only if the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ are separated in total variation distance by more than $\\varepsilon$. The requirement of a dominating measure is frequently violated in nonparametric statistics. In a passing remark, Le~Cam described an approach to address more general scenarios, but he stopped short of stating a formal theorem. This work completes Le~Cam's program, by presenting a matching necessary and sufficient condition for testability: for the aforementioned theorem to hold without assumptions, one must take the closures of the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ in the space of bounded finitely additive measures. We provide simple elucidating examples, and elaborate on various subtle measure theoretic and topological points regarding compactness and achievability.","authors":["Martin Larsson","Johannes Ruf","Aaditya Ramdas"],"pdf_url":"","comment":"28 pages"},{"id":"http://arxiv.org/abs/2601.02015v2","updated":"2026-01-08T18:27:27Z","published":"2026-01-05T11:24:33Z","title":"Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects","summary":"Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.","authors":["Omar Momen","Emilie Sitter","Berenike Herrmann","Sina Zarrieß"],"pdf_url":"","comment":"to be published at EACL 2026 main conference"},{"id":"http://arxiv.org/abs/2601.05173v1","updated":"2026-01-08T17:59:49Z","published":"2026-01-08T17:59:49Z","title":"Information-Theoretic Limits on Exact Subgraph Alignment Problem","summary":"The graph alignment problem aims to identify the vertex correspondence between two correlated graphs. Most existing studies focus on the scenario in which the two graphs share the same vertex set. However, in many real-world applications, such as computer vision, social network analysis, and bioinformatics, the task often involves locating a small graph pattern within a larger graph. Existing graph alignment algorithms and analysis cannot directly address these scenarios because they are not designed to identify the specific subset of vertices where the small graph pattern resides within the larger graph. Motivated by this limitation, we introduce the subgraph alignment problem, which seeks to recover both the vertex set and/or the vertex correspondence of a small graph pattern embedded in a larger graph. In the special case where the small graph pattern is an induced subgraph of the larger graph and both the vertex set and correspondence are to be recovered, the problem reduces to the subgraph isomorphism problem, which is NP-complete in the worst case. In this paper, we formally formulate the subgraph alignment problem by proposing the Erdos-Renyi subgraph pair model together with some appropriate recovery criterion. We then establish almost-tight information-theoretic results for the subgraph alignment problem and present some novel approaches for the analysis.","authors":["Chun Hei Michael Shiu","Hei Victor Cheng","Lele Wang"],"pdf_url":"","comment":"This work was presented in part at the 2025 IEEE International Symposium on Information Theory and submitted in part to the 2026 IEEE International Symposium on Information Theory"},{"id":"http://arxiv.org/abs/2601.05165v1","updated":"2026-01-08T17:55:55Z","published":"2026-01-08T17:55:55Z","title":"Fundamental Tradeoffs for ISAC Multiple Access in Finite-Blocklength Regime","summary":"This paper investigates the fundamental communication--sensing tradeoffs of uplink dual-functional integrated sensing and communication (ISAC) multiple access under finite blocklength (FBL) constraints. Unlike conventional asymptotic analyses, we explicitly account for the limitations under FBL constraints imposed by short packets and low-latency transmission. By examining the unbiased channel state sensing estimator, we establish a geometric decomposition of the sensing error, indicating that it is jointly determined by the signal-to-noise ratio and the correlation structure of the information codebook. This insight reveals how cross-correlation among active users in the codebook geometry fundamentally constrains dual-functional ISAC performance. Consequently, we derive achievability and converse bounds that characterize the tradeoff between communication code rate and sensing accuracy in the FBL regime, with the converse further bounded by Shannon capacity. Moreover, by treating channel state sensing as a high-level sensing objective, a universal Cramér--Rao bound is derived to link channel estimation accuracy to practical sensing parameters. Examples of parameter sensing are also provided based on 3GPP standard. Numerical results validate the theoretical analysis and demonstrate the impact of blocklength, antenna dimensions, and sensing requirements.","authors":["Zhentian Zhang","Christos Masouros","Kai-Kit Wong","Jian Dang","Zaichen Zhang","Kaitao Meng","Farshad Rostami Ghadi","Mohammad Javad Ahmadi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.07142v4","updated":"2026-01-08T17:18:24Z","published":"2025-08-10T02:25:48Z","title":"Why Does Stochastic Gradient Descent Slow Down in Low-Precision Training?","summary":"Low-precision training has become crucial for reducing the computational and memory costs of large-scale deep learning. However, quantizing gradients introduces magnitude shrinkage, which can change how stochastic gradient descent (SGD) converges. In this study, we explore SGD convergence under a gradient shrinkage model, where each stochastic gradient is scaled by a factor \\( q_k \\in (0,1] \\). We show that this shrinkage affect the usual stepsize \\( μ_k \\) with an effective stepsize \\( μ_k q_k \\), slowing convergence when \\( q_{\\min} < 1 \\). With typical smoothness and bounded-variance assumptions, we prove that low-precision SGD still converges, but at a slower pace set by \\( q_{\\min} \\), and with a higher steady error level due to quantization effects. We analyze theoretically how lower numerical precision slows training by treating it as gradient shrinkage within the standard SGD convergence setup.","authors":["Vincent-Daniel Yun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05092v1","updated":"2026-01-08T16:39:37Z","published":"2026-01-08T16:39:37Z","title":"Precoding Matrix Indicator in the 5G NR Protocol: A Tutorial on 3GPP Beamforming Codebooks","summary":"This paper bridges this critical gap by providing a systematic examination of the beamforming codebook technology, i.e., precoding matrix indicator (PMI), in the 5G NR from theoretical, standardization, and implementation perspectives. We begin by introducing the background of beamforming in multiple-input multiple-output (MIMO) systems and the signaling procedures for codebook-based beamforming in practical 5G systems. Then, we establish the fundamentals of regular codebooks and port-selection codebooks in 3GPP standards. Next, we provide rigorous technical analysis of 3GPP codebook evolution spanning Releases 15-18, with particular focus on: 1) We elucidate the core principles underlying codebook design, 2) provide clear physical interpretations for each symbolic variable in the codebook formulas, summarized in tabular form, and 3) offer intuitive visual illustrations to explain how codebook parameters convey information. These essential pedagogical elements are almost entirely absent in the often-obscure standardization documents. Through mathematical modeling, performance benchmarking, feedback comparisons, and scenario-dependent applicability analysis, we provide researchers and engineers with a unified understanding of beamforming codebooks in real-world systems. Furthermore, we identify future directions and other beamforming scenarios for ongoing research and development efforts. This work serves as both an informative tutorial and a guidance for future research, facilitating more effective collaboration between academia and industry in advancing wireless communication technologies.","authors":["Boyu Ning","Haifan Yin","Sixu Liu","Hao Deng","Songjie Yang","Yuchen Zhang","Weidong Mei","David Gesbert","Jaebum Park","Robert W. Heath","Emil Björnson"],"pdf_url":"","comment":"This work has been accepted by IEEE COMST with manuscript number 00802-2025.R1"},{"id":"http://arxiv.org/abs/2601.05051v1","updated":"2026-01-08T15:56:17Z","published":"2026-01-08T15:56:17Z","title":"Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence","summary":"Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.","authors":["Jennifer D'Souza","Soren Auer","Eleni Poupaki","Alex Watkins","Anjana Devi","Riikka L. Puurunen","Bora Karasulu","Adrie Mackus","Erwin Kessels"],"pdf_url":"","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2601.05030v1","updated":"2026-01-08T15:39:44Z","published":"2026-01-08T15:39:44Z","title":"Refinements of Jensen's Inequality for Twice-Differentiable Convex Functions with Bounded Hessian","summary":"Jensen's inequality, attributed to Johan Jensen -- a Danish mathematician and engineer noted for his contributions to the theory of functions -- is a ubiquitous result in convex analysis, providing a fundamental lower bound for the expectation of a convex function. In this paper, we establish rigorous refinements of this inequality specifically for twice-differentiable functions with bounded Hessians. By utilizing Taylor expansions with integral remainders, we tried to bridge the gap between classical variance-based bounds and higher-precision estimates. We also discover explicit error terms governed by Gruss-type inequalities, allowing for the incorporation of skewness and kurtosis into the bound. Using these new theoretical tools, we improve upon existing estimates for the Shannon entropy of continuous distributions and the ergodic capacity of Rayleigh fading channels, demonstrating the practical efficacy of our refinements.","authors":["Sambhab Mishra"],"pdf_url":"","comment":"15 Pages. Comments welcome!"},{"id":"http://arxiv.org/abs/2601.00245v2","updated":"2026-01-08T15:17:56Z","published":"2026-01-01T07:38:07Z","title":"Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing","summary":"The rapid growth of artificial intelligence (AI) has brought novel data processing and generative capabilities but also escalating energy requirements. This challenge motivates renewed interest in neuromorphic computing principles, which promise brain-like efficiency through discrete and sparse activations, recurrent dynamics, and non-linear feedback. In fact, modern AI architectures increasingly embody neuromorphic principles through heavily quantized activations, state-space dynamics, and sparse attention mechanisms. This paper elaborates on the connections between neuromorphic models, state-space models, and transformer architectures through the lens of the distinction between intra-token processing and inter-token processing. Most early work on neuromorphic AI was based on spiking neural networks (SNNs) for intra-token processing, i.e., for transformations involving multiple channels, or features, of the same vector input, such as the pixels of an image. In contrast, more recent research has explored how neuromorphic principles can be leveraged to design efficient inter-token processing methods, which selectively combine different information elements depending on their contextual relevance. Implementing associative memorization mechanisms, these approaches leverage state-space dynamics or sparse self-attention. Along with a systematic presentation of modern neuromorphic AI models through the lens of intra-token and inter-token processing, training methodologies for neuromorphic AI models are also reviewed. These range from surrogate gradients leveraging parallel convolutional processing to local learning rules based on reinforcement learning mechanisms.","authors":["Osvaldo Simeone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.18845v2","updated":"2026-01-08T14:58:35Z","published":"2025-08-26T09:21:37Z","title":"Unique Decoding of Extended Subcodes of GRS Codes Using Error-Correcting Pairs","summary":"Extended Han-Zhang codes are a class of linear codes where each code is either a non-generalized Reed-Solomon (non-GRS) maximum distance separable (MDS) code or a near MDS (NMDS) code. They have important applications in communication, cryptography, and storage systems. While many algebraic properties and explicit constructions of extended Han-Zhang codes have been well studied in the literature, their decoding has been unexplored. In this paper, we focus on their decoding problems in terms of $\\ell$-error-correcting pairs ($\\ell$-ECPs) and deep holes. On the one hand, we determine the existence and specific forms of their $\\ell$-ECPs, and further present an explicit decoding algorithm for extended Han-Zhang codes based on these $\\ell$-ECPs, which can correct up to $\\ell$ errors in polynomial time, with $\\ell$ about half of the minimum distance. On the other hand, we determine the covering radius of extended Han-Zhang codes and characterize two classes of their deep holes, which are closely related to the maximum-likelihood decoding method. By employing these deep holes, we also construct more non-GRS MDS codes with larger lengths and dimensions, and discuss the monomial equivalence between them and the well-known Roth-Lempel codes. Some concrete examples are also given to support these results.","authors":["Yang Li","Zhenliang Lu","San Ling","Shixin Zhu","Kwok Yan Lam"],"pdf_url":"","comment":"The revised version for submission"},{"id":"http://arxiv.org/abs/2601.04980v1","updated":"2026-01-08T14:33:04Z","published":"2026-01-08T14:33:04Z","title":"Learning Sparsifying Transforms for mmWave Communication via $\\ell^4$-Norm Maximization","summary":"The high directionality of wave propagation at millimeter-wave (mmWave) carrier frequencies results in only a small number of significant transmission paths between user equipments and the basestation (BS). This sparse nature of wave propagation is revealed in the beamspace domain, which is traditionally obtained by taking the spatial discrete Fourier transform (DFT) across a uniform linear antenna array at the BS, where each DFT output is associated with a distinct beam. In recent years, beamspace processing has emerged as a promising technique to reduce baseband complexity and power consumption in all-digital massive multiuser (MU) multiple-input multiple-output (MIMO) systems operating at mmWave frequencies. However, it remains unclear whether the DFT is the optimal sparsifying transform for finite-dimensional antenna arrays. In this paper, we extend the framework of Zhai et al. for complete dictionary learning via $\\ell^4$-norm maximization to the complex case in order to learn new sparsifying transforms. We provide a theoretical foundation for $\\ell^4$-norm maximization and propose two suitable learning algorithms. We then utilize these algorithms (i) to assess the optimality of the DFT for sparsifying channel vectors theoretically and via simulations and (ii) to learn improved sparsifying transforms for real-world and synthetically generated channel vectors.","authors":["Sueda Taner","Christoph Studer"],"pdf_url":"","comment":"Submitted to a journal"},{"id":"http://arxiv.org/abs/2601.04862v1","updated":"2026-01-08T11:57:24Z","published":"2026-01-08T11:57:24Z","title":"Wireless Communication with Cross-Linked Rotatable Antenna Array: Architecture Design and Rotation Optimization","summary":"Rotatable antenna (RA) technology can harness additional spatial degrees of freedom by enabling the dynamic three-dimensional orientation control of each antenna. Unfortunately, the hardware cost and control complexity of traditional RA systems is proportional to the number of RAs. To address the issue, we consider a cross-linked (CL) RA structure, which enables the coordinated rotation of multiple antennas, thereby offering a cost-effective solution. To evaluate the performance of the CL-RA array, we investigate a CL-RA-aided uplink system. Specifically, we first establish system models for both antenna element-level and antenna panel-level rotation. Then, we formulate a sum rate maximization problem by jointly optimizing the receive beamforming at the base station and the rotation angles. For the antenna element-level rotation, we derive the optimal solution of the CL-RA array under the single-user case. Subsequently, for two rotation schemes, we propose an alternating optimization algorithm to solve the formulated problem in the multi-user case, where the receive beamforming and the antenna rotation angles are obtained by applying the minimum mean square error method and feasible direction method, respectively. In addition, considering the hardware limitations, we apply the genetic algorithm to address the discrete rotation angles selection problem. Simulation results show that by carefully designing the row-column partition scheme, the performance of the CL-RA architecture is quite close to that of the flexible antenna orientation scheme. Moreover, the CL antenna element-level scheme surpasses the CL antenna panel-level scheme by 25% and delivers a 128% performance improvement over conventional fixed-direction antennas.","authors":["Ailing Zheng","Qingqing Wu","Ziyuan Zheng","Qiaoyan Peng","Yanze Zhu","Honghao Wang","Wen Chen","Guoying Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04849v1","updated":"2026-01-08T11:38:48Z","published":"2026-01-08T11:38:48Z","title":"Stability of Constrained Optimization Models for Structured Signal Recovery","summary":"Recovering an unknown but structured signal from its measurements is a challenging problem with significant applications in fields such as imaging restoration, wireless communications, and signal processing. In this paper, we consider the inherent problem stems from the prior knowledge about the signal's structure, such as sparsity which is critical for signal recovery models. We investigate three constrained optimization models that effectively address this challenge, each leveraging distinct forms of structural priors to regularize the solution space. Our theoretical analysis demonstrates that these models exhibit robustness to noise while maintaining stability with respect to tuning parameters that is a crucial property for practical applications, when the parameter selection is often nontrivial. By providing theoretical foundations, our work supports their practical use in scenarios where measurement imperfections and model uncertainties are unavoidable. Furthermore, under mild conditions, we establish tradeoff between the sample complexity and the mismatch error.","authors":["Yijun Zhong","Yi Shen"],"pdf_url":"","comment":"29 pages"},{"id":"http://arxiv.org/abs/2505.21400v2","updated":"2026-01-08T11:30:06Z","published":"2025-05-27T16:24:20Z","title":"Breaking AR's Sampling Bottleneck: Provable Acceleration via Diffusion Language Models","summary":"Diffusion models have emerged as a powerful paradigm for modern generative modeling, demonstrating strong potential for large language models (LLMs). Unlike conventional autoregressive (AR) models that generate tokens sequentially, diffusion models allow for parallel sampling, offering a promising path to accelerate generation and eliminate the left-to-right generation constraints. Despite their empirical success, theoretical understandings of diffusion language models remain underdeveloped. In this work, we develop convergence guarantees for diffusion language models from an information-theoretic perspective. Our analysis demonstrates that the sampling error, measured by the Kullback-Leibler (KL) divergence, decays inversely with the number of iterations $T$ and scales linearly with the mutual information between tokens in the target text sequence. Crucially, our theory covers the regime $T<L$, where $L$ is the text sequence length. This justifies that high-quality samples can be generated with fewer iterations than $L$, thereby breaking the fundamental sampling bottleneck of $L$ steps required by AR models. We further establish matching upper and lower bounds, up to some constant factor, that shows the tightness of our convergence analysis. These results offer novel theoretical insights into the practical effectiveness of diffusion language models.","authors":["Gen Li","Changxiao Cai"],"pdf_url":"","comment":"This is the full version of a paper published at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2601.04815v1","updated":"2026-01-08T10:47:50Z","published":"2026-01-08T10:47:50Z","title":"Privacy-Utility Trade-offs Under Multi-Level Point-Wise Leakage Constraints","summary":"An information-theoretic privacy mechanism design is studied, where an agent observes useful data $Y$ which is correlated with the private data $X$. The agent wants to reveal the information to a user, hence, the agent utilizes a privacy mechanism to produce disclosed data $U$ that can be revealed. We assume that the agent has no direct access to $X$, i.e., the private data is hidden. We study privacy mechanism design that maximizes the disclosed information about $Y$, measured by the mutual information between $Y$ and $U$, while satisfying a point-wise constraint with different privacy leakage budgets. We introduce a new measure, called the \\emph{multi-level point-wise leakage}, which allows us to impose different leakage levels for different realizations of $U$. In contrast to previous studies on point-wise measures, which use the same leakage level for each realization, we consider a more general scenario in which each data point can leak information up to a different threshold. As a result, this concept also covers cases in which some data points should not leak any information about the private data, i.e., they must satisfy perfect privacy. In other words, a combination of perfect privacy and non-zero leakage can be considered. When the leakage is sufficiently small, concepts from information geometry allow us to locally approximate the mutual information. We show that when the leakage matrix $P_{X|Y}$ is invertible, utilizing this approximation leads to a quadratic optimization problem that has closed-form solution under some constraints. In particular, we show that it is sufficient to consider only binary $U$ to attain the optimal utility. This leads to simple privacy designs with low complexity which are based on finding the maximum singular value and singular vector of a matrix.","authors":["Amirreza Zamani","Parastoo Sadeghi","Mikael Skoglund"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.13593v2","updated":"2026-01-08T10:22:25Z","published":"2025-08-19T07:59:27Z","title":"Repeater Swarm-Assisted Cellular Systems: Interaction Stability and Performance Analysis","summary":"We consider a cellular massive MIMO system where swarms of wireless repeaters are deployed to improve coverage. These repeaters are full-duplex relays with small form factors that receive and instantaneously retransmit signals. They can be deployed in a plug-and-play manner at low cost, while being transparent to the network--conceptually they are active channel scatterers with amplification capabilities. Two fundamental questions need to be addressed in repeater deployments: (I) How can we prevent destructive effects of positive feedback caused by inter-repeater interaction (i.e., each repeater receives and amplifies signals from others)? (ii) How much performance improvement can be achieved given that repeaters also inject noise and may introduce more interference? To answer these questions, we first derive a generalized Nyquist stability criterion for the repeater swarm system, and provide an easy-to-check stability condition. Then, we study the uplink performance and develop an efficient iterative algorithm that jointly optimizes the repeater gains, user transmit powers, and receive combining weights to maximize the weighted sum rate while ensuring system stability. Numerical results corroborate our theoretical findings and show that the repeaters can significantly improve the system performance, both in sub-6 GHz and millimeter-wave bands. The results also warrant careful deployment to fully realize the benefits of repeaters, for example, by ensuring a high probability of line-of-sight links between repeaters and the base station.","authors":["Jianan Bai","Anubhab Chowdhury","Anders Hansson","Erik G. Larsson"],"pdf_url":"","comment":"16 pages, 13 figures. Accepted for publication in IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2507.23433v2","updated":"2026-01-08T09:49:04Z","published":"2025-07-31T11:15:20Z","title":"From Timestamps to Versions: Version AoI in Single- and Multi-Hop Networks","summary":"Timely and informative data dissemination in communication networks is essential for enhancing system performance and energy efficiency, as it reduces the transmission of outdated or redundant data. Timeliness metrics, such as Age of Information (AoI), effectively quantify data freshness; however, these metrics fail to account for the intrinsic informativeness of the content itself. To address this limitation, content-based metrics have been proposed that combine both timeliness and informativeness. Nevertheless, existing studies have predominantly focused on evaluating average metric values, leaving the complete distribution-particularly in multi-hop network scenarios-largely unexplored. In this paper, we provide a comprehensive analysis of the stationary distribution of the Version Age of Information (VAoI), a content-based metric, under various scheduling policies, including randomized stationary, uniform, and threshold-based policies, with transmission constraints in single-hop and multi-hop networks. We derive closed-form expressions for the stationary distribution and average VAoI under these scheduling approaches. Furthermore, for threshold-based scheduling, we analytically determine the optimal threshold value that minimizes VAoI and derive the corresponding optimal VAoI in closed form. Numerical evaluations verify our analytical findings, providing valuable insights into leveraging VAoI in the design of efficient communication networks.","authors":["Erfan Delfani","Nikolaos Pappas"],"pdf_url":"","comment":"Accepted by IEEE INFOCOM 2026"},{"id":"http://arxiv.org/abs/2601.04723v1","updated":"2026-01-08T08:37:33Z","published":"2026-01-08T08:37:33Z","title":"Feasibility Study Regarding Self-sustainable Reconfigurable Intelligent Surfaces","summary":"Without requiring operational costs such as cabling and powering while maintaining reconfigurable phase-shift capability, self-sustainable reconfigurable intelligent surfaces (ssRISs) can be deployed in locations inaccessible to conventional relays or base stations, offering a novel approach to enhance wireless coverage. This study assesses the feasibility of ssRIS deployment by analyzing two harvest-and-reflect (HaR) schemes: element-splitting (ES) and time-splitting (TS). We examine how element requirements scale with key system parameters, transmit power, data rate demands, and outage constraints under both line-of-sight (LOS) and non-line-of-sight (NLOS) ssRIS-to-user equipment (UE) channels. Analytical and numerical results reveal distinct feasibility characteristics. The TS scheme demonstrates better channel hardening gain, maintaining stable element requirements across varying outage margins, making it advantageous for indoor deployments with favorable harvesting conditions and moderate data rates. However, TS exhibits an element requirement that exponentially scales to harvesting difficulty and data rate. Conversely, the ES scheme shows only linear growth with harvesting difficulty, providing better feasibility under challenging outdoor scenarios. These findings establish that TS excels in benign environments, prioritizing reliability, while ES is preferable for demanding conditions requiring operational robustness.","authors":["Zhenyu Li","Ozan Alp Topal","Özlem Tuğfe Demir","Emil Björnson","Cicek Cavdar"],"pdf_url":"","comment":"5pages, 3 figures, submitted and accepted by IEEE Wireless Communication Letter"},{"id":"http://arxiv.org/abs/2512.20368v2","updated":"2026-01-08T08:22:15Z","published":"2025-12-23T13:53:53Z","title":"Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via Stability","summary":"Statistical inference in contextual bandits is challenging due to the adaptive, non-i.i.d. nature of the data. A growing body of work shows that classical least-squares inference can fail under adaptive sampling, and that valid confidence intervals for linear functionals typically require an inflation of order $\\sqrt{d \\log T}$. This phenomenon -- often termed the price of adaptivity -- reflects the intrinsic difficulty of reliable inference under general contextual bandit policies. A key structural condition that overcomes this limitation is the stability condition of Lai and Wei, which requires the empirical feature covariance to converge to a deterministic limit. When stability holds, the ordinary least-squares estimator satisfies a central limit theorem, and classical Wald-type confidence intervals remain asymptotically valid under adaptation, without incurring the $\\sqrt{d \\log T}$ price of adaptivity.\n  In this paper, we propose and analyze a regularized EXP4 algorithm for linear contextual bandits. Our first main result shows that this procedure satisfies the Lai--Wei stability condition and therefore admits valid Wald-type confidence intervals for linear functionals. We additionally provide quantitative rates of convergence in the associated central limit theorem. Our second result establishes that the same algorithm achieves regret guarantees that are minimax optimal up to logarithmic factors, demonstrating that stability and statistical efficiency can coexist within a single contextual bandit method. As an application of our theory, we show how it can be used to construct confidence intervals for the conditional average treatment effect (CATE) under adaptively collected data. Finally, we complement our theory with simulations illustrating the empirical normality of the resulting estimators and the sharpness of the corresponding confidence intervals.","authors":["Samya Praharaj","Koulik Khamaru"],"pdf_url":"","comment":"Revised version containing additional quantitative rate of convergence for the CLT"},{"id":"http://arxiv.org/abs/2601.04665v1","updated":"2026-01-08T07:23:58Z","published":"2026-01-08T07:23:58Z","title":"Air-to-Ground Communications for Internet of Things: UAV-based Coverage Hole Detection and Recovery","summary":"Uncrewed aerial vehicles (UAVs) play a pivotal role in ensuring seamless connectivity for Internet of Things (IoT) devices, particularly in scenarios where conventional terrestrial networks are constrained or temporarily unavailable. However, traditional coverage-hole detection approaches, such as minimizing drive tests, are costly, time-consuming, and reliant on outdated radio-environment data, making them unsuitable for real-time applications. To address these limitations, this paper proposes a UAV-assisted framework for real-time detection and recovery of coverage holes in IoT networks. In the proposed scheme, a patrol UAV is first dispatched to identify coverage holes in regions where the operational status of terrestrial base stations (BSs) is uncertain. Once a coverage hole is detected, one or more UAVs acting as aerial BSs are deployed by a satellite or nearby operational BSs to restore connectivity. The UAV swarm is organized based on Delaunay triangulation, enabling scalable deployment and tractable analytical characterization using stochastic geometry. Moreover, a collision-avoidance mechanism grounded in multi-agent system theory ensures safe and coordinated motion among multiple UAVs. Simulation results demonstrate that the proposed framework achieves high efficiency in both coverage-hole detection and on-demand connectivity restoration while significantly reducing operational cost and time.","authors":["Xiao Fan","Wenkun Wen","Peiran Wu","Junhui Zhao","Minghua Xia"],"pdf_url":"","comment":"17 pages, 14 figures, 2 tables; to appear in IEEE Internet of Things Journal"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2601.05200v1","updated":"2026-01-08T18:22:18Z","published":"2026-01-08T18:22:18Z","title":"Multivector Reranking in the Era of Strong First-Stage Retrievers","summary":"Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \\emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.","authors":["Silvio Martinico","Franco Maria Nardini","Cosimo Rulli","Rossano Venturini"],"pdf_url":"","comment":"17 pages, 2 figures, ECIR 2026"},{"id":"http://arxiv.org/abs/2601.05099v1","updated":"2026-01-08T16:46:06Z","published":"2026-01-08T16:46:06Z","title":"Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts","summary":"Identifying suitable datasets for a research question remains challenging because existing dataset search engines rely heavily on metadata quality and keyword overlap, which often fail to capture the semantic intent of scientific investigation. We introduce a literature-driven framework that discovers datasets from citation contexts in scientific papers, enabling retrieval grounded in actual research use rather than metadata availability. Our approach combines large-scale citation-context extraction, schema-guided dataset recognition with Large Language Models, and provenance-preserving entity resolution. We evaluate the system on eight survey-derived computer science queries and find that it achieves substantially higher recall than Google Dataset Search and DataCite Commons, with normalized recall ranging from an average of 47.47% to a highest value of 81.82%. Beyond recovering gold-standard datasets, the method also surfaces additional datasets not documented in the surveys. Expert assessments across five top-level Fields of Science indicate that a substantial portion of the additional datasets are considered high utility, and some are regarded as novel for the specific topics chosen by the experts. These findings establish citation-context mining as an effective and generalizable paradigm for dataset discovery, particularly in settings where datasets lack sufficient or reliable metadata. To support reproducibility and future extensions, we release our code, evaluation datasets, and results on GitHub (https://github.com/Fireblossom/citation-context-dataset-discovery).","authors":["Zhiyin Tan","Changxu Duan"],"pdf_url":"","comment":"Accepted at the 25th ACM/IEEE Joint Conference on Digital Libraries (JCDL 2025)"},{"id":"http://arxiv.org/abs/2601.05081v1","updated":"2026-01-08T16:27:04Z","published":"2026-01-08T16:27:04Z","title":"Dynamics in Search Engine Query Suggestions for European Politicians","summary":"Search engines are commonly used for online political information seeking. Yet, it remains unclear how search query suggestions for political searches that reflect the latent interest of internet users vary across countries and over time. We provide a systematic analysis of Google search engine query suggestions for European and national politicians. Using an original dataset of search query suggestions for European politicians collected in ten countries, we find that query suggestions are less stable over time in politicians' countries of origin, when the politicians hold a supranational role, and for female politicians. Moreover, query suggestions for political leaders and male politicians are more similar across countries. We conclude by discussing possible future directions for studying information search about European politicians in online search.","authors":["Franziska Pradel","Fabian Haak","Sven-Oliver Proksch","Philipp Schaer"],"pdf_url":"","comment":"11 pages; 3 figures; 6 tables; published as a conference paper at WebSci '24 (May 21-24, 2024, Stuttgart, Germany)"},{"id":"http://arxiv.org/abs/2601.04918v1","updated":"2026-01-08T13:17:40Z","published":"2026-01-08T13:17:40Z","title":"Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective","summary":"With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.","authors":["Ziwen Wang","Shangshang Yang","Xiaoshan Yu","Haiping Ma","Xingyi Zhang"],"pdf_url":"","comment":"KDD2026, 15 pages"},{"id":"http://arxiv.org/abs/2506.10520v4","updated":"2026-01-08T09:46:24Z","published":"2025-06-12T09:28:43Z","title":"Macro Graph of Experts for Billion-Scale Multi-Task Recommendation","summary":"Graph-based multi-task learning at billion-scale presents a significant challenge, as different tasks correspond to distinct billion-scale graphs. Traditional multi-task learning methods often neglect these graph structures, relying solely on individual user and item embeddings. However, disregarding graph structures overlooks substantial potential for improving performance. In this paper, we introduce the Macro Graph of Experts (MGOE) framework, the first approach capable of leveraging macro graph embeddings to capture task-specific macro features while modeling the correlations between task-specific experts. Specifically, we propose the concept of a Macro Graph Bottom, which, for the first time, enables multi-task learning models to incorporate graph information effectively. We design the Macro Prediction Tower to dynamically integrate macro knowledge across tasks. MGOE has been deployed at scale, powering multi-task learning for a leading billion-scale recommender system, Alibaba. Extensive offline experiments conducted on three public benchmark datasets demonstrate its superiority over state-of-the-art multi-task learning methods, establishing MGOE as a breakthrough in multi-task graph-based recommendation. Furthermore, online A/B tests confirm the superiority of MGOE in billion-scale recommender systems.","authors":["Hongyu Yao","Zijin Hong","Hao Chen","Zhiqing Li","Qijie Shen","Zuobin Ying","Qihua Feng","Huan Gong","Feiran Huang"],"pdf_url":"","comment":"Accepted to KDD2026"},{"id":"http://arxiv.org/abs/2601.04768v1","updated":"2026-01-08T09:36:41Z","published":"2026-01-08T09:36:41Z","title":"LANGSAE EDITING: Improving Multilingual Information Retrieval via Post-hoc Language Identity Removal","summary":"Dense retrieval in multilingual settings often searches over mixed-language collections, yet multilingual embeddings encode language identity alongside semantics. This language signal can inflate similarity for same-language pairs and crowd out relevant evidence written in other languages. We propose LANGSAE EDITING, a post-hoc sparse autoencoder trained on pooled embeddings that enables controllable removal of language-identity signal directly in vector space. The method identifies language-associated latent units using cross-language activation statistics, suppresses these units at inference time, and reconstructs embeddings in the original dimensionality, making it compatible with existing vector databases without retraining the base encoder or re-encoding raw text. Experiments across multiple languages show consistent improvements in ranking quality and cross-language coverage, with especially strong gains for script-distinct languages.","authors":["Dongjun Kim","Jeongho Yoon","Chanjun Park","Heuiseok Lim"],"pdf_url":"","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2508.15658v3","updated":"2026-01-08T09:23:05Z","published":"2025-08-21T15:45:10Z","title":"SurGE: A Benchmark and Evaluation Framework for Scientific Survey Generation","summary":"The rapid growth of academic literature makes the manual creation of scientific surveys increasingly infeasible. While large language models show promise for automating this process, progress in this area is hindered by the absence of standardized benchmarks and evaluation protocols. To bridge this critical gap, we introduce SurGE (Survey Generation Evaluation), a new benchmark for scientific survey generation in computer science. SurGE consists of (1) a collection of test instances, each including a topic description, an expert-written survey, and its full set of cited references, and (2) a large-scale academic corpus of over one million papers. In addition, we propose an automated evaluation framework that measures the quality of generated surveys across four dimensions: comprehensiveness, citation accuracy, structural organization, and content quality. Our evaluation of diverse LLM-based methods demonstrates a significant performance gap, revealing that even advanced agentic frameworks struggle with the complexities of survey generation and highlighting the need for future research in this area. We have open-sourced all the code, data, and models at: https://github.com/oneal2000/SurGE","authors":["Weihang Su","Anzhe Xie","Qingyao Ai","Jianming Long","Jiaxin Mao","Ziyi Ye","Yiqun Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04745v1","updated":"2026-01-08T09:11:33Z","published":"2026-01-08T09:11:33Z","title":"KnowMe-Bench: Benchmarking Person Understanding for Lifelong Digital Companions","summary":"Existing long-horizon memory benchmarks mostly use multi-turn dialogues or synthetic user histories, which makes retrieval performance an imperfect proxy for person understanding. We present \\BenchName, a publicly releasable benchmark built from long-form autobiographical narratives, where actions, context, and inner thoughts provide dense evidence for inferring stable motivations and decision principles. \\BenchName~reconstructs each narrative into a flashback-aware, time-anchored stream and evaluates models with evidence-linked questions spanning factual recall, subjective state attribution, and principle-level reasoning. Across diverse narrative sources, retrieval-augmented systems mainly improve factual accuracy, while errors persist on temporally grounded explanations and higher-level inferences, highlighting the need for memory mechanisms beyond retrieval. Our data is in \\href{KnowMeBench}{https://github.com/QuantaAlpha/KnowMeBench}.","authors":["Tingyu Wu","Zhisheng Chen","Ziyan Weng","Shuhe Wang","Chenglong Li","Shuo Zhang","Sen Hu","Silin Wu","Qizhen Lan","Huacan Wang","Ronghao Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04674v1","updated":"2026-01-08T07:38:46Z","published":"2026-01-08T07:38:46Z","title":"PROMISE: Process Reward Models Unlock Test-Time Scaling Laws in Generative Recommendations","summary":"Generative Recommendation has emerged as a promising paradigm, reformulating recommendation as a sequence-to-sequence generation task over hierarchical Semantic IDs. However, existing methods suffer from a critical issue we term Semantic Drift, where errors in early, high-level tokens irreversibly divert the generation trajectory into irrelevant semantic subspaces. Inspired by Process Reward Models (PRMs) that enhance reasoning in Large Language Models, we propose Promise, a novel framework that integrates dense, step-by-step verification into generative models. Promise features a lightweight PRM to assess the quality of intermediate inference steps, coupled with a PRM-guided Beam Search strategy that leverages dense feedback to dynamically prune erroneous branches. Crucially, our approach unlocks Test-Time Scaling Laws for recommender systems: by increasing inference compute, smaller models can match or surpass larger models. Extensive offline experiments and online A/B tests on a large-scale platform demonstrate that Promise effectively mitigates Semantic Drift, significantly improving recommendation accuracy while enabling efficient deployment.","authors":["Chengcheng Guo","Kuo Cai","Yu Zhou","Qiang Luo","Ruiming Tang","Han Li","Kun Gai","Guorui Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.03957v2","updated":"2026-01-08T07:03:20Z","published":"2025-04-04T21:49:42Z","title":"Practical Poisoning Attacks against Retrieval-Augmented Generation","summary":"Large language models (LLMs) have demonstrated impressive natural language processing abilities but face challenges such as hallucination and outdated knowledge. Retrieval-Augmented Generation (RAG) has emerged as a state-of-the-art approach to mitigate these issues. While RAG enhances LLM outputs, it remains vulnerable to poisoning attacks. Recent studies show that injecting poisoned text into the knowledge database can compromise RAG systems, but most existing attacks assume that the attacker can insert a sufficient number of poisoned texts per query to outnumber correct-answer texts in retrieval, an assumption that is often unrealistic. To address this limitation, we propose CorruptRAG, a practical poisoning attack against RAG systems in which the attacker injects only a single poisoned text, enhancing both feasibility and stealth. Extensive experiments conducted on multiple large-scale datasets demonstrate that CorruptRAG achieves higher attack success rates than existing baselines.","authors":["Baolei Zhang","Yuxi Chen","Zhuqing Liu","Lihai Nie","Tong Li","Zheli Liu","Minghong Fang"],"pdf_url":"","comment":"To appear in ACM SACMAT 2026"},{"id":"http://arxiv.org/abs/2601.04651v1","updated":"2026-01-08T06:57:03Z","published":"2026-01-08T06:57:03Z","title":"Adversarial Yet Cooperative: Multi-Perspective Reasoning in Retrieved-Augmented Language Models","summary":"Recent advances in synergizing large reasoning models (LRMs) with retrieval-augmented generation (RAG) have shown promising results, yet two critical challenges remain: (1) reasoning models typically operate from a single, unchallenged perspective, limiting their ability to conduct deep, self-correcting reasoning over external documents, and (2) existing training paradigms rely excessively on outcome-oriented rewards, which provide insufficient signal for shaping the complex, multi-step reasoning process. To address these issues, we propose an Reasoner-Verifier framework named Adversarial Reasoning RAG (ARR). The Reasoner and Verifier engage in reasoning on retrieved evidence and critiquing each other's logic while being guided by process-aware advantage that requires no external scoring model. This reward combines explicit observational signals with internal model uncertainty to jointly optimize reasoning fidelity and verification rigor. Experiments on multiple benchmarks demonstrate the effectiveness of our method.","authors":["Can Xu","Lingyong Yan","Jiayi Wu","Haosen Wang","Shuaiqiang Wang","Yuchen Li","Jizhou Huang","Dawei Yin","Xiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04646v1","updated":"2026-01-08T06:44:40Z","published":"2026-01-08T06:44:40Z","title":"Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search","summary":"Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This \"dark data\" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \\textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \\textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \\textbf{consistency filtering} and relevance assignment. We further propose a practical \\textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.","authors":["Prateek Jain","Shabari S Nair","Ritesh Goru","Prakhar Agarwal","Ajay Yadav","Yoga Sri Varshan Varadharajan","Constantine Caramanis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04618v1","updated":"2026-01-08T05:46:50Z","published":"2026-01-08T05:46:50Z","title":"Adaptive Retrieval for Reasoning-Intensive Retrieval","summary":"We study leveraging adaptive retrieval to ensure sufficient \"bridge\" documents are retrieved for reasoning-intensive retrieval. Bridge documents are those that contribute to the reasoning process yet are not directly relevant to the initial query. While existing reasoning-based reranker pipelines attempt to surface these documents in ranking, they suffer from bounded recall. Naive solution with adaptive retrieval into these pipelines often leads to planning error propagation. To address this, we propose REPAIR, a framework that bridges this gap by repurposing reasoning plans as dense feedback signals for adaptive retrieval. Our key distinction is enabling mid-course correction during reranking through selective adaptive retrieval, retrieving documents that support the pivotal plan. Experimental results on reasoning-intensive retrieval and complex QA tasks demonstrate that our method outperforms existing baselines by 5.6%pt.","authors":["Jongho Kim","Jaeyoung Kim","Seung-won Hwang","Jihyuk Kim","Yu Jin Kim","Moontae Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19514v3","updated":"2026-01-08T04:04:04Z","published":"2025-11-24T03:00:04Z","title":"SCoTER: Structured Chain-of-Thought Transfer for Enhanced Recommendation","summary":"Harnessing the reasoning power of Large Language Models (LLMs) for recommender systems is hindered by two fundamental challenges. First, current approaches lack a mechanism for automated, data-driven discovery of effective reasoning patterns, relying instead on brittle manual templates or unstable zero-shot prompting. Second, they employ structure-collapsing integration: direct prompting incurs prohibitive online inference costs, while feature extraction collapses reasoning chains into single vectors, discarding stepwise logic. To address these challenges, we propose SCoTER (Structured Chain-of-Thought Transfer for Enhanced Recommendation), a unified framework that treats pattern discovery and structure-aware transfer as a jointly optimized problem. Specifically, SCoTER operationalizes this through two synergistic components: a GVM pipeline for automated pattern discovery and a structure-preserving integration architecture that transfers stepwise logic to efficient models. Formally, we provide information-theoretic justification proving that structure-preserving transfer achieves tighter performance bounds than structure-agnostic alternatives. Empirically, experiments on four benchmarks demonstrate improvements of 3.75\\%-11.59\\% over a strong TIGER backbone. Moreover, in production deployment on the Tencent Advertising Platform, SCoTER achieved a 2.14\\% lift in Gross Merchandise Value (GMV) while eliminating online LLM inference costs. Overall, SCoTER establishes a principled and production-validated blueprint for transferring structured LLM reasoning to large-scale recommender systems.","authors":["Yang Wu","Qian Li","Yuling Xiong","Hongbo Tang","Xun Liu","Jun Zhang","Huan Yu","Jie Jiang","Hailong Shi"],"pdf_url":"","comment":"Due to some internal company policies, we need to temporarily withdraw the paper. We will resubmit it after a further review"},{"id":"http://arxiv.org/abs/2601.04568v1","updated":"2026-01-08T03:53:05Z","published":"2026-01-08T03:53:05Z","title":"Neurosymbolic Retrievers for Retrieval-augmented Generation","summary":"Retrieval Augmented Generation (RAG) has made significant strides in overcoming key limitations of large language models, such as hallucination, lack of contextual grounding, and issues with transparency. However, traditional RAG systems consist of three interconnected neural components - the retriever, re-ranker, and generator - whose internal reasoning processes remain opaque. This lack of transparency complicates interpretability, hinders debugging efforts, and erodes trust, especially in high-stakes domains where clear decision-making is essential. To address these challenges, we introduce the concept of Neurosymbolic RAG, which integrates symbolic reasoning using a knowledge graph with neural retrieval techniques. This new framework aims to answer two primary questions: (a) Can retrievers provide a clear and interpretable basis for document selection? (b) Can symbolic knowledge enhance the clarity of the retrieval process? We propose three methods to improve this integration. First is MAR (Knowledge Modulation Aligned Retrieval) that employs modulation networks to refine query embeddings using interpretable symbolic features, thereby making document matching more explicit. Second, KG-Path RAG enhances queries by traversing knowledge graphs to improve overall retrieval quality and interpretability. Lastly, Process Knowledge-infused RAG utilizes domain-specific tools to reorder retrieved content based on validated workflows. Preliminary results from mental health risk assessment tasks indicate that this neurosymbolic approach enhances both transparency and overall performance","authors":["Yash Saxena","Manas Gaur"],"pdf_url":"","comment":"8 pages, 2 Figures, To Appear in IEEE Intelligent Systems"},{"id":"http://arxiv.org/abs/2601.04554v1","updated":"2026-01-08T03:33:43Z","published":"2026-01-08T03:33:43Z","title":"Exploring Recommender System Evaluation: A Multi-Modal User Agent Framework for A/B Testing","summary":"In recommender systems, online A/B testing is a crucial method for evaluating the performance of different models. However, conducting online A/B testing often presents significant challenges, including substantial economic costs, user experience degradation, and considerable time requirements. With the Large Language Models' powerful capacity, LLM-based agent shows great potential to replace traditional online A/B testing. Nonetheless, current agents fail to simulate the perception process and interaction patterns, due to the lack of real environments and visual perception capability. To address these challenges, we introduce a multi-modal user agent for A/B testing (A/B Agent). Specifically, we construct a recommendation sandbox environment for A/B testing, enabling multimodal and multi-page interactions that align with real user behavior on online platforms. The designed agent leverages multimodal information perception, fine-grained user preferences, and integrates profiles, action memory retrieval, and a fatigue system to simulate complex human decision-making. We validated the potential of the agent as an alternative to traditional A/B testing from three perspectives: model, data, and features. Furthermore, we found that the data generated by A/B Agent can effectively enhance the capabilities of recommendation models. Our code is publicly available at https://github.com/Applied-Machine-Learning-Lab/ABAgent.","authors":["Wenlin Zhang","Xiangyang Li","Qiyuan Ge","Kuicai Dong","Pengyue Jia","Xiaopeng Li","Zijian Zhang","Maolin Wang","Yichao Wang","Huifeng Guo","Ruiming Tang","Xiangyu Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02955v2","updated":"2026-01-08T03:20:47Z","published":"2026-01-06T11:59:02Z","title":"HarmonRank: Ranking-aligned Multi-objective Ensemble for Live-streaming E-commerce Recommendation","summary":"Recommendation for live-streaming e-commerce is gaining increasing attention due to the explosive growth of the live streaming economy. Different from traditional e-commerce, live-streaming e-commerce shifts the focus from products to streamers, which requires ranking mechanism to balance both purchases and user-streamer interactions for long-term ecology. To trade off multiple objectives, a popular solution is to build an ensemble model to integrate multi-objective scores into a unified score. The ensemble model is usually supervised by multiple independent binary classification losses of all objectives. However, this paradigm suffers from two inherent limitations. First, the optimization direction of the binary classification task is misaligned with the ranking task (evaluated by AUC). Second, this paradigm overlooks the alignment between objectives, e.g., comment and buy behaviors are partially dependent which can be revealed in labels correlations. The model can achieve better trade-offs if it learns the aligned parts of ranking abilities among different objectives.\n  To mitigate these limitations, we propose a novel multi-objective ensemble framework HarmonRank to fulfill both alignment to the ranking task and alignment among objectives. For alignment to ranking, we formulate ranking metric AUC as a rank-sum problem and utilize differentiable ranking techniques for ranking-oriented optimization. For inter-objective alignment, we change the original one-step ensemble paradigm to a two-step relation-aware ensemble scheme.\n  Extensive offline experiments results on two industrial datasets and online experiments demonstrate that our approach significantly outperforms existing state-of-the-art methods. The proposed method has been fully deployed in Kuaishou's live-streaming e-commerce recommendation platform with 400 million DAUs, contributing over 2% purchase gain.","authors":["Boyang Xia","Zhou Yu","Zhiliang Zhu","Hanxiao Sun","Biyun Han","Jun Wang","Runnan Liu","Wenwu Ou"],"pdf_url":"","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.04531v1","updated":"2026-01-08T02:56:04Z","published":"2026-01-08T02:56:04Z","title":"Self-MedRAG: a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering","summary":"Large Language Models (LLMs) have demonstrated significant potential in medical Question Answering (QA), yet they remain prone to hallucinations and ungrounded reasoning, limiting their reliability in high-stakes clinical scenarios. While Retrieval-Augmented Generation (RAG) mitigates these issues by incorporating external knowledge, conventional single-shot retrieval often fails to resolve complex biomedical queries requiring multi-step inference. To address this, we propose Self-MedRAG, a self-reflective hybrid framework designed to mimic the iterative hypothesis-verification process of clinical reasoning. Self-MedRAG integrates a hybrid retrieval strategy, combining sparse (BM25) and dense (Contriever) retrievers via Reciprocal Rank Fusion (RRF) to maximize evidence coverage. It employs a generator to produce answers with supporting rationales, which are then assessed by a lightweight self-reflection module using Natural Language Inference (NLI) or LLM-based verification. If the rationale lacks sufficient evidentiary support, the system autonomously reformulates the query and iterates to refine the context. We evaluated Self-MedRAG on the MedQA and PubMedQA benchmarks. The results demonstrate that our hybrid retrieval approach significantly outperforms single-retriever baselines. Furthermore, the inclusion of the self-reflective loop yielded substantial gains, increasing accuracy on MedQA from 80.00% to 83.33% and on PubMedQA from 69.10% to 79.82%. These findings confirm that integrating hybrid retrieval with iterative, evidence-based self-reflection effectively reduces unsupported claims and enhances the clinical reliability of LLM-based systems.","authors":["Jessica Ryan","Alexander I. Gumilang","Robert Wiliam","Derwin Suhartono"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04469v1","updated":"2026-01-08T01:05:51Z","published":"2026-01-08T01:05:51Z","title":"SampoNLP: A Self-Referential Toolkit for Morphological Analysis of Subword Tokenizers","summary":"The quality of subword tokenization is critical for Large Language Models, yet evaluating tokenizers for morphologically rich Uralic languages is hampered by the lack of clean morpheme lexicons.\n  We introduce SampoNLP, a corpus-free toolkit for morphological lexicon creation using MDL-inspired Self-Referential Atomicity Scoring, which filters composite forms through internal structural cues - suited for low-resource settings.\n  Using the high-purity lexicons generated by SampoNLP for Finnish, Hungarian, and Estonian, we conduct a systematic evaluation of BPE tokenizers across a range of vocabulary sizes (8k-256k). We propose a unified metric, the Integrated Performance Score (IPS), to navigate the trade-off between morpheme coverage and over-splitting. By analyzing the IPS curves, we identify the \"elbow points\" of diminishing returns and provide the first empirically grounded recommendations for optimal vocabulary sizes (k) in these languages. Our study not only offers practical guidance but also quantitatively demonstrates the limitations of standard BPE for highly agglutinative languages. The SampoNLP library and all generated resources are made publicly available: https://github.com/AragonerUA/SampoNLP","authors":["Iaroslav Chelombitko","Ekaterina Chelombitko","Aleksey Komissarov"],"pdf_url":"","comment":"Accepted to the 10th International Workshop on Computational Linguistics for Uralic Languages (IWCLUL 2025), pp. 57-67"},{"id":"http://arxiv.org/abs/2509.11080v3","updated":"2026-01-08T00:15:19Z","published":"2025-09-14T04:06:03Z","title":"Membership Inference Attacks on Recommender System: A Survey","summary":"Recommender systems (RecSys) have been widely applied to various applications, including E-commerce, finance, healthcare, social media and have become increasingly influential in shaping user behavior and decision-making, highlighting their growing impact in various domains. However, recent studies have shown that RecSys are vulnerable to membership inference attacks (MIAs), which aim to infer whether user interaction record was used to train a target model or not. MIAs on RecSys models can directly lead to a privacy breach. For example, via identifying the fact that a purchase record that has been used to train a RecSys associated with a specific user, an attacker can infer that user's special quirks. In recent years, MIAs have been shown to be effective on other ML tasks, e.g., classification models and natural language processing. However, traditional MIAs are ill-suited for RecSys due to the unseen posterior probability. Although MIAs on RecSys form a newly emerging and rapidly growing research area, there has been no systematic survey on this topic yet. In this article, we conduct the first comprehensive survey on RecSys MIAs. This survey offers a comprehensive review of the latest advancements in RecSys MIAs, exploring the design principles, challenges, attack and defense associated with this emerging field. We provide a unified taxonomy that categorizes different RecSys MIAs based on their characterizations and discuss their pros and cons. Based on the limitations and gaps identified in this survey, we point out several promising future research directions to inspire the researchers who wish to follow this area. This survey not only serves as a reference for the research community but also provides a clear description for researchers outside this research domain.","authors":["Jiajie He","Xintong Chen","Xinyang Fang","Min-Chun Chen","Yuechun Gu","Keke Chen"],"pdf_url":"","comment":"under review in ACM Survey"}],"Discrete Mathematics":[{"id":"http://arxiv.org/abs/2601.05195v1","updated":"2026-01-08T18:18:10Z","published":"2026-01-08T18:18:10Z","title":"Basis Number of Graphs Excluding Minors","summary":"The basis number of a graph $G$ is the minimum $k$ such that the cycle space of $G$ is generated by a family of cycles using each edge at most $k$ times. A classical result of Mac Lane states that planar graphs are exactly graphs with basis number at most 2, and more generally, graphs embedded on a fixed surface are known to have bounded basis number. Generalising this, we prove that graphs excluding a fixed minor $H$ have bounded basis number.\n  Our proof uses the Graph Minor Structure Theorem, which requires us to understand how basis number behaves in tree-decompositions. In particular, we prove that graphs of treewidth $k$ have basis number bounded by some function of $k$. We handle tree-decompositions using the proof framework developed by Bojańczyk and Pilipczuk in their proof of Courcelle's conjecture.\n  Combining our approach with independent results of Miraftab, Morin and Yuditsky (2025) on basis number and path-decompositions, one can moreover improve our upper bound to a polynomial one: there exists an absolute constant $c>0$ such that every $H$-minor free graph has basis number $O(|H|^c)$.","authors":["Colin Geniet","Ugo Giocanti"],"pdf_url":"","comment":"48 pages, 5 figures. Results from Section 4 have been proved independently by Babak Miraftab, Pat Morin and Yelena Yuditsky, with improved polynomial bounds"},{"id":"http://arxiv.org/abs/2601.04756v1","updated":"2026-01-08T09:22:22Z","published":"2026-01-08T09:22:22Z","title":"Branch-width of connectivity functions is fixed-parameter tractable","summary":"A connectivity function on a finite set $V$ is a symmetric submodular function $f \\colon 2^V \\to \\mathbb{Z}$ with $f(\\emptyset)=0$. We prove that finding a branch-decomposition of width at most $k$ for a connectivity function given by an oracle is fixed-parameter tractable (FPT), by providing an algorithm of running time $2^{O(k^2)} γn^6 \\log n$, where $γ$ is the time to compute $f(X)$ for any set $X$, and $n = |V|$. This improves the previous algorithm by Oum and Seymour [J. Combin. Theory Ser.~B, 2007], which runs in time $γn^{O(k)}$. Our algorithm can be applied to rank-width of graphs, branch-width of matroids, branch-width of (hyper)graphs, and carving-width of graphs. This resolves an open problem asked by Hliněný [SIAM J. Comput., 2005], who asked whether branch-width of matroids given by the rank oracle is fixed-parameter tractable. Furthermore, our algorithm improves the best known dependency on $k$ in the running times of FPT algorithms for graph branch-width, rank-width, and carving-width.","authors":["Tuukka Korhonen","Sang-il Oum"],"pdf_url":"","comment":"13 pages"},{"id":"http://arxiv.org/abs/2601.04637v1","updated":"2026-01-08T06:14:22Z","published":"2026-01-08T06:14:22Z","title":"Large induced forests in planar multigraphs","summary":"For a graph $G$ on $n$ vertices, denote by $a(G)$ the number of vertices in the largest induced forest in $G$. The Albertson-Berman conjecture, which is open since 1979, states that $a(G) \\geq \\frac{n}{2}$ for all simple planar graphs $G$. We show that the version of this problem for multigraphs (allowing parallel edges) is easily reduced to the problem about the independence number of simple planar graphs. Specifically, we prove that $a(M) \\geq \\frac{n}{4}$ for all planar multigraphs $M$ and that this lower bound is tight. Then, we study the case when the number of pairs of vertices with parallel edges, which we denote by $k$, is small. In particular, we prove the lower bound $a(M) \\geq \\frac{2}{5}n-\\frac{k}{10}$ and that the Albertson-Berman conjecture for simple planar graphs, assuming that it holds, would imply the lower bound $a(M) \\geq \\frac{n-k}{2}$ for planar multigraphs, which would be better than the general lower bound when $k$ is small. Finally, we study the variant of the problem where the plane multigraphs are prohibited from having $2$-faces, which is the main non-trivial problem that we introduce in this article. For that variant without $2$-faces, we prove the lower bound $a(M) \\geq \\frac{3}{10}n+\\frac{7}{30}$ and give a construction of an infinite sequence of multigraphs with $a(M)=\\frac{3}{7}n+\\frac{4}{7}$.","authors":["Mikhail Makarov"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2508.06489v4","updated":"2026-01-08T00:49:32Z","published":"2025-08-08T17:57:35Z","title":"An Incentive-Compatible Semi-Parallel Proof-of-Work Protocol","summary":"Parallel Proof-of-Work (PoW) protocols have been suggested in the literature to improve the safety guarantees, transaction throughput and confirmation latencies of Nakamoto consensus. In this work, we first consider the existing parallel PoW protocols and develop hard-coded incentive attack structures. Our theoretical results and simulations show that the existing parallel PoW protocols are more vulnerable to incentive attacks than the Nakamoto consensus, e.g., attacks have smaller profitability threshold and they result in higher relative rewards. Next, we introduce a voting-based semi-parallel PoW protocol that outperforms both Nakamoto consensus and the existing parallel PoW protocols from most practical perspectives such as communication overheads, throughput, transaction conflicts, incentive compatibility of the protocol as well as a fair distribution of transaction fees among the voters and the leaders. We use state-of-the-art analysis to evaluate the consistency of the protocol and consider Markov decision process (MDP) models to substantiate our claims about the resilience of our protocol against incentive attacks.","authors":["Mustafa Doger","Sennur Ulukus"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.11820v5","updated":"2026-01-08T00:31:00Z","published":"2025-11-30T12:20:03Z","title":"Toward P vs NP: An Observer-Theoretic Separation via SPDP Rank and a ZFC-Equivalent Foundation within the N-Frame Model","summary":"We present a self-contained separation framework for P vs NP developed entirely within ZFC. The approach consists of: (i) a deterministic, radius-1 compilation from uniform polynomial-time Turing computation to local sum-of-squares (SoS) polynomials with polylogarithmic contextual entanglement width (CEW); (ii) a formal Width-to-Rank upper bound for the resulting SPDP matrices at matching parameters; (iii) an NP-side identity-minor lower bound in the same encoding; and (iv) a rank-monotone, instance-uniform extraction map from the compiled P-side polynomials to the NP family. Together these yield a contradiction under the assumption P = NP, establishing a separation.\n  We develop a correspondence between CEW, viewed as a quantitative measure of computational contextuality, and SPDP rank, yielding a unified criterion for complexity separation. We prove that bounded-CEW observers correspond to polynomial-rank computations (the class P), while unbounded CEW characterizes the class NP. This implies that exponential SPDP rank for #3SAT and related hard families forces P != NP within the standard framework of complexity theory.\n  Key technical components include: (1) constructive lower bounds on SPDP rank via Ramanujan-Tseitin expander families; (2) a non-circular reduction from Turing-machine computation to low-rank polynomial evaluation; (3) a codimension-collapse lemma ensuring that rank amplification cannot occur within polynomial resources; and (4) proofs of barrier immunity against relativization, natural proofs, and algebrization. The result is a complete ZFC proof architecture whose primitives and compositions are fully derived, with community verification and machine-checked formalization left as future work.","authors":["Darren J. Edwards"],"pdf_url":"","comment":"208 pages, 15 Tables, 18 Figures"}],"Symbolic Computation":[{"id":"http://arxiv.org/abs/2601.05026v1","updated":"2026-01-08T15:33:58Z","published":"2026-01-08T15:33:58Z","title":"A data structure for monomial ideals with applications to signature Gröbner bases","summary":"We introduce monomial divisibility diagrams (MDDs), a data structure for monomial ideals that supports insertion of new generators and fast membership tests. MDDs stem from a canonical tree representation by maximally sharing equal subtrees, yielding a directed acyclic graph. We establish basic complexity bounds for membership and insertion, and study empirically the size of MDDs. As an application, we integrate MDDs into the signature Gröbner basis implementation of the Julia package AlgebraicSolving.jl. Membership tests in monomial ideals are used to detect some reductions to zero, and the use of MDDs leads to substantial speed-ups.","authors":["Pierre Lairez","Rafael Mohr","Théo Ternier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04901v1","updated":"2026-01-08T12:56:55Z","published":"2026-01-08T12:56:55Z","title":"Rigorous numerical computation of the Stokes multipliers for linear differential equations with single level one","summary":"We describe a practical algorithm for computing the Stokes multipliers of a linear differential equation with polynomial coefficients at an irregular singular point of single level one. The algorithm follows a classical approach based on Borel summation and numerical ODE solving, but avoids a large amount of redundant work compared to a direct implementation. It applies to differential equations of arbitrary order, with no genericity assumption, and is suited to high-precision computations. In addition, we present an open-source implementation of this algorithm in the SageMath computer algebra system and illustrate its use with several examples. Our implementation supports arbitrary-precision computations and automatically provides rigorous error bounds. The article assumes minimal prior knowledge of the asymptotic theory of meromorphic differential equations and provides an elementary introduction to the linear Stokes phenomenon that may be of independent interest.","authors":["Michèle Loday-Richaud","Marc Mezzarobba","Pascal Remy"],"pdf_url":"","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2601.05245v1","updated":"2026-01-08T18:59:32Z","published":"2026-01-08T18:59:32Z","title":"Optimal Lower Bounds for Online Multicalibration","summary":"We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.\n  In the general setting where group functions can depend on both context and the learner's predictions, we prove an $Ω(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.\n  We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\\widetildeΩ(T^{2/3})$ lower bound for online multicalibration via a $Θ(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.","authors":["Natalie Collina","Jiuyao Lu","Georgy Noarov","Aaron Roth"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05242v1","updated":"2026-01-08T18:59:24Z","published":"2026-01-08T18:59:24Z","title":"GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization","summary":"As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.","authors":["Shih-Yang Liu","Xin Dong","Ximing Lu","Shizhe Diao","Peter Belcak","Mingjie Liu","Min-Hung Chen","Hongxu Yin","Yu-Chiang Frank Wang","Kwang-Ting Cheng","Yejin Choi","Jan Kautz","Pavlo Molchanov"],"pdf_url":"","comment":"NVIDIA-Tech Report"},{"id":"http://arxiv.org/abs/2601.05240v1","updated":"2026-01-08T18:58:34Z","published":"2026-01-08T18:58:34Z","title":"Robust Reasoning as a Symmetry-Protected Topological Phase","summary":"Large language models suffer from \"hallucinations\"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a \"Metric Phase,\" where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic \"mass gap,\" maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \\times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\\times$ beyond training ($L=50 \\to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.","authors":["Ilmo Sung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05232v1","updated":"2026-01-08T18:57:01Z","published":"2026-01-08T18:57:01Z","title":"Measuring and Fostering Peace through Machine Learning and Artificial Intelligence","summary":"We used machine learning and artificial intelligence: 1) to measure levels of peace in countries from news and social media and 2) to develop on-line tools that promote peace by helping users better understand their own media diet. For news media, we used neural networks to measure levels of peace from text embeddings of on-line news sources. The model, trained on one news media dataset also showed high accuracy when used to analyze a different news dataset. For social media, such as YouTube, we developed other models to measure levels of social dimensions important in peace using word level (GoEmotions) and context level (Large Language Model) methods. To promote peace, we note that 71% of people 20-40 years old daily view most of their news through short videos on social media. Content creators of these videos are biased towards creating videos with emotional activation, making you angry to engage you, to increase clicks. We developed and tested a Chrome extension, MirrorMirror, which provides real-time feedback to YouTube viewers about the peacefulness of the media they are watching. Our long term goal is for MirrorMirror to evolve into an open-source tool for content creators, journalists, researchers, platforms, and individual users to better understand the tone of their media creation and consumption and its effects on viewers. Moving beyond simple engagement metrics, we hope to encourage more respectful, nuanced, and informative communication.","authors":["P. Gilda","P. Dungarwal","A. Thongkham","E. T. Ajayi","S. Choudhary","T. M. Terol","C. Lam","J. P. Araujo","M. McFadyen-Mungalln","L. S. Liebovitch","P. T. Coleman","H. West","K. Sieck","S. Carter"],"pdf_url":"","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.05227v1","updated":"2026-01-08T18:53:59Z","published":"2026-01-08T18:53:59Z","title":"Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data","summary":"I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.\n  A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning.","authors":["James Rice"],"pdf_url":"","comment":"20 pages, 6330 words"},{"id":"http://arxiv.org/abs/2601.05219v1","updated":"2026-01-08T18:44:21Z","published":"2026-01-08T18:44:21Z","title":"CAOS: Conformal Aggregation of One-Shot Predictors","summary":"One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data. Despite violating classical exchangeability assumptions, we prove that CAOS achieves valid marginal coverage using a monotonicity-based argument. Experiments on one-shot facial landmarking and RAFT text classification tasks show that CAOS produces substantially smaller prediction sets than split conformal baselines while maintaining reliable coverage.","authors":["Maja Waldron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05205v1","updated":"2026-01-08T18:31:11Z","published":"2026-01-08T18:31:11Z","title":"EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI","summary":"Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.","authors":["Zain Iqbal","Lorenzo Valerio"],"pdf_url":"","comment":"6 pages, 9 figures, 2 Tables, conference [Submitted in PerConAI-2026]"},{"id":"http://arxiv.org/abs/2503.19306v2","updated":"2026-01-08T18:25:55Z","published":"2025-03-25T03:12:52Z","title":"Centroid Decision Forest","summary":"This paper introduces the centroid decision forest (CDF), a novel ensemble learning framework that redefines the splitting strategy and tree building in the ordinary decision trees for high-dimensional classification. The splitting approach in CDF differs from the traditional decision trees in theat the class separability score (CSS) determines the selection of the most discriminative features at each node to construct centroids of the partitions (daughter nodes). The splitting criterion uses the Euclidean distance measurements from each class centroid to achieve a splitting mechanism that is more flexible and robust. Centroids are constructed by computing the mean feature values of the selected features for each class, ensuring a class-representative division of the feature space. This centroid-driven approach enables CDF to capture complex class structures while maintaining interpretability and scalability. To evaluate CDF, 23 high-dimensional datasets are used to assess its performance against different state-of-the-art classifiers through classification accuracy and Cohen's kappa statistic. The experimental results show that CDF outperforms the conventional methods establishing its effectiveness and flexibility for high-dimensional classification problems.","authors":["Amjad Ali","Saeed Aldahmani","Hailiang Du","Zardad Khan"],"pdf_url":"","comment":"This article has 11 pages, 6 figures, and 3 tables"},{"id":"http://arxiv.org/abs/2601.05202v1","updated":"2026-01-08T18:24:22Z","published":"2026-01-08T18:24:22Z","title":"Stock Market Price Prediction using Neural Prophet with Deep Neural Network","summary":"Stock market price prediction is a significant interdisciplinary research domain that depends at the intersection of finance, statistics, and economics. Forecasting Accurately predicting stock prices has always been a focal point for various researchers. However, existing statistical approaches for time-series prediction often fail to effectively forecast the probability range of future stock prices. Hence, to solve this problem, the Neural Prophet with a Deep Neural Network (NP-DNN) is proposed to predict stock market prices. The preprocessing technique used in this research is Z-score normalization, which normalizes stock price data by removing scale differences, making patterns easier to detect. Missing value imputation fills gaps in historical data, enhancing the models use of complete information for more accurate predictions. The Multi-Layer Perceptron (MLP) learns complex nonlinear relationships among stock market prices and extracts hidden patterns from the input data, thereby creating meaningful feature representations for better prediction accuracy. The proposed NP-DNN model achieved an accuracy of 99.21% compared with other approaches using the Fused Large Language Model. Keywords: deep neural network, forecasting stock prices, multi-layer perceptron, neural prophet, stock market price prediction.","authors":["Navin Chhibber","Suneel Khemka","Navneet Kumar Tyagi","Rohit Tewari","Bireswar Banerjee","Piyush Ranjan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.22555v2","updated":"2026-01-08T18:23:39Z","published":"2025-06-27T18:11:54Z","title":"Spectral Bias in Variational Quantum Machine Learning","summary":"In this work, we investigate the phenomenon of spectral bias in quantum machine learning, where, in classical settings, models tend to fit low-frequency components of a target function earlier during training than high-frequency ones, demonstrating a frequency-dependent rate of convergence. We study this effect specifically in parameterised quantum circuits (PQCs). Leveraging the established formulation of PQCs as Fourier series, we prove that spectral bias in this setting arises from the ``redundancy'' of the Fourier coefficients, which denotes the number of terms in the analytical form of the model contributing to the same frequency component. The choice of data encoding scheme dictates the degree of redundancy for a Fourier coefficient. We find that the magnitude of the Fourier coefficients' gradients during training strongly correlates with the coefficients' redundancy. We then further demonstrate this empirically with three different encoding schemes. Additionally, we demonstrate that PQCs with greater redundancy exhibit increased robustness to random perturbations in their parameters at the corresponding frequencies. We investigate how design choices affect the ability of PQCs to learn Fourier sums, focusing on parameter initialization scale and entanglement structure, finding large initializations and low-entanglement schemes tend to slow convergence.","authors":["Callum Duffy","Marcin Jastrzebski"],"pdf_url":"","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2502.03365v3","updated":"2026-01-08T18:22:37Z","published":"2025-02-05T17:02:42Z","title":"A Match Made in Heaven? AI-driven Matching of Vulnerabilities and Security Unit Tests","summary":"Software vulnerabilities are often detected via taint analysis, penetration testing, or fuzzing. They are also found via unit tests that exercise security-sensitive behavior with specific inputs, called vulnerability-witnessing tests. Generative AI models could help developers in writing them, but they require many examples to learn from, which are currently scarce. This paper introduces VuTeCo, an AI-driven framework for collecting examples of vulnerability-witnessing tests from Java repositories. VuTeCo carries out two tasks: (1) The \"Finding\" task to determine whether a unit test case is security-related, and (2) the \"Matching\" task to relate a test case to the vulnerability it witnesses. VuTeCo addresses the Finding task with UniXcoder, achieving an F0.5 score of 0.73 and a precision of 0.83 on a test set of unit tests from Vul4J. The Matching task is addressed using DeepSeek Coder, achieving an F0.5 score of 0.65 and a precision of 0.75 on a test set of pairs of unit tests and vulnerabilities from Vul4J. VuTeCo has been used in the wild on 427 Java projects and 1,238 vulnerabilities, obtaining 224 test cases confirmed to be security-related and 35 tests correctly matched to 29 vulnerabilities. The validated tests were collected in a new dataset called Test4Vul. VuTeCo lays the foundation for large-scale retrieval of vulnerability-witnessing tests, enabling future AI models to better understand and generate security unit tests.","authors":["Emanuele Iannone","Quang-Cuong Bui","Riccardo Scandariato"],"pdf_url":"","comment":"Accepted in the MSR 2026 Technical Track. This work was partially supported by EU-funded project Sec4AI4Sec (grant no. 101120393)"},{"id":"http://arxiv.org/abs/2601.05194v1","updated":"2026-01-08T18:17:31Z","published":"2026-01-08T18:17:31Z","title":"An interpretable data-driven approach to optimizing clinical fall risk assessment","summary":"In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.","authors":["Fardin Ganjkhanloo","Emmett Springer","Erik H. Hoyer","Daniel L. Young","Holley Farley","Kimia Ghobadi"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:2510.20714"},{"id":"http://arxiv.org/abs/2601.03470v2","updated":"2026-01-08T18:16:48Z","published":"2026-01-06T23:48:00Z","title":"Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms","summary":"We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigating multi-objective trade-offs inherent in trustworthiness evaluation. We demonstrate this approach using uncertainty quantification as an exemplar measurement mechanism and illustrate feasibility through an Uncrewed Aircraft System (UAS) detection case study.","authors":["Michael C. Darling","Alan H. Hesu","Michael A. Mardikes","Brian C. McGuigan","Reed M. Milewicz"],"pdf_url":"","comment":"Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification"},{"id":"http://arxiv.org/abs/2601.05191v1","updated":"2026-01-08T18:13:46Z","published":"2026-01-08T18:13:46Z","title":"Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable","summary":"When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines","authors":["Zuhair Ahmed Khan Taha","Mohammed Mudassir Uddin","Shahnawaz Alam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05174v1","updated":"2026-01-08T18:00:58Z","published":"2026-01-08T18:00:58Z","title":"FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts","summary":"Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.","authors":["Yiji Zhao","Zihao Zhong","Ao Wang","Haomin Wen","Ming Jin","Yuxuan Liang","Huaiyu Wan","Hao Wu"],"pdf_url":"","comment":"Accepted to KDD 2026"},{"id":"http://arxiv.org/abs/2601.05167v1","updated":"2026-01-08T17:56:16Z","published":"2026-01-08T17:56:16Z","title":"RelayLLM: Efficient Reasoning via Collaborative Decoding","summary":"Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.","authors":["Chengsong Huang","Tong Zheng","Langlin Huang","Jinyuan Li","Haolin Liu","Jiaxin Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05157v1","updated":"2026-01-08T17:47:58Z","published":"2026-01-08T17:47:58Z","title":"Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms","summary":"In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians.\n  All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments.\n  Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function.\n  Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.","authors":["Alkis Kalavasis","Pravesh K. Kothari","Shuchen Li","Manolis Zampetakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04487v4","updated":"2026-01-08T17:43:12Z","published":"2025-10-06T04:51:06Z","title":"Forking-Sequences","summary":"While accuracy is a critical requirement for time series forecasting, an equally important desideratum is forecast stability across forecast creation dates (FCDs). Even highly accurate models can produce erratic revisions between FCDs, disrupting downstream decision-making. To improve forecast stability of such revisions, several state-of-the-art models including MQCNN, MQT, and SPADE employ a powerful yet underexplored neural network architectural design known as forking-sequences. This architectural design jointly encodes and decodes the entire time series across all FCDs, producing an entire multi-horizon forecast grid in a single forward pass. This approach contrasts with conventional neural forecasting methods that process FCDs independently, generating only a single multi-horizon forecast per forward pass. In this work, we formalize the forking-sequences design and motivate its broader adoption by introducing a metric for quantifying excess volatility in forecast revisions and by providing theoretical and empirical analysis. We theoretically motivate three key benefits of forking-sequences: (i) increased forecast stability through ensembling; (ii) gradient variance reduction, leading to more stable and consistent training steps; and (iii) improved computational efficiency during inference. We validate the benefits of forking-sequences compared to baseline window-sampling on the M-series benchmark, using 16 datasets from the M1, M3, M4, and Tourism competitions. We observe median accuracy improvements across datasets of 29.7%, 46.2%, 49.3%, 28.6%, 24.7%, and 6.4% for MLP, RNN, LSTM, CNN, Transformer, and StateSpace-based architectures, respectively. We then show that forecast ensembling during inference can improve median forecast stability by 10.8%, 13.2%, 13.0%, 10.9%, 10.2%, and 11.2% for these respective models trained with forking-sequences, while maintaining accuracy.","authors":["Willa Potosnak","Malcolm Wolff","Mengfei Cao","Ruijun Ma","Tatiana Konstantinova","Dmitry Efimov","Michael W. Mahoney","Boris Oreshkin","Kin G. Olivares"],"pdf_url":"","comment":"Presented at the GPU-Accelerated and Scalable Optimization (ScaleOpt) Workshop, NeurIPS 2025"},{"id":"http://arxiv.org/abs/2601.05152v1","updated":"2026-01-08T17:42:56Z","published":"2026-01-08T17:42:56Z","title":"Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art","summary":"This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms.\n  Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning","authors":["Timofey Tomashevskiy"],"pdf_url":"","comment":"20 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.05151v1","updated":"2026-01-08T17:41:07Z","published":"2026-01-08T17:41:07Z","title":"ROOFS: RObust biOmarker Feature Selection","summary":"Feature selection (FS) is essential for biomarker discovery and in the analysis of biomedical datasets. However, challenges such as high-dimensional feature space, low sample size, multicollinearity, and missing values make FS non-trivial. Moreover, FS performances vary across datasets and predictive tasks. We propose roofs, a Python package available at https://gitlab.inria.fr/compo/roofs, designed to help researchers in the choice of FS method adapted to their problem. Roofs benchmarks multiple FS methods on the user's data and generates reports that summarize a comprehensive set of evaluation metrics, including downstream predictive performance estimated using optimism correction, stability, reliability of individual features, and true positive and false positive rates assessed on semi-synthetic data with a simulated outcome. We demonstrate the utility of roofs on data from the PIONeeR clinical trial, aimed at identifying predictors of resistance to anti-PD-(L)1 immunotherapy in lung cancer. The PIONeeR dataset contained 374 multi-source blood and tumor biomarkers from 435 patients. A reduced subset of 214 features was obtained through iterative variance inflation factor pre-filtering. Of the 34 FS methods gathered in roofs, we evaluated 23 in combination with 11 classifiers (253 models in total) and identified a filter based on the union of Benjamini-Hochberg false discovery rate-adjusted p-values from t-test and logistic regression as the optimal approach, outperforming other methods including the widely used LASSO. We conclude that comprehensive benchmarking with roofs has the potential to improve the robustness and reproducibility of FS discoveries and increase the translational value of clinical models.","authors":["Anastasiia Bakhmach","Paul Dufossé","Andrea Vaglio","Florence Monville","Laurent Greillier","Fabrice Barlési","Sébastien Benzekry"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05148v1","updated":"2026-01-08T17:37:00Z","published":"2026-01-08T17:37:00Z","title":"Atlas 2 -- Foundation models for clinical deployment","summary":"Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model dataset to date comprising 5.5 million histopathology whole slide images, collected from three medical institutions Charité - Universtätsmedizin Berlin, LMU Munich, and Mayo Clinic.","authors":["Maximilian Alber","Timo Milbich","Alexandra Carpen-Amarie","Stephan Tietz","Jonas Dippel","Lukas Muttenthaler","Beatriz Perez Cancer","Alessandro Benetti","Panos Korfiatis","Elias Eulig","Jérôme Lüscher","Jiasen Wu","Sayed Abid Hashimi","Gabriel Dernbach","Simon Schallenberg","Neelay Shah","Moritz Krügener","Aniruddh Jammoria","Jake Matras","Patrick Duffy","Matt Redlon","Philipp Jurmeister","David Horst","Lukas Ruff","Klaus-Robert Müller","Frederick Klauschen","Andrew Norgan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04083v2","updated":"2026-01-08T17:32:37Z","published":"2026-01-07T16:51:33Z","title":"Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning","summary":"The widespread deployment of 5G networks, together with the coexistence of 4G/LTE networks, provides mobile devices a diverse set of candidate cells to connect to. However, associating mobile devices to cells to maximize overall network performance, a.k.a. cell (re)selection, remains a key challenge for mobile operators. Today, cell (re)selection parameters are typically configured manually based on operator experience and rarely adapted to dynamic network conditions. In this work, we ask: Can an agent automatically learn and adapt cell (re)selection parameters to consistently improve network performance? We present a reinforcement learning (RL)-based framework called CellPilot that adaptively tunes cell (re)selection parameters by learning spatiotemporal patterns of mobile network dynamics. Our study with real-world data demonstrates that even a lightweight RL agent can outperform conventional heuristic reconfigurations by up to 167%, while generalizing effectively across different network scenarios. These results indicate that data-driven approaches can significantly improve cell (re)selection configurations and enhance mobile network performance.","authors":["Marvin Illian","Ramin Khalili","Antonio A. de A. Rocha","Lin Wang"],"pdf_url":"","comment":"11 pages, 12 figures, v2: Corrected performance numbers in the conclusion; no change to methodology"},{"id":"http://arxiv.org/abs/2405.14750v3","updated":"2026-01-08T17:31:42Z","published":"2024-05-23T16:17:16Z","title":"Extreme Solar Flare Prediction Using Residual Networks with HMI Magnetograms and Intensitygrams","summary":"Solar flares, especially C, M, and X class, pose significant risks to satellite operations, communication systems, and power grids. We present a novel approach for predicting extreme solar flares using HMI intensitygrams and magnetograms. By detecting sunspots from intensitygrams and extracting magnetic field patches from magnetograms, we train a Residual Network (ResNet) to classify extreme class flares. Our model demonstrates high accuracy, offering a robust tool for predicting extreme solar flares and improving space weather forecasting. Additionally, we show that HMI magnetograms provide more useful data for deep learning compared to other SDO AIA images by better capturing features critical for predicting flare magnitudes. This study underscores the importance of identifying magnetic fields in solar flare prediction, marking a significant advancement in solar activity prediction with practical implications for mitigating space weather impacts.","authors":["Juyoung Yun","Jungmin Shin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05137v1","updated":"2026-01-08T17:28:09Z","published":"2026-01-08T17:28:09Z","title":"Neural Algorithmic Reasoning for Approximate $k$-Coloring with Recursive Warm Starts","summary":"Node coloring is the task of assigning colors to the nodes of a graph such that no two adjacent nodes have the same color, while using as few colors as possible. It is the most widely studied instance of graph coloring and of central importance in graph theory; major results include the Four Color Theorem and work on the Hadwiger-Nelson Problem. As an abstraction of classical combinatorial optimization tasks, such as scheduling and resource allocation, it is also rich in practical applications. Here, we focus on a relaxed version, approximate $k$-coloring, which is the task of assigning at most $k$ colors to the nodes of a graph such that the number of edges whose vertices have the same color is approximately minimized. While classical approaches leverage mathematical programming or SAT solvers, recent studies have explored the use of machine learning. We follow this route and explore the use of graph neural networks (GNNs) for node coloring. We first present an optimized differentiable algorithm that improves a prior approach by Schuetz et al. with orthogonal node feature initialization and a loss function that penalizes conflicting edges more heavily when their endpoints have higher degree; the latter inspired by the classical result that a graph is $k$-colorable if and only if its $k$-core is $k$-colorable. Next, we introduce a lightweight greedy local search algorithm and show that it may be improved by recursively computing a $(k-1)$-coloring to use as a warm start. We then show that applying such recursive warm starts to the GNN approach leads to further improvements. Numerical experiments on a range of different graph structures show that while the local search algorithms perform best on small inputs, the GNN exhibits superior performance at scale. The recursive warm start may be of independent interest beyond graph coloring for local search methods for combinatorial optimization.","authors":["Knut Vanderbush","Melanie Weber"],"pdf_url":"","comment":"33 pages, 10 figures"},{"id":"http://arxiv.org/abs/2601.05134v1","updated":"2026-01-08T17:23:13Z","published":"2026-01-08T17:23:13Z","title":"Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning","summary":"Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.","authors":["Polina Dolgova","Sebastian U. Stich"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.04739v2","updated":"2026-01-08T17:22:46Z","published":"2025-02-04T14:47:30Z","title":"A Framework for Responsible AI Systems: Building Societal Trust through Domain Definition, Trustworthy AI Design, Auditability, Accountability, and Governance","summary":"Responsible Artificial Intelligence (RAI) addresses the ethical and regulatory challenges of deploying AI systems in high-risk scenarios. This paper proposes a comprehensive framework for the design of an RAI system (RAIS) that integrates five key dimensions: domain definition, trustworthy AI design, auditability, accountability, and governance. Unlike prior work that treats these components in isolation, our proposal emphasizes their inter-dependencies and iterative feedback loops, enabling proactive and reactive accountability throughout the AI lifecycle. Beyond presenting the framework, we synthesize recent developments in global AI governance and analyze limitations in existing principles-based approaches, highlighting fragmentation, implementation gaps, and the need for participatory governance. The paper also identifies critical challenges and research directions for the RAIS framework, including sector-specific adaptation and operationalization, to support certification, post-deployment monitoring, and risk-based auditing. By bridging technical design and institutional responsibility, this work offers a practical blueprint for embedding responsibility throughout the AI lifecycle, enabling transparent, ethically aligned, and legally compliant AI-based systems.","authors":["Andrés Herrera-Poyatos","Javier Del Ser","Marcos López de Prado","Fei-Yue Wang","Enrique Herrera-Viedma","Francisco Herrera"],"pdf_url":"","comment":"27 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2508.07142v4","updated":"2026-01-08T17:18:24Z","published":"2025-08-10T02:25:48Z","title":"Why Does Stochastic Gradient Descent Slow Down in Low-Precision Training?","summary":"Low-precision training has become crucial for reducing the computational and memory costs of large-scale deep learning. However, quantizing gradients introduces magnitude shrinkage, which can change how stochastic gradient descent (SGD) converges. In this study, we explore SGD convergence under a gradient shrinkage model, where each stochastic gradient is scaled by a factor \\( q_k \\in (0,1] \\). We show that this shrinkage affect the usual stepsize \\( μ_k \\) with an effective stepsize \\( μ_k q_k \\), slowing convergence when \\( q_{\\min} < 1 \\). With typical smoothness and bounded-variance assumptions, we prove that low-precision SGD still converges, but at a slower pace set by \\( q_{\\min} \\), and with a higher steady error level due to quantization effects. We analyze theoretically how lower numerical precision slows training by treating it as gradient shrinkage within the standard SGD convergence setup.","authors":["Vincent-Daniel Yun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.05729v2","updated":"2026-01-08T17:09:51Z","published":"2024-11-08T17:40:43Z","title":"Graph-Dictionary Signal Model for Sparse Representations of Multivariate Data","summary":"Representing and exploiting multivariate signals requires capturing relations between variables, which we can represent by graphs. Graph dictionaries allow to describe complex relational information as a sparse sum of simpler structures, but no prior model exists to infer such underlying structure elements from data. We define a novel Graph-Dictionary signal model, where a finite set of graphs characterizes relationships in data distribution as filters on the weighted sum of their Laplacians. We propose a framework to infer the graph dictionary representation from observed node signals, which allows to include a priori knowledge about signal properties, and about underlying graphs and their coefficients. We introduce a bilinear generalization of the primal-dual splitting algorithm to solve the learning problem. We show the capability of our method to reconstruct graphs from signals in multiple synthetic settings, where our model outperforms popular baselines. Then, we exploit graph-dictionary representations in an illustrative motor imagery decoding task on brain activity data, where we classify imagined motion better than standard methods relying on many more features. Our graph-dictionary model bridges a gap between sparse representations of multivariate data and a structured decomposition of sample-varying relationships into a sparse combination of elementary graph atoms.","authors":["William Cappelletti","Pascal Frossard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.04804v2","updated":"2026-01-08T17:07:57Z","published":"2025-11-06T20:49:13Z","title":"Simplex-FEM Networks (SiFEN): Learning A Triangulated Function Approximator","summary":"We introduce Simplex-FEM Networks (SiFEN), a learned piecewise-polynomial predictor that represents f: R^d -> R^k as a globally C^r finite-element field on a learned simplicial mesh in an optionally warped input space. Each query activates exactly one simplex and at most d+1 basis functions via barycentric coordinates, yielding explicit locality, controllable smoothness, and cache-friendly sparsity. SiFEN pairs degree-m Bernstein-Bezier polynomials with a light invertible warp and trains end-to-end with shape regularization, semi-discrete OT coverage, and differentiable edge flips. Under standard shape-regularity and bi-Lipschitz warp assumptions, SiFEN achieves the classic FEM approximation rate M^(-m/d) with M mesh vertices. Empirically, on synthetic approximation tasks, tabular regression/classification, and as a drop-in head on compact CNNs, SiFEN matches or surpasses MLPs and KANs at matched parameter budgets, improves calibration (lower ECE/Brier), and reduces inference latency due to geometric locality. These properties make SiFEN a compact, interpretable, and theoretically grounded alternative to dense MLPs and edge-spline networks.","authors":["Chaymae Yahyati","Ismail Lamaakal","Khalid El Makkaoui","Ibrahim Ouahbi","Yassine Maleh"],"pdf_url":"","comment":"We will improve our work soon"},{"id":"http://arxiv.org/abs/2410.24164v4","updated":"2026-01-08T17:01:05Z","published":"2024-10-31T17:22:30Z","title":"$π_0$: A Vision-Language-Action Flow Model for General Robot Control","summary":"Robot learning holds tremendous promise to unlock the full potential of flexible, general, and dexterous robot systems, as well as to address some of the deepest questions in artificial intelligence. However, bringing robot learning to the level of generality required for effective real-world systems faces major obstacles in terms of data, generalization, and robustness. In this paper, we discuss how generalist robot policies (i.e., robot foundation models) can address these challenges, and how we can design effective generalist robot policies for complex and highly dexterous tasks. We propose a novel flow matching architecture built on top of a pre-trained vision-language model (VLM) to inherit Internet-scale semantic knowledge. We then discuss how this model can be trained on a large and diverse dataset from multiple dexterous robot platforms, including single-arm robots, dual-arm robots, and mobile manipulators. We evaluate our model in terms of its ability to perform tasks in zero shot after pre-training, follow language instructions from people and from a high-level VLM policy, and its ability to acquire new skills via fine-tuning. Our results cover a wide variety of tasks, such as laundry folding, table cleaning, and assembling boxes.","authors":["Kevin Black","Noah Brown","Danny Driess","Adnan Esmail","Michael Equi","Chelsea Finn","Niccolo Fusai","Lachy Groom","Karol Hausman","Brian Ichter","Szymon Jakubczak","Tim Jones","Liyiming Ke","Sergey Levine","Adrian Li-Bell","Mohith Mothukuri","Suraj Nair","Karl Pertsch","Lucy Xiaoyang Shi","James Tanner","Quan Vuong","Anna Walling","Haohuan Wang","Ury Zhilinsky"],"pdf_url":"","comment":"See project website for videos: https://physicalintelligence.company/blog/pi0 Published in RSS 2025"},{"id":"http://arxiv.org/abs/2512.00949v2","updated":"2026-01-08T16:55:55Z","published":"2025-11-30T16:01:50Z","title":"Multi-Modal AI for Remote Patient Monitoring in Cancer Care","summary":"For patients undergoing systemic cancer therapy, the time between clinic visits is full of uncertainties and risks of unmonitored side effects. To bridge this gap in care, we developed and prospectively trialed a multi-modal AI framework for remote patient monitoring (RPM). This system integrates multi-modal data from the HALO-X platform, such as demographics, wearable sensors, daily surveys, and clinical events. Our observational trial is one of the largest of its kind and has collected over 2.1 million data points (6,080 patient-days) of monitoring from 84 patients. We developed and adapted a multi-modal AI model to handle the asynchronous and incomplete nature of real-world RPM data, forecasting a continuous risk of future adverse events. The model achieved an accuracy of 83.9% (AUROC=0.70). Notably, the model identified previous treatments, wellness check-ins, and daily maximum heart rate as key predictive features. A case study demonstrated the model's ability to provide early warnings by outputting escalating risk profiles prior to the event. This work establishes the feasibility of multi-modal AI RPM for cancer care and offers a path toward more proactive patient support.(Accepted at Europe NeurIPS 2025 Multimodal Representation Learning for Healthcare Workshop. Best Paper Poster Award.)","authors":["Yansong Liu","Ronnie Stafford","Pramit Khetrapal","Huriye Kocadag","Graça Carvalho","Patricia de Winter","Maryam Imran","Amelia Snook","Adamos Hadjivasiliou","D. Vijay Anand","Weining Lin","John Kelly","Yukun Zhou","Ivana Drobnjak"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.11151v3","updated":"2026-01-08T16:55:29Z","published":"2025-03-14T07:40:37Z","title":"Enabling Weak Client Participation via On-device Knowledge Distillation in Heterogeneous Federated Learning","summary":"Online Knowledge Distillation (KD) is recently highlighted to train large models in Federated Learning (FL) environments. Many existing studies adopt the logit ensemble method to perform KD on the server side. However, they often assume that unlabeled data collected at the edge is centralized on the server. Moreover, the logit ensemble method personalizes local models, which can degrade the quality of soft targets, especially when data is highly non-IID. To address these critical limitations,we propose a novel on-device KD-based heterogeneous FL method. Our approach leverages a small auxiliary model to learn from labeled local data. Subsequently, a subset of clients with strong system resources transfers knowledge to a large model through on-device KD using their unlabeled data. Our extensive experiments demonstrate that our on-device KD-based heterogeneous FL method effectively utilizes the system resources of all edge devices as well as the unlabeled data, resulting in higher accuracy compared to SOTA KD-based FL methods.","authors":["Jihyun Lim","Junhyuk Jo","Tuo Zhang","Sunwoo Lee"],"pdf_url":"","comment":"Accepted by ECAI 2025"},{"id":"http://arxiv.org/abs/2601.05106v1","updated":"2026-01-08T16:53:16Z","published":"2026-01-08T16:53:16Z","title":"Token-Level LLM Collaboration via FusionRoute","summary":"Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.","authors":["Nuoya Xiong","Yuhang Zhou","Hanqing Zeng","Zhaorun Chen","Furong Huang","Shuchao Bi","Lizhu Zhang","Zhuokai Zhao"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2512.16282v2","updated":"2026-01-08T16:51:18Z","published":"2025-12-18T08:01:19Z","title":"CALM: A CKA-Guided Adaptive Layer-Wise Modularization Framework for LLM Quantization","summary":"Current mainstream post-training quantization methods for large language models typically apply a uniform quantization strategy across all network layers, overlooking the substantial differences in algorithmic suitability among layers. To address this limitation, we propose CALM (A CKA-guided Adaptive Layer-wise Modularization)a fine-tuning-free, plug-and-play framework for algorithmic heterogeneous quantization. CALM independently evaluates multiple PTQ algorithms on each layer and employs Linear Centered Kernel Alignment (CKA) as a metric to automatically select the optimal quantization strategy per layer. The individually optimized strategies are then integrated to construct a hybrid quantized model. Experiments demonstrate that our approach consistently outperforms both uniform quantization baselines and state-of-the-art mixed-precision methods across mainstream LLMsincluding LLaMA and Qwenin terms of perplexity (PPL) and downstream task performance.","authors":["Jinhao Zhang","Yunquan Zhang","Daning Chen"," JunSun","Zicheng Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05091v1","updated":"2026-01-08T16:39:26Z","published":"2026-01-08T16:39:26Z","title":"Code-Mix Sentiment Analysis on Hinglish Tweets","summary":"The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.","authors":["Aashi Garg","Aneshya Das","Arshi Arya","Anushka Goyal"," Aditi"],"pdf_url":"","comment":"Accepted at the 9th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2025), Fukuoka, Japan"},{"id":"http://arxiv.org/abs/2601.05082v1","updated":"2026-01-08T16:27:09Z","published":"2026-01-08T16:27:09Z","title":"Exploring Student Expectations and Confidence in Learning Analytics","summary":"Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.","authors":["Hayk Asatryan","Basile Tousside","Janis Mohr","Malte Neugebauer","Hildo Bijl","Paul Spiegelberg","Claudia Frohn-Schauf","Jörg Frochte"],"pdf_url":"","comment":"7 pages, Keywords: Learning Analytics, Survey, Data Protection, Clustering"},{"id":"http://arxiv.org/abs/2601.05073v1","updated":"2026-01-08T16:17:56Z","published":"2026-01-08T16:17:56Z","title":"Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward","summary":"Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because \"black box\" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.","authors":["Jianlong Chen","Daocheng Fu","Shengze Xu","Jiawei Chen","Yuan Feng","Yue Yang","Junchi Yan","Hongyuan Zha","Renqiu Xia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.02415v2","updated":"2026-01-08T16:09:43Z","published":"2025-10-02T13:42:37Z","title":"The Equilibrium Response of Atmospheric Machine-Learning Models to Uniform Sea Surface Temperature Warming","summary":"Machine learning models for the global atmosphere that are capable of producing stable, multi-year simulations of Earth's climate have recently been developed. However, the ability of these ML models to generalize beyond the training distribution remains an open question. In this study, we evaluate the climate response of several state-of-the-art ML models (ACE2-ERA5, NeuralGCM, and cBottle) to a uniform sea surface temperature warming, a widely used benchmark for evaluating climate change. We assess each ML model's performance relative to a physics-based general circulation model (NOAA's Geophysical Fluid Dynamics Laboratory AM4) across key diagnostics, including surface air temperature, precipitation, temperature and wind profiles, and top-of-atmosphere radiation. While the ML models reproduce key aspects of the physical model response, particularly the response of precipitation, some exhibit notable departures from robust physical responses, including radiative responses and land region warming. Our results highlight the promise and current limitations of ML models for climate change applications and suggest that further improvements are needed for robust out-of-sample generalization.","authors":["Bosong Zhang","Timothy M. Merlis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05063v1","updated":"2026-01-08T16:08:58Z","published":"2026-01-08T16:08:58Z","title":"Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset","summary":"Magnetic resonance imaging (MRI) is a cornerstone of clinical neuroimaging, yet conventional MRIs provide qualitative information heavily dependent on scanner hardware and acquisition settings. While quantitative MRI (qMRI) offers intrinsic tissue parameters, the requirement for specialized acquisition protocols and reconstruction algorithms restricts its availability and impedes large-scale biomarker research. This study presents a self-supervised physics-guided deep learning framework to infer quantitative T1, T2, and proton-density (PD) maps directly from widely available clinical conventional T1-weighted, T2-weighted, and FLAIR MRIs. The framework was trained and evaluated on a large-scale, clinically heterogeneous dataset comprising 4,121 scan sessions acquired at our institution over six years on four different 3 T MRI scanner systems, capturing real-world clinical variability. The framework integrates Bloch-based signal models directly into the training objective. Across more than 600 test sessions, the generated maps exhibited white matter and gray matter values consistent with literature ranges. Additionally, the generated maps showed invariance to scanner hardware and acquisition protocol groups, with inter-group coefficients of variation $\\leq$ 1.1%. Subject-specific analyses demonstrated excellent voxel-wise reproducibility across scanner systems and sequence parameters, with Pearson $r$ and concordance correlation coefficients exceeding 0.82 for T1 and T2. Mean relative voxel-wise differences were low across all quantitative parameters, especially for T2 ($<$ 6%). These results indicate that the proposed framework can robustly transform diverse clinical conventional MRI data into quantitative maps, potentially paving the way for large-scale quantitative biomarker research.","authors":["Jelmer van Lune","Stefano Mandija","Oscar van der Heide","Matteo Maspero","Martin B. Schilder","Jan Willem Dankbaar","Cornelis A. T. van den Berg","Alessandro Sbrizzi"],"pdf_url":"","comment":"30 pages, 13 figures, full paper"},{"id":"http://arxiv.org/abs/2601.05062v1","updated":"2026-01-08T16:08:44Z","published":"2026-01-08T16:08:44Z","title":"Compositional Steering of Large Language Models with Steering Tokens","summary":"Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.","authors":["Gorjan Radevski","Kiril Gashteovski","Giwon Hong","Carolin Lawrence","Goran Glavaš"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05059v1","updated":"2026-01-08T16:02:56Z","published":"2026-01-08T16:02:56Z","title":"From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)","summary":"Vision Language Models (VLMs) are poised to revolutionize the digital transformation of pharmacyceutical industry by enabling intelligent, scalable, and automated multi-modality content processing. Traditional manual annotation of heterogeneous data modalities (text, images, video, audio, and web links), is prone to inconsistencies, quality degradation, and inefficiencies in content utilization. The sheer volume of long video and audio data further exacerbates these challenges, (e.g. long clinical trial interviews and educational seminars).\n  Here, we introduce a domain adapted Video to Video Clip Generation framework that integrates Audio Language Models (ALMs) and Vision Language Models (VLMs) to produce highlight clips. Our contributions are threefold: (i) a reproducible Cut & Merge algorithm with fade in/out and timestamp normalization, ensuring smooth transitions and audio/visual alignment; (ii) a personalization mechanism based on role definition and prompt injection for tailored outputs (marketing, training, regulatory); (iii) a cost efficient e2e pipeline strategy balancing ALM/VLM enhanced processing. Evaluations on Video MME benchmark (900) and our proprietary dataset of 16,159 pharmacy videos across 14 disease areas demonstrate 3 to 4 times speedup, 4 times cost reduction, and competitive clip quality. Beyond efficiency gains, we also report our methods improved clip coherence scores (0.348) and informativeness scores (0.721) over state of the art VLM baselines (e.g., Gemini 2.5 Pro), highlighting the potential of transparent, custom extractive, and compliance supporting video summarization for life sciences.","authors":["Suyash Mishra","Qiang Li","Srikanth Patil","Anubhav Girdhar"],"pdf_url":"","comment":"Contributed original research to top tier conference in VLM; currently undergoing peer review"},{"id":"http://arxiv.org/abs/2601.03327v2","updated":"2026-01-08T16:01:17Z","published":"2026-01-06T15:46:56Z","title":"Extreme-value forest fire prediction A study of the Loss Function in an Ordinality Scheme","summary":"Wildfires are highly imbalanced natural hazards in both space and severity, making the prediction of extreme events particularly challenging. In this work, we introduce the first ordinal classification framework for forecasting wildfire severity levels directly aligned with operational decision-making in France. Our study investigates the influence of loss-function design on the ability of neural models to predict rare yet critical high-severity fire occurrences. We compare standard cross-entropy with several ordinal-aware objectives, including the proposed probabilistic TDeGPD loss derived from a truncated discrete exponentiated Generalized Pareto Distribution. Through extensive benchmarking over multiple architectures and real operational data, we show that ordinal supervision substantially improves model performance over conventional approaches. In particular, the Weighted Kappa Loss (WKLoss) achieves the best overall results, with more than +0.1 IoU (Intersection Over Union) gain on the most extreme severity classes while maintaining competitive calibration quality. However, performance remains limited for the rarest events due to their extremely low representation in the dataset. These findings highlight the importance of integrating both severity ordering, data imbalance considerations, and seasonality risk into wildfire forecasting systems. Future work will focus on incorporating seasonal dynamics and uncertainty information into training to further improve the reliability of extreme-event prediction.","authors":["Nicolas Caron","Christophe Guyeux","Hassan Noura","Benjamin Aynes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05052v1","updated":"2026-01-08T15:56:28Z","published":"2026-01-08T15:56:28Z","title":"DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights","summary":"Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating partial neural network weights, particularly for larger models, such as ResNet and ViT. Those that do generate complete weights struggle with generation speed or require finetuning of the generated models. In this work, we present DeepWeightFlow, a Flow Matching model that operates directly in weight space to generate diverse and high-accuracy neural network weights for a variety of architectures, neural network sizes, and data modalities. The neural networks generated by DeepWeightFlow do not require fine-tuning to perform well and can scale to large networks. We apply Git Re-Basin and TransFusion for neural network canonicalization in the context of generative weight models to account for the impact of neural network permutation symmetries and to improve generation efficiency for larger model sizes. The generated networks excel at transfer learning, and ensembles of hundreds of neural networks can be generated in minutes, far exceeding the efficiency of diffusion-based methods. DeepWeightFlow models pave the way for more efficient and scalable generation of diverse sets of neural networks.","authors":["Saumya Gupta","Scott Biggs","Moritz Laber","Zohair Shafi","Robin Walters","Ayan Paul"],"pdf_url":"","comment":"25 pages, 20 tables, 2 figures"},{"id":"http://arxiv.org/abs/2601.05047v1","updated":"2026-01-08T15:52:11Z","published":"2026-01-08T15:52:11Z","title":"Challenges and Research Directions for Large Language Model Inference Hardware","summary":"Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.","authors":["Xiaoyu Ma","David Patterson"],"pdf_url":"","comment":"Accepted for publication by IEEE Computer, 2026"},{"id":"http://arxiv.org/abs/2601.05036v1","updated":"2026-01-08T15:44:41Z","published":"2026-01-08T15:44:41Z","title":"Exponential capacity scaling of classical GANs compared to hybrid latent style-based quantum GANs","summary":"Quantum generative modeling is a very active area of research in looking for practical advantage in data analysis. Quantum generative adversarial networks (QGANs) are leading candidates for quantum generative modeling and have been applied to diverse areas, from high-energy physics to image generation. The latent style-based QGAN, relying on a classical variational autoencoder to encode the input data into a latent space and then using a style-based QGAN for data generation has been proven to be efficient for image generation or drug design, hinting at the use of far less trainable parameters than their classical counterpart to achieve comparable performance, however this advantage has never been systematically studied. We present in this work the first comprehensive experimental analysis of this advantage of QGANS applied to SAT4 image generation, obtaining an exponential advantage in capacity scaling for a quantum generator in the hybrid latent style-based QGAN architecture. Careful tuning of the autoencoder is crucial to obtain stable, reliable results. Once this tuning is performed and defining training optimality as when the training is stable and the FID score is low and stable as well, the optimal capacity (or number of trainable parameters) of the classical discriminator scales exponentially with respect to the capacity of the quantum generator, and the same is true for the capacity of the classical generator. This hints toward a type of quantum advantage for quantum generative modeling.","authors":["Milan Liepelt","Julien Baglio"],"pdf_url":"","comment":"34 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2505.19946v4","updated":"2026-01-08T15:44:33Z","published":"2025-05-26T13:10:27Z","title":"Inverse Q-Learning Done Right: Offline Imitation Learning in $Q^π$-Realizable MDPs","summary":"We study the problem of offline imitation learning in Markov decision processes (MDPs), where the goal is to learn a well-performing policy given a dataset of state-action pairs generated by an expert policy. Complementing a recent line of work on this topic that assumes the expert belongs to a tractable class of known policies, we approach this problem from a new angle and leverage a different type of structural assumption about the environment. Specifically, for the class of linear $Q^π$-realizable MDPs, we introduce a new algorithm called saddle-point offline imitation learning (\\SPOIL), which is guaranteed to match the performance of any expert up to an additive error $\\varepsilon$ with access to $\\mathcal{O}(\\varepsilon^{-2})$ samples. Moreover, we extend this result to possibly nonlinear $Q^π$-realizable MDPs at the cost of a worse sample complexity of order $\\mathcal{O}(\\varepsilon^{-4})$. Finally, our analysis suggests a new loss function for training critic networks from expert data in deep imitation learning. Empirical evaluations on standard benchmarks demonstrate that the neural net implementation of \\SPOIL is superior to behavior cloning and competitive with state-of-the-art algorithms.","authors":["Antoine Moulin","Gergely Neu","Luca Viano"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16680v3","updated":"2026-01-08T15:43:41Z","published":"2025-04-23T12:58:15Z","title":"Uncertainty-Aware Robotic World Model Makes Offline Model-Based Reinforcement Learning Work on Real Robots","summary":"Reinforcement Learning (RL) has achieved impressive results in robotics, yet high-performing pipelines remain highly task-specific, with little reuse of prior data. Offline Model-based RL (MBRL) offers greater data efficiency by training policies entirely from existing datasets, but suffers from compounding errors and distribution shift in long-horizon rollouts. Although existing methods have shown success in controlled simulation benchmarks, robustly applying them to the noisy, biased, and partially observed datasets typical of real-world robotics remains challenging. We present a principled pipeline for making offline MBRL effective on physical robots. Our RWM-U extends autoregressive world models with epistemic uncertainty estimation, enabling temporally consistent multi-step rollouts with uncertainty effectively propagated over long horizons. We combine RWM-U with MOPO-PPO, which adapts uncertainty-penalized policy optimization to the stable, on-policy PPO framework for real-world control. We evaluate our approach on diverse manipulation and locomotion tasks in simulation and on real quadruped and humanoid, training policies entirely from offline datasets. The resulting policies consistently outperform model-free and uncertainty-unaware model-based baselines, and fusing real-world data in model learning further yields robust policies that surpass online model-free baselines trained solely in simulation.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05033v1","updated":"2026-01-08T15:43:28Z","published":"2026-01-08T15:43:28Z","title":"A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models","summary":"Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.","authors":["Anees Fatima","Mohammad Abdus Salam"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.19971v2","updated":"2026-01-08T15:36:06Z","published":"2025-10-22T19:01:50Z","title":"Guiding diffusion models to reconstruct flow fields from sparse data","summary":"The reconstruction of unsteady flow fields from limited measurements is a challenging and crucial task for many engineering applications. Machine learning models are gaining popularity for solving this problem due to their ability to learn complex patterns from data and to generalize across diverse conditions. Among these, diffusion models have emerged as being particularly powerful for generative tasks, producing high-quality samples by iteratively refining noisy inputs. In contrast to other methods, these generative models are capable of reconstructing the smallest scales of the fluid spectrum. In this work, we introduce a novel sampling method for diffusion models that enables the reconstruction of high-fidelity samples by guiding the reverse process using the available sparse data. Moreover, we enhance the reconstructions with available physics knowledge using a conflict-free update method during training. To evaluate the effectiveness of our method, we conduct experiments on 2 and 3-dimensional turbulent flow data. Our method consistently outperforms other diffusion-based methods in predicting the fluid's structure and in pixel-wise accuracy. This study underscores the remarkable potential of diffusion models in reconstructing flow field data, paving the way for leveraging them in fluid dynamics research and applications ranging from super-resolution to reconstructions of experiments.","authors":["Marc Amorós-Trepat","Luis Medrano-Navarro","Qiang Liu","Luca Guastoni","Nils Thuerey"],"pdf_url":"","comment":"Published on Physics of Fluids, code and data can be found at https://github.com/tum-pbs/sparse-reconstruction"},{"id":"http://arxiv.org/abs/2601.05028v1","updated":"2026-01-08T15:35:42Z","published":"2026-01-08T15:35:42Z","title":"Approximate equivariance via projection-based regularisation","summary":"Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has motivated the development of approximately equivariant models that strike a middle ground between respecting symmetries and fitting the data distribution. Existing approaches in this field usually apply sample-based regularisers which depend on data augmentation at training time, incurring a high sample complexity, in particular for continuous groups such as $SO(3)$. This work instead approaches approximate equivariance via a projection-based regulariser which leverages the orthogonal decomposition of linear layers into equivariant and non-equivariant components. In contrast to existing methods, this penalises non-equivariance at an operator level across the full group orbit, rather than point-wise. We present a mathematical framework for computing the non-equivariance penalty exactly and efficiently in both the spatial and spectral domain. In our experiments, our method consistently outperforms prior approximate equivariance approaches in both model performance and efficiency, achieving substantial runtime gains over sample-based regularisers.","authors":["Torben Berndt","Jan Stühmer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05017v1","updated":"2026-01-08T15:18:36Z","published":"2026-01-08T15:18:36Z","title":"HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference","summary":"Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.","authors":["Xiaopeng Luo","Zexi Tan","Zhuowei Wang"],"pdf_url":"","comment":"Submitted to ICASSP 2026"},{"id":"http://arxiv.org/abs/2601.00245v2","updated":"2026-01-08T15:17:56Z","published":"2026-01-01T07:38:07Z","title":"Modern Neuromorphic AI: From Intra-Token to Inter-Token Processing","summary":"The rapid growth of artificial intelligence (AI) has brought novel data processing and generative capabilities but also escalating energy requirements. This challenge motivates renewed interest in neuromorphic computing principles, which promise brain-like efficiency through discrete and sparse activations, recurrent dynamics, and non-linear feedback. In fact, modern AI architectures increasingly embody neuromorphic principles through heavily quantized activations, state-space dynamics, and sparse attention mechanisms. This paper elaborates on the connections between neuromorphic models, state-space models, and transformer architectures through the lens of the distinction between intra-token processing and inter-token processing. Most early work on neuromorphic AI was based on spiking neural networks (SNNs) for intra-token processing, i.e., for transformations involving multiple channels, or features, of the same vector input, such as the pixels of an image. In contrast, more recent research has explored how neuromorphic principles can be leveraged to design efficient inter-token processing methods, which selectively combine different information elements depending on their contextual relevance. Implementing associative memorization mechanisms, these approaches leverage state-space dynamics or sparse self-attention. Along with a systematic presentation of modern neuromorphic AI models through the lens of intra-token and inter-token processing, training methodologies for neuromorphic AI models are also reviewed. These range from surrogate gradients leveraging parallel convolutional processing to local learning rules based on reinforcement learning mechanisms.","authors":["Osvaldo Simeone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05011v1","updated":"2026-01-08T15:11:04Z","published":"2026-01-08T15:11:04Z","title":"Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification","summary":"Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.","authors":["Karim El Khoury","Maxime Zanella","Tiffanie Godelaine","Christophe De Vleeschouwer","Benoit Macq"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05002v1","updated":"2026-01-08T15:00:35Z","published":"2026-01-08T15:00:35Z","title":"On the Hidden Objective Biases of Group-based Reinforcement Learning","summary":"Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.","authors":["Aleksandar Fontana","Marco Simoni","Giulio Rossolini","Andrea Saracino","Paolo Mori"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19075v2","updated":"2026-01-08T14:59:01Z","published":"2025-11-24T13:11:27Z","title":"Structured Matching via Cost-Regularized Unbalanced Optimal Transport","summary":"Unbalanced optimal transport (UOT) provides a flexible way to match or compare nonnegative finite Radon measures. However, UOT requires a predefined ground transport cost, which may misrepresent the data's underlying geometry. Choosing such a cost is particularly challenging when datasets live in heterogeneous spaces, often motivating practitioners to adopt Gromov-Wasserstein formulations. To address this challenge, we introduce cost-regularized unbalanced optimal transport (CR-UOT), a framework that allows the ground cost to vary while allowing mass creation and removal. We show that CR-UOT incorporates unbalanced Gromov-Wasserstein type problems through families of inner-product costs parameterized by linear transformations, enabling the matching of measures or point clouds across Euclidean spaces. We develop algorithms for such CR-UOT problems using entropic regularization and demonstrate that this approach improves the alignment of heterogeneous single-cell omics profiles, especially when many cells lack direct matches.","authors":["Emanuele Pardini","Katerina Papagiannouli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07541v2","updated":"2026-01-08T14:48:01Z","published":"2025-12-08T13:22:25Z","title":"High-Dimensional Change Point Detection using Graph Spanning Ratio","summary":"Inspired by graph-based methodologies, we introduce a novel graph-spanning algorithm designed to identify changes in both offline and online data across low to high dimensions. This versatile approach is applicable to Euclidean and graph-structured data with unknown distributions, while maintaining control over error probabilities. Theoretically, we demonstrate that the algorithm achieves high detection power when the magnitude of the change surpasses the lower bound of the minimax separation rate, which scales on the order of $\\sqrt{nd}$. Our method outperforms other techniques in terms of accuracy for both Gaussian and non-Gaussian data. Notably, it maintains strong detection power even with small observation windows, making it particularly effective for online environments where timely and precise change detection is critical.","authors":["Yang-Wen Sun","Katerina Papagiannouli","Vladimir Spokoiny"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.02005v3","updated":"2026-01-08T14:42:36Z","published":"2024-02-03T03:17:44Z","title":"Topology-Informed Graph Transformer","summary":"Transformers have revolutionized performance in Natural Language Processing and Vision, paving the way for their integration with Graph Neural Networks (GNNs). One key challenge in enhancing graph transformers is strengthening the discriminative power of distinguishing isomorphisms of graphs, which plays a crucial role in boosting their predictive performances. To address this challenge, we introduce 'Topology-Informed Graph Transformer (TIGT)', a novel transformer enhancing both discriminative power in detecting graph isomorphisms and the overall performance of Graph Transformers. TIGT consists of four components: A topological positional embedding layer using non-isomorphic universal covers based on cyclic subgraphs of graphs to ensure unique graph representation: A dual-path message-passing layer to explicitly encode topological characteristics throughout the encoder layers: A global attention mechanism: And a graph information layer to recalibrate channel-wise graph features for better feature representation. TIGT outperforms previous Graph Transformers in classifying synthetic dataset aimed at distinguishing isomorphism classes of graphs. Additionally, mathematical analysis and empirical evaluations highlight our model's competitive edge over state-of-the-art Graph Transformers across various benchmark datasets.","authors":["Yun Young Choi","Sun Woo Park","Minho Lee","Youngho Woo"],"pdf_url":"","comment":"Proceedings of the Geometry-grounded Representation Learning and Generative Modeling Workshop (GRaM) at ICML 2024"},{"id":"http://arxiv.org/abs/2505.22094v7","updated":"2026-01-08T14:39:03Z","published":"2025-05-28T08:17:16Z","title":"ReinFlow: Fine-tuning Flow Matching Policy with Online Reinforcement Learning","summary":"We propose ReinFlow, a simple yet effective online reinforcement learning (RL) framework that fine-tunes a family of flow matching policies for continuous robotic control. Derived from rigorous RL theory, ReinFlow injects learnable noise into a flow policy's deterministic path, converting the flow into a discrete-time Markov Process for exact and straightforward likelihood computation. This conversion facilitates exploration and ensures training stability, enabling ReinFlow to fine-tune diverse flow model variants, including Rectified Flow [35] and Shortcut Models [19], particularly at very few or even one denoising step. We benchmark ReinFlow in representative locomotion and manipulation tasks, including long-horizon planning with visual input and sparse reward. The episode reward of Rectified Flow policies obtained an average net growth of 135.36% after fine-tuning in challenging legged locomotion tasks while saving denoising steps and 82.63% of wall time compared to state-of-the-art diffusion RL fine-tuning method DPPO [43]. The success rate of the Shortcut Model policies in state and visual manipulation tasks achieved an average net increase of 40.34% after fine-tuning with ReinFlow at four or even one denoising step, whose performance is comparable to fine-tuned DDIM policies while saving computation time for an average of 23.20%. Project webpage: https://reinflow.github.io/","authors":["Tonghe Zhang","Chao Yu","Sichang Su","Yu Wang"],"pdf_url":"","comment":"38 pages"},{"id":"http://arxiv.org/abs/2502.18770v4","updated":"2026-01-08T14:33:47Z","published":"2025-02-26T02:57:59Z","title":"Reward Shaping to Mitigate Reward Hacking in RLHF","summary":"Reinforcement Learning from Human Feedback (RLHF) is essential for aligning large language models (LLMs) with human values. However, RLHF is susceptible to \\emph{reward hacking}, where the agent exploits flaws in the reward function rather than learning the intended behavior, thus degrading alignment. Although reward shaping helps stabilize RLHF and partially mitigate reward hacking, a systematic investigation into shaping techniques and their underlying principles remains lacking. To bridge this gap, we present a comprehensive study of the prevalent reward shaping methods. Our analysis suggests two key design principles: (1) the RL reward should be bounded, and (2) the RL reward benefits from rapid initial growth followed by gradual convergence. Guided by these insights, we propose Preference As Reward (PAR), a novel approach that leverages the latent preferences embedded within the reward model as the signal for reinforcement learning. Moreover, PAR exhibits two critical variance-reduction properties that contribute to stabilizing the RLHF training process and effectively extending the tolerance window for early stopping. We evaluated PAR on the base model Gemma2-2B using two datasets, Ultrafeedback-Binarized and HH-RLHF. Experimental results demonstrate PAR's superior performance over other reward shaping methods. On the AlpacaEval 2.0 benchmark, PAR achieves a win rate of at least 5 percentage points higher than competing approaches. Furthermore, PAR exhibits remarkable data efficiency, requiring only a single reference reward for optimal performance, and maintains robustness against reward hacking even after two full epochs of training. The code is available at https://github.com/PorUna-byte/PAR.","authors":["Jiayi Fu","Xuandong Zhao","Chengyuan Yao","Heng Wang","Qi Han","Yanghua Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04977v1","updated":"2026-01-08T14:29:24Z","published":"2026-01-08T14:29:24Z","title":"On the Definition and Detection of Cherry-Picking in Counterfactual Explanations","summary":"Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.","authors":["James Hinns","Sofie Goethals","Stephan Van der Veeken","Theodoros Evgeniou","David Martens"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.18503v2","updated":"2026-01-08T14:23:21Z","published":"2025-12-20T20:42:30Z","title":"NASTaR: NovaSAR Automated Ship Target Recognition Dataset","summary":"Synthetic Aperture Radar (SAR) offers a unique capability for all-weather, space-based maritime activity monitoring by capturing and imaging strong reflections from ships at sea. A well-defined challenge in this domain is ship type classification. Due to the high diversity and complexity of ship types, accurate recognition is difficult and typically requires specialized deep learning models. These models, however, depend on large, high-quality ground-truth datasets to achieve robust performance and generalization. Furthermore, the growing variety of SAR satellites operating at different frequencies and spatial resolutions has amplified the need for more annotated datasets to enhance model accuracy. To address this, we present the NovaSAR Automated Ship Target Recognition (NASTaR) dataset. This dataset comprises of 3415 ship patches extracted from NovaSAR S-band imagery, with labels matched to AIS data. It includes distinctive features such as 23 unique classes, inshore/offshore separation, and an auxiliary wake dataset for patches where ship wakes are visible. We validated the dataset applicability across prominent ship-type classification scenarios using benchmark deep learning models. Results demonstrate over 60% accuracy for classifying four major ship types, over 70% for a three-class scenario, more than 75% for distinguishing cargo from tanker ships, and over 87% for identifying fishing vessels. The NASTaR dataset is available at https://doi.org/10.5523/bris.2tfa6x37oerz2lyiw6hp47058, while relevant codes for benchmarking and analysis are available at https://github.com/benyaminhosseiny/nastar.","authors":["Benyamin Hosseiny","Kamirul Kamirul","Odysseas Pappas","Alin Achim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14195v2","updated":"2026-01-08T14:19:17Z","published":"2025-11-18T07:03:58Z","title":"N-GLARE: An Non-Generative Latent Representation-Efficient LLM Safety Evaluator","summary":"Evaluating the safety robustness of LLMs is critical for their deployment. However, mainstream Red Teaming methods rely on online generation and black-box output analysis. These approaches are not only costly but also suffer from feedback latency, making them unsuitable for agile diagnostics after training a new model. To address this, we propose N-GLARE (A Non-Generative, Latent Representation-Efficient LLM Safety Evaluator). N-GLARE operates entirely on the model's latent representations, bypassing the need for full text generation. It characterizes hidden layer dynamics by analyzing the APT (Angular-Probabilistic Trajectory) of latent representations and introducing the JSS (Jensen-Shannon Separability) metric. Experiments on over 40 models and 20 red teaming strategies demonstrate that the JSS metric exhibits high consistency with the safety rankings derived from Red Teaming. N-GLARE reproduces the discriminative trends of large-scale red-teaming tests at less than 1\\% of the token cost and the runtime cost, providing an efficient output-free evaluation proxy for real-time diagnostics.","authors":["Zheyu Lin","Jirui Yang","Yukui Qiu","Hengqi Guo","Yubing Bao","Yao Guan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.21409v2","updated":"2026-01-08T14:14:03Z","published":"2025-12-24T20:15:41Z","title":"kooplearn: A Scikit-Learn Compatible Library of Algorithms for Evolution Operator Learning","summary":"kooplearn is a machine-learning library that implements linear, kernel, and deep-learning estimators of dynamical operators and their spectral decompositions. kooplearn can model both discrete-time evolution operators (Koopman/Transfer) and continuous-time infinitesimal generators. By learning these operators, users can analyze dynamical systems via spectral methods, derive data-driven reduced-order models, and forecast future states and observables. kooplearn's interface is compliant with the scikit-learn API, facilitating its integration into existing machine learning and data science workflows. Additionally, kooplearn includes curated benchmark datasets to support experimentation, reproducibility, and the fair comparison of learning algorithms. The software is available at https://github.com/Machine-Learning-Dynamical-Systems/kooplearn.","authors":["Giacomo Turri","Grégoire Pacreau","Giacomo Meanti","Timothée Devergne","Daniel Ordonez","Erfan Mirzaei","Bruno Belucci","Karim Lounici","Vladimir Kostic","Massimiliano Pontil","Pietro Novelli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.16938v3","updated":"2026-01-08T14:11:16Z","published":"2025-06-20T12:05:31Z","title":"Enhancing Expressivity of Quantum Neural Networks Based on the SWAP test","summary":"Quantum neural networks (QNNs) based on parametrized quantum circuits are promising candidates for machine learning applications, yet many architectures lack clear connections to classical models, potentially limiting their ability to leverage established classical neural network techniques. We examine QNNs built from SWAP test circuits and discuss their equivalence to classical two-layer feedforward networks with quadratic activations under amplitude encoding. Evaluation on real-world and synthetic datasets shows that while this architecture learns many practical binary classification tasks, it has fundamental expressivity limitations: polynomial activation functions do not satisfy the universal approximation theorem, and we show analytically that the architecture cannot learn the parity check function beyond two dimensions, regardless of network size. To address this, we introduce generalized SWAP test circuits with multiple Fredkin gates sharing an ancilla, implementing product layers with polynomial activations of arbitrary even degree. This modification enables successful learning of parity check functions in arbitrary dimensions as well as binary n-spiral tasks, and we provide numerical evidence that the expressivity enhancement extends to alternative encoding schemes such as angle (Z) and ZZ feature maps. We validate the practical feasibility of our proposed architecture by implementing a classically pretrained instance on the IBM Torino quantum processor, achieving 84% classification accuracy on the three-dimensional parity check despite hardware noise. Our work establishes a framework for analyzing and enhancing QNN expressivity through correspondence with classical architectures, and demonstrates that SWAP test-based QNNs possess broad representational capacity relevant to both classical and potentially quantum learning tasks.","authors":["Sebastian Nagies","Emiliano Tolotti","Davide Pastorello","Enrico Blanzieri"],"pdf_url":"","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.05988v2","updated":"2026-01-08T14:09:36Z","published":"2025-08-08T03:46:21Z","title":"Pruning the Unsurprising: Efficient LLM Reasoning via First-Token Surprisal","summary":"Large Reasoning Models (LRMs) have demonstrated remarkable capabilities by scaling up the length of Chain-of-Thought (CoT). However, excessively long reasoning traces pose substantial challenges for training cost and inference latency. While various CoT compression approaches have emerged to address this challenge, they face inherent trade-offs: token-level methods often disrupt syntactic and logical coherence, while step-level methods based on perplexity fail to reliably capture the logically critical reasoning steps because of the dilution of logical information. In this paper, we propose ASAP (Anchor-guided, SurprisAl-based Pruning), a novel coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided pruning to preserve the core reasoning structure, which efficiently reduces the search space for subsequent processing. Leveraging the insight that logical branching choices are concentrated at the onset of reasoning steps, it then enables logic-aware pruning by selecting logically essential reasoning steps based on a novel first-token surprisal metric. Finally, ASAP distills the models to autonomously generate and leverage these concise CoTs at inference time, enabling efficient reasoning. Experiments show that ASAP achieves state-of-the-art accuracy across multiple benchmarks while substantially reducing training and inference costs.","authors":["Wenhao Zeng","Yaoning Wang","Chao Hu","Yuling Shi","Chengcheng Wan","Hongyu Zhang","Xiaodong Gu"],"pdf_url":"","comment":"Code and model available at https://github.com/Zengwh02/ASAP"},{"id":"http://arxiv.org/abs/2601.04954v1","updated":"2026-01-08T14:00:51Z","published":"2026-01-08T14:00:51Z","title":"Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following","summary":"A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.","authors":["Yirong Zeng","Yufei Liu","Xiao Ding","Yutai Hou","Yuxian Wang","Haonan Song","Wu Ning","Dandan Tu","Qixun Zhang","Bibo Cai","Yuxiang He","Ting Liu"],"pdf_url":"","comment":"ACL under review 13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2408.11266v4","updated":"2026-01-08T13:54:27Z","published":"2024-08-21T01:34:20Z","title":"Practical Aspects on Solving Differential Equations Using Deep Learning: A Primer","summary":"Deep learning has become a popular tool across many scientific fields, including the study of differential equations, particularly partial differential equations. This work introduces the basic principles of deep learning and the Deep Galerkin method, which uses deep neural networks to solve differential equations. This primer aims to provide technical and practical insights into the Deep Galerkin method and its implementation. We demonstrate how to solve the one-dimensional heat equation step-by-step. We also show how to apply the Deep Galerkin method to solve systems of ordinary differential equations and integral equations, such as the Fredholm of the second kind. Additionally, we provide code snippets within the text and the complete source code on Github. The examples are designed so that one can run them on a simple computer without needing a GPU.","authors":["Georgios Is. Detorakis"],"pdf_url":"","comment":"32 pages, 12 figures, primer (tutorial)"},{"id":"http://arxiv.org/abs/2511.03554v2","updated":"2026-01-08T13:52:55Z","published":"2025-11-05T15:35:46Z","title":"The Structure of Cross-Validation Error: Stability, Covariance, and Minimax Limits","summary":"Despite ongoing theoretical research on cross-validation (CV), many theoretical questions remain widely open. This motivates our investigation into how properties of algorithm-distribution pairs can affect the choice for the number of folds in $k$-fold CV.\n  Our results consist of a novel decomposition of the mean-squared error of cross-validation for risk estimation, which explicitly captures the correlations of error estimates across overlapping folds and includes a novel algorithmic stability notion, squared loss stability, that is considerably weaker than the typically required hypothesis stability in other comparable works.\n  Furthermore, we prove:\n  1. For any learning algorithm that minimizes empirical risk, the mean-squared error of the $k$-fold cross-validation estimator $\\widehat{L}_{\\mathrm{CV}}^{(k)}$ of the population risk $L_{D}$ satisfies the following minimax lower bound: \\[ \\min_{k \\mid n} \\max_{D} \\mathbb{E}\\left[\\big(\\widehat{L}_{\\mathrm{CV}}^{(k)} - L_{D}\\big)^{2}\\right]=Ω\\big(\\sqrt{k^*}/n\\big), \\] where $n$ is the sample size, $k$ the number of folds, and $k^*$ denotes the number of folds attaining the minimax optimum. This shows that even under idealized conditions, for large values of $k$, CV cannot attain the optimum of order $1/n$ achievable by a validation set of size $n$, reflecting an inherent penalty caused by dependence between folds.\n  2. Complementing this, we exhibit learning rules for which \\[ \\max_{D}\\mathbb{E}\\!\\left[\\big(\\widehat{L}_{\\mathrm{CV}}^{(k)} - L_{D}\\big)^{2}\\right]=Ω(k/n), \\] matching (up to constants) the accuracy of a hold-out estimator of a single fold of size $n/k$.\n  Together these results delineate the fundamental trade-off in resampling-based risk estimation: CV cannot fully exploit all $n$ samples for unbiased risk evaluation, and its minimax performance is pinned between the $k/n$ and $\\sqrt{k}/n$ regimes.","authors":["Ido Nachum","Rüdiger Urbanke","Thomas Weinberger"],"pdf_url":"","comment":"60 pages"},{"id":"http://arxiv.org/abs/2601.04941v1","updated":"2026-01-08T13:43:55Z","published":"2026-01-08T13:43:55Z","title":"Cardinality augmented loss functions","summary":"Class imbalance is a common and pernicious issue for the training of neural networks. Often, an imbalanced majority class can dominate training to skew classifier performance towards the majority outcome. To address this problem we introduce cardinality augmented loss functions, derived from cardinality-like invariants in modern mathematics literature such as magnitude and the spread. These invariants enrich the concept of cardinality by evaluating the `effective diversity' of a metric space, and as such represent a natural solution to overly homogeneous training data. In this work, we establish a methodology for applying cardinality augmented loss functions in the training of neural networks and report results on both artificially imbalanced datasets as well as a real-world imbalanced material science dataset. We observe significant performance improvement among minority classes, as well as improvement in overall performance metrics.","authors":["Miguel O'Malley"],"pdf_url":"","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2601.03919v2","updated":"2026-01-08T13:31:51Z","published":"2026-01-07T13:40:30Z","title":"A Gap Between Decision Trees and Neural Networks","summary":"We study when geometric simplicity of decision boundaries, used here as a notion of interpretability, can conflict with accurate approximation of axis-aligned decision trees by shallow neural networks. Decision trees induce rule-based, axis-aligned decision regions (finite unions of boxes), whereas shallow ReLU networks are typically trained as score models whose predictions are obtained by thresholding. We analyze the infinite-width, bounded-norm, single-hidden-layer ReLU class through the Radon total variation ($\\mathrm{R}\\mathrm{TV}$) seminorm, which controls the geometric complexity of level sets.\n  We first show that the hard tree indicator $1_A$ has infinite $\\mathrm{R}\\mathrm{TV}$. Moreover, two natural split-wise continuous surrogates--piecewise-linear ramp smoothing and sigmoidal (logistic) smoothing--also have infinite $\\mathrm{R}\\mathrm{TV}$ in dimensions $d>1$, while Gaussian convolution yields finite $\\mathrm{R}\\mathrm{TV}$ but with an explicit exponential dependence on $d$.\n  We then separate two goals that are often conflated: classification after thresholding (recovering the decision set) versus score learning (learning a calibrated score close to $1_A$). For classification, we construct a smooth barrier score $S_A$ with finite $\\mathrm{R}\\mathrm{TV}$ whose fixed threshold $τ=1$ exactly recovers the box. Under a mild tube-mass condition near $\\partial A$, we prove an $L_1(P)$ calibration bound that decays polynomially in a sharpness parameter, along with an explicit $\\mathrm{R}\\mathrm{TV}$ upper bound in terms of face measures. Experiments on synthetic unions of rectangles illustrate the resulting accuracy--complexity tradeoff and how threshold selection shifts where training lands along it.","authors":["Akash Kumar"],"pdf_url":"","comment":"45 pages, plots were improved"},{"id":"http://arxiv.org/abs/2506.01722v3","updated":"2026-01-08T13:15:15Z","published":"2025-06-02T14:29:05Z","title":"When Lower-Order Terms Dominate: Adaptive Expert Algorithms for Heavy-Tailed Losses","summary":"We consider the problem setting of prediction with expert advice with possibly heavy-tailed losses, i.e. the only assumption on the losses is an upper bound on their second moments, denoted by $θ$. We develop adaptive algorithms that do not require any prior knowledge about the range or the second moment of the losses. Existing adaptive algorithms have what is typically considered a lower-order term in their regret guarantees. We show that this lower-order term, which is often the maximum of the losses, can actually dominate the regret bound in our setting. Specifically, we show that even with small constant $θ$, this lower-order term can scale as $\\sqrt{KT}$, where $K$ is the number of experts and $T$ is the time horizon. We propose adaptive algorithms with improved regret bounds that avoid the dependence on such a lower-order term and guarantee $\\mathcal{O}(\\sqrt{θT\\log(K)})$ regret in the worst case, and $\\mathcal{O}(θ\\log(KT)/Δ_{\\min})$ regret when the losses are sampled i.i.d. from some fixed distribution, where $Δ_{\\min}$ is the difference between the mean losses of the second best expert and the best expert. Additionally, when the loss function is the squared loss, our algorithm also guarantees improved regret bounds over prior results.","authors":["Antoine Moulin","Emmanuel Esposito","Dirk van der Hoeven"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04907v1","updated":"2026-01-08T13:05:36Z","published":"2026-01-08T13:05:36Z","title":"Distributed Online Convex Optimization with Efficient Communication: Improved Algorithm and Lower bounds","summary":"We investigate distributed online convex optimization with compressed communication, where $n$ learners connected by a network collaboratively minimize a sequence of global loss functions using only local information and compressed data from neighbors. Prior work has established regret bounds of $O(\\max\\{ω^{-2}ρ^{-4}n^{1/2},ω^{-4}ρ^{-8}\\}n\\sqrt{T})$ and $O(\\max\\{ω^{-2}ρ^{-4}n^{1/2},ω^{-4}ρ^{-8}\\}n\\ln{T})$ for convex and strongly convex functions, respectively, where $ω\\in(0,1]$ is the compression quality factor ($ω=1$ means no compression) and $ρ<1$ is the spectral gap of the communication matrix. However, these regret bounds suffer from a \\emph{quadratic} or even \\emph{quartic} dependence on $ω^{-1}$. Moreover, the \\emph{super-linear} dependence on $n$ is also undesirable. To overcome these limitations, we propose a novel algorithm that achieves improved regret bounds of $\\tilde{O}(ω^{-1/2}ρ^{-1}n\\sqrt{T})$ and $\\tilde{O}(ω^{-1}ρ^{-2}n\\ln{T})$ for convex and strongly convex functions, respectively. The primary idea is to design a \\emph{two-level blocking update framework} incorporating two novel ingredients: an online gossip strategy and an error compensation scheme, which collaborate to \\emph{achieve a better consensus} among learners. Furthermore, we establish the first lower bounds for this problem, justifying the optimality of our results with respect to both $ω$ and $T$. Additionally, we consider the bandit feedback scenario, and extend our method with the classic gradient estimators to enhance existing regret bounds.","authors":["Sifan Yang","Wenhao Yang","Wei Jiang","Lijun Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04899v1","updated":"2026-01-08T12:53:33Z","published":"2026-01-08T12:53:33Z","title":"Rotation-Robust Regression with Convolutional Model Trees","summary":"We study rotation-robust learning for image inputs using Convolutional Model Trees (CMTs) [1], whose split and leaf coefficients can be structured on the image grid and transformed geometrically at deployment time. In a controlled MNIST setting with a rotation-invariant regression target, we introduce three geometry-aware inductive biases for split directions -- convolutional smoothing, a tilt dominance constraint, and importance-based pruning -- and quantify their impact on robustness under in-plane rotations. We further evaluate a deployment-time orientation search that selects a discrete rotation maximizing a forest-level confidence proxy without updating model parameters. Orientation search improves robustness under severe rotations but can be harmful near the canonical orientation when confidence is misaligned with correctness. Finally, we observe consistent trends on MNIST digit recognition implemented as one-vs-rest regression, highlighting both the promise and limitations of confidence-based orientation selection for model-tree ensembles.","authors":["Hongyi Li","William Ward Armstrong","Jun Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04897v1","updated":"2026-01-08T12:50:14Z","published":"2026-01-08T12:50:14Z","title":"V-FAT: Benchmarking Visual Fidelity Against Text-bias","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated impressive performance on standard visual reasoning benchmarks. However, there is growing concern that these models rely excessively on linguistic shortcuts rather than genuine visual grounding, a phenomenon we term Text Bias. In this paper, we investigate the fundamental tension between visual perception and linguistic priors. We decouple the sources of this bias into two dimensions: Internal Corpus Bias, stemming from statistical correlations in pretraining, and External Instruction Bias, arising from the alignment-induced tendency toward sycophancy. To quantify this effect, we introduce V-FAT (Visual Fidelity Against Text-bias), a diagnostic benchmark comprising 4,026 VQA instances across six semantic domains. V-FAT employs a Three-Level Evaluation Framework that systematically increases the conflict between visual evidence and textual information: (L1) internal bias from atypical images, (L2) external bias from misleading instructions, and (L3) synergistic bias where both coincide. We introduce the Visual Robustness Score (VRS), a metric designed to penalize \"lucky\" linguistic guesses and reward true visual fidelity. Our evaluation of 12 frontier MLLMs reveals that while models excel in existing benchmarks, they experience significant visual collapse under high linguistic dominance.","authors":["Ziteng Wang","Yujie He","Guanliang Li","Siqi Yang","Jiaqi Xiong","Songxiang Liu"],"pdf_url":"","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2601.03706v2","updated":"2026-01-08T12:49:45Z","published":"2026-01-07T08:44:03Z","title":"The Geometry of the Pivot: A Note on Lazy Pivoted Cholesky and Farthest Point Sampling","summary":"Low-rank approximations of large kernel matrices are ubiquitous in machine learning, particularly for scaling Gaussian Processes to massive datasets. The Pivoted Cholesky decomposition is a standard tool for this task, offering a computationally efficient, greedy low-rank approximation. While its algebraic properties are well-documented in numerical linear algebra, its geometric intuition within the context of kernel methods often remains obscure. In this note, we elucidate the geometric interpretation of the algorithm within the Reproducing Kernel Hilbert Space (RKHS). We demonstrate that the pivotal selection step is mathematically equivalent to Farthest Point Sampling (FPS) using the kernel metric, and that the Cholesky factor construction is an implicit Gram-Schmidt orthogonalization. We provide a concise derivation and a minimalist Python implementation to bridge the gap between theory and practice.","authors":["Gil Shabat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04891v1","updated":"2026-01-08T12:42:17Z","published":"2026-01-08T12:42:17Z","title":"Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform","summary":"Vision Language Models (VLMs) have shown strong performance on multimodal reasoning tasks, yet most evaluations focus on short videos and assume unconstrained computational resources. In industrial settings such as pharmaceutical content understanding, practitioners must process long-form videos under strict GPU, latency, and cost constraints, where many existing approaches fail to scale. In this work, we present an industrial GenAI framework that processes over 200,000 PDFs, 25,326 videos across eight formats (e.g., MP4, M4V, etc.), and 888 multilingual audio files in more than 20 languages. Our study makes three contributions: (i) an industrial large-scale architecture for multimodal reasoning in pharmaceutical domains; (ii) empirical analysis of over 40 VLMs on two leading benchmarks (Video-MME and MMBench) and proprietary dataset of 25,326 videos across 14 disease areas; and (iii) four findings relevant to long-form video reasoning: the role of multimodality, attention mechanism trade-offs, temporal reasoning limits, and challenges of video splitting under GPU constraints. Results show 3-8 times efficiency gains with SDPA attention on commodity GPUs, multimodality improving up to 8/12 task domains (especially length-dependent tasks), and clear bottlenecks in temporal alignment and keyframe detection across open- and closed-source VLMs. Rather than proposing a new \"A+B\" model, this paper characterizes practical limits, trade-offs, and failure patterns of current VLMs under realistic deployment constraints, and provide actionable guidance for both researchers and practitioners designing scalable multimodal systems for long-form video understanding in industrial domains.","authors":["Suyash Mishra","Qiang Li","Srikanth Patil","Satyanarayan Pati","Baddu Narendra"],"pdf_url":"","comment":"Submitted to the Industry Track of Top Tier Conference; currently under peer review"},{"id":"http://arxiv.org/abs/2601.04890v1","updated":"2026-01-08T12:41:49Z","published":"2026-01-08T12:41:49Z","title":"Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers","summary":"Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.","authors":["Maksim Velikanov","Ilyas Chahed","Jingwei Zuo","Dhia Eddine Rhaiem","Younes Belkada","Hakim Hacid"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04885v1","updated":"2026-01-08T12:30:43Z","published":"2026-01-08T12:30:43Z","title":"CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters","summary":"As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \\textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \\textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \\textbf{\\textsc{CuMA}} (\\textbf{Cu}ltural \\textbf{M}ixture of \\textbf{A}dapters), a framework that frames alignment as a \\textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \\textsc{CuMA} internalizes a \\textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \\textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \\textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.","authors":["Ao Sun","Xiaoyu Wang","Zhe Tan","Yu Li","Jiachen Zhu","Shu Su","Yuheng Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04878v1","updated":"2026-01-08T12:25:37Z","published":"2026-01-08T12:25:37Z","title":"Higher-Order Knowledge Representations for Agentic Scientific Reasoning","summary":"Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a \"teacherless\" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.","authors":["Isabella A. Stewart","Markus J. Buehler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04873v1","updated":"2026-01-08T12:18:41Z","published":"2026-01-08T12:18:41Z","title":"FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions","summary":"Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.\n  A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.\n  Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.","authors":["Elisa Roldan","Kirstie Andrews","Stephen M. Richardson","Reyhaneh Fatahian","Glen Cooper","Rasool Erfani","Tasneem Sabir","Neil D. Reeves"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04867v1","updated":"2026-01-08T12:04:41Z","published":"2026-01-08T12:04:41Z","title":"Gradient-based Optimisation of Modulation Effects","summary":"Modulation effects such as phasers, flangers and chorus effects are heavily used in conjunction with the electric guitar. Machine learning based emulation of analog modulation units has been investigated in recent years, but most methods have either been limited to one class of effect or suffer from a high computational cost or latency compared to canonical digital implementations. Here, we build on previous work and present a framework for modelling flanger, chorus and phaser effects based on differentiable digital signal processing. The model is trained in the time-frequency domain, but at inference operates in the time-domain, requiring zero latency. We investigate the challenges associated with gradient-based optimisation of such effects, and show that low-frequency weighting of loss functions avoids convergence to local minima when learning delay times. We show that when trained against analog effects units, sound output from the model is in some cases perceptually indistinguishable from the reference, but challenges still remain for effects with long delay times and feedback.","authors":["Alistair Carson","Alec Wright","Stefan Bilbao"],"pdf_url":"","comment":"Submitted to J. Audio Eng. Soc. Dec. 2025"},{"id":"http://arxiv.org/abs/2601.04855v1","updated":"2026-01-08T11:45:59Z","published":"2026-01-08T11:45:59Z","title":"Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution","summary":"Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.","authors":["Francesco Ferrini","Veronica Lachi","Antonio Longa","Bruno Lepri","Matono Akiyoshi","Andrea Passerini","Xin Liu","Manfred Jaeger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04854v1","updated":"2026-01-08T11:44:34Z","published":"2026-01-08T11:44:34Z","title":"Token Maturation: Autoregressive Language Generation via Continuous Token Dynamics","summary":"Autoregressive language models are conventionally defined over discrete token sequences, committing to a specific token at every generation step. This early discretization forces uncertainty to be resolved through token-level sampling, often leading to instability, repetition, and sensitivity to decoding heuristics.\n  In this work, we introduce a continuous autoregressive formulation of language generation in which tokens are represented as continuous vectors that \\emph{mature} over multiple update steps before being discretized. Rather than sampling tokens, the model evolves continuous token representations through a deterministic dynamical process, committing to a discrete token only when the representation has sufficiently converged. Discrete text is recovered via hard decoding, while uncertainty is maintained and resolved in the continuous space.\n  We show that this maturation process alone is sufficient to produce coherent and diverse text using deterministic decoding (argmax), without reliance on token-level sampling, diffusion-style denoising, or auxiliary stabilization mechanisms. Additional perturbations, such as stochastic dynamics or history smoothing, can be incorporated naturally but are not required for the model to function.\n  To our knowledge, this is the first autoregressive language model that generates text by evolving continuous token representations to convergence prior to discretization, enabling stable generation without token-level sampling.","authors":["Oshri Naparstek"],"pdf_url":"","comment":"In preperation to ICML 2026"},{"id":"http://arxiv.org/abs/2505.21400v2","updated":"2026-01-08T11:30:06Z","published":"2025-05-27T16:24:20Z","title":"Breaking AR's Sampling Bottleneck: Provable Acceleration via Diffusion Language Models","summary":"Diffusion models have emerged as a powerful paradigm for modern generative modeling, demonstrating strong potential for large language models (LLMs). Unlike conventional autoregressive (AR) models that generate tokens sequentially, diffusion models allow for parallel sampling, offering a promising path to accelerate generation and eliminate the left-to-right generation constraints. Despite their empirical success, theoretical understandings of diffusion language models remain underdeveloped. In this work, we develop convergence guarantees for diffusion language models from an information-theoretic perspective. Our analysis demonstrates that the sampling error, measured by the Kullback-Leibler (KL) divergence, decays inversely with the number of iterations $T$ and scales linearly with the mutual information between tokens in the target text sequence. Crucially, our theory covers the regime $T<L$, where $L$ is the text sequence length. This justifies that high-quality samples can be generated with fewer iterations than $L$, thereby breaking the fundamental sampling bottleneck of $L$ steps required by AR models. We further establish matching upper and lower bounds, up to some constant factor, that shows the tightness of our convergence analysis. These results offer novel theoretical insights into the practical effectiveness of diffusion language models.","authors":["Gen Li","Changxiao Cai"],"pdf_url":"","comment":"This is the full version of a paper published at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2503.10509v3","updated":"2026-01-08T11:06:58Z","published":"2025-03-13T16:10:14Z","title":"From Actions to Words: Towards Abstractive-Textual Policy Summarization in RL","summary":"Explaining reinforcement learning agents is challenging because policies emerge from complex reward structures and neural representations that are difficult for humans to interpret. Existing approaches often rely on curated demonstrations that expose local behaviors but provide limited insight into an agent's global strategy, leaving users to infer intent from raw observations. We propose SySLLM (Synthesized Summary using Large Language Models), a framework that reframes policy interpretation as a language-generation problem. Instead of visual demonstrations, SySLLM converts spatiotemporal trajectories into structured text and prompts an LLM to generate coherent summaries describing the agent's goals, exploration style, and decision patterns. SySLLM scales to long-horizon, semantically rich environments without task-specific fine-tuning, leveraging LLM world knowledge and compositional reasoning to capture latent behavioral structure across policies. Expert evaluations show strong alignment with human analyses, and a large-scale user study found that 75.5% of participants preferred SySLLM summaries over state-of-the-art demonstration-based explanations. Together, these results position abstractive textual summarization as a paradigm for interpreting complex RL behavior.","authors":["Sahar Admoni","Assaf Hallak","Yftah Ziser","Omer Ben-Porat","Ofra Amir"],"pdf_url":"","comment":"In Proceedings of AAMAS 2026 (The 25th International Conference on Autonomous Agents and Multi-Agent Systems)"},{"id":"http://arxiv.org/abs/2601.04825v1","updated":"2026-01-08T11:00:40Z","published":"2026-01-08T11:00:40Z","title":"Illumination Angular Spectrum Encoding for Controlling the Functionality of Diffractive Networks","summary":"Diffractive neural networks have recently emerged as a promising framework for all-optical computing. However, these networks are typically trained for a single task, limiting their potential adoption in systems requiring multiple functionalities. Existing approaches to achieving multi-task functionality either modify the mechanical configuration of the network per task or use a different illumination wavelength or polarization state for each task. In this work, we propose a new control mechanism, which is based on the illumination's angular spectrum. Specifically, we shape the illumination using an amplitude mask that selectively controls its angular spectrum. We employ different illumination masks for achieving different network functionalities, so that the mask serves as a unique task encoder. Interestingly, we show that effective control can be achieved over a very narrow angular range, within the paraxial regime. We numerically illustrate the proposed approach by training a single diffractive network to perform multiple image-to-image translation tasks. In particular, we demonstrate translating handwritten digits into typeset digits of different values, and translating handwritten English letters into typeset numbers and typeset Greek letters, where the type of the output is determined by the illumination's angular components. As we show, the proposed framework can work under different coherence conditions, and can be combined with existing control strategies, such as different wavelengths. Our results establish the illumination angular spectrum as a powerful degree of freedom for controlling diffractive networks, enabling a scalable and versatile framework for multi-task all-optical computing.","authors":["Matan Kleiner","Lior Michaeli","Tomer Michaeli"],"pdf_url":"","comment":"Project's code https://github.com/matankleiner/Angular-Spectrum-Encoding"},{"id":"http://arxiv.org/abs/2509.04069v2","updated":"2026-01-08T10:57:57Z","published":"2025-09-04T10:02:32Z","title":"Solving Robotics Tasks with Prior Demonstration via Exploration-Efficient Deep Reinforcement Learning","summary":"This paper proposes an exploration-efficient Deep Reinforcement Learning with Reference policy (DRLR) framework for learning robotics tasks that incorporates demonstrations. The DRLR framework is developed based on an algorithm called Imitation Bootstrapped Reinforcement Learning (IBRL). We propose to improve IBRL by modifying the action selection module. The proposed action selection module provides a calibrated Q-value, which mitigates the bootstrapping error that otherwise leads to inefficient exploration. Furthermore, to prevent the RL policy from converging to a sub-optimal policy, SAC is used as the RL policy instead of TD3. The effectiveness of our method in mitigating bootstrapping error and preventing overfitting is empirically validated by learning two robotics tasks: bucket loading and open drawer, which require extensive interactions with the environment. Simulation results also demonstrate the robustness of the DRLR framework across tasks with both low and high state-action dimensions, and varying demonstration qualities. To evaluate the developed framework on a real-world industrial robotics task, the bucket loading task is deployed on a real wheel loader. The sim2real results validate the successful deployment of the DRLR framework.","authors":["Chengyandan Shen","Christoffer Sloth"],"pdf_url":"","comment":"This paper has been accepted for Journal publication in Frontiers in Robotics and AI"},{"id":"http://arxiv.org/abs/2601.01747v2","updated":"2026-01-08T10:46:04Z","published":"2026-01-05T02:49:33Z","title":"Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization","summary":"Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs","authors":["Jiwei Guan","Haibo Jin","Haohan Wang"],"pdf_url":"","comment":"EACL"},{"id":"http://arxiv.org/abs/2601.04808v1","updated":"2026-01-08T10:41:07Z","published":"2026-01-08T10:41:07Z","title":"Comparison of Maximum Likelihood Classification Before and After Applying Weierstrass Transform","summary":"The aim of this paper is to use Maximum Likelihood (ML) Classification on multispectral data by means of qualitative and quantitative approaches. Maximum Likelihood is a supervised classification algorithm which is based on the Classical Bayes theorem. It makes use of a discriminant function to assign pixel to the class with the highest likelihood. Class means vector and covariance matrix are the key inputs to the function and can be estimated from training pixels of a particular class. As Maximum Likelihood need some assumptions before it has to be applied on the data. In this paper we will compare the results of Maximum Likelihood Classification (ML) before apply the Weierstrass Transform and apply Weierstrass Transform and will see the difference between the accuracy on training pixels of high resolution Quickbird satellite image. Principle Component analysis (PCA) is also used for dimension reduction and also used to check the variation in bands. The results shows that the separation between mean of the classes in the decision space is to be the main factor that leads to the high classification accuracy of Maximum Likelihood (ML) after using Weierstrass Transform than without using it.","authors":["Muhammad Shoaib","Zaka Ur Rehman","Muhammad Qasim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04807v1","updated":"2026-01-08T10:39:48Z","published":"2026-01-08T10:39:48Z","title":"Parallelizing Node-Level Explainability in Graph Neural Networks","summary":"Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.","authors":["Oscar Llorente","Jaime Boal","Eugenio F. Sánchez-Úbeda","Antonio Diaz-Cano","Miguel Familiar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04801v1","updated":"2026-01-08T10:32:49Z","published":"2026-01-08T10:32:49Z","title":"MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration","summary":"High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at https://github.com/wslcccc/MPM-LLM4DSE.","authors":["Lei Xu","Shanshan Wang","Chenglong Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24334v2","updated":"2026-01-08T10:31:52Z","published":"2025-12-30T16:40:02Z","title":"OptiVote: Non-Coherent FSO Over-the-Air Majority Vote for Communication-Efficient Distributed Federated Learning in Space Data Centers","summary":"The rapid deployment of mega-constellations is driving the long-term vision of space data centers (SDCs), where interconnected satellites form in-orbit distributed computing and learning infrastructures. Enabling distributed federated learning in such systems is challenging because iterative training requires frequent aggregation over inter-satellite links that are bandwidth- and energy-constrained, and the link conditions can be highly dynamic. In this work, we exploit over-the-air computation (AirComp) as an in-network aggregation primitive. However, conventional coherent AirComp relies on stringent phase alignment, which is difficult to maintain in space environments due to satellite jitter and Doppler effects. To overcome this limitation, we propose OptiVote, a robust and communication-efficient non-coherent free-space optical (FSO) AirComp framework for federated learning toward Space Data Centers. OptiVote integrates sign stochastic gradient descent (signSGD) with a majority-vote (MV) aggregation principle and pulse-position modulation (PPM), where each satellite conveys local gradient signs by activating orthogonal PPM time slots. The aggregation node performs MV detection via non-coherent energy accumulation, transforming phase-sensitive field superposition into phase-agnostic optical intensity combining, thereby eliminating the need for precise phase synchronization and improving resilience under dynamic impairments. To mitigate aggregation bias induced by heterogeneous FSO channels, we further develop an importance-aware, channel state information (CSI)-free dynamic power control scheme that balances received energies without additional signaling. We provide theoretical analysis by characterizing the aggregate error probability under statistical FSO channels and establishing convergence guarantees for non-convex objectives.","authors":["Anbang Zhang","Chenyuan Feng","Wai Ho Mow","Jia Ye","Shuaishuai Guo","Geyong Min","Tony Q. S. Quek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04799v1","updated":"2026-01-08T10:29:49Z","published":"2026-01-08T10:29:49Z","title":"Neural-Symbolic Integration with Evolvable Policies","summary":"Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.","authors":["Marios Thoma","Vassilis Vassiliades","Loizos Michael"],"pdf_url":"","comment":"18 pages, 12 figures, related code available at https://github.com/CYENS/evolvable-nesy"},{"id":"http://arxiv.org/abs/2601.04791v1","updated":"2026-01-08T10:15:35Z","published":"2026-01-08T10:15:35Z","title":"Measurement-Consistent Langevin Corrector: A Remedy for Latent Diffusion Inverse Solvers","summary":"With recent advances in generative models, diffusion models have emerged as powerful priors for solving inverse problems in each domain. Since Latent Diffusion Models (LDMs) provide generic priors, several studies have explored their potential as domain-agnostic zero-shot inverse solvers. Despite these efforts, existing latent diffusion inverse solvers suffer from their instability, exhibiting undesirable artifacts and degraded quality. In this work, we first identify the instability as a discrepancy between the solver's and true reverse diffusion dynamics, and show that reducing this gap stabilizes the solver. Building on this, we introduce Measurement-Consistent Langevin Corrector (MCLC), a theoretically grounded plug-and-play correction module that remedies the LDM-based inverse solvers through measurement-consistent Langevin updates. Compared to prior approaches that rely on linear manifold assumptions, which often do not hold in latent space, MCLC operates without this assumption, leading to more stable and reliable behavior. We experimentally demonstrate the effectiveness of MCLC and its compatibility with existing solvers across diverse image restoration tasks. Additionally, we analyze blob artifacts and offer insights into their underlying causes. We highlight that MCLC is a key step toward more robust zero-shot inverse problem solvers.","authors":["Lee Hyoseok","Sohwi Lim","Eunju Cha","Tae-Hyun Oh"],"pdf_url":"","comment":"Under Review"},{"id":"http://arxiv.org/abs/2601.04786v1","updated":"2026-01-08T10:10:20Z","published":"2026-01-08T10:10:20Z","title":"AgentOCR: Reimagining Agent History via Optical Self-Compression","summary":"Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\\% of text-based agent performance while substantially reducing token consumption (>50\\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.","authors":["Lang Feng","Fuchao Yang","Feng Chen","Xin Cheng","Haiyang Xu","Zhenglin Wan","Ming Yan","Bo An"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2409.16316v2","updated":"2026-01-08T10:01:33Z","published":"2024-09-16T08:15:54Z","title":"Surface solar radiation: AI satellite retrieval can outperform Heliosat and generalizes well to other climate zones","summary":"Accurate estimates of surface solar irradiance (SSI) are essential for solar resource assessments and solar energy forecasts in grid integration and building control applications. SSI estimates for spatially extended regions can be retrieved from geostationary satellites such as Meteosat. Traditional SSI satellite retrievals like Heliosat rely on physical radiative transfer modelling. We introduce the first machine-learning-based satellite retrieval for instantaneous SSI and demonstrate its capability to provide accurate and generalizable SSI estimates across Europe. Our deep learning retrieval provides near real-time SSI estimates based on data-driven emulation of Heliosat and fine-tuning on pyranometer networks. By including SSI from ground stations, our SSI retrieval model can outperform Heliosat accuracy and generalize well to regions with other climates and surface albedos in cloudy conditions (clear-sky index < 0.8). We also show that the SSI retrieved from Heliosat exhibits large biases in mountain regions, and that training and fine-tuning our retrieval models on SSI data from ground stations strongly reduces these biases, outperforming Heliosat. Furthermore, we quantify the relative importance of the Meteosat channels and other predictor variables like solar zenith angle for the accuracy of our deep learning SSI retrieval model in different cloud conditions. We find that in cloudy conditions multiple near-infrared and infrared channels enhance the performance. Our results can facilitate the development of more accurate satellite retrieval models of surface solar irradiance.","authors":["K. R. Schuurman","A. Meyer"],"pdf_url":"","comment":"19 pages, 11 figures Published in International Journal of Remote Sensing, Volume 46, 2025"},{"id":"http://arxiv.org/abs/2506.10520v4","updated":"2026-01-08T09:46:24Z","published":"2025-06-12T09:28:43Z","title":"Macro Graph of Experts for Billion-Scale Multi-Task Recommendation","summary":"Graph-based multi-task learning at billion-scale presents a significant challenge, as different tasks correspond to distinct billion-scale graphs. Traditional multi-task learning methods often neglect these graph structures, relying solely on individual user and item embeddings. However, disregarding graph structures overlooks substantial potential for improving performance. In this paper, we introduce the Macro Graph of Experts (MGOE) framework, the first approach capable of leveraging macro graph embeddings to capture task-specific macro features while modeling the correlations between task-specific experts. Specifically, we propose the concept of a Macro Graph Bottom, which, for the first time, enables multi-task learning models to incorporate graph information effectively. We design the Macro Prediction Tower to dynamically integrate macro knowledge across tasks. MGOE has been deployed at scale, powering multi-task learning for a leading billion-scale recommender system, Alibaba. Extensive offline experiments conducted on three public benchmark datasets demonstrate its superiority over state-of-the-art multi-task learning methods, establishing MGOE as a breakthrough in multi-task graph-based recommendation. Furthermore, online A/B tests confirm the superiority of MGOE in billion-scale recommender systems.","authors":["Hongyu Yao","Zijin Hong","Hao Chen","Zhiqing Li","Qijie Shen","Zuobin Ying","Qihua Feng","Huan Gong","Feiran Huang"],"pdf_url":"","comment":"Accepted to KDD2026"},{"id":"http://arxiv.org/abs/2601.04765v1","updated":"2026-01-08T09:33:29Z","published":"2026-01-08T09:33:29Z","title":"Differential syntactic and semantic encoding in LLMs","summary":"We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.","authors":["Santiago Acevedo","Alessandro Laio","Marco Baroni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04761v1","updated":"2026-01-08T09:29:11Z","published":"2026-01-08T09:29:11Z","title":"Smart IoT-Based Wearable Device for Detection and Monitoring of Common Cow Diseases Using a Novel Machine Learning Technique","summary":"Manual observation and monitoring of individual cows for disease detection present significant challenges in large-scale farming operations, as the process is labor-intensive, time-consuming, and prone to reduced accuracy. The reliance on human observation often leads to delays in identifying symptoms, as the sheer number of animals can hinder timely attention to each cow. Consequently, the accuracy and precision of disease detection are significantly compromised, potentially affecting animal health and overall farm productivity. Furthermore, organizing and managing human resources for the manual observation and monitoring of cow health is a complex and economically demanding task. It necessitates the involvement of skilled personnel, thereby contributing to elevated farm maintenance costs and operational inefficiencies. Therefore, the development of an automated, low-cost, and reliable smart system is essential to address these challenges effectively. Although several studies have been conducted in this domain, very few have simultaneously considered the detection of multiple common diseases with high prediction accuracy. However, advancements in Internet of Things (IoT), Machine Learning (ML), and Cyber-Physical Systems have enabled the automation of cow health monitoring with enhanced accuracy and reduced operational costs. This study proposes an IoT-enabled Cyber-Physical System framework designed to monitor the daily activities and health status of cow. A novel ML algorithm is proposed for the diagnosis of common cow diseases using collected physiological and behavioral data. The algorithm is designed to predict multiple diseases by analyzing a comprehensive set of recorded physiological and behavioral features, enabling accurate and efficient health assessment.","authors":["Rupsa Rani Mishra","D. Chandrasekhar Rao","Ajaya Kumar Tripathy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23367v2","updated":"2026-01-08T09:20:35Z","published":"2025-12-29T10:50:23Z","title":"Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2","summary":"Huawei's openPangu-Embedded-1B and openPangu-Embedded-7B are variants of the openPangu large language model, designed for efficient deployment on Ascend NPUs. The 7B variant supports three distinct Chain-of-Thought (CoT) reasoning paradigms, namely slow_think, auto_think, and no_think, while the 1B variant operates exclusively in the no_think mode, which employs condensed reasoning for higher efficiency. Although CoT reasoning enhances capability, the generation of extended reasoning traces introduces substantial memory and latency overheads, posing challenges for practical deployment on Ascend NPUs. This paper addresses these computational constraints by leveraging low-bit quantization, which transforms FP16 computations into more efficient integer arithmetic. We introduce a unified low-bit inference framework, supporting INT8 (W8A8) and W4A8 quantization, specifically optimized for openPangu-Embedded models on the Atlas A2. Our comprehensive evaluation on code generation benchmarks (HumanEval and MBPP) demonstrates the efficacy of this approach. INT8 quantization consistently preserves over 90\\% of the FP16 baseline accuracy and achieves a 1.5x prefill speedup on the Atlas A2. Furthermore, W4A8 quantization significantly reduces memory consumption, albeit with a moderate trade-off in accuracy. These findings collectively indicate that low-bit quantization effectively facilitates efficient CoT reasoning on Ascend NPUs, maintaining high model fidelity.","authors":["Yilun Luo","Huaqing Zheng","Haoqian Meng","Wenyuan Liu","Peng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04751v1","updated":"2026-01-08T09:15:14Z","published":"2026-01-08T09:15:14Z","title":"Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models","summary":"We present a novel framework for spatiotemporal photovoltaic (PV) power forecasting and use it to evaluate the reliability, sharpness, and overall performance of seven intraday PV power nowcasting models. The model suite includes satellite-based deep learning and optical-flow approaches and physics-based numerical weather prediction models, covering both deterministic and probabilistic formulations. Forecasts are first validated against satellite-derived surface solar irradiance (SSI). Irradiance fields are then converted into PV power using station-specific machine learning models, enabling comparison with production data from 6434 PV stations across Switzerland. To our knowledge, this is the first study to investigate spatiotemporal PV forecasting at a national scale. We additionally provide the first visualizations of how mesoscale cloud systems shape national PV production on hourly and sub-hourly timescales. Our results show that satellite-based approaches outperform the Integrated Forecast System (IFS-ENS), particularly at short lead times. Among them, SolarSTEPS and SHADECast deliver the most accurate SSI and PV power predictions, with SHADECast providing the most reliable ensemble spread. The deterministic model IrradianceNet achieves the lowest root mean square error, while probabilistic forecasts of SolarSTEPS and SHADECast provide better-calibrated uncertainty. Forecast skill generally decreases with elevation. At a national scale, satellite-based models forecast the daily total PV generation with relative errors below 10% for 82% of the days in 2019-2020, demonstrating robustness and their potential for operational use.","authors":["Luca Lanzilao","Angela Meyer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.06568v4","updated":"2026-01-08T09:13:10Z","published":"2024-11-10T19:11:48Z","title":"Meta-Learning Objectives for Preference Optimization","summary":"Evaluating preference optimization (PO) algorithms on LLM alignment is a challenging task that presents prohibitive costs, noise, and several variables like model size and hyper-parameters. In this work, we show that it is possible to gain insights on the efficacy of PO algorithm on simpler benchmarks. We design a diagnostic suite of MuJoCo tasks and datasets, which we use to systematically evaluate PO algorithms, establishing a more controlled and cheaper benchmark. We then propose a novel family of PO algorithms based on mirror descent, which we call Mirror Preference Optimization (MPO). Through evolutionary strategies, we search this class to discover algorithms specialized to specific properties of preference datasets, such as mixed-quality or noisy data. We demonstrate that our discovered PO algorithms outperform all known algorithms in the targeted MuJoCo settings. Finally, based on the insights gained from our MuJoCo experiments, we design a PO algorithm that significantly outperform existing baselines in an LLM alignment task.","authors":["Carlo Alfano","Silvia Sapora","Jakob Nicolaus Foerster","Patrick Rebeschini","Yee Whye Teh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04741v1","updated":"2026-01-08T09:05:57Z","published":"2026-01-08T09:05:57Z","title":"Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams","summary":"Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.","authors":["Kota Nakamura","Koki Kawabata","Yasuko Matsubara","Yasushi Sakurai"],"pdf_url":"","comment":"Accepted by KDD 2026"},{"id":"http://arxiv.org/abs/2601.03825v2","updated":"2026-01-08T09:04:27Z","published":"2026-01-07T11:40:02Z","title":"Beyond Physical Labels: Redefining Domains for Robust WiFi-based Gesture Recognition","summary":"In this paper, we propose GesFi, a novel WiFi-based gesture recognition system that introduces WiFi latent domain mining to redefine domains directly from the data itself. GesFi first processes raw sensing data collected from WiFi receivers using CSI-ratio denoising, Short-Time Fast Fourier Transform, and visualization techniques to generate standardized input representations. It then employs class-wise adversarial learning to suppress gesture semantic and leverages unsupervised clustering to automatically uncover latent domain factors responsible for distributional shifts. These latent domains are then aligned through adversarial learning to support robust cross-domain generalization. Finally, the system is applied to the target environment for robust gesture inference. We deployed GesFi under both single-pair and multi-pair settings using commodity WiFi transceivers, and evaluated it across multiple public datasets and real-world environments. Compared to state-of-the-art baselines, GesFi achieves up to 78% and 50% performance improvements over existing adversarial methods, and consistently outperforms prior generalization approaches across most cross-domain tasks.","authors":["Xiang Zhang","Huan Yan","Jinyang Huang","Bin Liu","Yuanhao Feng","Jianchun Liu","Meng Li","Fusang Zhang","Zhi Liu"],"pdf_url":"","comment":"Accepted by IMWUT/Ubicomp 2026"},{"id":"http://arxiv.org/abs/2506.14641v3","updated":"2026-01-08T09:01:32Z","published":"2025-06-17T15:39:33Z","title":"Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot","summary":"In-Context Learning (ICL) is an essential emergent ability of Large Language Models (LLMs), and recent studies introduce Chain-of-Thought (CoT) to exemplars of ICL to enhance the reasoning capability, especially in mathematics tasks. However, given the continuous advancement of model capabilities, it remains unclear whether CoT exemplars still benefit recent, stronger models in such tasks. Through systematic experiments, we find that for recent strong models such as the Qwen2.5 series, adding traditional CoT exemplars does not improve reasoning performance compared to Zero-Shot CoT. Instead, their primary function is to align the output format with human expectations. We further investigate the effectiveness of enhanced CoT exemplars, constructed using answers from advanced models such as \\texttt{Qwen2.5-Max} and \\texttt{DeepSeek-R1}. Experimental results indicate that these enhanced exemplars still fail to improve the model's reasoning performance. Further analysis reveals that models tend to ignore the exemplars and focus primarily on the instructions, leading to no observable gain in reasoning ability. Overall, our findings highlight the limitations of the current ICL+CoT framework in mathematical reasoning, calling for a re-examination of the ICL paradigm and the definition of exemplars.","authors":["Xiang Cheng","Chengyan Pan","Minjun Zhao","Deyang Li","Fangchao Liu","Xinyu Zhang","Xiao Zhang","Yong Liu"],"pdf_url":"","comment":"EMNLP25-findings camera_ready, 19 pages,22 figures"},{"id":"http://arxiv.org/abs/2509.23313v2","updated":"2026-01-08T08:59:34Z","published":"2025-09-27T14:00:27Z","title":"ASTGI: Adaptive Spatio-Temporal Graph Interactions for Irregular Multivariate Time Series Forecasting","summary":"Irregular multivariate time series (IMTS) are prevalent in critical domains like healthcare and finance, where accurate forecasting is vital for proactive decision-making. However, the asynchronous sampling and irregular intervals inherent to IMTS pose two core challenges for existing methods: (1) how to accurately represent the raw information of irregular time series without introducing data distortion, and (2) how to effectively capture the complex dynamic dependencies between observation points. To address these challenges, we propose the Adaptive Spatio-Temporal Graph Interaction (ASTGI) framework. Specifically, the framework first employs a Spatio-Temporal Point Representation module to encode each discrete observation as a point within a learnable spatio-temporal embedding space. Second, a Neighborhood-Adaptive Graph Construction module adaptively builds a causal graph for each point in the embedding space via nearest neighbor search. Subsequently, a Spatio-Temporal Dynamic Propagation module iteratively updates information on these adaptive causal graphs by generating messages and computing interaction weights based on the relative spatio-temporal positions between points. Finally, a Query Point-based Prediction module generates the final forecast by aggregating neighborhood information for a new query point and performing regression. Extensive experiments on multiple benchmark datasets demonstrate that ASTGI outperforms various state-of-the-art methods.","authors":["Xvyuan Liu","Xiangfei Qiu","Hanyin Cheng","Xingjian Wu","Chenjuan Guo","Bin Yang","Jilin Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04732v1","updated":"2026-01-08T08:54:44Z","published":"2026-01-08T08:54:44Z","title":"The Role of Quantum in Hybrid Quantum-Classical Neural Networks: A Realistic Assessment","summary":"Quantum machine learning has emerged as a promising application domain for near-term quantum hardware, particularly through hybrid quantum-classical models that leverage both classical and quantum processing. Although numerous hybrid architectures have been proposed and demonstrated successfully on benchmark tasks, a significant open question remains regarding the specific contribution of quantum components to the overall performance of these models. In this work, we aim to shed light on the impact of quantum processing within hybrid quantum-classical neural network architectures through a rigorous statistical study. We systematically assess common hybrid models on medical signal data as well as planar and volumetric images, examining the influence attributable to classical and quantum aspects such as encoding schemes, entanglement, and circuit size. We find that in best-case scenarios, hybrid models show performance comparable to their classical counterparts, however, in most cases, performance metrics deteriorate under the influence of quantum components. Our multi-modal analysis provides realistic insights into the contributions of quantum components and advocates for cautious claims and design choices for hybrid models in near-term applications.","authors":["Dominik Freinberger","Philipp Moser"],"pdf_url":"","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.10664v3","updated":"2026-01-08T08:53:05Z","published":"2024-08-20T09:05:44Z","title":"Federated Clustering: An Unsupervised Cluster-Wise Training for Decentralized Data Distributions","summary":"Federated Learning (FL) enables decentralized machine learning while preserving data privacy, making it ideal for sensitive applications where data cannot be shared. While FL has been widely studied in supervised contexts, its application to unsupervised learning remains underdeveloped. This work introduces FedCRef, a novel unsupervised federated learning method designed to uncover all underlying data distributions across decentralized clients without requiring labels. This task, known as Federated Clustering, presents challenges due to heterogeneous, non-uniform data distributions and the lack of centralized coordination. Unlike previous methods that assume a one-cluster-per-client setup or require prior knowledge of the number of clusters, FedCRef generalizes to multi-cluster-per-client scenarios. Clients iteratively refine their data partitions while discovering all distinct distributions in the system. The process combines local clustering, model exchange and evaluation via reconstruction error analysis, and collaborative refinement within federated groups of similar distributions to enhance clustering accuracy. Extensive evaluations on four public datasets (EMNIST, KMNIST, Fashion-MNIST and KMNIST49) show that FedCRef successfully identifies true global data distributions, achieving an average local accuracy of up to 95%. The method is also robust to noisy conditions, scalable, and lightweight, making it suitable for resource-constrained edge devices.","authors":["Mirko Nardi","Lorenzo Valerio","Andrea Passarella"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04728v1","updated":"2026-01-08T08:46:42Z","published":"2026-01-08T08:46:42Z","title":"Excess Description Length of Learning Generalizable Predictors","summary":"Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.","authors":["Elizabeth Donoway","Hailey Joren","Fabien Roger","Jan Leike"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.12225v3","updated":"2026-01-08T08:44:58Z","published":"2025-05-18T04:00:35Z","title":"Mining Intrinsic Rewards from LLM Hidden States for Efficient Best-of-N Sampling","summary":"Best-of-N sampling is a powerful method for improving Large Language Model (LLM) performance, but it is often limited by its dependence on massive, text-based reward models. These models are not only computationally expensive but also data-hungry, requiring extensive labeled datasets for training. This creates a significant data challenge, as they overlook a rich, readily available data source: the LLM's own internal hidden states. To address this data and efficiency gap, we introduce SWIFT (Simple Weighted Intrinsic Feedback Technique), a novel and lightweight method that learns a reward function directly from the rich information embedded in LLM hidden states. Operating at the token embedding level, SWIFT employs simple linear layers to effectively distinguish between preferred and dispreferred generations, eliminating the need for computationally intensive text-based modeling. Extensive experiments on standard benchmarks show that SWIFT outperforms existing baselines (12.7% higher accuracy than EurusRM-7B on MATH dataset) while using less than 0.005% of their parameters. Its robust scalability, compatibility with certain closed-source models via logit access, and ability to combine with traditional reward models for additional performance highlight SWIFT's practical value and contribution to more efficient data-driven LLM post-training. Our code is available at https://github.com/aster2024/SWIFT .","authors":["Jizhou Guo","Zhaomin Wu","Hanchen Yang","Philip S. Yu"],"pdf_url":"","comment":"Accepted by KDD 2026 (Research Track). Project page: https://aster2024.github.io/swift-website/"},{"id":"http://arxiv.org/abs/2510.21830v4","updated":"2026-01-08T08:42:56Z","published":"2025-10-22T03:37:49Z","title":"GAPO: Robust Advantage Estimation for Real-World Code LLMs","summary":"Reinforcement learning (RL) is widely used for post-training large language models (LLMs) in code editing, where group-relative methods, such as GRPO, are popular due to their critic-free and normalized advantage estimation. However, in real-world code-editing scenarios, reward distributions are often skewed with unpredictable noise, leading to distorted advantage computation and increased rollout outliers. To address this issue, we propose Group Adaptive Policy Optimization (GAPO), which adaptively finds an interval with the highest SNR (Signal to Noise Ratio) per prompt and uses the median of that interval as an adaptive Q to replace the group mean in advantage calculation to reduce noise further. This adaptive Q robustly handles rollout noise while remaining plug-and-play and efficient. We evaluate GAPO on nine instruction-tuned LLMs (3B-14B) using a collected large dataset of 51,844 real-world, history-aware code-editing tasks spanning 10 programming languages. GAPO yields up to 4.35 in-domain (ID) and 5.30 out-of-domain (OOD) exact-match improvements over GRPO and its variant DAPO, while achieving lower clipping ratios and higher GPU throughput. Code: https://github.com/TsingZ0/verl-GAPO.","authors":["Jianqing Zhang","Zhezheng Hao","Wei Xia","Hande Dong","Hong Wang","Chenxing Wei","Yuyan Zhou","Yubin Qi","Qiang Lin","Jian Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04719v1","updated":"2026-01-08T08:35:56Z","published":"2026-01-08T08:35:56Z","title":"GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models","summary":"The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior","authors":["Maanas Taneja","Purab Shingvi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04710v1","updated":"2026-01-08T08:27:15Z","published":"2026-01-08T08:27:15Z","title":"Prior-Informed Zeroth-Order Optimization with Adaptive Direction Alignment for Memory-Efficient LLM Fine-Tuning","summary":"Fine-tuning large language models (LLMs) has achieved remarkable success across various NLP tasks, but the substantial memory overhead during backpropagation remains a critical bottleneck, especially as model scales grow. Zeroth-order (ZO) optimization alleviates this issue by estimating gradients through forward passes and Gaussian sampling, avoiding the need for backpropagation. However, conventional ZO methods suffer from high variance in gradient estimation due to their reliance on random perturbations, leading to slow convergence and suboptimal performance. We propose a simple plug-and-play method that incorporates prior-informed perturbations to refine gradient estimation. Our method dynamically computes a guiding vector from Gaussian samples, which directs perturbations toward more informative directions, significantly accelerating convergence compared to standard ZO approaches. We further investigate a greedy perturbation strategy to explore the impact of prior knowledge on gradient estimation. Theoretically, we prove that our gradient estimator achieves stronger alignment with the true gradient direction, enhancing optimization efficiency. Extensive experiments across LLMs of varying scales and architectures demonstrate that our proposed method could seamlessly integrate into existing optimization methods, delivering faster convergence and superior performance. Notably, on the OPT-13B model, our method outperforms traditional ZO optimization across all 11 benchmark tasks and surpasses gradient-based baselines on 9 out of 11 tasks, establishing a robust balance between efficiency and accuracy.","authors":["Feihu Jin","Shipeng Cen","Ying Tan"],"pdf_url":"","comment":"12pages, 6figures"},{"id":"http://arxiv.org/abs/2402.12937v2","updated":"2026-01-08T08:24:18Z","published":"2024-02-20T11:38:52Z","title":"GRAPHGINI: Fostering Individual and Group Fairness in Graph Neural Networks","summary":"Graph Neural Networks (GNNs) have demonstrated impressive performance across various tasks, leading to their increased adoption in high-stakes decision-making systems. However, concerns have arisen about GNNs potentially generating unfair decisions for underprivileged groups or individuals when lacking fairness constraints. This work addresses this issue by introducing GraphGini, a novel approach that incorporates the Gini coefficient to enhance both individual and group fairness within the GNN framework. We rigorously establish that the Gini coefficient offers greater robustness and promotes equal opportunity among GNN outcomes, advantages not afforded by the prevailing Lipschitz constant methodology. Additionally, we employ the Nash social welfare program to ensure our solution yields a Pareto optimal distribution of group fairness. Extensive experimentation on real-world datasets demonstrates GraphGini's efficacy in significantly improving individual fairness compared to state-of-the-art methods while maintaining utility and group fairness.","authors":["Anuj Kumar Sirohi","Anjali Gupta","Sandeep Kumar","Amitabha Bagchi","Sayan Ranu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.03296v2","updated":"2026-01-08T08:23:50Z","published":"2025-08-05T10:16:04Z","title":"Towards Trustworthy Multimodal Moderation via Policy-Aligned Reasoning and Hierarchical Labeling","summary":"Social platforms have revolutionized information sharing, but also accelerated the dissemination of harmful and policy-violating content. To ensure safety and compliance at scale, moderation systems must go beyond efficiency and offer accuracy and interpretability. However, current approaches largely rely on noisy, label-driven learning, lacking alignment with moderation rules and producing opaque decisions that hinder human review. Therefore, we propose Hierarchical Guard (Hi-Guard), a multimodal moderation framework that introduces a new policy-aligned decision paradigm. The term \"Hierarchical\" reflects two key aspects of our system design: (1) a hierarchical moderation pipeline, where a lightweight binary model first filters safe content and a stronger model handles fine-grained risk classification; and (2) a hierarchical taxonomy in the second stage, where the model performs path-based classification over a hierarchical taxonomy ranging from coarse to fine-grained levels. To ensure alignment with evolving moderation policies, Hi-Guard directly incorporates rule definitions into the model prompt. To further enhance structured prediction and reasoning, we introduce a multi-level soft-margin reward and optimize with Group Relative Policy Optimization (GRPO), penalizing semantically adjacent misclassifications and improving explanation quality. Extensive experiments and real-world deployment demonstrate that Hi-Guard achieves superior classification accuracy, generalization, and interpretability, paving the way toward scalable, transparent, and trustworthy content safety systems. Code is available at: https://github.com/lianqi1008/Hi-Guard.","authors":["Anqi Li","Wenwei Jin","Jintao Tong","Pengda Qin","Weijia Li","Guo Lu"],"pdf_url":"","comment":"Accepted by KDD 2026. Code is available at https://github.com/lianqi1008/Hi-Guard"},{"id":"http://arxiv.org/abs/2512.20368v2","updated":"2026-01-08T08:22:15Z","published":"2025-12-23T13:53:53Z","title":"Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via Stability","summary":"Statistical inference in contextual bandits is challenging due to the adaptive, non-i.i.d. nature of the data. A growing body of work shows that classical least-squares inference can fail under adaptive sampling, and that valid confidence intervals for linear functionals typically require an inflation of order $\\sqrt{d \\log T}$. This phenomenon -- often termed the price of adaptivity -- reflects the intrinsic difficulty of reliable inference under general contextual bandit policies. A key structural condition that overcomes this limitation is the stability condition of Lai and Wei, which requires the empirical feature covariance to converge to a deterministic limit. When stability holds, the ordinary least-squares estimator satisfies a central limit theorem, and classical Wald-type confidence intervals remain asymptotically valid under adaptation, without incurring the $\\sqrt{d \\log T}$ price of adaptivity.\n  In this paper, we propose and analyze a regularized EXP4 algorithm for linear contextual bandits. Our first main result shows that this procedure satisfies the Lai--Wei stability condition and therefore admits valid Wald-type confidence intervals for linear functionals. We additionally provide quantitative rates of convergence in the associated central limit theorem. Our second result establishes that the same algorithm achieves regret guarantees that are minimax optimal up to logarithmic factors, demonstrating that stability and statistical efficiency can coexist within a single contextual bandit method. As an application of our theory, we show how it can be used to construct confidence intervals for the conditional average treatment effect (CATE) under adaptively collected data. Finally, we complement our theory with simulations illustrating the empirical normality of the resulting estimators and the sharpness of the corresponding confidence intervals.","authors":["Samya Praharaj","Koulik Khamaru"],"pdf_url":"","comment":"Revised version containing additional quantitative rate of convergence for the CLT"},{"id":"http://arxiv.org/abs/2601.04707v1","updated":"2026-01-08T08:19:47Z","published":"2026-01-08T08:19:47Z","title":"MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training","summary":"Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \\boldmath $\\bm{4.6\\,\\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.","authors":["Irfan Ullah","Young-Koo Lee"],"pdf_url":"","comment":"IEEE Access 2025"},{"id":"http://arxiv.org/abs/2601.04705v1","updated":"2026-01-08T08:18:32Z","published":"2026-01-08T08:18:32Z","title":"A zone-based training approach for last-mile routing using Graph Neural Networks and Pointer Networks","summary":"Rapid e-commerce growth has pushed last-mile delivery networks to their limits, where small routing gains translate into lower costs, faster service, and fewer emissions. Classical heuristics struggle to adapt when travel times are highly asymmetric (e.g., one-way streets, congestion). A deep learning-based approach to the last-mile routing problem is presented to generate geographical zones composed of stop sequences to minimize last-mile delivery times.\n  The presented approach is an encoder-decoder architecture. Each route is represented as a complete directed graph whose nodes are stops and whose edge weights are asymmetric travel times. A Graph Neural Network encoder produces node embeddings that captures the spatial relationships between stops. A Pointer Network decoder then takes the embeddings and the route's start node to sequentially select the next stops, assigning a probability to each unvisited node as the next destination.\n  Cells of a Discrete Global Grid System which contain route stops in the training data are obtained and clustered to generate geographical zones of similar size in which the process of training and inference are divided. Subsequently, a different instance of the model is trained per zone only considering the stops of the training routes which are included in that zone.\n  This approach is evaluated using the Los Angeles routes from the 2021 Amazon Last Mile Routing Challenge. Results from general and zone-based training are compared, showing a reduction in the average predicted route length in the zone-based training compared to the general training. The performance improvement of the zone-based approach becomes more pronounced as the number of stops per route increases.","authors":["Àngel Ruiz-Fas","Carlos Granell","José Francisco Ramos","Joaquín Huerta","Sergio Trilles"],"pdf_url":"","comment":"Accepted in SMF 2026. 8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2601.04698v1","updated":"2026-01-08T08:08:35Z","published":"2026-01-08T08:08:35Z","title":"TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning","summary":"Travel planning is a sophisticated decision-making process that requires synthesizing multifaceted information to construct itineraries. However, existing travel planning approaches face several challenges: (1) Pruning candidate points of interest (POIs) while maintaining a high recall rate; (2) A single reasoning path restricts the exploration capability within the feasible solution space for travel planning; (3) Simultaneously optimizing hard constraints and soft constraints remains a significant difficulty. To address these challenges, we propose TourPlanner, a comprehensive framework featuring multi-path reasoning and constraint-gated reinforcement learning. Specifically, we first introduce a Personalized Recall and Spatial Optimization (PReSO) workflow to construct spatially-aware candidate POIs' set. Subsequently, we propose Competitive consensus Chain-of-Thought (CCoT), a multi-path reasoning paradigm that improves the ability of exploring the feasible solution space. To further refine the plan, we integrate a sigmoid-based gating mechanism into the reinforcement learning stage, which dynamically prioritizes soft-constraint satisfaction only after hard constraints are met. Experimental results on travel planning benchmarks demonstrate that TourPlanner achieves state-of-the-art performance, significantly surpassing existing methods in both feasibility and user-preference alignment.","authors":["Yinuo Wang","Mining Tan","Wenxiang Jiao","Xiaoxi Li","Hao Wang","Xuanyu Zhang","Yuan Lu","Weiming Dong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04695v1","updated":"2026-01-08T08:05:42Z","published":"2026-01-08T08:05:42Z","title":"Tape: A Cellular Automata Benchmark for Evaluating Rule-Shift Generalization in Reinforcement Learning","summary":"We present Tape, a controlled reinforcement-learning benchmark designed to isolate out-of-distribution (OOD) failure under latent rule shifts.Tape is derived from one-dimensional cellular automata, enabling precise train/test splits where observation and action spaces are held fixed while transition rules change. Using a reproducible evaluation pipeline, we compare model-free baselines, model-based planning with learned world models, and task-inference (meta-RL) methods. A consistent pattern emerges: methods that are strong in-distribution (ID) can collapse under heldout-rule OOD, and high-variance OOD evaluation can make rankings unstable unless experiments are sufficiently replicated.We provide (i) standardized OOD protocols, (ii) statistical reporting requirements (seeds, confidence intervals, and hypothesis tests), and (iii) information-theoretic identities connecting entropy reduction to conditional mutual information and expected posterior KL divergence, clarifying what \"uncertainty reduction\" objectives can and cannot guarantee under rule shifts.","authors":["Enze Pan"],"pdf_url":"","comment":"4 tables"},{"id":"http://arxiv.org/abs/2601.04690v1","updated":"2026-01-08T07:58:28Z","published":"2026-01-08T07:58:28Z","title":"Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?","summary":"Large Language Models (LLMs) have emerged as promising recommendation systems, offering novel ways to model user preferences through generative approaches. However, many existing methods often rely solely on text semantics or incorporate collaborative signals in a limited manner, typically using only user or item embeddings. These methods struggle to handle multiple item embeddings representing user history, reverting to textual semantics and neglecting richer collaborative information. In this work, we propose a simple yet effective solution that projects user and item embeddings, learned from collaborative filtering, into the LLM token space via separate lightweight projector modules. A finetuned LLM then conditions on these projected embeddings alongside textual tokens to generate recommendations. Preliminary results show that this design effectively leverages structured user-item interaction data, improves recommendation performance over text-only LLM baselines, and offers a practical path for bridging traditional recommendation systems with modern LLMs.","authors":["Mir Rayat Imtiaz Hossain","Leo Feng","Leonid Sigal","Mohamed Osama Ahmed"],"pdf_url":"","comment":"Presented in Multimodal Algorithmic Reasoning Workshop at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2601.04686v1","updated":"2026-01-08T07:55:07Z","published":"2026-01-08T07:55:07Z","title":"Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead","summary":"Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.","authors":["Oluwatosin Oseni","Shengjie Wang","Jun Zhu","Micah Corah"],"pdf_url":"","comment":"RSS'25: Multi-Objective Optimization and Planning in Robotics Workshop: 5 pages, 8 figures"},{"id":"http://arxiv.org/abs/2506.22809v3","updated":"2026-01-08T07:40:27Z","published":"2025-06-28T08:22:02Z","title":"Low-rank variational dropout: Rank selection and uncertainty in adapters","summary":"Low-rank adaptation methods enable efficient task-specific updates in large neural networks, but provide no principled mechanism for uncertainty estimation or capacity control. We introduce Low-Rank Variational Dropout (LRVD), a Bayesian framework that operates directly in the space of low-rank adaptation. LRVD employs a scale-invariant, sparsity-inducing prior together with a structured variational family that ties uncertainty at the level of latent rank components, inducing rank-wise noise-to-signal ratios for automatic capacity selection. As a concrete instantiation, we apply LRVD to low-rank adaptation and obtain BayesLoRA, which jointly learns predictive uncertainty and the effective adapter rank with only O(r) additional parameters, where r is the adapter rank. We empirically show that BayesLoRA induces stable, non-arbitrary rank structure aligned with the intrinsic singular directions of the learned updates, and outperforms existing low-rank sparsification methods in accuracy at comparable training cost while delivering substantially improved predictive calibration at negligible additional overhead.","authors":["Cooper Doyle","Rebecca Chan","Andy Hu","Anna Leontjeva"],"pdf_url":"","comment":"8 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2601.04673v1","updated":"2026-01-08T07:37:10Z","published":"2026-01-08T07:37:10Z","title":"Estimating Causal Effects in Gaussian Linear SCMs with Finite Data","summary":"Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.","authors":["Aurghya Maiti","Prateek Jain"],"pdf_url":"","comment":"Accepted at the Workshop on Scaling Up Intervention Models at the 42nd International Conference on Machine Learning (ICML 2025)"},{"id":"http://arxiv.org/abs/2601.04670v1","updated":"2026-01-08T07:32:15Z","published":"2026-01-08T07:32:15Z","title":"Learning Dynamics in RL Post-Training for Language Models","summary":"Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.","authors":["Akiyoshi Tomihari"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.10062v2","updated":"2026-01-08T07:16:45Z","published":"2025-11-13T08:04:17Z","title":"FAQNAS: FLOPs-aware Hybrid Quantum Neural Architecture Search using Genetic Algorithm","summary":"Hybrid Quantum Neural Networks (HQNNs), which combine parameterized quantum circuits with classical neural layers, are emerging as promising models in the noisy intermediate-scale quantum (NISQ) era. While quantum circuits are not naturally measured in floating point operations (FLOPs), most HQNNs (in NISQ era) are still trained on classical simulators where FLOPs directly dictate runtime and scalability. Hence, FLOPs represent a practical and viable metric to measure the computational complexity of HQNNs. In this work, we introduce FAQNAS, a FLOPs-aware neural architecture search (NAS) framework that formulates HQNN design as a multi-objective optimization problem balancing accuracy and FLOPs. Unlike traditional approaches, FAQNAS explicitly incorporates FLOPs into the optimization objective, enabling the discovery of architectures that achieve strong performance while minimizing computational cost. Experiments on five benchmark datasets (MNIST, Digits, Wine, Breast Cancer, and Iris) show that quantum FLOPs dominate accuracy improvements, while classical FLOPs remain largely fixed. Pareto-optimal solutions reveal that competitive accuracy can often be achieved with significantly reduced computational cost compared to FLOPs-agnostic baselines. Our results establish FLOPs-awareness as a practical criterion for HQNN design in the NISQ era and as a scalable principle for future HQNN systems.","authors":["Muhammad Kashif","Shaf Khalid","Alberto Marchisio","Nouhaila Innan","Muhammad Shafique"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.02515v3","updated":"2026-01-08T07:03:42Z","published":"2025-06-03T06:44:42Z","title":"FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning","summary":"Multi-step symbolic reasoning is essential for robust financial analysis; yet, current benchmarks largely overlook this capability. Existing datasets such as FinQA and ConvFinQA emphasize final numerical answers while neglecting the intermediate reasoning required for transparency and verification. To address this gap, we introduce FINCHAIN, the first benchmark specifically designed for verifiable Chain-of-Thought (CoT) evaluation in finance. FINCHAIN spans 58 topics across 12 financial domains, each represented by parameterized symbolic templates with executable Python traces that enable fully machine-verifiable reasoning and scalable, contamination-free data generation. To assess reasoning capacity, we propose CHAINEVAL, a dynamic alignment measure that jointly evaluates both the final-answer correctness and the step-level reasoning consistency. Our evaluation of 26 leading LLMs reveals that even frontier proprietary LLMs exhibit clear limitations in symbolic financial reasoning, while domain-adapted and math-enhanced fine-tuned models can substantially narrow this gap. Overall, FINCHAIN exposes persistent weaknesses in multi-step financial reasoning and provides a foundation for developing trustworthy, interpretable, and verifiable financial AI.","authors":["Zhuohan Xie","Daniil Orel","Rushil Thareja","Dhruv Sahnan","Hachem Madmoun","Fan Zhang","Debopriyo Banerjee","Georgi Georgiev","Xueqing Peng","Lingfei Qian","Jimin Huang","Jinyan Su","Aaryamonvikram Singh","Rui Xing","Rania Elbadry","Chen Xu","Haonan Li","Fajri Koto","Ivan Koychev","Tanmoy Chakraborty","Yuxia Wang","Salem Lahlou","Veselin Stoyanov","Sophia Ananiadou","Preslav Nakov"],"pdf_url":"","comment":"24 pages, includes 12 figures and 9 tables; introduces the FinChain benchmark and ChainEval metric"},{"id":"http://arxiv.org/abs/2504.03957v2","updated":"2026-01-08T07:03:20Z","published":"2025-04-04T21:49:42Z","title":"Practical Poisoning Attacks against Retrieval-Augmented Generation","summary":"Large language models (LLMs) have demonstrated impressive natural language processing abilities but face challenges such as hallucination and outdated knowledge. Retrieval-Augmented Generation (RAG) has emerged as a state-of-the-art approach to mitigate these issues. While RAG enhances LLM outputs, it remains vulnerable to poisoning attacks. Recent studies show that injecting poisoned text into the knowledge database can compromise RAG systems, but most existing attacks assume that the attacker can insert a sufficient number of poisoned texts per query to outnumber correct-answer texts in retrieval, an assumption that is often unrealistic. To address this limitation, we propose CorruptRAG, a practical poisoning attack against RAG systems in which the attacker injects only a single poisoned text, enhancing both feasibility and stealth. Extensive experiments conducted on multiple large-scale datasets demonstrate that CorruptRAG achieves higher attack success rates than existing baselines.","authors":["Baolei Zhang","Yuxi Chen","Zhuqing Liu","Lihai Nie","Tong Li","Zheli Liu","Minghong Fang"],"pdf_url":"","comment":"To appear in ACM SACMAT 2026"},{"id":"http://arxiv.org/abs/2512.10427v5","updated":"2026-01-08T07:00:01Z","published":"2025-12-11T08:38:46Z","title":"Renormalizable Spectral-Shell Dynamics as the Origin of Neural Scaling Laws","summary":"Neural scaling laws and double-descent phenomena suggest that deep-network training obeys a simple macroscopic structure despite highly nonlinear optimization dynamics. We derive such structure directly from gradient descent in function space. For mean-squared error loss, the training error evolves as $\\dot e_t=-M(t)e_t$ with $M(t)=J_{θ(t)}J_{θ(t)}^{\\!*}$, a time-dependent self-adjoint operator induced by the network Jacobian. Using Kato perturbation theory, we obtain an exact system of coupled modewise ODEs in the instantaneous eigenbasis of $M(t)$.\n  To extract macroscopic behavior, we introduce a logarithmic spectral-shell coarse-graining and track quadratic error energy across shells. Microscopic interactions within each shell cancel identically at the energy level, so shell energies evolve only through dissipation and external inter-shell interactions. We formalize this via a \\emph{renormalizable shell-dynamics} assumption, under which cumulative microscopic effects reduce to a controlled net flux across shell boundaries.\n  Assuming an effective power-law spectral transport in a relevant resolution range, the shell dynamics admits a self-similar solution with a moving resolution frontier and explicit scaling exponents. This framework explains neural scaling laws and double descent, and unifies lazy (NTK-like) training and feature learning as two limits of the same spectral-shell dynamics.","authors":["Yizhou Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.23013v2","updated":"2026-01-08T06:48:22Z","published":"2025-10-27T05:16:10Z","title":"MoEMeta: Mixture-of-Experts Meta Learning for Few-Shot Relational Learning","summary":"Few-shot knowledge graph relational learning seeks to perform reasoning over relations given only a limited number of training examples. While existing approaches largely adopt a meta-learning framework for enabling fast adaptation to new relations, they suffer from two key pitfalls. First, they learn relation meta-knowledge in isolation, failing to capture common relational patterns shared across tasks. Second, they struggle to effectively incorporate local, task-specific contexts crucial for rapid adaptation. To address these limitations, we propose MoEMeta, a novel meta-learning framework that disentangles globally shared knowledge from task-specific contexts to enable both effective model generalization and rapid adaptation. MoEMeta introduces two key innovations: (i) a mixture-of-experts (MoE) model that learns globally shared relational prototypes to enhance generalization, and (ii) a task-tailored adaptation mechanism that captures local contexts for fast task-specific adaptation. By balancing global generalization with local adaptability, MoEMeta significantly advances few-shot relational learning. Extensive experiments and analyses on three KG benchmarks show that MoEMeta consistently outperforms existing baselines, achieving state-of-the-art performance.","authors":["Han Wu","Jie Yin"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2601.04648v1","updated":"2026-01-08T06:45:22Z","published":"2026-01-08T06:45:22Z","title":"Mechanism Design for Federated Learning with Non-Monotonic Network Effects","summary":"Mechanism design is pivotal to federated learning (FL) for maximizing social welfare by coordinating self-interested clients. Existing mechanisms, however, often overlook the network effects of client participation and the diverse model performance requirements (i.e., generalization error) across applications, leading to suboptimal incentives and social welfare, or even inapplicability in real deployments. To address this gap, we explore incentive mechanism design for FL with network effects and application-specific requirements of model performance. We develop a theoretical model to quantify the impact of network effects on heterogeneous client participation, revealing the non-monotonic nature of such effects. Based on these insights, we propose a Model Trading and Sharing (MoTS) framework, which enables clients to obtain FL models through either participation or purchase. To further address clients' strategic behaviors, we design a Social Welfare maximization with Application-aware and Network effects (SWAN) mechanism, exploiting model customer payments for incentivization. Experimental results on a hardware prototype demonstrate that our SWAN mechanism outperforms existing FL mechanisms, improving social welfare by up to $352.42\\%$ and reducing extra incentive costs by $93.07\\%$.","authors":["Xiang Li","Bing Luo","Jianwei Huang","Yuan Luo"],"pdf_url":"","comment":"Journal extension of Mobihoc conference version, under review of IEEE TMC"},{"id":"http://arxiv.org/abs/2601.04646v1","updated":"2026-01-08T06:44:40Z","published":"2026-01-08T06:44:40Z","title":"Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search","summary":"Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This \"dark data\" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \\textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \\textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \\textbf{consistency filtering} and relevance assignment. We further propose a practical \\textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.","authors":["Prateek Jain","Shabari S Nair","Ritesh Goru","Prakhar Agarwal","Ajay Yadav","Yoga Sri Varshan Varadharajan","Constantine Caramanis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.00416v2","updated":"2026-01-08T06:43:19Z","published":"2025-05-31T06:41:04Z","title":"Blockchain-Enabled Privacy-Preserving Second-Order Federated Edge Learning in Personalized Healthcare","summary":"Federated learning (FL) is increasingly recognised for addressing security and privacy concerns in traditional cloud-centric machine learning (ML), particularly within personalised health monitoring such as wearable devices. By enabling global model training through localised policies, FL allows resource-constrained wearables to operate independently. However, conventional first-order FL approaches face several challenges in personalised model training due to the heterogeneous non-independent and identically distributed (non-iid) data by each individual's unique physiology and usage patterns. Recently, second-order FL approaches maintain the stability and consistency of non-iid datasets while improving personalised model training. This study proposes and develops a verifiable and auditable optimised second-order FL framework BFEL (blockchain enhanced federated edge learning) based on optimised FedCurv for personalised healthcare systems. FedCurv incorporates information about the importance of each parameter to each client's task (through fisher information matrix) which helps to preserve client-specific knowledge and reduce model drift during aggregation. Moreover, it minimizes communication rounds required to achieve a target precision convergence for each client device while effectively managing personalised training on non-iid and heterogeneous data. The incorporation of ethereum-based model aggregation ensures trust, verifiability, and auditability while public key encryption enhances privacy and security. Experimental results of federated CNNs and MLPs utilizing mnist, cifar-10, and PathMnist demonstrate framework's high efficiency, scalability, suitability for edge deployment on wearables, and significant reduction in communication cost.","authors":["Anum Nawaz","Muhammad Irfan","Xianjia Yu","Hamad Aldawsari","Rayan Hamza Alsisi","Zhuo Zou","Tomi Westerlund"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17381v2","updated":"2026-01-08T06:36:49Z","published":"2025-12-19T09:36:44Z","title":"Timely Information Updating for Mobile Devices Without and With ML Advice","summary":"This paper investigates an information update system in which a mobile device monitors a physical process and sends status updates to an access point (AP). A fundamental trade-off arises between the timeliness of the information maintained at the AP and the update cost incurred at the device. To address this trade-off, we propose an online algorithm that determines when to transmit updates using only available observations. The proposed algorithm asymptotically achieves the optimal competitive ratio against an adversary that can simultaneously manipulate multiple sources of uncertainty, including the operation duration, information staleness, update cost, and update opportunities. Furthermore, by incorporating machine learning (ML) advice of unknown reliability into the design, we develop an ML-augmented algorithm that asymptotically attains the optimal consistency-robustness trade-off, even when the adversary can additionally corrupt the ML advice. The optimal competitive ratio scales linearly with the range of update costs, but is unaffected by other sources of uncertainty. Moreover, an optimal competitive online algorithm exhibits a threshold-like response to the ML advice: it either fully trusts or completely ignores the ML advice, as partially trusting the advice cannot improve the consistency without severely degrading the robustness. Extensive simulations in stochastic settings further validate the theoretical findings in the adversarial environment.","authors":["Yu-Pin Hsu","Yi-Hsuan Tseng"],"pdf_url":"","comment":"23 pages, journal version of arXiv:1901.03137, submitted for possible journal publication"},{"id":"http://arxiv.org/abs/2601.04641v1","updated":"2026-01-08T06:33:15Z","published":"2026-01-08T06:33:15Z","title":"DP-MGTD: Privacy-Preserving Machine-Generated Text Detection via Adaptive Differentially Private Entity Sanitization","summary":"The deployment of Machine-Generated Text (MGT) detection systems necessitates processing sensitive user data, creating a fundamental conflict between authorship verification and privacy preservation. Standard anonymization techniques often disrupt linguistic fluency, while rigorous Differential Privacy (DP) mechanisms typically degrade the statistical signals required for accurate detection. To resolve this dilemma, we propose \\textbf{DP-MGTD}, a framework incorporating an Adaptive Differentially Private Entity Sanitization algorithm. Our approach utilizes a two-stage mechanism that performs noisy frequency estimation and dynamically calibrates privacy budgets, applying Laplace and Exponential mechanisms to numerical and textual entities respectively. Crucially, we identify a counter-intuitive phenomenon where the application of DP noise amplifies the distinguishability between human and machine text by exposing distinct sensitivity patterns to perturbation. Extensive experiments on the MGTBench-2.0 dataset show that our method achieves near-perfect detection accuracy, significantly outperforming non-private baselines while satisfying strict privacy guarantees.","authors":["Lionel Z. Wang","Yusheng Zhao","Jiabin Luo","Xinfeng Li","Lixu Wang","Yinan Peng","Haoyang Li","XiaoFeng Wang","Wei Dong"],"pdf_url":"","comment":"12 pages, 1 figure, 1 tables"},{"id":"http://arxiv.org/abs/2601.03667v2","updated":"2026-01-08T06:30:42Z","published":"2026-01-07T07:41:57Z","title":"TRec: Egocentric Action Recognition using 2D Point Tracks","summary":"We present a novel approach for egocentric action recognition that leverages 2D point tracks as an additional motion cue. While most existing methods rely on RGB appearance, human pose estimation, or their combination, our work demonstrates that tracking randomly sampled image points across video frames can substantially improve recognition accuracy. Unlike prior approaches, we do not detect hands, objects, or interaction regions. Instead, we employ CoTracker to follow a set of randomly initialized points through each video and use the resulting trajectories, together with the corresponding image frames, as input to a Transformer-based recognition model. Surprisingly, our method achieves notable gains even when only the initial frame and its associated point tracks are provided, without incorporating the full video sequence. Experimental results confirm that integrating 2D point tracks consistently enhances performance compared to the same model trained without motion information, highlighting their potential as a lightweight yet effective representation for egocentric action understanding.","authors":["Dennis Holzmann","Sven Wachsmuth"],"pdf_url":"","comment":"submitted to ICPR 2026"},{"id":"http://arxiv.org/abs/2507.00301v2","updated":"2026-01-08T05:55:02Z","published":"2025-06-30T22:35:25Z","title":"Structure-preserving Lift & Learn: Scientific machine learning for nonlinear conservative partial differential equations","summary":"This work presents structure-preserving Lift & Learn, a scientific machine learning method that employs lifting variable transformations to learn structure-preserving reduced-order models for nonlinear partial differential equations (PDEs) with conservation laws. We propose a hybrid learning approach based on a recently developed energy-quadratization strategy that uses knowledge of the nonlinearity at the PDE level to derive an equivalent quadratic lifted system with quadratic system energy. The lifted dynamics obtained via energy quadratization are linear in the old variables, making model learning very effective in the lifted setting. Based on the lifted quadratic PDE model form, the proposed method derives quadratic reduced terms analytically and then uses those derived terms to formulate a constrained optimization problem to learn the remaining linear reduced operators in a structure-preserving way. The proposed hybrid learning approach yields computationally efficient quadratic reduced-order models that respect the underlying physics of the high-dimensional problem. We demonstrate the generalizability of quadratic models learned via the proposed structure-preserving Lift & Learn method through three numerical examples: the one-dimensional wave equation with exponential nonlinearity, the two-dimensional sine-Gordon equation, and the two-dimensional Klein-Gordon-Zakharov equations. The numerical results show that the proposed learning approach is competitive with the state-of-the-art structure-preserving data-driven model reduction method in terms of both accuracy and computational efficiency.","authors":["Harsh Sharma","Juan Diego Draxl Giannoni","Boris Kramer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04616v1","updated":"2026-01-08T05:46:14Z","published":"2026-01-08T05:46:14Z","title":"DeepHalo: A Neural Choice Model with Controllable Context Effects","summary":"Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.","authors":["Shuhan Zhang","Zhi Wang","Rui Gao","Shuang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.13408v3","updated":"2026-01-08T05:38:18Z","published":"2025-11-17T14:21:43Z","title":"Taming Barren Plateaus in Arbitrary Parameterized Quantum Circuits without Sacrificing Expressibility","summary":"Quantum algorithms based on parameterized quantum circuits (PQCs) have enabled a wide range of applications on near-term quantum devices. However, existing PQC architectures face several challenges, among which the ``barren plateaus\" phenomenon is particularly prominent. In such cases, the loss function concentrates exponentially with increasing system size, thereby hindering effective parameter optimization. To address this challenge, we propose a general and hardware-efficient method for eliminating barren plateaus in an arbitrary PQC. Specifically, our approach achieves this by inserting a layer of easily implementable quantum channels into the original PQC, each channel requiring only one ancilla qubit and four additional gates, yielding a modified PQC (MPQC) that is provably at least as expressive as the original PQC and, under mild assumptions, is guaranteed to be free from barren plateaus. Furthermore, by appropriately adjusting the structure of MPQCs, we rigorously prove that any parameter in the original PQC can be made trainable. Importantly, the absence of barren plateaus in MPQCs is robust against realistic noise, making our approach directly applicable to near-term quantum hardware. Numerical simulations demonstrate that MPQC effectively eliminates barren plateaus in PQCs for preparing thermal states of systems with up to 100 qubits and 2400 layers. Furthermore, in end-to-end simulations, MPQC significantly outperforms PQC in finding the ground-state energy of a complex Hamiltonian.","authors":["Zhenyu Chen","Yuguo Shao","Zhengwei Liu","Zhaohui Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.22662v2","updated":"2026-01-08T05:34:50Z","published":"2025-05-28T17:59:53Z","title":"AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models","summary":"Reasoning-capable large language models (LLMs) achieve strong performance on complex tasks but often exhibit overthinking after distillation, generating unnecessarily long chain-of-thought (CoT) reasoning even for simple inputs and incurring high inference cost. However, naively shortening reasoning length can degrade reasoning accuracy, as concise reasoning may be insufficient for certain inputs and lacks explicit supervision. We propose Auto Long-Short Reasoning (AutoL2S), a distillation framework that empowers non-reasoning LLMs to think thoroughly but only when necessary. AutoL2S first learns a lightweight switching token with verified long-short CoTs to enable instance-wise long-short reasoning selection. Then it leverages long-short reasoning rollouts induced by a switching token in a GRPO-style loss to improve reasoning efficiency while maintaining accuracy. Experiments demonstrate that AutoL2S effectively reduces reasoning length up to 71% with minimal accuracy loss, yielding markedly better trade-off in token length and inference time while preserving accuracy.","authors":["Feng Luo","Yu-Neng Chuang","Guanchu Wang","Hoang Anh Duy Le","Shaochen Zhong","Hongyi Liu","Jiayi Yuan","Yang Sui","Vladimir Braverman","Vipin Chaudhary","Xia Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.03740v2","updated":"2026-01-08T05:33:36Z","published":"2024-11-06T08:13:09Z","title":"Human-in-the-Loop Feature Selection Using Interpretable Kolmogorov-Arnold Network-based Double Deep Q-Network","summary":"Feature selection is critical for improving the performance and interpretability of machine learning models, particularly in high-dimensional spaces where complex feature interactions can reduce accuracy and increase computational demands. Existing approaches often rely on static feature subsets or manual intervention, limiting adaptability and scalability. However, dynamic, per-instance feature selection methods and model-specific interpretability in reinforcement learning remain underexplored. This study proposes a human-in-the-loop (HITL) feature selection framework integrated into a Double Deep Q-Network (DDQN) using a Kolmogorov-Arnold Network (KAN). Our novel approach leverages simulated human feedback and stochastic distribution-based sampling, specifically Beta, to iteratively refine feature subsets per data instance, improving flexibility in feature selection. The KAN-DDQN achieved notable test accuracies of 93% on MNIST and 83% on FashionMNIST, outperforming conventional MLP-DDQN models by up to 9%. The KAN-based model provided high interpretability via symbolic representation while using 4 times fewer neurons in the hidden layer than MLPs did. Comparatively, the models without feature selection achieved test accuracies of only 58% on MNIST and 64% on FashionMNIST, highlighting significant gains with our framework. We further validate scalability on CIFAR-10 and CIFAR-100, achieving up to 30% relative macro F1 improvement on MNIST and 5% on CIFAR-10, while reducing calibration error by 25%. Complexity analysis confirms real-time feasibility with latency below 1 ms and parameter counts under 0.02M. Pruning and visualization further enhanced model transparency by elucidating decision pathways. These findings present a scalable, interpretable solution for feature selection that is suitable for applications requiring real-time, adaptive decision-making with minimal human oversight.","authors":["Md Abrar Jahin","M. F. Mridha","Nilanjan Dey","Md. Jakir Hossen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03646v2","updated":"2026-01-08T05:28:59Z","published":"2026-01-07T06:50:56Z","title":"ReLA: Representation Learning and Aggregation for Job Scheduling with Reinforcement Learning","summary":"Job scheduling is widely used in real-world manufacturing systems to assign ordered job operations to machines under various constraints. Existing solutions remain limited by long running time or insufficient schedule quality, especially when problem scale increases. In this paper, we propose ReLA, a reinforcement-learning (RL) scheduler built on structured representation learning and aggregation. ReLA first learns diverse representations from scheduling entities, including job operations and machines, using two intra-entity learning modules with self-attention and convolution and one inter-entity learning module with cross-attention. These modules are applied in a multi-scale architecture, and their outputs are aggregated to support RL decision-making. Across experiments on small, medium, and large job instances, ReLA achieves the best makespan in most tested settings over the latest solutions. On non-large instances, ReLA reduces the optimality gap of the SOTA baseline by 13.0%, while on large-scale instances it reduces the gap by 78.6%, with the average optimality gaps lowered to 7.3% and 2.1%, respectively. These results confirm that ReLA's learned representations and aggregation provide strong decision support for RL scheduling, and enable fast job completion and decision-making for real-world applications.","authors":["Zhengyi Kwan","Wei Zhang","Aik Beng Ng","Zhengkui Wang","Simon See"],"pdf_url":"","comment":"15 pages"},{"id":"http://arxiv.org/abs/2601.04606v1","updated":"2026-01-08T05:24:59Z","published":"2026-01-08T05:24:59Z","title":"Crystal Generation using the Fully Differentiable Pipeline and Latent Space Optimization","summary":"We present a materials generation framework that couples a symmetry-conditioned variational autoencoder (CVAE) with a differentiable SO(3) power spectrum objective to steer candidates toward a specified local environment under the crystallographic constraints. In particular, we implement a fully differentiable pipeline that performs batch-wise optimization on both direct and latent crystallographic representations. Using the GPU acceleration, the implementation achieves about fivefold speed compared to our previous CPU workflow, while yielding comparable outcomes. In addition, we introduce the optimization strategy that alternatively performs optimization on the direct and latent crystal representations. This dual-level relaxation approach can effectively overcome local barrier defined by different objective gradients, thus increasing the success rate of generating complex structures satisfying the targe local environments. This framework can be extended to systems consisting of multi-components and multi-environments, providing a scalable route to generate material structures with the target local environment.","authors":["Osman Goni Ridwan","Gilles Frapper","Hongfei Xue","Qiang Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04600v1","updated":"2026-01-08T05:05:09Z","published":"2026-01-08T05:05:09Z","title":"On the Limitations of Rank-One Model Editing in Answering Multi-hop Questions","summary":"Recent advances in Knowledge Editing (KE), particularly Rank-One Model Editing (ROME), show superior efficiency over fine-tuning and in-context learning for updating single-hop facts in transformers. However, these methods face significant challenges when applied to multi-hop reasoning tasks requiring knowledge chaining. In this work, we study the effect of editing knowledge with ROME on different layer depths and identify three key failure modes. First, the \"hopping-too-late\" problem occurs as later layers lack access to necessary intermediate representations. Second, generalization ability deteriorates sharply when editing later layers. Third, the model overfits to edited knowledge, incorrectly prioritizing edited-hop answers regardless of context. To mitigate the issues of \"hopping-too-late\" and generalisation decay, we propose Redundant Editing, a simple yet effective strategy that enhances multi-hop reasoning. Our experiments demonstrate that this approach can improve accuracy on 2-hop questions by at least 15.5 percentage points, representing a 96% increase over the previous single-edit strategy, while trading off some specificity and language naturalness.","authors":["Zhiyuan He","Binghan Chen","Tianxiang Xiong","Ziyang Sun","Mozhao Zhu","Xi Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01331v2","updated":"2026-01-08T04:49:41Z","published":"2026-01-04T02:15:17Z","title":"AppellateGen: A Benchmark for Appellate Legal Judgment Generation","summary":"Legal judgment generation is a critical task in legal intelligence. However, existing research in legal judgment generation has predominantly focused on first-instance trials, relying on static fact-to-verdict mappings while neglecting the dialectical nature of appellate (second-instance) review. To address this, we introduce AppellateGen, a benchmark for second-instance legal judgment generation comprising 7,351 case pairs. The task requires models to draft legally binding judgments by reasoning over the initial verdict and evidentiary updates, thereby modeling the causal dependency between trial stages. We further propose a judicial Standard Operating Procedure (SOP)-based Legal Multi-Agent System (SLMAS) to simulate judicial workflows, which decomposes the generation process into discrete stages of issue identification, retrieval, and drafting. Experimental results indicate that while SLMAS improves logical consistency, the complexity of appellate reasoning remains a substantial challenge for current LLMs. The dataset and code are publicly available at: https://anonymous.4open.science/r/AppellateGen-5763.","authors":["Hongkun Yang","Lionel Z. Wang","Wei Fan","Yiran Hu","Lixu Wang","Chenyu Liu","Shenghong Fu","Haoyang Li","Xin Xu","Jiexin Zheng","Wei Dong"],"pdf_url":"","comment":"15 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2601.04592v1","updated":"2026-01-08T04:44:04Z","published":"2026-01-08T04:44:04Z","title":"Density Matrix RNN (DM-RNN): A Quantum Information Theoretic Framework for Modeling Musical Context and Polyphony","summary":"Classical Recurrent Neural Networks (RNNs) summarize musical context into a deterministic hidden state vector, imposing an information bottleneck that fails to capture the inherent ambiguity in music. We propose the Density Matrix RNN (DM-RNN), a novel theoretical architecture utilizing the Density Matrix. This allows the model to maintain a statistical ensemble of musical interpretations (a mixed state), capturing both classical probabilities and quantum coherences. We rigorously define the temporal dynamics using Quantum Channels (CPTP maps). Crucially, we detail a parameterization strategy based on the Choi-Jamiolkowski isomorphism, ensuring the learned dynamics remain physically valid (CPTP) by construction. We introduce an analytical framework using Von Neumann Entropy to quantify musical uncertainty and Quantum Mutual Information (QMI) to measure entanglement between voices. The DM-RNN provides a mathematically rigorous framework for modeling complex, ambiguous musical structures.","authors":["Joonwon Seo","Mariana Montiel"],"pdf_url":"","comment":"Submitted to the 10th International Conference on Mathematics and Computation in Music (MCM 2026)"},{"id":"http://arxiv.org/abs/2601.04587v1","updated":"2026-01-08T04:35:28Z","published":"2026-01-08T04:35:28Z","title":"FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems","summary":"This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.","authors":["Quang-Tu Pham","Hoang-Dieu Vu","Dinh-Dat Pham","Hieu H. Pham"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.11046v2","updated":"2026-01-08T04:26:02Z","published":"2025-11-14T08:00:19Z","title":"Enhancing Graph Representations with Neighborhood-Contextualized Message-Passing","summary":"Graph neural networks (GNNs) have become an indispensable tool for analyzing relational data. Classical GNNs are broadly classified into three variants: convolutional, attentional, and message-passing. While the standard message-passing variant is expressive, its typical pair-wise messages only consider the features of the center node and each neighboring node individually. This design fails to incorporate contextual information contained within the broader local neighborhood, potentially hindering its ability to learn complex relationships within the entire set of neighboring nodes. To address this limitation, this work first formalizes the concept of neighborhood-contextualization, rooted in a key property of the attentional variant. This then serves as the foundation for generalizing the message-passing variant to the proposed neighborhood-contextualized message-passing (NCMP) framework. To demonstrate its utility, a simple, practical, and efficient method to parametrize and operationalize NCMP is presented, leading to the development of the proposed Soft-Isomorphic Neighborhood-Contextualized Graph Convolution Network (SINC-GCN). Across a diverse set of synthetic and benchmark GNN datasets, SINC-GCN demonstrates competitive performance against baseline GNN models, highlighting its expressivity and efficiency. Notably, it also delivers substantial and statistically significant performance gains in graph property prediction tasks, further underscoring the distinctive utility of neighborhood-contextualization. Overall, the paper lays the foundation for the NCMP framework as a practical path toward enhancing the graph representational power of classical GNNs.","authors":["Brian Godwin Lim","Galvin Brice Lim","Renzo Roel Tan","Irwin King","Kazushi Ikeda"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04577v1","updated":"2026-01-08T04:12:47Z","published":"2026-01-08T04:12:47Z","title":"Sci-Reasoning: A Dataset Decoding AI Innovation Patterns","summary":"While AI innovation accelerates rapidly, the intellectual process behind breakthroughs -- how researchers identify gaps, synthesize prior work, and generate insights -- remains poorly understood. The lack of structured data on scientific reasoning hinders systematic analysis and development of AI research agents. We introduce Sci-Reasoning, the first dataset capturing the intellectual synthesis behind high-quality AI research. Using community-validated quality signals and an LLM-accelerated, human-verified pipeline, we trace Oral and Spotlight papers across NeurIPS, ICML, and ICLR (2023-2025) to its key predecessors, articulating specific reasoning links in a structured format. Our analysis identifies 15 distinct thinking patterns, with three dominant strategies accounting for 52.7%: Gap-Driven Reframing (24.2%), Cross-Domain Synthesis (18.0%), and Representation Shift (10.5%). The most powerful innovation recipes combine multiple patterns: Gap-Driven Reframing + Representation Shift, Cross-Domain Synthesis + Representation Shift, and Gap-Driven Reframing + Cross-Domain Synthesis. This dataset enables quantitative studies of scientific progress and provides structured reasoning trajectories for training the next generation AI research agents.","authors":["Jiachen Liu","Maestro Harmon","Zechen Zhang"],"pdf_url":"","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2601.01410v3","updated":"2026-01-08T04:12:43Z","published":"2026-01-04T07:30:50Z","title":"Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems","summary":"Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics mask this operational asymmetry. We introduce a grid-specific evaluation framework (Asymmetric MAPE, Under-Prediction Rate, and Reserve Margin) that directly measures operational risk rather than statistical accuracy alone. Using this framework, we conduct a systematic evaluation of Mamba-based State Space Models for California grid forecasting on a weather-aligned CA ISO-TAC dataset spanning Nov 2023 to Nov 2025 (84,498 hourly records across 5 transmission areas). Our analysis reveals that standard accuracy metrics are poor proxies for operational safety: models with identical MAPE can require vastly different reserve margins. We demonstrate that forecast errors are weakly but statistically significantly associated with temperature (r = 0.16), motivating weather-aware modeling rather than loss function modification alone. The S-Mamba model achieves the lowest 99.5th-percentile reserve margin (14.12 percent) compared to 16.66 percent for iTransformer, demonstrating superior forecast reliability under a 99.5th-percentile tail-risk reserve proxy.","authors":["Jisoo Lee","Sunki Hong"],"pdf_url":"","comment":"25 pages, 7 figures, 8 tables"}],"Artificial Intelligence Learning":[{"id":"http://arxiv.org/abs/2601.05242v1","updated":"2026-01-08T18:59:24Z","published":"2026-01-08T18:59:24Z","title":"GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization","summary":"As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.","authors":["Shih-Yang Liu","Xin Dong","Ximing Lu","Shizhe Diao","Peter Belcak","Mingjie Liu","Min-Hung Chen","Hongxu Yin","Yu-Chiang Frank Wang","Kwang-Ting Cheng","Yejin Choi","Jan Kautz","Pavlo Molchanov"],"pdf_url":"","comment":"NVIDIA-Tech Report"},{"id":"http://arxiv.org/abs/2601.05241v1","updated":"2026-01-08T18:59:22Z","published":"2026-01-08T18:59:22Z","title":"RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation","summary":"The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.","authors":["Boyang Wang","Haoran Zhang","Shujie Zhang","Jinkun Hao","Mingda Jia","Qi Lv","Yucheng Mao","Zhaoyang Lyu","Jia Zeng","Xudong Xu","Jiangmiao Pang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05240v1","updated":"2026-01-08T18:58:34Z","published":"2026-01-08T18:58:34Z","title":"Robust Reasoning as a Symmetry-Protected Topological Phase","summary":"Large language models suffer from \"hallucinations\"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a \"Metric Phase,\" where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic \"mass gap,\" maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \\times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\\times$ beyond training ($L=50 \\to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.","authors":["Ilmo Sung"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05230v1","updated":"2026-01-08T18:55:39Z","published":"2026-01-08T18:55:39Z","title":"Learning Latent Action World Models In The Wild","summary":"Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require action labels, that can be complex to obtain at scale. This motivates the learning of latent action models, that can learn an action space from videos alone. Our work addresses the problem of learning latent actions world models on in-the-wild videos, expanding the scope of existing works that focus on simple robotics simulations, video games, or manipulation data. While this allows us to capture richer actions, it also introduces challenges stemming from the video diversity, such as environmental noise, or the lack of a common embodiment across videos. To address some of the challenges, we discuss properties that actions should follow as well as relevant architectural choices and evaluations. We find that continuous, but constrained, latent actions are able to capture the complexity of actions from in-the-wild videos, something that the common vector quantization does not. We for example find that changes in the environment coming from agents, such as humans entering the room, can be transferred across videos. This highlights the capability of learning actions that are specific to in-the-wild videos. In the absence of a common embodiment across videos, we are mainly able to learn latent actions that become localized in space, relative to the camera. Nonetheless, we are able to train a controller that maps known actions to latent ones, allowing us to use latent actions as a universal interface and solve planning tasks with our world model with similar performance as action-conditioned baselines. Our analyses and experiments provide a step towards scaling latent action models to the real world.","authors":["Quentin Garrido","Tushar Nagarajan","Basile Terver","Nicolas Ballas","Yann LeCun","Michael Rabbat"],"pdf_url":"","comment":"37 pages, 25 figures"},{"id":"http://arxiv.org/abs/2601.05219v1","updated":"2026-01-08T18:44:21Z","published":"2026-01-08T18:44:21Z","title":"CAOS: Conformal Aggregation of One-Shot Predictors","summary":"One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data. Despite violating classical exchangeability assumptions, we prove that CAOS achieves valid marginal coverage using a monotonicity-based argument. Experiments on one-shot facial landmarking and RAFT text classification tasks show that CAOS produces substantially smaller prediction sets than split conformal baselines while maintaining reliable coverage.","authors":["Maja Waldron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05215v1","updated":"2026-01-08T18:39:52Z","published":"2026-01-08T18:39:52Z","title":"MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents","summary":"We present \\textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \\emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.\n  As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \\textbf{216} subtasks across \\textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.","authors":["Tamil Sudaravan Mohan Doss","Michael Xu","Sudha Rao","Andrew D. Wilson","Balasaravanan Thoravi Kumaravel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05214v1","updated":"2026-01-08T18:38:45Z","published":"2026-01-08T18:38:45Z","title":"Internal Representations as Indicators of Hallucinations in Agent Tool Selection","summary":"Large Language Models (LLMs) have shown remarkable capabilities in tool calling and tool usage, but suffer from hallucinations where they choose incorrect tools, provide malformed parameters and exhibit 'tool bypass' behavior by performing simulations and generating outputs instead of invoking specialized tools or external systems. This undermines the reliability of LLM based agents in production systems as it leads to inconsistent results, and bypasses security and audit controls. Such hallucinations in agent tool selection require early detection and error handling. Unlike existing hallucination detection methods that require multiple forward passes or external validation, we present a computationally efficient framework that detects tool-calling hallucinations in real-time by leveraging LLMs' internal representations during the same forward pass used for generation. We evaluate this approach on reasoning tasks across multiple domains, demonstrating strong detection performance (up to 86.4\\% accuracy) while maintaining real-time inference capabilities with minimal computational overhead, particularly excelling at detecting parameter-level hallucinations and inappropriate tool selections, critical for reliable agent deployment.","authors":["Kait Healy","Bharathi Srinivasan","Visakh Madathil","Jing Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10105v2","updated":"2026-01-08T18:34:35Z","published":"2025-12-10T21:51:16Z","title":"Belief Is All You Need: Modeling Narrative Archetypes in Conspiratorial Discourse","summary":"Conspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features.\n  Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.","authors":["Soorya Ram Shimgekar","Abhay Goyal","Roy Ka-Wei Lee","Koustuv Saha","Pi Zonooz","Navin Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01266v2","updated":"2026-01-08T18:28:40Z","published":"2026-01-03T19:24:51Z","title":"From Policy to Logic for Efficient and Interpretable Coverage Assessment","summary":"Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.","authors":["Rhitabrat Pokharel","Hamid Reza Hassanzadeh","Ameeta Agrawal"],"pdf_url":"","comment":"Accepted at AIMedHealth @ AAAI 2026"},{"id":"http://arxiv.org/abs/2601.02015v2","updated":"2026-01-08T18:27:27Z","published":"2026-01-05T11:24:33Z","title":"Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects","summary":"Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.","authors":["Omar Momen","Emilie Sitter","Berenike Herrmann","Sina Zarrieß"],"pdf_url":"","comment":"to be published at EACL 2026 main conference"},{"id":"http://arxiv.org/abs/2601.05202v1","updated":"2026-01-08T18:24:22Z","published":"2026-01-08T18:24:22Z","title":"Stock Market Price Prediction using Neural Prophet with Deep Neural Network","summary":"Stock market price prediction is a significant interdisciplinary research domain that depends at the intersection of finance, statistics, and economics. Forecasting Accurately predicting stock prices has always been a focal point for various researchers. However, existing statistical approaches for time-series prediction often fail to effectively forecast the probability range of future stock prices. Hence, to solve this problem, the Neural Prophet with a Deep Neural Network (NP-DNN) is proposed to predict stock market prices. The preprocessing technique used in this research is Z-score normalization, which normalizes stock price data by removing scale differences, making patterns easier to detect. Missing value imputation fills gaps in historical data, enhancing the models use of complete information for more accurate predictions. The Multi-Layer Perceptron (MLP) learns complex nonlinear relationships among stock market prices and extracts hidden patterns from the input data, thereby creating meaningful feature representations for better prediction accuracy. The proposed NP-DNN model achieved an accuracy of 99.21% compared with other approaches using the Fused Large Language Model. Keywords: deep neural network, forecasting stock prices, multi-layer perceptron, neural prophet, stock market price prediction.","authors":["Navin Chhibber","Suneel Khemka","Navneet Kumar Tyagi","Rohit Tewari","Bireswar Banerjee","Piyush Ranjan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05201v1","updated":"2026-01-08T18:23:03Z","published":"2026-01-08T18:23:03Z","title":"Mechanisms of Prompt-Induced Hallucination in Vision-Language Models","summary":"Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy. Through mechanistic analysis of three VLMs, we identify a small set of attention heads whose ablation substantially reduces prompt-induced hallucinations (PIH) by at least 40% without additional training. Across models, PIH-heads mediate prompt copying in model-specific ways. We characterize these differences and show that PIH ablation increases correction toward visual evidence. Our findings offer insights into the internal mechanisms driving prompt-induced hallucinations, revealing model-specific differences in how these behaviors are implemented.","authors":["William Rudman","Michal Golovanevsky","Dana Arad","Yonatan Belinkov","Ritambhara Singh","Carsten Eickhoff","Kyle Mahowald"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03470v2","updated":"2026-01-08T18:16:48Z","published":"2026-01-06T23:48:00Z","title":"Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms","summary":"We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigating multi-objective trade-offs inherent in trustworthiness evaluation. We demonstrate this approach using uncertainty quantification as an exemplar measurement mechanism and illustrate feasibility through an Uncrewed Aircraft System (UAS) detection case study.","authors":["Michael C. Darling","Alan H. Hesu","Michael A. Mardikes","Brian C. McGuigan","Reed M. Milewicz"],"pdf_url":"","comment":"Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification"},{"id":"http://arxiv.org/abs/2601.05187v1","updated":"2026-01-08T18:10:35Z","published":"2026-01-08T18:10:35Z","title":"SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning","summary":"Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle sparse rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-preserving, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between LLMs and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.","authors":["Yanchang Liang","Xiaowei Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05184v1","updated":"2026-01-08T18:08:15Z","published":"2026-01-08T18:08:15Z","title":"Observations and Remedies for Large Language Model Bias in Self-Consuming Performative Loop","summary":"The rapid advancement of large language models (LLMs) has led to growing interest in using synthetic data to train future models. However, this creates a self-consuming retraining loop, where models are trained on their own outputs and may cause performance drops and induce emerging biases. In real-world applications, previously deployed LLMs may influence the data they generate, leading to a dynamic system driven by user feedback. For example, if a model continues to underserve users from a group, less query data will be collected from this particular demographic of users. In this study, we introduce the concept of \\textbf{S}elf-\\textbf{C}onsuming \\textbf{P}erformative \\textbf{L}oop (\\textbf{SCPL}) and investigate the role of synthetic data in shaping bias during these dynamic iterative training processes under controlled performative feedback. This controlled setting is motivated by the inaccessibility of real-world user preference data from dynamic production systems, and enables us to isolate and analyze feedback-driven bias evolution in a principled manner. We focus on two types of loops, including the typical retraining setting and the incremental fine-tuning setting, which is largely underexplored. Through experiments on three real-world tasks, we find that the performative loop increases preference bias and decreases disparate bias. We design a reward-based rejection sampling strategy to mitigate the bias, moving towards more trustworthy self-improving systems.","authors":["Yaxuan Wang","Zhongteng Cai","Yujia Bao","Xueru Zhang","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05174v1","updated":"2026-01-08T18:00:58Z","published":"2026-01-08T18:00:58Z","title":"FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts","summary":"Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.","authors":["Yiji Zhao","Zihao Zhong","Ao Wang","Haomin Wen","Ming Jin","Yuxuan Liang","Huaiyu Wan","Hao Wu"],"pdf_url":"","comment":"Accepted to KDD 2026"},{"id":"http://arxiv.org/abs/2601.05172v1","updated":"2026-01-08T17:59:42Z","published":"2026-01-08T17:59:42Z","title":"CoV: Chain-of-View Prompting for Spatial Reasoning","summary":"Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process. CoV first employs a View Selection agent to filter redundant frames and identify question-aligned anchor views. It then performs fine-grained view adjustment by interleaving iterative reasoning with discrete camera actions, obtaining new observations from the underlying 3D scene representation until sufficient context is gathered or a step budget is reached.\n  We evaluate CoV on OpenEQA across four mainstream VLMs and obtain an average +11.56\\% improvement in LLM-Match, with a maximum gain of +13.62\\% on Qwen3-VL-Flash. CoV further exhibits test-time scaling: increasing the minimum action budget yields an additional +2.51\\% average improvement, peaking at +3.73\\% on Gemini-2.5-Flash. On ScanQA and SQA3D, CoV delivers strong performance (e.g., 116 CIDEr / 31.9 EM@1 on ScanQA and 51.1 EM@1 on SQA3D). Overall, these results suggest that question-aligned view selection coupled with open-view search is an effective, model-agnostic strategy for improving spatial reasoning in 3D EQA without additional training.","authors":["Haoyu Zhao","Akide Liu","Zeyu Zhang","Weijie Wang","Feng Chen","Ruihan Zhu","Gholamreza Haffari","Bohan Zhuang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05167v1","updated":"2026-01-08T17:56:16Z","published":"2026-01-08T17:56:16Z","title":"RelayLLM: Efficient Reasoning via Collaborative Decoding","summary":"Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.","authors":["Chengsong Huang","Tong Zheng","Langlin Huang","Jinyuan Li","Haolin Liu","Jiaxin Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10152v2","updated":"2026-01-08T17:54:58Z","published":"2025-08-13T19:32:01Z","title":"Improving and Evaluating Open Deep Research Agents","summary":"We focus here on Deep Research Agents (DRAs), which are systems that can take a natural language prompt from a user, and then autonomously search for, and utilize, internet-based content to address the prompt. Recent DRAs have demonstrated impressive capabilities on public benchmarks however, recent research largely involves proprietary closed-source systems. At the time of this work, we only found one open-source DRA, termed Open Deep Research (ODR). In this work we adapt the challenging recent BrowseComp benchmark to compare ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small), comprising a subset of BrowseComp, as a more computationally-tractable DRA benchmark for academic labs. We benchmark ODR and two other proprietary systems on BC-Small: one system from Anthropic and one system from Google. We find that all three systems achieve 0% accuracy on the test set of 60 questions. We introduce three strategic improvements to ODR, resulting in the ODR+ model, which achieves a state-of-the-art 10% success rate on BC-Small among both closed-source and open-source systems. We report ablation studies indicating that all three of our improvements contributed to the success of ODR+.","authors":["Doaa Allabadi","Kyle Bradbury","Jordan M. Malof"],"pdf_url":"","comment":"8 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2601.05159v1","updated":"2026-01-08T17:49:13Z","published":"2026-01-08T17:49:13Z","title":"Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering","summary":"Object hallucination critically undermines the reliability of Multimodal Large Language Models, often stemming from a fundamental failure in cognitive introspection, where models blindly trust linguistic priors over specific visual evidence. Existing mitigations remain limited: contrastive decoding approaches operate superficially without rectifying internal semantic misalignments, while current latent steering methods rely on static vectors that lack instance-specific precision. We introduce Vision-Language Introspection (VLI), a training-free inference framework that simulates a metacognitive self-correction process. VLI first performs Attributive Introspection to diagnose hallucination risks via probabilistic conflict detection and localize the causal visual anchors. It then employs Interpretable Bi-Causal Steering to actively modulate the inference process, dynamically isolating visual evidence from background noise while neutralizing blind confidence through adaptive calibration. VLI achieves state-of-the-art performance on advanced models, reducing object hallucination rates by 12.67% on MMHal-Bench and improving accuracy by 5.8% on POPE.","authors":["Shuliang Liu","Songbo Yang","Dong Fang","Sihang Jia","Yuqi Tang","Lingfeng Su","Ruoshui Peng","Yibo Yan","Xin Zou","Xuming Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05152v1","updated":"2026-01-08T17:42:56Z","published":"2026-01-08T17:42:56Z","title":"Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art","summary":"This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms.\n  Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning","authors":["Timofey Tomashevskiy"],"pdf_url":"","comment":"20 pages, 4 figures"},{"id":"http://arxiv.org/abs/2601.05148v1","updated":"2026-01-08T17:37:00Z","published":"2026-01-08T17:37:00Z","title":"Atlas 2 -- Foundation models for clinical deployment","summary":"Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model dataset to date comprising 5.5 million histopathology whole slide images, collected from three medical institutions Charité - Universtätsmedizin Berlin, LMU Munich, and Mayo Clinic.","authors":["Maximilian Alber","Timo Milbich","Alexandra Carpen-Amarie","Stephan Tietz","Jonas Dippel","Lukas Muttenthaler","Beatriz Perez Cancer","Alessandro Benetti","Panos Korfiatis","Elias Eulig","Jérôme Lüscher","Jiasen Wu","Sayed Abid Hashimi","Gabriel Dernbach","Simon Schallenberg","Neelay Shah","Moritz Krügener","Aniruddh Jammoria","Jake Matras","Patrick Duffy","Matt Redlon","Philipp Jurmeister","David Horst","Lukas Ruff","Klaus-Robert Müller","Frederick Klauschen","Andrew Norgan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05144v1","updated":"2026-01-08T17:32:22Z","published":"2026-01-08T17:32:22Z","title":"Distilling the Thought, Watermarking the Answer: A Principle Semantic Guided Watermark for Large Reasoning Models","summary":"Reasoning Large Language Models (RLLMs) excelling in complex tasks present unique challenges for digital watermarking, as existing methods often disrupt logical coherence or incur high computational costs. Token-based watermarking techniques can corrupt the reasoning flow by applying pseudo-random biases, while semantic-aware approaches improve quality but introduce significant latency or require auxiliary models. This paper introduces ReasonMark, a novel watermarking framework specifically designed for reasoning-intensive LLMs. Our approach decouples generation into an undisturbed Thinking Phase and a watermarked Answering Phase. We propose a Criticality Score to identify semantically pivotal tokens from the reasoning trace, which are distilled into a Principal Semantic Vector (PSV). The PSV then guides a semantically-adaptive mechanism that modulates watermark strength based on token-PSV alignment, ensuring robustness without compromising logical integrity. Extensive experiments show ReasonMark surpasses state-of-the-art methods by reducing text Perplexity by 0.35, increasing translation BLEU score by 0.164, and raising mathematical accuracy by 0.67 points. These advancements are achieved alongside a 0.34% higher watermark detection AUC and stronger robustness to attacks, all with a negligible increase in latency. This work enables the traceable and trustworthy deployment of reasoning LLMs in real-world applications.","authors":["Shuliang Liu","Xingyu Li","Hongyi Liu","Yibo Yan","Bingchen Duan","Qi Zheng","Dong Fang","Lingfeng Su","Xuming Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.14750v3","updated":"2026-01-08T17:31:42Z","published":"2024-05-23T16:17:16Z","title":"Extreme Solar Flare Prediction Using Residual Networks with HMI Magnetograms and Intensitygrams","summary":"Solar flares, especially C, M, and X class, pose significant risks to satellite operations, communication systems, and power grids. We present a novel approach for predicting extreme solar flares using HMI intensitygrams and magnetograms. By detecting sunspots from intensitygrams and extracting magnetic field patches from magnetograms, we train a Residual Network (ResNet) to classify extreme class flares. Our model demonstrates high accuracy, offering a robust tool for predicting extreme solar flares and improving space weather forecasting. Additionally, we show that HMI magnetograms provide more useful data for deep learning compared to other SDO AIA images by better capturing features critical for predicting flare magnitudes. This study underscores the importance of identifying magnetic fields in solar flare prediction, marking a significant advancement in solar activity prediction with practical implications for mitigating space weather impacts.","authors":["Juyoung Yun","Jungmin Shin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.04739v2","updated":"2026-01-08T17:22:46Z","published":"2025-02-04T14:47:30Z","title":"A Framework for Responsible AI Systems: Building Societal Trust through Domain Definition, Trustworthy AI Design, Auditability, Accountability, and Governance","summary":"Responsible Artificial Intelligence (RAI) addresses the ethical and regulatory challenges of deploying AI systems in high-risk scenarios. This paper proposes a comprehensive framework for the design of an RAI system (RAIS) that integrates five key dimensions: domain definition, trustworthy AI design, auditability, accountability, and governance. Unlike prior work that treats these components in isolation, our proposal emphasizes their inter-dependencies and iterative feedback loops, enabling proactive and reactive accountability throughout the AI lifecycle. Beyond presenting the framework, we synthesize recent developments in global AI governance and analyze limitations in existing principles-based approaches, highlighting fragmentation, implementation gaps, and the need for participatory governance. The paper also identifies critical challenges and research directions for the RAIS framework, including sector-specific adaptation and operationalization, to support certification, post-deployment monitoring, and risk-based auditing. By bridging technical design and institutional responsibility, this work offers a practical blueprint for embedding responsibility throughout the AI lifecycle, enabling transparent, ethically aligned, and legally compliant AI-based systems.","authors":["Andrés Herrera-Poyatos","Javier Del Ser","Marcos López de Prado","Fei-Yue Wang","Enrique Herrera-Viedma","Francisco Herrera"],"pdf_url":"","comment":"27 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2508.07142v4","updated":"2026-01-08T17:18:24Z","published":"2025-08-10T02:25:48Z","title":"Why Does Stochastic Gradient Descent Slow Down in Low-Precision Training?","summary":"Low-precision training has become crucial for reducing the computational and memory costs of large-scale deep learning. However, quantizing gradients introduces magnitude shrinkage, which can change how stochastic gradient descent (SGD) converges. In this study, we explore SGD convergence under a gradient shrinkage model, where each stochastic gradient is scaled by a factor \\( q_k \\in (0,1] \\). We show that this shrinkage affect the usual stepsize \\( μ_k \\) with an effective stepsize \\( μ_k q_k \\), slowing convergence when \\( q_{\\min} < 1 \\). With typical smoothness and bounded-variance assumptions, we prove that low-precision SGD still converges, but at a slower pace set by \\( q_{\\min} \\), and with a higher steady error level due to quantization effects. We analyze theoretically how lower numerical precision slows training by treating it as gradient shrinkage within the standard SGD convergence setup.","authors":["Vincent-Daniel Yun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05125v1","updated":"2026-01-08T17:15:15Z","published":"2026-01-08T17:15:15Z","title":"VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding","summary":"This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters. We validate the methodology by training on the synthetic MERIT Dataset and evaluating on its real-world counterpart, MERIT Secret. Results show that VERSE helps uncover the visual features associated with error-prone clusters, and that retraining with samples containing these features substantially boosts F1 performance without degrading generalization. Furthermore, we demonstrate that on-premise models such as Donut and Idefics2, when optimized with VERSE, match or even surpass the performance of SaaS solutions like GPT-4 and Pixtral.","authors":["Ignacio de Rodrigo","Alvaro J. Lopez-Lopez","Jaime Boal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.18526v2","updated":"2026-01-08T17:04:29Z","published":"2025-03-24T10:31:31Z","title":"SciClaims: An End-to-End Generative System for Biomedical Claim Analysis","summary":"We present SciClaims, an interactive web-based system for end-to-end scientific claim analysis in the biomedical domain. Designed for high-stakes use cases such as systematic literature reviews and patent validation, SciClaims extracts claims from text, retrieves relevant evidence from PubMed, and verifies their veracity. The system features a user-friendly interface where users can input scientific text and view extracted claims, predictions, supporting or refuting evidence, and justifications in natural language. Unlike prior approaches, SciClaims seamlessly integrates the entire scientific claim analysis process using a single large language model, without requiring additional fine-tuning. SciClaims is optimized to run efficiently on a single GPU and is publicly available for live interaction.","authors":["Raúl Ortega","José Manuel Gómez-Pérez"],"pdf_url":"","comment":"In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: System Demonstrations"},{"id":"http://arxiv.org/abs/2601.05114v1","updated":"2026-01-08T17:02:22Z","published":"2026-01-08T17:02:22Z","title":"Evaluative Fingerprints: Stable and Systematic Differences in LLM Evaluator Behavior","summary":"LLM-as-judge systems promise scalable, consistent evaluation. We find the opposite: judges are consistent, but not with each other; they are consistent with themselves. Across 3,240 evaluations (9 judges x 120 unique video x pack items x 3 independent runs), inter-judge agreement is near-zero (Krippendorff's α = 0.042). On two dimensions, judges disagree more than random noise would predict (α < 0). Yet this disagreement isn't chaos; it's structured. A classifier identifies which judge produced an evaluation with 77.1% accuracy from rubric scores alone, rising to 89.9% with disposition features. Within model families, the signal is even stronger: GPT-4.1 and GPT-5.2 are distinguishable with 99.6% accuracy. We call this the reliability paradox: judges cannot agree on what constitutes quality, yet their disagreement patterns are so stable they function as fingerprints. Each judge implements a distinct, stable theory of quality: an \"evaluative disposition\" that shapes how it interprets any rubric. We characterize these dispositions along multiple axes: harshness/leniency, dimension emphasis, within-judge stability (ICC), and evidence behavior (receipt validity, semantic linkage via NLI, and shotgun index). The implication is stark: LLM judges are not interchangeable instruments measuring a shared construct. They are distinct measurement devices, each encoding its own implicit theory of quality. Averaging their scores produces a synthetic verdict that corresponds to no judge's actual values.","authors":["Wajid Nasser"],"pdf_url":"","comment":"23 pages, 6 figures, code and artifacts at : https://github.com/wajid-nasser/evaluative-fingerprints"},{"id":"http://arxiv.org/abs/2507.11939v2","updated":"2026-01-08T17:00:25Z","published":"2025-07-16T06:09:02Z","title":"POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering","summary":"Charts are a universally adopted medium for data communication, yet existing chart understanding benchmarks are overwhelmingly English-centric, limiting their accessibility and relevance to global audiences. To address this limitation, we introduce PolyChartQA, the first large-scale multilingual benchmark for chart question answering, comprising 22,606 charts and 26,151 QA pairs across 10 diverse languages. PolyChartQA is constructed through a scalable pipeline that enables efficient multilingual chart generation via data translation and code reuse, supported by LLM-based translation and rigorous quality control. We systematically evaluate multilingual chart understanding with PolyChartQA on state-of-the-art LVLMs and reveal a significant performance gap between English and other languages, particularly low-resource ones. Additionally, we introduce a companion multilingual chart question answering training set, PolyChartQA-Train, on which fine-tuning LVLMs yields substantial gains in multilingual chart understanding across diverse model sizes and architectures. Together, our benchmark provides a foundation for developing globally inclusive vision-language models capable of understanding charts across diverse linguistic contexts.","authors":["Yichen Xu","Liangyu Chen","Liang Zhang","Jianzhe Ma","Wenxuan Wang","Qin Jin"],"pdf_url":"","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2505.23923v2","updated":"2026-01-08T16:58:59Z","published":"2025-05-29T18:15:18Z","title":"Act-Adaptive Margin: Dynamically Calibrating Reward Models for Subjective Ambiguity","summary":"Currently, most reinforcement learning tasks focus on domains like mathematics and programming, where verification is relatively straightforward. However, in subjective tasks such as role-playing, alignment techniques struggle to make progress, primarily because subjective reward modeling using the Bradley-Terry model faces significant challenges when dealing with ambiguous preferences. To improve reward modeling in subjective tasks, this paper proposes AAM (\\textbf{\\underline{A}}ct-\\textbf{\\underline{A}}daptive \\textbf{\\underline{M}}argin), which enhances reward modeling by dynamically calibrating preference margins using the model's internal parameter knowledge. We design two versions of AAM that efficiently generate contextually-appropriate preference gaps without additional human annotation. This approach fundamentally improves how reward models handle subjective rewards by better integrating generative understanding with preference scoring. To validate AAM's effectiveness in subjective reward modeling, we conduct evaluations on RewardBench, JudgeBench, and challenging role-playing tasks. Results show that AAM significantly improves subjective reward modeling performance, enhancing Bradley-Terry reward models by 2.95\\% in general tasks and 4.85\\% in subjective role-playing tasks. Furthermore, reward models trained with AAM can help downstream alignment tasks achieve better results. Our test results show that applying rewards generated by AAM-Augmented RM to preference learning techniques (e.g., GRPO) achieves state-of-the-art results on CharacterEval and Charm. Code and dataset are available at https://github.com/calubkk/AAM.","authors":["Feiteng Fang","Dingwei Chen","Xiang Huang","Ting-En Lin","Yuchuan Wu","Xiong Liu","Xinge Ye","Ziqiang Liu","Haonan Zhang","Liang Zhu","Hamid Alinejad-Rokny","Min Yang","Yongbin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05111v1","updated":"2026-01-08T16:58:10Z","published":"2026-01-08T16:58:10Z","title":"Agent-as-a-Judge","summary":"LLM-as-a-Judge has revolutionized AI evaluation by leveraging large language models for scalable assessments. However, as evaluands become increasingly complex, specialized, and multi-step, the reliability of LLM-as-a-Judge has become constrained by inherent biases, shallow single-pass reasoning, and the inability to verify assessments against real-world observations. This has catalyzed the transition to Agent-as-a-Judge, where agentic judges employ planning, tool-augmented verification, multi-agent collaboration, and persistent memory to enable more robust, verifiable, and nuanced evaluations. Despite the rapid proliferation of agentic evaluation systems, the field lacks a unified framework to navigate this shifting landscape. To bridge this gap, we present the first comprehensive survey tracing this evolution. Specifically, we identify key dimensions that characterize this paradigm shift and establish a developmental taxonomy. We organize core methodologies and survey applications across general and professional domains. Furthermore, we analyze frontier challenges and identify promising research directions, ultimately providing a clear roadmap for the next generation of agentic evaluation.","authors":["Runyang You","Hongru Cai","Caiqi Zhang","Qiancheng Xu","Meng Liu","Tiezheng Yu","Yongqi Li","Wenjie Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05110v1","updated":"2026-01-08T16:58:07Z","published":"2026-01-08T16:58:07Z","title":"GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts","summary":"Large Reasoning Models (LRMs) achieve remarkable performance by explicitly generating multi-step chains of thought, but this capability incurs substantial inference latency and computational cost. Collaborative inference offers a promising solution by selectively allocating work between lightweight and large models, yet a fundamental challenge remains: determining when a reasoning step requires the capacity of a large model or the efficiency of a small model. Existing routing strategies either rely on local token probabilities or post-hoc verification, introducing significant inference overhead. In this work, we propose a novel perspective on step-wise collaboration: the difficulty of a reasoning step can be inferred from its very first token. Inspired by the \"Aha Moment\" phenomenon in LRMs, we show that the entropy of the initial token serves as a strong predictor of step difficulty. Building on this insight, we introduce GlimpRouter, a training-free step-wise collaboration framework. GlimpRouter employs a lightweight model to generate only the first token of each reasoning step and routes the step to a larger model only when the initial token entropy exceeds a threshold. Experiments on multiple benchmarks demonstrate that our approach significantly reduces inference latency while preserving accuracy. For instance, GlimpRouter attains a substantial 10.7% improvement in accuracy while reducing inference latency by 25.9% compared to a standalone large model on AIME25. These results suggest a simple yet effective mechanism for reasoning: allocating computation based on a glimpse of thought rather than full-step evaluation.","authors":["Wenhao Zeng","Xuteng Zhang","Yuling Shi","Chao Hu","Yuting Chen","Beijun Shen","Xiaodong Gu"],"pdf_url":"","comment":"Code available at https://github.com/Zengwh02/GlimpRouter"},{"id":"http://arxiv.org/abs/2512.00949v2","updated":"2026-01-08T16:55:55Z","published":"2025-11-30T16:01:50Z","title":"Multi-Modal AI for Remote Patient Monitoring in Cancer Care","summary":"For patients undergoing systemic cancer therapy, the time between clinic visits is full of uncertainties and risks of unmonitored side effects. To bridge this gap in care, we developed and prospectively trialed a multi-modal AI framework for remote patient monitoring (RPM). This system integrates multi-modal data from the HALO-X platform, such as demographics, wearable sensors, daily surveys, and clinical events. Our observational trial is one of the largest of its kind and has collected over 2.1 million data points (6,080 patient-days) of monitoring from 84 patients. We developed and adapted a multi-modal AI model to handle the asynchronous and incomplete nature of real-world RPM data, forecasting a continuous risk of future adverse events. The model achieved an accuracy of 83.9% (AUROC=0.70). Notably, the model identified previous treatments, wellness check-ins, and daily maximum heart rate as key predictive features. A case study demonstrated the model's ability to provide early warnings by outputting escalating risk profiles prior to the event. This work establishes the feasibility of multi-modal AI RPM for cancer care and offers a path toward more proactive patient support.(Accepted at Europe NeurIPS 2025 Multimodal Representation Learning for Healthcare Workshop. Best Paper Poster Award.)","authors":["Yansong Liu","Ronnie Stafford","Pramit Khetrapal","Huriye Kocadag","Graça Carvalho","Patricia de Winter","Maryam Imran","Amelia Snook","Adamos Hadjivasiliou","D. Vijay Anand","Weining Lin","John Kelly","Yukun Zhou","Ivana Drobnjak"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05107v1","updated":"2026-01-08T16:54:30Z","published":"2026-01-08T16:54:30Z","title":"Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction","summary":"As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory usage: incorporating all relevant past information can lead to \\textit{Memory Anchoring}, where the agent is trapped by past interactions, while excluding memory entirely results in under-utilization and the loss of important interaction history. We show that an agent's reliance on memory can be modeled as an explicit and user-controllable dimension. We first introduce a behavioral metric of memory dependence to quantify the influence of past interactions on current outputs. We then propose \\textbf{Stee}rable \\textbf{M}emory Agent, \\texttt{SteeM}, a framework that allows users to dynamically regulate memory reliance, ranging from a fresh-start mode that promotes innovation to a high-fidelity mode that closely follows interaction history. Experiments across different scenarios demonstrate that our approach consistently outperforms conventional prompting and rigid memory masking strategies, yielding a more nuanced and effective control for personalized human-agent collaboration.","authors":["Muzhao Tian","Zisu Huang","Xiaohua Wang","Jingwen Xu","Zhengkang Guo","Qi Qian","Yuanzhe Shen","Kaitao Song","Jiakang Yuan","Changze Lv","Xiaoqing Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05106v1","updated":"2026-01-08T16:53:16Z","published":"2026-01-08T16:53:16Z","title":"Token-Level LLM Collaboration via FusionRoute","summary":"Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.","authors":["Nuoya Xiong","Yuhang Zhou","Hanqing Zeng","Zhaorun Chen","Furong Huang","Shuchao Bi","Lizhu Zhang","Zhuokai Zhao"],"pdf_url":"","comment":"25 pages"},{"id":"http://arxiv.org/abs/2512.16282v2","updated":"2026-01-08T16:51:18Z","published":"2025-12-18T08:01:19Z","title":"CALM: A CKA-Guided Adaptive Layer-Wise Modularization Framework for LLM Quantization","summary":"Current mainstream post-training quantization methods for large language models typically apply a uniform quantization strategy across all network layers, overlooking the substantial differences in algorithmic suitability among layers. To address this limitation, we propose CALM (A CKA-guided Adaptive Layer-wise Modularization)a fine-tuning-free, plug-and-play framework for algorithmic heterogeneous quantization. CALM independently evaluates multiple PTQ algorithms on each layer and employs Linear Centered Kernel Alignment (CKA) as a metric to automatically select the optimal quantization strategy per layer. The individually optimized strategies are then integrated to construct a hybrid quantized model. Experiments demonstrate that our approach consistently outperforms both uniform quantization baselines and state-of-the-art mixed-precision methods across mainstream LLMsincluding LLaMA and Qwenin terms of perplexity (PPL) and downstream task performance.","authors":["Jinhao Zhang","Yunquan Zhang","Daning Chen"," JunSun","Zicheng Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05101v1","updated":"2026-01-08T16:47:09Z","published":"2026-01-08T16:47:09Z","title":"Arabic Prompts with English Tools: A Benchmark","summary":"Large Language Models (LLMs) are now integral to numerous industries, increasingly serving as the core reasoning engine for autonomous agents that perform complex tasks through tool-use. While the development of Arabic-native LLMs is accelerating, the benchmarks for evaluating their capabilities lag behind, with most existing frameworks focusing on English. A critical and overlooked area is tool-calling, where the performance of models prompted in non-English languages like Arabic is poorly understood, especially since these models are often pretrained on predominantly English data. This paper addresses this critical gap by introducing the first dedicated benchmark for evaluating the tool-calling and agentic capabilities of LLMs in the Arabic language. Our work provides a standardized framework to measure the functional accuracy and robustness of models in Arabic agentic workflows. Our findings reveal a huge performance gap: when users interact in Arabic, tool-calling accuracy drops by an average of 5-10\\%, regardless of whether the tool descriptions themselves are in Arabic or English. By shedding light on these critical challenges, this benchmark aims to foster the development of more reliable and linguistically equitable AI agents for Arabic-speaking users.","authors":["Konstantin Kubrak","Ahmed El-Moselhy","Ammar Alsulami","Remaz Altuwaim","Hassan Ismail Fawaz","Faisal Alsaby"],"pdf_url":"","comment":"10 pages, 10 figures, LLMs, Big Data, and Multilinguality for All (LLMs4All) Workshop at IEEE BigData 2025 Conference, Macau, December 10, 2025"},{"id":"http://arxiv.org/abs/2507.21928v4","updated":"2026-01-08T16:44:45Z","published":"2025-07-29T15:44:55Z","title":"Vibe Coding as a Reconfiguration of Intent Mediation in Software Development: Definition, Implications, and Research Agenda","summary":"Software development is undergoing a fundamental transformation as vibe coding becomes widespread, with large portions of contemporary codebases now being generated by Artificial Intelligence (AI). The disconnect between rapid adoption and limited conceptual understanding highlights the need for an inquiry into this emerging paradigm. Drawing on an intent perspective and historical analysis, we define vibe coding as a software development paradigm where humans and Generative AI (GenAI) engage in collaborative flow to co-create software artifacts through natural language dialogue, shifting the mediation of developer intent from deterministic instruction to probabilistic inference. By intent mediation, we refer to the fundamental process through which developers translate their conceptual goals into representations that computational systems can execute. Our results show that vibe coding redistributes epistemic labor between humans and machines, shifting expertise from technical implementation toward collaborative orchestration. We identify key opportunities, including democratization, acceleration, and systemic leverage, alongside risks such as black-box codebases, responsibility gaps, and ecosystem bias. We conclude with a research agenda spanning human-, technology-, and organization-centered directions to guide future investigations of this paradigm.","authors":["Christian Meske","Tobias Hermanns","Esther von der Weiden","Kai-Uwe Loser","Thorsten Berger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05091v1","updated":"2026-01-08T16:39:26Z","published":"2026-01-08T16:39:26Z","title":"Code-Mix Sentiment Analysis on Hinglish Tweets","summary":"The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.","authors":["Aashi Garg","Aneshya Das","Arshi Arya","Anushka Goyal"," Aditi"],"pdf_url":"","comment":"Accepted at the 9th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2025), Fukuoka, Japan"},{"id":"http://arxiv.org/abs/2506.15480v2","updated":"2026-01-08T16:32:25Z","published":"2025-06-18T14:13:56Z","title":"Instruction Tuning with and without Context: Behavioral Shifts and Downstream Impact","summary":"Instruction tuning is a widely used approach to improve the instruction-following ability of large language models (LLMs). Instruction-tuning datasets typically include a mixture of context-augmented and context-free examples, yet prior work has largely combined these data types without examining their distinct effects. In this paper, we investigate how training LLMs with or without context affects model behavior and downstream performance. First, in the text domain, we show that LLMs trained with context attend more strongly to the provided knowledge, achieving better grounding. We also observe that context-augmented training shifts how LLMs use knowledge: models store and leverage less on parametric knowledge and instead depend more on the provided context. Second, we observe that using LLM trained with context-augmented data as the backbone for vision-language models reduces hallucination and improves grounding in the visual domain. Finally, we explore practical strategies for real-world deployments where context availability varies. We show that maintaining separate context-augmented and context-free models and routing inputs between them yields more robust overall performance than training a single mixed model, as it better preserves their complementary strengths.","authors":["Hyunji Lee","Seunghyun Yoon","Yunjae Won","Hanseok Oh","Geewook Kim","Trung Bui","Franck Dernoncourt","Elias Stengel-Eskin","Mohit Bansal","Minjoon Seo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05084v1","updated":"2026-01-08T16:29:08Z","published":"2026-01-08T16:29:08Z","title":"Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication","summary":"Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.","authors":["Niloufar Alavi","Swati Shah","Rezvan Alamian","Stefan Goetz"],"pdf_url":"","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.05083v1","updated":"2026-01-08T16:28:24Z","published":"2026-01-08T16:28:24Z","title":"Driving on Registers","summary":"We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.","authors":["Ellington Kirby","Alexandre Boulch","Yihong Xu","Yuan Yin","Gilles Puy","Éloi Zablocki","Andrei Bursuc","Spyros Gidaris","Renaud Marlet","Florent Bartoccioni","Anh-Quan Cao","Nermin Samet","Tuan-Hung VU","Matthieu Cord"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05076v1","updated":"2026-01-08T16:19:43Z","published":"2026-01-08T16:19:43Z","title":"Chain-of-Sanitized-Thoughts: Plugging PII Leakage in CoT of Large Reasoning Models","summary":"Large Reasoning Models (LRMs) improve performance, reliability, and interpretability by generating explicit chain-of-thought (CoT) reasoning, but this transparency introduces a serious privacy risk: intermediate reasoning often leaks personally identifiable information (PII) even when final answers are sanitized. We study how to induce privacy-first reasoning, where models reason without exposing sensitive information, using deployable interventions rather than post-hoc redaction. We introduce PII-CoT-Bench, a supervised dataset with privacy-aware CoT annotations, and a category-balanced evaluation benchmark covering realistic and adversarial leakage scenarios. Our results reveal a capability-dependent trend: state-of-the-art models benefit most from prompt-based controls, whereas weaker models require fine-tuning to achieve meaningful leakage reduction. Across models and categories, both approaches substantially reduce PII exposure with minimal degradation in utility, demonstrating that private reasoning can be achieved without sacrificing performance. Overall, we show that private CoT reasoning can be achieved with minimal utility loss, providing practical guidance for building privacy-preserving reasoning systems.","authors":["Arghyadeep Das","Sai Sreenivas Chintha","Rishiraj Girmal","Kinjal Pandey","Sharvi Endait"],"pdf_url":"","comment":"12 pages, 6 figures, 1 table"},{"id":"http://arxiv.org/abs/2510.17722v2","updated":"2026-01-08T16:16:20Z","published":"2025-10-20T16:38:40Z","title":"MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues","summary":"The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AI's ability to understand visual modalities. However, existing evaluation benchmarks remain limited to single-turn question answering, overlooking the complexity of multi-turn dialogues in real-world scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video understanding benchmark for evaluating MLLMs in multi-turn dialogues. Specifically, our MT-Video-Bench mainly assesses 6 core competencies that focus on perceptivity and interactivity, encompassing 1,000 meticulously curated multi-turn dialogues from diverse domains. These capabilities are rigorously aligned with real-world applications, such as interactive sports analysis and multi-turn video-based intelligent tutoring. With MT-Video-Bench, we extensively evaluate various state-of-the-art open-source and closed-source MLLMs, revealing their significant performance discrepancies and limitations in handling multi-turn video dialogues. The benchmark will be publicly available to foster future research.","authors":["Yaning Pan","Qianqian Xie","Guohui Zhang","Zekun Wang","Yongqian Wen","Yuanxing Zhang","Haoxuan Hu","Zhiyu Pan","Yibing Huang","Zhidong Gan","Yonghong Lin","An Ping","Shihao Li","Yanghai Wang","Tianhao Peng","Jiaheng Liu"],"pdf_url":"","comment":"Project Website: https://github.com/NJU-LINK/MT-Video-Bench"},{"id":"http://arxiv.org/abs/2601.05062v1","updated":"2026-01-08T16:08:44Z","published":"2026-01-08T16:08:44Z","title":"Compositional Steering of Large Language Models with Steering Tokens","summary":"Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.","authors":["Gorjan Radevski","Kiril Gashteovski","Giwon Hong","Carolin Lawrence","Goran Glavaš"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03327v2","updated":"2026-01-08T16:01:17Z","published":"2026-01-06T15:46:56Z","title":"Extreme-value forest fire prediction A study of the Loss Function in an Ordinality Scheme","summary":"Wildfires are highly imbalanced natural hazards in both space and severity, making the prediction of extreme events particularly challenging. In this work, we introduce the first ordinal classification framework for forecasting wildfire severity levels directly aligned with operational decision-making in France. Our study investigates the influence of loss-function design on the ability of neural models to predict rare yet critical high-severity fire occurrences. We compare standard cross-entropy with several ordinal-aware objectives, including the proposed probabilistic TDeGPD loss derived from a truncated discrete exponentiated Generalized Pareto Distribution. Through extensive benchmarking over multiple architectures and real operational data, we show that ordinal supervision substantially improves model performance over conventional approaches. In particular, the Weighted Kappa Loss (WKLoss) achieves the best overall results, with more than +0.1 IoU (Intersection Over Union) gain on the most extreme severity classes while maintaining competitive calibration quality. However, performance remains limited for the rarest events due to their extremely low representation in the dataset. These findings highlight the importance of integrating both severity ordering, data imbalance considerations, and seasonality risk into wildfire forecasting systems. Future work will focus on incorporating seasonal dynamics and uncertainty information into training to further improve the reliability of extreme-event prediction.","authors":["Nicolas Caron","Christophe Guyeux","Hassan Noura","Benjamin Aynes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05053v1","updated":"2026-01-08T15:56:44Z","published":"2026-01-08T15:56:44Z","title":"Reinforced Efficient Reasoning via Semantically Diverse Exploration","summary":"Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.","authors":["Ziqi Zhao","Zhaochun Ren","Jiahong Zou","Liu Yang","Zhiwei Xu","Xuri Ge","Zhumin Chen","Xinyu Ma","Daiting Shi","Shuaiqiang Wang","Dawei Yin","Xin Xin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05051v1","updated":"2026-01-08T15:56:17Z","published":"2026-01-08T15:56:17Z","title":"Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence","summary":"Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.","authors":["Jennifer D'Souza","Soren Auer","Eleni Poupaki","Alex Watkins","Anjana Devi","Riikka L. Puurunen","Bora Karasulu","Adrie Mackus","Erwin Kessels"],"pdf_url":"","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2601.05050v1","updated":"2026-01-08T15:56:05Z","published":"2026-01-08T15:56:05Z","title":"Large language models can effectively convince people to believe conspiracies","summary":"Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against (\"debunking\") or for (\"bunking\") that conspiracy. When using a \"jailbroken\" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.","authors":["Thomas H. Costello","Kellin Pelrine","Matthew Kowal","Antonio A. Arechar","Jean-François Godbout","Adam Gleave","David Rand","Gordon Pennycook"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05049v1","updated":"2026-01-08T15:55:13Z","published":"2026-01-08T15:55:13Z","title":"How to Set the Learning Rate for Large-Scale Pre-training?","summary":"Optimal configuration of the learning rate (LR) is a fundamental yet formidable challenge in large-scale pre-training. Given the stringent trade-off between training costs and model performance, the pivotal question is whether the optimal LR can be accurately extrapolated from low-cost experiments. In this paper, we formalize this investigation into two distinct research paradigms: Fitting and Transfer. Within the Fitting Paradigm, we innovatively introduce a Scaling Law for search factor, effectively reducing the search complexity from O(n^3) to O(n*C_D*C_η) via predictive modeling. Within the Transfer Paradigm, we extend the principles of $μ$Transfer to the Mixture of Experts (MoE) architecture, broadening its applicability to encompass model depth, weight decay, and token horizons. By pushing the boundaries of existing hyperparameter research in terms of scale, we conduct a comprehensive comparison between these two paradigms. Our empirical results challenge the scalability of the widely adopted $μ$ Transfer in large-scale pre-training scenarios. Furthermore, we provide a rigorous analysis through the dual lenses of training stability and feature learning to elucidate the underlying reasons why module-wise parameter tuning underperforms in large-scale settings. This work offers systematic practical guidelines and a fresh theoretical perspective for optimizing industrial-level pre-training.","authors":["Yunhua Zhou","Shuhao Xing","Junhao Huang","Xipeng Qiu","Qipeng Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05047v1","updated":"2026-01-08T15:52:11Z","published":"2026-01-08T15:52:11Z","title":"Challenges and Research Directions for Large Language Model Inference Hardware","summary":"Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.","authors":["Xiaoyu Ma","David Patterson"],"pdf_url":"","comment":"Accepted for publication by IEEE Computer, 2026"},{"id":"http://arxiv.org/abs/2412.17189v4","updated":"2026-01-08T15:45:17Z","published":"2024-12-22T23:31:03Z","title":"Talking with Tables for Better LLM Factual Data Interactions","summary":"Large Language Models (LLMs) often struggle with requests related to information retrieval and data manipulation that frequently arise in real-world scenarios under multiple conditions. In this paper, we demonstrate that leveraging tabular structures in LLM interactions, is more effective than utilizing other structures for handling prevalent requests that operate over factual data. Through comprehensive evaluations across various scenarios and request types, we show that providing tabular structures yields a 40.29\\% average performance gain along with better robustness and token efficiency. Through attention-value analysis, we discover that tables help LLMs better locate relevant information, explaining these improvements. Beyond tables and text, we evaluate whether (1) blending structuredness within text, such as providing templates or fixing the order of attributes, and (2) other representative structures, such as knowledge graphs and JSON are helpful. We observe that utilizing tables offers the best balance between efficiency and effectiveness. The method remains robust to task complexity and adapts to unstructured sources through text-to-table conversion. Overall, we highlight the untapped potential of tabular representations for future LLM applications.","authors":["Jio Oh","Geon Heo","Seungjun Oh","Hyunjin Kim","JinYeong Bak","Jindong Wang","Xing Xie","Steven Euijong Whang"],"pdf_url":"","comment":"20 pages, 9 figures"},{"id":"http://arxiv.org/abs/2601.05038v1","updated":"2026-01-08T15:44:52Z","published":"2026-01-08T15:44:52Z","title":"ArcAligner: Adaptive Recursive Aligner for Compressed Context Embeddings in RAG","summary":"Retrieval-Augmented Generation (RAG) helps LLMs stay accurate, but feeding long documents into a prompt makes the model slow and expensive. This has motivated context compression, ranging from token pruning and summarization to embedding-based compression. While researchers have tried ''compressing'' these documents into smaller summaries or mathematical embeddings, there is a catch: the more you compress the data, the more the LLM struggles to understand it. To address this challenge, we propose ArcAligner (Adaptive recursive context *Aligner*), a lightweight module integrated into the language model layers to help the model better utilize highly compressed context representations for downstream generation. It uses an adaptive ''gating'' system that only adds extra processing power when the information is complex, keeping the system fast. Across knowledge-intensive QA benchmarks, ArcAligner consistently beats compression baselines at comparable compression rates, especially on multi-hop and long-tail settings. The source code is publicly available.","authors":["Jianbo Li","Yi Jiang","Sendong Zhao","Bairui Hu","Haochun Wang","Bing Qin"],"pdf_url":"","comment":"Code is available at https://github.com/liunian-Jay/ArcAligner.git"},{"id":"http://arxiv.org/abs/2601.05036v1","updated":"2026-01-08T15:44:41Z","published":"2026-01-08T15:44:41Z","title":"Exponential capacity scaling of classical GANs compared to hybrid latent style-based quantum GANs","summary":"Quantum generative modeling is a very active area of research in looking for practical advantage in data analysis. Quantum generative adversarial networks (QGANs) are leading candidates for quantum generative modeling and have been applied to diverse areas, from high-energy physics to image generation. The latent style-based QGAN, relying on a classical variational autoencoder to encode the input data into a latent space and then using a style-based QGAN for data generation has been proven to be efficient for image generation or drug design, hinting at the use of far less trainable parameters than their classical counterpart to achieve comparable performance, however this advantage has never been systematically studied. We present in this work the first comprehensive experimental analysis of this advantage of QGANS applied to SAT4 image generation, obtaining an exponential advantage in capacity scaling for a quantum generator in the hybrid latent style-based QGAN architecture. Careful tuning of the autoencoder is crucial to obtain stable, reliable results. Once this tuning is performed and defining training optimality as when the training is stable and the FID score is low and stable as well, the optimal capacity (or number of trainable parameters) of the classical discriminator scales exponentially with respect to the capacity of the quantum generator, and the same is true for the capacity of the classical generator. This hints toward a type of quantum advantage for quantum generative modeling.","authors":["Milan Liepelt","Julien Baglio"],"pdf_url":"","comment":"34 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2504.16680v3","updated":"2026-01-08T15:43:41Z","published":"2025-04-23T12:58:15Z","title":"Uncertainty-Aware Robotic World Model Makes Offline Model-Based Reinforcement Learning Work on Real Robots","summary":"Reinforcement Learning (RL) has achieved impressive results in robotics, yet high-performing pipelines remain highly task-specific, with little reuse of prior data. Offline Model-based RL (MBRL) offers greater data efficiency by training policies entirely from existing datasets, but suffers from compounding errors and distribution shift in long-horizon rollouts. Although existing methods have shown success in controlled simulation benchmarks, robustly applying them to the noisy, biased, and partially observed datasets typical of real-world robotics remains challenging. We present a principled pipeline for making offline MBRL effective on physical robots. Our RWM-U extends autoregressive world models with epistemic uncertainty estimation, enabling temporally consistent multi-step rollouts with uncertainty effectively propagated over long horizons. We combine RWM-U with MOPO-PPO, which adapts uncertainty-penalized policy optimization to the stable, on-policy PPO framework for real-world control. We evaluate our approach on diverse manipulation and locomotion tasks in simulation and on real quadruped and humanoid, training policies entirely from offline datasets. The resulting policies consistently outperform model-free and uncertainty-unaware model-based baselines, and fusing real-world data in model learning further yields robust policies that surpass online model-free baselines trained solely in simulation.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05034v1","updated":"2026-01-08T15:43:31Z","published":"2026-01-08T15:43:31Z","title":"How to Set the Batch Size for Large-Scale Pre-training?","summary":"The concept of Critical Batch Size, as pioneered by OpenAI, has long served as a foundational principle for large-scale pre-training. However, with the paradigm shift towards the Warmup-Stable-Decay (WSD) learning rate scheduler, we observe that the original theoretical framework and its underlying mechanisms fail to align with new pre-training dynamics. To bridge this gap between theory and practice, this paper derives a revised E(S) relationship tailored for WSD scheduler, characterizing the trade-off between training data consumption E and steps S during pre-training. Our theoretical analysis reveals two fundamental properties of WSD-based pre-training: 1) B_min, the minimum batch size threshold required to achieve a target loss, and 2) B_opt, the optimal batch size that maximizes data efficiency by minimizing total tokens. Building upon these properties, we propose a dynamic Batch Size Scheduler. Extensive experiments demonstrate that our revised formula precisely captures the dynamics of large-scale pre-training, and the resulting scheduling strategy significantly enhances both training efficiency and final model quality.","authors":["Yunhua Zhou","Junhao Huang","Shuhao Xin","Yechen Zhang","Runyu Peng","Qiping Guo","Xipeng Qiu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05027v1","updated":"2026-01-08T15:35:01Z","published":"2026-01-08T15:35:01Z","title":"OptiSet: Unified Optimizing Set Selection and Ranking for Retrieval-Augmented Generation","summary":"Retrieval-Augmented Generation (RAG) improves generation quality by incorporating evidence retrieved from large external corpora. However, most existing methods rely on statically selecting top-k passages based on individual relevance, which fails to exploit combinatorial gains among passages and often introduces substantial redundancy. To address this limitation, we propose OptiSet, a set-centric framework that unifies set selection and set-level ranking for RAG. OptiSet adopts an \"Expand-then-Refine\" paradigm: it first expands a query into multiple perspectives to enable a diverse candidate pool and then refines the candidate pool via re-selection to form a compact evidence set. We then devise a self-synthesis strategy without strong LLM supervision to derive preference labels from the set conditional utility changes of the generator, thereby identifying complementary and redundant evidence. Finally, we introduce a set-list wise training strategy that jointly optimizes set selection and set-level ranking, enabling the model to favor compact, high-gain evidence sets. Extensive experiments demonstrate that OptiSet improves performance on complex combinatorial problems and makes generation more efficient. The source code is publicly available.","authors":["Yi Jiang","Sendong Zhao","Jianbo Li","Bairui Hu","Yanrui Du","Haochun Wang","Bing Qin"],"pdf_url":"","comment":"Code is available at https://github.com/liunian-Jay/OptiSet.git"},{"id":"http://arxiv.org/abs/2601.05019v1","updated":"2026-01-08T15:27:03Z","published":"2026-01-08T15:27:03Z","title":"Hán Dān Xué Bù (Mimicry) or Qīng Chū Yú Lán (Mastery)? A Cognitive Perspective on Reasoning Distillation in Large Language Models","summary":"Recent Large Reasoning Models trained via reinforcement learning exhibit a \"natural\" alignment with human cognitive costs. However, we show that the prevailing paradigm of reasoning distillation -- training student models to mimic these traces via Supervised Fine-Tuning (SFT) -- fails to transmit this cognitive structure. Testing the \"Hán Dān Xué Bù\" (Superficial Mimicry) hypothesis across 14 models, we find that distillation induces a \"Functional Alignment Collapse\": while teacher models mirror human difficulty scaling ($\\bar{r}=0.64$), distilled students significantly degrade this alignment ($\\bar{r}=0.34$), often underperforming their own pre-distillation baselines (\"Negative Transfer\"). Our analysis suggests that SFT induces a \"Cargo Cult\" effect, where students ritualistically replicate the linguistic form of reasoning (verbosity) without internalizing the teacher's dynamic resource allocation policy. Consequently, reasoning distillation decouples computational cost from cognitive demand, revealing that human-like cognition is an emergent property of active reinforcement, not passive imitation.","authors":["Yueqing Hu","Xinyang Peng","Shuting Peng","Hanqi Wang","Tianhong Wang"],"pdf_url":"","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.05017v1","updated":"2026-01-08T15:18:36Z","published":"2026-01-08T15:18:36Z","title":"HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference","summary":"Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.","authors":["Xiaopeng Luo","Zexi Tan","Zhuowei Wang"],"pdf_url":"","comment":"Submitted to ICASSP 2026"},{"id":"http://arxiv.org/abs/2601.05016v1","updated":"2026-01-08T15:18:12Z","published":"2026-01-08T15:18:12Z","title":"From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling","summary":"We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.","authors":["Jin Gao","Saichandu Juluri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05009v1","updated":"2026-01-08T15:10:32Z","published":"2026-01-08T15:10:32Z","title":"An Empirical Investigation of Robustness in Large Language Models under Tabular Distortions","summary":"We investigate how large language models (LLMs) fail when tabular data in an otherwise canonical representation is subjected to semantic and structural distortions. Our findings reveal that LLMs lack an inherent ability to detect and correct subtle distortions in table representations. Only when provided with an explicit prior, via a system prompt, do models partially adjust their reasoning strategies and correct some distortions, though not consistently or completely. To study this phenomenon, we introduce a small, expert-curated dataset that explicitly evaluates LLMs on table question answering (TQA) tasks requiring an additional error-correction step prior to analysis. Our results reveal systematic differences in how LLMs ingest and interpret tabular information under distortion, with even SoTA models such as GPT-5.2 model exhibiting a drop of minimum 22% accuracy under distortion. These findings raise important questions for future research, particularly regarding when and how models should autonomously decide to realign tabular inputs, analogous to human behavior, without relying on explicit prompts or tabular data pre-processing.","authors":["Avik Dutta","Harshit Nigam","Hosein Hasanbeig","Arjun Radhakrishna","Sumit Gulwani"],"pdf_url":"","comment":"4 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2511.13368v2","updated":"2026-01-08T15:10:27Z","published":"2025-11-17T13:41:31Z","title":"Donors and Recipients: On Asymmetric Transfer Across Tasks and Languages with Parameter-Efficient Fine-Tuning","summary":"Large language models (LLMs) perform strongly across tasks and languages, yet how improvements in one task or language affect other tasks and languages remains poorly understood. We conduct a controlled LoRA fine-tuning study across multiple open-weight LLM families and scales, using a standardised grid of 11 languages and four benchmarks. We fine-tune each model on a single task-language source and measure transfer when evaluated on all other task-language target pairs. We decompose transfer into three regimes: (i) Matched-Task (Cross-Language), (ii) Matched-Language (Cross-Task), and (iii) Cross-Task (Cross-Language). Single-source fine-tuning yields a net positive uplift across regimes, but the gains are strongly asymmetric. Matched-Task (Cross-Language) transfer emerges as the most effective and predictable regime, driven principally by the identity of the target language rather than model architecture. We identify a stable hierarchy where high-resource languages and broad semantic tasks act as efficient recipients that absorb gains from diverse sources, while specialised tasks and lower-resource languages are more isolated. These results imply that effective fine-tuning requires navigating donor-recipient roles to maximise downstream gains.","authors":["Kajetan Dymkiewicz","Ivan Vulic","Helen Yannakoudakis","Eilam Shapira","Roi Reichart","Anna Korhonen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05002v1","updated":"2026-01-08T15:00:35Z","published":"2026-01-08T15:00:35Z","title":"On the Hidden Objective Biases of Group-based Reinforcement Learning","summary":"Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.","authors":["Aleksandar Fontana","Marco Simoni","Giulio Rossolini","Andrea Saracino","Paolo Mori"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.10424v2","updated":"2026-01-08T14:58:52Z","published":"2024-02-16T03:20:14Z","title":"Pelican Soup Framework: A Theoretical Framework for Language Model Capabilities","summary":"In this work, we propose a simple theoretical framework, Pelican Soup, aiming to better understand how pretraining allows LLMs to (1) generalize to unseen instructions and (2) perform in-context learning, even when the verbalizers are irrelevant to the task. To this end, in our framework, we introduce the notion of \"knowledge base\" and \"reference-sense association\" and a simple formalism for natural language processing tasks. Our framework demonstrates how linguistic, psychology, and philosophy studies can inform our understanding of the language model and is connected to several other existing theoretical results. As an illustration of the usage of our framework, we derive a bound on in-context learning loss with our framework. Finally, we support our framework with empirical experiments and provide possible future research directions.","authors":["Ting-Rui Chiang","Dani Yogatama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04996v1","updated":"2026-01-08T14:54:44Z","published":"2026-01-08T14:54:44Z","title":"AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms?","summary":"Reasoning ability has become a central focus in the advancement of Large Reasoning Models (LRMs). Although notable progress has been achieved on several reasoning benchmarks such as MATH500 and LiveCodeBench, existing benchmarks for algorithmic reasoning remain limited, failing to answer a critical question: Do LRMs truly master algorithmic reasoning? To answer this question, we propose AlgBench, an expert-curated benchmark that evaluates LRMs under an algorithm-centric paradigm.\n  AlgBench consists of over 3,000 original problems spanning 27 algorithms, constructed by ACM algorithmic experts and organized under a comprehensive taxonomy, including Euclidean-structured, non-Euclidean-structured, non-optimized, local-optimized, global-optimized, and heuristic-optimized categories. Empirical evaluations on leading LRMs (e.g., Gemini-3-Pro, DeepSeek-v3.2-Speciale and GPT-o3) reveal substantial performance heterogeneity: while models perform well on non-optimized tasks (up to 92%), accuracy drops sharply to around 49% on globally optimized algorithms such as dynamic programming. Further analysis uncovers \\textbf{strategic over-shifts}, wherein models prematurely abandon correct algorithmic designs due to necessary low-entropy tokens. These findings expose fundamental limitations of problem-centric reinforcement learning and highlight the necessity of an algorithm-centric training paradigm for robust algorithmic reasoning.","authors":["Henan Sun","Kaichi Yu","Yuyao Wang","Bowen Liu","Xunkai Li","Rong-Hua Li","Nuo Chen","Jia Li"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2601.04982v1","updated":"2026-01-08T14:35:17Z","published":"2026-01-08T14:35:17Z","title":"When to Act: Calibrated Confidence for Reliable Human Intention Prediction in Assistive Robotics","summary":"Assistive devices must determine both what a user intends to do and how reliable that prediction is before providing support. We introduce a safety-critical triggering framework based on calibrated probabilities for multimodal next-action prediction in Activities of Daily Living. Raw model confidence often fails to reflect true correctness, posing a safety risk. Post-hoc calibration aligns predicted confidence with empirical reliability and reduces miscalibration by about an order of magnitude without affecting accuracy. The calibrated confidence drives a simple ACT/HOLD rule that acts only when reliability is high and withholds assistance otherwise. This turns the confidence threshold into a quantitative safety parameter for assisted actions and enables verifiable behavior in an assistive control loop.","authors":["Johannes A. Gaus","Winfried Ilg","Daniel Haeufle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.14361v2","updated":"2026-01-08T14:35:09Z","published":"2025-11-18T11:07:31Z","title":"Clinically-Validated Innovative Mobile Application for Assessing Blinking and Eyelid Movements","summary":"Blinking is a vital physiological process that protects and maintains the health of the ocular surface. Objective assessment of eyelid movements remains challenging due to the complexity, cost, and limited clinical applicability of existing tools. This study presents the Bapp (Blink Application), a mobile application developed using the Flutter framework and integrated with Google ML Kit for on-device, real-time analysis of eyelid movements, and its clinical validation. The validation was performed using 45 videos from patients, whose blinks were manually annotated by an ophthalmology specialist as the ground truth. The Bapp's performance was evaluated using standard metrics, with results demonstrating 98.4% precision, 96.9% recall, and an overall accuracy of 98.3%. These outcomes confirm the reliability of the Bapp as a portable, accessible, and objective tool for monitoring eyelid movements. The application offers a promising alternative to traditional manual blink counting, supporting continuous ocular health monitoring and postoperative evaluation in clinical environments.","authors":["Gustavo Adolpho Bonesso","Carlos Marcelo Gurjão de Godoy","Tammy Hentona Osaki","Midori Hentona Osaki","Bárbara Moreira Ribeiro Trindade dos Santos","Juliana Yuka Washiya","Regina Célia Coelho"],"pdf_url":"","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2502.18770v4","updated":"2026-01-08T14:33:47Z","published":"2025-02-26T02:57:59Z","title":"Reward Shaping to Mitigate Reward Hacking in RLHF","summary":"Reinforcement Learning from Human Feedback (RLHF) is essential for aligning large language models (LLMs) with human values. However, RLHF is susceptible to \\emph{reward hacking}, where the agent exploits flaws in the reward function rather than learning the intended behavior, thus degrading alignment. Although reward shaping helps stabilize RLHF and partially mitigate reward hacking, a systematic investigation into shaping techniques and their underlying principles remains lacking. To bridge this gap, we present a comprehensive study of the prevalent reward shaping methods. Our analysis suggests two key design principles: (1) the RL reward should be bounded, and (2) the RL reward benefits from rapid initial growth followed by gradual convergence. Guided by these insights, we propose Preference As Reward (PAR), a novel approach that leverages the latent preferences embedded within the reward model as the signal for reinforcement learning. Moreover, PAR exhibits two critical variance-reduction properties that contribute to stabilizing the RLHF training process and effectively extending the tolerance window for early stopping. We evaluated PAR on the base model Gemma2-2B using two datasets, Ultrafeedback-Binarized and HH-RLHF. Experimental results demonstrate PAR's superior performance over other reward shaping methods. On the AlpacaEval 2.0 benchmark, PAR achieves a win rate of at least 5 percentage points higher than competing approaches. Furthermore, PAR exhibits remarkable data efficiency, requiring only a single reference reward for optimal performance, and maintains robustness against reward hacking even after two full epochs of training. The code is available at https://github.com/PorUna-byte/PAR.","authors":["Jiayi Fu","Xuandong Zhao","Chengyuan Yao","Heng Wang","Qi Han","Yanghua Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04977v1","updated":"2026-01-08T14:29:24Z","published":"2026-01-08T14:29:24Z","title":"On the Definition and Detection of Cherry-Picking in Counterfactual Explanations","summary":"Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.","authors":["James Hinns","Sofie Goethals","Stephan Van der Veeken","Theodoros Evgeniou","David Martens"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04973v1","updated":"2026-01-08T14:22:58Z","published":"2026-01-08T14:22:58Z","title":"ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning","summary":"Recent breakthroughs in Large Reasoning Models (LRMs) have demonstrated that extensive Chain-of-Thought (CoT) generation is critical for enabling intricate cognitive behaviors, such as self-verification and backtracking, to solve complex tasks. However, this capability often leads to ``overthinking'', where models generate redundant reasoning paths that inflate computational costs without improving accuracy. While Supervised Fine-Tuning (SFT) on reasoning traces is a standard paradigm for the 'cold start' phase, applying existing compression techniques to these traces often compromises logical coherence or incurs prohibitive sampling costs. In this paper, we introduce ConMax (Confidence-Maximizing Compression), a novel reinforcement learning framework designed to automatically compress reasoning traces while preserving essential reasoning patterns. ConMax formulates compression as a reward-driven optimization problem, training a policy to prune redundancy by maximizing a weighted combination of answer confidence for predictive fidelity and thinking confidence for reasoning validity through a frozen auxiliary LRM. Extensive experiments across five reasoning datasets demonstrate that ConMax achieves a superior efficiency-performance trade-off. Specifically, it reduces inference length by 43% over strong baselines at the cost of a mere 0.7% dip in accuracy, proving its effectiveness in generating high-quality, efficient training data for LRMs.","authors":["Minda Hu","Zexuan Qiu","Zenan Xu","Kun Li","Bo Zhou","Irwin King"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24957v2","updated":"2026-01-08T14:15:25Z","published":"2025-12-31T16:39:09Z","title":"AMAP Agentic Planning Technical Report","summary":"We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries by retaining less than 1\\% of the raw data, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.","authors":[" AMAP AI Agent Team","Yulan Hu","Xiangwen Zhang","Sheng Ouyang","Hao Yi","Lu Xu","Qinglin Lang","Lide Tan","Xiang Cheng","Tianchen Ye","Zhicong Li","Ge Chen","Wenjin Yang","Zheng Pan","Shaopan Xiong","Siran Yang","Ju Huang","Yan Zhang","Jiamang Wang","Yong Liu","Yinfeng Huang","Ning Wang","Tucheng Lin","Xin Li","Ning Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04963v1","updated":"2026-01-08T14:09:17Z","published":"2026-01-08T14:09:17Z","title":"Text as a Universal Interface for Transferable Personalization","summary":"We study the problem of personalization in large language models (LLMs). Prior work predominantly represents user preferences as implicit, model-specific vectors or parameters, yielding opaque ``black-box'' profiles that are difficult to interpret and transfer across models and tasks. In contrast, we advocate natural language as a universal, model- and task-agnostic interface for preference representation. The formulation leads to interpretable and reusable preference descriptions, while naturally supporting continual evolution as new interactions are observed. To learn such representations, we introduce a two-stage training framework that combines supervised fine-tuning on high-quality synthesized data with reinforcement learning to optimize long-term utility and cross-task transferability. Based on this framework, we develop AlignXplore+, a universal preference reasoning model that generates textual preference summaries. Experiments on nine benchmarks show that our 8B model achieves state-of-the-art performanc -- outperforming substantially larger open-source models -- while exhibiting strong transferability across tasks, model families, and interaction formats.","authors":["Yuting Liu","Jian Guan","Jia-Nan Li","Wei Wu","Jiang-Ming Yang","Jianzhe Zhao","Guibing Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04954v1","updated":"2026-01-08T14:00:51Z","published":"2026-01-08T14:00:51Z","title":"Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following","summary":"A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.","authors":["Yirong Zeng","Yufei Liu","Xiao Ding","Yutai Hou","Yuxian Wang","Haonan Song","Wu Ning","Dandan Tu","Qixun Zhang","Bibo Cai","Yuxiang He","Ting Liu"],"pdf_url":"","comment":"ACL under review 13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2601.01802v3","updated":"2026-01-08T13:52:50Z","published":"2026-01-05T05:26:57Z","title":"PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism AI Psychological Counselor","summary":"To develop a reliable AI for psychological assessment, we introduce \\texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \\textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \\textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \\textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \\texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.","authors":["Qianjun Pan","Junyi Wang","Jie Zhou","Yutao Yang","Junsong Li","Kaiyin Xu","Yougen Zhou","Yihan Li","Jingyuan Zhao","Qin Chen","Ningning Zhou","Kai Chen","Liang He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04946v1","updated":"2026-01-08T13:49:14Z","published":"2026-01-08T13:49:14Z","title":"Prototypicality Bias Reveals Blindspots in Multimodal Evaluation Metrics","summary":"Automatic metrics are now central to evaluating text-to-image models, often substituting for human judgment in benchmarking and large-scale filtering. However, it remains unclear whether these metrics truly prioritize semantic correctness or instead favor visually and socially prototypical images learned from biased data distributions. We identify and study \\emph{prototypicality bias} as a systematic failure mode in multimodal evaluation. We introduce a controlled contrastive benchmark \\textsc{\\textbf{ProtoBias}} (\\textit{\\textbf{Proto}typical \\textbf{Bias}}), spanning Animals, Objects, and Demography images, where semantically correct but non-prototypical images are paired with subtly incorrect yet prototypical adversarial counterparts. This setup enables a directional evaluation of whether metrics follow textual semantics or default to prototypes. Our results show that widely used metrics, including CLIPScore, PickScore, and VQA-based scores, frequently misrank these pairs, while even LLM-as-Judge systems exhibit uneven robustness in socially grounded cases. Human evaluations consistently favour semantic correctness with larger decision margins. Motivated by these findings, we propose \\textbf{\\textsc{ProtoScore}}, a robust 7B-parameter metric that substantially reduces failure rates and suppresses misranking, while running at orders of magnitude faster than the inference time of GPT-5, approaching the robustness of much larger closed-source judges.","authors":["Subhadeep Roy","Gagan Bhatia","Steffen Eger"],"pdf_url":"","comment":"First version"},{"id":"http://arxiv.org/abs/2601.04945v1","updated":"2026-01-08T13:49:12Z","published":"2026-01-08T13:49:12Z","title":"T-Retriever: Tree-based Hierarchical Retrieval Augmented Generation for Textual Graphs","summary":"Retrieval-Augmented Generation (RAG) has significantly enhanced Large Language Models' ability to access external knowledge, yet current graph-based RAG approaches face two critical limitations in managing hierarchical information: they impose rigid layer-specific compression quotas that damage local graph structures, and they prioritize topological structure while neglecting semantic content. We introduce T-Retriever, a novel framework that reformulates attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree. Our approach features two key innovations: (1) Adaptive Compression Encoding, which replaces artificial compression quotas with a global optimization strategy that preserves the graph's natural hierarchical organization, and (2) Semantic-Structural Entropy ($S^2$-Entropy), which jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions. Experiments across diverse graph reasoning benchmarks demonstrate that T-Retriever significantly outperforms state-of-the-art RAG methods, providing more coherent and contextually relevant responses to complex queries.","authors":["Chunyu Wei","Huaiyu Qin","Siyuan He","Yunhai Wang","Yueguo Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04940v1","updated":"2026-01-08T13:43:15Z","published":"2026-01-08T13:43:15Z","title":"CurricuLLM: Designing Personalized and Workforce-Aligned Cybersecurity Curricula Using Fine-Tuned LLMs","summary":"The cybersecurity landscape is constantly evolving, driven by increased digitalization and new cybersecurity threats. Cybersecurity programs often fail to equip graduates with skills demanded by the workforce, particularly concerning recent developments in cybersecurity, as curriculum design is costly and labor-intensive. To address this misalignment, we present a novel Large Language Model (LLM)-based framework for automated design and analysis of cybersecurity curricula, called CurricuLLM. Our approach provides three key contributions: (1) automation of personalized curriculum design, (2) a data-driven pipeline aligned with industry demands, and (3) a comprehensive methodology for leveraging fine-tuned LLMs in curriculum development.\n  CurricuLLM utilizes a two-tier approach consisting of PreprocessLM, which standardizes input data, and ClassifyLM, which assigns course content to nine Knowledge Areas in cybersecurity. We systematically evaluated multiple Natural Language Processing (NLP) architectures and fine-tuning strategies, ultimately selecting the Bidirectional Encoder Representations from Transformers (BERT) model as ClassifyLM, fine-tuned on foundational cybersecurity concepts and workforce competencies.\n  We are the first to validate our method with human experts who analyzed real-world cybersecurity curricula and frameworks, motivating that CurricuLLM is an efficient solution to replace labor-intensive curriculum analysis. Moreover, once course content has been classified, it can be integrated with established cybersecurity role-based weights, enabling alignment of the educational program with specific job roles, workforce categories, or general market needs. This lays the foundation for personalized, workforce-aligned cybersecurity curricula that prepare students for the evolving demands in cybersecurity.","authors":["Arthur Nijdam","Harri Kähkönen","Valtteri Niemi","Paul Stankovski Wagner","Sara Ramezanian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.03919v2","updated":"2026-01-08T13:31:51Z","published":"2026-01-07T13:40:30Z","title":"A Gap Between Decision Trees and Neural Networks","summary":"We study when geometric simplicity of decision boundaries, used here as a notion of interpretability, can conflict with accurate approximation of axis-aligned decision trees by shallow neural networks. Decision trees induce rule-based, axis-aligned decision regions (finite unions of boxes), whereas shallow ReLU networks are typically trained as score models whose predictions are obtained by thresholding. We analyze the infinite-width, bounded-norm, single-hidden-layer ReLU class through the Radon total variation ($\\mathrm{R}\\mathrm{TV}$) seminorm, which controls the geometric complexity of level sets.\n  We first show that the hard tree indicator $1_A$ has infinite $\\mathrm{R}\\mathrm{TV}$. Moreover, two natural split-wise continuous surrogates--piecewise-linear ramp smoothing and sigmoidal (logistic) smoothing--also have infinite $\\mathrm{R}\\mathrm{TV}$ in dimensions $d>1$, while Gaussian convolution yields finite $\\mathrm{R}\\mathrm{TV}$ but with an explicit exponential dependence on $d$.\n  We then separate two goals that are often conflated: classification after thresholding (recovering the decision set) versus score learning (learning a calibrated score close to $1_A$). For classification, we construct a smooth barrier score $S_A$ with finite $\\mathrm{R}\\mathrm{TV}$ whose fixed threshold $τ=1$ exactly recovers the box. Under a mild tube-mass condition near $\\partial A$, we prove an $L_1(P)$ calibration bound that decays polynomially in a sharpness parameter, along with an explicit $\\mathrm{R}\\mathrm{TV}$ upper bound in terms of face measures. Experiments on synthetic unions of rectangles illustrate the resulting accuracy--complexity tradeoff and how threshold selection shifts where training lands along it.","authors":["Akash Kumar"],"pdf_url":"","comment":"45 pages, plots were improved"},{"id":"http://arxiv.org/abs/2506.06842v2","updated":"2026-01-08T13:25:34Z","published":"2025-06-07T15:46:02Z","title":"PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation","summary":"Disinformation detection is a key aspect of media literacy. Psychological studies have shown that knowledge of persuasive fallacies helps individuals detect disinformation. Inspired by these findings, we experimented with large language models (LLMs) to test whether infusing persuasion knowledge enhances disinformation detection. As a result, we introduce the Persuasion-Augmented Chain of Thought (PCoT), a novel approach that leverages persuasion to improve disinformation detection in zero-shot classification. We extensively evaluate PCoT on online news and social media posts. Moreover, we publish two novel, up-to-date disinformation datasets: EUDisinfo and MultiDis. These datasets enable the evaluation of PCoT on content entirely unseen by the LLMs used in our experiments, as the content was published after the models' knowledge cutoffs. We show that, on average, PCoT outperforms competitive methods by 15% across five LLMs and five datasets. These findings highlight the value of persuasion in strengthening zero-shot disinformation detection.","authors":["Arkadiusz Modzelewski","Witold Sosnowski","Tiziano Labruna","Adam Wierzbicki","Giovanni Da San Martino"],"pdf_url":"","comment":"Accepted to ACL 2025 Main Conference"},{"id":"http://arxiv.org/abs/2601.04920v1","updated":"2026-01-08T13:17:50Z","published":"2026-01-08T13:17:50Z","title":"Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition","summary":"Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.","authors":["Nils Einecke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04919v1","updated":"2026-01-08T13:17:44Z","published":"2026-01-08T13:17:44Z","title":"What Students Ask, How a Generative AI Assistant Responds: Exploring Higher Education Students' Dialogues on Learning Analytics Feedback","summary":"Learning analytics dashboards (LADs) aim to support students' regulation of learning by translating complex data into feedback. Yet students, especially those with lower self-regulated learning (SRL) competence, often struggle to engage with and interpret analytics feedback. Conversational generative artificial intelligence (GenAI) assistants have shown potential to scaffold this process through real-time, personalised, dialogue-based support. Further advancing this potential, we explored authentic dialogues between students and GenAI assistant integrated into LAD during a 10-week semester. The analysis focused on questions students with different SRL levels posed, the relevance and quality of the assistant's answers, and how students perceived the assistant's role in their learning. Findings revealed distinct query patterns. While low SRL students sought clarification and reassurance, high SRL students queried technical aspects and requested personalised strategies. The assistant provided clear and reliable explanations but limited in personalisation, handling emotionally charged queries, and integrating multiple data points for tailored responses. Findings further extend that GenAI interventions can be especially valuable for low SRL students, offering scaffolding that supports engagement with feedback and narrows gaps with their higher SRL peers. At the same time, students' reflections underscored the importance of trust, need for greater adaptivity, context-awareness, and technical refinement in future systems.","authors":["Yildiz Uzun","Andrea Gauthier","Mutlu Cukurova"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04918v1","updated":"2026-01-08T13:17:40Z","published":"2026-01-08T13:17:40Z","title":"Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective","summary":"With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.","authors":["Ziwen Wang","Shangshang Yang","Xiaoshan Yu","Haiping Ma","Xingyi Zhang"],"pdf_url":"","comment":"KDD2026, 15 pages"},{"id":"http://arxiv.org/abs/2601.04911v1","updated":"2026-01-08T13:09:43Z","published":"2026-01-08T13:09:43Z","title":"From Stories to Cities to Games: A Qualitative Evaluation of Behaviour Planning","summary":"The primary objective of a diverse planning approach is to generate a set of plans that are distinct from one another. Such an approach is applied in a variety of real-world domains, including risk management, automated stream data analysis, and malware detection. More recently, a novel diverse planning paradigm, referred to as behaviour planning, has been proposed. This approach extends earlier methods by explicitly incorporating a diversity model into the planning process and supporting multiple planning categories. In this paper, we demonstrate the usefulness of behaviour planning in real-world settings by presenting three case studies. The first case study focuses on storytelling, the second addresses urban planning, and the third examines game evaluation.","authors":["Mustafa F. Abdelwahed","Joan Espasa","Alice Toniolo","Ian P. Gent"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.15949v2","updated":"2026-01-08T13:08:59Z","published":"2025-10-10T13:01:51Z","title":"ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination","summary":"Large language models show promise for financial decision-making, yet deploying them as autonomous trading agents raises fundamental challenges: how to adapt instructions when rewards arrive late and obscured by market noise, how to synthesize heterogeneous information streams into coherent decisions, and how to bridge the gap between model outputs and executable market actions. We present ATLAS (Adaptive Trading with LLM AgentS), a unified multi-agent framework that integrates structured information from markets, news, and corporate fundamentals to support robust trading decisions. Within ATLAS, the central trading agent operates in an order-aware action space, ensuring that outputs correspond to executable market orders rather than abstract signals. The agent can incorporate feedback while trading using Adaptive-OPRO, a novel prompt-optimization technique that dynamically adapts the prompt by incorporating real-time, stochastic feedback, leading to increasing performance over time. Across regime-specific equity studies and multiple LLM families, Adaptive-OPRO consistently outperforms fixed prompts, while reflection-based feedback fails to provide systematic gains.","authors":["Charidimos Papadakis","Angeliki Dimitriou","Giorgos Filandrianos","Maria Lymperaiou","Konstantinos Thomas","Giorgos Stamou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.08973v3","updated":"2026-01-08T13:08:33Z","published":"2024-12-12T06:09:49Z","title":"Is Contrastive Distillation Enough for Learning Comprehensive 3D Representations?","summary":"Cross-modal contrastive distillation has recently been explored for learning effective 3D representations. However, existing methods focus primarily on modality-shared features, neglecting the modality-specific features during the pre-training process, which leads to suboptimal representations. In this paper, we theoretically analyze the limitations of current contrastive methods for 3D representation learning and propose a new framework, namely CMCR (Cross-Modal Comprehensive Representation Learning), to address these shortcomings. Our approach improves upon traditional methods by better integrating both modality-shared and modality-specific features. Specifically, we introduce masked image modeling and occupancy estimation tasks to guide the network in learning more comprehensive modality-specific features. Furthermore, we propose a novel multi-modal unified codebook that learns an embedding space shared across different modalities. Besides, we introduce geometry-enhanced masked image modeling to further boost 3D representation learning. Extensive experiments demonstrate that our method mitigates the challenges faced by traditional approaches and consistently outperforms existing image-to-LiDAR contrastive distillation methods in downstream tasks. Code will be available at https://github.com/Eaphan/CMCR.","authors":["Yifan Zhang","Junhui Hou"],"pdf_url":"","comment":"22 pages, 10 figures"},{"id":"http://arxiv.org/abs/2601.04895v1","updated":"2026-01-08T12:48:40Z","published":"2026-01-08T12:48:40Z","title":"DVD: A Robust Method for Detecting Variant Contamination in Large Language Model Evaluation","summary":"Evaluating large language models (LLMs) is increasingly confounded by \\emph{variant contamination}: the training corpus contains semantically equivalent yet lexically or syntactically altered versions of test items. Unlike verbatim leakage, these paraphrased or structurally transformed variants evade existing detectors based on sampling consistency or perplexity, thereby inflating benchmark scores via memorization rather than genuine reasoning. We formalize this problem and introduce \\textbf{DVD} (\\textbf{D}etection via \\textbf{V}ariance of generation \\textbf{D}istribution), a single-sample detector that models the local output distribution induced by temperature sampling. Our key insight is that contaminated items trigger alternation between a \\emph{memory-adherence} state and a \\emph{perturbation-drift} state, yielding abnormally high variance in the synthetic difficulty of low-probability tokens; uncontaminated items remain in drift with comparatively smooth variance. We construct the first benchmark for variant contamination across two domains Omni-MATH and SuperGPQA by generating and filtering semantically equivalent variants, and simulate contamination via fine-tuning models of different scales and architectures (Qwen2.5 and Llama3.1). Across datasets and models, \\textbf{DVD} consistently outperforms perplexity-based, Min-$k$\\%++, edit-distance (CDD), and embedding-similarity baselines, while exhibiting strong robustness to hyperparameters. Our results establish variance of the generation distribution as a principled and practical fingerprint for detecting variant contamination in LLM evaluation.","authors":["Renzhao Liang","Jingru Chen","Bo Jia","Bo Deng","Chenggang Xie","Yidong Wang","Ke Jin","Xin Wang","Linfeng Zhang","Cunxiang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04888v1","updated":"2026-01-08T12:39:05Z","published":"2026-01-08T12:39:05Z","title":"SmartSearch: Process Reward-Guided Query Refinement for Search Agents","summary":"Large language model (LLM)-based search agents have proven promising for addressing knowledge-intensive problems by incorporating information retrieval capabilities. Existing works largely focus on optimizing the reasoning paradigms of search agents, yet the quality of intermediate search queries during reasoning remains overlooked. As a result, the generated queries often remain inaccurate, leading to unexpected retrieval results and ultimately limiting search agents' overall effectiveness. To mitigate this issue, we introduce SmartSearch, a framework built upon two key mechanisms: (1) Process rewards, which provide fine-grained supervision for the quality of each intermediate search query through Dual-Level Credit Assessment. (2) Query refinement, which promotes the optimization of query generation by selectively refining low-quality search queries and regenerating subsequent search rounds based on these refinements. To enable the search agent to progressively internalize the ability to improve query quality under the guidance of process rewards, we design a three-stage curriculum learning framework. This framework guides the agent through a progression from imitation, to alignment, and ultimately to generalization. Experimental results show that SmartSearch consistently surpasses existing baselines, and additional quantitative analyses further confirm its significant gains in both search efficiency and query quality. The code is available at https://github.com/MYVAE/SmartSearch.","authors":["Tongyu Wen","Guanting Dong","Zhicheng Dou"],"pdf_url":"","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2601.04887v1","updated":"2026-01-08T12:37:02Z","published":"2026-01-08T12:37:02Z","title":"Flexible Manufacturing Systems Intralogistics: Dynamic Optimization of AGVs and Tool Sharing Using Coloured-Timed Petri Nets and Actor-Critic RL with Actions Masking","summary":"Flexible Manufacturing Systems (FMS) are pivotal in optimizing production processes in today's rapidly evolving manufacturing landscape. This paper advances the traditional job shop scheduling problem by incorporating additional complexities through the simultaneous integration of automated guided vehicles (AGVs) and tool-sharing systems. We propose a novel approach that combines Colored-Timed Petri Nets (CTPNs) with actor-critic model-based reinforcement learning (MBRL), effectively addressing the multifaceted challenges associated with FMS. CTPNs provide a formal modeling structure and dynamic action masking, significantly reducing the action search space, while MBRL ensures adaptability to changing environments through the learned policy. Leveraging the advantages of MBRL, we incorporate a lookahead strategy for optimal positioning of AGVs, improving operational efficiency. Our approach was evaluated on small-sized public benchmarks and a newly developed large-scale benchmark inspired by the Taillard benchmark. The results show that our approach matches traditional methods on smaller instances and outperforms them on larger ones in terms of makespan while achieving a tenfold reduction in computation time. To ensure reproducibility, we propose a gym-compatible environment and an instance generator. Additionally, an ablation study evaluates the contribution of each framework component to its overall performance.","authors":["Sofiene Lassoued","Laxmikant Shrikant Bahetic","Nathalie Weiß-Borkowskib","Stefan Lierc","Andreas Schwunga"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04886v1","updated":"2026-01-08T12:31:02Z","published":"2026-01-08T12:31:02Z","title":"Analyzing Message-Code Inconsistency in AI Coding Agent-Authored Pull Requests","summary":"Pull request (PR) descriptions generated by AI coding agents are the primary channel for communicating code changes to human reviewers. However, the alignment between these messages and the actual changes remains unexplored, raising concerns about the trustworthiness of AI agents. To fill this gap, we analyzed 23,247 agentic PRs across five agents using PR message-code inconsistency (PR-MCI). We contributed 974 manually annotated PRs, found 406 PRs (1.7%) exhibited high PR-MCI, and identified eight PR-MCI types, revealing that descriptions claiming unimplemented changes was the most common issue (45.4%). Statistical tests confirmed that high-MCI PRs had 51.7% lower acceptance rates (28.3% vs. 80.0%) and took 3.5x longer to merge (55.8 vs. 16.0 hours). Our findings suggest that unreliable PR descriptions undermine trust in AI agents, highlighting the need for PR-MCI verification mechanisms and improved PR generation to enable trustworthy human-AI collaboration.","authors":["Jingzhi Gong","Giovanni Pinna","Yixin Bian","Jie M. Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04885v1","updated":"2026-01-08T12:30:43Z","published":"2026-01-08T12:30:43Z","title":"CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters","summary":"As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \\textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \\textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \\textbf{\\textsc{CuMA}} (\\textbf{Cu}ltural \\textbf{M}ixture of \\textbf{A}dapters), a framework that frames alignment as a \\textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \\textsc{CuMA} internalizes a \\textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \\textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \\textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.","authors":["Ao Sun","Xiaoyu Wang","Zhe Tan","Yu Li","Jiachen Zhu","Shu Su","Yuheng Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04884v1","updated":"2026-01-08T12:30:36Z","published":"2026-01-08T12:30:36Z","title":"Precomputing Multi-Agent Path Replanning using Temporal Flexibility: A Case Study on the Dutch Railway Network","summary":"Executing a multi-agent plan can be challenging when an agent is delayed, because this typically creates conflicts with other agents. So, we need to quickly find a new safe plan. Replanning only the delayed agent often does not result in an efficient plan, and sometimes cannot even yield a feasible plan. On the other hand, replanning other agents may lead to a cascade of changes and delays. We show how to efficiently replan by tracking and using the temporal flexibility of other agents while avoiding cascading delays. This flexibility is the maximum delay an agent can take without changing the order of or further delaying more agents. Our algorithm, FlexSIPP, precomputes all possible plans for the delayed agent, also returning the changes for the other agents, for any single-agent delay within the given scenario. We demonstrate our method in a real-world case study of replanning trains in the densely-used Dutch railway network. Our experiments show that FlexSIPP provides effective solutions, relevant to real-world adjustments, and within a reasonable timeframe.","authors":["Issa Hanou","Eric Kemmeren","Devin Wild Thomas","Mathijs de Weerdt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.03979v3","updated":"2026-01-08T12:28:51Z","published":"2025-12-03T17:10:44Z","title":"BlurDM: A Blur Diffusion Model for Image Deblurring","summary":"Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The project page is available at https://jin-ting-he.github.io/BlurDM/.","authors":["Jin-Ting He","Fu-Jen Tsai","Yan-Tsung Peng","Min-Hung Chen","Chia-Wen Lin","Yen-Yu Lin"],"pdf_url":"","comment":"NeurIPS 2025. Project Page: https://jin-ting-he.github.io/BlurDM/"},{"id":"http://arxiv.org/abs/2601.04878v1","updated":"2026-01-08T12:25:37Z","published":"2026-01-08T12:25:37Z","title":"Higher-Order Knowledge Representations for Agentic Scientific Reasoning","summary":"Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a \"teacherless\" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.","authors":["Isabella A. Stewart","Markus J. Buehler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.10643v3","updated":"2026-01-08T12:15:40Z","published":"2025-11-13T18:58:37Z","title":"Black-Box On-Policy Distillation of Large Language Models","summary":"Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.","authors":["Tianzhu Ye","Li Dong","Zewen Chi","Xun Wu","Shaohan Huang","Furu Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04864v1","updated":"2026-01-08T11:59:35Z","published":"2026-01-08T11:59:35Z","title":"Key-Value Pair-Free Continual Learner via Task-Specific Prompt-Prototype","summary":"Continual learning aims to enable models to acquire new knowledge while retaining previously learned information. Prompt-based methods have shown remarkable performance in this domain; however, they typically rely on key-value pairing, which can introduce inter-task interference and hinder scalability. To overcome these limitations, we propose a novel approach employing task-specific Prompt-Prototype (ProP), thereby eliminating the need for key-value pairs. In our method, task-specific prompts facilitate more effective feature learning for the current task, while corresponding prototypes capture the representative features of the input. During inference, predictions are generated by binding each task-specific prompt with its associated prototype. Additionally, we introduce regularization constraints during prompt initialization to penalize excessively large values, thereby enhancing stability. Experiments on several widely used datasets demonstrate the effectiveness of the proposed method. In contrast to mainstream prompt-based approaches, our framework removes the dependency on key-value pairs, offering a fresh perspective for future continual learning research.","authors":["Haihua Luo","Xuming Ran","Zhengji Li","Huiyan Xue","Tingting Jiang","Jiangrong Shen","Tommi Kärkkäinen","Qi Xu","Fengyu Cong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04861v1","updated":"2026-01-08T11:56:09Z","published":"2026-01-08T11:56:09Z","title":"Orchestrating Intelligence: Confidence-Aware Routing for Efficient Multi-Agent Collaboration across Multi-Scale Models","summary":"While multi-agent systems (MAS) have demonstrated superior performance over single-agent approaches in complex reasoning tasks, they often suffer from significant computational inefficiencies. Existing frameworks typically deploy large language models (LLMs) uniformly across all agent roles, failing to account for the varying cognitive demands of different reasoning stages. We address this inefficiency by proposing OI-MAS framework, a novel multi-agent framework that implements an adaptive model-selection policy across a heterogeneous pool of multi-scale LLMs. Specifically, OI-MAS introduces a state-dependent routing mechanism that dynamically selects agent roles and model scales throughout the reasoning process. In addition, we introduce a confidence-aware mechanism that selects appropriate model scales conditioned on task complexity, thus reducing unnecessary reliance on large-scale models. Experimental results show that OI-MAS consistently outperforms baseline multi-agent systems, improving accuracy by up to 12.88\\% while reducing cost by up to 79.78\\%.","authors":["Jingbo Wang","Sendong Zhao","Jiatong Liu","Haochun Wang","Wanting Li","Bing Qin","Ting Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.12641v2","updated":"2026-01-08T11:53:15Z","published":"2025-05-19T02:50:15Z","title":"Single Image Reflection Separation via Dual Prior Interaction Transformer","summary":"Single image reflection separation aims to separate the transmission and reflection layers from a mixed image. Existing methods typically combine general priors from pre-trained models with task-specific priors such as text prompts and reflection detection. However, the transmission prior, as the most direct task-specific prior for the target transmission layer, has not been effectively modeled or fully utilized, limiting performance in complex scenarios. To address this issue, we propose a dual-prior interaction framework based on lightweight transmission prior generation and effective prior fusion. First, we design a Local Linear Correction Network (LLCN) that finetunes pre-trained models based on the physical constraint T=SI+B, where S and B represent pixel-wise and channel-wise scaling and bias transformations. LLCN efficiently generates high-quality transmission priors with minimal parameters. Second, we construct a Dual-Prior Interaction Transformer (DPIT) that employs a dual-stream channel reorganization attention mechanism. By reorganizing features from general and transmission priors for attention computation, DPIT achieves deep fusion of both priors, fully exploiting their complementary information. Experimental results on multiple benchmark datasets demonstrate that the proposed method achieves state-of-the-art performance.","authors":["Yue Huang","Zi'ang Li","Tianle Hu","Jie Wen","Guanbin Li","Jinglin Zhang","Guoxu Zhou","Xiaozhao Fang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04855v1","updated":"2026-01-08T11:45:59Z","published":"2026-01-08T11:45:59Z","title":"Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution","summary":"Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.","authors":["Francesco Ferrini","Veronica Lachi","Antonio Longa","Bruno Lepri","Matono Akiyoshi","Andrea Passerini","Xin Liu","Manfred Jaeger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04854v1","updated":"2026-01-08T11:44:34Z","published":"2026-01-08T11:44:34Z","title":"Token Maturation: Autoregressive Language Generation via Continuous Token Dynamics","summary":"Autoregressive language models are conventionally defined over discrete token sequences, committing to a specific token at every generation step. This early discretization forces uncertainty to be resolved through token-level sampling, often leading to instability, repetition, and sensitivity to decoding heuristics.\n  In this work, we introduce a continuous autoregressive formulation of language generation in which tokens are represented as continuous vectors that \\emph{mature} over multiple update steps before being discretized. Rather than sampling tokens, the model evolves continuous token representations through a deterministic dynamical process, committing to a discrete token only when the representation has sufficiently converged. Discrete text is recovered via hard decoding, while uncertainty is maintained and resolved in the continuous space.\n  We show that this maturation process alone is sufficient to produce coherent and diverse text using deterministic decoding (argmax), without reliance on token-level sampling, diffusion-style denoising, or auxiliary stabilization mechanisms. Additional perturbations, such as stochastic dynamics or history smoothing, can be incorporated naturally but are not required for the model to function.\n  To our knowledge, this is the first autoregressive language model that generates text by evolving continuous token representations to convergence prior to discretization, enabling stable generation without token-level sampling.","authors":["Oshri Naparstek"],"pdf_url":"","comment":"In preperation to ICML 2026"},{"id":"http://arxiv.org/abs/2508.12611v3","updated":"2026-01-08T11:15:52Z","published":"2025-08-18T04:15:35Z","title":"An LLM + ASP Workflow for Joint Entity-Relation Extraction","summary":"Joint entity-relation extraction (JERE) identifies both entities and their relationships simultaneously. Traditional machine-learning based approaches to performing this task require a large corpus of annotated data and lack the ability to easily incorporate domain specific information in the construction of the model. Therefore, creating a model for JERE is often labor intensive, time consuming, and elaboration intolerant. In this paper, we propose harnessing the capabilities of generative pre-trained large language models (LLMs) and the knowledge representation and reasoning capabilities of Answer Set Programming (ASP) to perform JERE. We present a generic workflow for JERE using LLMs and ASP. The workflow is generic in the sense that it can be applied for JERE in any domain. It takes advantage of LLM's capability in natural language understanding in that it works directly with unannotated text. It exploits the elaboration tolerant feature of ASP in that no modification of its core program is required when additional domain specific knowledge, in the form of type specifications, is found and needs to be used. We demonstrate the usefulness of the proposed workflow through experiments with limited training data on three well-known benchmarks for JERE. The results of our experiments show that the LLM + ASP workflow is better than state-of-the-art JERE systems in several categories with only 10% of training data. It is able to achieve a 2.5 times (35% over 15%) improvement in the Relation Extraction task for the SciERC corpus, one of the most difficult benchmarks.","authors":["Trang Tran","Trung Hoang Le","Huiping Cao","Tran Cao Son"],"pdf_url":"","comment":"In Proceedings ICLP 2025, arXiv:2601.00047"},{"id":"http://arxiv.org/abs/2601.03193v2","updated":"2026-01-08T11:08:10Z","published":"2026-01-06T17:15:50Z","title":"UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision","summary":"While Unified Multimodal Models (UMMs) have achieved remarkable success in cross-modal comprehension, a significant gap persists in their ability to leverage such internal knowledge for high-quality generation. We formalize this discrepancy as Conduction Aphasia, a phenomenon where models accurately interpret multimodal inputs but struggle to translate that understanding into faithful and controllable synthesis. To address this, we propose UniCorn, a simple yet elegant self-improvement framework that eliminates the need for external data or teacher supervision. By partitioning a single UMM into three collaborative roles: Proposer, Solver, and Judge, UniCorn generates high-quality interactions via self-play and employs cognitive pattern reconstruction to distill latent understanding into explicit generative signals. To validate the restoration of multimodal coherence, we introduce UniCycle, a cycle-consistency benchmark based on a Text to Image to Text reconstruction loop. Extensive experiments demonstrate that UniCorn achieves comprehensive and substantial improvements over the base model across six general image generation benchmarks. Notably, it achieves SOTA performance on TIIF(73.8), DPG(86.8), CompBench(88.5), and UniCycle while further delivering substantial gains of +5.0 on WISE and +6.5 on OneIG. These results highlight that our method significantly enhances T2I generation while maintaining robust comprehension, demonstrating the scalability of fully self-supervised refinement for unified multimodal intelligence.","authors":["Ruiyan Han","Zhen Fang","XinYu Sun","Yuchen Ma","Ziheng Wang","Yu Zeng","Zehui Chen","Lin Chen","Wenxuan Huang","Wei-Jie Xu","Yi Cao","Feng Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04823v1","updated":"2026-01-08T10:58:51Z","published":"2026-01-08T10:58:51Z","title":"DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation","summary":"Mixture-of-Experts (MoE) has become a prominent paradigm for scaling Large Language Models (LLMs). Parameter-efficient fine-tuning (PEFT), such as LoRA, is widely adopted to adapt pretrained MoE LLMs to downstream tasks. However, existing approaches assign identical LoRA ranks to all experts, overlooking the intrinsic functional specialization within MoE LLMs. This uniform allocation leads to resource mismatch, task-relevant experts are under-provisioned while less relevant ones receive redundant parameters. We propose a Dynamic Rank LoRA framework named DR-LoRA, which dynamically grows expert LoRA ranks during fine-tuning based on task-specific demands. DR-LoRA employs an Expert Saliency Scoring mechanism that integrates expert routing frequency and LoRA rank importance to quantify each expert's demand for additional capacity. Experts with higher saliency scores are prioritized for rank expansion, enabling the automatic formation of a heterogeneous rank distribution tailored to the target task. Experiments on multiple benchmarks demonstrate that DR-LoRA consistently outperforms standard LoRA and static allocation strategies under the same parameter budget, achieving superior task performance with more efficient parameter utilization.","authors":["Guanzhi Deng","Bo Li","Ronghao Chen","Huacan Wang","Linqi Song","Lijie Wen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.02046v2","updated":"2026-01-08T10:57:37Z","published":"2026-01-05T12:06:43Z","title":"Agentic Retoucher for Text-To-Image Generation","summary":"Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.","authors":["Shaocheng Shen","Jianfeng Liang","Chunlei Cai","Cong Geng","Huiyu Duan","Xiaoyun Zhang","Qiang Hu","Guangtao Zhai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04819v1","updated":"2026-01-08T10:54:32Z","published":"2026-01-08T10:54:32Z","title":"AECV-Bench: Benchmarking Multimodal Models on Architectural and Engineering Drawings Understanding","summary":"AEC drawings encode geometry and semantics through symbols, layout conventions, and dense annotation, yet it remains unclear whether modern multimodal and vision-language models can reliably interpret this graphical language. We present AECV-Bench, a benchmark for evaluating multimodal and vision-language models on realistic AEC artefacts via two complementary use cases: (i) object counting on 120 high-quality floor plans (doors, windows, bedrooms, toilets), and (ii) drawing-grounded document QA spanning 192 question-answer pairs that test text extraction (OCR), instance counting, spatial reasoning, and comparative reasoning over common drawing regions. Object-counting performance is reported using per-field exact-match accuracy and MAPE results, while document-QA performance is reported using overall accuracy and per-category breakdowns with an LLM-as-a-judge scoring pipeline and targeted human adjudication for edge cases. Evaluating a broad set of state-of-the-art models under a unified protocol, we observe a stable capability gradient; OCR and text-centric document QA are strongest (up to 0.95 accuracy), spatial reasoning is moderate, and symbol-centric drawing understanding - especially reliable counting of doors and windows - remains unsolved (often 0.40-0.55 accuracy) with substantial proportional errors. These results suggest that current systems function well as document assistants but lack robust drawing literacy, motivating domain-specific representations and tool-augmented, human-in-the-loop workflows for an efficient AEC automation.","authors":["Aleksei Kondratenko","Mussie Birhane","Houssame E. Hsain","Guido Maciocci"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01747v2","updated":"2026-01-08T10:46:04Z","published":"2026-01-05T02:49:33Z","title":"Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization","summary":"Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs","authors":["Jiwei Guan","Haibo Jin","Haohan Wang"],"pdf_url":"","comment":"EACL"},{"id":"http://arxiv.org/abs/2601.04809v1","updated":"2026-01-08T10:42:04Z","published":"2026-01-08T10:42:04Z","title":"SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning","summary":"Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.","authors":["Caijun Xu","Changyi Xiao","Zhongyuan Peng","Xinrun Wang","Yixin Cao"],"pdf_url":"","comment":"19 pages,5 figures"},{"id":"http://arxiv.org/abs/2601.04807v1","updated":"2026-01-08T10:39:48Z","published":"2026-01-08T10:39:48Z","title":"Parallelizing Node-Level Explainability in Graph Neural Networks","summary":"Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.","authors":["Oscar Llorente","Jaime Boal","Eugenio F. Sánchez-Úbeda","Antonio Diaz-Cano","Miguel Familiar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04805v1","updated":"2026-01-08T10:38:41Z","published":"2026-01-08T10:38:41Z","title":"Thinking-Based Non-Thinking: Solving the Reward Hacking Problem in Training Hybrid Reasoning Models via Reinforcement Learning","summary":"Large reasoning models (LRMs) have attracted much attention due to their exceptional performance. However, their performance mainly stems from thinking, a long Chain of Thought (CoT), which significantly increase computational overhead. To address this overthinking problem, existing work focuses on using reinforcement learning (RL) to train hybrid reasoning models that automatically decide whether to engage in thinking or not based on the complexity of the query. Unfortunately, using RL will suffer the the reward hacking problem, e.g., the model engages in thinking but is judged as not doing so, resulting in incorrect rewards. To mitigate this problem, existing works either employ supervised fine-tuning (SFT), which incurs high computational costs, or enforce uniform token limits on non-thinking responses, which yields limited mitigation of the problem. In this paper, we propose Thinking-Based Non-Thinking (TNT). It does not employ SFT, and sets different maximum token usage for responses not using thinking across various queries by leveraging information from the solution component of the responses using thinking. Experiments on five mathematical benchmarks demonstrate that TNT reduces token usage by around 50% compared to DeepSeek-R1-Distill-Qwen-1.5B/7B and DeepScaleR-1.5B, while significantly improving accuracy. In fact, TNT achieves the optimal trade-off between accuracy and efficiency among all tested methods. Additionally, the probability of reward hacking problem in TNT's responses, which are classified as not using thinking, remains below 10% across all tested datasets.","authors":["Siyuan Gan","Jiaheng Liu","Boyan Wang","Tianpei Yang","Runqing Miao","Yuyao Zhang","Fanyu Meng","Junlan Feng","Linjian Meng","Jing Huo","Yang Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.05547v2","updated":"2026-01-08T10:24:34Z","published":"2025-11-01T19:05:09Z","title":"Automated Invoice Data Extraction: Using LLM and OCR","summary":"Conventional Optical Character Recognition (OCR) systems are challenged by variant invoice layouts, handwritten text, and low-quality scans, which are often caused by strong template dependencies that restrict their flexibility across different document structures and layouts. Newer solutions utilize advanced deep learning models such as Convolutional Neural Networks (CNN) as well as Transformers, and domain-specific models for better layout analysis and accuracy across various sections over varied document types. Large Language Models (LLMs) have revolutionized extraction pipelines at their core with sophisticated entity recognition and semantic comprehension to support complex contextual relationship mapping without direct programming specification. Visual Named Entity Recognition (NER) capabilities permit extraction from invoice images with greater contextual sensitivity and much higher accuracy rates than older approaches. Existing industry best practices utilize hybrid architectures that blend OCR technology and LLM for maximum scalability and minimal human intervention. This work introduces a holistic Artificial Intelligence (AI) platform combining OCR, deep learning, LLMs, and graph analytics to achieve unprecedented extraction quality and consistency.","authors":["Khushi Khanchandani","Advait Thakur","Akshita Shetty","Chaitravi Reddy","Ritisa Behera"],"pdf_url":"","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2601.04795v1","updated":"2026-01-08T10:21:56Z","published":"2026-01-08T10:21:56Z","title":"Defense Against Indirect Prompt Injection via Tool Result Parsing","summary":"As LLM agents transition from digital assistants to physical controllers in autonomous systems and robotics, they face an escalating threat from indirect prompt injection. By embedding adversarial instructions into the results of tool calls, attackers can hijack the agent's decision-making process to execute unauthorized actions. This vulnerability poses a significant risk as agents gain more direct control over physical environments. Existing defense mechanisms against Indirect Prompt Injection (IPI) generally fall into two categories. The first involves training dedicated detection models; however, this approach entails high computational overhead for both training and inference, and requires frequent updates to keep pace with evolving attack vectors. Alternatively, prompt-based methods leverage the inherent capabilities of LLMs to detect or ignore malicious instructions via prompt engineering. Despite their flexibility, most current prompt-based defenses suffer from high Attack Success Rates (ASR), demonstrating limited robustness against sophisticated injection attacks. In this paper, we propose a novel method that provides LLMs with precise data via tool result parsing while effectively filtering out injected malicious code. Our approach achieves competitive Utility under Attack (UA) while maintaining the lowest Attack Success Rate (ASR) to date, significantly outperforming existing methods. Code is available at GitHub.","authors":["Qiang Yu","Xinran Cheng","Chuanyi Liu"],"pdf_url":"","comment":"20 pages, 3 figures, 5 tables"},{"id":"http://arxiv.org/abs/2601.04794v1","updated":"2026-01-08T10:21:49Z","published":"2026-01-08T10:21:49Z","title":"APEX: Academic Poster Editing Agentic Expert","summary":"Designing academic posters is a labor-intensive process requiring the precise balance of high-density content and sophisticated layout. While existing paper-to-poster generation methods automate initial drafting, they are typically single-pass and non-interactive, often fail to align with complex, subjective user intent. To bridge this gap, we propose APEX (Academic Poster Editing agentic eXpert), the first agentic framework for interactive academic poster editing, supporting fine-grained control with robust multi-level API-based editing and a review-and-adjustment Mechanism. In addition, we introduce APEX-Bench, the first systematic benchmark comprising 514 academic poster editing instructions, categorized by a multi-dimensional taxonomy including operation type, difficulty, and abstraction level, constructed via reference-guided and reference-free strategies to ensure realism and diversity. We further establish a multi-dimensional VLM-as-a-judge evaluation protocol to assess instruction fulfillment, modification scope, and visual consistency & harmony. Experimental results demonstrate that APEX significantly outperforms baseline methods. Our implementation is available at https://github.com/Breesiu/APEX.","authors":["Chengxin Shi","Qinnan Cai","Zeyuan Chen","Long Zeng","Yibo Zhao","Jing Yu","Jianxiang Yu","Xiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04790v1","updated":"2026-01-08T10:13:56Z","published":"2026-01-08T10:13:56Z","title":"Belief in Authority: Impact of Authority in Multi-Agent Evaluation Framework","summary":"Multi-agent systems utilizing large language models often assign authoritative roles to improve performance, yet the impact of authority bias on agent interactions remains underexplored. We present the first systematic analysis of role-based authority bias in free-form multi-agent evaluation using ChatEval. Applying French and Raven's power-based theory, we classify authoritative roles into legitimate, referent, and expert types and analyze their influence across 12-turn conversations. Experiments with GPT-4o and DeepSeek R1 reveal that Expert and Referent power roles exert stronger influence than Legitimate power roles. Crucially, authority bias emerges not through active conformity by general agents, but through authoritative roles consistently maintaining their positions while general agents demonstrate flexibility. Furthermore, authority influence requires clear position statements, as neutral responses fail to generate bias. These findings provide key insights for designing multi-agent frameworks with asymmetric interaction patterns.","authors":["Junhyuk Choi","Jeongyoun Kwon","Heeju Kim","Haeun Cho","Hayeong Jung","Sehee Min","Bugeun Kim"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2601.04789v1","updated":"2026-01-08T10:12:45Z","published":"2026-01-08T10:12:45Z","title":"NC2C: Automated Convexification of Generic Non-Convex Optimization Problems","summary":"Non-convex optimization problems are pervasive across mathematical programming, engineering design, and scientific computing, often posing intractable challenges for traditional solvers due to their complex objective functions and constrained landscapes. To address the inefficiency of manual convexification and the over-reliance on expert knowledge, we propose NC2C, an LLM-based end-to-end automated framework designed to transform generic non-convex optimization problems into solvable convex forms using large language models. NC2C leverages LLMs' mathematical reasoning capabilities to autonomously detect non-convex components, select optimal convexification strategies, and generate rigorous convex equivalents. The framework integrates symbolic reasoning, adaptive transformation techniques, and iterative validation, equipped with error correction loops and feasibility domain correction mechanisms to ensure the robustness and validity of transformed problems. Experimental results on a diverse dataset of 100 generic non-convex problems demonstrate that NC2C achieves an 89.3\\% execution rate and a 76\\% success rate in producing feasible, high-quality convex transformations. This outperforms baseline methods by a significant margin, highlighting NC2C's ability to leverage LLMs for automated non-convex to convex transformation, reduce expert dependency, and enable efficient deployment of convex solvers for previously intractable optimization tasks.","authors":["Xinyue Peng","Yanming Liu","Yihan Cang","Yuwei Zhang","Xinyi Wang","Songhang Deng","Jiannan Cao"],"pdf_url":"","comment":"First version of NC2C"},{"id":"http://arxiv.org/abs/2601.04786v1","updated":"2026-01-08T10:10:20Z","published":"2026-01-08T10:10:20Z","title":"AgentOCR: Reimagining Agent History via Optical Self-Compression","summary":"Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\\% of text-based agent performance while substantially reducing token consumption (>50\\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.","authors":["Lang Feng","Fuchao Yang","Feng Chen","Xin Cheng","Haiyang Xu","Zhenglin Wan","Ming Yan","Bo An"],"pdf_url":"","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2601.04785v1","updated":"2026-01-08T10:10:03Z","published":"2026-01-08T10:10:03Z","title":"SRU-Pix2Pix: A Fusion-Driven Generator Network for Medical Image Translation with Few-Shot Learning","summary":"Magnetic Resonance Imaging (MRI) provides detailed tissue information, but its clinical application is limited by long acquisition time, high cost, and restricted resolution. Image translation has recently gained attention as a strategy to address these limitations. Although Pix2Pix has been widely applied in medical image translation, its potential has not been fully explored. In this study, we propose an enhanced Pix2Pix framework that integrates Squeeze-and-Excitation Residual Networks (SEResNet) and U-Net++ to improve image generation quality and structural fidelity. SEResNet strengthens critical feature representation through channel attention, while U-Net++ enhances multi-scale feature fusion. A simplified PatchGAN discriminator further stabilizes training and refines local anatomical realism. Experimental results demonstrate that under few-shot conditions with fewer than 500 images, the proposed method achieves consistent structural fidelity and superior image quality across multiple intra-modality MRI translation tasks, showing strong generalization ability. These results suggest an effective extension of Pix2Pix for medical image translation.","authors":["Xihe Qiu","Yang Dai","Xiaoyu Tan","Sijia Li","Fenghao Sun","Lu Gan","Liang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04778v1","updated":"2026-01-08T10:03:07Z","published":"2026-01-08T10:03:07Z","title":"CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models","summary":"Video-language models (VLMs) achieve strong multimodal understanding but remain prone to hallucinations, especially when reasoning about actions and temporal order. Existing mitigation strategies, such as textual filtering or random video perturbations, often fail to address the root cause: over-reliance on language priors rather than fine-grained visual dynamics. We propose a scalable framework for counterfactual video generation that synthesizes videos differing only in actions or temporal structure while preserving scene context. Our pipeline combines multimodal LLMs for action proposal and editing guidance with diffusion-based image and video models to generate semantic hard negatives at scale. Using this framework, we build CounterVid, a synthetic dataset of ~26k preference pairs targeting action recognition and temporal reasoning. We further introduce MixDPO, a unified Direct Preference Optimization approach that jointly leverages textual and visual preferences. Fine-tuning Qwen2.5-VL with MixDPO yields consistent improvements, notably in temporal ordering, and transfers effectively to standard video hallucination benchmarks. Code and models will be made publicly available.","authors":["Tobia Poppi","Burak Uzkent","Amanmeet Garg","Lucas Porto","Garin Kessler","Yezhou Yang","Marcella Cornia","Lorenzo Baraldi","Rita Cucchiara","Florian Schiffers"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.16316v2","updated":"2026-01-08T10:01:33Z","published":"2024-09-16T08:15:54Z","title":"Surface solar radiation: AI satellite retrieval can outperform Heliosat and generalizes well to other climate zones","summary":"Accurate estimates of surface solar irradiance (SSI) are essential for solar resource assessments and solar energy forecasts in grid integration and building control applications. SSI estimates for spatially extended regions can be retrieved from geostationary satellites such as Meteosat. Traditional SSI satellite retrievals like Heliosat rely on physical radiative transfer modelling. We introduce the first machine-learning-based satellite retrieval for instantaneous SSI and demonstrate its capability to provide accurate and generalizable SSI estimates across Europe. Our deep learning retrieval provides near real-time SSI estimates based on data-driven emulation of Heliosat and fine-tuning on pyranometer networks. By including SSI from ground stations, our SSI retrieval model can outperform Heliosat accuracy and generalize well to regions with other climates and surface albedos in cloudy conditions (clear-sky index < 0.8). We also show that the SSI retrieved from Heliosat exhibits large biases in mountain regions, and that training and fine-tuning our retrieval models on SSI data from ground stations strongly reduces these biases, outperforming Heliosat. Furthermore, we quantify the relative importance of the Meteosat channels and other predictor variables like solar zenith angle for the accuracy of our deep learning SSI retrieval model in different cloud conditions. We find that in cloudy conditions multiple near-infrared and infrared channels enhance the performance. Our results can facilitate the development of more accurate satellite retrieval models of surface solar irradiance.","authors":["K. R. Schuurman","A. Meyer"],"pdf_url":"","comment":"19 pages, 11 figures Published in International Journal of Remote Sensing, Volume 46, 2025"},{"id":"http://arxiv.org/abs/2601.04777v1","updated":"2026-01-08T09:58:35Z","published":"2026-01-08T09:58:35Z","title":"GeM-VG: Towards Generalized Multi-image Visual Grounding with Multimodal Large Language Models","summary":"Multimodal Large Language Models (MLLMs) have demonstrated impressive progress in single-image grounding and general multi-image understanding. Recently, some methods begin to address multi-image grounding. However, they are constrained by single-target localization and limited types of practical tasks, due to the lack of unified modeling for generalized grounding tasks. Therefore, we propose GeM-VG, an MLLM capable of Generalized Multi-image Visual Grounding. To support this, we systematically categorize and organize existing multi-image grounding tasks according to their reliance of cross-image cues and reasoning, and introduce the MG-Data-240K dataset, addressing the limitations of existing datasets regarding target quantity and image relation. To tackle the challenges of robustly handling diverse multi-image grounding tasks, we further propose a hybrid reinforcement finetuning strategy that integrates chain-of-thought (CoT) reasoning and direct answering, considering their complementary strengths. This strategy adopts an R1-like algorithm guided by a carefully designed rule-based reward, effectively enhancing the model's overall perception and reasoning capabilities. Extensive experiments demonstrate the superior generalized grounding capabilities of our model. For multi-image grounding, it outperforms the previous leading MLLMs by 2.0% and 9.7% on MIG-Bench and MC-Bench, respectively. In single-image grounding, it achieves a 9.1% improvement over the base model on ODINW. Furthermore, our model retains strong capabilities in general multi-image understanding.","authors":["Shurong Zheng","Yousong Zhu","Hongyin Zhao","Fan Yang","Yufei Zhan","Ming Tang","Jinqiao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04770v1","updated":"2026-01-08T09:45:58Z","published":"2026-01-08T09:45:58Z","title":"SciIF: Benchmarking Scientific Instruction Following Towards Rigorous Scientific Intelligence","summary":"As large language models (LLMs) transition from general knowledge retrieval to complex scientific discovery, their evaluation standards must also incorporate the rigorous norms of scientific inquiry. Existing benchmarks exhibit a critical blind spot: general instruction-following metrics focus on superficial formatting, while domain-specific scientific benchmarks assess only final-answer correctness, often rewarding models that arrive at the right result with the wrong reasons. To address this gap, we introduce scientific instruction following: the capability to solve problems while strictly adhering to the constraints that establish scientific validity. Specifically, we introduce SciIF, a multi-discipline benchmark that evaluates this capability by pairing university-level problems with a fixed catalog of constraints across three pillars: scientific conditions (e.g., boundary checks and assumptions), semantic stability (e.g., unit and symbol conventions), and specific processes(e.g., required numerical methods). Uniquely, SciIF emphasizes auditability, requiring models to provide explicit evidence of constraint satisfaction rather than implicit compliance. By measuring both solution correctness and multi-constraint adherence, SciIF enables finegrained diagnosis of compositional reasoning failures, ensuring that LLMs can function as reliable agents within the strict logical frameworks of science.","authors":["Encheng Su","Jianyu Wu","Chen Tang","Lintao Wang","Pengze Li","Aoran Wang","Jinouwen Zhang","Yizhou Wang","Yuan Meng","Xinzhu Ma","Shixiang Tang","Houqiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04767v1","updated":"2026-01-08T09:35:49Z","published":"2026-01-08T09:35:49Z","title":"AT$^2$PO: Agentic Turn-based Policy Optimization via Tree Search","summary":"LLM agents have emerged as powerful systems for tackling multi-turn tasks by interleaving internal reasoning and external tool interactions. Agentic Reinforcement Learning has recently drawn significant research attention as a critical post-training paradigm to further refine these capabilities. In this paper, we present AT$^2$PO (Agentic Turn-based Policy Optimization via Tree Search), a unified framework for multi-turn agentic RL that addresses three core challenges: limited exploration diversity, sparse credit assignment, and misaligned policy optimization. AT$^2$PO introduces a turn-level tree structure that jointly enables Entropy-Guided Tree Expansion for strategic exploration and Turn-wise Credit Assignment for fine-grained reward propagation from sparse outcomes. Complementing this, we propose Agentic Turn-based Policy Optimization, a turn-level learning objective that aligns policy updates with the natural decision granularity of agentic interactions. ATPO is orthogonal to tree search and can be readily integrated into any multi-turn RL pipeline. Experiments across seven benchmarks demonstrate consistent improvements over the state-of-the-art baseline by up to 1.84 percentage points in average, with ablation studies validating the effectiveness of each component. Our code is available at https://github.com/zzfoutofspace/ATPO.","authors":["Zefang Zong","Dingwei Chen","Yang Li","Qi Yi","Bo Zhou","Chengming Li","Bo Qian","Peng Chen","Jie Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04765v1","updated":"2026-01-08T09:33:29Z","published":"2026-01-08T09:33:29Z","title":"Differential syntactic and semantic encoding in LLMs","summary":"We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.","authors":["Santiago Acevedo","Alessandro Laio","Marco Baroni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04764v1","updated":"2026-01-08T09:32:01Z","published":"2026-01-08T09:32:01Z","title":"Orion-RAG: Path-Aligned Hybrid Retrieval for Graphless Data","summary":"Retrieval-Augmented Generation (RAG) has proven effective for knowledge synthesis, yet it encounters significant challenges in practical scenarios where data is inherently discrete and fragmented. In most environments, information is distributed across isolated files like reports and logs that lack explicit links. Standard search engines process files independently, ignoring the connections between them. Furthermore, manually building Knowledge Graphs is impractical for such vast data. To bridge this gap, we present Orion-RAG. Our core insight is simple yet effective: we do not need heavy algorithms to organize this data. Instead, we use a low-complexity strategy to extract lightweight paths that naturally link related concepts. We demonstrate that this streamlined approach suffices to transform fragmented documents into semi-structured data, enabling the system to link information across different files effectively. Extensive experiments demonstrate that Orion-RAG consistently outperforms mainstream frameworks across diverse domains, supporting real-time updates and explicit Human-in-the-Loop verification with high cost-efficiency. Experiments on FinanceBench demonstrate superior precision with a 25.2% relative improvement over strong baselines.","authors":["Zhen Chen","Weihao Xie","Peilin Chen","Shiqi Wang","Jianping Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04761v1","updated":"2026-01-08T09:29:11Z","published":"2026-01-08T09:29:11Z","title":"Smart IoT-Based Wearable Device for Detection and Monitoring of Common Cow Diseases Using a Novel Machine Learning Technique","summary":"Manual observation and monitoring of individual cows for disease detection present significant challenges in large-scale farming operations, as the process is labor-intensive, time-consuming, and prone to reduced accuracy. The reliance on human observation often leads to delays in identifying symptoms, as the sheer number of animals can hinder timely attention to each cow. Consequently, the accuracy and precision of disease detection are significantly compromised, potentially affecting animal health and overall farm productivity. Furthermore, organizing and managing human resources for the manual observation and monitoring of cow health is a complex and economically demanding task. It necessitates the involvement of skilled personnel, thereby contributing to elevated farm maintenance costs and operational inefficiencies. Therefore, the development of an automated, low-cost, and reliable smart system is essential to address these challenges effectively. Although several studies have been conducted in this domain, very few have simultaneously considered the detection of multiple common diseases with high prediction accuracy. However, advancements in Internet of Things (IoT), Machine Learning (ML), and Cyber-Physical Systems have enabled the automation of cow health monitoring with enhanced accuracy and reduced operational costs. This study proposes an IoT-enabled Cyber-Physical System framework designed to monitor the daily activities and health status of cow. A novel ML algorithm is proposed for the diagnosis of common cow diseases using collected physiological and behavioral data. The algorithm is designed to predict multiple diseases by analyzing a comprehensive set of recorded physiological and behavioral features, enabling accurate and efficient health assessment.","authors":["Rupsa Rani Mishra","D. Chandrasekhar Rao","Ajaya Kumar Tripathy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04758v1","updated":"2026-01-08T09:26:05Z","published":"2026-01-08T09:26:05Z","title":"PILOT-Bench: A Benchmark for Legal Reasoning in the Patent Domain with IRAC-Aligned Classification Tasks","summary":"The Patent Trial and Appeal Board (PTAB) of the USPTO adjudicates thousands of ex parte appeals each year, requiring the integration of technical understanding and legal reasoning. While large language models (LLMs) are increasingly applied in patent and legal practice, their use has remained limited to lightweight tasks, with no established means of systematically evaluating their capacity for structured legal reasoning in the patent domain. In this work, we introduce PILOT-Bench, the first PTAB-centric benchmark that aligns PTAB decisions with USPTO patent data at the case-level and formalizes three IRAC-aligned classification tasks: Issue Type, Board Authorities, and Subdecision. We evaluate a diverse set of closed-source (commercial) and open-source LLMs and conduct analyses across multiple perspectives, including input-variation settings, model families, and error tendencies. Notably, on the Issue Type task, closed-source models consistently exceed 0.75 in Micro-F1 score, whereas the strongest open-source model (Qwen-8B) achieves performance around 0.56, highlighting a substantial gap in reasoning capabilities. PILOT-Bench establishes a foundation for the systematic evaluation of patent-domain legal reasoning and points toward future directions for improving LLMs through dataset design and model alignment. All data, code, and benchmark resources are available at https://github.com/TeamLab/pilot-bench.","authors":["Yehoon Jang","Chaewon Lee","Hyun-seok Min","Sungchul Choi"],"pdf_url":"","comment":"Accepted at the NLLP Workshop at EMNLP 2025"},{"id":"http://arxiv.org/abs/2507.13425v2","updated":"2026-01-08T09:25:09Z","published":"2025-07-17T17:10:37Z","title":"CaTFormer: Causal Temporal Transformer with Dynamic Contextual Fusion for Driving Intention Prediction","summary":"Accurate prediction of driving intention is key to enhancing the safety and interactive efficiency of human-machine co-driving systems. It serves as a cornerstone for achieving high-level autonomous driving. However, current approaches remain inadequate for accurately modeling the complex spatiotemporal interdependencies and the unpredictable variability of human driving behavior. To address these challenges, we propose CaTFormer, a causal Temporal Transformer that explicitly models causal interactions between driver behavior and environmental context for robust intention prediction. Specifically, CaTFormer introduces a novel Reciprocal Delayed Fusion (RDF) mechanism for precise temporal alignment of interior and exterior feature streams, a Counterfactual Residual Encoding (CRE) module that systematically eliminates spurious correlations to reveal authentic causal dependencies, and an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these purified representations into coherent temporal representations. Experimental results demonstrate that CaTFormer attains state-of-the-art performance on the Brain4Cars dataset. It effectively captures complex causal temporal dependencies and enhances both the accuracy and transparency of driving intention prediction.","authors":["Sirui Wang","Zhou Guan","Bingxi Zhao","Tongjia Gu","Jie Liu"],"pdf_url":"","comment":"Accepted at AAAI 2026"},{"id":"http://arxiv.org/abs/2508.15658v3","updated":"2026-01-08T09:23:05Z","published":"2025-08-21T15:45:10Z","title":"SurGE: A Benchmark and Evaluation Framework for Scientific Survey Generation","summary":"The rapid growth of academic literature makes the manual creation of scientific surveys increasingly infeasible. While large language models show promise for automating this process, progress in this area is hindered by the absence of standardized benchmarks and evaluation protocols. To bridge this critical gap, we introduce SurGE (Survey Generation Evaluation), a new benchmark for scientific survey generation in computer science. SurGE consists of (1) a collection of test instances, each including a topic description, an expert-written survey, and its full set of cited references, and (2) a large-scale academic corpus of over one million papers. In addition, we propose an automated evaluation framework that measures the quality of generated surveys across four dimensions: comprehensiveness, citation accuracy, structural organization, and content quality. Our evaluation of diverse LLM-based methods demonstrates a significant performance gap, revealing that even advanced agentic frameworks struggle with the complexities of survey generation and highlighting the need for future research in this area. We have open-sourced all the code, data, and models at: https://github.com/oneal2000/SurGE","authors":["Weihang Su","Anzhe Xie","Qingyao Ai","Jianming Long","Jiaxin Mao","Ziyi Ye","Yiqun Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.23367v2","updated":"2026-01-08T09:20:35Z","published":"2025-12-29T10:50:23Z","title":"Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2","summary":"Huawei's openPangu-Embedded-1B and openPangu-Embedded-7B are variants of the openPangu large language model, designed for efficient deployment on Ascend NPUs. The 7B variant supports three distinct Chain-of-Thought (CoT) reasoning paradigms, namely slow_think, auto_think, and no_think, while the 1B variant operates exclusively in the no_think mode, which employs condensed reasoning for higher efficiency. Although CoT reasoning enhances capability, the generation of extended reasoning traces introduces substantial memory and latency overheads, posing challenges for practical deployment on Ascend NPUs. This paper addresses these computational constraints by leveraging low-bit quantization, which transforms FP16 computations into more efficient integer arithmetic. We introduce a unified low-bit inference framework, supporting INT8 (W8A8) and W4A8 quantization, specifically optimized for openPangu-Embedded models on the Atlas A2. Our comprehensive evaluation on code generation benchmarks (HumanEval and MBPP) demonstrates the efficacy of this approach. INT8 quantization consistently preserves over 90\\% of the FP16 baseline accuracy and achieves a 1.5x prefill speedup on the Atlas A2. Furthermore, W4A8 quantization significantly reduces memory consumption, albeit with a moderate trade-off in accuracy. These findings collectively indicate that low-bit quantization effectively facilitates efficient CoT reasoning on Ascend NPUs, maintaining high model fidelity.","authors":["Yilun Luo","Huaqing Zheng","Haoqian Meng","Wenyuan Liu","Peng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04748v1","updated":"2026-01-08T09:14:26Z","published":"2026-01-08T09:14:26Z","title":"When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail","summary":"Multi-agent AI systems have proven effective for complex reasoning. These systems are compounded by specialized agents, which collaborate through explicit communication, but incur substantial computational overhead. A natural question arises: can we achieve similar modularity benefits with a single agent that selects from a library of skills? We explore this question by viewing skills as internalized agent behaviors. From this perspective, a multi-agent system can be compiled into an equivalent single-agent system, trading inter-agent communication for skill selection. Our preliminary experiments suggest this approach can substantially reduce token usage and latency while maintaining competitive accuracy on reasoning benchmarks. However, this efficiency raises a deeper question that has received little attention: how does skill selection scale as libraries grow?\n  Drawing on principles from cognitive science, we propose that LLM skill selection exhibits bounded capacity analogous to human decision-making. We investigate the scaling behavior of skill selection and observe a striking pattern. Rather than degrading gradually, selection accuracy remains stable up to a critical library size, then drops sharply, indicating a phase transition reminiscent of capacity limits in human cognition. Furthermore, we find evidence that semantic confusability among similar skills, rather than library size alone, plays a central role in this degradation. This perspective suggests that hierarchical organization, which has long helped humans manage complex choices, may similarly benefit AI systems. Our initial results with hierarchical routing support this hypothesis. This work opens new questions about the fundamental limits of semantic-based skill selection in LLMs and offers a cognitive-grounded framework and practical guidelines for designing scalable skill-based agents.","authors":["Xiaoxiao Li"],"pdf_url":"","comment":"25 pages, technical report"},{"id":"http://arxiv.org/abs/2411.06568v4","updated":"2026-01-08T09:13:10Z","published":"2024-11-10T19:11:48Z","title":"Meta-Learning Objectives for Preference Optimization","summary":"Evaluating preference optimization (PO) algorithms on LLM alignment is a challenging task that presents prohibitive costs, noise, and several variables like model size and hyper-parameters. In this work, we show that it is possible to gain insights on the efficacy of PO algorithm on simpler benchmarks. We design a diagnostic suite of MuJoCo tasks and datasets, which we use to systematically evaluate PO algorithms, establishing a more controlled and cheaper benchmark. We then propose a novel family of PO algorithms based on mirror descent, which we call Mirror Preference Optimization (MPO). Through evolutionary strategies, we search this class to discover algorithms specialized to specific properties of preference datasets, such as mixed-quality or noisy data. We demonstrate that our discovered PO algorithms outperform all known algorithms in the targeted MuJoCo settings. Finally, based on the insights gained from our MuJoCo experiments, we design a PO algorithm that significantly outperform existing baselines in an LLM alignment task.","authors":["Carlo Alfano","Silvia Sapora","Jakob Nicolaus Foerster","Patrick Rebeschini","Yee Whye Teh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04745v1","updated":"2026-01-08T09:11:33Z","published":"2026-01-08T09:11:33Z","title":"KnowMe-Bench: Benchmarking Person Understanding for Lifelong Digital Companions","summary":"Existing long-horizon memory benchmarks mostly use multi-turn dialogues or synthetic user histories, which makes retrieval performance an imperfect proxy for person understanding. We present \\BenchName, a publicly releasable benchmark built from long-form autobiographical narratives, where actions, context, and inner thoughts provide dense evidence for inferring stable motivations and decision principles. \\BenchName~reconstructs each narrative into a flashback-aware, time-anchored stream and evaluates models with evidence-linked questions spanning factual recall, subjective state attribution, and principle-level reasoning. Across diverse narrative sources, retrieval-augmented systems mainly improve factual accuracy, while errors persist on temporally grounded explanations and higher-level inferences, highlighting the need for memory mechanisms beyond retrieval. Our data is in \\href{KnowMeBench}{https://github.com/QuantaAlpha/KnowMeBench}.","authors":["Tingyu Wu","Zhisheng Chen","Ziyan Weng","Shuhe Wang","Chenglong Li","Shuo Zhang","Sen Hu","Silin Wu","Qizhen Lan","Huacan Wang","Ronghao Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.07602v2","updated":"2026-01-08T09:11:33Z","published":"2025-08-11T04:13:06Z","title":"HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol","summary":"Invoking external tools enables Large Language Models (LLMs) to perform complex, real-world tasks, yet selecting the correct tool from large, hierarchically-structured libraries remains a significant challenge. The limited context windows of LLMs and noise from irrelevant options often lead to low selection accuracy and high computational costs. To address this, we propose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic pruning method for scalable tool invocation. HGMF first maps the user query and all tool descriptions into a unified semantic space. The framework then operates in two stages: it clusters servers using a Gaussian Mixture Model (GMM) and filters them based on the query's likelihood. Subsequently, it applies the same GMM-based clustering and filtering to the tools associated with the selected servers. This hierarchical process produces a compact, high-relevance candidate set, simplifying the final selection task for the LLM. Experiments on a public dataset show that HGMF significantly improves tool selection accuracy while reducing inference latency, confirming the framework's scalability and effectiveness for large-scale tool libraries.","authors":["Wenpeng Xing","Zhipeng Chen","Changting Lin","Meng Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04744v1","updated":"2026-01-08T09:10:16Z","published":"2026-01-08T09:10:16Z","title":"Semi-Supervised Diseased Detection from Speech Dialogues with Multi-Level Data Modeling","summary":"Detecting medical conditions from speech acoustics is fundamentally a weakly-supervised learning problem: a single, often noisy, session-level label must be linked to nuanced patterns within a long, complex audio recording. This task is further hampered by severe data scarcity and the subjective nature of clinical annotations. While semi-supervised learning (SSL) offers a viable path to leverage unlabeled data, existing audio methods often fail to address the core challenge that pathological traits are not uniformly expressed in a patient's speech. We propose a novel, audio-only SSL framework that explicitly models this hierarchy by jointly learning from frame-level, segment-level, and session-level representations within unsegmented clinical dialogues. Our end-to-end approach dynamically aggregates these multi-granularity features and generates high-quality pseudo-labels to efficiently utilize unlabeled data. Extensive experiments show the framework is model-agnostic, robust across languages and conditions, and highly data-efficient-achieving, for instance, 90\\% of fully-supervised performance using only 11 labeled samples. This work provides a principled approach to learning from weak, far-end supervision in medical speech analysis.","authors":["Xingyuan Li","Mengyue Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.05633v2","updated":"2026-01-08T09:08:41Z","published":"2024-11-08T15:22:49Z","title":"SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection","summary":"Developing robust drone detection systems is often constrained by the limited availability of large-scale annotated training data and the high costs associated with real-world data collection. However, leveraging synthetic data generated via game engine-based simulations provides a promising and cost-effective solution to overcome this issue. Therefore, we present SynDroneVision, a synthetic dataset specifically designed for RGB-based drone detection in surveillance applications. Featuring diverse backgrounds, lighting conditions, and drone models, SynDroneVision offers a comprehensive training foundation for deep learning algorithms. To evaluate the dataset's effectiveness, we perform a comparative analysis across a selection of recent YOLO detection models. Our findings demonstrate that SynDroneVision is a valuable resource for real-world data enrichment, achieving notable enhancements in model performance and robustness, while significantly reducing the time and costs of real-world data acquisition. SynDroneVision will be publicly released upon paper acceptance.","authors":["Tamara R. Lenhard","Andreas Weinmann","Kai Franke","Tobias Koch"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04741v1","updated":"2026-01-08T09:05:57Z","published":"2026-01-08T09:05:57Z","title":"Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams","summary":"Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.","authors":["Kota Nakamura","Koki Kawabata","Yasuko Matsubara","Yasushi Sakurai"],"pdf_url":"","comment":"Accepted by KDD 2026"},{"id":"http://arxiv.org/abs/2601.04740v1","updated":"2026-01-08T09:05:28Z","published":"2026-01-08T09:05:28Z","title":"RiskAtlas: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation","summary":"Large language models (LLMs) are increasingly applied in specialized domains such as finance and healthcare, where they introduce unique safety risks. Domain-specific datasets of harmful prompts remain scarce and still largely rely on manual construction; public datasets mainly focus on explicit harmful prompts, which modern LLM defenses can often detect and refuse. In contrast, implicit harmful prompts-expressed through indirect domain knowledge-are harder to detect and better reflect real-world threats. We identify two challenges: transforming domain knowledge into actionable constraints and increasing the implicitness of generated harmful prompts. To address them, we propose an end-to-end framework that first performs knowledge-graph-guided harmful prompt generation to systematically produce domain-relevant prompts, and then applies dual-path obfuscation rewriting to convert explicit harmful prompts into implicit variants via direct and context-enhanced rewriting. This framework yields high-quality datasets combining strong domain relevance with implicitness, enabling more realistic red-teaming and advancing LLM safety research. We release our code and datasets at GitHub.","authors":["Huawei Zheng","Xinqi Jiang","Sen Yang","Shouling Ji","Yingcai Wu","Dazhen Deng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.14641v3","updated":"2026-01-08T09:01:32Z","published":"2025-06-17T15:39:33Z","title":"Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot","summary":"In-Context Learning (ICL) is an essential emergent ability of Large Language Models (LLMs), and recent studies introduce Chain-of-Thought (CoT) to exemplars of ICL to enhance the reasoning capability, especially in mathematics tasks. However, given the continuous advancement of model capabilities, it remains unclear whether CoT exemplars still benefit recent, stronger models in such tasks. Through systematic experiments, we find that for recent strong models such as the Qwen2.5 series, adding traditional CoT exemplars does not improve reasoning performance compared to Zero-Shot CoT. Instead, their primary function is to align the output format with human expectations. We further investigate the effectiveness of enhanced CoT exemplars, constructed using answers from advanced models such as \\texttt{Qwen2.5-Max} and \\texttt{DeepSeek-R1}. Experimental results indicate that these enhanced exemplars still fail to improve the model's reasoning performance. Further analysis reveals that models tend to ignore the exemplars and focus primarily on the instructions, leading to no observable gain in reasoning ability. Overall, our findings highlight the limitations of the current ICL+CoT framework in mathematical reasoning, calling for a re-examination of the ICL paradigm and the definition of exemplars.","authors":["Xiang Cheng","Chengyan Pan","Minjun Zhao","Deyang Li","Fangchao Liu","Xinyu Zhang","Xiao Zhang","Yong Liu"],"pdf_url":"","comment":"EMNLP25-findings camera_ready, 19 pages,22 figures"},{"id":"http://arxiv.org/abs/2601.04732v1","updated":"2026-01-08T08:54:44Z","published":"2026-01-08T08:54:44Z","title":"The Role of Quantum in Hybrid Quantum-Classical Neural Networks: A Realistic Assessment","summary":"Quantum machine learning has emerged as a promising application domain for near-term quantum hardware, particularly through hybrid quantum-classical models that leverage both classical and quantum processing. Although numerous hybrid architectures have been proposed and demonstrated successfully on benchmark tasks, a significant open question remains regarding the specific contribution of quantum components to the overall performance of these models. In this work, we aim to shed light on the impact of quantum processing within hybrid quantum-classical neural network architectures through a rigorous statistical study. We systematically assess common hybrid models on medical signal data as well as planar and volumetric images, examining the influence attributable to classical and quantum aspects such as encoding schemes, entanglement, and circuit size. We find that in best-case scenarios, hybrid models show performance comparable to their classical counterparts, however, in most cases, performance metrics deteriorate under the influence of quantum components. Our multi-modal analysis provides realistic insights into the contributions of quantum components and advocates for cautious claims and design choices for hybrid models in near-term applications.","authors":["Dominik Freinberger","Philipp Moser"],"pdf_url":"","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2601.04731v1","updated":"2026-01-08T08:52:37Z","published":"2026-01-08T08:52:37Z","title":"Miner:Mining Intrinsic Mastery for Data-Efficient RL in Large Reasoning Models","summary":"Current critic-free RL methods for large reasoning models suffer from severe inefficiency when training on positive homogeneous prompts (where all rollouts are correct), resulting in waste of rollouts due to zero advantage estimates. We introduce a radically simple yet powerful solution to \\uline{M}ine \\uline{in}trinsic mast\\uline{er}y (Miner), that repurposes the policy's intrinsic uncertainty as a self-supervised reward signal, with no external supervision, auxiliary models, or additional inference cost. Our method pioneers two key innovations: (1) a token-level focal credit assignment mechanism that dynamically amplifies gradients on critical uncertain tokens while suppressing overconfident ones, and (2) adaptive advantage calibration to seamlessly integrate intrinsic and verifiable rewards. Evaluated across six reasoning benchmarks on Qwen3-4B and Qwen3-8B base models, Miner achieves state-of-the-art performance among the other four algorithms, yielding up to \\textbf{4.58} absolute gains in Pass@1 and \\textbf{6.66} gains in Pass@K compared to GRPO. Comparison with other methods targeted at exploration enhancement further discloses the superiority of the two newly proposed innovations. This demonstrates that latent uncertainty exploitation is both necessary and sufficient for efficient and scalable RL training of reasoning models.","authors":["Shuyang Jiang","Yuhao Wang","Ya Zhang","Yanfeng Wang","Yu Wang"],"pdf_url":"","comment":"22 pages"},{"id":"http://arxiv.org/abs/2601.04728v1","updated":"2026-01-08T08:46:42Z","published":"2026-01-08T08:46:42Z","title":"Excess Description Length of Learning Generalizable Predictors","summary":"Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.","authors":["Elizabeth Donoway","Hailey Joren","Fabien Roger","Jan Leike"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.12225v3","updated":"2026-01-08T08:44:58Z","published":"2025-05-18T04:00:35Z","title":"Mining Intrinsic Rewards from LLM Hidden States for Efficient Best-of-N Sampling","summary":"Best-of-N sampling is a powerful method for improving Large Language Model (LLM) performance, but it is often limited by its dependence on massive, text-based reward models. These models are not only computationally expensive but also data-hungry, requiring extensive labeled datasets for training. This creates a significant data challenge, as they overlook a rich, readily available data source: the LLM's own internal hidden states. To address this data and efficiency gap, we introduce SWIFT (Simple Weighted Intrinsic Feedback Technique), a novel and lightweight method that learns a reward function directly from the rich information embedded in LLM hidden states. Operating at the token embedding level, SWIFT employs simple linear layers to effectively distinguish between preferred and dispreferred generations, eliminating the need for computationally intensive text-based modeling. Extensive experiments on standard benchmarks show that SWIFT outperforms existing baselines (12.7% higher accuracy than EurusRM-7B on MATH dataset) while using less than 0.005% of their parameters. Its robust scalability, compatibility with certain closed-source models via logit access, and ability to combine with traditional reward models for additional performance highlight SWIFT's practical value and contribution to more efficient data-driven LLM post-training. Our code is available at https://github.com/aster2024/SWIFT .","authors":["Jizhou Guo","Zhaomin Wu","Hanchen Yang","Philip S. Yu"],"pdf_url":"","comment":"Accepted by KDD 2026 (Research Track). Project page: https://aster2024.github.io/swift-website/"},{"id":"http://arxiv.org/abs/2601.04726v1","updated":"2026-01-08T08:44:07Z","published":"2026-01-08T08:44:07Z","title":"Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning","summary":"Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.","authors":["Yuyang Hu","Jiongnan Liu","Jiejun Tan","Yutao Zhu","Zhicheng Dou"],"pdf_url":"","comment":"19 pages,6 figures"},{"id":"http://arxiv.org/abs/2601.01568v2","updated":"2026-01-08T08:43:41Z","published":"2026-01-04T15:26:15Z","title":"MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning","summary":"Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.","authors":["Chunyu Qiang","Jun Wang","Xiaopeng Wang","Kang Yin","Yuxin Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.21830v4","updated":"2026-01-08T08:42:56Z","published":"2025-10-22T03:37:49Z","title":"GAPO: Robust Advantage Estimation for Real-World Code LLMs","summary":"Reinforcement learning (RL) is widely used for post-training large language models (LLMs) in code editing, where group-relative methods, such as GRPO, are popular due to their critic-free and normalized advantage estimation. However, in real-world code-editing scenarios, reward distributions are often skewed with unpredictable noise, leading to distorted advantage computation and increased rollout outliers. To address this issue, we propose Group Adaptive Policy Optimization (GAPO), which adaptively finds an interval with the highest SNR (Signal to Noise Ratio) per prompt and uses the median of that interval as an adaptive Q to replace the group mean in advantage calculation to reduce noise further. This adaptive Q robustly handles rollout noise while remaining plug-and-play and efficient. We evaluate GAPO on nine instruction-tuned LLMs (3B-14B) using a collected large dataset of 51,844 real-world, history-aware code-editing tasks spanning 10 programming languages. GAPO yields up to 4.35 in-domain (ID) and 5.30 out-of-domain (OOD) exact-match improvements over GRPO and its variant DAPO, while achieving lower clipping ratios and higher GPU throughput. Code: https://github.com/TsingZ0/verl-GAPO.","authors":["Jianqing Zhang","Zhezheng Hao","Wei Xia","Hande Dong","Hong Wang","Chenxing Wei","Yuyan Zhou","Yubin Qi","Qiang Lin","Jian Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.10991v4","updated":"2026-01-08T08:42:42Z","published":"2025-08-14T18:00:25Z","title":"MCP-Guard: A Multi-Stage Defense-in-Depth Framework for Securing Model Context Protocol in Agentic AI","summary":"While Large Language Models (LLMs) have achieved remarkable performance, they remain vulnerable to jailbreak. The integration of Large Language Models (LLMs) with external tools via protocols such as the Model Context Protocol (MCP) introduces critical security vulnerabilities, including prompt injection, data exfiltration, and other threats. To counter these challenges, we propose MCP-GUARD, a robust, layered defense architecture designed for LLM-tool interactions. MCP-GUARD employs a three-stage detection pipeline that balances efficiency with accuracy: it progresses from lightweight static scanning for overt threats and a deep neural detector for semantic attacks, to our fine-tuned E5-based model which achieves 96.01\\% accuracy in identifying adversarial prompts. Finally, an LLM arbitrator synthesizes these signals to deliver the final decision. To enable rigorous training and evaluation, we introduce MCP-ATTACKBENCH, a comprehensive benchmark comprising 70,448 samples augmented by GPT-4. This benchmark simulates diverse real-world attack vectors that circumvent conventional defenses in the MCP paradigm, thereby laying a solid foundation for future research on securing LLM-tool ecosystems.","authors":["Wenpeng Xing","Zhonghao Qi","Yupeng Qin","Yilin Li","Caini Chang","Jiahui Yu","Changting Lin","Zhenzhen Xie","Meng Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04714v1","updated":"2026-01-08T08:30:36Z","published":"2026-01-08T08:30:36Z","title":"ThinkDrive: Chain-of-Thought Guided Progressive Reinforcement Learning Fine-Tuning for Autonomous Driving","summary":"With the rapid advancement of large language models (LLMs) technologies, their application in the domain of autonomous driving has become increasingly widespread. However, existing methods suffer from unstructured reasoning, poor generalization, and misalignment with human driving intent. While Chain-of-Thought (CoT) reasoning enhances decision transparency, conventional supervised fine-tuning (SFT) fails to fully exploit its potential, and reinforcement learning (RL) approaches face instability and suboptimal reasoning depth. We propose ThinkDrive, a CoT guided progressive RL fine-tuning framework for autonomous driving that synergizes explicit reasoning with difficulty-aware adaptive policy optimization. Our method employs a two-stage training strategy. First, we perform SFT using CoT explanations. Then, we apply progressive RL with a difficulty-aware adaptive policy optimizer that dynamically adjusts learning intensity based on sample complexity. We evaluate our approach on a public dataset. The results show that ThinkDrive outperforms strong RL baselines by 1.45%, 1.95%, and 1.01% on exam, easy-exam, and accuracy, respectively. Moreover, a 2B-parameter model trained with our method surpasses the much larger GPT-4o by 3.28% on the exam metric.","authors":["Chang Zhao","Zheming Yang","Yunqing Hu","Qi Guo","Zijian Wang","Pengcheng Li","Wen Ji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04711v1","updated":"2026-01-08T08:27:47Z","published":"2026-01-08T08:27:47Z","title":"DSC2025 -- ViHallu Challenge: Detecting Hallucination in Vietnamese LLMs","summary":"The reliability of large language models (LLMs) in production environments remains significantly constrained by their propensity to generate hallucinations -- fluent, plausible-sounding outputs that contradict or fabricate information. While hallucination detection has recently emerged as a priority in English-centric benchmarks, low-to-medium resource languages such as Vietnamese remain inadequately covered by standardized evaluation frameworks. This paper introduces the DSC2025 ViHallu Challenge, the first large-scale shared task for detecting hallucinations in Vietnamese LLMs. We present the ViHallu dataset, comprising 10,000 annotated triplets of (context, prompt, response) samples systematically partitioned into three hallucination categories: no hallucination, intrinsic, and extrinsic hallucinations. The dataset incorporates three prompt types -- factual, noisy, and adversarial -- to stress-test model robustness. A total of 111 teams participated, with the best-performing system achieving a macro-F1 score of 84.80\\%, compared to a baseline encoder-only score of 32.83\\%, demonstrating that instruction-tuned LLMs with structured prompting and ensemble strategies substantially outperform generic architectures. However, the gap to perfect performance indicates that hallucination detection remains a challenging problem, particularly for intrinsic (contradiction-based) hallucinations. This work establishes a rigorous benchmark and explores a diverse range of detection methodologies, providing a foundation for future research into the trustworthiness and reliability of Vietnamese language AI systems.","authors":["Anh Thi-Hoang Nguyen","Khanh Quoc Tran","Tin Van Huynh","Phuoc Tan-Hoang Nguyen","Cam Tan Nguyen","Kiet Van Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04709v1","updated":"2026-01-08T08:20:44Z","published":"2026-01-08T08:20:44Z","title":"Bridging Temporal and Textual Modalities: A Multimodal Framework for Automated Cloud Failure Root Cause Analysis","summary":"Root cause analysis in modern cloud infrastructure demands sophisticated understanding of heterogeneous data sources, particularly time-series performance metrics that involve core failure signatures. While large language models demonstrate remarkable capabilities in textual reasoning, their discrete token-based architecture creates fundamental incompatibilities with continuous numerical sequences exhibiting temporal dependencies. Current methodologies inadequately address this modality mismatch, constraining the potential of language model-driven automation in incident management workflows. This paper presents a multimodal diagnostic framework that harmonizes time-series representations with pretrained language model embedding spaces. Our approach contributes three technical advances: (1) a semantic compression technique that distills temporal segments into single-token abstractions while preserving pattern semantics, (2) an alignment encoder utilizing gated cross-attention to project time-series features into language model latent space, and (3) a retrieval-augmented diagnostic pipeline that synthesizes aligned embeddings with historical incident knowledge for expert-level failure attribution. Comprehensive evaluation across six cloud system benchmarks demonstrates that our framework achieves leading performance, reaching 48.75% diagnostic accuracy with notable improvements on scenarios involving compound failure modes. The results validate embedding-space alignment as an effective strategy for enabling language models to reason over multimodal telemetry data in production incident response contexts.","authors":["Gijun Park"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04707v1","updated":"2026-01-08T08:19:47Z","published":"2026-01-08T08:19:47Z","title":"MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training","summary":"Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \\boldmath $\\bm{4.6\\,\\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.","authors":["Irfan Ullah","Young-Koo Lee"],"pdf_url":"","comment":"IEEE Access 2025"},{"id":"http://arxiv.org/abs/2511.07267v2","updated":"2026-01-08T08:15:04Z","published":"2025-11-10T16:15:53Z","title":"Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion","summary":"Multi-agent debate (MAD) frameworks have emerged as promising approaches for misinformation detection by simulating adversarial reasoning. While prior work has focused on detection accuracy, it overlooks the importance of helping users understand the reasoning behind factual judgments and develop future resilience. The debate transcripts generated during MAD offer a rich but underutilized resource for transparent reasoning. In this study, we introduce ED2D, an evidence-based MAD framework that extends previous approach by incorporating factual evidence retrieval. More importantly, ED2D is designed not only as a detection framework but also as a persuasive multi-agent system aimed at correcting user beliefs and discouraging misinformation sharing. We compare the persuasive effects of ED2D-generated debunking transcripts with those authored by human experts. Results demonstrate that ED2D outperforms existing baselines across three misinformation detection benchmarks. When ED2D generates correct predictions, its debunking transcripts exhibit persuasive effects comparable to those of human experts; However, when ED2D misclassifies, its accompanying explanations may inadvertently reinforce users'misconceptions, even when presented alongside accurate human explanations. Our findings highlight both the promise and the potential risks of deploying MAD systems for misinformation intervention. We further develop a public community website to help users explore ED2D, fostering transparency, critical thinking, and collaborative fact-checking.","authors":["Chen Han","Yijia Ma","Jin Tan","Wenzhen Zheng","Xijin Tang"],"pdf_url":"","comment":"This paper has been accepted to AAAI 2026"}],"Systems and Control":[{"id":"http://arxiv.org/abs/2506.20780v2","updated":"2026-01-08T18:48:00Z","published":"2025-06-25T19:10:23Z","title":"Noise-Tolerant Hybrid Approach for Data-Driven Predictive Control","summary":"This paper focuses on a key challenge in hybrid data-driven predictive control: the effect of measurement noise on Hankel matrices. While noise is handled in direct and indirect methods, hybrid approaches often overlook its impact during trajectory estimation. We propose a Noise-Tolerant Data-Driven Predictive Control (NTDPC) framework that integrates singular value decomposition to separate system dynamics from noise within reduced-order Hankel matrices. This enables accurate prediction with shorter data horizons and lower computational effort. A sensitivity index is introduced to support horizon selection under different noise levels. Simulation results indicate improved robustness and efficiency compared to existing hybrid methods.","authors":["Mahmood Mazare","Hossein Ramezani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05087v1","updated":"2026-01-08T16:35:43Z","published":"2026-01-08T16:35:43Z","title":"Online Bayesian Learning of Agent Behavior in Differential Games","summary":"This work introduces an online Bayesian game-theoretic method for behavior identification in multi-agent dynamical systems. By casting Hamilton-Jacobi-Bellman optimality conditions as linear-in-parameter residuals, the method enables fast sequential Bayesian updates, uncertainty-aware inference, and robust prediction from limited, noisy data-without history stacks. The approach accommodates nonlinear dynamics and nonquadratic value functions through basis expansions, providing flexible models. Experiments, including linear-quadratic and nonlinear shared-control scenarios, demonstrate accurate prediction with quantified uncertainty, highlighting the method's relevance for adaptive interaction and real-time decision making.","authors":["Francesco Bianchin","Robert Lefringhausen","Sandra Hirche"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05084v1","updated":"2026-01-08T16:29:08Z","published":"2026-01-08T16:29:08Z","title":"Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication","summary":"Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.","authors":["Niloufar Alavi","Swati Shah","Rezvan Alamian","Stefan Goetz"],"pdf_url":"","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2601.05070v1","updated":"2026-01-08T16:14:22Z","published":"2026-01-08T16:14:22Z","title":"Effect of Dispatch Decisions on Small-Signal Stability of Converter-Dominated Power Systems","summary":"Small-signal stability of modern converter-dominated power systems has been the subject of extensive research, particularly from the perspective of device-level control design for grid-forming (GFM) and grid-following (GFL) converters. However, the influence of power flow variables on system stability has received limited attention. Conventional small-signal stability analyses are typically conducted at a specific operating point, emphasizing the selection of control or system design parameters while neglecting the sensitivity of stability characteristics to operating conditions. This paper seeks to bridge this gap by systematically investigating the impact of dispatch decisions on the small-signal stability of converter-based power systems. Our findings are first illustrated on a three-bus system and then validated on the standard IEEE 39-bus test system to demonstrate scalability. Across the test systems, we find that high-voltage capacitive operation of GFL converters limits its active power injection, whereas inductive operation permits higher injections, and it is generally preferable for the GFM converter to supply more active power.","authors":["Maitraya Avadhut Desai","Ognjen Stanojev","Simon Muntwiler","Gabriela Hug"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05056v1","updated":"2026-01-08T15:58:16Z","published":"2026-01-08T15:58:16Z","title":"ZIVR: An Incremental Variance Reduction Technique For Zeroth-Order Composite Problems","summary":"This paper investigates zeroth-order (ZO) finite-sum composite optimization. Recently, variance reduction techniques have been applied to ZO methods to mitigate the non-vanishing variance of 2-point estimators in constrained/composite optimization, yielding improved convergence rates. However, existing ZO variance reduction methods typically involve batch sampling of size at least $Θ(n)$ or $Θ(d)$, which can be computationally prohibitive for large-scale problems. In this work, we propose a general variance reduction framework, Zeroth-Order Incremental Variance Reduction (ZIVR), which supports flexible implementations$\\unicode{x2014}$including a pure 2-point zeroth-order algorithm that eliminates the need for large batch sampling. Furthermore, we establish comprehensive convergence guarantees for ZIVR across strongly-convex, convex, and non-convex settings that match their first-order counterparts. Numerical experiments validate the effectiveness of our proposed algorithm.","authors":["Silan Zhang","Yujie Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04957v1","updated":"2026-01-08T14:02:34Z","published":"2026-01-08T14:02:34Z","title":"Safe Reinforcement Learning Beyond Baseline Control: A Hierarchical Framework for Space Triangle Tethered Formation System","summary":"Triangular tethered formation system (TTFS) provide a promising platform for deep space exploration and distributed sensing due to its intrinsic spatial-orientation stability and capability of adjusting distances among node satellites through deployment and retrieval of tethers. However, due to the coupled tether-satellite dynamics and disturbance sensitivity of TTFS, traditional control methods struggle to achieve a balanced trade-off among configuration accuracy requirements, tension constraints, and energy efficiency consumption throughout the deployment process.In this paper, a novel model-reference reinforcement learning control framework is proposed for TTFS. By integrating baseline model-based control with a Soft Actor-Critic (SAC) compensator, the proposed method simultaneously achieves high-precision tracking, fuel efficiency, and compliance with tension limits. A hierarchical training scheme is developed to address the convergence difficulties arising from strongly coupled states in centralized training, while tailored reward functions, reset conditions, and normalization criteria are designed to accelerate training convergence. Closed-loop stability of the overall control law is rigorously proven using Lyapunov methods. Simulation results demonstrate that the proposed controller reduces steady-state tracking errors by over 96% for tethers and 99% for node satellites, while cutting fuel consumption by two orders of magnitude compared with the baseline method. These results validate the effectiveness and stability of the proposed approach for TTFS deployment control.","authors":["Xinyi Tao","Panfeng Huang","Fan Zhang"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2601.04817v1","updated":"2026-01-08T10:53:47Z","published":"2026-01-08T10:53:47Z","title":"Towards Sustainable 6G: A Holistic View of Trade-offs and Enablers","summary":"The sixth generation of mobile networks (6G) can play a central role in shaping a sustainable future, the most compelling contemporary challenge. Connecting the unconnected, reducing carbon emissions of vertical sectors, and allowing heterogeneous types of intelligence (including humans) to safely and constructively interact in complex environments, are only a few of the several challenges that can be supported by 6G. However, this requires a careful design that balances positive and negative impacts of 6G, towards a sustainable and sustainability-enabling technology. This paper presents a holistic view that translates the complex interplay between the 6G enabling effects and the sustainability of 6G by design, into concrete trade-offs and research questions. Starting from today's challenges for society and associated key values, we unfold the dilemma into a set of technical trade-offs, whose solutions span from technological innovations to standardization actions towards applicability.","authors":["Mattia Merluzzi","Olivier Bouchet","Ali Balador","Gilles Callebaut","Anastasius Gavras","Liesbet Van der Perre","Albert Banchs","Mauro Renato Boldi","Emilio Calvanese Strinati","Bahare M Khorsandi","Marja Matinmikko-Blue","Lars Christoph Schmelz"],"pdf_url":"","comment":"This work has been submitted to IEEE Communications Magazine"},{"id":"http://arxiv.org/abs/2512.10580v2","updated":"2026-01-08T10:49:49Z","published":"2025-12-11T12:18:48Z","title":"Structural Methods for handling mode changes in multimode DAE systems","summary":"Hybrid systems are an important concept in Cyber-Physical Systems modeling, for which multiphysics modeling from first principles and the reuse of models from libraries are key. To achieve this, DAEs must be used to specify the dynamics in each discrete state (or mode in our context). This led to the development of DAE-based equational languages supporting multiple modes, of which Modelica is a popular standard. Mode switching can be time- or state-based. Impulsive behaviors can occur at mode changes. While mode changes are well understood in particular physics (e.g., contact mechanics), this is not the case in physics-agnostic paradigms such as Modelica. This situation causes difficulties for the compilation of programs, often requiring users to manually smooth out mode changes. In this paper, we propose a novel approach for the hot restart at mode changes in such paradigms. We propose a mathematical meaning for hot restarts (such a mathematical meaning does not exist in general), as well as a combined structural and impulse analysis for mode changes, generating the hot restart even in the presence of impulses. Our algorithm detects at compile time if the mode change is insufficiently specified, in which case it returns diagnostics information to the user.","authors":["Albert Benveniste","Benoit Caillaud","Yahao Chen","Khalil Ghorbal","Mathias Malandain"],"pdf_url":"","comment":"53 pages, 3 figures"},{"id":"http://arxiv.org/abs/2601.04796v1","updated":"2026-01-08T10:24:12Z","published":"2026-01-08T10:24:12Z","title":"Matrix-Valued Passivity Indices: Foundations, Properties, and Stability Implications","summary":"The passivity index, a quantitative measure of a system's passivity deficiency or excess, has been widely used in stability analysis and control. Existing studies mostly rely on scalar forms of indices, which are restrictive for multi-input, multi-output (MIMO) systems. This paper extends the classical scalar indices to a systematic matrix-valued framework, referred to as passivity matrices. A broad range of classical results in passivity theory can be naturally generalized in this framework. We first show that, under the matrix representation, passivity indices essentially correspond to the curvature of the dissipativity functional under a second-variation interpretation. This result reveals that the intrinsic geometric structure of passivity consists of its directions and intensities, which a scalar index cannot fully capture. For linear time-invariant (LTI) systems, we examine the structural properties of passivity matrices with respect to the Loewner partial order and propose two principled criteria for selecting representative matrices. Compared with conventional scalar indices, the matrix-valued indices capture the passivity coupling among different input-output channels in MIMO systems and provide a more comprehensive description of system passivity. This richer information leads to lower passivation effort and less conservative stability assessment.","authors":["Xi Ru","Xiaoyu Peng","Xinghua Chen","Zhaojian Wang","Peng Yang","Feng Liu"],"pdf_url":"","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2508.13593v2","updated":"2026-01-08T10:22:25Z","published":"2025-08-19T07:59:27Z","title":"Repeater Swarm-Assisted Cellular Systems: Interaction Stability and Performance Analysis","summary":"We consider a cellular massive MIMO system where swarms of wireless repeaters are deployed to improve coverage. These repeaters are full-duplex relays with small form factors that receive and instantaneously retransmit signals. They can be deployed in a plug-and-play manner at low cost, while being transparent to the network--conceptually they are active channel scatterers with amplification capabilities. Two fundamental questions need to be addressed in repeater deployments: (I) How can we prevent destructive effects of positive feedback caused by inter-repeater interaction (i.e., each repeater receives and amplifies signals from others)? (ii) How much performance improvement can be achieved given that repeaters also inject noise and may introduce more interference? To answer these questions, we first derive a generalized Nyquist stability criterion for the repeater swarm system, and provide an easy-to-check stability condition. Then, we study the uplink performance and develop an efficient iterative algorithm that jointly optimizes the repeater gains, user transmit powers, and receive combining weights to maximize the weighted sum rate while ensuring system stability. Numerical results corroborate our theoretical findings and show that the repeaters can significantly improve the system performance, both in sub-6 GHz and millimeter-wave bands. The results also warrant careful deployment to fully realize the benefits of repeaters, for example, by ensuring a high probability of line-of-sight links between repeaters and the base station.","authors":["Jianan Bai","Anubhab Chowdhury","Anders Hansson","Erik G. Larsson"],"pdf_url":"","comment":"16 pages, 13 figures. Accepted for publication in IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2511.08900v2","updated":"2026-01-08T07:30:49Z","published":"2025-11-12T02:20:47Z","title":"An Improved Dual-Attention Transformer-LSTM for Small-Sample Prediction of Modal Frequency and Actual Anchor Radius in Micro Hemispherical Resonator Design","summary":"The high-temperature glassblowing-fabricated micro hemispherical resonator (MHR) exhibits high symmetry and high Q-value for precision inertial navigation. However, MHR design entails a comprehensive evaluation of multiple possible configurations and demands extremely time-consuming simulation of key parameters combination. To address this problem, this paper proposed a rapid prediction method of modal frequency and actual anchor radius of designed MHR using an improved Transformer-LSTM (Long Short-Term Memory) model for rapid design sizing. High-temperature-induced softening deformation at the anchor point reduces the actual anchor radius below the designed value. By varying key parameters such as resonator height, anchor radius and edge thickness, finite element glassblowing simulation and modal analyse were conducted to obtain the first six modal frequencies and actual anchor radius. To address regression prediction challenges with limited data, dual multi-head self-attention (MHSA) mechanisms replaced the transformer's standard Feed Forward Network, to improve hidden information capture for high-accuracy predictions of modal frequencies and anchor radius. By checking fabricating feasibility of anchor radius and allowing rapid modal characteristics evaluation without interference, ablation and comparative experiments validated the method's superiority, as an effective support of MHR design. Design optimization experiments demonstrate a prediction accuracy of 96.35%, with computational time reduced to 1/48,000 of traditional finite element methods, significantly improving design efficiency. This study offers a new paradigm for intelligent Micro-Electro-Mechanical System (MEMS) device design under complex process conditions.","authors":["Yuyi Yao","Gongliu Yang","Runzhuo Xu","Yongqiang Tu","Haozhou Mo"],"pdf_url":"","comment":"Due to the fact that the results of this article are from simulation experiments and there is a certain gap with the actual experimental results, this article has not been corrected. Therefore, the authors Yang and Tu have not given final consent to this submitted version, nor have they authorized the submitter to publish this public preprint"},{"id":"http://arxiv.org/abs/2601.01410v3","updated":"2026-01-08T04:12:43Z","published":"2026-01-04T07:30:50Z","title":"Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems","summary":"Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics mask this operational asymmetry. We introduce a grid-specific evaluation framework (Asymmetric MAPE, Under-Prediction Rate, and Reserve Margin) that directly measures operational risk rather than statistical accuracy alone. Using this framework, we conduct a systematic evaluation of Mamba-based State Space Models for California grid forecasting on a weather-aligned CA ISO-TAC dataset spanning Nov 2023 to Nov 2025 (84,498 hourly records across 5 transmission areas). Our analysis reveals that standard accuracy metrics are poor proxies for operational safety: models with identical MAPE can require vastly different reserve margins. We demonstrate that forecast errors are weakly but statistically significantly associated with temperature (r = 0.16), motivating weather-aware modeling rather than loss function modification alone. The S-Mamba model achieves the lowest 99.5th-percentile reserve margin (14.12 percent) compared to 16.66 percent for iTransformer, demonstrating superior forecast reliability under a 99.5th-percentile tail-risk reserve proxy.","authors":["Jisoo Lee","Sunki Hong"],"pdf_url":"","comment":"25 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2601.04505v1","updated":"2026-01-08T02:18:43Z","published":"2026-01-08T02:18:43Z","title":"CircuitLM: A Multi-Agent LLM-Aided Design Framework for Generating Circuit Schematics from Natural Language Prompts","summary":"Generating accurate circuit schematics from high-level natural language descriptions remains a persistent challenge in electronics design, as large language models (LLMs) frequently hallucinate in granular details, violate electrical constraints, and produce non-machine-readable outputs. We present CircuitLM, a novel multi-agent LLM-aided circuit design pipeline that translates user prompts into structured, visually interpretable CircuitJSON schematics through five sequential stages: (i) LLM-based component identification, (ii) canonical pinout retrieval, (iii) chain-of-thought reasoning by an electronics expert agent, (iv) JSON schematic synthesis, and (v) force-directed SVG visualization. Anchored by a curated, embedding-powered component knowledge base. While LLMs often violate electrical constraints, CircuitLM bridges this gap by grounding generation in a verified and dynamically extensible component database, initially comprising 50 components. To ensure safety, we incorporate a hybrid evaluation framework, namely Dual-Metric Circuit Validation (DMCV), validated against human-expert assessments, which achieves high fidelity in microcontroller-centric designs. We evaluate the system on 100 diverse embedded-systems prompts across six LLMs and introduce DMCV to assess both structural and electrical validity. This work bridges natural language input to deployable hardware designs, enabling reliable circuit prototyping by non-experts. Our code and data will be made public upon acceptance.","authors":["Khandakar Shakib Al Hasan","Syed Rifat Raiyan","Hasin Mahtab Alvee","Wahid Sadik"],"pdf_url":"","comment":"Under review, 13 pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2601.04504v1","updated":"2026-01-08T02:16:29Z","published":"2026-01-08T02:16:29Z","title":"Definition and Formulation of Inertia Service Incorporating Inverter-Based Resources","summary":"Increasing concerns over the scarcity of inertia have motivated the procurement of inertia as an ancillary service (AS). Despite numerous academic and practical efforts, there remains a lack of consensus regarding the definition and treatment of inertia service in market operations, particularly the specification of inertia variables and the separation between synchronous inertia (SI) from synchronous generators and virtual inertia (VI) from inverter-based resources. To address these issues, this paper proposes a power-oriented (P-oriented) definition based on inertial response, which establishes conceptual consistency between SI and VI and makes the inertia service commensurable with other ASs. This definition explicitly incorporates both positive and negative inertial responses during frequency drop events. We then formulate a security-constrained economic dispatch framework based on this P-oriented definition and demonstrate its practical effectiveness through simulations. Case studies on a modified IEEE 30-bus system show that the proposed bidirectional service definition ensures price signals that reflect the economic value of inertial provision.","authors":["Sojin Park","Ross Baldick","Hunyoung Shin"],"pdf_url":"","comment":"10 pages, 5 figures"}],"Robotics":[{"id":"http://arxiv.org/abs/2601.05248v1","updated":"2026-01-08T18:59:53Z","published":"2026-01-08T18:59:53Z","title":"LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model","summary":"Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0","authors":["Zhuoyang Liu","Jiaming Liu","Hao Chen","Ziyu Guo","Chengkai Hou","Chenyang Gu","Jiale Yu","Xiangju Mi","Renrui Zhang","Zhengping Che","Jian Tang","Pheng-Ann Heng","Shanghang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05243v1","updated":"2026-01-08T18:59:30Z","published":"2026-01-08T18:59:30Z","title":"Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration","summary":"Functional grasping with dexterous robotic hands is a key capability for enabling tool use and complex manipulation, yet progress has been constrained by two persistent bottlenecks: the scarcity of large-scale datasets and the absence of integrated semantic and geometric reasoning in learned models. In this work, we present CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration. At the core of our approach is a correspondence-based data engine that generates diverse, high-quality training data in simulation. Based on the human demonstration, our data engine generates diverse object instances of the same category, transfers the expert grasp to the generated objects through correspondence estimation, and adapts the grasp through optimization. Building on the generated data, we introduce a multimodal prediction network that integrates visual and geometric information. By devising a local-global fusion module and an importance-aware sampling mechanism, we enable robust and computationally efficient prediction of functional dexterous grasps. Through extensive experiments across various object categories, we demonstrate that CorDex generalizes well to unseen object instances and significantly outperforms state-of-the-art baselines.","authors":["Xingyi He","Adhitya Polavaram","Yunhao Cao","Om Deshmukh","Tianrui Wang","Xiaowei Zhou","Kuan Fang"],"pdf_url":"","comment":"Project Page: https://cordex-manipulation.github.io/"},{"id":"http://arxiv.org/abs/2601.05241v1","updated":"2026-01-08T18:59:22Z","published":"2026-01-08T18:59:22Z","title":"RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation","summary":"The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.","authors":["Boyang Wang","Haoran Zhang","Shujie Zhang","Jinkun Hao","Mingda Jia","Qi Lv","Yucheng Mao","Zhaoyang Lyu","Jia Zeng","Xudong Xu","Jiangmiao Pang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.24164v4","updated":"2026-01-08T17:01:05Z","published":"2024-10-31T17:22:30Z","title":"$π_0$: A Vision-Language-Action Flow Model for General Robot Control","summary":"Robot learning holds tremendous promise to unlock the full potential of flexible, general, and dexterous robot systems, as well as to address some of the deepest questions in artificial intelligence. However, bringing robot learning to the level of generality required for effective real-world systems faces major obstacles in terms of data, generalization, and robustness. In this paper, we discuss how generalist robot policies (i.e., robot foundation models) can address these challenges, and how we can design effective generalist robot policies for complex and highly dexterous tasks. We propose a novel flow matching architecture built on top of a pre-trained vision-language model (VLM) to inherit Internet-scale semantic knowledge. We then discuss how this model can be trained on a large and diverse dataset from multiple dexterous robot platforms, including single-arm robots, dual-arm robots, and mobile manipulators. We evaluate our model in terms of its ability to perform tasks in zero shot after pre-training, follow language instructions from people and from a high-level VLM policy, and its ability to acquire new skills via fine-tuning. Our results cover a wide variety of tasks, such as laundry folding, table cleaning, and assembling boxes.","authors":["Kevin Black","Noah Brown","Danny Driess","Adnan Esmail","Michael Equi","Chelsea Finn","Niccolo Fusai","Lachy Groom","Karol Hausman","Brian Ichter","Szymon Jakubczak","Tim Jones","Liyiming Ke","Sergey Levine","Adrian Li-Bell","Mohith Mothukuri","Suraj Nair","Karl Pertsch","Lucy Xiaoyang Shi","James Tanner","Quan Vuong","Anna Walling","Haohuan Wang","Ury Zhilinsky"],"pdf_url":"","comment":"See project website for videos: https://physicalintelligence.company/blog/pi0 Published in RSS 2025"},{"id":"http://arxiv.org/abs/2601.05083v1","updated":"2026-01-08T16:28:24Z","published":"2026-01-08T16:28:24Z","title":"Driving on Registers","summary":"We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.","authors":["Ellington Kirby","Alexandre Boulch","Yihong Xu","Yuan Yin","Gilles Puy","Éloi Zablocki","Andrei Bursuc","Spyros Gidaris","Renaud Marlet","Florent Bartoccioni","Anh-Quan Cao","Nermin Samet","Tuan-Hung VU","Matthieu Cord"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05074v1","updated":"2026-01-08T16:18:10Z","published":"2026-01-08T16:18:10Z","title":"Compensation Effect Amplification Control (CEAC): A movement-based approach for coordinated position and velocity control of the elbow of upper-limb prostheses","summary":"Despite advances in upper-limb (UL) prosthetic design, achieving intuitive control of intermediate joints - such as the wrist and elbow - remains challenging, particularly for continuous and velocity-modulated movements. We introduce a novel movement-based control paradigm entitled Compensation Effect Amplification Control (CEAC) that leverages users' trunk flexion and extension as input for controlling prosthetic elbow velocity. Considering that the trunk can be both a functional and compensatory joint when performing upper-limb actions, CEAC amplifies the natural coupling between trunk and prosthesis while introducing a controlled delay that allows users to modulate both the position and velocity of the prosthetic joint. We evaluated CEAC in a generic drawing task performed by twelve able-bodied participants using a supernumerary prosthesis with an active elbow. Additionally a multiple-target-reaching task was performed by a subset of ten participants. Results demonstrate task performances comparable to those obtained with natural arm movements, even when gesture velocity or drawing size were varied, while maintaining ergonomic trunk postures. Analysis revealed that CEAC effectively restores joint coordinated action, distributes movement effort between trunk and elbow, enabling intuitive trajectory control without requiring extreme compensatory movements. Overall, CEAC offers a promising control strategy for intermediate joints of UL prostheses, particularly in tasks requiring continuous and precise coordination.","authors":["Julian Kulozik","Nathanaël Jarrassé"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05072v1","updated":"2026-01-08T16:17:48Z","published":"2026-01-08T16:17:48Z","title":"DAVOS: An Autonomous Vehicle Operating System in the Vehicle Computing Era","summary":"Vehicle computing represents a fundamental shift in how autonomous vehicles are designed and deployed, transforming them from isolated transportation systems into mobile computing platforms that support both safety-critical, real-time driving and data-centric services. In this setting, vehicles simultaneously support real-time driving pipelines and a growing set of data-driven applications, placing increased responsibility on the vehicle operating system to coordinate computation, data movement, storage, and access. These demands highlight recurring system considerations related to predictable execution, data and execution protection, efficient handling of high-rate sensor data, and long-term system evolvability, commonly summarized as Safety, Security, Efficiency, and Extensibility (SSEE). Existing vehicle operating systems and runtimes address these concerns in isolation, resulting in fragmented software stacks that limit coordination between autonomy workloads and vehicle data services. This paper presents DAVOS, the Delaware Autonomous Vehicle Operating System, a unified vehicle operating system architecture designed for the vehicle computing context. DAVOS provides a cohesive operating system foundation that supports both real-time autonomy and extensible vehicle computing within a single system framework.","authors":["Yuxin Wang","Yuankai He","Boyang Tian","Lichen Xian","Weisong Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.16680v3","updated":"2026-01-08T15:43:41Z","published":"2025-04-23T12:58:15Z","title":"Uncertainty-Aware Robotic World Model Makes Offline Model-Based Reinforcement Learning Work on Real Robots","summary":"Reinforcement Learning (RL) has achieved impressive results in robotics, yet high-performing pipelines remain highly task-specific, with little reuse of prior data. Offline Model-based RL (MBRL) offers greater data efficiency by training policies entirely from existing datasets, but suffers from compounding errors and distribution shift in long-horizon rollouts. Although existing methods have shown success in controlled simulation benchmarks, robustly applying them to the noisy, biased, and partially observed datasets typical of real-world robotics remains challenging. We present a principled pipeline for making offline MBRL effective on physical robots. Our RWM-U extends autoregressive world models with epistemic uncertainty estimation, enabling temporally consistent multi-step rollouts with uncertainty effectively propagated over long horizons. We combine RWM-U with MOPO-PPO, which adapts uncertainty-penalized policy optimization to the stable, on-policy PPO framework for real-world control. We evaluate our approach on diverse manipulation and locomotion tasks in simulation and on real quadruped and humanoid, training policies entirely from offline datasets. The resulting policies consistently outperform model-free and uncertainty-unaware model-based baselines, and fusing real-world data in model learning further yields robust policies that surpass online model-free baselines trained solely in simulation.","authors":["Chenhao Li","Andreas Krause","Marco Hutter"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05014v1","updated":"2026-01-08T15:16:18Z","published":"2026-01-08T15:16:18Z","title":"The RoboSense Challenge: Sense Anything, Navigate Anywhere, Adapt Across Platforms","summary":"Autonomous systems are increasingly deployed in open and dynamic environments -- from city streets to aerial and indoor spaces -- where perception models must remain reliable under sensor noise, environmental variation, and platform shifts. However, even state-of-the-art methods often degrade under unseen conditions, highlighting the need for robust and generalizable robot sensing. The RoboSense 2025 Challenge is designed to advance robustness and adaptability in robot perception across diverse sensing scenarios. It unifies five complementary research tracks spanning language-grounded decision making, socially compliant navigation, sensor configuration generalization, cross-view and cross-modal correspondence, and cross-platform 3D perception. Together, these tasks form a comprehensive benchmark for evaluating real-world sensing reliability under domain shifts, sensor failures, and platform discrepancies. RoboSense 2025 provides standardized datasets, baseline models, and unified evaluation protocols, enabling large-scale and reproducible comparison of robust perception methods. The challenge attracted 143 teams from 85 institutions across 16 countries, reflecting broad community engagement. By consolidating insights from 23 winning solutions, this report highlights emerging methodological trends, shared design principles, and open challenges across all tracks, marking a step toward building robots that can sense reliably, act robustly, and adapt across platforms in real-world environments.","authors":["Lingdong Kong","Shaoyuan Xie","Zeying Gong","Ye Li","Meng Chu","Ao Liang","Yuhao Dong","Tianshuai Hu","Ronghe Qiu","Rong Li","Hanjiang Hu","Dongyue Lu","Wei Yin","Wenhao Ding","Linfeng Li","Hang Song","Wenwei Zhang","Yuexin Ma","Junwei Liang","Zhedong Zheng","Lai Xing Ng","Benoit R. Cottereau","Wei Tsang Ooi","Ziwei Liu","Zhanpeng Zhang","Weichao Qiu","Wei Zhang","Ji Ao","Jiangpeng Zheng","Siyu Wang","Guang Yang","Zihao Zhang","Yu Zhong","Enzhu Gao","Xinhan Zheng","Xueting Wang","Shouming Li","Yunkai Gao","Siming Lan","Mingfei Han","Xing Hu","Dusan Malic","Christian Fruhwirth-Reisinger","Alexander Prutsch","Wei Lin","Samuel Schulter","Horst Possegger","Linfeng Li","Jian Zhao","Zepeng Yang","Yuhang Song","Bojun Lin","Tianle Zhang","Yuchen Yuan","Chi Zhang","Xuelong Li","Youngseok Kim","Sihwan Hwang","Hyeonjun Jeong","Aodi Wu","Xubo Luo","Erjia Xiao","Lingfeng Zhang","Yingbo Tang","Hao Cheng","Renjing Xu","Wenbo Ding","Lei Zhou","Long Chen","Hangjun Ye","Xiaoshuai Hao","Shuangzhi Li","Junlong Shen","Xingyu Li","Hao Ruan","Jinliang Lin","Zhiming Luo","Yu Zang","Cheng Wang","Hanshi Wang","Xijie Gong","Yixiang Yang","Qianli Ma","Zhipeng Zhang","Wenxiang Shi","Jingmeng Zhou","Weijun Zeng","Kexin Xu","Yuchen Zhang","Haoxiang Fu","Ruibin Hu","Yanbiao Ma","Xiyan Feng","Wenbo Zhang","Lu Zhang","Yunzhi Zhuge","Huchuan Lu","You He","Seungjun Yu","Junsung Park","Youngsun Lim","Hyunjung Shim","Faduo Liang","Zihang Wang","Yiming Peng","Guanyu Zong","Xu Li","Binghao Wang","Hao Wei","Yongxin Ma","Yunke Shi","Shuaipeng Liu","Dong Kong","Yongchun Lin","Huitong Yang","Liang Lei","Haoang Li","Xinliang Zhang","Zhiyong Wang","Xiaofeng Wang","Yuxia Fu","Yadan Luo","Djamahl Etchegaray","Yang Li","Congfei Li","Yuxiang Sun","Wenkai Zhu","Wang Xu","Linru Li","Longjie Liao","Jun Yan","Benwu Wang","Xueliang Ren","Xiaoyu Yue","Jixian Zheng","Jinfeng Wu","Shurui Qin","Wei Cong","Yao He"],"pdf_url":"","comment":"Official IROS 2025 RoboSense Challenge Report; 51 pages, 37 figures, 5 tables; Competition Website at https://robosense2025.github.io/"},{"id":"http://arxiv.org/abs/2505.22094v7","updated":"2026-01-08T14:39:03Z","published":"2025-05-28T08:17:16Z","title":"ReinFlow: Fine-tuning Flow Matching Policy with Online Reinforcement Learning","summary":"We propose ReinFlow, a simple yet effective online reinforcement learning (RL) framework that fine-tunes a family of flow matching policies for continuous robotic control. Derived from rigorous RL theory, ReinFlow injects learnable noise into a flow policy's deterministic path, converting the flow into a discrete-time Markov Process for exact and straightforward likelihood computation. This conversion facilitates exploration and ensures training stability, enabling ReinFlow to fine-tune diverse flow model variants, including Rectified Flow [35] and Shortcut Models [19], particularly at very few or even one denoising step. We benchmark ReinFlow in representative locomotion and manipulation tasks, including long-horizon planning with visual input and sparse reward. The episode reward of Rectified Flow policies obtained an average net growth of 135.36% after fine-tuning in challenging legged locomotion tasks while saving denoising steps and 82.63% of wall time compared to state-of-the-art diffusion RL fine-tuning method DPPO [43]. The success rate of the Shortcut Model policies in state and visual manipulation tasks achieved an average net increase of 40.34% after fine-tuning with ReinFlow at four or even one denoising step, whose performance is comparable to fine-tuned DDIM policies while saving computation time for an average of 23.20%. Project webpage: https://reinflow.github.io/","authors":["Tonghe Zhang","Chao Yu","Sichang Su","Yu Wang"],"pdf_url":"","comment":"38 pages"},{"id":"http://arxiv.org/abs/2601.04982v1","updated":"2026-01-08T14:35:17Z","published":"2026-01-08T14:35:17Z","title":"When to Act: Calibrated Confidence for Reliable Human Intention Prediction in Assistive Robotics","summary":"Assistive devices must determine both what a user intends to do and how reliable that prediction is before providing support. We introduce a safety-critical triggering framework based on calibrated probabilities for multimodal next-action prediction in Activities of Daily Living. Raw model confidence often fails to reflect true correctness, posing a safety risk. Post-hoc calibration aligns predicted confidence with empirical reliability and reduces miscalibration by about an order of magnitude without affecting accuracy. The calibrated confidence drives a simple ACT/HOLD rule that acts only when reliability is high and withholds assistance otherwise. This turns the confidence threshold into a quantitative safety parameter for assisted actions and enables verifiable behavior in an assistive control loop.","authors":["Johannes A. Gaus","Winfried Ilg","Daniel Haeufle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04948v1","updated":"2026-01-08T13:54:22Z","published":"2026-01-08T13:54:22Z","title":"SKATER: Synthesized Kinematics for Advanced Traversing Efficiency on a Humanoid Robot via Roller Skate Swizzles","summary":"Although recent years have seen significant progress of humanoid robots in walking and running, the frequent foot strikes with ground during these locomotion gaits inevitably generate high instantaneous impact forces, which leads to exacerbated joint wear and poor energy utilization. Roller skating, as a sport with substantial biomechanical value, can achieve fast and continuous sliding through rational utilization of body inertia, featuring minimal kinetic energy loss. Therefore, this study proposes a novel humanoid robot with each foot equipped with a row of four passive wheels for roller skating. A deep reinforcement learning control framework is also developed for the swizzle gait with the reward function design based on the intrinsic characteristics of roller skating. The learned policy is first analyzed in simulation and then deployed on the physical robot to demonstrate the smoothness and efficiency of the swizzle gait over traditional bipedal walking gait in terms of Impact Intensity and Cost of Transport during locomotion. A reduction of $75.86\\%$ and $63.34\\%$ of these two metrics indicate roller skating as a superior locomotion mode for enhanced energy efficiency and joint longevity.","authors":["Junchi Gu","Feiyang Yuan","Weize Shi","Tianchen Huang","Haopeng Zhang","Xiaohu Zhang","Yu Wang","Wei Gao","Shiwu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17435v2","updated":"2026-01-08T12:38:18Z","published":"2025-12-19T10:40:16Z","title":"ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination","summary":"Visual navigation is a fundamental capability for autonomous home-assistance robots, enabling long-horizon tasks such as object search. While recent methods have leveraged Large Language Models (LLMs) to incorporate commonsense reasoning and improve exploration efficiency, their planning remains constrained by textual representations, which cannot adequately capture spatial occupancy or scene geometry--critical factors for navigation decisions. We explore whether Vision-Language Models (VLMs) can achieve mapless visual navigation using only onboard RGB/RGB-D streams, unlocking their potential for spatial perception and planning. We achieve this through an imagination-powered navigation framework, ImagineNav++, which imagines future observation images from candidate robot views and translates navigation planning into a simple best-view image selection problem for VLMs. First, a future-view imagination module distills human navigation preferences to generate semantically meaningful viewpoints with high exploration potential. These imagined views then serve as visual prompts for the VLM to identify the most informative viewpoint. To maintain spatial consistency, we develop a selective foveation memory mechanism, which hierarchically integrates keyframe observations via a sparse-to-dense framework, constructing a compact yet comprehensive memory for long-term spatial reasoning. This approach transforms goal-oriented navigation into a series of tractable point-goal navigation tasks. Extensive experiments on open-vocabulary object and instance navigation benchmarks show that ImagineNav++ achieves SOTA performance in mapless settings, even surpassing most map-based methods, highlighting the importance of scene imagination and memory in VLM-based spatial reasoning.","authors":["Teng Wang","Xinxin Zhao","Wenzhe Cai","Changyin Sun"],"pdf_url":"","comment":"17 pages, 10 figures. arXiv admin note: text overlap with arXiv:2410.09874"},{"id":"http://arxiv.org/abs/2601.04881v1","updated":"2026-01-08T12:29:21Z","published":"2026-01-08T12:29:21Z","title":"Zero Wrench Control via Wrench Disturbance Observer for Learning-free Peg-in-hole Assembly","summary":"This paper proposes a Dynamic Wrench Disturbance Observer (DW-DOB) designed to achieve highly sensitive zero-wrench control in contact-rich manipulation. By embedding task-space inertia into the observer nominal model, DW-DOB cleanly separates intrinsic dynamic reactions from true external wrenches. This preserves sensitivity to small forces and moments while ensuring robust regulation of contact wrenches. A passivity-based analysis further demonstrates that DW-DOB guarantees stable interactions under dynamic conditions, addressing the shortcomings of conventional observers that fail to compensate for inertial effects. Peg-in-hole experiments at industrial tolerances (H7/h6) validate the approach, yielding deeper and more compliant insertions with minimal residual wrenches and outperforming a conventional wrench disturbance observer and a PD baseline. These results highlight DW-DOB as a practical learning-free solution for high-precision zero-wrench control in contact-rich tasks.","authors":["Kiyoung Choi","Juwon Jeong","Sehoon Oh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.21581v3","updated":"2026-01-08T11:48:39Z","published":"2025-05-27T09:58:43Z","title":"Cognitive-Hierarchy Guided End-to-End Planning for Autonomous Driving","summary":"While end-to-end autonomous driving has advanced significantly, prevailing methods remain fundamentally misaligned with human cognitive principles in both perception and planning. In this paper, we propose CogAD, a novel end-to-end autonomous driving model that emulates the hierarchical cognition mechanisms of human drivers. CogAD implements dual hierarchical mechanisms: global-to-local context processing for human-like perception and intent-conditioned multi-mode trajectory generation for cognitively-inspired planning. The proposed method demonstrates three principal advantages: comprehensive environmental understanding through hierarchical perception, robust planning exploration enabled by multi-level planning, and diverse yet reasonable multi-modal trajectory generation facilitated by dual-level uncertainty modeling. Extensive experiments on nuScenes and Bench2Drive demonstrate that CogAD achieves state-of-the-art performance in end-to-end planning, exhibiting particular superiority in long-tail scenarios and robust generalization to complex real-world driving conditions.","authors":["Zhennan Wang","Jianing Teng","Canqun Xiang","Kangliang Chen","Xing Pan","Lu Deng","Weihao Gu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.04069v2","updated":"2026-01-08T10:57:57Z","published":"2025-09-04T10:02:32Z","title":"Solving Robotics Tasks with Prior Demonstration via Exploration-Efficient Deep Reinforcement Learning","summary":"This paper proposes an exploration-efficient Deep Reinforcement Learning with Reference policy (DRLR) framework for learning robotics tasks that incorporates demonstrations. The DRLR framework is developed based on an algorithm called Imitation Bootstrapped Reinforcement Learning (IBRL). We propose to improve IBRL by modifying the action selection module. The proposed action selection module provides a calibrated Q-value, which mitigates the bootstrapping error that otherwise leads to inefficient exploration. Furthermore, to prevent the RL policy from converging to a sub-optimal policy, SAC is used as the RL policy instead of TD3. The effectiveness of our method in mitigating bootstrapping error and preventing overfitting is empirically validated by learning two robotics tasks: bucket loading and open drawer, which require extensive interactions with the environment. Simulation results also demonstrate the robustness of the DRLR framework across tasks with both low and high state-action dimensions, and varying demonstration qualities. To evaluate the developed framework on a real-world industrial robotics task, the bucket loading task is deployed on a real wheel loader. The sim2real results validate the successful deployment of the DRLR framework.","authors":["Chengyandan Shen","Christoffer Sloth"],"pdf_url":"","comment":"This paper has been accepted for Journal publication in Frontiers in Robotics and AI"},{"id":"http://arxiv.org/abs/2505.13064v2","updated":"2026-01-08T10:38:35Z","published":"2025-05-19T12:54:03Z","title":"Properties of Lyapunov Subcenter Manifolds in Conservative Mechanical Systems","summary":"Multi-body mechanical systems have rich internal dynamics, whose solutions can be exploited as efficient control targets. Yet, solutions non-trivially depend on system parameters, obscuring feasible properties for use as target trajectories. For periodic regulation tasks in robotics applications, we investigate properties of nonlinear normal modes (NNMs) collected in Lyapunov subcenter manifolds (LSMs) of conservative mechanical systems. Using a time-symmetry of conservative mechanical systems, we show that mild non-resonance conditions guarantee LSMs to be Eigenmanifolds, in which NNMs are guaranteed to oscillate between two points of zero velocity. We also prove the existence of a unique generator, which is a connected, 1D manifold that collects these points of zero velocity for a given Eigenmanifold. Furthermore, we show that an additional spatial symmetry provides LSMs with yet stronger properties of Rosenberg manifolds. Here all brake trajectories pass through a unique equilibrium configuration, which can be favorable for control applications. These theoretical results are numerically confirmed on two mechanical systems: a double pendulum and a 5-link pendulum.","authors":["Yannik P. Wotte","Arne Sachtler","Alin Albu-Schäffer","Stefano Stramigioli","Cosimo Della Santina"],"pdf_url":"","comment":"18 pages, 27 figures, submitted to Automatica"},{"id":"http://arxiv.org/abs/2411.05633v2","updated":"2026-01-08T09:08:41Z","published":"2024-11-08T15:22:49Z","title":"SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection","summary":"Developing robust drone detection systems is often constrained by the limited availability of large-scale annotated training data and the high costs associated with real-world data collection. However, leveraging synthetic data generated via game engine-based simulations provides a promising and cost-effective solution to overcome this issue. Therefore, we present SynDroneVision, a synthetic dataset specifically designed for RGB-based drone detection in surveillance applications. Featuring diverse backgrounds, lighting conditions, and drone models, SynDroneVision offers a comprehensive training foundation for deep learning algorithms. To evaluate the dataset's effectiveness, we perform a comparative analysis across a selection of recent YOLO detection models. Our findings demonstrate that SynDroneVision is a valuable resource for real-world data enrichment, achieving notable enhancements in model performance and robustness, while significantly reducing the time and costs of real-world data acquisition. SynDroneVision will be publicly released upon paper acceptance.","authors":["Tamara R. Lenhard","Andreas Weinmann","Kai Franke","Tobias Koch"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.00675v2","updated":"2026-01-08T08:49:12Z","published":"2026-01-02T12:47:34Z","title":"RoboReward: General-Purpose Vision-Language Reward Models for Robotics","summary":"A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotics, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) RoboReward, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a negative examples data augmentation pipeline that generates calibrated negative and near-misses via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we build a large training and evaluation dataset spanning diverse tasks and embodiments to test whether state-of-the-art VLMs can reliably provide rewards for robot learning. Our evaluation of open and proprietary VLMs finds that no model excels across tasks, highlighting substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B model in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5 while narrowing the gap to RL training with human-provided rewards. We release the full dataset, trained reward models, and evaluation suite on our website to advance the development of general-purpose reward models in robotics: https://crfm.stanford.edu/helm/robo-reward-bench (project website).","authors":["Tony Lee","Andrew Wagenmaker","Karl Pertsch","Percy Liang","Sergey Levine","Chelsea Finn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.02207v2","updated":"2026-01-08T08:45:32Z","published":"2025-02-04T10:45:52Z","title":"Human-Aided Trajectory Planning for Automated Vehicles through Teleoperation and Arbitration Graphs","summary":"Teleoperation enables remote human support of automated vehicles in scenarios where the automation is not able to find an appropriate solution. Remote assistance concepts, where operators provide discrete inputs to aid specific automation modules like planning, is gaining interest due to its reduced workload on the human remote operator and improved safety. However, these concepts are challenging to implement and maintain due to their deep integration and interaction with the automated driving system. In this paper, we propose a solution to facilitate the implementation of remote assistance concepts that intervene on planning level and extend the operational design domain of the vehicle at runtime. Using arbitration graphs, a modular decision-making framework, we integrate remote assistance into an existing automated driving system without modifying the original software components. Our simulative implementation demonstrates this approach in two use cases, allowing operators to adjust planner constraints and enable trajectory generation beyond nominal operational design domains.","authors":["Nick Le Large","David Brecht","Willi Poh","Jan-Hendrik Pauls","Martin Lauer","Frank Diermeyer"],"pdf_url":"","comment":"7 pages, 8 figures, presented at IEEE Intelligent Vehicles Symposium 2025, video demonstration available at https://www.youtube.com/watch?v=fVSO-YOeGMk"},{"id":"http://arxiv.org/abs/2503.07989v3","updated":"2026-01-08T08:14:57Z","published":"2025-03-11T02:47:21Z","title":"Bio-Skin: A Cost-Effective Thermostatic Tactile Sensor with Multi-Modal Force and Temperature Detection","summary":"Tactile sensors can significantly enhance the perception of humanoid robotics systems by providing contact information that facilitates human-like interactions. However, existing commercial tactile sensors focus on improving the resolution and sensitivity of single-modal detection with high-cost components and densely integrated design, incurring complex manufacturing processes and unaffordable prices. In this work, we present Bio-Skin, a cost-effective multi-modal tactile sensor that utilizes single-axis Hall-effect sensors for planar normal force measurement and bar-shape piezo resistors for 2D shear force measurement. A thermistor coupling with a heating wire is integrated into a silicone body to achieve temperature sensation and thermostatic function analogous to human skin. We also present a cross-reference framework to validate the two modalities of the force sensing signal, improving the sensing fidelity in a complex electromagnetic environment. Bio-Skin has a multi-layer design, and each layer is manufactured sequentially and subsequently integrated, thereby offering a fast production pathway. After calibration, Bio-Skin demonstrates performance metrics-including signal-to-range ratio, sampling rate, and measurement range-comparable to current commercial products, with one-tenth of the cost. The sensor's real-world performance is evaluated using an Allegro hand in object grasping tasks, while its temperature regulation functionality was assessed in a material detection task.","authors":["Haoran Guo","Haoyang Wang","Zhengxiong Li","Lingfeng Tao"],"pdf_url":"","comment":"This work has been published by IROS2025"},{"id":"http://arxiv.org/abs/2601.04699v1","updated":"2026-01-08T08:09:24Z","published":"2026-01-08T08:09:24Z","title":"SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning","summary":"Sequential-Horizon Vision-and-Language Navigation (SH-VLN) presents a challenging scenario where agents should sequentially execute multi-task navigation guided by complex, long-horizon language instructions. Current vision-and-language navigation models exhibit significant performance degradation with such multi-task instructions, as information overload impairs the agent's ability to attend to observationally relevant details. To address this problem, we propose SeqWalker, a navigation model built on a hierarchical planning framework. Our SeqWalker features: i) A High-Level Planner that dynamically selects global instructions into contextually relevant sub-instructions based on the agent's current visual observations, thus reducing cognitive load; ii) A Low-Level Planner incorporating an Exploration-Verification strategy that leverages the inherent logical structure of instructions for trajectory error correction. To evaluate SH-VLN performance, we also extend the IVLN dataset and establish a new benchmark. Extensive experiments are performed to demonstrate the superiority of the proposed SeqWalker.","authors":["Zebin Han","Xudong Wang","Baichen Liu","Qi Lyu","Zhenduo Shang","Jiahua Dong","Lianqing Liu","Zhi Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04686v1","updated":"2026-01-08T07:55:07Z","published":"2026-01-08T07:55:07Z","title":"Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead","summary":"Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.","authors":["Oluwatosin Oseni","Shengjie Wang","Jun Zhu","Micah Corah"],"pdf_url":"","comment":"RSS'25: Multi-Objective Optimization and Planning in Robotics Workshop: 5 pages, 8 figures"},{"id":"http://arxiv.org/abs/2601.04668v1","updated":"2026-01-08T07:28:11Z","published":"2026-01-08T07:28:11Z","title":"Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture","summary":"This study focuses on optimizing path planning for unmanned ground vehicles (UGVs) in precision agriculture using deep reinforcement learning (DRL) techniques in continuous action spaces. The research begins with a review of traditional grid-based methods, such as A* and Dijkstra's algorithms, and discusses their limitations in dynamic agricultural environments, highlighting the need for adaptive learning strategies. The study then explores DRL approaches, including Deep Q-Networks (DQN), which demonstrate improved adaptability and performance in two-dimensional simulations. Enhancements such as Double Q-Networks and Dueling Networks are evaluated to further improve decision-making. Building on these results, the focus shifts to continuous action space models, specifically Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3), which are tested in increasingly complex environments. Experiments conducted in a three-dimensional environment using ROS and Gazebo demonstrate the effectiveness of continuous DRL algorithms in navigating dynamic agricultural scenarios. Notably, the pretrained TD3 agent achieves a 95 percent success rate in dynamic environments, demonstrating the robustness of the proposed approach in handling moving obstacles while ensuring safety for both crops and the robot.","authors":["Laukik Patade","Rohan Rane","Sandeep Pillai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04657v1","updated":"2026-01-08T07:05:18Z","published":"2026-01-08T07:05:18Z","title":"Model of Spatial Human-Agent Interaction with Consideration for Others","summary":"Communication robots often need to initiate conversations with people in public spaces. At the same time, such robots must not disturb pedestrians. To handle these two requirements, an agent needs to estimate the communication desires of others based on their behavior and then adjust its own communication activities accordingly. In this study, we construct a computational spatial interaction model that considers others. Consideration is expressed as a quantitative parameter: the amount of adjustment of one's internal state to the estimated internal state of the other. To validate the model, we experimented with a human and a virtual robot interacting in a VR environment. The results show that when the participant moves to the target, a virtual robot with a low consideration value inhibits the participant's movement, while a robot with a higher consideration value did not inhibit the participant's movement. When the participant approached the robot, the robot also exhibited approaching behavior, regardless of the consideration value, thus decreasing the participant's movement. These results appear to verify the proposed model's ability to clarify interactions with consideration for others.","authors":["Takafumi Sakamoto","Yugo Takeuchi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04629v1","updated":"2026-01-08T06:00:24Z","published":"2026-01-08T06:00:24Z","title":"UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation","summary":"We present UniBiDex a unified teleoperation framework for robotic bimanual dexterous manipulation that supports both VRbased and leaderfollower input modalities UniBiDex enables realtime contactrich dualarm teleoperation by integrating heterogeneous input devices into a shared control stack with consistent kinematic treatment and safety guarantees The framework employs nullspace control to optimize bimanual configurations ensuring smooth collisionfree and singularityaware motion across tasks We validate UniBiDex on a longhorizon kitchentidying task involving five sequential manipulation subtasks demonstrating higher task success rates smoother trajectories and improved robustness compared to strong baselines By releasing all hardware and software components as opensource we aim to lower the barrier to collecting largescale highquality human demonstration datasets and accelerate progress in robot learning.","authors":["Zhongxuan Li","Zeliang Guo","Jun Hu","David Navarro-Alarcon","Jia Pan","Hongmin Wu","Peng Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04551v1","updated":"2026-01-08T03:28:56Z","published":"2026-01-08T03:28:56Z","title":"Discrete Fourier Transform-based Point Cloud Compression for Efficient SLAM in Featureless Terrain","summary":"Simultaneous Localization and Mapping (SLAM) is an essential technology for the efficiency and reliability of unmanned robotic exploration missions. While the onboard computational capability and communication bandwidth are critically limited, the point cloud data handled by SLAM is large in size, attracting attention to data compression methods. To address such a problem, in this paper, we propose a new method for compressing point cloud maps by exploiting the Discrete Fourier Transform (DFT). The proposed technique converts the Digital Elevation Model (DEM) to the frequency-domain 2D image and omits its high-frequency components, focusing on the exploration of gradual terrains such as planets and deserts. Unlike terrains with detailed structures such as artificial environments, high-frequency components contribute little to the representation of gradual terrains. Thus, this method is effective in compressing data size without significant degradation of the point cloud. We evaluated the method in terms of compression rate and accuracy using camera sequences of two terrains with different elevation profiles.","authors":["Riku Suzuki","Ayumi Umemura","Shreya Santra","Kentaro Uno","Kazuya Yoshida"],"pdf_url":"","comment":"Author's version of a manuscript accepted at the 11th International Conference on Automation, Robotics, and Applications (ICARA). (c) IEEE"},{"id":"http://arxiv.org/abs/2601.04547v1","updated":"2026-01-08T03:23:31Z","published":"2026-01-08T03:23:31Z","title":"Data-Driven Terramechanics Approach Towards a Realistic Real-Time Simulator for Lunar Rovers","summary":"High-fidelity simulators for the lunar surface provide a digital environment for extensive testing of rover operations and mission planning. However, current simulators focus on either visual realism or physical accuracy, which limits their capability to replicate lunar conditions comprehensively. This work addresses that gap by combining high visual fidelity with realistic terrain interaction for a realistic representation of rovers on the lunar surface. Because direct simulation of wheel-soil interactions is computationally expensive, a data-driven approach was adopted, using regression models for slip and sinkage from data collected in both full-rover and single-wheel experiments and simulations. The resulting regression-based terramechanics model accurately reproduced steady-state and dynamic slip, as well as sinkage behavior, on flat terrain and slopes up to 20 degrees, with validation against field test results. Additionally, improvements were made to enhance the realism of terrain deformation and wheel trace visualization. This method supports real-time applications that require physically plausible terrain response alongside high visual fidelity.","authors":["Jakob M. Kern","James M. Hurrell","Shreya Santra","Keisuke Takehana","Kentaro Uno","Kazuya Yoshida"],"pdf_url":"","comment":"Author's version of a manuscript accepted at the International Conference on Space Robotics 2025 (iSpaRo 2025). (c) IEEE"},{"id":"http://arxiv.org/abs/2601.04541v1","updated":"2026-01-08T03:15:31Z","published":"2026-01-08T03:15:31Z","title":"Design and Development of Modular Limbs for Reconfigurable Robots on the Moon","summary":"In this paper, we present the development of 4-DOF robot limbs, which we call Moonbots, designed to connect in various configurations with each other and wheel modules, enabling adaptation to different environments and tasks. These modular components are intended primarily for robotic systems in space exploration and construction on the Moon in our Moonshot project. Such modular robots add flexibility and versatility for space missions where resources are constrained. Each module is driven by a common actuator characterized by a high torque-to-speed ratio, supporting both precise control and dynamic motion when required. This unified actuator design simplifies development and maintenance across the different module types. The paper describes the hardware implementation, the mechanical design of the modules, and the overall software architecture used to control and coordinate them. Additionally, we evaluate the control performance of the actuator under various load conditions to characterize its suitability for modular robot applications. To demonstrate the adaptability of the system, we introduce nine functional configurations assembled from the same set of modules: 4DOF-limb, 8DOF-limb, vehicle, dragon, minimal, quadruped, cargo, cargo-minimal, and bike. These configurations reflect different locomotion strategies and task-specific behaviors, offering a practical foundation for further research in reconfigurable robotic systems.","authors":["Gustavo H. Diaz","A. Sejal Jain","Matteo Brugnera","Elian Neppel","Shreya Santra","Kentaro Uno","Kazuya Yoshida"],"pdf_url":"","comment":"Author's version of a manuscript accepted at the International Conference on Space Robotics 2025 (iSpaRo 2025). (c) IEEE"},{"id":"http://arxiv.org/abs/2512.24385v2","updated":"2026-01-08T02:52:40Z","published":"2025-12-30T17:58:01Z","title":"Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems","summary":"The rapid advancement of autonomous systems, including self-driving vehicles and drones, has intensified the need to forge true Spatial Intelligence from multi-modal onboard sensor data. While foundation models excel in single-modal contexts, integrating their capabilities across diverse sensors like cameras and LiDAR to create a unified understanding remains a formidable challenge. This paper presents a comprehensive framework for multi-modal pre-training, identifying the core set of techniques driving progress toward this goal. We dissect the interplay between foundational sensor characteristics and learning strategies, evaluating the role of platform-specific datasets in enabling these advancements. Our central contribution is the formulation of a unified taxonomy for pre-training paradigms: ranging from single-modality baselines to sophisticated unified frameworks that learn holistic representations for advanced tasks like 3D object detection and semantic occupancy prediction. Furthermore, we investigate the integration of textual inputs and occupancy representations to facilitate open-world perception and planning. Finally, we identify critical bottlenecks, such as computational efficiency and model scalability, and propose a roadmap toward general-purpose multi-modal foundation models capable of achieving robust Spatial Intelligence for real-world deployment.","authors":["Song Wang","Lingdong Kong","Xiaolu Liu","Hao Shi","Wentong Li","Jianke Zhu","Steven C. H. Hoi"],"pdf_url":"","comment":"Survey; 40 pages, 7 figures, 9 tables; GitHub Repo at https://github.com/worldbench/awesome-spatial-intelligence"},{"id":"http://arxiv.org/abs/2601.04511v1","updated":"2026-01-08T02:26:57Z","published":"2026-01-08T02:26:57Z","title":"Multiagent Reinforcement Learning with Neighbor Action Estimation","summary":"Multiagent reinforcement learning, as a prominent intelligent paradigm, enables collaborative decision-making within complex systems. However, existing approaches often rely on explicit action exchange between agents to evaluate action value functions, which is frequently impractical in real-world engineering environments due to communication constraints, latency, energy consumption, and reliability requirements. From an artificial intelligence perspective, this paper proposes an enhanced multiagent reinforcement learning framework that employs action estimation neural networks to infer agent behaviors. By integrating a lightweight action estimation module, each agent infers neighboring agents' behaviors using only locally observable information, enabling collaborative policy learning without explicit action sharing. This approach is fully compatible with standard TD3 algorithms and scalable to larger multiagent systems. At the engineering application level, this framework has been implemented and validated in dual-arm robotic manipulation tasks: two robotic arms collaboratively lift objects. Experimental results demonstrate that this approach significantly enhances the robustness and deployment feasibility of real-world robotic systems while reducing dependence on information infrastructure. Overall, this research advances the development of decentralized multiagent artificial intelligence systems while enabling AI to operate effectively in dynamic, information-constrained real-world environments.","authors":["Zhenglong Luo","Zhiyong Chen","Aoxiang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04493v1","updated":"2026-01-08T01:53:42Z","published":"2026-01-08T01:53:42Z","title":"Fast Continuum Robot Shape and External Load State Estimation on SE(3)","summary":"Previous on-manifold approaches to continuum robot state estimation have typically adopted simplified Cosserat rod models, which cannot directly account for actuation inputs or external loads. We introduce a general framework that incorporates uncertainty models for actuation (e.g., tendon tensions), applied forces and moments, process noise, boundary conditions, and arbitrary backbone measurements. By adding temporal priors across time steps, our method additionally performs joint estimation in both the spatial (arclength) and temporal domains, enabling full \\textit{spacetime} state estimation. Discretizing the arclength domain yields a factor graph representation of the continuum robot model, which can be exploited for fast batch sparse nonlinear optimization in the style of SLAM. The framework is general and applies to a broad class of continuum robots; as illustrative cases, we show (i) tendon-driven robots in simulation, where we demonstrate real-time kinematics with uncertainty, tip force sensing from position feedback, and distributed load estimation from backbone strain, and (ii) a surgical concentric tube robot in experiment, where we validate accurate kinematics and tip force estimation, highlighting potential for surgical palpation.","authors":["James M. Ferguson","Alan Kuntz","Tucker Hermans"],"pdf_url":"","comment":"Public preprint for ICRA 2026"},{"id":"http://arxiv.org/abs/2505.09109v2","updated":"2026-01-08T01:52:57Z","published":"2025-05-14T03:34:30Z","title":"FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis","summary":"Due to the deformability of garments, generating a large amount of high-quality data for robotic garment manipulation tasks is highly challenging. In this paper, we present a synthetic garment dataset that can be used for robotic garment folding. We begin by constructing geometric garment templates based on keypoints and applying generative models to generate realistic texture patterns. Leveraging these keypoint annotations, we generate folding demonstrations in simulation and train folding policies via closed-loop imitation learning. To improve robustness, we propose KG-DAgger, which uses a keypoint-based strategy to generate demonstration data for recovering from failures. KG-DAgger significantly improves the model performance, boosting the real-world success rate by 25\\%. After training with 15K trajectories (about 2M image-action pairs), the model achieves a 75\\% success rate in the real world. Experiments in both simulation and real-world settings validate the effectiveness of our proposed framework.","authors":["Yuxing Chen","Bowen Xiao","He Wang"],"pdf_url":"","comment":null}],"Analysis of PDEs":[{"id":"http://arxiv.org/abs/2506.09812v2","updated":"2026-01-08T17:43:20Z","published":"2025-06-11T14:52:09Z","title":"Balanced quasistatic evolutions of critical points in metric spaces","summary":"Quasistatic evolutions of critical points of time-dependent energies exhibit piecewise smooth behavior, making them useful for modeling continuum mechanics phenomena like elastic-plasticity and fracture. Traditionally, such evolutions have been derived as vanishing viscosity and inertia limits, leading to balanced viscosity solutions. However, for nonconvex energies, these constructions have been realized in Euclidean spaces and assume non-degenerate critical points. In this paper, we take a different approach by decoupling the time scales of the energy evolution and of the transition to equilibria. Namely, starting from an equilibrium configuration, we let the energy evolve, while keeping frozen the system state; then, we update the state by freezing the energy, while letting the system transit via gradient flow or an approximation of it (e.g., minimizing movement or backward differentiation schemes). This approach has several advantages. It aligns with the physical principle that systems transit through energy-minimizing steady states. It is also fully constructive and computationally implementable, with physical and computational costs governed by appropriate action functionals. Additionally, our analysis is simpler and more general than previous formulations in the literature, as it does not require non-degenerate critical points. Finally, this approach extends to evolutions in locally compact metric path spaces, and our axiomatic presentation allows for various realizations.","authors":["Stefano Almi","Massimo Fornasier","Jona Klemenc","Alessandro Scagliotti"],"pdf_url":"","comment":"66 pages, 6 figures. Minor adjustments and corrections"},{"id":"http://arxiv.org/abs/2601.05146v1","updated":"2026-01-08T17:34:40Z","published":"2026-01-08T17:34:40Z","title":"A simple rigorous integrator for semilinear parabolic PDEs","summary":"Simulations of the dynamics generated by partial differential equations (PDEs) provide approximate, numerical solutions to initial value problems. Such simulations are ubiquitous in scientific computing, but the correctness of the results is usually not guaranteed. We propose a new method for the rigorous integration of parabolic PDEs, i.e., the derivation of rigorous and explicit error bounds between the numerically obtained approximate solution and the exact one, which is then proven to exist over the entire time interval considered. These guaranteed error bounds are obtained a posteriori, using a fixed point reformulation based on a piece-wise in time constant approximation of the linearization around the numerical solution. Our setup leads to relatively simple-to-understand estimates, which has several advantages. Most critically, it allows us to optimize various aspects of the proof, and in particular to provide an adaptive time-stepping strategy. In case the solution converges to a stable hyperbolic equilibrium, we are also able to prove this convergence, applying our rigorous integrator with a final, infinitely long timestep. We showcase the ability of our method to rigorously integrate over relatively long time intervals, and to capture non-trivial dynamics, via examples on the Swift--Hohenberg equation, the Ohta--Kawasaki equation and the Kuramoto--Sivashinsky equation. We expect that the simplicity and efficiency of the approach will enable generalization to a wide variety of other parabolic PDEs, as well as applications to boundary value problems.","authors":["Jan Bouwe van den Berg","Maxime Breden"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2403.12652v3","updated":"2026-01-08T17:28:32Z","published":"2024-03-19T11:36:13Z","title":"Well-posedness of the stochastic thin-film equation with an interface potential","summary":"We consider strictly positive solutions to a class of fourth-order conservative quasilinear SPDEs on the $d$-dimensional torus modeled after the stochastic thin-film equation. We prove local Lipschitz estimates in Bessel potential spaces under minimal assumptions on the parameters and corresponding stochastic maximal $L^p$-regularity estimates for thin-film type operators with measurable in-time coefficients. As a result, we deduce local well-posedness of the stochastic thin-film equation as well as blow-up criteria and instantaneous regularization for the solution. In dimension one, we additionally close $α$-entropy estimates and subsequently an energy estimate for the stochastic thin-film equation with an interface potential so that global well-posedness follows. We allow for a wide range of mobility functions including the power laws $u^n$ for $n\\in [0,6)$ as long as the interface potential is sufficiently repulsive.","authors":["Antonio Agresti","Max Sauerbrey"],"pdf_url":"","comment":"Improved presentation. To appear in Communications in Mathematical Physics. 48 pages"},{"id":"http://arxiv.org/abs/2408.03597v2","updated":"2026-01-08T17:24:22Z","published":"2024-08-07T07:31:37Z","title":"Long time validity of the linearized Boltzmann uncut-off and the linearized Landau equations from the Newton Law","summary":"We provide a rigorous justification of the linearized Boltzmann- and Landau equations from interacting particle systems with long-range interaction. The result shows that the fluctuations of Hamiltonian $N$- particle systems governed by truncated power law potentials of the form $\\mathcal{U}(r)\\sim |r/\\varepsilon|^{-s}$ (near $r \\approx 0$) converge to solutions of kinetic equations in appropriate scaling limits $\\varepsilon \\rightarrow 0$ and $N\\rightarrow \\infty$. We prove that for $s\\in [0,1)$, the limiting system approaches the uncutoff linearized Boltzmann equation or the linearized Landau equation, depending on the scaling limit. The Coulomb singularity $s=1$ appears as a threshold value. Kinetic scaling limits with $s\\in (0,1]$ universally converge to the linearized Landau equation, and we prove the onset of the Coulomb logarithm for $s=1$. To the best of our knowledge, this is the first result on the derivation of kinetic equations from interacting particle systems with long-range power-law interaction.","authors":["Corentin Le Bihan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05130v1","updated":"2026-01-08T17:20:00Z","published":"2026-01-08T17:20:00Z","title":"Sparsity and uniform regularity for regularised optimal transport","summary":"We consider regularised quadratic optimal transport with subquadratic polynomial or entropic regularisation. In both cases, we prove interior Lipschitz-estimates on a transport-like map and interior gradient Lipschitz-estimates on the potentials, under the assumption that the transport map solving the unregularised problem is bi-$C^{1,α}$-regular. For strictly subquadratic and entropic regularisation, the estimates improve to interior $C^1$ and $C^2$ estimates for the transport-like map and the potentials, respectively. Our estimates are uniform in the regularisation parameter. As a consequence of this, we obtain convergence of the transport-like map (resp. the potentials) to the unregularised transport map (resp. Kantorovich potentials) in $C^{0,1-}_{\\mathrm{loc}}$ (resp. $C^{1,1-}_{\\mathrm{loc}}$).\n  Central to our approach are sharp local bounds on the size of the support for regularised optimal transport which we derive for a general convex, superlinear regularisation term. These bounds are of independent interest and imply global bias bounds for the regularised transport plans. Our global bounds, while not necessarily sharp, improve on the best known results in the literature for quadratic regularisation.","authors":["Rishabh S. Gvalani","Lukas Koch"],"pdf_url":"","comment":"27 pages, no figures"},{"id":"http://arxiv.org/abs/2501.06544v3","updated":"2026-01-08T16:52:16Z","published":"2025-01-11T13:49:13Z","title":"Around the Quantum Lenard-Balescu equation","summary":"In the mean-field regime, a gas of quantum particles with Boltzmann statistics can be described by the Hartree-Fock equation. This dynamics becomes trivial if the initial distribution of particle is invariant by translation. However, the first correction is given on time of order $O(N)$ by the quantum Lenard--Balescu equation. In the first part of the present article, we justify this equation until time of order $O((\\log N)^{1-δ})$ (for any $δ\\in(0,1)$).\n  A similar phenomenon exists in the classical setting (with a similar validity time obtained by Duerinckx \\cite{Duerinckx}). In a second time, we prove the convergence for dimension $d\\geq 2$ of the solutions of the quantum Lenard--Balescu equation to the solutions of its classical counterpart in the semi-classical limit. This problem can be interpreted as a grazing collision limit: the quantum Lenard--Balescu equation looks like a cut-off Boltzmann equation, when the classical one looks like the Landau equation.","authors":["Corentin Le Bihan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05080v1","updated":"2026-01-08T16:25:16Z","published":"2026-01-08T16:25:16Z","title":"Non-linear parabolic PDEs with rough data and coefficients: existence, uniqueness and regularity of weak solutions in critical spaces","summary":"This article investigates the well-posedness of weak solutions to non-linear parabolic PDEs driven by rough coefficients with rough initial data in critical homogeneous Besov spaces. Well-posedness is understood in the sense of existence and uniqueness of maximal weak solutions in suitable weighted $Z$-spaces in the absence of smallness conditions. We showcase our theory with an application to rough reaction--diffusion equations. Subsequent articles will treat further classes of equations, including equations of Burgers-type and quasi-linear problems, using the same approach. Our toolkit includes a novel theory of hypercontractive singular integral operators (SIOs) on weighted $Z$-spaces and a self-improving property for super-linear reverse Hölder inequalities.","authors":["Pascal Auscher","Sebastian Bechtel"],"pdf_url":"","comment":"50 pages"},{"id":"http://arxiv.org/abs/2601.05054v1","updated":"2026-01-08T15:57:56Z","published":"2026-01-08T15:57:56Z","title":"On the effects of protection zone and directed population flux in prey-predator dynamics","summary":"We study a spatial predator-prey model in which prey can enter a protection zone (refuge) inaccessible to predators, while predators exhibit directed movement toward prey-rich regions. The directed movement is modeled by a far-sighted population flux motivated by classical movement rules, in contrast to the more commonly analyzed near-sighted chemotaxis-type mechanisms. We first establish local-in-time well-posedness for the corresponding nonstationary problem under Neumann boundary conditions, despite the discontinuity induced by the refuge interface. We then investigate the stationary problem, focusing on how the coexistence states emerge and organize globally in parameter space. In particular, we identify the bifurcation threshold for positive steady states from semitrivial predator-only equilibria, and describe the global continuation of the resulting branches. Our analysis reveals that strong directed movement can induce turning-point structures and multiplicity of coexistence steady states, highlighting a nontrivial interplay between spatial protection and predator movement behavior.","authors":["Kousuke Kuto","Kazuhiro Oeda"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17854v2","updated":"2026-01-08T15:53:58Z","published":"2025-12-19T17:56:32Z","title":"Conformal invariants for the zero mode equation","summary":"For non-trivial solutions to the zero mode equation on a closed spin manifold \\[D \\varphi=iA\\cdot \\varphi,\\] we first provide a simple proof for the sharp inequality \\eq{ \\norm{A}_{L^n}^2 \\ge \\frac {n}{4(n-1)} Y(M,[g]), } where $Y(M,[g])$ is the Yamabe constant of $(M,g)$, which was obtained by Frank-Loss and Reuss. Then we classify completely the equality case by proving that equality holds if and only if $\\varphi$ is a Killing spinor, and if and only if $(M,g)$ is a Sasaki-Einstein manifold with $A$ (up to scaling) as its Reeb field and $\\varphi$ a vacuum up to a conformal transformation. More generalizations have been also studied.","authors":["Guofang Wang","Mingwei Zhang"],"pdf_url":"","comment":"Added a generalized result in Section 5; revised argument in the proof of Theorem 5.7, results unchanged"},{"id":"http://arxiv.org/abs/2601.05023v1","updated":"2026-01-08T15:32:07Z","published":"2026-01-08T15:32:07Z","title":"Finite-time blow-up in a quasilinear two-species chemotaxis system with two chemicals","summary":"This paper investigates the finite-time blow-up phenomena to a quasilinear two-species chemotaxis system with two chemicals \\begin{align}\\tag{$\\star$}\n  \\begin{cases}\n  u_t = \\nabla \\cdot \\left(D_1(u) \\nabla u\\right) - \\nabla \\cdot \\left(u \\nabla v\\right), & x \\in Ω, \\ t > 0,\n  0 = Δv - μ_2 + w, \\quad μ_2=\\fint_Ωw, & x \\in Ω, \\ t > 0,\n  w_t = \\nabla \\cdot \\left(D_2(w) \\nabla w\\right) - \\nabla \\cdot \\left(w \\nabla z\\right), & x \\in Ω, \\ t > 0,\n  0 = Δz - μ_1 + u, \\quad μ_1=\\fint_Ωu, & x \\in Ω, \\ t > 0,\n  \\frac{\\partial u}{\\partial ν} = \\frac{\\partial v}{\\partial ν} = \\frac{\\partial w}{\\partial ν} = \\frac{\\partial z}{\\partial ν} = 0, & x \\in \\partial Ω, \\ t > 0,\n  u(x, 0) = u_0(x), \\quad w(x, 0) = w_0(x), & x \\in Ω,\n  \\end{cases} \\end{align} where $Ω\\subset \\mathbb{R}^n$ $(n \\geqslant 3)$ is a smoothly bounded domain. The nonlinear diffusion functions \\( D_1(s) \\) and \\( D_2(s) \\) are of the following forms: \\begin{align*}\n  D_1(s)\\simeq s^{m_1-1} \\quad \\text{and}\\quad D_2(s) \\simeq s^{m_2-1}, \\quad m_1,m_2> 1 \\end{align*} for $s\\geqslant 1$.\n  For the classical two-species chemotaxis system with two chemicals (i.e. the second and fourth equations are replaced by $0 = Δv - v + w$ and $0 = Δz - z + u$ ), Zhong [J. Math. Anal. Appl., 500 (2021), Paper No. 125130, pp. 22.] showed that the system possesses a globally bounded classical solution in the case that \\[ m_1 + m_2 < \\max\\left\\{m_1m_2 + \\frac{2m_1}{ n},\\ m_1m_2 + \\frac{2m_2 }{ n}\\right\\}. \\]\n  Complementing the boundedness result, we prove that the system ($\\star$) admits solutions that blow up in finite time, if \\[ m_1 + m_2 > \\max\\left\\{ m_1m_2 + \\frac{2m_1}{ n},\\ m_1m_2 + \\frac{2m_2}{ n}\\right\\} \\] with $n\\geqslant 3$.","authors":["Mingzhang Cai","Yuxiang Li","Ziyue Zeng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05015v1","updated":"2026-01-08T15:17:24Z","published":"2026-01-08T15:17:24Z","title":"Nodal set comparison for Allen--Cahn solutions with conical asymptotics","summary":"We establish a comparison principle for entire solutions of the Allen--Cahn equation whose nodal sets, possibly singular, are asymptotic to a regular minimizing hypercone. We show that inclusion of the positive phases enforces a global ordering of the solutions. As a consequence, the positive phase uniquely determines the solution, and strict phase inclusion implies that the corresponding nodal sets are disjoint. Our analysis relies on a maximum principle for the linearized operator on unbounded domains that are not necessarily smooth, and yields an Allen--Cahn analogue of the strong maximum principle for minimal hypersurfaces.","authors":["Sanghoon Lee","Taehun Lee"],"pdf_url":"","comment":"12 pages"},{"id":"http://arxiv.org/abs/2509.23276v2","updated":"2026-01-08T15:10:22Z","published":"2025-09-27T12:10:33Z","title":"An ancient Ricci flow emerging from Taub-Bolt","summary":"This paper proves that there exists a non-trivial ancient solution to the Ricci flow emerging from the Taub-Bolt metric.","authors":["John Hughes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05008v1","updated":"2026-01-08T15:08:16Z","published":"2026-01-08T15:08:16Z","title":"Critical blow-up curve in a two-species chemotaxis system with two chemicals involving flux-limitation","summary":"We investigate the following two-species chemotaxis system with two chemicals involving flux-limitation \\begin{align}\\tag{$\\star$} \\begin{cases} u_t = Δu - \\nabla \\cdot \\left(u(1+|\\nabla v|^2)^{-\\frac{p}{2}}\\nabla v\\right), & x \\in Ω, \\ t > 0, \\\\ 0 = Δv - μ_w + w, \\quad μ_{w}=f_Ω w, & x \\in Ω, \\ t > 0, \\\\ w_t = Δw - \\nabla \\cdot \\left(w (1+|\\nabla z|^2)^{-\\frac{q}{2}} \\nabla z\\right), & x \\in Ω, \\ t > 0, \\\\ 0 = Δz - μ_u + u, \\quad μ_{u}=f_Ω u, & x \\in Ω, \\ t > 0, \\\\ \\frac{\\partial u}{\\partial ν} = \\frac{\\partial v}{\\partial ν} = \\frac{\\partial w}{\\partial ν} = \\frac{\\partial z}{\\partial ν} = 0, & x \\in \\partial Ω, \\ t > 0, \\\\ u(x, 0) = u_0(x), \\quad w(x, 0) = w_0(x), & x \\in Ω, \\end{cases} \\end{align} where $p,q \\in \\mathbb{R}$ and $Ω\\subset \\mathbb{R}^n$ is a smooth bounded domain. In this paper, we identify a critical blow-up curve ( i.e $p=\\frac{n-2}{n-1}$ and $q=\\frac{n-2}{n-1}$ in the square $(0,\\frac{n-2}{n-1}] \\times (0,\\frac{n-2}{n-1}]$) for system ($\\star$) with $n\\geq 3$ and $p,q>0$. Specifically, \\begin{itemize}\n  \\item when $Ω=B_R(0) \\subset \\mathbb{R}^n$ with $n\\geq 3$, if $0<p<\\frac{n-2}{n-1}$ and $0<q<\\frac{n-2}{n-1}$, there exist radially symmetric initial data such that the corresponding solution blows up in finite time;\n  \\item for any general smooth bounded domain, if either $n=1$ ( with $p,q \\in \\mathbb{R}$ arbitrary) or $n\\geq 2$ with $p>\\frac{n-2}{n-1}$ or $q>\\frac{n-2}{n-1}$, then solutions exist globally and remain bounded. \\end{itemize}","authors":["Ziyue Zeng","Yuxiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04994v1","updated":"2026-01-08T14:52:00Z","published":"2026-01-08T14:52:00Z","title":"Critical blow-up lines in a two-species quasilinear chemotaxis system with two chemicals","summary":"In this study, we explore the quasilinear two-species chemotaxis system with two chemicals \\begin{align}\\tag{$\\star$} \\begin{cases} u_t = \\nabla \\cdot(D(u)\\nabla u) - \\nabla \\cdot \\left(S(u) \\nabla v\\right), & x \\in Ω, \\ t > 0, \\\\ 0 = Δv - μ_w + w, \\quad μ_w=\\fint_Ωw, & x \\in Ω, \\ t > 0, \\\\ w_t = Δw - \\nabla \\cdot \\left(w \\nabla z\\right), & x \\in Ω, \\ t > 0, \\\\ 0 = Δz - μ_u + u, \\quad μ_u=\\fint_Ωu, & x \\in Ω, \\ t > 0, \\\\ \\frac{\\partial u}{\\partial ν} = \\frac{\\partial v}{\\partial ν} = \\frac{\\partial w}{\\partial ν} = \\frac{\\partial z}{\\partial ν} = 0, & x \\in \\partial Ω, \\ t > 0, \\\\ u(x, 0) = u_0(x), \\quad w(x, 0) = w_0(x), & x \\in Ω, \\end{cases} \\end{align} where $Ω\\subset \\mathbb{R}^n$ ($n \\geq3$) is a smooth bounded domain. The functions $D(s)$ and $S(s)$ exhibit asymptotic behavior of the form \\begin{align*} D(s) \\simeq k_D s^p \\ \\text {and} \\ S(s) \\simeq k_S s^q, \\quad s \\gg 1 \\end{align*} with $p,q \\in \\mathbb{R}$. We prove that \\begin{itemize}\n  \\item when $Ω$ is a ball, if $q-p>2-\\frac{n}{2}$ and $q>1-\\frac{n}{2}$, there exist radially symmetric initial data $u_0$ and $w_0$, such that the corresponding solutions blow up in finite time;\n  \\item for any general smooth bounded domain $Ω\\subset \\mathbb{R}^n$, if $q-p<2-\\frac{n}{2}$, all solutions are globally bounded;\n  \\item for any general smooth bounded domain $Ω\\subset \\mathbb{R}^n$, if $q<1-\\frac{n}{2}$, all solutions are global. \\end{itemize} We point out that our results implies that the system ($\\star$) possess two critical lines $ q-p=2-\\frac{n}{2}$ and $q=1-\\frac{n}{2}$ to classify three dynamics among global boundedness, finite-time blow-up, and global existence of solutions to system ($\\star$).","authors":["Ziyue Zeng","Yuxiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17767v2","updated":"2026-01-08T14:06:58Z","published":"2025-12-19T16:39:02Z","title":"Existence, uniqueness, and time-asymptotics of regular solutions in multidimensional thermoelasticity on domains with boundary","summary":"In the paper, we investigate the nonlinear thermoelasticity model in two- and three-dimensional convex and bounded domains. We propose new boundary conditions for the displacement. These conditions are not usual in thermoelasticity. Whereas, we posit the Neumann boundary condition for the temperature. We prove the existence of global, unique solutions for small initial data. The temperature positivity is also shown. Next, we investigate the long-time behavior of solutions. We show that the divergence-free part of the displacement oscillates. On the other hand, we prove that the potential part and the temperature are strongly coupled. The non-rotation part is heavily affected by heat propagation. It turns out that it tends to $0$ as $x$ approaches infinity. Additionally, the temperature converges to a constant function.\n  Our techniques are firmly based on the functional $\\F$ adopted from {\\sc Bies, P. M., Cieślak, T., Fuest, M., Lankeit, J., Muha, B., and Trifunović, S.}, \\emph{Existence, uniqueness, and long-time asymptotic behavior of regular solutions in multidimensional thermoelasticity}, arXiv: 2507.20794, 2025. The functional is based on the Fisher information and higher-order derivatives of the displacement. It responds well to the new boundary conditions. It allows us to close a priori estimates. We also need $L^{\\infty}$-estimates for the temperature here. The Moser iterative procedure ensures it.\n  The Helmholtz decomposition is applied to the displacement. The boundary conditions are crucial here. The boundary integrals that appear in the calculations at this point disappear thanks to these conditions. This allows us to split the problem into two separate ones. Each of them is associated with one part of the Helmholtz decomposition.","authors":["Piotr Michał Bies"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04944v1","updated":"2026-01-08T13:49:00Z","published":"2026-01-08T13:49:00Z","title":"On Navier-Stokes equations arising from the rotation of an obstacle in a fluid","summary":"We consider the modified Navier-Stokes equations in R3 describing the motion of a fluid in the presence of a rotating rigid body. Weighted Sobolev spaces are used to describe the behavior of solutions at large distances. Under suitable assumptions, w e prove the existence and regularity of solutions satisfying appropriate conditions at infinity.","authors":["Tahar Zamène Boulmezaoud","Nabil Kerdid","Amel Kourta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04894v1","updated":"2026-01-08T12:43:58Z","published":"2026-01-08T12:43:58Z","title":"Improved convergence rates in the fast-reaction approximation of the triangular Shigesada-Kawasaki-Teramoto system","summary":"We consider the fast-reaction approximation to the triangular Shigesada-Kawasaki-Teramoto model on a bounded domain in the physical dimension $d\\le 3$. We provide explicit convergence rates on the whole domain in $\\textnormal{L}^\\infty\\textnormal{L}^2\\cap\\textnormal{L}^2\\textnormal{H}^1$ and in the interior we prove convergence with an explicit rate in any $\\textnormal{L}^\\infty\\textnormal{H}^l$ for all $l > 0$.","authors":["Hector Bouton"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.09159v2","updated":"2026-01-08T12:02:33Z","published":"2025-11-12T09:51:31Z","title":"Rademacher's Theorem for Calderon-Zygmund-type Spaces","summary":"Rademacher's Theorem can be interpreted as an almost-everywhere \\emph{little-$o$ improvement principle}: if a function admits a uniform pointwise first-order Lipschitz control at every point, then this control improves to a vanishing one at almost every point. In the language of Calderón--Zygmund pointwise spaces, this means that \\[ f \\in T^\\infty_1(x) \\quad \\forall x \\in \\mathbb{R}^d \\qquad \\Longrightarrow \\qquad f \\in t^\\infty_1(x) \\quad \\text{for a.e. } x \\in \\mathbb{R}^d. \\]\n  The purpose of this paper is to establish an analogous almost-everywhere improvement principle in a refined $L^p$ setting. We consider pointwise Calderón-Zygmund spaces $T^p_φ(x)$ defined via polynomial approximation in $L^p$ with a function parameter $φ$, allowing for fractional regularity indices and logarithmic corrections through Boyd functions. We prove that, under natural assumptions on $φ$, the uniform membership \\[ f \\in T^p_φ(x) \\quad \\forall x \\in E \\] on a measurable set $E \\subset \\mathbb{R}^d$ implies an almost-everywhere improvement to a vanishing approximation rate, namely \\[ f \\in t^p_{φ,n+1}(x) \\quad \\text{for a.e. } x \\in E, \\] where $n < \\underline{b}(φ) \\leq \\overline{b}(φ) < n+1$.\n  The proof combines measurability arguments, a generalized Whitney extension theorem, and fine properties of Sobolev spaces. We also show that this result is essentially sharp: in general, one cannot expect almost-everywhere membership in $t^p_{φ,n}(x)$ for fractional indices, and explicit counterexamples are provided.","authors":["Thomas Lamby"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.02357v3","updated":"2026-01-08T11:50:16Z","published":"2024-10-03T10:11:44Z","title":"A universal example for quantitative semi-uniform stability","summary":"We characterise quantitative semi-uniform stability for $C_0$-semigroups arising from port-Hamiltonian systems, complementing recent works on exponential and strong stability. With the result, we present a simple universal example class of port-Hamiltonian $C_0$-semigroups exhibiting arbitrary decay rates slower than $t^{-1/2}$.\n  The latter is based on results from the theory of Diophantine approximation, as the decay rates will be strongly related to the approximation properties of irrational numbers by rationals obtained from cut-offs of continued fraction expansions.","authors":["Sahiba Arora","Felix Schwenninger","Ingrid Vukusic","Marcus Waurick"],"pdf_url":"","comment":"24 pages; this is version 3, included the proof of Theorem A.5 and fixed an error in proof of Theorem A.6"},{"id":"http://arxiv.org/abs/2601.04845v1","updated":"2026-01-08T11:34:15Z","published":"2026-01-08T11:34:15Z","title":"Boundedness in a two-dimensional doubly degenerate nutrient taxis system with logistic source","summary":"We are concerned with the following doubly degenerate nutrient taxis system \\begin{align} \\begin{cases}\\tag{$\\star$}\\label{eq-0.1} u_t=\\nabla\\cdot(u v\\nabla u)-\\nabla\\cdot(u^{2} v\\nabla v)+u-u^2,\\\\[1mm] v_t=Δv-u v, \\end{cases} \\end{align} posed in a bounded smooth domain $Ω\\subset\\mathbb{R}^2$ under homogeneous Neumann boundary conditions. This model was introduced to describe the aggregation patterns of colonies of \\emph{Bacillus subtilis} observed on thin agar plates. Previous results have established global boundedness in one space dimension and, in two dimensions, under additional assumptions such as small initial data or convex domains (see, e.g., M. Winkler, \\textit{Trans. Amer. Math. Soc.}, 2021; M. Winkler, \\textit{J. Differ. Equ.}, 2024). In the presence of the quadratic degradation term in the logistic growth, which markedly enhances the dissipative structure of the system, and by employing a weighted energy method, we prove that for arbitrary smooth initial data the problem \\eqref{eq-0.1} admits a global weak solution that remains uniformly bounded in time.","authors":["Zhiguang Zhang","Yuxiang Li"],"pdf_url":"","comment":null}],"Dynamical Systems":[{"id":"http://arxiv.org/abs/2601.05225v1","updated":"2026-01-08T18:53:52Z","published":"2026-01-08T18:53:52Z","title":"Concurrent Balanced Augmented Trees","summary":"Augmentation makes search trees tremendously more versatile, allowing them to support efficient aggregation queries, order-statistic queries, and range queries in addition to insertion, deletion, and lookup. In this paper, we present the first lock-free augmented balanced search tree. Our algorithmic ideas build upon a recent augmented unbalanced search tree presented by Fatourou and Ruppert [DISC, 2024]. We implement both data structures, solving some memory reclamation challenges in the process, and provide an experimental performance analysis of them. We also present optimized versions of our balanced tree that use delegation to achieve better scalability and performance (by more than 2x in some workloads). Our experiments show that our augmented balanced tree is 2.2 to 30 times faster than the unbalanced augmented tree, and up to several orders of magnitude faster than unaugmented trees on 120 threads.","authors":["Evan Wrench","Ajay Singh","Younghun Roh","Panagiota Fatourou","Siddhartha Jayanti","Eric Ruppert","Yuanhao Wei"],"pdf_url":"","comment":"To appear in PPoPP 2026"},{"id":"http://arxiv.org/abs/2601.05166v1","updated":"2026-01-08T17:55:57Z","published":"2026-01-08T17:55:57Z","title":"Inapproximability of Counting Permutation Patterns","summary":"Detecting and counting copies of permutation patterns are fundamental algorithmic problems, with applications in the analysis of rankings, nonparametric statistics, and property testing tasks such as independence and quasirandomness testing. From an algorithmic perspective, there is a sharp difference in complexity between detecting and counting the copies of a given length-$k$ pattern in a length-$n$ permutation. The former admits a $2^{\\mathcal{O}(k^2)} \\cdot n$ time algorithm (Guillemot and Marx, 2014) while the latter cannot be solved in time $f(k)\\cdot n^{o(k/\\log k)}$ unless the Exponential Time Hypothesis (ETH) fails (Berendsohn, Kozma, and Marx, 2021). In fact already for patterns of length 4, exact counting is unlikely to admit near-linear time algorithms under standard fine-grained complexity assumptions (Dudek and Gawrychowski, 2020).\n  Recently, Ben-Eliezer, Mitrović and Sristava (2026) showed that for patterns of length up to 5, a $(1+\\varepsilon)$-approximation of the pattern count can be computed in near-linear time, yielding a separation between exact and approximate counting for small patterns, and conjectured that approximate counting is asymptotically easier than exact counting in general. We strongly refute their conjecture by showing that, under ETH, no algorithm running in time $f(k)\\cdot n^{o(k/\\log k)}$ can approximate the number of copies of a length-$k$ pattern within a multiplicative factor $n^{(1/2-\\varepsilon)k}$. The lower bound on runtime matches the conditional lower bound for exact pattern counting, and the obtained bound on the multiplicative error factor is essentially tight, as an $n^{k/2}$-approximation can be computed in $2^{\\mathcal{O}(k^2)}\\cdot n$ time using an algorithm for pattern detection.","authors":["Michal Opler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05157v1","updated":"2026-01-08T17:47:58Z","published":"2026-01-08T17:47:58Z","title":"Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms","summary":"In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians.\n  All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments.\n  Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function.\n  Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.","authors":["Alkis Kalavasis","Pravesh K. Kothari","Shuchen Li","Manolis Zampetakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.07749v4","updated":"2026-01-08T16:15:45Z","published":"2024-07-10T15:20:21Z","title":"Fast Approximation Algorithms for Euclidean Minimum Weight Perfect Matching","summary":"We study the Euclidean minimum weight perfect matching problem for $n$ points in the plane. It is known that any deterministic approximation algorithm whose approximation ratio depends only on $n$ requires at least $Ω(n \\log n)$ time. We propose such an algorithm for the Euclidean minimum weight perfect matching problem with runtime $O(n\\log n)$ and show that it has approximation ratio $O(n^{0.206})$. This improves the so far best known approximation ratio of $n/2$. We also develop an $O(n \\log n)$ algorithm for the Euclidean minimum weight perfect matching problem in higher dimensions and show it has approximation ratio $O(n^{0.412})$ in all fixed dimensions.","authors":["Stefan Hougardy","Karolina Tammemaa"],"pdf_url":"","comment":"revised, 22 pages"},{"id":"http://arxiv.org/abs/2601.05044v1","updated":"2026-01-08T15:49:39Z","published":"2026-01-08T15:49:39Z","title":"An Invitation to \"Fine-grained Complexity of NP-Complete Problems\"","summary":"Assuming that P is not equal to NP, the worst-case run time of any algorithm solving an NP-complete problem must be super-polynomial. But what is the fastest run time we can get? Before one can even hope to approach this question, a more provocative question presents itself: Since for many problems the naive brute-force baseline algorithms are still the fastest ones, maybe their run times are already optimal?\n  The area that we call in this survey \"fine-grained complexity of NP-complete problems\" studies exactly this question. We invite the reader to catch up on selected classic results as well as delve into exciting recent developments in a riveting tour through the area passing by (among others) algebra, complexity theory, extremal and additive combinatorics, cryptography, and, of course, last but not least, algorithm design.","authors":["Jesper Nederlof"],"pdf_url":"","comment":"40 pages. Invited survey (currently under review, remarks are welcome)"},{"id":"http://arxiv.org/abs/2601.05026v1","updated":"2026-01-08T15:33:58Z","published":"2026-01-08T15:33:58Z","title":"A data structure for monomial ideals with applications to signature Gröbner bases","summary":"We introduce monomial divisibility diagrams (MDDs), a data structure for monomial ideals that supports insertion of new generators and fast membership tests. MDDs stem from a canonical tree representation by maximally sharing equal subtrees, yielding a directed acyclic graph. We establish basic complexity bounds for membership and insertion, and study empirically the size of MDDs. As an application, we integrate MDDs into the signature Gröbner basis implementation of the Julia package AlgebraicSolving.jl. Membership tests in monomial ideals are used to detect some reductions to zero, and the use of MDDs leads to substantial speed-ups.","authors":["Pierre Lairez","Rafael Mohr","Théo Ternier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2301.12783v4","updated":"2026-01-08T13:05:49Z","published":"2023-01-30T11:03:54Z","title":"The Leafed Induced Subtree in chordal and bounded treewidth graphs","summary":"In the Fully Leafed Induced Subtrees, one is given a graph $G$ and two integers $a$ and $b$ and the question is to find an induced subtree of $G$ with $a$ vertices and at least $b$ leaves. This problem is known to be NP-complete even when the input graph is $4$-regular. Polynomial algorithms are known when the input graph is restricted to be a tree or series-parallel. In this paper we generalize these results by providing an FPT algorithm parameterized by treewidth. We also provide a polynomial algorithm when the input graph is restricted to be a chordal graph.","authors":["Julien Baste"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:1704.07284, arXiv:2103.06536"},{"id":"http://arxiv.org/abs/2305.11352v3","updated":"2026-01-08T10:09:21Z","published":"2023-05-19T00:07:32Z","title":"Randomized adiabatic quantum linear solver algorithm with optimal complexity scaling and detailed running costs","summary":"Solving linear systems of equations is a fundamental problem with a wide variety of applications across many fields of science, and there is increasing effort to develop quantum linear solver algorithms. [Subaşi et al., Phys. Rev. Lett. (2019)] proposed a randomized algorithm inspired by adiabatic quantum computing, based on a sequence of random Hamiltonian simulation steps, with suboptimal scaling in the condition number $κ$ of the linear system and the target error $ε$. Here we go beyond these results in several ways. Firstly, using filtering~[Lin et al., Quantum (2019)] and Poissonization techniques [Cunningham et al., arXiv:2406.03972 (2024)], the algorithm complexity is improved to the optimal scaling $O(κ\\log(1/ε))$ -- an exponential improvement in $ε$, and a shaving of a $\\log κ$ scaling factor in $κ$. Secondly, the algorithm is further modified to achieve constant factor improvements, which are vital as we progress towards hardware implementations on fault-tolerant devices. We introduce a cheaper randomized walk operator method replacing Hamiltonian simulation -- which also removes the need for potentially challenging classical precomputations; randomized routines are sampled over optimized random variables; circuit constructions are improved. We obtain a closed formula rigorously upper bounding the expected number of times one needs to apply a block-encoding of the linear system matrix to output a quantum state encoding the solution to the linear system. The upper bound is $837 κ$ at $ε=10^{-10}$ for Hermitian matrices.","authors":["David Jennings","Matteo Lostaglio","Sam Pallister","Andrew T Sornborger","Yiğit Subaşı"],"pdf_url":"","comment":"19 pages. Published version"},{"id":"http://arxiv.org/abs/2601.04756v1","updated":"2026-01-08T09:22:22Z","published":"2026-01-08T09:22:22Z","title":"Branch-width of connectivity functions is fixed-parameter tractable","summary":"A connectivity function on a finite set $V$ is a symmetric submodular function $f \\colon 2^V \\to \\mathbb{Z}$ with $f(\\emptyset)=0$. We prove that finding a branch-decomposition of width at most $k$ for a connectivity function given by an oracle is fixed-parameter tractable (FPT), by providing an algorithm of running time $2^{O(k^2)} γn^6 \\log n$, where $γ$ is the time to compute $f(X)$ for any set $X$, and $n = |V|$. This improves the previous algorithm by Oum and Seymour [J. Combin. Theory Ser.~B, 2007], which runs in time $γn^{O(k)}$. Our algorithm can be applied to rank-width of graphs, branch-width of matroids, branch-width of (hyper)graphs, and carving-width of graphs. This resolves an open problem asked by Hliněný [SIAM J. Comput., 2005], who asked whether branch-width of matroids given by the rank oracle is fixed-parameter tractable. Furthermore, our algorithm improves the best known dependency on $k$ in the running times of FPT algorithms for graph branch-width, rank-width, and carving-width.","authors":["Tuukka Korhonen","Sang-il Oum"],"pdf_url":"","comment":"13 pages"},{"id":"http://arxiv.org/abs/2601.04626v1","updated":"2026-01-08T05:55:26Z","published":"2026-01-08T05:55:26Z","title":"Using Ray-shooting Queries for Sublinear Algorithms for Dominating Sets in RDV Graphs","summary":"In this paper, we study the dominating set problem in \\emph{RDV graphs}, a graph class that lies between interval graphs and chordal graphs and is defined as the \\textbf{v}ertex-intersection graphs of \\textbf{d}ownward paths in a \\textbf{r}ooted tree. It was shown in a previous paper that adjacency queries in an RDV graph can be reduced to the question whether a horizontal segment intersects a vertical segment. This was then used to find a maximum matching in an $n$-vertex RDV graph, using priority search trees, in $O(n\\log n)$ time, i.e., without even looking at all edges. In this paper, we show that if additionally we also use a ray shooting data structure, we can also find a minimum dominating set in an RDV graph $O(n\\log n)$ time (presuming a linear-sized representation of the graph is given). The same idea can also be used for a new proof to find a minimum dominating set in an interval graph in $O(n)$ time.","authors":["Therese Biedl","Prashant Gokhale"],"pdf_url":"","comment":"To appear at SOFSEM'26"},{"id":"http://arxiv.org/abs/2406.15011v3","updated":"2026-01-08T04:17:11Z","published":"2024-06-21T09:40:50Z","title":"Space-efficient SLP encoding for $O(\\log N)$-time random access","summary":"A Straight-Line Program (SLP) $G$ for a string $T$ is a context-free grammar (CFG) that derives $T$ only, which can be considered as a compressed representation of $T$. In this paper, we show how to encode $G$ in $n \\lceil \\lg N \\rceil + (n + n') \\lceil \\lg (n+σ) \\rceil + 4n - 2n' + o(n)$ bits to support random access queries of extracting $T[p..q]$ in worst-case $O(\\log N + q - p)$ time, where $N$ is the length of $T$, $σ$ is the alphabet size, $n$ is the number of variables in $G$ and $n' \\le n$ is the number of symmetric centroid paths in the DAG representation for $G$. The time complexity is almost optimal because Verbin and Yu [CPM 2013] proved that $O(\\log N)$ term cannot be significantly improved in general with $\\mathrm{poly}(n)$-space data structures. We also present alternative encodings that achieve the same random access time with $n \\lceil \\lg N \\rceil + n \\lceil \\lg (n+σ) \\rceil + 5n + n' + o(n)$ or $n \\lceil \\lg N \\rceil + n \\lceil \\lg (n+σ) \\rceil + 5n - n' + σ+ o(n+σ)$ bits of space.","authors":["Akito Takasaka","Tomohiro I"],"pdf_url":"","comment":"An extended journal version accepted for publication in the Theory of Computing Systems"},{"id":"http://arxiv.org/abs/2207.03427v2","updated":"2026-01-08T00:28:17Z","published":"2022-07-07T16:52:50Z","title":"Binary Iterative Hard Thresholding Converges with Optimal Number of Measurements for 1-Bit Compressed Sensing","summary":"Compressed sensing has been a very successful high-dimensional signal acquisition and recovery technique that relies on linear operations. However, the actual measurements of signals have to be quantized before storing or processing. 1(One)-bit compressed sensing is a heavily quantized version of compressed sensing, where each linear measurement of a signal is reduced to just one bit: the sign of the measurement. Once enough of such measurements are collected, the recovery problem in 1-bit compressed sensing aims to find the original signal with as much accuracy as possible. The recovery problem is related to the traditional \"halfspace-learning\" problem in learning theory.\n  For recovery of sparse vectors, a popular reconstruction method from 1-bit measurements is the binary iterative hard thresholding (BIHT) algorithm. The algorithm is a simple projected sub-gradient descent method, and is known to converge well empirically, despite the nonconvexity of the problem. The convergence property of BIHT was not theoretically justified, except with an exorbitantly large number of measurements (i.e., a number of measurement greater than $\\max\\{k^{10}, 24^{48}, k^{3.5}/ε\\}$, where $k$ is the sparsity, $ε$ denotes the approximation error, and even this expression hides other factors). In this paper we show that the BIHT algorithm converges with only $\\tilde{O}(\\frac{k}ε)$ measurements. Note that, this dependence on $k$ and $ε$ is optimal for any recovery method in 1-bit compressed sensing. With this result, to the best of our knowledge, BIHT is the only practical and efficient (polynomial time) algorithm that requires the optimal number of measurements in all parameters (both $k$ and $ε$). This is also an example of a gradient descent algorithm converging to the correct solution for a nonconvex problem, under suitable structural conditions.","authors":["Namiko Matsumoto","Arya Mazumdar"],"pdf_url":"","comment":"Published in Journal of the ACM, 2024; conference version published in FOCS 2022"}],"Hardware Architecture":[{"id":"http://arxiv.org/abs/2601.05057v1","updated":"2026-01-08T15:58:30Z","published":"2026-01-08T15:58:30Z","title":"Supporting Secured Integration of Microarchitectural Defenses","summary":"There has been a plethora of microarchitectural-level attacks leading to many proposed countermeasures. This has created an unexpected and unaddressed security issue where naive integration of those defenses can potentially lead to security vulnerabilities. This occurs when one defense changes an aspect of a microarchitecture that is crucial for the security of another defense. We refer to this problem as a microarchitectural defense assumption violation} (MDAV).\n  We propose a two-step methodology to screen for potential MDAVs in the early-stage of integration. The first step is to design and integrate a composed model, guided by bounded model checking of security properties. The second step is to implement the model concretely on a simulator and to evaluate with simulated attacks. As a contribution supporting the first step, we propose an event-based modeling framework, called Maestro, for testing and evaluating microarchitectural models with integrated defenses. In our evaluation, Maestro reveals MDAVs (8), supports compact expression (~15x Alloy LoC ratio), enables semantic composability and eliminates performance degradations (>100x).\n  As a contribution supporting the second step, we use an event-based simulator (GEM5) for investigating integrated microarchitectural defenses. We show that a covert channel attack is possible on a naively integrated implementation of some state-of-the-art defenses, and a repaired implementation using our integration methodology is resilient to the attack.","authors":["Kartik Ramkrishnan","Stephen McCamant","Antonia Zhai","Pen-Chung Yew"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.05047v1","updated":"2026-01-08T15:52:11Z","published":"2026-01-08T15:52:11Z","title":"Challenges and Research Directions for Large Language Model Inference Hardware","summary":"Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.","authors":["Xiaoyu Ma","David Patterson"],"pdf_url":"","comment":"Accepted for publication by IEEE Computer, 2026"},{"id":"http://arxiv.org/abs/2601.04801v1","updated":"2026-01-08T10:32:49Z","published":"2026-01-08T10:32:49Z","title":"MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration","summary":"High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at https://github.com/wslcccc/MPM-LLM4DSE.","authors":["Lei Xu","Shanshan Wang","Chenglong Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04476v1","updated":"2026-01-08T01:28:45Z","published":"2026-01-08T01:28:45Z","title":"Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing","summary":"Recent hardware acceleration advances have enabled powerful specialized accelerators for finite element computations, spiking neural network inference, and sparse tensor operations. However, existing approaches face fundamental limitations: (1) finite element methods lack comprehensive rounding error analysis for reduced-precision implementations and use fixed precision assignment strategies that cannot adapt to varying numerical conditioning; (2) spiking neural network accelerators cannot handle non-spike operations and suffer from bit-width escalation as network depth increases; and (3) FPGA tensor accelerators optimize only for dense computations while requiring manual configuration for each sparsity pattern. To address these challenges, we introduce \\textbf{Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing}, a novel framework that integrates three enhanced modules with memory-guided adaptation for efficient mixed-workload processing on unified platforms. Our approach employs memory-guided precision selection to overcome fixed precision limitations, integrates experience-driven bit-width management and dynamic parallelism adaptation for enhanced spiking neural network acceleration, and introduces curriculum learning for automatic sparsity pattern discovery. Extensive experiments on FEniCS, COMSOL, ANSYS benchmarks, MNIST, CIFAR-10, CIFAR-100, DVS-Gesture datasets, and COCO 2017 demonstrate 2.8\\% improvement in numerical accuracy, 47\\% throughput increase, 34\\% energy reduction, and 45-65\\% throughput improvement compared to specialized accelerators. Our work enables unified processing of finite element methods, spiking neural networks, and sparse computations on a single platform while eliminating data transfer overhead between separate units.","authors":["Chuanzhen Wang","Leo Zhang","Eric Liu"],"pdf_url":"","comment":"22 pages"}],"Computational Finance":[{"id":"http://arxiv.org/abs/2601.04160v2","updated":"2026-01-08T14:39:03Z","published":"2026-01-07T18:18:28Z","title":"All That Glisters Is Not Gold: A Benchmark for Reference-Free Counterfactual Financial Misinformation Detection","summary":"We introduce RFC Bench, a benchmark for evaluating large language models on financial misinformation under realistic news. RFC Bench operates at the paragraph level and captures the contextual complexity of financial news where meaning emerges from dispersed cues. The benchmark defines two complementary tasks: reference free misinformation detection and comparison based diagnosis using paired original perturbed inputs. Experiments reveal a consistent pattern: performance is substantially stronger when comparative context is available, while reference free settings expose significant weaknesses, including unstable predictions and elevated invalid outputs. These results indicate that current models struggle to maintain coherent belief states without external grounding. By highlighting this gap, RFC Bench provides a structured testbed for studying reference free reasoning and advancing more reliable financial misinformation detection in real world settings.","authors":["Yuechen Jiang","Zhiwei Liu","Yupeng Cao","Yueru He","Chen Xu","Ziyang Xu","Zhiyang Deng","Prayag Tiwari","Xi Chen","Alejandro Lopez-Lira","Jimin Huang","Junichi Tsujii","Sophia Ananiadou"],"pdf_url":"","comment":"49 pages; 24 figures"},{"id":"http://arxiv.org/abs/2601.04896v1","updated":"2026-01-08T12:49:11Z","published":"2026-01-08T12:49:11Z","title":"Deep Reinforcement Learning for Optimum Order Execution: Mitigating Risk and Maximizing Returns","summary":"Optimal Order Execution is a well-established problem in finance that pertains to the flawless execution of a trade (buy or sell) for a given volume within a specified time frame. This problem revolves around optimizing returns while minimizing risk, yet recent research predominantly focuses on addressing one aspect of this challenge. In this paper, we introduce an innovative approach to Optimal Order Execution within the US market, leveraging Deep Reinforcement Learning (DRL) to effectively address this optimization problem holistically. Our study assesses the performance of our model in comparison to two widely employed execution strategies: Volume Weighted Average Price (VWAP) and Time Weighted Average Price (TWAP). Our experimental findings clearly demonstrate that our DRL-based approach outperforms both VWAP and TWAP in terms of return on investment and risk management. The model's ability to adapt dynamically to market conditions, even during periods of market stress, underscores its promise as a robust solution.","authors":["Khabbab Zakaria","Jayapaulraj Jerinsh","Andreas Maier","Patrick Krauss","Stefano Pasquali","Dhagash Mehta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.23461v3","updated":"2026-01-08T11:49:53Z","published":"2025-10-27T16:00:15Z","title":"Adaptive Multilevel Splitting: First Application to Rare-Event Derivative Pricing","summary":"This work investigates the computational burden of pricing binary options in rare event regimes and introduces an adaptation of the adaptive multilevel splitting (AMS) method for financial derivatives. Standard Monte Carlo becomes inefficient for deep out-of-the-money binaries due to discontinuous payoffs and extremely small exercise probabilities, requiring prohibitively large sample sizes for accurate estimation. The proposed AMS framework reformulates the rare-event problem as a sequence of conditional events and is applied under both Black-Scholes and Heston dynamics. Numerical experiments cover European, Asian, and up-and-in barrier digital options, together with a multidimensional digital payoff designed as a stress test. Across all contracts, AMS achieves substantial gains, reaching up to 200-fold improvements over standard Monte Carlo, while preserving unbiasedness and showing robust performance with respect to the choice of importance function. To the best of our knowledge, this is the first application of AMS to derivative pricing. An open-source Rcpp implementation is provided, supporting multiple discretisation schemes and alternative importance functions.","authors":["Riccardo Gozzo"],"pdf_url":"","comment":"27 pages, 4 figures"},{"id":"http://arxiv.org/abs/2509.15232v2","updated":"2026-01-08T09:52:50Z","published":"2025-09-10T10:09:31Z","title":"Community-level Contagion among Diverse Financial Assets","summary":"As global financial markets become increasingly interconnected, financial contagion has developed into a major influencer of asset price dynamics. Motivated by this context, our study explores financial contagion both within and between asset communities. We contribute to the literature by examining the contagion phenomenon at the community level rather than among individual assets. Our experiments rely on high-frequency data comprising cryptocurrencies, stocks and US ETFs over the 4-year period from April 2019 to May 2023. Using the Louvain community detection algorithm, Vector Autoregression contagion detection model and Tracy-Widom random matrix theory for noise removal from financial assets, we present three main findings. Firstly, while the magnitude of contagion remains relatively stable over time, contagion density (the percentage of asset pairs exhibiting contagion within a financial system) increases. This suggests that market uncertainty is better characterized by the transmission of shocks more broadly than by the strength of any single spillover. Secondly, there is no significant difference between intra- and inter-community contagion, indicating that contagion is a system-wide phenomenon rather than being confined to specific asset groups. Lastly, certain communities themselves, especially those dominated by Information Technology assets, tend to act as major contagion transmitters in the financial network over the examined period, spreading shocks with high densities to many other communities. Our findings suggest that traditional risk management strategies such as portfolio diversification through investing in low-correlated assets or different types of investment vehicle might be insufficient due to widespread contagion.","authors":["An Pham Ngoc Nguyen","Marija Bezbradica","Martin Crane"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04608v1","updated":"2026-01-08T05:26:43Z","published":"2026-01-08T05:26:43Z","title":"Forecasting the U.S. Treasury Yield Curve: A Distributionally Robust Machine Learning Approach","summary":"We study U.S. Treasury yield curve forecasting under distributional uncertainty and recast forecasting as an operations research and managerial decision problem. Rather than minimizing average forecast error, the forecaster selects a decision rule that minimizes worst case expected loss over an ambiguity set of forecast error distributions. To this end, we propose a distributionally robust ensemble forecasting framework that integrates parametric factor models with high dimensional nonparametric machine learning models through adaptive forecast combinations. The framework consists of three machine learning components. First, a rolling window Factor Augmented Dynamic Nelson Siegel model captures level, slope, and curvature dynamics using principal components extracted from economic indicators. Second, Random Forest models capture nonlinear interactions among macro financial drivers and lagged Treasury yields. Third, distributionally robust forecast combination schemes aggregate heterogeneous forecasts under moment uncertainty, penalizing downside tail risk via expected shortfall and stabilizing second moment estimation through ridge regularized covariance matrices. The severity of the worst case criterion is adjustable, allowing the forecaster to regulate the trade off between robustness and statistical efficiency. Using monthly data, we evaluate out of sample forecasts across maturities and horizons from one to twelve months ahead. Adaptive combinations deliver superior performance at short horizons, while Random Forest forecasts dominate at longer horizons. Extensions to global sovereign bond yields confirm the stability and generalizability of the proposed framework.","authors":["Jinjun Liu","Ming-Yen Cheng"],"pdf_url":"","comment":"44 pages( including e-companion), 6 figures, under journal review"},{"id":"http://arxiv.org/abs/2601.04602v1","updated":"2026-01-08T05:16:06Z","published":"2026-01-08T05:16:06Z","title":"Forecasting Equity Correlations with Hybrid Transformer Graph Neural Network","summary":"This paper studies forward-looking stock-stock correlation forecasting for S\\&P 500 constituents and evaluates whether learned correlation forecasts can improve graph-based clustering used in basket trading strategies. We cast 10-day ahead correlation prediction in Fisher-z space and train a Temporal-Heterogeneous Graph Neural Network (THGNN) to predict residual deviations from a rolling historical baseline. The architecture combines a Transformer-based temporal encoder, which captures non-stationary, complex, temporal dependencies, with an edge-aware graph attention network that propagates cross-asset information over the equity network. Inputs span daily returns, technicals, sector structure, previous correlations, and macro signals, enabling regime-aware forecasts and attention-based feature and neighbor importance to provide interpretability. Out-of-sample results from 2019-2024 show that the proposed model meaningfully reduces correlation forecasting error relative to rolling-window estimates. When integrated into a graph-based clustering framework, forward-looking correlations produce adaptable and economically meaningfully baskets, particularly during periods of market stress. These findings suggest that improvements in correlation forecasts translate into meaningful gains during portfolio construction tasks.","authors":["Jack Fanshawe","Rumi Masih","Alexander Cameron"],"pdf_url":"","comment":"23 pages, 9 large figures, detailed appendix"},{"id":"http://arxiv.org/abs/2506.18210v3","updated":"2026-01-08T03:11:06Z","published":"2025-06-23T00:13:08Z","title":"American options valuation in time-dependent jump-diffusion models via integral equations and characteristic functions","summary":"Despite significant advancements in machine learning for derivative pricing, the efficient and accurate valuation of American options remains a persistent challenge due to complex exercise boundaries, near-expiry behavior, and intricate contractual features. This paper extends a semi-analytical approach for pricing American options in time-inhomogeneous models, including pure diffusions, jump-diffusions, and Levy processes. Building on prior work, we derive and solve Volterra integral equations of the second kind to determine the exercise boundary explicitly, offering a computationally superior alternative to traditional finite-difference and Monte Carlo methods. We address key open problems: (1) extending the decomposition method, i.e. splitting the American option price into its European counterpart and an early exercise premium, to general jump-diffusion and Levy models; (2) handling cases where closed-form transition densities are unavailable by leveraging characteristic functions via, e.g., the COS method; and (3) generalizing the framework to multidimensional diffusions. Numerical examples demonstrate the method's efficiency and robustness. Our results underscore the advantages of the integral equation approach for large-scale industrial applications, while resolving some limitations of existing techniques.","authors":["Andrey Itkin"],"pdf_url":"","comment":"27 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2108.00480v5","updated":"2026-01-08T00:40:43Z","published":"2021-08-01T15:43:57Z","title":"Realised Volatility Forecasting: Machine Learning via Financial Word Embedding","summary":"We examine whether news can improve realised volatility forecasting using a modern yet operationally simple NLP framework. News text is transformed into embedding-based representations, and forecasts are evaluated both as a standalone, news-only model and as a complement to standard realised volatility benchmarks. In out-of-sample tests on a cross-section of stocks, news contains useful predictive information, with stronger effects for stock-related content and during high volatility days. Combining the news-based signal with a leading benchmark yields consistent improvements in statistical performance and economically meaningful gains, while explainability analysis highlights the news themes most relevant for volatility.","authors":["Eghbal Rahimikia","Stefan Zohren","Ser-Huang Poon"],"pdf_url":"","comment":null}],"Mathematical Finance":[{"id":"http://arxiv.org/abs/2409.09179v2","updated":"2026-01-08T16:46:59Z","published":"2024-09-13T20:35:18Z","title":"Credit Spreads' Term Structure: Stochastic Modeling with CIR++ Intensity","summary":"This paper introduces a novel stochastic model for credit spreads. The stochastic approach leverages the diffusion of default intensities via a CIR++ model and is formulated within a risk-neutral probability space. Our research primarily addresses two gaps in the literature. The first is the lack of credit spread models founded on a stochastic basis that enables continuous modeling, as many existing models rely on factorial assumptions. The second is the limited availability of models that directly yield a term structure of credit spreads. An intermediate result of our model is the provision of a term structure for the prices of defaultable bonds. We present the model alongside an innovative, practical, and conservative calibration approach that minimizes the error between historical and theoretical volatilities of default intensities. We demonstrate the robustness of both the model and its calibration process by comparing its behavior to historical credit spread values. Our findings indicate that the model not only produces realistic credit spread term structure curves but also exhibits consistent diffusion over time. Additionally, the model accurately fits the initial term structure of implied survival probabilities and provides an analytical expression for the credit spread of any given maturity at any future time.","authors":["Mohamed Ben Alaya","Ahmed Kebaier","Djibril Sarr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04914v1","updated":"2026-01-08T13:13:14Z","published":"2026-01-08T13:13:14Z","title":"Analytic Regularity and Approximation Limits of Coefficient-Constrained Shallow Networks","summary":"We study approximation limits of single-hidden-layer neural networks with analytic activation functions under global coefficient constraints. Under uniform $\\ell^1$ bounds, or more generally sub-exponential growth of the coefficients, we show that such networks generate model classes with strong quantitative regularity, leading to uniform analyticity of the realized functions. As a consequence, up to an exponentially small residual term, the error of best network approximation on generic target functions is bounded from below by the error of best polynomial approximation. In particular, networks with analytic activation functions with controlled coefficients cannot outperform classical polynomial approximation rates on non-analytic targets. The underlying rigidity phenomenon extends to smoother, non-analytic activations satisfying Gevrey-type regularity assumptions, yielding sub-exponential variants of the approximation barrier. The analysis is entirely deterministic and relies on a comparison argument combined with classical Bernstein-type estimates; extensions to higher dimensions are also discussed.","authors":["Jean-Gabriel Attali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04900v1","updated":"2026-01-08T12:55:12Z","published":"2026-01-08T12:55:12Z","title":"Uniqueness of invariant measures as a structural property of markov kernels","summary":"We identify indecomposability as a key measure-theoretic underlying uniqueness of invariant probability measures for discrete-time Markov kernels on general state spaces. The argument relies on the mutual singularity of distinct invariant ergodic measures and on the observation that uniqueness follows whenever all invariant probability measures are forced to charge a common reference measure.\n  Once existence of invariant probability measures is known, indecomposability alone is sufficient to rule out multiplicity. On standard Borel spaces, this viewpoint is consistent with the classical theory: irreducibility appears as a convenient sufficient condition ensuring indecomposability, rather than as a structural requirement for uniqueness.\n  The resulting proofs are purely measure-theoretic and do not rely on recurrence, regeneration, return-time estimates, or regularity assumptions on the transition kernel.","authors":["Jean-Gabriel Attali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04608v1","updated":"2026-01-08T05:26:43Z","published":"2026-01-08T05:26:43Z","title":"Forecasting the U.S. Treasury Yield Curve: A Distributionally Robust Machine Learning Approach","summary":"We study U.S. Treasury yield curve forecasting under distributional uncertainty and recast forecasting as an operations research and managerial decision problem. Rather than minimizing average forecast error, the forecaster selects a decision rule that minimizes worst case expected loss over an ambiguity set of forecast error distributions. To this end, we propose a distributionally robust ensemble forecasting framework that integrates parametric factor models with high dimensional nonparametric machine learning models through adaptive forecast combinations. The framework consists of three machine learning components. First, a rolling window Factor Augmented Dynamic Nelson Siegel model captures level, slope, and curvature dynamics using principal components extracted from economic indicators. Second, Random Forest models capture nonlinear interactions among macro financial drivers and lagged Treasury yields. Third, distributionally robust forecast combination schemes aggregate heterogeneous forecasts under moment uncertainty, penalizing downside tail risk via expected shortfall and stabilizing second moment estimation through ridge regularized covariance matrices. The severity of the worst case criterion is adjustable, allowing the forecaster to regulate the trade off between robustness and statistical efficiency. Using monthly data, we evaluate out of sample forecasts across maturities and horizons from one to twelve months ahead. Adaptive combinations deliver superior performance at short horizons, while Random Forest forecasts dominate at longer horizons. Extensions to global sovereign bond yields confirm the stability and generalizability of the proposed framework.","authors":["Jinjun Liu","Ming-Yen Cheng"],"pdf_url":"","comment":"44 pages( including e-companion), 6 figures, under journal review"},{"id":"http://arxiv.org/abs/2506.18210v3","updated":"2026-01-08T03:11:06Z","published":"2025-06-23T00:13:08Z","title":"American options valuation in time-dependent jump-diffusion models via integral equations and characteristic functions","summary":"Despite significant advancements in machine learning for derivative pricing, the efficient and accurate valuation of American options remains a persistent challenge due to complex exercise boundaries, near-expiry behavior, and intricate contractual features. This paper extends a semi-analytical approach for pricing American options in time-inhomogeneous models, including pure diffusions, jump-diffusions, and Levy processes. Building on prior work, we derive and solve Volterra integral equations of the second kind to determine the exercise boundary explicitly, offering a computationally superior alternative to traditional finite-difference and Monte Carlo methods. We address key open problems: (1) extending the decomposition method, i.e. splitting the American option price into its European counterpart and an early exercise premium, to general jump-diffusion and Levy models; (2) handling cases where closed-form transition densities are unavailable by leveraging characteristic functions via, e.g., the COS method; and (3) generalizing the framework to multidimensional diffusions. Numerical examples demonstrate the method's efficiency and robustness. Our results underscore the advantages of the integral equation approach for large-scale industrial applications, while resolving some limitations of existing techniques.","authors":["Andrey Itkin"],"pdf_url":"","comment":"27 pages, 3 figures, 2 tables"}],"Portfolio Management":[{"id":"http://arxiv.org/abs/2504.15268v16","updated":"2026-01-08T11:52:13Z","published":"2025-04-21T17:52:36Z","title":"Beyond Correlation: Positive Definite Dependence Measures for Robust Inference, Flexible Scenarios, and Causal Modeling for Financial Portfolios","summary":"We live in a multivariate world, and effective modeling of financial portfolios, including their construction, allocation, forecasting, and risk analysis, simply is not possible without explicitly modeling the dependence structure of their assets. Dependence structure can drive portfolio results more than the combined effects of other parameters in investment and risk models, but the literature provides relatively little to define the finite-sample distributions of dependence measures under challenging, real-world financial data conditions. Yet this is exactly what is needed to make valid inferences about their estimates, and to use these inferences for essential purposes such as hypothesis testing, dynamic monitoring, realistic and granular scenario and reverse scenario analyses, and mitigating the effects of correlation breakdowns during market upheavals. This work develops a new and straightforward method, Nonparametric Angles-based Correlation (NAbC), for defining the finite-sample distributions of any dependence measure whose matrix of pairwise associations is positive definite (e.g. Pearsons, Kendalls, Spearmans, the Tail Dependence Matrix, and others). The solution remains valid under marginal asset distributions characterized by notably different and varying degrees of serial correlation, non-stationarity, heavy-tailedness, and asymmetry. Importantly, it provides p-values and confidence intervals at the matrix level, even when selected cells in the matrix are frozen, thus enabling flexible, granular, and realistic scenarios, reverse scenarios, and stress tests. Finally, when applied to directional dependence measures, NAbC enables accurate DAG recovery in causal modeling. NAbC stands alone in providing all of these capabilities simultaneously, and should prove to be a very useful means by which we can better understand and manage financial portfolios in our multivariate world.","authors":["JD Opdyke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.04062v2","updated":"2026-01-08T07:58:48Z","published":"2026-01-07T16:28:30Z","title":"Smart Predict--then--Optimize Paradigm for Portfolio Optimization in Real Markets","summary":"Improvements in return forecast accuracy do not always lead to proportional improvements in portfolio decision quality, especially under realistic trading frictions and constraints. This paper adopts the Smart Predict--then--Optimize (SPO) paradigm for portfolio optimization in real markets, which explicitly aligns the learning objective with downstream portfolio decision quality rather than pointwise prediction accuracy. Within this paradigm, predictive models are trained using an SPO-based surrogate loss that directly reflects the performance of the resulting investment decisions. To preserve interpretability and robustness, we employ linear predictors built on return-based and technical-indicator features and integrate them with portfolio optimization models that incorporate transaction costs, turnover control, and regularization. We evaluate the proposed approach on U.S. ETF data (2015--2025) using a rolling-window backtest with monthly rebalancing. Empirical results show that decision-focused training consistently improves risk-adjusted performance over predict--then--optimize baselines and classical optimization benchmarks, and yields strong robustness during adverse market regimes (e.g., the 2020 COVID-19). These findings highlight the practical value of the Smart Predict--then--Optimize paradigm for portfolio optimization in realistic and non-stationary financial environments.","authors":["Wang Yi","Takashi Hasuike"],"pdf_url":"","comment":null}]}}